<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-100 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-100</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-100</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-5.html">extraction-schema-5</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <p><strong>Paper ID:</strong> paper-63b7543c141db9d67f72c429d22d61c7bab0d3d8</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/63b7543c141db9d67f72c429d22d61c7bab0d3d8" target="_blank">Emergence of Stable Synaptic Clusters on Dendrites Through Synaptic Rewiring</a></p>
                <p><strong>Paper Venue:</strong> Frontiers in Computational Neuroscience</p>
                <p><strong>Paper TL;DR:</strong> It is found that synaptic clustering through the proposed rewiring mechanism can serve as a mechanism to protect memories from subsequent modifications on a medium time scale, and may counteract the general problem of catastrophic forgetting in neural networks.</p>
                <p><strong>Paper Abstract:</strong> The connectivity structure of neuronal networks in cortex is highly dynamic. This ongoing cortical rewiring is assumed to serve important functions for learning and memory. We analyze in this article a model for the self-organization of synaptic inputs onto dendritic branches of pyramidal cells. The model combines a generic stochastic rewiring principle with a simple synaptic plasticity rule that depends on local dendritic activity. In computer simulations, we find that this synaptic rewiring model leads to synaptic clustering, that is, temporally correlated inputs become locally clustered on dendritic branches. This empirical finding is backed up by a theoretical analysis which shows that rewiring in our model favors network configurations with synaptic clustering. We propose that synaptic clustering plays an important role in the organization of computation and memory in cortical circuits: we find that synaptic clustering through the proposed rewiring mechanism can serve as a mechanism to protect memories from subsequent modifications on a medium time scale. Rewiring of synaptic connections onto specific dendritic branches may thus counteract the general problem of catastrophic forgetting in neural networks.</p>
                <p><strong>Cost:</strong> 0.022</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e100.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e100.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Dendritic-spike-dependent plasticity</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Dendritic-spike-dependent synaptic plasticity (branch-local NMDA plateau gated LTP/LTD)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A plasticity rule in which coincidence of presynaptic activity with a local dendritic NMDA plateau (dendritic spike) drives potentiation of active synapses and depression of inactive synapses on that branch; induction is gated by the presence and timing/duration of dendritic plateau potentials.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>Dendritic-spike-dependent LTP/LTD</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>Plasticity updates occur only during a branch-local NMDA plateau potential (Γ_k(t)=1). For established synapses (θ_{ki}>0) the deterministic functional term is f_{ki}^L(t) = c_L Γ_k(t) ( x_i(t) - γ(1 - x_i(t)) ), where x_i(t) is an exponential presynaptic spike trace (τ_x = 20 ms by default), c_L scales potentiation, and γ sets threshold between LTD and LTP; inactive/non-established synapses receive no deterministic update. An alternative variant (Cichon & Gan style) uses two presynaptic traces (fast LTP trace τ≈20 ms incremented during plateaus, and slow LTD trace τ≈500 ms incremented outside plateaus) and separates a potentiation term gated by presence of plateau and a depression term gated by dendritic spike onset. Only functional synapses are subject to deterministic updates; non-established synapses change only by stochastic noise crossing θ through zero.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>Fast: presynaptic spike timing and dendritic spike gating operate on milliseconds to hundreds of milliseconds (presynaptic trace τ_x≈20 ms; dendritic plateau durations 20–300 ms; LTP/LTD induction during plateau). Slow/structural: resulting synapse creation/deletion via θ crossing (stochastic) occurs over minutes to hours (simulations show clustering in ~17 min; biological references indicate hours–days for spine turnover).</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>Cortical pyramidal cells (layer V pyramidal neuron model with multiple dendritic branches); branch-local dendritic compartments (tuft/basal branches) receiving inputs from input assemblies.</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>Controls local placement (presence and weight) of synapses on dendritic branches, promoting clustering of temporally correlated inputs onto the same branch; interacts with a soft bound on number of synapses per branch (N_syn = 20) enforced by structural term.</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Associative / pattern memorization and retention (storage of input assemblies, motor/task-specific representations), protection against catastrophic forgetting in incremental learning.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Computational spiking neuron model (multi-compartment branch model) with simulations and theoretical analysis; rule motivated by experimental studies (Golding et al. 2002; Cichon & Gan 2015 etc.).</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>Fast dendritic events (ms→100s ms) provide the local gating signal for plasticity (when Γ_k=1). Slow synaptic parameters θ integrate many such events with a small learning rate η and a stochastic term, so repeated gated events over minutes drive θ positive (establish or strengthen synapse) while lack of activation with plateaus drives θ negative (weakening and eventual deletion). Thus rapid spike coincidences determine the sign of plasticity instantaneously, while network-level rewiring and stable cluster formation emerge over minutes-to-hours via cumulative θ changes and stochastic re-sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>When plasticity is gated by local dendritic plateau potentials, temporally correlated presynaptic inputs self-organize into clusters on individual dendritic branches (assembly-specific clustering). Branch-local gating is necessary: removing dendritic nonlinearities (linear integration) abolished clustering. The dendritic-spike-dependent rule both potentiates co-active synapses during plateaus and depresses inactive synapses on that branch, causing weak synapses to retract and clusters to form. Clustering emerges in simulations within ~17 minutes of patterned activation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td>Cluster criterion: branch considered clustered if it receives ≥10 synapses from one assembly with total weight ≥50 nA (50 nA chosen as threshold likely to elicit dendritic spike). Observed network metrics: baseline firing ≈6.19 Hz; during strong clustered assembly activation firing up to ≈63.5 Hz; cluster emergence in simulations after 17 min of pattern presentation. With this rule alone (without STDP) mean represented assemblies ≈6.36 ± 0.84 (n=25 runs) out of 8 assemblies.</td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>The paper reports that clustering provides medium-timescale protection (minutes→hours) of stored patterns against subsequent rewiring. However, stochastic noise in θ causes gradual forgetting over longer timescales (simulations and supplement). Authors propose additional consolidation strategies (in Supplementary Material) to reduce gradual forgetting; no full systems-level consolidation to very long (days+) memory is implemented in the main model.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Emergence of Stable Synaptic Clusters on Dendrites Through Synaptic Rewiring', 'publication_date_yy_mm': '2020-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e100.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e100.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>STDP (inverted distal)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Spike-timing-dependent plasticity (inverted pre-before-post depression for distal dendrites)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A somatically-mediated STDP-like mechanism implemented as global competition across branches: each somatic spike causes depression at synapses that had recent presynaptic activity but whose branch was inactive, thereby introducing competition between branches for representing patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>Inverted STDP (pre-before-post → LTD)</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>STDP update is implemented as an additional term f_{ki}^{STDP}(t) = -c_STDP x_i(t) S(t) when local branch voltage V_k^b(t) >= STDP_th, where x_i(t) is the presynaptic trace (τ_x = 20 ms), S(t) is somatic spike train (Dirac pulses), c_STDP scales LTD; this implements depression at synapses that recently fired when the neuron spikes but the local branch was not strongly activated, corresponding to inverted STDP observed in distal dendrites (Kampa et al. 2007). It is applied only to established synapses (θ>0).</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>Milliseconds to tens of milliseconds (presynaptic trace τ_x = 20 ms; STDP events triggered at somatic spikes). Cumulative effects on branch competition and resource allocation evolve over minutes in simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>Cortical pyramidal neurons (distal dendrites vs soma) — distal dendritic synapses subject to inverted STDP-like depression mediated by somatic spikes.</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>Introduces competition across dendritic branches leading to decorrelation of clusters across branches (reduces multiple branches clustering the same assembly); increases effective capacity by ensuring one assembly tends to occupy a small number of branches.</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Pattern separation / capacity increase for storing multiple associative patterns; supports sequential learning by preventing early patterns from occupying all branches.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Computational model implementation inspired by experimental findings (e.g., Kampa et al. 2007) and used in simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>Fast STDP depressions occur on ms–tens of ms at each somatic spike, but their repeated application across many pattern presentations biases slow θ dynamics so that only branches that earlier developed strong clusters remain potentiated; this shapes the slow rewiring distribution and increases the number of represented assemblies over minutes of learning.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Adding this STDP term increased the average number of assemblies represented on the neuron from 6.36 ± 0.84 to 7.40 ± 0.57 (n=25, significant t-test p<0.0001) and improved capacity to store assemblies, especially under sequential presentation, by enforcing competition between branches; without STDP sequential learning caused early assemblies to occupy most branches (mean represented assemblies dropped to 4.04 ± 0.72 without STDP in sequential paradigm).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td>Quantitative increases: represented assemblies mean increased from 6.36 ± 0.84 to 7.40 ± 0.57; in sequential presentation with STDP mean represented assemblies 6.92 ± 0.89; without STDP 4.04 ± 0.72 (n=25 trials). STDP parameters: c_STDP=3.2, STDPth=-67 mV, τ_s=20 ms.</td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>STDP acts as a fast competitive mechanism that shapes slow structural changes; it indirectly protects older clusters by depressing synapses at branches that would otherwise form competing clusters, but it is not a consolidation mechanism per se. Consolidation of long-term memories is discussed as requiring additional mechanisms (Supplementary Material).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Emergence of Stable Synaptic Clusters on Dendrites Through Synaptic Rewiring', 'publication_date_yy_mm': '2020-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e100.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e100.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Synaptic sampling / rewiring</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Synaptic sampling framework for stochastic rewiring (Kappel et al. framework applied here)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A probabilistic framework that models synaptic parameters θ as undergoing Langevin dynamics combining deterministic gradients from structural priors and functional likelihoods with a stochastic (Wiener) term, so the network performs stochastic sampling over possible connectivity configurations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Network plasticity as Bayesian inference</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>Synaptic sampling (stochastic gradient Langevin dynamics)</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>Parameter θ_{ki} follows SDE dθ = η(∂_θ log p_S(θ) + ∂_θ log p_L(θ)) dt + √(2ηT) dW, where p_S encodes structural prior (e.g., soft bound on synapse count per branch) and p_L encodes functional likelihood (rewarding synaptic configurations that produce dendritic plateaus in coordination with presynaptic activity); the stochastic term (temperature T) yields exploration and spontaneous spine turnover, and θ's sign encodes whether synapse is established (θ>0 mapped to weight w=c0 θ).</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>Fast stochastic term acts continuously (ms-scale updates in simulation time-step 1 ms), but effective structural rewiring (θ crossing zero and network-level configuration changes) occurs over many iterations and corresponds to minutes→hours (and biologically hours→days for spine turnover). Temperature T and learning rate η control exploration vs exploitation and timescale of changes (η=0.002, T=0.3 in simulations).</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>Applied to model of cortical pyramidal neuron dendritic compartments; each branch has many potential synapses from presynaptic population.</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>Samples connectivity structures from a posterior proportional to p_S(θ) p_L(θ)^(1/T); favors configurations that meet structural constraints (sparse count per branch) and functional goals (clustered inputs that drive plateaus). This produces assembly-specific clustering and dynamic addition/deletion of synapses (rewiring).</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Unsupervised/stochastic structural optimization supporting associative storage and memory protection via selection of clustered configurations (a form of structure learning and continual learning).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Computational / theoretical model; uses synaptic sampling theory from Kappel et al. and implements it in spiking multi-branch neuron simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>Deterministic gradients (∂ log p_L and ∂ log p_S) reflect accumulated functional/structural preferences over long input exposure windows (minutes), while the stochastic Wiener process causes spontaneous synapse turnover on longer timescales and permits exploration of alternative connectivity; the combination yields a sampling process where fast spike interactions shape the functional likelihood, and slow θ evolution implements rewiring.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The dynamics approximate Langevin sampling from p*(θ) ∝ (p_S(θ) p_L(θ))^{1/T}, which favors clustered synaptic configurations that produce branch-local dendritic plateaus. This provides a principled explanation of why rewiring leads to clustering and how structural constraints and stochasticity interact to explore connectivity space. Rewiring plus functional term leads to stable clusters in simulations and can protect memories at medium timescales.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td>Model parameters: η=0.002, T=0.3, c0=1 nA mapping, N_syn=20 soft bound. Empirical outcomes: clustering emerged within ~17 minutes of patterned inputs; number of represented assemblies quantified as above. Analytical result: stationary distribution p*(θ) given by Equation (5) indicates sampling over connectivity space.</td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>Synaptic sampling provides medium-timescale stabilization of configurations (clusters) via the functional likelihood; long-term consolidation beyond stochastic erosion is not intrinsic but can be added (authors discuss simple consolidation mechanisms in Supplementary Material).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Emergence of Stable Synaptic Clusters on Dendrites Through Synaptic Rewiring', 'publication_date_yy_mm': '2020-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e100.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e100.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Synapse-autonomous stochastic turnover</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Synapse-autonomous stochastic component (Wiener process-driven random walk of synaptic parameter θ)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An activity-independent stochastic term in the synaptic parameter dynamics implemented as Wiener-process increments that cause spontaneous fluctuations in θ and can lead to random creation (θ crossing 0 upward) and deletion (θ crossing 0 downward) of synapses, modeling spine turnover.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>Stochastic synapse-autonomous random walk</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>Added SDE term √(2 η T) dW_{ki} (Wiener process) produces unbiased stochastic fluctuations of synaptic parameter θ_{ki} even when deterministic terms vanish (θ≤0 or small). This models experimentally observed spine autonomous variability and provides spontaneous creation of new synapses when the random walk crosses zero, enabling exploration and turnover.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>Operates continuously but effect on connectivity (creation/deletion of synapses) occurs over minutes to hours in simulations and is interpreted as corresponding to hours→days-scale biological spine turnover; strength controlled by temperature T (T=0.3 in simulations) and learning rate η.</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>Modeled for cortical pyramidal neuron dendritic branches; represents spontaneous spine dynamics observed in cortex.</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>Generates ongoing rewiring and exploration of potential synaptic partners; interacts with functional plasticity to bias which spontaneously created synapses are stabilized (those that participate in plateaus become potentiated).</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Enables continuous structural exploration that supports long-term reorganization and recovery, contributes to forgetting/gradual change if memories aren't reinforced, and allows sampling-based search for functionally advantageous wiring.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Computational model motivated by experimental observations of autonomous spine size fluctuation (e.g., Yasumatsu et al. 2008; Dvorkin & Ziv 2016).</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>Fast timescale: stochastic increments occur at each simulation timestep (1 ms). Slow timescale: accumulation of fluctuations leads to crossing of establishment threshold and hence synapse addition/deletion on minutes–hours scale; when coupled with fast dendritic-gated plasticity, only those stochastic events that coincide with functional relevance are stabilized over long times.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Stochastic component is necessary to implement ongoing rewiring and to enable the system to explore connectivity configurations. It also explains gradual forgetting if memories are not repeatedly activated (noise-induced erosion). Authors quantify that older memories decay over much longer times than pattern presentation intervals, and they propose consolidation mechanisms to mitigate this.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td>Simulation parameters: η=0.002, T=0.3. Observed behavioral consequences: gradual weakening of inactive clusters over time; supplement contains analyses of weight decrease as function of noise strength. No single numerical forgetting time constant provided in main text, but clusters formed in ~17 min and decay occurs over longer, noise-dependent timescales.</td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>Paper notes that this stochastic term necessitates additional consolidation to maintain memories long-term; authors present possible consolidation methods in the Supplementary Material to reduce gradual forgetting and stabilize old clusters against noise-induced erosion.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Emergence of Stable Synaptic Clusters on Dendrites Through Synaptic Rewiring', 'publication_date_yy_mm': '2020-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e100.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e100.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Structural prior (soft synapse count)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Structural plasticity prior enforcing a soft upper bound on synapses per branch</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A deterministic structural term that penalizes branches approaching a target maximum number of active synapses (N_syn), implemented via a differentiable soft-count and sigmoid penalty that depresses weak synapses when branch synapse count is close to or exceeds N_syn.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>Soft-count structural plasticity prior</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>Defines a soft synapse count N(θ_k)=Σ_i 2(σ(c_w w_{ki}) - 0.5) where σ is logistic sigmoid; structural term f_{ki}^S = -2 λ c_w c0 [1 - σ(λ(N_syn - N(θ_k)))] σ'(c_w w_{ki}) H(θ_{ki}), which depresses (small) weights when the branch synapse count approaches/exceeds N_syn (N_syn=20 used). This term vanishes when θ≤0 and otherwise enforces sparsity per branch.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>Operates continuously in parameter update dynamics; effects on connectivity manifest over minutes in simulations (in combination with other terms) but reflect structural constraints that are physiologically on hours–days scale.</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>Applied to dendritic branches of cortical pyramidal neuron model to reflect physical limit of number of synapses per dendritic compartment.</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>Enforces local sparsity per branch and prevents unbounded accumulation of synapses on a single branch; biases rewiring to distribute clusters across branches and maintain resource constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Supports structural organization of associative learning by constraining where clusters can form (promotes distribution of assemblies across branches); contributes indirectly to memory capacity and pattern segregation.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Computational implementation to model plausible anatomical constraints; motivated by cortical branch synapse limits.</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>Acts on same slow θ dynamics as functional term; structural prior provides a slowly varying pressure that interacts with fast dendritic gating and stochastic exploration so that cluster formation must additionally satisfy local synapse count constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Including the structural prior produced realistic cluster sizes and prevented all synapses from accumulating on a few branches; combined with functional term and stochastic sampling it yields a stationary distribution favoring clustered yet locally sparse configurations.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td>Parameter N_syn=20; λ and c_w control sigmoidal steepness (λ=10, c_w=0.55 nA^{-1}). Structural term contributes to sampled stationary distribution p*(θ) and was used in all simulations that produced clustering.</td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>Structural prior itself is not a consolidation mechanism but constrains where consolidation could act; combined with added consolidation (Supplement) can help protect memories by preventing new connections from crowding branches that store prior memories.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Emergence of Stable Synaptic Clusters on Dendrites Through Synaptic Rewiring', 'publication_date_yy_mm': '2020-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e100.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e100.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Synaptic clustering (assembly-specific)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Assembly-specific synaptic clustering on dendritic branches</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A connectivity pattern in which inputs that are temporally correlated (part of the same input assembly or memory engram) become co-localized and strengthened on the same dendritic branch, producing branch-specific activation patterns (dendritic plateaus) and segregated representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>n/a</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>Not a single plasticity rule but an emergent connectivity motif resulting from the interaction of dendritic-spike-dependent plasticity, stochastic rewiring, structural prior, and optional STDP: repeated co-activation of an assembly produces potentiation of its synapses on a branch during plateaus while other synapses on that branch are depressed, leading to a concentrated cluster of strong synapses from that assembly.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>Emerges from fast spike coincidences (ms→100s ms) gated by dendritic plateaus; cluster formation observed in simulations within ~17 minutes of patterned input; biological structural rewiring and spine turnover supporting clustering is on hours→days scale according to cited literature.</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>Cortical pyramidal neurons (dendritic branches of PCs, e.g., layer V tuft/basal dendrites); assemblies of presynaptic cortical neurons representing sensory, motor or memory-related activity.</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>Local clustering (many strong synapses from the same assembly on one branch) and segregation (different assemblies occupy different branches); some branches remain un-specialized and available for future patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Associative memory encoding (task-specific or pattern-specific representations), increases memory retention for previously learned patterns and helps avoid catastrophic forgetting on a medium timescale by segregating representations across dendritic subunits.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Observed in the computational model presented here; hypothesis linked to experimental observations (e.g., Cichon & Gan 2015; Fu et al. 2012) and to theoretical literature (e.g., Govindarajan et al. 2006).</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>Fast co-activation events (ms–100s ms) cause local potentiation during plateaus; repeated activations over minutes solidify clusters via θ updates; stochastic turnover and structural constraints act on longer times (minutes→hours) and determine long-term stability; occasional reactivation restores weakened clusters before stochastic erosion leads to forgetting.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Simulations show robust emergence of assembly-specific clusters on branches when inputs are reliably co-activated; STDP increases number of distinct assemblies represented and prevents early patterns from monopolizing branches; clustering confers functional benefits: branches with clusters produce dendritic plateaus and strong somatic responses to their associated assembly, while novel or non-clustered assemblies elicit low response.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td>Quantified by 'number of represented assemblies' per neuron (criteria: ≥10 synapses from assembly and total weight ≥50 nA). Example numbers: with STDP and intermixed presentation mean represented assemblies 7.40 ± 0.57; without STDP 6.36 ± 0.84. Neuronal firing during cluster activation up to ≈63.5 Hz; response to novel random assemblies ≈11.3 Hz versus ≈27.6 Hz to memorized in one test.</td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>Clustering provides a medium-timescale protective effect against overwriting by novel patterns by isolating plasticity to branches activated by the novel pattern; however, long-term consolidation beyond stochastic decay requires additional mechanisms (authors propose possible consolidation in Supplementary Material).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Emergence of Stable Synaptic Clusters on Dendrites Through Synaptic Rewiring', 'publication_date_yy_mm': '2020-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Branch-specific dendritic Ca2+ spikes cause persistent synaptic plasticity <em>(Rating: 2)</em></li>
                <li>Network plasticity as Bayesian inference <em>(Rating: 2)</em></li>
                <li>A clustered plasticity model of long-term memory engrams <em>(Rating: 1)</em></li>
                <li>Dendritic spikes as a mechanism for cooperative long-term potentiation <em>(Rating: 1)</em></li>
                <li>Functional mapping of single spines in cortical neurons in vivo <em>(Rating: 1)</em></li>
            </ol>
        </div>

        </div>

    </div>
</body>
</html>