<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-112 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-112</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-112</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-5.html">extraction-schema-5</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <p><strong>Paper ID:</strong> paper-e33118890da9d2a1b1d08670b46bef2b59d2a996</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/e33118890da9d2a1b1d08670b46bef2b59d2a996" target="_blank">Learning Input Correlations through Nonlinear Temporally Asymmetric Hebbian Plasticity</a></p>
                <p><strong>Paper Venue:</strong> Journal of Neuroscience</p>
                <p><strong>Paper TL;DR:</strong> It is demonstrated that by adjusting the weight dependence of the synaptic changes in TAH plasticity, it is possible to enhance the synaptic representation of temporal input correlations while maintaining the system in a stable learning regime, and the learning efficiency can be optimized.</p>
                <p><strong>Cost:</strong> 0.024</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e112.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e112.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NLTAH</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Nonlinear Temporally Asymmetric Hebbian plasticity (generalized STDP)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A family of spike-timing-dependent plasticity rules that introduce a power-law weight dependence f_+(w)=(1-w)^μ and f_-(w)=α w^μ, interpolating between additive (μ=0) and multiplicative (μ=1) STDP; designed to balance sensitivity to input correlations and stability of synaptic dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>Temporally asymmetric Hebbian plasticity (STDP-like) with nonlinear weight dependence (NLTAH)</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>Single spike-pair update: Δw = λ f_+(w) K(Δt) for Δt>0 (potentiation) and Δw = -λ f_-(w) K(Δt) for Δt≤0 (depression), where K(Δt)=exp(-|Δt|/τ) (τ=20 ms here). Weight-dependence: f_+(w)=(1-w)^μ, f_-(w)=α w^μ (μ≥0, α>0). μ=0 -> additive (Δw independent of w, requires clipping), μ=1 -> multiplicative (linear attenuation toward boundaries). Plasticity is implemented by summing contributions of all causal/anti-causal spike pairs (pairwise additive composition). Key parameters: μ (weight-dependence exponent), α (potentiation/depression asymmetry), λ (learning rate, e.g., 0.001), τ (time constant of STDP window, 20 ms).</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>Fast: spike-timing window τ = 20 ms (individual pair updates sensitive on tens of milliseconds). Slow: small learning rate λ (e.g., 0.001) causes accumulation of changes over seconds → minutes → longer (simulations read out equilibria after hundreds of seconds); rule therefore links ms-scale spike timing to long-term synaptic reconfiguration over seconds–hours (implicitly long-term memory).</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>Generic cortical-like afferent pool to a single postsynaptic neuron (models motivated by cortical development such as ocular dominance); implemented in leaky integrate-and-fire and linear Poisson neuron models with N excitatory afferents (examples N=100,1000) and fixed inhibitory inputs.</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>Feedforward afferent pool to single neuron; studied input correlation structures include uncorrelated inputs, uniformly correlated populations, correlated subgroups (M groups with within-group correlation c), and delay-line temporally shifted inputs (relative latencies Δ_i).</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Unsupervised, competitive Hebbian learning (STDP-based); learns temporal correlations and can produce segregation/symmetry breaking (map-like structures) and imprint temporal order into synaptic weights.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Computational/theoretical model: analytical mean-field (Fokker–Planck) treatment for a linear Poisson neuron and numerical simulations of both linear Poisson and leaky integrate-and-fire spiking neuron models.</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>Fast pairwise STDP updates (ms window) determine sign and instantaneous magnitude of Δw; because λ is small, many such millisecond-scale events accumulate slowly to a mean synaptic drift ṡw that evolves over seconds–minutes to a stable distribution. The exponent μ controls a stabilizing drift that acts on slow timescales by reducing potentiation near upper bounds and increasing depression near lower bounds. Thus fast timing → slow accumulation → stable representations; metaplastic adaptation of μ is suggested as a mechanism to match learning rule to slow changes in input statistics.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>NLTAH (0<μ<1) can reconcile stability and sensitivity: intermediate μ yields non-saturated graded synaptic representations that faithfully reflect input correlations; additive limit (μ=0) is unstable and produces binary/clipped weights that may not reflect input structure reliably; multiplicative limit (μ=1) is very stable but insensitive (homogeneous weights) and fails to segregate correlated groups; there exists a stability criterion R = C1 f_+(w*) - g_o (>0 leads to symmetry breaking) that depends on input effective correlations (C1), weight-dependence (through f_+ and g_o), α, and effective population size τ r N; optimal μ (maximizing sensitivity S) depends on input temporal scale σ relative to τ (examples: μ_opt ~ 0.02 in some settings; μ_crit ~0.023 for N=1000, r=10 Hz in reported simulations).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td>Sensitivity S (information-theoretic proxy): S = (1/2) ln |det(χ^T χ)| where χ_ij = ∂w_i/∂Φ_j evaluated at steady-state; numerical examples: τ=20 ms, λ=0.001, μ_opt ≈ 0.02 for certain delay/correlation scenarios; µ_crit reported ≈0.023 in examples (N=1000, r=10 Hz), learning convergence assessed over hundreds of seconds (readouts every 500 s).</td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>No explicit biological consolidation protocol is implemented; the model embodies consolidation implicitly by accumulation of many fast STDP updates (ms-scale) via small λ into long-lived synaptic changes (seconds to many minutes). The paper also suggests metaplastic adaptation of μ on slow timescales but does not provide an explicit consolidation mechanism.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Learning Input Correlations through Nonlinear Temporally Asymmetric Hebbian Plasticity', 'publication_date_yy_mm': '2003-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e112.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e112.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Additive TAH (STDP)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Additive temporally asymmetric Hebbian plasticity (additive STDP)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An STDP rule where potentiation and depression magnitudes are independent of current synaptic weight (f_± constant, μ=0); leads to hard-bound clipping, strong competition, and binary (bimodal) weight distributions in many regimes.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>Additive temporally asymmetric Hebbian plasticity (additive STDP)</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>Δw = ± λ K(Δt) with K(Δt)=exp(-|Δt|/τ); f_+(w)=f_-(w)=1 (μ=0), so per-pair changes do not scale with w; weights must be clipped at [0,1] to prevent runaway. Competition and saturation are strong; analytic mean-field yields no interior steady-state without clipping.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>Per-pair updates sensitive on τ = 20 ms window; accumulation over seconds to reach saturated steady states (simulations used λ up to 0.003 for additive case); output rate normalization emerges as slow-scale effect (independent of input rate in a parameter regime).</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>Used as a comparison in the same cortical-like single-neuron afferent pool models (integrate-and-fire and linear Poisson).</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>Feedforward afferent pool; strong competition across many synapses leads to many synapses saturating at 0 or 1, producing bimodal distributions even when input correlations are homogeneous or weak.</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Unsupervised competitive Hebbian learning; can produce map-like segregation but often in a way that does not faithfully reflect input correlation structure.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Computational/theoretical model (comparison case in simulations and analytic treatment).</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>Fast ms-scale updates drive weights toward boundaries; because Δw independent of w, slow dynamics are dominated by boundary clipping leading to abrupt long-term (slow) binary outcomes rather than graded consolidation.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Additive STDP readily produces bimodal (binary) synaptic distributions and exhibits strong competition that can normalize output rate (r_post ≈ 1/(2 τ N (α-1)) independent of input rate in a regime). However, it requires careful tuning of α and can misrepresent input correlation structure (unfaithful splitting).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td>Analytical expressions: fraction of synapses at upper bound n_up = 1/(2 τ r N (α - 1)) (if ≤1); output rate r_post = n_up r. Example parameter: λ=0.003 used in additive simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>No explicit consolidation; long-term saturated states result from many fast pairwise updates plus clipping.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Learning Input Correlations through Nonlinear Temporally Asymmetric Hebbian Plasticity', 'publication_date_yy_mm': '2003-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e112.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e112.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Multiplicative TAH (STDP)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Multiplicative temporally asymmetric Hebbian plasticity (multiplicative STDP)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An STDP rule in which potentiation and depression scale linearly with distance to the upper and lower bounds (f_+=(1-w), f_-=α w), producing intrinsically stable equilibria but reduced competitive segregation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>Multiplicative temporally asymmetric Hebbian plasticity (multiplicative STDP)</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>Δw = λ (1-w) K(Δt) for potentiation and Δw = -λ α w K(Δt) for depression (μ=1 case of the family). Weight-dependent linear attenuation prevents runaway, producing a unique interior homogeneous steady-state w* for positive input correlations.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>STDP time window τ = 20 ms for per-pair updates; slow approach to homogeneous equilibrium over seconds-minutes due to small λ.</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>Same model framework (afferent pool to single neuron).</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>Feedforward afferent pool; multiplicative scaling strongly stabilizes homogeneous synaptic distributions across the population regardless of positive homogeneous correlation structure.</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Unsupervised learning with low representational competition; tends not to produce segregated maps even when inputs contain subgroup correlations.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Computational/theoretical model (considered as μ=1 limit in analysis and simulations).</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>Fast ms-scale STDP updates are attenuated near bounds, so slow accumulation leads to a confined central steady state and little slow timescale divergence between synapses.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Multiplicative rule yields robust stability: homogeneous steady-state is always stable for μ=1 given no negative input correlations; as a result, the rule has low sensitivity to input correlation structure and cannot produce symmetry breaking between correlated groups.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td>Stability analysis shows ℛ<0 for μ=1 in examined cases; sensitivity S is low compared to intermediate μ values (plots in paper demonstrate reduced S).</td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>No explicit consolidation described; steady-state arises through gradual accumulation of many ms-scale updates.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Learning Input Correlations through Nonlinear Temporally Asymmetric Hebbian Plasticity', 'publication_date_yy_mm': '2003-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e112.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e112.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Correlated subgroups & delay-line</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Presynaptic correlation structures: correlated subgroups and delay-line (temporal latency) inputs</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Connectivity/correlation patterns used as structured inputs: (1) M equally sized correlated subgroups with within-group instantaneous correlation c and zero between-group correlation; (2) delay-line inputs formed by time-shifted copies of a common Poisson train with relative latencies Δ_i (spanning σ). These patterns determine cooperative/competitive interactions driving segregation or graded mapping.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>Connectivity/correlation patterns: within-group instantaneous correlations (c) and delay-line temporal offsets (Δ)</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>Instantaneous correlations: Γ_ij^α(Δt) = (1/r) c_{ij} δ(Δt) with c_{ij}=c within group, 0 between groups, giving C_0 = C_1 = c/(τ r M) in large-N limit. Delay-line correlations: inputs are ρ_pre_i(t)=ρ_0(t-Δ_i) giving effective correlation matrices C_ij^± = Θ(∓(Δ_i-Δ_j-ε)) (τ r)^(-1) exp(±(Δ_i-Δ_j-ε)/τ). Parameters: c, Δ spacing σ, postsynaptic delay ε.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>Relative latencies and correlations are compared to τ (20 ms); when σ ≲ few × τ correlations are strong (cooperation strong), when σ ≫ τ correlations are weak; resulting learning effects (segregation, mapping) emerge over slow accumulation times (seconds→minutes) as weights converge.</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>Model of a neuron receiving many afferents; patterns motivated by cortical maps (e.g., ocular dominance) and auditory delay-line models (Jeffress-type).</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>Feedforward groups (M groups) or ordered delay-line across N afferents; effective connectivity pattern determined by temporal correlations rather than anatomical rewiring in the model.</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Unsupervised segregation and imprinting of temporal order into synaptic weights (map formation); leading synapses (earlier delays) tend to strengthen under causal STDP.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Analyzed analytically (linear Poisson) and simulated (integrate-and-fire) to study stability, symmetry breaking, and mapping between delays and equilibrium weights.</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>Ms-scale relative delays produce positive/negative effective causal/backward correlations (C^+, C^-) via exponential STDP kernel; these rapidly determine per-pair Δw signs but their accumulated effect over many events drives slow drift and eventual segregation or graded weight maps depending on μ, c, N, τ r N.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Two-group correlated subpopulations can cause symmetry breaking and group segregation in NLTAH for intermediate μ even for large N if within-group c is sufficiently large; delay-line inputs produce a monotonic mapping from relative latency to steady-state weight (leading inputs strongest); sensitivity S to small changes in delays shows a peak at intermediate μ and at an optimal σ/τ, indicating that the temporal scale of the input correlations determines the optimal weight-dependence.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td>Analytical forms: C_0 = C_1 = c/(τ r M) (large-N), and C_0,C_1 formulae used in stability criterion; sensitivity per feature S/R was plotted for N=101, r=10 Hz, α=1.5 showing nonmonotonic dependence on μ and σ (see Fig.10). Numerical examples: segregation thresholds μ_crit and c_crit reported in figures (e.g., μ≈0.15 border in some linear neuron plots).</td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>No explicit multi-stage consolidation; long-term imprinting of the temporal structure occurs via slow accumulation of fast STDP events; authors suggest metaplastic adaptation (e.g., of μ) as a possible slow mechanism to optimize sensitivity but do not implement it.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Learning Input Correlations through Nonlinear Temporally Asymmetric Hebbian Plasticity', 'publication_date_yy_mm': '2003-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e112.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e112.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Sensitivity S (susceptibility)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Sensitivity measure S based on susceptibility matrix χ (proxy for mutual information)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A quantitative measure of how much small changes in input features Φ (e.g., correlation strength, relative delays) change the learned synaptic weights w*; constructed as S = (1/2) ln |det(χ^T χ)| where χ_ij = ∂w_i/∂Φ_j evaluated at steady state.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>Performance metric: sensitivity S (susceptibility-based, infomax proxy)</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>Compute steady-state w* from mean-field drift equations; form susceptibility χ_{ij} = ∂w_i/∂Φ_j via implicit differentiation (χ = -M^{-1} M^o where M is Jacobian ∂ṡw/∂w and M^o = ∂ṡw/∂Φ). Then S = 0.5 ln |det(χ^T χ)|. S_avg is average over feature distributions and relates to mutual information in small-λ limit.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>Used to quantify mapping from fast ms-scale temporal features (delays Δ in units of τ=20 ms or instantaneous correlations) to slow steady-state synaptic changes; χ is evaluated at steady-state after long-time convergence (simulations used readouts over hundreds of seconds).</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>Applied to model neuron with afferent pools (linear Poisson analytical case and numerical simulations).</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>Applied to structured inputs: two correlated subgroups and delay-line ensembles; quantifies sensitivity of learned weights to small changes in within-group correlation c or to small independent changes in individual delays Δ_i.</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Metric for unsupervised learning performance (how well TAH rules store temporal correlation structure into synaptic weights).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Analytical computation (linear Poisson) and numerical evaluation (simulations), used to compare NLTAH variants and parameter choices.</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>S captures how ms-scale temporal structure (via STDP kernel and effective correlations C^{±}) translates into slow steady-state weight changes; shows optimal μ that maximizes S for given input temporal scale σ/τ.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>S is nonmonotonic with μ: low μ leads to saturation and loss of sensitivity, high μ strongly confines weights and reduces sensitivity; intermediate μ maximizes S. S also depends nonmonotonically on temporal dispersion σ, showing an optimal σ/τ for which sensitivity per feature is maximal (plots shown in Fig.10).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td>Equation: S = (1/2) ln |det(χ^T χ)| with χ = -M^{-1} M^o. Numerical settings: N=101, r=10 Hz, α=1.5 used in examples; curves show S/R vs μ and vs σ/τ.</td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>S does not model consolidation but measures how much information about fast temporal features is stored in slow steady-state synaptic weights; authors note S yields an upper bound on learnable information available for later readout.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Learning Input Correlations through Nonlinear Temporally Asymmetric Hebbian Plasticity', 'publication_date_yy_mm': '2003-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Activity-induced synaptic modifications in hippocampal culture: dependence on spike timing, synaptic strength, and cell type <em>(Rating: 2)</em></li>
                <li>Competitive Hebbian learning through spike-timing-dependent synaptic plasticity <em>(Rating: 2)</em></li>
                <li>Stable Hebbian learning from spike timing-dependent plasticity <em>(Rating: 2)</em></li>
                <li>Equilibrium properties of temporally asymmetric Hebbian plasticity <em>(Rating: 2)</em></li>
                <li>Hebbian learning and spiking neurons <em>(Rating: 1)</em></li>
                <li>Intrinsic stabilization of output rates by spike-based Hebbian learning <em>(Rating: 1)</em></li>
                <li>A neuronal learning rule for sub-millisecond temporal coding <em>(Rating: 1)</em></li>
            </ol>
        </div>

        </div>

    </div>
</body>
</html>