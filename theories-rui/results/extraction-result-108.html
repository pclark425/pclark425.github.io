<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-108 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-108</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-108</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-5.html">extraction-schema-5</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <p><strong>Paper ID:</strong> paper-2d4f073144d46f59f4485bc116451e4a59460581</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/2d4f073144d46f59f4485bc116451e4a59460581" target="_blank">Structural Synaptic Plasticity Has High Memory Capacity and Can Explain Graded Amnesia, Catastrophic Forgetting, and the Spacing Effect</a></p>
                <p><strong>Paper Venue:</strong> PLoS ONE</p>
                <p><strong>Paper TL;DR:</strong> This model of structural plasticity produces gradients of effectual connectivity in the course of learning, thereby explaining various cognitive phenomena including graded amnesia, catastrophic forgetting, and the spacing effect.</p>
                <p><strong>Paper Abstract:</strong> Although already William James and, more explicitly, Donald Hebb's theory of cell assemblies have suggested that activity-dependent rewiring of neuronal networks is the substrate of learning and memory, over the last six decades most theoretical work on memory has focused on plasticity of existing synapses in prewired networks. Research in the last decade has emphasized that structural modification of synaptic connectivity is common in the adult brain and tightly correlated with learning and memory. Here we present a parsimonious computational model for learning by structural plasticity. The basic modeling units are “potential synapses” defined as locations in the network where synapses can potentially grow to connect two neurons. This model generalizes well-known previous models for associative learning based on weight plasticity. Therefore, existing theory can be applied to analyze how many memories and how much information structural plasticity can store in a synapse. Surprisingly, we find that structural plasticity largely outperforms weight plasticity and can achieve a much higher storage capacity per synapse. The effect of structural plasticity on the structure of sparsely connected networks is quite intuitive: Structural plasticity increases the “effectual network connectivity”, that is, the network wiring that specifically supports storage and recall of the memories. Further, this model of structural plasticity produces gradients of effectual connectivity in the course of learning, thereby explaining various cognitive phenomena including graded amnesia, catastrophic forgetting, and the spacing effect.</p>
                <p><strong>Cost:</strong> 0.025</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e108.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e108.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hebbian weight plasticity (Willshaw)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hebbian-type weight plasticity (Willshaw/Willshaw-type binary Hebbian rule)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Local synaptic potentiation rule that strengthens existing synapses when pre- and postsynaptic units are co-active; instantiated in the paper by the binary Willshaw learning rule (W_{ij} = min(1, sum_mu u_i^mu v_j^mu)). Used as the fast learning component in the simulations and analytic results.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>Hebbian weight plasticity (Willshaw binary Hebbian rule)</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>Binary Hebbian consolidation: when pre- and postsynaptic neurons fire together during a memory presentation, the synapse is potentiated (weight set to 1); no depression in the classical Willshaw instantiation (p_{d|s}=0). In the paper this is represented by Eq.5 and by state transitions 0->1 driven by a consolidation signal S_{ij}. Key parameters: p_{e|s} (probability of potentiation given S), p_{d|s} (probability of deconsolidation), and the binary weight space {0,1}.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>Relatively fast compared to structural plasticity — spans from sub-millisecond/sub-second spike-timing sensitivity (STDP mechanisms discussed) up to rapid consolidation on the order of simulation 'time steps' (interpreted in the paper as seconds–minutes to hours depending on mapping), but explicitly treated as faster than structural spine growth/elimination which occurs over days.</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>Applied in cortical networks and auto-/hetero-associative connections (u↔v, cortical macrocolumns); used within the Willshaw/Hopfield-type models in cortex; relevant to cortico-hippocampal interactions when driven by replay.</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>Assumed on top of an (possibly sparse) anatomical connectivity P; operates on existing realized synapses (does not change wiring). Simulations use recurrent auto-associative and hetero-associative projections with sparse assemblies (k active units).</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Associative memory storage and recall (hetero- and auto-associative), rapid consolidation of rehearsed patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Computational/theoretical model (Willshaw-type associative network; analytical approximations and microscopic simulations).</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>Acts as the fast consolidation stage that can rapidly potentiate synapses (0→1) when S_{ij} indicates co-activation; operates faster than structural processes so that repeated fast consolidations can stabilize synapses before structural changes relocate/grow new synapses.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Hebbian (Willshaw) weight plasticity alone yields limited capacity (weight capacity C^{wp} ≤ 0.69 bits/synapse); it is the fast mechanism that, when combined with slower structural plasticity, enables consolidation of newly formed or migrated synapses and thus improved long-term storage.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td>Weight capacity C^{wp} computed (Eq.14) with an upper bound ~0.69 bits per synapse; used in pattern capacity M_ε expressions (Eq.13). Simulated network sizes include n up to 100,000; example parameters: P=0.1, k variable.</td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>Fast potentiation under repeated activation (S_{ij} > 0) which consolidates synapses into long-lived state (1); this fast consolidation permits structural plasticity to later 'migrate' synapses to the locations needed for stored memories.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Structural Synaptic Plasticity Has High Memory Capacity and Can Explain Graded Amnesia, Catastrophic Forgetting, and the Spacing Effect', 'publication_date_yy_mm': '2014-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e108.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e108.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Structural plasticity</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Structural synaptic plasticity (synaptogenesis, pruning, synapse migration)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Creation and elimination (and redistribution) of synaptic contacts (spine growth, synaptogenesis, pruning) that changes the wiring pattern; modeled as stochastic state transitions of potential synapses (π ↔ 0 ↔ 1) under consolidation signals and homeostatic constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>Structural plasticity (synapse generation/elimination and consolidation)</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>A three-state potential-synapse model: π = potential (no real synapse yet), 0 = realized but silent/unconsolidated synapse, 1 = realized and consolidated/stable synapse. Transitions: blind generation p_g: π→0; potentiation/consolidation p_{e|s}: 0→1 driven by consolidation signal S_{ij}; elimination/deconsolidation p_{d|s}: 1→0 (or 0→π for pruning). Homeostatic adjustment of p_g keeps anatomical connectivity P roughly constant in adulthood. Parameters such as p_{e0}, p_{e|1}, p_g, p_{d0} govern time scales and equilibrium.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>Slower than weight plasticity: operates over hours–days for spine turnover (paper maps mean lifetime of unconsolidated/unrequested synapses ≈ 1/p_{e0} to 'a few days' per cited experimental data [10]); developmental structural changes occur over months–years (years-scale pruning and overgrowth), while homeostatic balance is maintained across lifespan (years–decades).</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>Neocortex (local cortical circuits, cortical macrocolumns), modeled projections between cortical populations u and v; also implicated in cortico-hippocampal consolidation interactions (hippocampal replay driving cortical consolidation).</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>Changes anatomical connectivity P and redistributes the pool of P n^2 actual synapses across P_{pot} n^2 potential locations; key connectivity measures defined are anatomical connectivity P, potential connectivity P_{pot}, effectual connectivity P_{eff}, and filling fraction P/P_{pot}. May allow multiple synapses per neuron pair (multi-synapse variant) or a single synapse per pair.</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Long-term memory formation and consolidation, prevention of catastrophic forgetting, support of spacing effect, and enabling sparse coding by increasing effectual connectivity for stored memories.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Computational/theoretical model (stochastic state model of potential synapses; microscopic simulations and macroscopic analysis) grounded in and compared to experimental findings on spine turnover and developmental pruning.</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>Structural changes are slow: synaptogenesis (π→0) and pruning (0→π) occur over days whereas weight consolidation (0→1) happens faster; repeated fast consolidations across sessions allow structural processes to 'migrate' and stabilize synapses; homeostatic control of p_g interacts over longer times (days→years) to set P.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Ongoing structural plasticity increases effectual connectivity P_{eff} from P toward P_{pot}, strongly boosting storage capacity per synapse (total capacity C^{tot} can approach ≈ log2(n) bits/synapse), prevents catastrophic forgetting by keeping the number of consolidated synapses below capacity, explains graded (Ribot) retrograde amnesia via gradients in P_{eff}, and naturally produces the spacing effect because structural growth is slower than weight consolidation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td>Effectual connectivity P_{eff}(t) dynamics (Fig.4); capacity measures: C^{tot} (total capacity), examples: anatomical P=0.1, potential P_{pot}≈0.5, macrocolumn n=1e5 → structural plasticity yields large C^{tot} (Fig.5); mean lifetime of unconsolidated synapses ≈ 1/p_{e0} mapped to 'a few days'.</td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>Repeated activations (rehearsal or hippocampal replay) supply the consolidation signal S which selects synapse locations to be consolidated; structural plasticity creates candidate synapses during intervals between rehearsals which can be consolidated in subsequent sessions — the asymmetry of slow structural growth vs. faster weight consolidation underlies the spacing effect.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Structural Synaptic Plasticity Has High Memory Capacity and Can Explain Graded Amnesia, Catastrophic Forgetting, and the Spacing Effect', 'publication_date_yy_mm': '2014-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e108.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e108.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Effectual connectivity (P_eff)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Effectual connectivity (overlap of actual and requested synapses, P_eff)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A macroscopic measure introduced in the paper: the fraction of requested/consolidation-signaled synapses that are actually realized and potentiated; formalized as P_eff = (sum_{ij} W_{ij} S_{ij}) / (sum_{ij} S_{ij}) for binary weights.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>Effectual connectivity (measure of functional wiring match)</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>Not a plasticity rule but a network-level metric: S_{ij} defines the synapse ensemble required by the memory set (consolidation signal); W_{ij} are actual synaptic weights (1 if potentiated). P_eff quantifies how well the anatomical wiring supports the current memory set (0 ≤ P_eff ≤ 1). Key derived quantities: consolidation load P_{1S} = fraction of S non-zero entries; filling fraction P/P_{pot}.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>Dynamics studied across simulation steps mapped to days for structural turnover (P_eff increases quickly initially — one-step consolidation — and then more slowly toward P_{pot}; changes accumulate over days to many days depending on parameters).</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>Used to quantify functional wiring in cortical projections (u→v), macrocolumn-scale networks, and during cortico-hippocampal replay-driven consolidation.</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>Relates requested synapse ensemble S to actual anatomical connectivity P and potential connectivity P_{pot}; explains how sparse anatomical networks can emulate higher effective connectivity by migrating synapses to requested locations.</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Metric for associative long-term memory consolidation and retrieval performance; used to study aging of memories, catastrophic forgetting, Ribot gradients, and spacing effect.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Computational/theoretical construct introduced and used in simulations and analytical results in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>P_eff is the state variable that increases as fast (weight consolidation) and slow (structural migration) processes act: immediate increase to P after an initial consolidation step, then slow approach to P_{pot} driven by structural turnover across sessions.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>P_eff captures the functional improvement provided by structural plasticity; increases in P_eff significantly raise pattern capacity M_c and information per synapse C^{tot}; gradients in P_eff (older memories having higher P_eff) explain graded retrograde amnesia and absence of catastrophic forgetting; P_eff dynamics explain the spacing effect.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td>P_eff(t) curves (Fig.4) under different P, P_{pot}, P_{1S}, P_1(0); numerical examples: P rising from 0.1 toward P_{pot}=1 in simulations; capacity plots (Fig.5) show M_c and C^{tot} as functions of P_eff and k for n=100,000.</td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>P_eff is increased by repeated replay/rehearsal (S applied each time step) which consolidates selected synapses quickly (weight plasticity) and, over longer times, structural plasticity grows/eliminates synapses so that more requested locations have realized synapses.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Structural Synaptic Plasticity Has High Memory Capacity and Can Explain Graded Amnesia, Catastrophic Forgetting, and the Spacing Effect', 'publication_date_yy_mm': '2014-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e108.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e108.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Consolidation signal S (synaptic tagging)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Consolidation signal S_{ij} (learning/consolidation tag matrix)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Matrix S that 'tags' potential synapses for consolidation (S_{ij}=1 when synapse ij is requested to be consolidated for the memory set); provides the decisive local signal for transitioning synapses from unconsolidated to consolidated states in the model.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>Hebbian consolidation signal / synaptic tagging (S_{ij})</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>S_{ij} is derived from Hebbian correlations (co-activation) between presynaptic u_i and postsynaptic v_j across presentations/replay; S_{ij} drives potentiation probability p_{e|s} (0→1) and thereby stabilizes synapses at locations required by the memory set. The consolidation load P_{1S} is the fraction of potential synapse locations requested by S.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>Provided whenever memory patterns are reactivated; acts on the fast consolidation timescale (weight plasticity) during each rehearsal/replay event (per-step in simulations). Aggregate effects over repeated events occur over hours→days depending on rehearsal schedule.</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>Represents local Hebbian tags in cortical u→v projections; in episodic memory scenarios, S is supplied by hippocampal replay to neocortex during consolidation.</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>S defines the subset (ensemble) of potential synapse locations that should become realized/potentiated for a particular memory set; interacts with anatomical and potential connectivity to determine P_eff.</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Memory consolidation (drives synapse stabilization), episodic-to-cortical consolidation when provided by hippocampal replay, enables selective structural migration of synapses.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Model construct implemented in simulations (S used to decide consolidation events); conceptually related to synaptic tagging and capture hypotheses in experimental literature.</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>S is the fast-timescale signal (per rehearsal) that triggers rapid weight consolidation; structural plasticity acts between spaced S events to create new candidate synapses that can be consolidated in subsequent S episodes — key to spacing effect.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Explicitly modeling S as the consolidation signal explains how targeted consolidation + blind synaptogenesis + pruning can migrate synapses to requested locations, increasing P_eff and memory capacity; S-driven consolidation combined with structural turnover explains how rehearsal scheduling (spacing) changes P_eff and retention.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td>Consolidation load P_{1S} (fraction of requested synapse locations) used as parameter in simulations; P_{1S} strongly affects speed of P_eff increase and hence capacity and retention (Fig.4A shows slower consolidation for larger P_{1S}).</td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>S is provided via repeated bottom-up stimulation or hippocampal replay; each occurrence increases p_{e|s} at those locations, leading to potentiation; across episodes, structural plasticity supplies new synapses that S can consolidate, enabling long-term storage.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Structural Synaptic Plasticity Has High Memory Capacity and Can Explain Graded Amnesia, Catastrophic Forgetting, and the Spacing Effect', 'publication_date_yy_mm': '2014-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e108.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e108.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Homeostatic structural plasticity</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Homeostatic control of synaptogenesis/elimination (homeostatic structural plasticity)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Regulatory mechanism that adjusts generation/elimination rates (notably p_g) to keep anatomical connectivity P (or average firing rates) near a target level; implemented in the model to maintain constant P in adulthood.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>Homeostatic structural plasticity (activity/firing-rate dependent p_g control)</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>Blind synaptogenesis rate p_g is adjusted (in simulations explicitly set) so that synapse generation balances elimination, keeping anatomical connectivity P steady. Conceptually p_g could be controlled by neurons' mean firing rates (low firing → increased p_g), implementing a negative-feedback homeostatic loop.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>Operates over slow timescales relative to rapid weight plasticity — days to weeks or longer for maintaining stable synapse numbers; during development it shapes connectivity over months–years.</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>Global regulation across cortical projections (u→v) and within cortical areas; applied to macrocolumn-scale networks in simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>Maintains anatomical connectivity P constant even while individual synapses turn over; interacts with consolidation-driven structural migration to regulate filling fraction P/P_{pot}.</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Supports long-term learning capacity by balancing metabolic/space constraints with learning speed; enables sampling bias that equalizes neuron usage across memories.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Model mechanism implemented in simulations; tied to experimental literature on homeostatic spine turnover and firing-rate homeostasis.</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>Homeostatic control runs on the slowest scale, setting the available substrate (number of migratable synapses) for structural plasticity and thereby constraining how quickly P_eff can increase; interacts with faster weight consolidation and intermediate structural turnover.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Homeostatic structural plasticity is necessary to trade off learning speed (higher P gives faster consolidation) vs. metabolic/space efficiency (low P), and to enable uniform usage of neurons across memories which optimizes capacity; novelty-driven transient increases of P (via p_g) can speed learning.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td>Homeostatic balance condition used in simulations: eliminated synapses per time step equal generated synapses so P is constant; examples in Table 1 use this setting (p_{z0} set equal to s etc.).</td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>By keeping P constant, homeostasis constrains how many new synapses can be generated between rehearsals, indirectly shaping consolidation dynamics (P_eff growth) over long times.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Structural Synaptic Plasticity Has High Memory Capacity and Can Explain Graded Amnesia, Catastrophic Forgetting, and the Spacing Effect', 'publication_date_yy_mm': '2014-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e108.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e108.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>STDP / spike-timing rules</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Spike-timing-dependent plasticity (STDP) and temporal Hebbian rules</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Temporal synaptic plasticity rules where the precise millisecond-scale timing of pre- and postsynaptic spikes determines potentiation vs depression; discussed in the paper as more realistic weight plasticity mechanisms that are broadly consistent with Hebbian consolidation in the model.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>Spike-timing-dependent plasticity (STDP)</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>Potentiation or depression is induced depending on the relative timing of pre- and postsynaptic spikes (pre-before-post → LTP; post-before-pre → LTD in classic STDP), with characteristic temporal windows on the order of tens of milliseconds or less; more biophysically detailed variants include voltage-dependence and dendritic propagation delays.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>Operates on very fast timescales: sub-millisecond to tens of milliseconds (spike-time windows), giving rise to fast weight changes during activity; interacts with slower consolidation processes.</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>Mentioned generically for cortical synapses and as plausible underlying mechanisms for the Hebbian consolidation signal; also referenced in discussion of realistic synaptic dynamics (e.g., hippocampus/cortex literature).</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>Acts on existing synapses (weights) rather than creating/eliminating wiring; timing-dependent cooperation may support formation of cooperative synapses/multi-synapse motifs.</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Fast synaptic learning tied to precise temporal patterns of spiking; contributes to initial tagging/potentiation that can be consolidated into longer-lasting changes.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Mentioned and cited (references to experimental and modeling work); not implemented as the primary plasticity rule in the paper's core simulations (the paper uses simplified Hebbian binary plasticity and structural state transitions).</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>STDP provides the millisecond-scale potentiation/depression events that, when repeated, produce the consolidation signal S and weight changes that are then stabilized by slower structural plasticity; STDP can therefore feed the fast branch of a multi-timescale consolidation process.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Paper argues that biologically realistic STDP models can be consistent with Hebbian-like consolidation and cell-assembly formation; STDP is compatible with the model's assumptions about fast weight consolidation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>STDP-driven potentiation could serve as the fast 'tagging' or potentiation that S abstracts; repeated STDP events across sessions allow consolidation into long-term synaptic state which structural plasticity can then exploit.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Structural Synaptic Plasticity Has High Memory Capacity and Can Explain Graded Amnesia, Catastrophic Forgetting, and the Spacing Effect', 'publication_date_yy_mm': '2014-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e108.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e108.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Cortico-hippocampal replay</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hippocampus-driven replay to neocortex (cortico-hippocampal memory replay)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Mechanism by which hippocampal short-term episodic memory replays are assumed to reactivate cortical patterns, providing consolidation signal S to cortical synapses across multiple replay episodes; modeled as the source of repeated activations needed for long-term cortical consolidation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>Replay-driven consolidation (hippocampal replay supplying S)</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>Hippocampal replay reactivates stored episodic patterns (u^mu, v^mu) and thereby causes correlated pre- and postsynaptic activity in cortex; this repeated activation populates the S_{ij} consolidation matrix for the cortical projection, driving p_{e|s} transitions and enabling cortical stabilization and structural migration.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>Replay events occur over short episodes (seconds–minutes per replay episode in models) but repeated replay across hours→days provides the cumulative consolidation time shaping long-term cortical P_eff; hippocampal replay has a limited role (time-limited window) in consolidation per experimental literature noted in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>Hippocampus (HC) as a short-term buffer replaying to cortical populations (u and v); the model specifically examines neocortical projections receiving hippocampal replay.</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>Replay drives which cortical synapse locations are requested (S), interacting with anatomical P and potential P_{pot} to determine where synapses should be consolidated; repeated replay over time increases P_eff for early memories more than recent ones, producing Ribot gradients.</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Episodic memory consolidation into long-term cortical representations; supports multi-session rehearsal and spacing effects when replay is intermittent.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Modeling assumption for simulations (episodic memories in hippocampus are replayed to cortex for fixed numbers of simulation steps); grounded in experimental hippocampal replay literature cited in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>Replay supplies the per-episode fast consolidation signal S (weight-level events); structural plasticity acts between replay episodes (growth/pruning over days) so replay scheduling (distributed vs. massed) crucially affects long-term P_eff and retention (spacing effect).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Modeling hippocampal replay driving cortical S explains graded retrograde amnesia (Ribot gradients) without requiring unlimited replay: older memories have accumulated higher P_eff and are more resilient; spacing of replay/rehearsal benefits consolidation because structural growth between episodes supplies new synapses that can be consolidated.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td>Simulations illustrating catastrophic forgetting and Ribot gradients (Fig.6) use n=1000, k=50, 25 memory blocks, replay durations per block varied; spacing simulations show greater P_eff and lower retrieval noise ε for spaced schedules.</td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>Hippocampal replay repeatedly activates cortical patterns (S) enabling fast potentiation events; over multiple replay sessions structural plasticity grows candidate synapses that are then consolidated, yielding long-term storage.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Structural Synaptic Plasticity Has High Memory Capacity and Can Explain Graded Amnesia, Catastrophic Forgetting, and the Spacing Effect', 'publication_date_yy_mm': '2014-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Geometry and structural plasticity of synaptic connectivity <em>(Rating: 2)</em></li>
                <li>Synaptic tagging and long-term potentiation <em>(Rating: 2)</em></li>
                <li>Cascade models of synaptically stored memories <em>(Rating: 2)</em></li>
                <li>Activity-dependent structural plasticity <em>(Rating: 2)</em></li>
                <li>Experience-dependent structural synaptic plasticity in the mammalian brain <em>(Rating: 2)</em></li>
                <li>The hippocampo-neocortical dialogue <em>(Rating: 1)</em></li>
            </ol>
        </div>

        </div>

    </div>
</body>
</html>