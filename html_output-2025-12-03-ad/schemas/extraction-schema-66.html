<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction Schema extraction-schema-66 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extraction Schema Details for extraction-schema-66</h1>

        <div class="section">
            <h2>Extraction Schema (General Information)</h2>
            <div class="info-section">
                <p><strong>Schema ID:</strong> extraction-schema-66</p>
                <p><strong>Extraction Query:</strong> Extract any mentions of automated research systems, AI scientists, or automated idea generation/implementation systems, including details about what types of research problems they were applied to, the characteristics of those problems, and the success or failure rates of the automated system.</p>
            </div>
        </div>

        <div class="section">
            <h2>Extraction Schema (Details)</h2>
            <table>
                <thead>
                    <tr>
                        <th style="width: 20%;">Field Name</th>
                        <th style="width: 15%;">Type</th>
                        <th style="width: 65%;">Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>system_name</strong></td>
                        <td>str</td>
                        <td>The name of the automated research/discovery system, AI scientist, AutoML system, or automated idea generation system being evaluated.</td>
                    </tr>
                    <tr>
                        <td><strong>system_description</strong></td>
                        <td>str</td>
                        <td>A detailed description of how the automated system works, including its key capabilities (e.g., generates hypotheses, designs experiments, implements code, analyzes results, etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>system_type</strong></td>
                        <td>str</td>
                        <td>The category/type of automated system (e.g., 'AutoML', 'AI Scientist', 'Automated Discovery System', 'Hypothesis Generation System', 'Automated Experimentation Platform', etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>problem_domain</strong></td>
                        <td>str</td>
                        <td>The research domain(s) or field(s) where the automated system was applied (e.g., 'machine learning', 'biology', 'chemistry', 'physics', 'materials science', 'drug discovery', 'computer vision', etc.). Be specific.</td>
                    </tr>
                    <tr>
                        <td><strong>problem_description</strong></td>
                        <td>str</td>
                        <td>A detailed description of the specific research problem(s) or task(s) that the automated system attempted to solve or investigate.</td>
                    </tr>
                    <tr>
                        <td><strong>problem_complexity</strong></td>
                        <td>str</td>
                        <td>Description of the complexity of the research problem, including factors like: problem dimensionality, number of variables, search space size, non-linearity, multi-objective nature, etc. Include any quantitative measures if available.</td>
                    </tr>
                    <tr>
                        <td><strong>data_availability</strong></td>
                        <td>str</td>
                        <td>Description of data availability for the problem: amount of data available, data quality, whether data needed to be generated vs. pre-existing, cost/difficulty of obtaining data, etc.</td>
                    </tr>
                    <tr>
                        <td><strong>computational_requirements</strong></td>
                        <td>str</td>
                        <td>Description of computational requirements: compute time, memory requirements, number of experiments/evaluations needed, cost in compute hours or dollars, etc. Include quantitative measures if available.</td>
                    </tr>
                    <tr>
                        <td><strong>problem_structure</strong></td>
                        <td>str</td>
                        <td>Description of the problem structure: is it well-defined vs. open-ended, discrete vs. continuous, deterministic vs. stochastic, presence of clear evaluation metrics, degree of domain knowledge required, etc.</td>
                    </tr>
                    <tr>
                        <td><strong>success_metric</strong></td>
                        <td>str</td>
                        <td>What metric(s) were used to evaluate the success of the automated system? (e.g., 'accuracy', 'novel discoveries made', 'papers published', 'performance vs. human baseline', 'solution quality', etc.)</td>
                    </tr>
                    <tr>
                        <td><strong>success_rate</strong></td>
                        <td>str</td>
                        <td>What was the success rate or performance of the automated system on this problem? Include quantitative results with units. If comparing to baselines (human researchers, other methods), include those comparisons.</td>
                    </tr>
                    <tr>
                        <td><strong>failure_modes</strong></td>
                        <td>str</td>
                        <td>If the system failed or had limitations, what were the failure modes? What types of problems did it struggle with? What were the bottlenecks or challenges?</td>
                    </tr>
                    <tr>
                        <td><strong>success_factors</strong></td>
                        <td>str</td>
                        <td>What factors contributed to success? What problem characteristics made the automated system work well?</td>
                    </tr>
                    <tr>
                        <td><strong>comparative_results</strong></td>
                        <td>str</td>
                        <td>If the paper compares performance across multiple problem types or domains, summarize those comparative results in a concise, information-dense way that highlights how problem characteristics affected success.</td>
                    </tr>
                    <tr>
                        <td><strong>human_baseline</strong></td>
                        <td>str</td>
                        <td>If available, what was the human researcher performance or baseline on the same problem? Include quantitative comparisons.</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <div class="section">
            <h2>Extraction Schema (Debug)</h2>
            <pre><code>{
    "id": "extraction-schema-66",
    "schema": [
        {
            "name": "system_name",
            "type": "str",
            "description": "The name of the automated research/discovery system, AI scientist, AutoML system, or automated idea generation system being evaluated."
        },
        {
            "name": "system_description",
            "type": "str",
            "description": "A detailed description of how the automated system works, including its key capabilities (e.g., generates hypotheses, designs experiments, implements code, analyzes results, etc.)."
        },
        {
            "name": "system_type",
            "type": "str",
            "description": "The category/type of automated system (e.g., 'AutoML', 'AI Scientist', 'Automated Discovery System', 'Hypothesis Generation System', 'Automated Experimentation Platform', etc.)."
        },
        {
            "name": "problem_domain",
            "type": "str",
            "description": "The research domain(s) or field(s) where the automated system was applied (e.g., 'machine learning', 'biology', 'chemistry', 'physics', 'materials science', 'drug discovery', 'computer vision', etc.). Be specific."
        },
        {
            "name": "problem_description",
            "type": "str",
            "description": "A detailed description of the specific research problem(s) or task(s) that the automated system attempted to solve or investigate."
        },
        {
            "name": "problem_complexity",
            "type": "str",
            "description": "Description of the complexity of the research problem, including factors like: problem dimensionality, number of variables, search space size, non-linearity, multi-objective nature, etc. Include any quantitative measures if available."
        },
        {
            "name": "data_availability",
            "type": "str",
            "description": "Description of data availability for the problem: amount of data available, data quality, whether data needed to be generated vs. pre-existing, cost/difficulty of obtaining data, etc."
        },
        {
            "name": "computational_requirements",
            "type": "str",
            "description": "Description of computational requirements: compute time, memory requirements, number of experiments/evaluations needed, cost in compute hours or dollars, etc. Include quantitative measures if available."
        },
        {
            "name": "problem_structure",
            "type": "str",
            "description": "Description of the problem structure: is it well-defined vs. open-ended, discrete vs. continuous, deterministic vs. stochastic, presence of clear evaluation metrics, degree of domain knowledge required, etc."
        },
        {
            "name": "success_metric",
            "type": "str",
            "description": "What metric(s) were used to evaluate the success of the automated system? (e.g., 'accuracy', 'novel discoveries made', 'papers published', 'performance vs. human baseline', 'solution quality', etc.)"
        },
        {
            "name": "success_rate",
            "type": "str",
            "description": "What was the success rate or performance of the automated system on this problem? Include quantitative results with units. If comparing to baselines (human researchers, other methods), include those comparisons."
        },
        {
            "name": "failure_modes",
            "type": "str",
            "description": "If the system failed or had limitations, what were the failure modes? What types of problems did it struggle with? What were the bottlenecks or challenges?"
        },
        {
            "name": "success_factors",
            "type": "str",
            "description": "What factors contributed to success? What problem characteristics made the automated system work well?"
        },
        {
            "name": "comparative_results",
            "type": "str",
            "description": "If the paper compares performance across multiple problem types or domains, summarize those comparative results in a concise, information-dense way that highlights how problem characteristics affected success."
        },
        {
            "name": "human_baseline",
            "type": "str",
            "description": "If available, what was the human researcher performance or baseline on the same problem? Include quantitative comparisons."
        }
    ],
    "extraction_query": "Extract any mentions of automated research systems, AI scientists, or automated idea generation/implementation systems, including details about what types of research problems they were applied to, the characteristics of those problems, and the success or failure rates of the automated system.",
    "supporting_theory_ids": [],
    "model_str": "claude-sonnet-4-5-20250929"
}</code></pre>
        </div>
    </div>
</body>
</html>