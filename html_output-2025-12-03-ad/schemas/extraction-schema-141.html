<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction Schema extraction-schema-141 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extraction Schema Details for extraction-schema-141</h1>

        <div class="section">
            <h2>Extraction Schema (General Information)</h2>
            <div class="info-section">
                <p><strong>Schema ID:</strong> extraction-schema-141</p>
                <p><strong>Extraction Query:</strong> Extract any mentions of how large language models estimate probabilities for future real-world scientific discoveries, including model details, prediction targets, datasets, forecasting horizon, probability estimation methods, evaluation metrics, reported performance, calibration quality, baselines, limitations, and concrete probability examples.</p>
            </div>
        </div>

        <div class="section">
            <h2>Extraction Schema (Details)</h2>
            <table>
                <thead>
                    <tr>
                        <th style="width: 20%;">Field Name</th>
                        <th style="width: 15%;">Type</th>
                        <th style="width: 65%;">Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>model_name</strong></td>
                        <td>str</td>
                        <td>The name or identifier of the LLM used for forecasting (e.g., GPT-4, PaLM 2, SciBERT).</td>
                    </tr>
                    <tr>
                        <td><strong>model_description</strong></td>
                        <td>str</td>
                        <td>A brief description of the model architecture or training regime relevant to probability estimation.</td>
                    </tr>
                    <tr>
                        <td><strong>model_size</strong></td>
                        <td>str</td>
                        <td>Size of the model in parameters or other scale indicator (e.g., 13B, 540B).</td>
                    </tr>
                    <tr>
                        <td><strong>probability_estimation_method</strong></td>
                        <td>str</td>
                        <td>Method used to obtain calibrated probabilities (e.g., temperature scaling, Bayesian inference, Monte‑Carlo dropout, ensemble averaging).</td>
                    </tr>
                    <tr>
                        <td><strong>prediction_target</strong></td>
                        <td>str</td>
                        <td>Specific type of future scientific discovery being predicted (e.g., new drug candidate, novel material, breakthrough algorithm).</td>
                    </tr>
                    <tr>
                        <td><strong>domain</strong></td>
                        <td>str</td>
                        <td>Scientific domain of the predicted discovery (e.g., biomedicine, materials science, physics).</td>
                    </tr>
                    <tr>
                        <td><strong>dataset_used</strong></td>
                        <td>str</td>
                        <td>Dataset(s) on which the model was trained/evaluated for forecasting (e.g., arXiv abstracts 1990‑2020, USPTO patents, PubMed).</td>
                    </tr>
                    <tr>
                        <td><strong>forecasting_horizon</strong></td>
                        <td>str</td>
                        <td>Time horizon of the prediction (e.g., 1 year, 5 years, by 2030).</td>
                    </tr>
                    <tr>
                        <td><strong>evaluation_metric</strong></td>
                        <td>str</td>
                        <td>Metric(s) used to assess probability forecasts (e.g., Brier score, log‑loss, ROC‑AUC, calibration error).</td>
                    </tr>
                    <tr>
                        <td><strong>reported_performance</strong></td>
                        <td>str</td>
                        <td>Quantitative performance results for the model on the chosen metric(s), including units where applicable.</td>
                    </tr>
                    <tr>
                        <td><strong>calibration_quality</strong></td>
                        <td>str</td>
                        <td>Authors' assessment of calibration (e.g., well‑calibrated, overconfident, underconfident) possibly with numeric calibration error.</td>
                    </tr>
                    <tr>
                        <td><strong>baseline_methods</strong></td>
                        <td>str</td>
                        <td>Other methods or models used for comparison (e.g., citation count trends, traditional time‑series models, non‑LLM baselines).</td>
                    </tr>
                    <tr>
                        <td><strong>limitations</strong></td>
                        <td>str</td>
                        <td>Any reported challenges, caveats, or limitations of the approach (e.g., data sparsity, concept drift, interpretability).</td>
                    </tr>
                    <tr>
                        <td><strong>probability_examples</strong></td>
                        <td>str</td>
                        <td>Concrete examples of predicted probabilities for specific future discoveries provided in the paper (e.g., "0.68 probability of a new high‑Tc superconductor by 2027").</td>
                    </tr>
                    <tr>
                        <td><strong>real_world_future</strong></td>
                        <td>bool</td>
                        <td>Indicates whether the paper reports forward‑looking predictions about undiscovered events (true) versus retrospective validation on past discoveries (false).</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <div class="section">
            <h2>Extraction Schema (Debug)</h2>
            <pre><code>{
    "id": "extraction-schema-141",
    "schema": [
        {
            "name": "model_name",
            "type": "str",
            "description": "The name or identifier of the LLM used for forecasting (e.g., GPT-4, PaLM 2, SciBERT)."
        },
        {
            "name": "model_description",
            "type": "str",
            "description": "A brief description of the model architecture or training regime relevant to probability estimation."
        },
        {
            "name": "model_size",
            "type": "str",
            "description": "Size of the model in parameters or other scale indicator (e.g., 13B, 540B)."
        },
        {
            "name": "probability_estimation_method",
            "type": "str",
            "description": "Method used to obtain calibrated probabilities (e.g., temperature scaling, Bayesian inference, Monte‑Carlo dropout, ensemble averaging)."
        },
        {
            "name": "prediction_target",
            "type": "str",
            "description": "Specific type of future scientific discovery being predicted (e.g., new drug candidate, novel material, breakthrough algorithm)."
        },
        {
            "name": "domain",
            "type": "str",
            "description": "Scientific domain of the predicted discovery (e.g., biomedicine, materials science, physics)."
        },
        {
            "name": "dataset_used",
            "type": "str",
            "description": "Dataset(s) on which the model was trained/evaluated for forecasting (e.g., arXiv abstracts 1990‑2020, USPTO patents, PubMed)."
        },
        {
            "name": "forecasting_horizon",
            "type": "str",
            "description": "Time horizon of the prediction (e.g., 1 year, 5 years, by 2030)."
        },
        {
            "name": "evaluation_metric",
            "type": "str",
            "description": "Metric(s) used to assess probability forecasts (e.g., Brier score, log‑loss, ROC‑AUC, calibration error)."
        },
        {
            "name": "reported_performance",
            "type": "str",
            "description": "Quantitative performance results for the model on the chosen metric(s), including units where applicable."
        },
        {
            "name": "calibration_quality",
            "type": "str",
            "description": "Authors' assessment of calibration (e.g., well‑calibrated, overconfident, underconfident) possibly with numeric calibration error."
        },
        {
            "name": "baseline_methods",
            "type": "str",
            "description": "Other methods or models used for comparison (e.g., citation count trends, traditional time‑series models, non‑LLM baselines)."
        },
        {
            "name": "limitations",
            "type": "str",
            "description": "Any reported challenges, caveats, or limitations of the approach (e.g., data sparsity, concept drift, interpretability)."
        },
        {
            "name": "probability_examples",
            "type": "str",
            "description": "Concrete examples of predicted probabilities for specific future discoveries provided in the paper (e.g., \"0.68 probability of a new high‑Tc superconductor by 2027\")."
        },
        {
            "name": "real_world_future",
            "type": "bool",
            "description": "Indicates whether the paper reports forward‑looking predictions about undiscovered events (true) versus retrospective validation on past discoveries (false)."
        }
    ],
    "extraction_query": "Extract any mentions of how large language models estimate probabilities for future real-world scientific discoveries, including model details, prediction targets, datasets, forecasting horizon, probability estimation methods, evaluation metrics, reported performance, calibration quality, baselines, limitations, and concrete probability examples.",
    "supporting_theory_ids": [],
    "model_str": "openrouter/openai/gpt-oss-120b"
}</code></pre>
        </div>
    </div>
</body>
</html>