<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction Schema extraction-schema-75 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extraction Schema Details for extraction-schema-75</h1>

        <div class="section">
            <h2>Extraction Schema (General Information)</h2>
            <div class="info-section">
                <p><strong>Schema ID:</strong> extraction-schema-75</p>
                <p><strong>Extraction Query:</strong> Extract any mentions of LLM agents playing text games, with a focus on how memory is used, what types of memory are implemented, and how memory affects performance on text game tasks.</p>
            </div>
        </div>

        <div class="section">
            <h2>Extraction Schema (Details)</h2>
            <table>
                <thead>
                    <tr>
                        <th style="width: 20%;">Field Name</th>
                        <th style="width: 15%;">Type</th>
                        <th style="width: 65%;">Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>agent_name</strong></td>
                        <td>str</td>
                        <td>The name of the LLM agent or model evaluated in the paper (e.g. 'GPT-4-TextWorld', 'LLM-GameAgent').</td>
                    </tr>
                    <tr>
                        <td><strong>agent_description</strong></td>
                        <td>str</td>
                        <td>A brief description of the LLM agent, including architecture, training, and any relevant details.</td>
                    </tr>
                    <tr>
                        <td><strong>game_or_benchmark_name</strong></td>
                        <td>str</td>
                        <td>The name of the text game, environment, or benchmark used (e.g. 'TextWorld', 'Jericho', 'Zork').</td>
                    </tr>
                    <tr>
                        <td><strong>task_description</strong></td>
                        <td>str</td>
                        <td>A brief description of the specific task(s) or objectives the agent is evaluated on within the text game.</td>
                    </tr>
                    <tr>
                        <td><strong>uses_memory</strong></td>
                        <td>bool</td>
                        <td>Does the agent use any form of memory mechanism to solve the task? (true, false, or null if not specified)</td>
                    </tr>
                    <tr>
                        <td><strong>memory_type</strong></td>
                        <td>str</td>
                        <td>Type of memory used (e.g. 'episodic memory', 'working memory', 'external memory', 'retrieval-augmented', 'scratchpad', 'context window extension', etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>memory_implementation_details</strong></td>
                        <td>str</td>
                        <td>Details on how memory is implemented or integrated (e.g. 'retrieves past observations', 'stores action history', 'uses vector database', 'attention over memory buffer').</td>
                    </tr>
                    <tr>
                        <td><strong>performance_with_memory</strong></td>
                        <td>str</td>
                        <td>Performance of the agent on the task when using memory (quantitative, include units and metrics if available; null if not reported).</td>
                    </tr>
                    <tr>
                        <td><strong>performance_without_memory</strong></td>
                        <td>str</td>
                        <td>Performance of the agent on the task without using memory (quantitative, include units and metrics if available; null if not reported).</td>
                    </tr>
                    <tr>
                        <td><strong>has_performance_comparison</strong></td>
                        <td>bool</td>
                        <td>Does the paper report a direct comparison of performance with and without memory? (true, false, or null if not specified)</td>
                    </tr>
                    <tr>
                        <td><strong>memory_benefits</strong></td>
                        <td>str</td>
                        <td>Summary of observed benefits or improvements attributed to memory usage (e.g. 'improved long-term planning', 'better quest completion', 'higher reward').</td>
                    </tr>
                    <tr>
                        <td><strong>memory_limitations_or_failures</strong></td>
                        <td>str</td>
                        <td>Summary of any limitations, failure cases, or negative effects of memory usage (e.g. 'memory confusion', 'diminishing returns', 'overfitting to history').</td>
                    </tr>
                    <tr>
                        <td><strong>best_practices_or_recommendations</strong></td>
                        <td>str</td>
                        <td>Any recommendations, best practices, or theoretical insights from the paper regarding how LLM agents should use memory in text games.</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <div class="section">
            <h2>Extraction Schema (Debug)</h2>
            <pre><code>{
    "id": "extraction-schema-75",
    "schema": [
        {
            "name": "agent_name",
            "type": "str",
            "description": "The name of the LLM agent or model evaluated in the paper (e.g. 'GPT-4-TextWorld', 'LLM-GameAgent')."
        },
        {
            "name": "agent_description",
            "type": "str",
            "description": "A brief description of the LLM agent, including architecture, training, and any relevant details."
        },
        {
            "name": "game_or_benchmark_name",
            "type": "str",
            "description": "The name of the text game, environment, or benchmark used (e.g. 'TextWorld', 'Jericho', 'Zork')."
        },
        {
            "name": "task_description",
            "type": "str",
            "description": "A brief description of the specific task(s) or objectives the agent is evaluated on within the text game."
        },
        {
            "name": "uses_memory",
            "type": "bool",
            "description": "Does the agent use any form of memory mechanism to solve the task? (true, false, or null if not specified)"
        },
        {
            "name": "memory_type",
            "type": "str",
            "description": "Type of memory used (e.g. 'episodic memory', 'working memory', 'external memory', 'retrieval-augmented', 'scratchpad', 'context window extension', etc.)."
        },
        {
            "name": "memory_implementation_details",
            "type": "str",
            "description": "Details on how memory is implemented or integrated (e.g. 'retrieves past observations', 'stores action history', 'uses vector database', 'attention over memory buffer')."
        },
        {
            "name": "performance_with_memory",
            "type": "str",
            "description": "Performance of the agent on the task when using memory (quantitative, include units and metrics if available; null if not reported)."
        },
        {
            "name": "performance_without_memory",
            "type": "str",
            "description": "Performance of the agent on the task without using memory (quantitative, include units and metrics if available; null if not reported)."
        },
        {
            "name": "has_performance_comparison",
            "type": "bool",
            "description": "Does the paper report a direct comparison of performance with and without memory? (true, false, or null if not specified)"
        },
        {
            "name": "memory_benefits",
            "type": "str",
            "description": "Summary of observed benefits or improvements attributed to memory usage (e.g. 'improved long-term planning', 'better quest completion', 'higher reward')."
        },
        {
            "name": "memory_limitations_or_failures",
            "type": "str",
            "description": "Summary of any limitations, failure cases, or negative effects of memory usage (e.g. 'memory confusion', 'diminishing returns', 'overfitting to history')."
        },
        {
            "name": "best_practices_or_recommendations",
            "type": "str",
            "description": "Any recommendations, best practices, or theoretical insights from the paper regarding how LLM agents should use memory in text games."
        }
    ],
    "extraction_query": "Extract any mentions of LLM agents playing text games, with a focus on how memory is used, what types of memory are implemented, and how memory affects performance on text game tasks.",
    "supporting_theory_ids": [],
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>