<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction Schema extraction-schema-127 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extraction Schema Details for extraction-schema-127</h1>

        <div class="section">
            <h2>Extraction Schema (General Information)</h2>
            <div class="info-section">
                <p><strong>Schema ID:</strong> extraction-schema-127</p>
                <p><strong>Extraction Query:</strong> Extract any mentions of language model agents that employ a memory mechanism to solve tasks, including details of the memory type, how it is accessed or updated, the tasks/benchmarks evaluated, performance with and without the memory, and any reported trade‑offs or limitations.</p>
            </div>
        </div>

        <div class="section">
            <h2>Extraction Schema (Details)</h2>
            <table>
                <thead>
                    <tr>
                        <th style="width: 20%;">Field Name</th>
                        <th style="width: 15%;">Type</th>
                        <th style="width: 65%;">Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>agent_name</strong></td>
                        <td>str</td>
                        <td>Name or identifier of the language model agent (e.g., ReAct, RAG‑GPT, MemGPT).</td>
                    </tr>
                    <tr>
                        <td><strong>agent_description</strong></td>
                        <td>str</td>
                        <td>Brief description of the agent architecture or algorithm, focusing on how it interacts with memory.</td>
                    </tr>
                    <tr>
                        <td><strong>model_size</strong></td>
                        <td>str</td>
                        <td>Scale of the underlying language model (e.g., 7B, 13B, 70B parameters).</td>
                    </tr>
                    <tr>
                        <td><strong>memory_used</strong></td>
                        <td>bool</td>
                        <td>Whether the agent incorporates an explicit memory component (true/false).</td>
                    </tr>
                    <tr>
                        <td><strong>memory_type</strong></td>
                        <td>str</td>
                        <td>Type of memory employed (e.g., external vector store, differentiable neural computer, cache, episodic buffer, retrieval‑augmented generation).</td>
                    </tr>
                    <tr>
                        <td><strong>memory_representation</strong></td>
                        <td>str</td>
                        <td>What is stored in memory (e.g., token embeddings, key‑value pairs, raw text passages, program states).</td>
                    </tr>
                    <tr>
                        <td><strong>memory_access_mechanism</strong></td>
                        <td>str</td>
                        <td>How the agent reads from or writes to memory (e.g., similarity search, attention over keys, learned write controller).</td>
                    </tr>
                    <tr>
                        <td><strong>task_name</strong></td>
                        <td>str</td>
                        <td>Name of the benchmark or task used to evaluate the agent (e.g., HotpotQA, ALFWorld, Codeforces, WebShop).</td>
                    </tr>
                    <tr>
                        <td><strong>task_category</strong></td>
                        <td>str</td>
                        <td>High‑level category of the task (e.g., multi‑hop reasoning, planning, dialogue, code generation, retrieval).</td>
                    </tr>
                    <tr>
                        <td><strong>performance_with_memory</strong></td>
                        <td>str</td>
                        <td>Reported performance metric(s) when the memory component is active (include numeric value and unit, e.g., 78.4% EM, 0.62 F1).</td>
                    </tr>
                    <tr>
                        <td><strong>performance_without_memory</strong></td>
                        <td>str</td>
                        <td>Reported performance metric(s) for the same task when the memory component is disabled or absent (same format as above).</td>
                    </tr>
                    <tr>
                        <td><strong>has_comparative_results</strong></td>
                        <td>bool</td>
                        <td>Does the paper provide a direct comparison between with‑memory and without‑memory versions (true/false).</td>
                    </tr>
                    <tr>
                        <td><strong>performance_metric</strong></td>
                        <td>str</td>
                        <td>Metric used to report performance (e.g., Exact Match, Accuracy, Success Rate, BLEU).</td>
                    </tr>
                    <tr>
                        <td><strong>tradeoffs_reported</strong></td>
                        <td>str</td>
                        <td>Any reported trade‑offs such as latency, memory footprint, scalability, or training stability when using memory.</td>
                    </tr>
                    <tr>
                        <td><strong>limitations_or_failure_cases</strong></td>
                        <td>str</td>
                        <td>Specific scenarios or task types where memory did not improve or hurt performance, as described in the paper.</td>
                    </tr>
                    <tr>
                        <td><strong>citation</strong></td>
                        <td>str</td>
                        <td>Full citation of the paper (authors, year, title, venue) for reference.</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <div class="section">
            <h2>Extraction Schema (Debug)</h2>
            <pre><code>{
    "id": "extraction-schema-127",
    "schema": [
        {
            "name": "agent_name",
            "type": "str",
            "description": "Name or identifier of the language model agent (e.g., ReAct, RAG‑GPT, MemGPT)."
        },
        {
            "name": "agent_description",
            "type": "str",
            "description": "Brief description of the agent architecture or algorithm, focusing on how it interacts with memory."
        },
        {
            "name": "model_size",
            "type": "str",
            "description": "Scale of the underlying language model (e.g., 7B, 13B, 70B parameters)."
        },
        {
            "name": "memory_used",
            "type": "bool",
            "description": "Whether the agent incorporates an explicit memory component (true/false)."
        },
        {
            "name": "memory_type",
            "type": "str",
            "description": "Type of memory employed (e.g., external vector store, differentiable neural computer, cache, episodic buffer, retrieval‑augmented generation)."
        },
        {
            "name": "memory_representation",
            "type": "str",
            "description": "What is stored in memory (e.g., token embeddings, key‑value pairs, raw text passages, program states)."
        },
        {
            "name": "memory_access_mechanism",
            "type": "str",
            "description": "How the agent reads from or writes to memory (e.g., similarity search, attention over keys, learned write controller)."
        },
        {
            "name": "task_name",
            "type": "str",
            "description": "Name of the benchmark or task used to evaluate the agent (e.g., HotpotQA, ALFWorld, Codeforces, WebShop)."
        },
        {
            "name": "task_category",
            "type": "str",
            "description": "High‑level category of the task (e.g., multi‑hop reasoning, planning, dialogue, code generation, retrieval)."
        },
        {
            "name": "performance_with_memory",
            "type": "str",
            "description": "Reported performance metric(s) when the memory component is active (include numeric value and unit, e.g., 78.4% EM, 0.62 F1)."
        },
        {
            "name": "performance_without_memory",
            "type": "str",
            "description": "Reported performance metric(s) for the same task when the memory component is disabled or absent (same format as above)."
        },
        {
            "name": "has_comparative_results",
            "type": "bool",
            "description": "Does the paper provide a direct comparison between with‑memory and without‑memory versions (true/false)."
        },
        {
            "name": "performance_metric",
            "type": "str",
            "description": "Metric used to report performance (e.g., Exact Match, Accuracy, Success Rate, BLEU)."
        },
        {
            "name": "tradeoffs_reported",
            "type": "str",
            "description": "Any reported trade‑offs such as latency, memory footprint, scalability, or training stability when using memory."
        },
        {
            "name": "limitations_or_failure_cases",
            "type": "str",
            "description": "Specific scenarios or task types where memory did not improve or hurt performance, as described in the paper."
        },
        {
            "name": "citation",
            "type": "str",
            "description": "Full citation of the paper (authors, year, title, venue) for reference."
        }
    ],
    "extraction_query": "Extract any mentions of language model agents that employ a memory mechanism to solve tasks, including details of the memory type, how it is accessed or updated, the tasks/benchmarks evaluated, performance with and without the memory, and any reported trade‑offs or limitations.",
    "supporting_theory_ids": [],
    "model_str": "openrouter/openai/gpt-oss-120b"
}</code></pre>
        </div>
    </div>
</body>
</html>