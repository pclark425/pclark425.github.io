<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction Schema extraction-schema-132 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extraction Schema Details for extraction-schema-132</h1>

        <div class="section">
            <h2>Extraction Schema (General Information)</h2>
            <div class="info-section">
                <p><strong>Schema ID:</strong> extraction-schema-132</p>
                <p><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</p>
            </div>
        </div>

        <div class="section">
            <h2>Extraction Schema (Details)</h2>
            <table>
                <thead>
                    <tr>
                        <th style="width: 20%;">Field Name</th>
                        <th style="width: 15%;">Type</th>
                        <th style="width: 65%;">Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>model_name</strong></td>
                        <td>str</td>
                        <td>The name or identifier of the language model used (e.g., GPT-4, ChemGPT, Galactica, LLaMA, etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>model_type</strong></td>
                        <td>str</td>
                        <td>The type of model (e.g., decoder-only LLM, encoder-decoder, fine-tuned model, prompt-only, chain‑of‑thought, tool‑using agent).</td>
                    </tr>
                    <tr>
                        <td><strong>model_size</strong></td>
                        <td>str</td>
                        <td>Size of the model in parameters or a comparable descriptor (e.g., 6B, 13B, 175B, "small", "large").</td>
                    </tr>
                    <tr>
                        <td><strong>training_data_description</strong></td>
                        <td>str</td>
                        <td>Brief description of the data the model was trained on, especially chemical corpora (e.g., SMILES from ZINC, patents, PubChem, ChEMBL).</td>
                    </tr>
                    <tr>
                        <td><strong>generation_method</strong></td>
                        <td>str</td>
                        <td>How the model generates chemicals (e.g., direct SMILES generation, few‑shot prompting, reinforcement learning, fine‑tuning, chain‑of‑thought reasoning, tool‑use with external simulators).</td>
                    </tr>
                    <tr>
                        <td><strong>chemical_representation</strong></td>
                        <td>str</td>
                        <td>The format used to represent molecules (e.g., SMILES, SELFIES, InChI, textual description, graph tokens).</td>
                    </tr>
                    <tr>
                        <td><strong>target_application</strong></td>
                        <td>str</td>
                        <td>Specific application domain for the generated chemicals (e.g., drug discovery, catalyst design, polymer synthesis, material property optimization, agrochemical, fragrance).</td>
                    </tr>
                    <tr>
                        <td><strong>constraints_used</strong></td>
                        <td>str</td>
                        <td>Any constraints or filters applied during generation (e.g., synthetic accessibility score, toxicity filters, property windows, cost, patentability).</td>
                    </tr>
                    <tr>
                        <td><strong>integration_with_external_tools</strong></td>
                        <td>str</td>
                        <td>External computational tools or pipelines used together with the LLM (e.g., docking software, quantum chemistry calculators, retrosynthesis planners, property predictors).</td>
                    </tr>
                    <tr>
                        <td><strong>dataset_used</strong></td>
                        <td>str</td>
                        <td>Dataset(s) employed for training, fine‑tuning, or evaluation (e.g., ZINC, ChEMBL, QM9, proprietary pharma data).</td>
                    </tr>
                    <tr>
                        <td><strong>evaluation_metrics</strong></td>
                        <td>str</td>
                        <td>Metrics reported to assess generated chemicals (e.g., validity %, uniqueness %, novelty %, synthetic accessibility score, QED, binding affinity, top‑k hit rate, property improvement).</td>
                    </tr>
                    <tr>
                        <td><strong>reported_results</strong></td>
                        <td>str</td>
                        <td>Quantitative results for the evaluation metrics (include numbers and units where applicable).</td>
                    </tr>
                    <tr>
                        <td><strong>experimental_validation</strong></td>
                        <td>bool</td>
                        <td>Whether any of the generated compounds were synthesized and experimentally tested (true/false/null if not reported).</td>
                    </tr>
                    <tr>
                        <td><strong>challenges_or_limitations</strong></td>
                        <td>str</td>
                        <td>Any reported challenges, failure modes, or limitations of using LLMs for chemical synthesis (e.g., hallucinated SMILES, low validity, bias, computational cost).</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <div class="section">
            <h2>Extraction Schema (Debug)</h2>
            <pre><code>{
    "id": "extraction-schema-132",
    "schema": [
        {
            "name": "model_name",
            "type": "str",
            "description": "The name or identifier of the language model used (e.g., GPT-4, ChemGPT, Galactica, LLaMA, etc.)."
        },
        {
            "name": "model_type",
            "type": "str",
            "description": "The type of model (e.g., decoder-only LLM, encoder-decoder, fine-tuned model, prompt-only, chain‑of‑thought, tool‑using agent)."
        },
        {
            "name": "model_size",
            "type": "str",
            "description": "Size of the model in parameters or a comparable descriptor (e.g., 6B, 13B, 175B, \"small\", \"large\")."
        },
        {
            "name": "training_data_description",
            "type": "str",
            "description": "Brief description of the data the model was trained on, especially chemical corpora (e.g., SMILES from ZINC, patents, PubChem, ChEMBL)."
        },
        {
            "name": "generation_method",
            "type": "str",
            "description": "How the model generates chemicals (e.g., direct SMILES generation, few‑shot prompting, reinforcement learning, fine‑tuning, chain‑of‑thought reasoning, tool‑use with external simulators)."
        },
        {
            "name": "chemical_representation",
            "type": "str",
            "description": "The format used to represent molecules (e.g., SMILES, SELFIES, InChI, textual description, graph tokens)."
        },
        {
            "name": "target_application",
            "type": "str",
            "description": "Specific application domain for the generated chemicals (e.g., drug discovery, catalyst design, polymer synthesis, material property optimization, agrochemical, fragrance)."
        },
        {
            "name": "constraints_used",
            "type": "str",
            "description": "Any constraints or filters applied during generation (e.g., synthetic accessibility score, toxicity filters, property windows, cost, patentability)."
        },
        {
            "name": "integration_with_external_tools",
            "type": "str",
            "description": "External computational tools or pipelines used together with the LLM (e.g., docking software, quantum chemistry calculators, retrosynthesis planners, property predictors)."
        },
        {
            "name": "dataset_used",
            "type": "str",
            "description": "Dataset(s) employed for training, fine‑tuning, or evaluation (e.g., ZINC, ChEMBL, QM9, proprietary pharma data)."
        },
        {
            "name": "evaluation_metrics",
            "type": "str",
            "description": "Metrics reported to assess generated chemicals (e.g., validity %, uniqueness %, novelty %, synthetic accessibility score, QED, binding affinity, top‑k hit rate, property improvement)."
        },
        {
            "name": "reported_results",
            "type": "str",
            "description": "Quantitative results for the evaluation metrics (include numbers and units where applicable)."
        },
        {
            "name": "experimental_validation",
            "type": "bool",
            "description": "Whether any of the generated compounds were synthesized and experimentally tested (true/false/null if not reported)."
        },
        {
            "name": "challenges_or_limitations",
            "type": "str",
            "description": "Any reported challenges, failure modes, or limitations of using LLMs for chemical synthesis (e.g., hallucinated SMILES, low validity, bias, computational cost)."
        }
    ],
    "extraction_query": "Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.",
    "supporting_theory_ids": [],
    "model_str": "openrouter/openai/gpt-oss-120b"
}</code></pre>
        </div>
    </div>
</body>
</html>