<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction Schema extraction-schema-76 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extraction Schema Details for extraction-schema-76</h1>

        <div class="section">
            <h2>Extraction Schema (General Information)</h2>
            <div class="info-section">
                <p><strong>Schema ID:</strong> extraction-schema-76</p>
                <p><strong>Extraction Query:</strong> Extract any mentions of language models using diverse reasoning methods versus similar reasoning styles to solve reasoning problems, including details of the reasoning methods, tasks, model types, and performance comparisons.</p>
            </div>
        </div>

        <div class="section">
            <h2>Extraction Schema (Details)</h2>
            <table>
                <thead>
                    <tr>
                        <th style="width: 20%;">Field Name</th>
                        <th style="width: 15%;">Type</th>
                        <th style="width: 65%;">Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>model_name</strong></td>
                        <td>str</td>
                        <td>The name of the language model being evaluated (e.g., GPT-4, PaLM, Llama-2, etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>model_description</strong></td>
                        <td>str</td>
                        <td>A brief description of the language model, including architecture, training data, or other relevant details.</td>
                    </tr>
                    <tr>
                        <td><strong>model_size</strong></td>
                        <td>str</td>
                        <td>The size of the model, in parameters (e.g., 7B, 13B, 70B, etc.), if available.</td>
                    </tr>
                    <tr>
                        <td><strong>reasoning_methods</strong></td>
                        <td>list[str]</td>
                        <td>A list of the reasoning methods or strategies used or analyzed in the paper (e.g., chain-of-thought, retrieval-augmented, analogical, deductive, step-by-step, etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>reasoning_methods_description</strong></td>
                        <td>str</td>
                        <td>A brief description of each reasoning method or style, including how it is implemented or prompted in the model.</td>
                    </tr>
                    <tr>
                        <td><strong>diversity_of_methods</strong></td>
                        <td>str</td>
                        <td>Does the model use a diverse set of reasoning methods, a single method, or similar styles? Summarize how this is determined in the paper (e.g., via prompting, architecture, or analysis).</td>
                    </tr>
                    <tr>
                        <td><strong>reasoning_task_name</strong></td>
                        <td>str</td>
                        <td>The name of the reasoning task or benchmark (e.g., GSM8K, ARC, BigBench, etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>reasoning_task_description</strong></td>
                        <td>str</td>
                        <td>A brief description of the reasoning task or benchmark.</td>
                    </tr>
                    <tr>
                        <td><strong>performance_by_method</strong></td>
                        <td>str</td>
                        <td>Performance metrics (accuracy, F1, etc.) for each reasoning method or style, as reported in the paper. Include units and breakdowns if available.</td>
                    </tr>
                    <tr>
                        <td><strong>comparison_of_methods</strong></td>
                        <td>str</td>
                        <td>Any explicit comparisons, ablations, or experiments contrasting diverse reasoning methods versus similar styles, including key findings.</td>
                    </tr>
                    <tr>
                        <td><strong>key_findings</strong></td>
                        <td>str</td>
                        <td>A concise summary of the main findings regarding the use of diverse versus similar reasoning methods in language models.</td>
                    </tr>
                    <tr>
                        <td><strong>counter_examples_or_negative_results</strong></td>
                        <td>str</td>
                        <td>Any counter-examples, negative results, or cases where diverse reasoning methods did not outperform similar styles, as reported in the paper.</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <div class="section">
            <h2>Extraction Schema (Debug)</h2>
            <pre><code>{
    "id": "extraction-schema-76",
    "schema": [
        {
            "name": "model_name",
            "type": "str",
            "description": "The name of the language model being evaluated (e.g., GPT-4, PaLM, Llama-2, etc.)."
        },
        {
            "name": "model_description",
            "type": "str",
            "description": "A brief description of the language model, including architecture, training data, or other relevant details."
        },
        {
            "name": "model_size",
            "type": "str",
            "description": "The size of the model, in parameters (e.g., 7B, 13B, 70B, etc.), if available."
        },
        {
            "name": "reasoning_methods",
            "type": "list[str]",
            "description": "A list of the reasoning methods or strategies used or analyzed in the paper (e.g., chain-of-thought, retrieval-augmented, analogical, deductive, step-by-step, etc.)."
        },
        {
            "name": "reasoning_methods_description",
            "type": "str",
            "description": "A brief description of each reasoning method or style, including how it is implemented or prompted in the model."
        },
        {
            "name": "diversity_of_methods",
            "type": "str",
            "description": "Does the model use a diverse set of reasoning methods, a single method, or similar styles? Summarize how this is determined in the paper (e.g., via prompting, architecture, or analysis)."
        },
        {
            "name": "reasoning_task_name",
            "type": "str",
            "description": "The name of the reasoning task or benchmark (e.g., GSM8K, ARC, BigBench, etc.)."
        },
        {
            "name": "reasoning_task_description",
            "type": "str",
            "description": "A brief description of the reasoning task or benchmark."
        },
        {
            "name": "performance_by_method",
            "type": "str",
            "description": "Performance metrics (accuracy, F1, etc.) for each reasoning method or style, as reported in the paper. Include units and breakdowns if available."
        },
        {
            "name": "comparison_of_methods",
            "type": "str",
            "description": "Any explicit comparisons, ablations, or experiments contrasting diverse reasoning methods versus similar styles, including key findings."
        },
        {
            "name": "key_findings",
            "type": "str",
            "description": "A concise summary of the main findings regarding the use of diverse versus similar reasoning methods in language models."
        },
        {
            "name": "counter_examples_or_negative_results",
            "type": "str",
            "description": "Any counter-examples, negative results, or cases where diverse reasoning methods did not outperform similar styles, as reported in the paper."
        }
    ],
    "extraction_query": "Extract any mentions of language models using diverse reasoning methods versus similar reasoning styles to solve reasoning problems, including details of the reasoning methods, tasks, model types, and performance comparisons.",
    "supporting_theory_ids": [],
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>