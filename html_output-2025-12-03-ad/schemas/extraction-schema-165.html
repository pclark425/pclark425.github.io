<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction Schema extraction-schema-165 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extraction Schema Details for extraction-schema-165</h1>

        <div class="section">
            <h2>Extraction Schema (General Information)</h2>
            <div class="info-section">
                <p><strong>Schema ID:</strong> extraction-schema-165</p>
                <p><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</p>
            </div>
        </div>

        <div class="section">
            <h2>Extraction Schema (Details)</h2>
            <table>
                <thead>
                    <tr>
                        <th style="width: 20%;">Field Name</th>
                        <th style="width: 15%;">Type</th>
                        <th style="width: 65%;">Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>llm_model_name</strong></td>
                        <td>str</td>
                        <td>The name of the large language model (LLM) used for qualitative law extraction (e.g., GPT-4, Llama-2, PaLM, etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>llm_model_description</strong></td>
                        <td>str</td>
                        <td>A brief description of the LLM, including size, architecture, and any relevant fine-tuning or adaptation for the task.</td>
                    </tr>
                    <tr>
                        <td><strong>application_domain</strong></td>
                        <td>str</td>
                        <td>The scientific or scholarly domain in which the LLM is applied (e.g., chemistry, physics, medicine, social science, etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>input_corpus_description</strong></td>
                        <td>str</td>
                        <td>A description of the input corpus, including the number of scholarly papers, their source, and any relevant filtering or preprocessing steps.</td>
                    </tr>
                    <tr>
                        <td><strong>qualitative_law_type</strong></td>
                        <td>str</td>
                        <td>The type or nature of the qualitative law, principle, or rule extracted (e.g., 'structure-activity relationship', 'causal mechanism', 'thematic pattern').</td>
                    </tr>
                    <tr>
                        <td><strong>qualitative_law_example</strong></td>
                        <td>str</td>
                        <td>An example of a qualitative law, principle, or rule extracted by the LLM, as reported in the paper.</td>
                    </tr>
                    <tr>
                        <td><strong>extraction_methodology</strong></td>
                        <td>str</td>
                        <td>A concise description of how the LLM was used to extract qualitative laws (e.g., prompt engineering, chain-of-thought, retrieval-augmented generation, fine-tuning, etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>evaluation_method</strong></td>
                        <td>str</td>
                        <td>How the quality or validity of the extracted qualitative laws was evaluated (e.g., expert review, comparison to known laws, human annotation, etc.).</td>
                    </tr>
                    <tr>
                        <td><strong>results_summary</strong></td>
                        <td>str</td>
                        <td>A brief summary of the results, including successes, limitations, and any quantitative or qualitative findings.</td>
                    </tr>
                    <tr>
                        <td><strong>comparison_to_baseline</strong></td>
                        <td>str</td>
                        <td>Any comparison to baseline methods (e.g., human experts, traditional meta-analysis, other automated methods), including performance differences.</td>
                    </tr>
                    <tr>
                        <td><strong>reported_limitations</strong></td>
                        <td>str</td>
                        <td>Any reported limitations, challenges, or failure cases in using LLMs for qualitative law extraction.</td>
                    </tr>
                    <tr>
                        <td><strong>bias_or_hallucination_issues</strong></td>
                        <td>str</td>
                        <td>Any mentions of bias, hallucination, or reproducibility issues encountered in the LLM's outputs.</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <div class="section">
            <h2>Extraction Schema (Debug)</h2>
            <pre><code>{
    "id": "extraction-schema-165",
    "schema": [
        {
            "name": "llm_model_name",
            "type": "str",
            "description": "The name of the large language model (LLM) used for qualitative law extraction (e.g., GPT-4, Llama-2, PaLM, etc.)."
        },
        {
            "name": "llm_model_description",
            "type": "str",
            "description": "A brief description of the LLM, including size, architecture, and any relevant fine-tuning or adaptation for the task."
        },
        {
            "name": "application_domain",
            "type": "str",
            "description": "The scientific or scholarly domain in which the LLM is applied (e.g., chemistry, physics, medicine, social science, etc.)."
        },
        {
            "name": "input_corpus_description",
            "type": "str",
            "description": "A description of the input corpus, including the number of scholarly papers, their source, and any relevant filtering or preprocessing steps."
        },
        {
            "name": "qualitative_law_type",
            "type": "str",
            "description": "The type or nature of the qualitative law, principle, or rule extracted (e.g., 'structure-activity relationship', 'causal mechanism', 'thematic pattern')."
        },
        {
            "name": "qualitative_law_example",
            "type": "str",
            "description": "An example of a qualitative law, principle, or rule extracted by the LLM, as reported in the paper."
        },
        {
            "name": "extraction_methodology",
            "type": "str",
            "description": "A concise description of how the LLM was used to extract qualitative laws (e.g., prompt engineering, chain-of-thought, retrieval-augmented generation, fine-tuning, etc.)."
        },
        {
            "name": "evaluation_method",
            "type": "str",
            "description": "How the quality or validity of the extracted qualitative laws was evaluated (e.g., expert review, comparison to known laws, human annotation, etc.)."
        },
        {
            "name": "results_summary",
            "type": "str",
            "description": "A brief summary of the results, including successes, limitations, and any quantitative or qualitative findings."
        },
        {
            "name": "comparison_to_baseline",
            "type": "str",
            "description": "Any comparison to baseline methods (e.g., human experts, traditional meta-analysis, other automated methods), including performance differences."
        },
        {
            "name": "reported_limitations",
            "type": "str",
            "description": "Any reported limitations, challenges, or failure cases in using LLMs for qualitative law extraction."
        },
        {
            "name": "bias_or_hallucination_issues",
            "type": "str",
            "description": "Any mentions of bias, hallucination, or reproducibility issues encountered in the LLM's outputs."
        }
    ],
    "extraction_query": "Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.",
    "supporting_theory_ids": [],
    "model_str": "openai/gpt-4.1-2025-04-14"
}</code></pre>
        </div>
    </div>
</body>
</html>