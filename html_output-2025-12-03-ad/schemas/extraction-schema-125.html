<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction Schema extraction-schema-125 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extraction Schema Details for extraction-schema-125</h1>

        <div class="section">
            <h2>Extraction Schema (General Information)</h2>
            <div class="info-section">
                <p><strong>Schema ID:</strong> extraction-schema-125</p>
                <p><strong>Extraction Query:</strong> Extract any mentions of large language model agents that use memory to solve text‑based games, including details about the memory type, representation, update mechanism, benchmark used, performance with and without memory, training method, and any reported challenges or ablations.</p>
            </div>
        </div>

        <div class="section">
            <h2>Extraction Schema (Details)</h2>
            <table>
                <thead>
                    <tr>
                        <th style="width: 20%;">Field Name</th>
                        <th style="width: 15%;">Type</th>
                        <th style="width: 65%;">Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>paper_title</strong></td>
                        <td>str</td>
                        <td>Title of the paper.</td>
                    </tr>
                    <tr>
                        <td><strong>model_name</strong></td>
                        <td>str</td>
                        <td>Name of the LLM or agent architecture evaluated (e.g., GPT‑3, PaLM, ReAct, GATA).</td>
                    </tr>
                    <tr>
                        <td><strong>model_description</strong></td>
                        <td>str</td>
                        <td>Brief description of the model/agent, focusing on its core architecture.</td>
                    </tr>
                    <tr>
                        <td><strong>model_size</strong></td>
                        <td>str</td>
                        <td>Scale of the model in parameters (e.g., 6B, 13B, 175B).</td>
                    </tr>
                    <tr>
                        <td><strong>memory_used</strong></td>
                        <td>bool</td>
                        <td>Whether the agent incorporates an explicit memory component (true/false).</td>
                    </tr>
                    <tr>
                        <td><strong>memory_type</strong></td>
                        <td>str</td>
                        <td>Type of memory employed (e.g., external vector store, key‑value cache, neural Turing machine, recurrent hidden state, episodic buffer).</td>
                    </tr>
                    <tr>
                        <td><strong>memory_representation</strong></td>
                        <td>str</td>
                        <td>What is stored in memory (e.g., raw observations, embeddings, action‑observation pairs, program traces).</td>
                    </tr>
                    <tr>
                        <td><strong>memory_update_mechanism</strong></td>
                        <td>str</td>
                        <td>How the memory is updated or queried (e.g., attention over past steps, gradient‑based write, reinforcement‑learned write policy, similarity search).</td>
                    </tr>
                    <tr>
                        <td><strong>text_game_name</strong></td>
                        <td>str</td>
                        <td>Name of the text‑game benchmark used (e.g., TextWorld, Jericho, LIGHT, Zork).</td>
                    </tr>
                    <tr>
                        <td><strong>text_game_description</strong></td>
                        <td>str</td>
                        <td>Brief description of the game or task (e.g., quest‑based, puzzle‑solving, dialogue‑driven).</td>
                    </tr>
                    <tr>
                        <td><strong>training_method</strong></td>
                        <td>str</td>
                        <td>Learning paradigm used for the agent (e.g., reinforcement learning, supervised fine‑tuning, few‑shot prompting, imitation learning).</td>
                    </tr>
                    <tr>
                        <td><strong>evaluation_metric</strong></td>
                        <td>str</td>
                        <td>Metric reported for game performance (e.g., success rate, normalized score, average steps to solve).</td>
                    </tr>
                    <tr>
                        <td><strong>performance_with_memory</strong></td>
                        <td>str</td>
                        <td>Reported performance of the agent when the memory component is enabled (include numeric value and metric).</td>
                    </tr>
                    <tr>
                        <td><strong>performance_without_memory</strong></td>
                        <td>str</td>
                        <td>Reported performance of the same agent without the memory component (include numeric value and metric).</td>
                    </tr>
                    <tr>
                        <td><strong>performance_improvement</strong></td>
                        <td>str</td>
                        <td>Quantitative improvement attributed to memory (e.g., +12% success rate, Δ0.35 normalized score).</td>
                    </tr>
                    <tr>
                        <td><strong>ablation_study</strong></td>
                        <td>bool</td>
                        <td>Whether the paper includes an ablation that isolates memory effects (true/false).</td>
                    </tr>
                    <tr>
                        <td><strong>challenges_noted</strong></td>
                        <td>str</td>
                        <td>Any limitations, failure modes, or scalability issues reported regarding the memory usage.</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <div class="section">
            <h2>Extraction Schema (Debug)</h2>
            <pre><code>{
    "id": "extraction-schema-125",
    "schema": [
        {
            "name": "paper_title",
            "type": "str",
            "description": "Title of the paper."
        },
        {
            "name": "model_name",
            "type": "str",
            "description": "Name of the LLM or agent architecture evaluated (e.g., GPT‑3, PaLM, ReAct, GATA)."
        },
        {
            "name": "model_description",
            "type": "str",
            "description": "Brief description of the model/agent, focusing on its core architecture."
        },
        {
            "name": "model_size",
            "type": "str",
            "description": "Scale of the model in parameters (e.g., 6B, 13B, 175B)."
        },
        {
            "name": "memory_used",
            "type": "bool",
            "description": "Whether the agent incorporates an explicit memory component (true/false)."
        },
        {
            "name": "memory_type",
            "type": "str",
            "description": "Type of memory employed (e.g., external vector store, key‑value cache, neural Turing machine, recurrent hidden state, episodic buffer)."
        },
        {
            "name": "memory_representation",
            "type": "str",
            "description": "What is stored in memory (e.g., raw observations, embeddings, action‑observation pairs, program traces)."
        },
        {
            "name": "memory_update_mechanism",
            "type": "str",
            "description": "How the memory is updated or queried (e.g., attention over past steps, gradient‑based write, reinforcement‑learned write policy, similarity search)."
        },
        {
            "name": "text_game_name",
            "type": "str",
            "description": "Name of the text‑game benchmark used (e.g., TextWorld, Jericho, LIGHT, Zork)."
        },
        {
            "name": "text_game_description",
            "type": "str",
            "description": "Brief description of the game or task (e.g., quest‑based, puzzle‑solving, dialogue‑driven)."
        },
        {
            "name": "training_method",
            "type": "str",
            "description": "Learning paradigm used for the agent (e.g., reinforcement learning, supervised fine‑tuning, few‑shot prompting, imitation learning)."
        },
        {
            "name": "evaluation_metric",
            "type": "str",
            "description": "Metric reported for game performance (e.g., success rate, normalized score, average steps to solve)."
        },
        {
            "name": "performance_with_memory",
            "type": "str",
            "description": "Reported performance of the agent when the memory component is enabled (include numeric value and metric)."
        },
        {
            "name": "performance_without_memory",
            "type": "str",
            "description": "Reported performance of the same agent without the memory component (include numeric value and metric)."
        },
        {
            "name": "performance_improvement",
            "type": "str",
            "description": "Quantitative improvement attributed to memory (e.g., +12% success rate, Δ0.35 normalized score)."
        },
        {
            "name": "ablation_study",
            "type": "bool",
            "description": "Whether the paper includes an ablation that isolates memory effects (true/false)."
        },
        {
            "name": "challenges_noted",
            "type": "str",
            "description": "Any limitations, failure modes, or scalability issues reported regarding the memory usage."
        }
    ],
    "extraction_query": "Extract any mentions of large language model agents that use memory to solve text‑based games, including details about the memory type, representation, update mechanism, benchmark used, performance with and without memory, training method, and any reported challenges or ablations.",
    "supporting_theory_ids": [],
    "model_str": "openrouter/openai/gpt-oss-120b"
}</code></pre>
        </div>
    </div>
</body>
</html>