<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9647 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9647</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9647</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-167.html">extraction-schema-167</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to distill or synthesize theories or knowledge from large numbers of scholarly papers, including details about the models, input corpora, methods, outputs, evaluations, strengths, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-272368029</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2409.00054v2.pdf" target="_blank">Automating Intervention Discovery from Scientific Literature: A Progressive Ontology Prompting and Dual-LLM Framework</a></p>
                <p><strong>Paper Abstract:</strong> Identifying effective interventions from the scientific literature is challenging due to the high volume of publications, specialized terminology, and inconsistent reporting formats, making manual curation laborious and prone to oversight. To address this challenge, this paper proposes a novel framework leveraging large language models (LLMs), which integrates a progressive ontology prompting (POP) algorithm with a dual-agent system, named LLM-Duo. On the one hand, the POP algorithm conducts a prioritized breadth-first search (BFS) across a predefined ontology, generating structured prompt templates and action sequences to guide the automatic annotation process. On the other hand, the LLM-Duo system features two specialized LLM agents, an explorer and an evaluator, working collaboratively and adversarially to continuously refine annotation quality. We showcase the real-world applicability of our framework through a case study focused on speech-language intervention discovery. Experimental results show that our approach surpasses advanced baselines, achieving more accurate and comprehensive annotations through a fully automated process. Our approach successfully identified 2,421 interventions from a corpus of 64,177 research articles in the speech-language pathology domain, culminating in the creation of a publicly accessible intervention knowledge base with great potential to benefit the speech-language pathology community.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9647.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9647.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to distill or synthesize theories or knowledge from large numbers of scholarly papers, including details about the models, input corpora, methods, outputs, evaluations, strengths, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-Duo</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLM-Duo dual-agent annotation framework</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A two-agent LLM system (an explorer and an evaluator) that iteratively annotates literature using retrieval-grounded answers from an explorer and adversarial/collaborative critique from an evaluator to produce structured, high-fidelity knowledge extractions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLM-Duo (Explorer + Evaluator)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Explorer: a retrieval-augmented chatbot implemented with Llamaindex that retrieves top-k document chunks and answers annotation QA; Evaluator: an external LLM (no document context) that reviews, critiques, and requests refinements or defends answers in an iterative loop. The two agents operate collaboratively and adversarially to refine annotations until consistency/completeness criteria are met.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>A curated literature corpus in speech-language pathology assembled with keyword queries; the framework was used both in focused evaluation on 8 randomly selected papers and at large scale to discover interventions across the full corpus.</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_size</strong></td>
                            <td>64177</td>
                        </tr>
                        <tr>
                            <td><strong>topic_query_description</strong></td>
                            <td>Automated discovery and structured extraction of speech-language interventions and their aspects (e.g., intervention name, disorder, procedure, efficacy, therapy activities, setting) guided by a predefined intervention ontology.</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td>Progressive Ontology Prompting (POP) to derive a sequence of ontology-anchored prompt templates and action orders, combined with a dual-agent iterative annotation loop: explorer answers QA grounded by retrieval-augmented generation (RAG) and a separate evaluator LLM critiques and requests refinements (or the explorer defends answers), repeating until consistency/completeness.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Structured annotations anchored to an intervention ontology and a populated intervention knowledge graph (KG).</td>
                        </tr>
                        <tr>
                            <td><strong>output_example</strong></td>
                            <td>{"Intervention": "Lee Silverman Voice Treatment (LSVT LOUD)", "Disorder": ["stroke","ataxia"], "Procedure": "intensive high-effort exercises ... 16 one-hour sessions" , "Frequency": "four times a week", "Efficacy": "statistically significant increases in vocal dB SPL" }</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Quantitative automatic metrics (Consistency Rounds, Verbosity Index, Enumeration Quantity, Faithfulness via Llamaindex FaithfulnessEvaluator, Accuracy, Coverage) and human expert review: human annotators produced gold standards for Intervention Recognition (IR) and Intervention Knowledge Completion (IKC); 19 clinicians/students reviewed annotations for large-scale outputs via surveys.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_results</strong></td>
                            <td>LLM-Duo (when run with RAG) outperformed baselines (RAG-only, CoT-RAG, Self-Refine-RAG, long-context GPT-4 baseline) on annotation accuracy and comprehensiveness in the 8-paper evaluation and enabled large-scale discovery: 2,421 interventions extracted from 64,177 papers; final KG: 33,148 nodes and 324,707 relations. Human reviews and automatic faithfulness metrics indicated higher faithfulness and coverage vs. baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>strengths</strong></td>
                            <td>Scalable to very large literature corpora; combines retrieval grounding to reduce hallucination with an evaluator agent to improve rationality and completeness; adaptable to a predefined ontology; achieves high-quality structured outputs (KG) and comparable quality with open-source LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Depends on a predefined ontology crafted by domain experts; relies on retrieval quality and chunking/coreference preprocessing; evaluator is an LLM that does not have direct document context (relies on explorer for context); some evaluation settings used small held-out sets (8 papers) for detailed comparisons; potential remaining hallucination risk if retrieval is weak.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Short-context zero-shot prompting with full paper text failed for some large open-source models (produced misaligned outputs). RAG retrieval with too-small context (k=1) returned low-similarity chunks causing poor annotations; removing reranking or coreference modules significantly reduced accuracy in ablation studies. One-shot prompting that included entire KG schema produced incomplete annotations compared to POP-guided progressive prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Automating Intervention Discovery from Scientific Literature: A Progressive Ontology Prompting and Dual-LLM Framework', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9647.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9647.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to distill or synthesize theories or knowledge from large numbers of scholarly papers, including details about the models, input corpora, methods, outputs, evaluations, strengths, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>POP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Progressive Ontology Prompting (POP)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An ontology-driven prompt construction and scheduling algorithm that performs a prioritized breadth-first traversal of a predefined KG ontology to produce context-aware prompt templates and an ordered sequence of annotation queries for LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>POP (prompt scheduler)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Algorithmic method, not a neural model: uses prioritized BFS on the ontology using an out-to-in ratio R(v) to prioritize nodes with high outgoing degree, constructs k-hop contextual templates T_v, and fills templates with completed annotations to produce progressive prompts for LLM annotation.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Applied to the speech-language intervention ontology and used to schedule annotation queries across papers; context window size k (k-hop neighborhood) was varied in experiments to assess impact on retrieval and accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_size</strong></td>
                            <td>64177</td>
                        </tr>
                        <tr>
                            <td><strong>topic_query_description</strong></td>
                            <td>Generate ordered, context-aware annotation queries for extracting intervention-related entities/relations (e.g., TherapyActivity→TherapyGoal→Disorder) from scientific papers.</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td>Outdegree-prioritized BFS to collect k-hop neighborhood context, few-shot template generation for prompt templates, progressive application of completed annotations in the context to subsequent prompts to preserve contextual coherence during extraction.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Ordered prompt templates and action sequences used to steer LLMs toward more complete, contextually consistent structured annotations.</td>
                        </tr>
                        <tr>
                            <td><strong>output_example</strong></td>
                            <td>Example visit order: 'TherapyActivity' → 'TherapyGoal' → 'Disorder'. For node v, Prompt_v := T_v(Annotation(N_k(v))) where T_v concatenates Prefix(N_{k-1}(u)) with questions about (v,e,u) triples.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Ablation/comparison experiments: one-shot prompt including whole KG schema vs. POP without prioritization vs. POP with prioritized BFS; also context-size (k) sweep experiments for impact on retrieval quality and annotation accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_results</strong></td>
                            <td>Larger context sizes (k≥2) improved annotation accuracy and retrieval relevance; prioritized BFS ordering improved annotation performance compared to unprioritized POP and one-shot KG prompting (Table 2 reported prioritized POP yielded notable gains).</td>
                        </tr>
                        <tr>
                            <td><strong>strengths</strong></td>
                            <td>Encodes ontology structure into prompt scheduling to exploit local contextual dependencies; improves retrieval relevance and final annotation accuracy; reduces omissions vs. one-shot KG prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Requires a predefined ontology (domain expert effort); choice of k and prioritization heuristics affect performance and must be tuned; POP itself is not a remedy for retrieval failures—benefits depend on the quality of the retrieval/LLM components.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>One-shot annotation including entire KG schema produced incomplete annotations; POP with low context size (k=1) led to retrievals with low similarity and lower annotation quality.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Automating Intervention Discovery from Scientific Literature: A Progressive Ontology Prompting and Dual-LLM Framework', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9647.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9647.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to distill or synthesize theories or knowledge from large numbers of scholarly papers, including details about the models, input corpora, methods, outputs, evaluations, strengths, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RAG (Llamaindex)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Retrieval-Augmented Generation pipeline (implemented with Llamaindex, Chroma, and text-embedding-3-large)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A retrieval-grounding pipeline used by the explorer agent: documents are chunked (256 tokens, 128 overlap) with coreference resolution, embedded using text-embedding-3-large, stored in Chroma, top-8 chunks retrieved and reranked with a cross-encoder before being provided to the LLM for QA.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>RAG pipeline (Llamaindex + Chroma + text-embedding-3-large + cross-encoder rerank)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Chunking with coreference resolution (FastCoref) -> embeddings via OpenAI 'text-embedding-3-large' -> vector DB: Chroma -> retrieve top-8 chunks -> rerank with cross-encoder/msmarco-MiniLM-L-2-v2 -> fed to LLM (explorer) to answer annotation queries.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Applied to the speech-language literature corpus (64,177 papers) with document-level metadata filtering so the explorer answers are restricted to the specific target document during annotation cycles.</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_size</strong></td>
                            <td>64177</td>
                        </tr>
                        <tr>
                            <td><strong>topic_query_description</strong></td>
                            <td>Ground annotation QA in retrieved, high-similarity document fragments to reduce hallucinations and enable document-faithful structured extraction of intervention aspects.</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td>RAG: retrieval of supporting text chunks, reranking, and conditioning of LLM responses on retrieved evidence. Used with POP-generated prompts and the LLM-Duo explorer agent.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Evidence-grounded annotation responses (structured fields) and supporting provenance (document chunk IDs).</td>
                        </tr>
                        <tr>
                            <td><strong>output_example</strong></td>
                            <td>{"supported_chunks": [doc_id:1234, chunk_id:5], "Procedure": "...16 sessions...", "Evidence": "quoted text from chunk"}</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Ablation studies removing reranking or coreference modules, measuring intervention recognition accuracy and downstream annotation quality; comparisons against non-RAG baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_results</strong></td>
                            <td>Removing rerank or coreference reduced accuracy significantly; RAG grounding improved faithfulness and reduced hallucination relative to direct LLM QA without retrieval, but RAG alone was outperformed by LLM-Duo (RAG + evaluator) and some self-refinement methods in particular metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>strengths</strong></td>
                            <td>Provides document grounding to answers, reduces hallucination, enables retrieval of long-range evidence across long documents, and supports provenance.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Quality depends on chunking strategy, embedding model, reranker quality and similarity thresholds; small context prompts (k=1) can produce low-similarity retrievals harming performance; retrieval is an additional failure point.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Low-similarity retrievals for small k yielded poor annotations; naive RAG without evaluator produced lower comprehensiveness and faithfulness than LLM-Duo-RAG.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Automating Intervention Discovery from Scientific Literature: A Progressive Ontology Prompting and Dual-LLM Framework', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9647.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9647.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to distill or synthesize theories or knowledge from large numbers of scholarly papers, including details about the models, input corpora, methods, outputs, evaluations, strengths, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4-turbo-128k</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4 Turbo with 128k context window</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A long-context commercial LLM used as a baseline and as the evaluator or long-context explorer in some experiments; capable of ingesting long documents but still produced less comprehensive extraction coverage in direct prompting baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4-turbo (128k context)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI's GPT-4 Turbo with an expanded 128k token context window, used both in 'LongContext' baselines and in an LLM-Duo-LongContext configuration.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Used in evaluation experiments on small evaluation sets (8 randomly selected papers) to compare direct long-context annotation vs. POP+RAG+LLM-Duo approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_size</strong></td>
                            <td>8</td>
                        </tr>
                        <tr>
                            <td><strong>topic_query_description</strong></td>
                            <td>Direct zero- or few-shot QA annotation of full-paper text for intervention extraction vs. retrieval-grounded and progressive prompting methods.</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td>Direct long-context prompting (feed entire document tokens) for zero-shot QA annotation and also integrated into LLM-Duo-LongContext variant where it participates in the dual-agent loop without chunking/RAG.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Structured annotation responses (same schema as other methods).</td>
                        </tr>
                        <tr>
                            <td><strong>output_example</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Compared quantitatively on the same evaluation metrics (accuracy, coverage, faithfulness, verbosity, etc.) against RAG and LLM-Duo variants on the 8-paper test set.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_results</strong></td>
                            <td>GPT-4-turbo could generate annotations but its annotation coverage was inadequate compared to LLM-Duo-RAG; integrating GPT-4-turbo into LLM-Duo improved accuracy and comprehensiveness vs. GPT-4-turbo alone.</td>
                        </tr>
                        <tr>
                            <td><strong>strengths</strong></td>
                            <td>Very large context capacity enables processing of long documents directly without chunking; strong reasoning capabilities.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Despite long context, direct prompting led to insufficient coverage and omissions; costly to run at scale compared to open-source alternatives integrated in LLM-Duo-RAG.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>LongContext alone missed many intervention aspects that POP+RAG+LLM-Duo captured; LLMs still susceptible to omissions/hallucinations when asked to synthesize across long documents without retrieval and scheduling.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Automating Intervention Discovery from Scientific Literature: A Progressive Ontology Prompting and Dual-LLM Framework', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9647.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e9647.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to distill or synthesize theories or knowledge from large numbers of scholarly papers, including details about the models, input corpora, methods, outputs, evaluations, strengths, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CoT-RAG</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chain-of-Thought prompting combined with RAG</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A baseline that equips the RAG-based explorer with Chain-of-Thought prompting to elicit multi-step reasoning and self-correction when answering annotation queries.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>CoT-RAG (Chain-of-Thought prompts + RAG)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Explorer uses RAG retrieval plus CoT prompting templates (e.g., 'Make a plan to answer the question again') to encourage stepwise reasoning and improved answers.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Applied to the 8-paper evaluation subset to compare against LLM-Duo-RAG and other baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_size</strong></td>
                            <td>8</td>
                        </tr>
                        <tr>
                            <td><strong>topic_query_description</strong></td>
                            <td>Improve extraction completeness and rationality via internal chain-of-thought planning and stepwise refinement.</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td>RAG retrieval + CoT prompting where the model is instructed to plan and then answer, optionally re-planning to increase comprehensiveness.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Structured annotations with more elaborate reasoning traces.</td>
                        </tr>
                        <tr>
                            <td><strong>output_example</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Quantitative comparison on the annotation metrics reported in the paper (accuracy, faithfulness, coverage, verbosity, etc.).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_results</strong></td>
                            <td>CoT-RAG significantly improved over plain RAG but performed worse than LLM-Duo-RAG. It achieved higher intervention recognition and coverage than basic RAG but lower comprehensiveness vs. the dual-agent approach.</td>
                        </tr>
                        <tr>
                            <td><strong>strengths</strong></td>
                            <td>Encourages internal reasoning and can improve self-correction without an external evaluator; simple to add to RAG pipelines.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Still limited by grounding and lacks adversarial external critique; worse than dual-agent evaluator loop in achieving completeness.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>CoT planning alone could not reach the same level of comprehensiveness and faithfulness as LLM-Duo with a separate evaluator.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Automating Intervention Discovery from Scientific Literature: A Progressive Ontology Prompting and Dual-LLM Framework', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9647.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e9647.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to distill or synthesize theories or knowledge from large numbers of scholarly papers, including details about the models, input corpora, methods, outputs, evaluations, strengths, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Self-Refine-RAG</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Self-Refine prompting combined with RAG</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A baseline in which the retrieval-grounded explorer iteratively reflects on and revises its own answers via a Self-Refine prompt loop (no external evaluator).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Self-Refine-RAG</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>RAG-backed explorer that uses Self-Refine prompts (reflect, critique, revise) to attempt iterative self-improvement of annotations.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Applied to the 8-paper evaluation subset as a baseline to compare against LLM-Duo-RAG and CoT-RAG.</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_size</strong></td>
                            <td>8</td>
                        </tr>
                        <tr>
                            <td><strong>topic_query_description</strong></td>
                            <td>Automatic iterative self-correction to improve faithfulness and completeness without a separate evaluator agent.</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td>RAG retrieval + a sequence of Self-Refine prompts asking the model to reflect and revise its previous answer based on its own critiquing.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Structured annotations after self-refinement rounds.</td>
                        </tr>
                        <tr>
                            <td><strong>output_example</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Quantitative comparison using the paper's metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_results</strong></td>
                            <td>Self-Refine-RAG improved over raw RAG but performed worse than LLM-Duo-RAG; in some metrics it was comparable to CoT-RAG but lower on overall accuracy/coverage relative to the dual-agent framework.</td>
                        </tr>
                        <tr>
                            <td><strong>strengths</strong></td>
                            <td>Enables autonomous refinement without extra LLM costs for a second agent; simple prompting strategy.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Intrinsic self-correction has limits; lacks the adversarial critique that an independent evaluator provides, which the paper found beneficial.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Self-refine loops sometimes converged prematurely or failed to discover missing aspects that an external evaluator would identify.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Automating Intervention Discovery from Scientific Literature: A Progressive Ontology Prompting and Dual-LLM Framework', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9647.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e9647.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to distill or synthesize theories or knowledge from large numbers of scholarly papers, including details about the models, input corpora, methods, outputs, evaluations, strengths, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Open-source LLMs (Llama3 & Mistral)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Llama3-instruct-70b and Mistral-instruct-8x22b</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Large open-source instruction-tuned models used in LLM-Duo-RAG as cost-effective alternatives to GPTs, achieving comparable annotation quality in the experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama3-instruct-70b; Mistral-instruct-8x22b</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Instruction-tuned open-source LLMs: Llama3-instruct (70B parameters) and Mistral-instruct (approx 22B inferential variant) used as explorer and/or annotator LLMs within the RAG and LLM-Duo pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>70B; 22B</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Used in the annotation baselines and as the LLM in LLM-Duo-RAG for large-scale discovery experiments on the 64k paper corpus and in the 8-paper evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_size</strong></td>
                            <td>64177</td>
                        </tr>
                        <tr>
                            <td><strong>topic_query_description</strong></td>
                            <td>Same intervention extraction queries driven by POP and RAG, to evaluate tradeoffs between cost and annotation quality versus proprietary models.</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td>RAG-backed retrieval with POP-guided prompts, exchanging messages with evaluator LLM; used within LLM-Duo-RAG.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Structured annotations and populated KG entries.</td>
                        </tr>
                        <tr>
                            <td><strong>output_example</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Direct quantitative comparison to GPT-based baselines on annotation metrics presented in Table 1.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_results</strong></td>
                            <td>LLM-Duo-RAG using these open-source models achieved comparable annotation quality to GPT-based setups while being more cost-effective; reported to achieve annotation results close to GPT baselines in many metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>strengths</strong></td>
                            <td>Cost-effective at large scale; when combined with RAG and POP they are competitive with GPTs for the annotation task.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Direct zero-shot prompting of full paper text (ShortContext setup) with these models failed to produce valid annotations in experiments; require the RAG + POP scaffolding to succeed.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>ShortContext prompting with Llama3-instruct-70b and Mistral-instruct-8x22b (no RAG) failed to produce aligned annotations in zero-shot QA settings.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Automating Intervention Discovery from Scientific Literature: A Progressive Ontology Prompting and Dual-LLM Framework', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9647.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e9647.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to distill or synthesize theories or knowledge from large numbers of scholarly papers, including details about the models, input corpora, methods, outputs, evaluations, strengths, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Supporting pipeline components</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Llamaindex, text-embedding-3-large, FastCoref, Chroma, cross-encoder reranker, FaithfulnessEvaluator</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Set of tooling used to operationalize retrieval grounding, embedding, coreference resolution, vector storage, reranking, and faithfulness evaluation in the pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llamaindex + OpenAI text-embedding-3-large + FastCoref + Chroma + cross-encoder/msmarco-MiniLM-L-2-v2 + Llamaindex FaithfulnessEvaluator</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Pipeline: FastCoref for coreference before chunking; embedding via OpenAI 'text-embedding-3-large'; vector DB: Chroma; retrieval: top-8 chunks then reranked by cross-encoder/msmarco-MiniLM-L-2-v2; faithfulness measured by Llamaindex FaithfulnessEvaluator.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Used across the 64k paper corpus and evaluation subsets to preprocess, embed, store, retrieve, and evaluate evidence used by the explorer and for automated faithfulness scoring.</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_size</strong></td>
                            <td>64177</td>
                        </tr>
                        <tr>
                            <td><strong>topic_query_description</strong></td>
                            <td>Support retrieval and evidence-grounding for the intervention extraction tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td>Preprocessing -> embedding -> vector store -> similarity retrieval -> cross-encoder reranking -> feed to LLM; faithfulness scoring on outputs using an automated evaluator.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Retrieved evidence chunks, reranked passages, metadata filtered results, and automatic faithfulness scores.</td>
                        </tr>
                        <tr>
                            <td><strong>output_example</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Ablation of reranker and coreference modules measuring drop in intervention recognition accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_results</strong></td>
                            <td>Ablation showed major accuracy drops when reranking or coreference preprocessing were removed, indicating these components are necessary for high-quality retrieval and downstream extraction.</td>
                        </tr>
                        <tr>
                            <td><strong>strengths</strong></td>
                            <td>Improves retrieval relevance, evidence fidelity, and automated faithfulness scoring; enables document-level grounding.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Adds engineering complexity; performance sensitive to hyperparameters (chunk size, overlap, rerank thresholds); reliance on external embedding service for text-embedding-3-large.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Loss of rerank or coreference produced marked degradation in results; low-similarity retrievals when using too small POP context sizes.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Automating Intervention Discovery from Scientific Literature: A Progressive Ontology Prompting and Dual-LLM Framework', 'publication_date_yy_mm': '2024-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Chain-of-thought prompting elicits reasoning in large language models <em>(Rating: 2)</em></li>
                <li>Self-Refine: iterative self-refinement for LLMs <em>(Rating: 2)</em></li>
                <li>Autogen: Enabling next-gen LLM applications via multi-agent conversation framework <em>(Rating: 2)</em></li>
                <li>Meganno+: A human-LLM collaborative annotation system <em>(Rating: 2)</em></li>
                <li>Can LLMs produce faithful explanations for fact-checking? towards faithful explainable fact-checking via multi-agent debate <em>(Rating: 1)</em></li>
                <li>Consistency guided knowledge retrieval and denoising in LLMs for zero-shot document-level relation triplet extraction <em>(Rating: 2)</em></li>
                <li>Large language models have intrinsic self-correction ability <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9647",
    "paper_id": "paper-272368029",
    "extraction_schema_id": "extraction-schema-167",
    "extracted_data": [
        {
            "name_short": "LLM-Duo",
            "name_full": "LLM-Duo dual-agent annotation framework",
            "brief_description": "A two-agent LLM system (an explorer and an evaluator) that iteratively annotates literature using retrieval-grounded answers from an explorer and adversarial/collaborative critique from an evaluator to produce structured, high-fidelity knowledge extractions.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "LLM-Duo (Explorer + Evaluator)",
            "model_description": "Explorer: a retrieval-augmented chatbot implemented with Llamaindex that retrieves top-k document chunks and answers annotation QA; Evaluator: an external LLM (no document context) that reviews, critiques, and requests refinements or defends answers in an iterative loop. The two agents operate collaboratively and adversarially to refine annotations until consistency/completeness criteria are met.",
            "model_size": null,
            "input_corpus_description": "A curated literature corpus in speech-language pathology assembled with keyword queries; the framework was used both in focused evaluation on 8 randomly selected papers and at large scale to discover interventions across the full corpus.",
            "input_corpus_size": 64177,
            "topic_query_description": "Automated discovery and structured extraction of speech-language interventions and their aspects (e.g., intervention name, disorder, procedure, efficacy, therapy activities, setting) guided by a predefined intervention ontology.",
            "distillation_method": "Progressive Ontology Prompting (POP) to derive a sequence of ontology-anchored prompt templates and action orders, combined with a dual-agent iterative annotation loop: explorer answers QA grounded by retrieval-augmented generation (RAG) and a separate evaluator LLM critiques and requests refinements (or the explorer defends answers), repeating until consistency/completeness.",
            "output_type": "Structured annotations anchored to an intervention ontology and a populated intervention knowledge graph (KG).",
            "output_example": "{\"Intervention\": \"Lee Silverman Voice Treatment (LSVT LOUD)\", \"Disorder\": [\"stroke\",\"ataxia\"], \"Procedure\": \"intensive high-effort exercises ... 16 one-hour sessions\" , \"Frequency\": \"four times a week\", \"Efficacy\": \"statistically significant increases in vocal dB SPL\" }",
            "evaluation_method": "Quantitative automatic metrics (Consistency Rounds, Verbosity Index, Enumeration Quantity, Faithfulness via Llamaindex FaithfulnessEvaluator, Accuracy, Coverage) and human expert review: human annotators produced gold standards for Intervention Recognition (IR) and Intervention Knowledge Completion (IKC); 19 clinicians/students reviewed annotations for large-scale outputs via surveys.",
            "evaluation_results": "LLM-Duo (when run with RAG) outperformed baselines (RAG-only, CoT-RAG, Self-Refine-RAG, long-context GPT-4 baseline) on annotation accuracy and comprehensiveness in the 8-paper evaluation and enabled large-scale discovery: 2,421 interventions extracted from 64,177 papers; final KG: 33,148 nodes and 324,707 relations. Human reviews and automatic faithfulness metrics indicated higher faithfulness and coverage vs. baselines.",
            "strengths": "Scalable to very large literature corpora; combines retrieval grounding to reduce hallucination with an evaluator agent to improve rationality and completeness; adaptable to a predefined ontology; achieves high-quality structured outputs (KG) and comparable quality with open-source LLMs.",
            "limitations": "Depends on a predefined ontology crafted by domain experts; relies on retrieval quality and chunking/coreference preprocessing; evaluator is an LLM that does not have direct document context (relies on explorer for context); some evaluation settings used small held-out sets (8 papers) for detailed comparisons; potential remaining hallucination risk if retrieval is weak.",
            "failure_cases": "Short-context zero-shot prompting with full paper text failed for some large open-source models (produced misaligned outputs). RAG retrieval with too-small context (k=1) returned low-similarity chunks causing poor annotations; removing reranking or coreference modules significantly reduced accuracy in ablation studies. One-shot prompting that included entire KG schema produced incomplete annotations compared to POP-guided progressive prompting.",
            "uuid": "e9647.0",
            "source_info": {
                "paper_title": "Automating Intervention Discovery from Scientific Literature: A Progressive Ontology Prompting and Dual-LLM Framework",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "POP",
            "name_full": "Progressive Ontology Prompting (POP)",
            "brief_description": "An ontology-driven prompt construction and scheduling algorithm that performs a prioritized breadth-first traversal of a predefined KG ontology to produce context-aware prompt templates and an ordered sequence of annotation queries for LLMs.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "POP (prompt scheduler)",
            "model_description": "Algorithmic method, not a neural model: uses prioritized BFS on the ontology using an out-to-in ratio R(v) to prioritize nodes with high outgoing degree, constructs k-hop contextual templates T_v, and fills templates with completed annotations to produce progressive prompts for LLM annotation.",
            "model_size": null,
            "input_corpus_description": "Applied to the speech-language intervention ontology and used to schedule annotation queries across papers; context window size k (k-hop neighborhood) was varied in experiments to assess impact on retrieval and accuracy.",
            "input_corpus_size": 64177,
            "topic_query_description": "Generate ordered, context-aware annotation queries for extracting intervention-related entities/relations (e.g., TherapyActivity→TherapyGoal→Disorder) from scientific papers.",
            "distillation_method": "Outdegree-prioritized BFS to collect k-hop neighborhood context, few-shot template generation for prompt templates, progressive application of completed annotations in the context to subsequent prompts to preserve contextual coherence during extraction.",
            "output_type": "Ordered prompt templates and action sequences used to steer LLMs toward more complete, contextually consistent structured annotations.",
            "output_example": "Example visit order: 'TherapyActivity' → 'TherapyGoal' → 'Disorder'. For node v, Prompt_v := T_v(Annotation(N_k(v))) where T_v concatenates Prefix(N_{k-1}(u)) with questions about (v,e,u) triples.",
            "evaluation_method": "Ablation/comparison experiments: one-shot prompt including whole KG schema vs. POP without prioritization vs. POP with prioritized BFS; also context-size (k) sweep experiments for impact on retrieval quality and annotation accuracy.",
            "evaluation_results": "Larger context sizes (k≥2) improved annotation accuracy and retrieval relevance; prioritized BFS ordering improved annotation performance compared to unprioritized POP and one-shot KG prompting (Table 2 reported prioritized POP yielded notable gains).",
            "strengths": "Encodes ontology structure into prompt scheduling to exploit local contextual dependencies; improves retrieval relevance and final annotation accuracy; reduces omissions vs. one-shot KG prompting.",
            "limitations": "Requires a predefined ontology (domain expert effort); choice of k and prioritization heuristics affect performance and must be tuned; POP itself is not a remedy for retrieval failures—benefits depend on the quality of the retrieval/LLM components.",
            "failure_cases": "One-shot annotation including entire KG schema produced incomplete annotations; POP with low context size (k=1) led to retrievals with low similarity and lower annotation quality.",
            "uuid": "e9647.1",
            "source_info": {
                "paper_title": "Automating Intervention Discovery from Scientific Literature: A Progressive Ontology Prompting and Dual-LLM Framework",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "RAG (Llamaindex)",
            "name_full": "Retrieval-Augmented Generation pipeline (implemented with Llamaindex, Chroma, and text-embedding-3-large)",
            "brief_description": "A retrieval-grounding pipeline used by the explorer agent: documents are chunked (256 tokens, 128 overlap) with coreference resolution, embedded using text-embedding-3-large, stored in Chroma, top-8 chunks retrieved and reranked with a cross-encoder before being provided to the LLM for QA.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "RAG pipeline (Llamaindex + Chroma + text-embedding-3-large + cross-encoder rerank)",
            "model_description": "Chunking with coreference resolution (FastCoref) -&gt; embeddings via OpenAI 'text-embedding-3-large' -&gt; vector DB: Chroma -&gt; retrieve top-8 chunks -&gt; rerank with cross-encoder/msmarco-MiniLM-L-2-v2 -&gt; fed to LLM (explorer) to answer annotation queries.",
            "model_size": null,
            "input_corpus_description": "Applied to the speech-language literature corpus (64,177 papers) with document-level metadata filtering so the explorer answers are restricted to the specific target document during annotation cycles.",
            "input_corpus_size": 64177,
            "topic_query_description": "Ground annotation QA in retrieved, high-similarity document fragments to reduce hallucinations and enable document-faithful structured extraction of intervention aspects.",
            "distillation_method": "RAG: retrieval of supporting text chunks, reranking, and conditioning of LLM responses on retrieved evidence. Used with POP-generated prompts and the LLM-Duo explorer agent.",
            "output_type": "Evidence-grounded annotation responses (structured fields) and supporting provenance (document chunk IDs).",
            "output_example": "{\"supported_chunks\": [doc_id:1234, chunk_id:5], \"Procedure\": \"...16 sessions...\", \"Evidence\": \"quoted text from chunk\"}",
            "evaluation_method": "Ablation studies removing reranking or coreference modules, measuring intervention recognition accuracy and downstream annotation quality; comparisons against non-RAG baselines.",
            "evaluation_results": "Removing rerank or coreference reduced accuracy significantly; RAG grounding improved faithfulness and reduced hallucination relative to direct LLM QA without retrieval, but RAG alone was outperformed by LLM-Duo (RAG + evaluator) and some self-refinement methods in particular metrics.",
            "strengths": "Provides document grounding to answers, reduces hallucination, enables retrieval of long-range evidence across long documents, and supports provenance.",
            "limitations": "Quality depends on chunking strategy, embedding model, reranker quality and similarity thresholds; small context prompts (k=1) can produce low-similarity retrievals harming performance; retrieval is an additional failure point.",
            "failure_cases": "Low-similarity retrievals for small k yielded poor annotations; naive RAG without evaluator produced lower comprehensiveness and faithfulness than LLM-Duo-RAG.",
            "uuid": "e9647.2",
            "source_info": {
                "paper_title": "Automating Intervention Discovery from Scientific Literature: A Progressive Ontology Prompting and Dual-LLM Framework",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "GPT-4-turbo-128k",
            "name_full": "GPT-4 Turbo with 128k context window",
            "brief_description": "A long-context commercial LLM used as a baseline and as the evaluator or long-context explorer in some experiments; capable of ingesting long documents but still produced less comprehensive extraction coverage in direct prompting baselines.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-4-turbo (128k context)",
            "model_description": "OpenAI's GPT-4 Turbo with an expanded 128k token context window, used both in 'LongContext' baselines and in an LLM-Duo-LongContext configuration.",
            "model_size": null,
            "input_corpus_description": "Used in evaluation experiments on small evaluation sets (8 randomly selected papers) to compare direct long-context annotation vs. POP+RAG+LLM-Duo approaches.",
            "input_corpus_size": 8,
            "topic_query_description": "Direct zero- or few-shot QA annotation of full-paper text for intervention extraction vs. retrieval-grounded and progressive prompting methods.",
            "distillation_method": "Direct long-context prompting (feed entire document tokens) for zero-shot QA annotation and also integrated into LLM-Duo-LongContext variant where it participates in the dual-agent loop without chunking/RAG.",
            "output_type": "Structured annotation responses (same schema as other methods).",
            "output_example": null,
            "evaluation_method": "Compared quantitatively on the same evaluation metrics (accuracy, coverage, faithfulness, verbosity, etc.) against RAG and LLM-Duo variants on the 8-paper test set.",
            "evaluation_results": "GPT-4-turbo could generate annotations but its annotation coverage was inadequate compared to LLM-Duo-RAG; integrating GPT-4-turbo into LLM-Duo improved accuracy and comprehensiveness vs. GPT-4-turbo alone.",
            "strengths": "Very large context capacity enables processing of long documents directly without chunking; strong reasoning capabilities.",
            "limitations": "Despite long context, direct prompting led to insufficient coverage and omissions; costly to run at scale compared to open-source alternatives integrated in LLM-Duo-RAG.",
            "failure_cases": "LongContext alone missed many intervention aspects that POP+RAG+LLM-Duo captured; LLMs still susceptible to omissions/hallucinations when asked to synthesize across long documents without retrieval and scheduling.",
            "uuid": "e9647.3",
            "source_info": {
                "paper_title": "Automating Intervention Discovery from Scientific Literature: A Progressive Ontology Prompting and Dual-LLM Framework",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "CoT-RAG",
            "name_full": "Chain-of-Thought prompting combined with RAG",
            "brief_description": "A baseline that equips the RAG-based explorer with Chain-of-Thought prompting to elicit multi-step reasoning and self-correction when answering annotation queries.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "CoT-RAG (Chain-of-Thought prompts + RAG)",
            "model_description": "Explorer uses RAG retrieval plus CoT prompting templates (e.g., 'Make a plan to answer the question again') to encourage stepwise reasoning and improved answers.",
            "model_size": null,
            "input_corpus_description": "Applied to the 8-paper evaluation subset to compare against LLM-Duo-RAG and other baselines.",
            "input_corpus_size": 8,
            "topic_query_description": "Improve extraction completeness and rationality via internal chain-of-thought planning and stepwise refinement.",
            "distillation_method": "RAG retrieval + CoT prompting where the model is instructed to plan and then answer, optionally re-planning to increase comprehensiveness.",
            "output_type": "Structured annotations with more elaborate reasoning traces.",
            "output_example": null,
            "evaluation_method": "Quantitative comparison on the annotation metrics reported in the paper (accuracy, faithfulness, coverage, verbosity, etc.).",
            "evaluation_results": "CoT-RAG significantly improved over plain RAG but performed worse than LLM-Duo-RAG. It achieved higher intervention recognition and coverage than basic RAG but lower comprehensiveness vs. the dual-agent approach.",
            "strengths": "Encourages internal reasoning and can improve self-correction without an external evaluator; simple to add to RAG pipelines.",
            "limitations": "Still limited by grounding and lacks adversarial external critique; worse than dual-agent evaluator loop in achieving completeness.",
            "failure_cases": "CoT planning alone could not reach the same level of comprehensiveness and faithfulness as LLM-Duo with a separate evaluator.",
            "uuid": "e9647.4",
            "source_info": {
                "paper_title": "Automating Intervention Discovery from Scientific Literature: A Progressive Ontology Prompting and Dual-LLM Framework",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "Self-Refine-RAG",
            "name_full": "Self-Refine prompting combined with RAG",
            "brief_description": "A baseline in which the retrieval-grounded explorer iteratively reflects on and revises its own answers via a Self-Refine prompt loop (no external evaluator).",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Self-Refine-RAG",
            "model_description": "RAG-backed explorer that uses Self-Refine prompts (reflect, critique, revise) to attempt iterative self-improvement of annotations.",
            "model_size": null,
            "input_corpus_description": "Applied to the 8-paper evaluation subset as a baseline to compare against LLM-Duo-RAG and CoT-RAG.",
            "input_corpus_size": 8,
            "topic_query_description": "Automatic iterative self-correction to improve faithfulness and completeness without a separate evaluator agent.",
            "distillation_method": "RAG retrieval + a sequence of Self-Refine prompts asking the model to reflect and revise its previous answer based on its own critiquing.",
            "output_type": "Structured annotations after self-refinement rounds.",
            "output_example": null,
            "evaluation_method": "Quantitative comparison using the paper's metrics.",
            "evaluation_results": "Self-Refine-RAG improved over raw RAG but performed worse than LLM-Duo-RAG; in some metrics it was comparable to CoT-RAG but lower on overall accuracy/coverage relative to the dual-agent framework.",
            "strengths": "Enables autonomous refinement without extra LLM costs for a second agent; simple prompting strategy.",
            "limitations": "Intrinsic self-correction has limits; lacks the adversarial critique that an independent evaluator provides, which the paper found beneficial.",
            "failure_cases": "Self-refine loops sometimes converged prematurely or failed to discover missing aspects that an external evaluator would identify.",
            "uuid": "e9647.5",
            "source_info": {
                "paper_title": "Automating Intervention Discovery from Scientific Literature: A Progressive Ontology Prompting and Dual-LLM Framework",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "Open-source LLMs (Llama3 & Mistral)",
            "name_full": "Llama3-instruct-70b and Mistral-instruct-8x22b",
            "brief_description": "Large open-source instruction-tuned models used in LLM-Duo-RAG as cost-effective alternatives to GPTs, achieving comparable annotation quality in the experiments.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Llama3-instruct-70b; Mistral-instruct-8x22b",
            "model_description": "Instruction-tuned open-source LLMs: Llama3-instruct (70B parameters) and Mistral-instruct (approx 22B inferential variant) used as explorer and/or annotator LLMs within the RAG and LLM-Duo pipeline.",
            "model_size": "70B; 22B",
            "input_corpus_description": "Used in the annotation baselines and as the LLM in LLM-Duo-RAG for large-scale discovery experiments on the 64k paper corpus and in the 8-paper evaluations.",
            "input_corpus_size": 64177,
            "topic_query_description": "Same intervention extraction queries driven by POP and RAG, to evaluate tradeoffs between cost and annotation quality versus proprietary models.",
            "distillation_method": "RAG-backed retrieval with POP-guided prompts, exchanging messages with evaluator LLM; used within LLM-Duo-RAG.",
            "output_type": "Structured annotations and populated KG entries.",
            "output_example": null,
            "evaluation_method": "Direct quantitative comparison to GPT-based baselines on annotation metrics presented in Table 1.",
            "evaluation_results": "LLM-Duo-RAG using these open-source models achieved comparable annotation quality to GPT-based setups while being more cost-effective; reported to achieve annotation results close to GPT baselines in many metrics.",
            "strengths": "Cost-effective at large scale; when combined with RAG and POP they are competitive with GPTs for the annotation task.",
            "limitations": "Direct zero-shot prompting of full paper text (ShortContext setup) with these models failed to produce valid annotations in experiments; require the RAG + POP scaffolding to succeed.",
            "failure_cases": "ShortContext prompting with Llama3-instruct-70b and Mistral-instruct-8x22b (no RAG) failed to produce aligned annotations in zero-shot QA settings.",
            "uuid": "e9647.6",
            "source_info": {
                "paper_title": "Automating Intervention Discovery from Scientific Literature: A Progressive Ontology Prompting and Dual-LLM Framework",
                "publication_date_yy_mm": "2024-08"
            }
        },
        {
            "name_short": "Supporting pipeline components",
            "name_full": "Llamaindex, text-embedding-3-large, FastCoref, Chroma, cross-encoder reranker, FaithfulnessEvaluator",
            "brief_description": "Set of tooling used to operationalize retrieval grounding, embedding, coreference resolution, vector storage, reranking, and faithfulness evaluation in the pipeline.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Llamaindex + OpenAI text-embedding-3-large + FastCoref + Chroma + cross-encoder/msmarco-MiniLM-L-2-v2 + Llamaindex FaithfulnessEvaluator",
            "model_description": "Pipeline: FastCoref for coreference before chunking; embedding via OpenAI 'text-embedding-3-large'; vector DB: Chroma; retrieval: top-8 chunks then reranked by cross-encoder/msmarco-MiniLM-L-2-v2; faithfulness measured by Llamaindex FaithfulnessEvaluator.",
            "model_size": null,
            "input_corpus_description": "Used across the 64k paper corpus and evaluation subsets to preprocess, embed, store, retrieve, and evaluate evidence used by the explorer and for automated faithfulness scoring.",
            "input_corpus_size": 64177,
            "topic_query_description": "Support retrieval and evidence-grounding for the intervention extraction tasks.",
            "distillation_method": "Preprocessing -&gt; embedding -&gt; vector store -&gt; similarity retrieval -&gt; cross-encoder reranking -&gt; feed to LLM; faithfulness scoring on outputs using an automated evaluator.",
            "output_type": "Retrieved evidence chunks, reranked passages, metadata filtered results, and automatic faithfulness scores.",
            "output_example": null,
            "evaluation_method": "Ablation of reranker and coreference modules measuring drop in intervention recognition accuracy.",
            "evaluation_results": "Ablation showed major accuracy drops when reranking or coreference preprocessing were removed, indicating these components are necessary for high-quality retrieval and downstream extraction.",
            "strengths": "Improves retrieval relevance, evidence fidelity, and automated faithfulness scoring; enables document-level grounding.",
            "limitations": "Adds engineering complexity; performance sensitive to hyperparameters (chunk size, overlap, rerank thresholds); reliance on external embedding service for text-embedding-3-large.",
            "failure_cases": "Loss of rerank or coreference produced marked degradation in results; low-similarity retrievals when using too small POP context sizes.",
            "uuid": "e9647.7",
            "source_info": {
                "paper_title": "Automating Intervention Discovery from Scientific Literature: A Progressive Ontology Prompting and Dual-LLM Framework",
                "publication_date_yy_mm": "2024-08"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Chain-of-thought prompting elicits reasoning in large language models",
            "rating": 2,
            "sanitized_title": "chainofthought_prompting_elicits_reasoning_in_large_language_models"
        },
        {
            "paper_title": "Self-Refine: iterative self-refinement for LLMs",
            "rating": 2,
            "sanitized_title": "selfrefine_iterative_selfrefinement_for_llms"
        },
        {
            "paper_title": "Autogen: Enabling next-gen LLM applications via multi-agent conversation framework",
            "rating": 2,
            "sanitized_title": "autogen_enabling_nextgen_llm_applications_via_multiagent_conversation_framework"
        },
        {
            "paper_title": "Meganno+: A human-LLM collaborative annotation system",
            "rating": 2,
            "sanitized_title": "meganno_a_humanllm_collaborative_annotation_system"
        },
        {
            "paper_title": "Can LLMs produce faithful explanations for fact-checking? towards faithful explainable fact-checking via multi-agent debate",
            "rating": 1,
            "sanitized_title": "can_llms_produce_faithful_explanations_for_factchecking_towards_faithful_explainable_factchecking_via_multiagent_debate"
        },
        {
            "paper_title": "Consistency guided knowledge retrieval and denoising in LLMs for zero-shot document-level relation triplet extraction",
            "rating": 2,
            "sanitized_title": "consistency_guided_knowledge_retrieval_and_denoising_in_llms_for_zeroshot_documentlevel_relation_triplet_extraction"
        },
        {
            "paper_title": "Large language models have intrinsic self-correction ability",
            "rating": 1,
            "sanitized_title": "large_language_models_have_intrinsic_selfcorrection_ability"
        }
    ],
    "cost": 0.01830875,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Automating Intervention Discovery from Scientific Literature: A Progressive Ontology Prompting and Dual-LLM Framework *</p>
<p>Yuting Hu 
University at Buffalo</p>
<p>Dancheng Liu 
University at Buffalo</p>
<p>Qingyun Wang qingyun4@illinois.edu 
University of Illinois at Urbana-Champaign</p>
<p>Charles Yu 
Chenhui Xu 
University at Buffalo</p>
<p>University of Illinois at Urbana-Champaign</p>
<p>Qingxiao Zheng qingxiao@buffalo.edu 
University at Buffalo</p>
<p>Heng Ji hengji@illinois.edu 
University of Illinois at Urbana-Champaign</p>
<p>Jinjun Xiong jinjun@buffalo.edu 
University at Buffalo</p>
<p>Automating Intervention Discovery from Scientific Literature: A Progressive Ontology Prompting and Dual-LLM Framework *
04439A9FE11623D3E0DE91FDD04D7BA6
Identifying effective interventions from the scientific literature is challenging due to the high volume of publications, specialized terminology, and inconsistent reporting formats, making manual curation laborious and prone to oversight.To address this challenge, this paper proposes a novel framework leveraging large language models (LLMs), which integrates a progressive ontology prompting (POP) algorithm with a dual-agent system, named LLM-Duo.On the one hand, the POP algorithm conducts a prioritized breadth-first search (BFS) across a predefined ontology, generating structured prompt templates and action sequences to guide the automatic annotation process.On the other hand, the LLM-Duo system features two specialized LLM agents, an explorer and an evaluator, working collaboratively and adversarially to continuously refine annotation quality.We showcase the real-world applicability of our framework through a case study focused on speech-language intervention discovery.Experimental results show that our approach surpasses advanced baselines, achieving more accurate and comprehensive annotations through a fully automated process.Our approach successfully identified 2,421 interventions from a corpus of 64,177 research articles in the speech-language pathology domain, culminating in the creation of a publicly accessible intervention knowledge base 1 with great potential to benefit the speech-language pathology community.</p>
<p>Introduction</p>
<p>Evidence-based interventions refer to practices and treatments grounded in systematic research and proven effective through controlled studies [Rutten et al., 2021] [Melnyk and Fineout-Overholt, 2022].It emphasizes the use of evidence from well-designed and well-conducted research as the foundation for healthcare decision-making [Sackett, 1997].</p>
<p>Intervention discovery from scientific literature enables researchers to keep abreast of the latest advancements and facilitate valuable insights that can significantly enhance the healthcare quality [Usai et al., 2018][Wang et al., 2023a].However, due to the labor-intensive nature of human review, only a small fraction of intervention knowledge is systematically collected and curated.In healthcare, one of the biggest challenges for healthcare providers is the efficient identification of relevant intervention evidence from an overwhelming body of research, highlighting the urgent need for automated knowledge extraction tools to streamline the process and enhance the accessibility of this valuable information.</p>
<p>In recent years, large language models (LLMs) have been employed to categorize research papers, extract key findings, summarize complex studies, and create conversational assistants for question-answering and note generation, showing their impressive ability in understanding and extracting valuable insights from text [Achiam et al., 2023][Li et al., 2024a].Many studies have utilized LLMs to streamline various subtasks involved in knowledge graph construction, such as named entity recognition (NER), relation extraction (RE), event extraction (EE), and entity linking (EL) [Wang et al., 2023b][Zhu et al., 2024].Some research has also explored the collaboration between LLMs and human annotators to improve annotation quality [Kim et al., 2024a][Wang et al., 2024][Tang et al., 2024].However, extracting intervention knowledge from long-range, domain-specific literature remains a significant challenge.On the one hand, developing human-annotated datasets for training deep learning models in NER and RE tasks requires specialized domain expertise to accurately interpret the literature.On the other hand, mining knowledge from long-range documents is a great challenge due to the vast volume of content, the inherent ambiguity of natural language, and the individual bias of human interpretation [Ye et al., 2022].Particularly in healthcare contexts, these challenges are further compounded by the need for specialized therapeutic expertise, labor-intensive manual annotation, and difficulties in maintaining consistency and scalability [Zhao et al., 2021].In this context, LLMs offer a promising alternative through in-context learning, enabling scalable information extraction without the need for extensive humanlabeled data.Despite these advancements, fully automated knowledge graph construction remains a challenge, particularly when dealing with long-range documents.Most cur-arXiv:2409.00054v2[cs.CL] 20 May 2025 rent knowledge graph construction approaches focus on short texts, leaving significant potential for further development in handling more complex, lengthy content.</p>
<p>In this paper, we address the challenge of automating intervention discovery via LLMs by formulating it as a prompt design and annotation scheduling problem with a predefined intervention ontology graph structure and designing a framework leveraging two LLM agents to iteratively enhance the annotation quality.Specifically, we introduce a progressive ontology prompting (POP) algorithm that employs an outdegree-prioritized breadth-first search (BFS) across the intervention ontology to create a series of prompt templates and action sequences to guide the annotation process conducted by LLMs.To enhance the annotation quality, we propose LLM-Duo, an interactive annotation framework by leveraging the power of LLMs while addressing the limitations of LLMs.Particularly, it integrates two LLM agents working both collaboratively and adversarially to refine annotation generation.</p>
<p>To showcase the practical impact of our approach, we apply our method in a case study of speech-language intervention discovery.We conduct experiments to compare our intervention discovery framework with several advanced baselines including long context LLM (i.e., GPT-4-Turbo with 128k context window length), and RAG-based annotation chatbot with advanced prompting techniques including Chain-of-Thought (CoT) [Wei et al., 2022] and Self-Refine [Madaan et al., 2024].The experimental results demonstrate that our method not only delivers more accurate and comprehensive annotations over these strong baselines but also significantly accelerates the intervention discovery process.Furthermore, through our framework, we successfully curate a speechlanguage intervention knowledge base, providing a valuable resource for the speech-language pathology community.To our knowledge, this is the first intervention knowledge base in the speech-language pathology field.Related Work.Traditional approaches to automated knowledge discovery typically rely on pipelines to handle various NLP tasks such as named entity recognition, relation extraction, coreference resolution, entity linking, and event detection [Luan et al., 2018][Martins et al., 2019][Wei et al., 2019][Zhong et al., 2023][Laurenzi et al., 2024].Recent advancements leverage LLMs to generate relational triplets in zero/few-shot settings for knowledge graph construction, achieving promising results [Wei et al., 2023][Sun et al., 2024][He et al., 2024].Some studies [Zhang and Soh, 2024][Carta et al., 2023][Vamsi et al., 2024][Zhu et al., 2024] have further streamlined knowledge graph construction by breaking it down into distinct phases, enabling LLMs to infer knowledge graph schemas without relying on predefined ontologies.However, these methods are often constrained to short texts or have only been validated on tasks like entity and relation extraction using human-annotated datasets, such as DuIE2.0 [Li et al., 2019] and DocRED [Yao et al., 2019], without being proven effective in real-world applications.Moreover, domain-specific knowledge often exhibits complex patterns that cannot be captured solely through sentence-level syntactic structures.As a result, most existing approaches [Du et al., 2020][Rossanez et al., 2020][Alam et al., 2023] are limited to handling abstracts and fail to extract and summarize knowledge across long-range contexts.</p>
<p>Preliminaries</p>
<p>A knowledge graph (KG) is a semantic network structured as an ontology, consisting of concepts and their relationships in a clear, interpretable format at scale [Peng et al., 2023].For intervention knowledge discovery from literature, LLMs can enhance this process by leveraging their capabilities to understand long-range text.This allows for transforming unstructured data into structured formats, and finally, populating the intervention ontology to create the intervention knowledge graph.</p>
<p>In our methodology, the intervention KG ontology is crafted by domain experts, which can be represented by a directed acyclic graph (DAG) G = (E, R, F).Here E, R, and F are sets of concepts, relationships, and semantic triples respectively.F is a collection of triples (h, r, t) with a head concept h ∈ E, a tail concept t ∈ E, and a relation r ∈ R [Gruninger, 1995].To effectively instruct LLMs to extract intervention knowledge anchored to G automatically, the design of annotation prompts and the query sequences plays a crucial role.We thereby frame the problem of automated intervention knowledge discovery via LLMs as one of prompt design and scheduling, described by the following equation:
f (G(E, R, F)) = {(P rompti, Orderi)|i ∈ [1, N ]} (1)
where f is a function that translates intervention KG ontology into a set of annotation prompts and query sequences for the LLMs.A common case of f is directly prompting LLMs to generate triplets in a zero-shot/few-shot manner by including the whole KG schema within the prompt such as the annotation methods used in [Mihindukulasooriya et al., 2023][Kommineni et al., 2024].However, those methods generate annotations in one shot and ignore the importance of contextual correlations between concepts within their surrounding neighborhood, resulting in incomplete annotations.</p>
<p>Methodology</p>
<p>In this section, we first introduce the POP algorithm that converts an intervention KG ontology into a set of annotation prompt templates and query orders, then propose an interactive annotation framework based on two LLM agents to enable more convincing and accurate annotation generations.</p>
<p>Progressive Ontology Prompting</p>
<p>We develop a progressive ontology prompting (POP) algorithm that employs a prioritized BFS on the intervention ontology graph G(E, R, F) to generate a set of annotation prompt templates and query sequences for LLMs.In our algorithm, the prompt formulation and scheduling follow a progressive manner.As illustrated in Figure 1, the annotation process begins at a source node (i.e., a concept node that only has outgoing edges) and continues by traversing its neighboring nodes in the order of a prioritized BFS.To allow for quick accessing a large portion of the graph, we enhance BFS by sorting neighboring nodes based on their out-to-in ratio R(v), which is defined by:
R(v) = | {(h, r, t) ∈ F} |h = v| | {(h, r, t) ∈ F} |t = v| (2)
Our algorithm selects the neighboring node with the maximum R value to visit in the next step.For instance, in the example of Figure 1, visiting the 'Patient' node before the 'Disorder' node can provide more context for the 'Disorder' concept annotation.For each concept node v, we use the visited nodes within its k hop neighborhood as its context.The P rompt v for annotating concept v is crafted based on its context and the completed annotations within that context.The action order Order v for P rompt v is determined by the sequence in which node v is visited during the prioritized BFS traversal.</p>
<p>Our algorithm first follows prioritized BFS traversal to capture the local k hop context and visit order of a specific concept node v, then composes the annotation prompts P rompt v based on its ontology substructure N k (v) and completed annotations within its context.This process can be expressed as follows:
P romptv ← Tv(Annotation(N k (v)))
(3)
Tv ← {P ref ix (N k−1 (u)) ⊕ Question ((v, e, u) | (v, e, u) ∈ F ) | u ∈ N1(v)}(4)
, where ⊕ is the concatenation.P rompt v represents a set of annotation prompts for node v, generated by applying completed annotations to the prompt template T v .As illustrated in Figure 1, the prompt template T v consists of two parts: 1) Question, an annotation question derived from the relationship between node v and one of its neighboring nodes u; and 2) Prefix, a description based on the k − 1 hop path of neighbor node u.We leverage few-shot learning to task LLMs in generating prompt templates.</p>
<p>LLM-Duo Annotation Framework</p>
<p>To guarantee the integrity and reliability of LLM annotations, we propose LLM-Duo, a dual-agent annotation system.The central idea of a multi-agent system is to employ combinations of LLMs that can converse with each other to collaboratively accomplish tasks [Wu et al., 2023].Drawing inspiration from the multi-agent debate idea in [Kim et al., 2024b], we developed a framework where agents work both collaboratively and adversarially to enhance the quality of annotations.</p>
<p>The architecture of LLM-Duo is shown in Figure 2, featuring two LLM agents: the explorer and the evaluator.Specifically, the explorer is a chatbot performing annotation tasks using zero-shot question answering (QA).To break the context window limit of LLMs and ensure the generated annotations are faithful to the provided literature content, RAG is employed in explorer to reference relevant sources, minimizing LLM hallucinations.To further improve the accuracy and reliability of the annotations, the evaluator LLM is incorporated to review and validate the explorer's responses, ensuring higher-quality results.</p>
<p>LLM-Duo will be tasked with annotation prompts follow- Question2: Your answer might be problematic.{#Reason1}.Correct your answer and give strong evidences.</p>
<p>Answer1: Disagree Reason1: The 'Reason' does not confirm that any particular methods are proposed or detailed, only that their effects are being tested.ing the sequential order generated by the POP algorithm.</p>
<p>During each annotation cycle for a specific concept node, when focusing on concepts that emphasize rationality (e.g., disorder, intervention efficacy), the explorer provides an answer and an explanatory rationale to the evaluator.The evaluator then reviews the reasoning and offers feedback.Based on this feedback, the explorer either refines its answer or, if in disagreement, presents stronger evidence to defend its original answer and challenge the evaluator's judgment.For concepts that emphasize completeness (e.g., intervention procedure, therapy activity), the evaluator extracts the aspects covered in each round of the explorer's answer, combines them with aspects from previous rounds, and prompts the explorer to expand further beyond the newly integrated aspect collection.This iterative process continues until the annotations reach a consistent and comprehensive state.As the example shown in Figure 3, by facilitating interactive loops between two LLM agents, LLM-Duo enables more accurate and complete annotations.</p>
<p>Experiments 4.1 Implementation</p>
<p>For LLM-Duo, the explorer is a chatbot built on LLM with RAG, implemented with Llamaindex2 framework.We use OpenAI 'text-embedding-3-large'3 as the embedding model and set the chunk size to 256 tokens with an overlapping size of 128.Particularly, we use 'FastCoref ' [Otmazgin et al., 2022] to process text chunks for coreference resolution before text embedding.Additionally, we include the document ID as metadata for chunks and apply a metadata filter in the chat engine to ensure that the explorer only answers based on the specific document being annotated.We use Chroma 4 as the vector database.We set the retrieval to be on the top 8 text chunks based on similarity scores reranked with Sen-tenceTransformerRerank 5 employing the 'cross-encoder/msmarco-MiniLM-L-2-v2' 6 model in Llamaindex.The evaluator is an external LLM who does not share any document context with the explorer.To verify the effectiveness of our method in a realistic scenario, we employ our framework in a speech-language intervention discovery setting.The ontology is shown in Figure 4. To enable a large-scale discovery, we cultivate a literature base including 64,177 papers within the domain of speechlanguage therapy.</p>
<p>Annotation Baselines</p>
<p>The core idea of our automated intervention framework is to leverage the POP algorithm for guiding the annotation process while utilizing LLM-Duo to refine initial annotations by incorporating external feedback from another LLM.Instead of setting up another LLM for evaluation, recent studies demonstrate that LLMs can engage in self-correction to enhance their responses autonomously [Liu et al., 2024][Li et al., 2024b].Notable examples of this include Chain-of-Thought (CoT) [Wei et al., 2022] and Self-Refine [Madaan et al., 2024].We separately equip the explorer chatbot based on RAG with these two prompting methods for annotation and denote them as CoT-RAG and Self-Refine-RAG.Additionally, in LLM-Duo, a potential substitution of explorer is long-context LLM, which is capable of processing entire document tokens instead of chunking and retrieval with RAG.We refer to the LLM-Duo system as LLM-Duo-RAG when using explorer built on RAG, and as LLM-Duo-LongContext when utilizing long-context LLMs.Besides, we also compare with methods that directly input paper text to LLMs for zero-shot QA annotation without the evaluation feedback loop, including ShortContext LLM, LongContext LLM, OpenAI Assistant, and RAG.</p>
<p>Evaluation</p>
<p>In the experiment of comparing LLM-Duo with annotation baselines, we report six types of metrics: 1) Consistency Rounds (CR): the number of refine loops the method makes before the annotation generation achieving consistency; 2) Verbosity Index (VI): the number of covered aspects per 1k tokens in the annotations, which is an important metric for emphasizing content completeness; 3) Enumeration Quantity (EQ): the number of items listed in the annotations (i.e., therapy activities, therapy goals.);4) Faithfulness (Faith): the extent of the annotation faithful to the provided literature literature, which is measured by FaithfulnessEvaluator7 of Llamaindex.5) Accuracy (ACC): the percentage of correct annotations in all LLM-generated annotations.6) Cover: the percentage of correct LLM-generated annotations to the total mentioned concept entities in the provided literature.</p>
<p>Results</p>
<p>In this section, we first provide a detailed evaluation of our progressive ontology prompting algorithm and the LLM-Duo annotation framework.Then, we showcase the results of speech-language intervention discoveries using our automated intervention discovery framework.</p>
<p>POP Algorithm Study</p>
<p>Context Size Analysis.In the POP algorithm, the context size k determines the diversity and volume of information included in the intervention annotation prompt.To assess the impact of context size on annotation quality, we conducted experiments using various k values to generate intervention annotation prompts for LLM-Duo-RAG.As shown in Figure 5a, we annotate the 'participant' concept for the experiment, which was based on a random selection of 8 speechlanguage pathology literature.</p>
<p>The annotation accuracy is shown in Figure 5b.The results indicate that as the context size k increases, annotation accuracy improves significantly, suggesting that a larger context provides more informative prompts, thereby enhancing annotation quality.Moreover, GPT-4-turbo consistently outperforms GPT-3.5-turboacross all k values, demonstrating that more advanced language models can further improve annotation accuracy.Besides, we inspect the text chunks retrieved back by different informative annotation queries based on various k values.We report the range of similarity scores and token count distribution of retrieved-back chunks in Fig- ure 5c.The similarity score represents the semantically relevancy between retrieved texts to annotation queries.The results show that for k = 1, the retrieved text chunks generally have low similarity to the query, and the token count decreases as the similarity score increases, leading to lower annotation quality.In contrast, higher k values, especially k = 2, yield more relevant retrievals.For k = 2, the token count increases with higher similarity scores, indicating that richer and more relevant content is captured, resulting in improved annotation quality.Prioritized BFS Analysis.In the POP algorithm, we employ the out-to-in ratio to prioritize neighboring nodes during BFS-based prompt creation and scheduling.This strategy ensures that nodes with more outgoing edges are visited first, allowing them to provide more context for annotating other nodes.For example, one annotation sequence following prioritized POP over the speech-language intervention ontology is 'TherapyActivity'→'TherapyGoal'→'Disorder'.In this section, we compare the 'Disorder' annotation results using the POP algorithm with and without prioritization, as   well as one-shot annotation without using POP, where the entire KG schema is included on a single annotation prompt to extract all triplets.The results are presented in Table 2.We can observe that applying both the POP and prioritized BFS notably enhances annotation performance.</p>
<p>LLM-Duo</p>
<p>LLM-Duo with Baselines</p>
<p>In this section, we compare LLM-Duo with several advanced baselines using annotations of 8 randomly selected papers from our speech-language literature corpus.The evaluation focuses on three key dimensions: 1) Intervention Recognition (IR), identifying intervention entities within the literature; 2) Intervention Aspect Summary (IAS), annotating the key aspects (e.g., procedure, therapy activity, therapy goals) of the intervention by capturing and summarizing relevant information from the paper; and 3) Intervention Knowledge Completion (IKC), linking interventions to theme classes (e.g., speech awareness, speech articulation, comprehension, foundation skills, etc.) and setting concept nodes (e.g., home, healthcare facilities, schools, teletherapy, etc.).We use human annotators for the IR and IKC tasks to generate goldstandard results for comparison.In the IAS task, we only ask human annotators to tag relevant text fragments related to specific intervention aspects due to potential individual bias in human interpretation.</p>
<p>The experimental results are reported in Table 1.It should be noted that we implemented 'ShortContext' using Llama3-instruct-70b (FP16) and Mistral-instruct-8x22b models (INT8).However, directly prompting these models with full paper text fails to produce annotations in a zero-shot QA setting.Their generations do not align with the annotation questions.The results in Table 1 show that LLM-Duo-RAG outperforms all baselines.Although GPT4-turbo has a 128k context window length and is capable of generating annotations, its annotation coverage remains inadequate.Integrating it with the LLM-Duo framework can significantly improve both the accuracy and the comprehensiveness of the intervention annotations.Additionally, compared with simple RAG, self-correct prompting methods such as CoT and Self-Refine can significantly enhance intervention annotations, but their performance is still worse than LLM-Duo-RAG.Instead of utilizing costly GPT models, LLM-Duo-RAG, which employs open-source models including Llama3-instruct-70b and    Mistral-instruct-8x22b, can achieve comparable annotation quality.</p>
<p>Ablation Study</p>
<p>In our implementation, the RAG technique serves as the backbone of explorer.We employ 'FastCoref' for coreference resolution and rerank retrieved chunks by similarity score using the 'cross-encoder/ms-marco-MiniLM-L-2-v2 model'.This section presents ablation studies for both components.We report the accuracy of intervention recognition in this section.</p>
<p>As shown in Figure 6a, the results demonstrate that removing these components significantly decreases annotation accuracy, showing the necessity of each module.</p>
<p>Speech-Language Intervention Discovery</p>
<p>Through our automated intervention discovery framework, we identified 2,421 interventions supported by case studies from 64,177 literature in the speech-language pathology domain.The statistics of discovered interventions are presented in Figure 6b and Figure 6c.More intervention examples are provided in Table 3. 19 clinicians and students reviewed our annotations through online Google forms.We have constructed the first intervention knowledge graph in the speech-language pathology domain, which will be made publicly accessible upon acceptance.This knowledge graph is anticipated to be a valuable resource for domain experts, facilitating evidence-based clinical decision-making, questionanswering, and recommendation systems, ultimately contributing to improved healthcare outcomes.</p>
<p>Conclusion</p>
<p>In this paper, we developed a novel LLM-based framework for automatic intervention discovery from literature, featuring a progressive ontology prompting algorithm and a dual-agent system.The proposed method achieves superior performance compared with advanced baselines, enabling more accurate intervention discoveries.Our approach is adaptable to various intervention ontologies in healthcare and offers practical value to improve healthcare quality.</p>
<p>B.2 Annotation Ontology</p>
<p>Speech-language pathology provides interventions for individuals with speech-language deficits, improving their quality of life at various stages.When choosing an intervention, evidence-based practice (EBP) is attractive as it integrates research evidence from literature into the decision-making process to ensure high-quality patient care [Law et al., 1996].</p>
<p>Research on interventions, especially those presenting clear frameworks and comprehensive case studies, serves as valuable guidance for designing EBPs.In this paper, we apply our automated framework to speech-language intervention discovery, with the intervention ontology shown in Figure 4.A detailed explanation of the concepts within the ontology is provided below:</p>
<p>• Intervention represents a targeted treatment practice designed to enhance an individual's communication skills.</p>
<p>• Disorder represents the type of disorder that causes difficulties in an individual's voice, speech, language, or swallowing functions.</p>
<p>• Setting represents a specific environment where interventions are implemented.We identify six key settings: home, healthcare facilities (such as hospitals or rehabilitation centers), early childhood centers (like nurseries or daycare), schools, clinics and private practices, and teletherapy.</p>
<p>• Theme represents the theme of the intervention.As shown in Table 4, we categorize interventions into 10 themes based on their characteristics and therapy goals.</p>
<p>• Therapy Activity represents a task designed to address a particular speech or language challenge in an individual, such as using a minimal pairs activity to enhance phonological awareness.</p>
<p>• Therapy Goal represents a specific area that the intervention is designed to enhance.</p>
<p>• Procedure represents a comprehensive description of how the intervention is carried out.</p>
<p>• Efficacy represents the conclusion about the effectiveness of the intervention.</p>
<p>• Frequency/Dosage/Duration represents the frequency/dosage/ duration of the intervention practiced in the case study that demonstrates its efficacy.</p>
<p>D Annotation Example</p>
<p>Below is an example of an intervention annotation from the paper "Intensive Treatment of Dysarthria Secondary to Stroke" [Mahler and Ramig, 2012].</p>
<p>"Intervention": "Lee Silverman Voice Treatment (LSVT LOUD)", "Disorder": [ "stroke", "ataxia", "multiple sclerosis", "traumatic brain injury (TBI)" ], "Procedure": "The therapy process of conducting the Lee Silverman Voice Treatment (LSVT LOUD) intervention involves intensive high-effort exercises aimed at increasing vocal loudness to a level within normal limits using healthy and efficient voice techniques.The treatment protocol includes sessions four times a week for 4 weeks, totaling 16 individual one-hour sessions.Each session consists of tasks such as maximal sustained vowel phonation, pitch range exercises, and reading functional phrases at individual target loudness levels.The second half of each session progresses to functional speech tasks, moving from words and phrases to conversation over the course of the 16 sessions.Additionally, participants are assigned daily homework to practice using normal loudness and facilitate generalization of normal loudness outside the treatment room.","Frequency": "four times a week", "Dosage": "one-hour session.","Duration": "4 weeks, totaling 16 individual one-hour sessions.","Efficacy": "The outcome of the Lee Silverman Voice Treatment (LSVT LOUD) intervention in this study showed positive changes in acoustic variables of speech for all participants with dysarthria secondary to stroke.There were statistically significant increases in vocal dB SPL for sustained vowel phonation and speech tasks, indicating improvements in loudness levels and phonatory stability.Additionally, posttreatment speech samples were rated as having better voice quality and sounding more natural, suggesting an amelioration of dysarthria characteristics.Participants also reported increased confidence in their speech during post-treatment interviews.","Therapy Goal": [ "Increase vocal loudness to a level within normal limits", "Use healthy and efficient voice techniques", "Progress from words and phrases to conversation over 16 sessions", "Facilitate generalization of normal loudness outside the treatment room" ], "Participant": "Four participants (P01 to P04).", "Age": "Participants in the study ranged in age from 50 to 74 years.","Language": "assume to be English.","Case Study": "Case studies and experiments regarding the Lee Silverman Voice Treatment (LSVT LOUD) intervention in the paper include studies on people diagnosed with stroke, ataxia, multiple sclerosis, and traumatic brain injury (TBI).These studies have shown improvement in articulatory features as well as loudness.","Therapy Activity": [ "Maximal sustained vowel phonation", "Pitch range exercises", "Reading 10 functional phrases at individual target loudness levels", "Functional speech tasks progressing from words and phrases to conversation" ], "Setting": "home", "Theme": "speech articulation"</p>
<p>E Speech-Language Intervention Knowledge Base</p>
<p>Through our intervention discovery framework, we constructed the first intervention knowledge graph in the speechlanguage pathology domain.Our intervention KG contains 33,148 nodes with 324,707 relations.We present some views of our intervention KG in Figure 7 and Figure 8.</p>
<p>Figure 1: Illustration of prompt design and scheduling based on the progressive ontology prompting algorithm.</p>
<p>Figure 2 :
2
Figure 2: Iterative annotation with two LLM agents under the LLM-Duo framework.</p>
<p>Question1:</p>
<p>What aspects this text is describing?{#Answer1}Question1: One intervention studied in this paper is Auditory-Motor Mapping Training (AMMT).Can you describe this intervention in detail?Answer1: SRT is a control treatment designed to improve speech production accuracy in minimally verbal children with autism spectrum disorder... Aspects1: Objective, Target Population, Approach, Control Group, Outcome Measures, Results, Limitations.Question2: Re-answer my question and cover more aspects except from: {#Aspects1}.Answer2: SRT is a control treatment designed to improve speech production accuracy in minimally verbal children with autism spectrum disorder... 【 SRT involves a series of structured steps to facilitate speech repetition and accuracy.These steps may include...】 Question2: What aspects this text is describing?{#Answer2}.Integrate your answer with {#Aspects1}.Aspects2: Objective, Target Population, Approach, Control Group, Outcome Measures, Results, Limitati-ons, 【 Therapeutic Steps, Therapeutic Techniques, Feedback Mechanisms, Duration and Frequency, Multisensory Approach, Individualized Treatment, Maintenance and Generalization, Collaboration with Caregivers.】Question1: Analyze the following text: 'Answer':{#Answer1}; 'Reason': {#Reason1}; Do you agree with the answer based on the provided reason?Give your argument.Question1: Does this paper present any therapy/ intervention/treatment for individuals having speech or language deficits?Answer1: Yes Reason1: The paper discusses the tests of intonation-based speech treatment for minimally verbal children with autism.</p>
<p>Figure 3 :
3
Figure 3: Annotation examples of speech-language intervention discovery using the LLM-Duo framework.</p>
<p>Figure 4 :
4
Figure 4: Ontology of speech-language intervention.4https://github.com/chroma-core/chroma5https://docs.llamaindex.ai/en/stable/examples/nodepostprocessor/ SentenceTransformerRerank 6 https://huggingface.co/cross-encoder/ms-marco-MiniLM-L-2-v2</p>
<p>(a) Illustration of 'participant' annotation under different k values.(b) Range of 'participant' annotation accuracy using LLM-Duo-RAG with GPTs at k=1,2,3.(c)Token count distribution of retrieved-back chunks across varying similarity scores using 'participant' annotation queries of k=1,2,3.</p>
<p>Figure 5 :
5
Figure 5: Evaluation of 'participant' annotation with POP of different context sizes.</p>
<p>(a) Ablation studies of removing rerank (wo rerank) and corefenence (wo coref) modules in LLM-Duo-RAG.(b) Number of discovered interventions for top 20 disorders.(c) Number of discovered interventions for different age groups.</p>
<p>Figure 6 :
6
Figure 6: Ablation study and annotated speech-language intervention statistics.Disorder Interventions Intervention Examples Aphasia 202 Phonological therapy, Semantic therapy, Syntax Stimulation Program, Melodic Intonation Therapy (MIT), Multimodal Speech Therapy with tDCS, Cross-Language Generalization Therapy (CLGT), Word Learning Paradigm Autism Spectrum Disorder 178 Personalized Idiom Intervention (PII), Classroom-wide peer tutoring, Idiom Isolation Intervention, Hanen More Than Words, Parent-Mediated Communication-Focused Treatment, Picture Exchange Communication System (PECS) Dysphagia 129 Swallowing Maneuver Therapy, Focal Vibration Therapy (FVT), Oral Neuromuscular Training and Vibrational Therapy, Prophylactic Swallowing Intervention, High-speed jaw-opening exercise, Palatal Augmentation Prostheses (PAP)</p>
<p>Figure 7 :
7
Figure 7: Partial views of Intervention-Disorder in the intervention KG.</p>
<p>Figure 8 :
8
Figure 8: Partial views of Intervention-TherapyActivity in intervention KG.</p>
<p>4.2 Case Study: Speech-language Intervention DiscoverySpeech-language therapy provides interventions for individuals with speech-language deficits, enhancing their quality of life across various life stages.When choosing an intervention, evidence-based practice (EBP) is attractive as it integrates research evidence from literature into the decisionmaking process to ensure high-quality patient care [Law et al., 1996].Intervention research, especially studies that offer clear intervention frameworks and comprehensive case studies, are valuable references to guide EBP designs.Intervention discovery aims to extensively gather speech-language interventions from the literature corpus as references to facilitate EBP design.It involves identifying relevant studies and extracting essential features of interventions including target disorder, procedure, efficacy, case study, therapy activity, etc., which is extremely labor-intensive for human reviewers, highlighting the efficiency of automating knowledge discovery based on LLMs.</p>
<p>Table 1 :
1
Comparison of annotation results with baselines using different LLMs.
MethodsLLMIRICAIKCCRACCCoverCRVIEQFaithCRACCShortContextGPT3.5-turbo-36.9%50%-0.0249 5.46 0.9667-48.2%OpenAI AssistantGPT4-turbo-76.1% 69.0%-0.0631 4.17 0.7857-53.3%LongContextGPT4-turbo-76.3% 57.1%-0.0919 8.641.0-61.2%LLM-Duo-LongContext GPT4-turbo2.17 81.0% 68.7%2.5 0.0926 8.68 0.8571 1.31 69.6%RAGGPT3.5-turbo-47.6%50%-0.0319 7.96 0.8550-48.7%CoT-RAGGPT3.5-turbo1.04 78.6%81%3.18 0.0771 10.37 0.7250 1.07 73.2%Self-Refine-RAGGPT3.5-turbo1.19 78.5% 54.4% 2.85 0.0694 7.17 0.8125 1.12 54.8%GPT3.5-turbo1.84 100% 86.4% 2.58 0.1159 13.71 0.9285 1.46 85.6%LLM-Duo-RAGLlama3-instruct-70b2.71 78.6% 55.6% 2.59 0.0748 9.79 0.8648 1.52 61.0%Mistral-instruct-8x22b 2.30 81.9% 67.5% 2.16 0.0763 9.87 0.8875 1.46 67.2%</p>
<p>Table 2 :
2
Comparison of annotation results with and without the POP and prioritized BFS.
-RAGGPT3.5-turbo GPT4-turboPOP✗68.1872.73POP✓ Prioritized-BFS✗77.2883.20POP✓ Prioritized-BFS✓81.8286.37</p>
<p>Stuttering 91 Lidcombe Program, Syllable-timed speech, Electronic devices for stuttering, Computer software for stuttering, Bone Conduction Delayed Feedback Therapy, Fluency Techniques and Fear Reduction, Cognitive Behavioral Therapy (CBT)
Phonological Disorder74Nonlinear Phonological Intervention Program, Metronome-paced Speech Therapy, Phonological Awareness and Articulatory Training (PAAT),Phonological Meaning Therapy, Motor-based Intervention ApproachAgeGroupInterventions Intervention ExamplesChildren745Pharyngeal flap procedure, National Health Service (NHS) 1-week intensive course, Ultrasound Visual Biofeedback (U-VBF), Intensive SpeechTherapy, Community-Based Speech Therapy Models, Early Vocal Intervention, Auditory-Verbal Therapy (AVT)School-age Children571Intensive Speech Therapy, Early Vocal Intervention, APD intervention, Auditory-Verbal Therapy (AVT), Multisensory Stimulation Therapy,Oral Functional Training (OFT), Rhythmic Reading Training (RRT), Rapid Syllable Transition Treatment (ReST)Older children366Semantic Categorization Therapy, Early Vocal Intervention, Rhythmic Reading Training (RRT), Speech Bulb Reduction Program, Intensivespeech and language therapy, Peer-Mediated Intervention, Lidcombe Program, Oral Functional Training (OFT)Preschoolers347Early Vocal Intervention, Treatment-as-usual, The Lidcombe Program, Oral Functional Training (OFT), Speech Production Therapy withReward System, Phonological Interventions and Contrast Therapy, Cycles Phonological Remediation ApproachAdult319Pharyngeal flap procedure, Linguistic Retrieval Therapy (LRT), Oral Hydration Intervention, Physiologic Swallowing Therapy, MyofunctionalIntervention (OMT), Orthognathic speech therapy, Eye-Tongue Movement Training, Behavioral Voice Therapy</p>
<p>Table 3 :
3
Intervention-disorder examples in our discoveries.</p>
<p>Table 4 :
4
Definition of intervention themes.</p>
<p>•</p>
<p>Case Study represents a detailed examination of the intervention on a particular individual or group with communication disorders.The purpose of a case study is to provide a deep understanding of the patient's unique needs and assess the intervention's effectiveness.• Participant represents the individuals or populations that are involved in the case study of intervention.• Age represent the age of experiment participant or claimed target population of the intervention.The age is quantified with a granularity of half a year.We additionally convert age to age groups including "newborn, infants, toddlers, children, preschoolers, school-age children, older children, youth, teens, adolescents, adult, young adult, middle aged, aged, senior".Each specific age may be associated with multiple age groups.For instance, an individual aged 13 years could be categorized into the 'teens,' 'adolescents,' and 'children' age groups.• Language represents the speaking language of the experiment participant in the case study of the intervention.
Prompt_SelfRefine_Refine1: "{#Background} Critics: {#feedback}.Based on your last answer and itscritics, revise your answer to myquestion. Your answer:"Prompt_SelfRefine_Feedback2: "{#Background} Reflect your answer.Analyze the included aspects inyour answer. Provide critque tohelp make the response morecomprehensive. Your feedback:"Prompt_SelfRefine_Refine2: "{#Background} Critics: {#feedback}.Based on your last answer and itscritics, revise your answer to myquestion. Your answer:"C CoT &amp; Self-Refine BaselinesInstead of using an external LLM to provide evaluation feed-back to the explorer, we use CoT and SelfRefine promptingtechniques as baselines to task explorer refine annotationsindependently. The prompts of CoT and SelfRefine are asfollows:Background: Your last answer to myquestion {#init annotation question}is: {#last annotation}.---<em> CoT:Prompt_CoT1: "{#Background} Make aplan to correctly answer myquestion again."Prompt_CoT2: "{#Background} Make aplan to answer my question againwith more comprehensive results."---</em> SelfRefine:Prompt_SelfRefine_Feedback1: "{#Background} Reflect your answer.Analyze the correctness of theinformation provided. Providecritque to help improve the answer. Your feedback:"
https://www.llamaindex.ai
https://platform.openai.com/docs/guides/embeddings/embedding-models
https://docs.llamaindex.ai/en/stable/examples/evaluation/faithfulness eval
AcknowledgmentsThe research was supported, in part, by the National AI Institute for Exceptional Education (NSF Award #2229873), Center for Early Literacy and Responsible AI (IES Award #R305C240046), FuSe-TG (NSF Award #2235364) and SaTC (NSF Award #2329704).The opinions expressed are those of the authors and do not represent the views of any sponsors.Theme Definition speech awareness work that involves recognizing and understanding speech sounds.It includes phonological awareness (identifying and manipulating sounds), auditory discrimination (distinguishing sounds), and sound identification (recognizing the meaning of sounds).speech articulation work that refers to the physical production of speech sounds using the mouth, lips, tongue, and respiratory system.It focuses on the clarity and accuracy of pronouncing phonemes and forming them into words.comprehension work that aims to improve the understanding of (receptive) language.expressive language work that aims to improve the children's expressive language, in quantity, vocabulary or structure.self-monitoring work designed to help the patient's awareness of their speech and language difficulties and how they might be able to overcome them.generalisation work to help make speech and language or therapy gains transferable to other situations and environments.foundation skills work to practise and improve a range of early skills, many of which might be considered foundations for speech and language development.functional communication work focusing on those aspects of communication that help the child's involvement and participation in life situations; this might be functional language, signing or the use of symbols.adult understanding and empowerment work that helps parents to understand the nature of their child's speech and language difficulty, what helps to improve it and why.adult-child interaction work on the interaction between the parent/adult and the child.All of the changes to adult/parent-child interactions were emphasised in terms of those that encourage speech and language development.A POP AlgorithmA.2 Annotation Prompt Template GenerationIn the POP algorithm, the annotation prompt for a specific concept node is generated from a template T , which is constructed using the node's context (the k-hop visited neighborhood) and the completed annotations within that context.We carefully design the prompt to task LLM to generate T as follows:The Since template T is composed of concept nodes visited before the current node, the final annotation prompt for the current node is derived by incorporating the annotations associated with these concept nodes into T .B Speech-Language Intervention Annotation B.1 Literature CorpusWe cultivate a literature corpus of 64,177 research articles within the domain of speech-language pathology to facilitate intervention discovery.To conduct our literature search, we use a collection of carefully selected keywords drawn from a glossary of commonly used terms in speech-language pathology.These keywords include:"speech language therapy, speech language disorder, speech sound disorder, articulation disorder, speech intervention, language intervention, auditory discrimination, auditory processing disorder, phonological awareness, phonological processes, auditory perception, babbling, motor speech disorder, morpheme, phonology, prosody, stuttering, language impairment, speech language pathologist, speech and language therapist, babbling, expressive language delay, cleft speech disorder, autism spectrum disorder, developmental phonological disorder, developmental stuttering, phonological impairment, developmental dysarthria, down syndrome, swallowing disorder, communication impairment, articulation impairment, dyslexia, apraxia, dysarthria, dysphagia, communication disorder, expressive language disorder, dyspraxia, aphasia, augmentative and alternative communication, central auditory processing disorder, cleft lip and palate, down syndrome, fluency disorders, hearing loss, orofacial myofunctional disorders, spoken language disorders, written language disorders, acquired brain injury, apraxia of speech, auditory comprehension, literacy impairments, voice difficulties, language-based learning disabilities."
A knowledge graph of combined drug therapies using semantic predications from biomedical literature: Algorithm development. Achiam, arXiv:2303.08774arXiv:2307.01128Shyamal Anadkat, et al. Gpt-4 technical report. Leonardo Piano, Alessandro Sebastian Podda2023. 2023. 2023. 2023. 2023. 2023. 2020. 2020233e18323arXiv preprintJMIR medical informatics</p>
<p>Zero-shot relation triplet extraction via knowledge-driven llm synthetic data generation. Michael Gruninger, Li Gruninger, Hayilang He, Jie Zhang, Kang Liu, Qing Sun, Zhang, Proc. IJCAI'95, Workshop on Basic Ontological Issues in Knowledge Sharing. IJCAI'95, Workshop on Basic Ontological Issues in Knowledge SharingSpringer1995. 1995. 2024International Conference on Intelligent Computing</p>
<p>Psychosocial Cochrane Developmental, and Learning Problems Group. Speech and language therapy interventions for children with primary speech and language delay or disorder. Kim, arXiv:2402.18050arXiv:2403.08345Meganno+: A human-llm collaborative annotation system. Kommineni, Zoe Garrett, Chad NyeJames Law2024a. 2024. 2024b. 2024. 2024. 2024. 1996. 2015. 19963arXiv preprintCan llms produce faithful explanations for fact-checking? towards faithful explainable fact-checking via multi-agent debate</p>
<p>Duie: A large-scale chinese dataset for information extraction. Li, Natural Language Processing and Chinese Computing: 8th CCF International Conference, NLPCC 2019. Dunhuang, ChinaSpringer2019. October 9-14, 2019. 2019Proceedings, Part II 8</p>
<p>A preliminary roadmap for llms as assistants in exploring, analyzing, and visualizing knowledge graphs. Li, arXiv:2404.014252024a. 2024arXiv preprint</p>
<p>Confidence matters: Revisiting intrinsic self-correction capabilities of large language models. Li, 2024b. 2024</p>
<p>Large language models have intrinsic self-correction ability. Liu, 2024. 2024</p>
<p>Multi-task identification of entities, relations, and coreference for scientific knowledge graph construction. Luan, arXiv:1808.09602arXiv:1907.08243Zita Marinho, and André FT Martins. Joint learning of named entity recognition and entity linking. Pedro Henrique Martins2018. 2018. 2024. 2024. 2012. 2019. 201936arXiv preprintAdvances in Neural Information Processing Systems</p>
<p>Text2kgbench: A benchmark for ontology-driven knowledge graph generation from text. Fineout-Overholt ; Melnyk, Mihindukulasooriya, arXiv:2209.04280Shon Otmazgin, Arie Cattan, and Yoav Goldberg. F-coref: Fast, accurate and easy to use coreference resolution. Bernadette Mazurek, Melnyk , Ellen Fineout-Overholt, Springer2022. 2022. 2023. 2023. 2022arXiv preprintInternational Semantic Web Conference</p>
<p>Knowledge graphs: Opportunities and challenges. Peng, Artificial Intelligence Review. 56112023. 2023</p>
<p>Kgen: a knowledge graph generator from biomedical scientific literature. Rossanez, BMC medical informatics and decision making. Ricardo da Silva Torres, and Hélène de Ribaupierre202020. 2020</p>
<p>Evidence-based strategies for clinical organizations to address covid-19 vaccine hesitancy. Rutten , Mayo clinic proceedings. Elsevier2021. 202196</p>
<p>Evidence-based medicine. David L Sackett, Sackett, Seminars in perinatology. Elsevier1997. 199721</p>
<p>Consistency guided knowledge retrieval and denoising in llms for zeroshot document-level relation triplet extraction. Sun, Proceedings of the ACM on Web Conference 2024. the ACM on Web Conference 20242024. 2024</p>
<p>From human experts to machines: An llm supported approach to ontology and knowledge graph construction. Tang, arXiv:2304.10428arXiv:1909.03227Proceedings of the 29th International Conference on Intelligent User Interfaces. Krishna Kommineni Vamsi, Krishna Vamsi, Sheeba Kommineni, Samuel, the 29th International Conference on Intelligent User Interfaces2024. 2024. 2018. 2018. 2024. 2024. 2023a. 2023. 2023b. 2023. 2024. 2024. 201922arXiv preprintProceedings of the CHI Conference on Human Factors in Computing Systems. Wei et al., 2019] Zhepei Wei, Jianlin Su, Yue Wang, Yuan Tian, and Yi Chang. A novel cascade binary tagging framework for relational triple extraction</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. Wei, arXiv:2302.102052022. 2022. 2023. 202335arXiv preprintZero-shot information extraction via chatting with chatgpt</p>
<p>Autogen: Enabling next-gen llm applications via multi-agent conversation framework. Wu, arXiv:2308.08155arXiv:1906.061272023. 2023. 2019. 2019arXiv preprintDocred: A large-scale document-level relation extraction dataset</p>
<p>A novel joint biomedical event extraction framework via two-level modeling of documents. Ye, arXiv:2210.12714arXiv:2404.03868Shumin Deng, Huajun Chen, and Ningyu Zhang. Llms for knowledge graph construction and reasoning: Recent capabilities and future opportunities. 2022. 2022. 2024. 2021. 2021. 2023. 2023. 202455058arXiv preprintGenerative knowledge graph construction: A review. World Wide Web</p>            </div>
        </div>

    </div>
</body>
</html>