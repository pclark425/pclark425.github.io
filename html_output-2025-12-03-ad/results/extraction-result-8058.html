<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8058 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8058</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8058</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-146.html">extraction-schema-146</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of comparisons between LLM-as-a-judge evaluations and human evaluations, including reported differences, limitations, failure modes, and any quantitative agreement metrics.</div>
                <p><strong>Paper ID:</strong> paper-ae3d869719c15099889c02c03b922516b3b60aa0</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/ae3d869719c15099889c02c03b922516b3b60aa0" target="_blank">How Good Are GPT Models at Machine Translation? A Comprehensive Evaluation</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> This paper presents a comprehensive evaluation of GPT models for machine translation, covering various aspects such as quality of different G PT models in comparison with state-of-the-art research and commercial systems, effect of prompting strategies, robustness towards domain shifts and document-level translation.</p>
                <p><strong>Paper Abstract:</strong> Generative Pre-trained Transformer (GPT) models have shown remarkable capabilities for natural language generation, but their performance for machine translation has not been thoroughly investigated. In this paper, we present a comprehensive evaluation of GPT models for machine translation, covering various aspects such as quality of different GPT models in comparison with state-of-the-art research and commercial systems, effect of prompting strategies, robustness towards domain shifts and document-level translation. We experiment with eighteen different translation directions involving high and low resource languages, as well as non English-centric translations, and evaluate the performance of three GPT models: ChatGPT, GPT3.5 (text-davinci-003), and text-davinci-002. Our results show that GPT models achieve very competitive translation quality for high resource languages, while having limited capabilities for low resource languages. We also show that hybrid approaches, which combine GPT models with other translation systems, can further enhance the translation quality. We perform comprehensive analysis and human evaluation to further understand the characteristics of GPT translations. We hope that our paper provides valuable insights for researchers and practitioners in the field and helps to better understand the potential and limitations of GPT models for translation.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8058.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8058.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of comparisons between LLM-as-a-judge evaluations and human evaluations, including reported differences, limitations, failure modes, and any quantitative agreement metrics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>COMETkiwi</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>COMETkiwi (wmt22-COMETkiwi-da)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A reference-less neural quality-estimation metric from the WMT22 metrics suite used to score MT outputs without references; in this paper it is used to judge GPT and NMT translations and compared against professional human DA+SQM judgments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>How Good Are GPT Models at Machine Translation? A Comprehensive Evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_task</strong></td>
                            <td>Machine translation quality evaluation (quality estimation / ranking of MT outputs)</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>WMT testsets (WMT22 for most languages; WMT21 for Icelandic and Hausa); human evaluation subset: 425 sampled non-identical item pairs per language pair</td>
                        </tr>
                        <tr>
                            <td><strong>judge_model_name</strong></td>
                            <td>COMETkiwi (neural reference-less metric)</td>
                        </tr>
                        <tr>
                            <td><strong>judge_model_details</strong></td>
                            <td>WMT22 reference-less neural metric (wmt22-COMETkiwi-da) used for quality estimation; trained to predict human Direct Assessment style scores and used here as an automatic judge for MT outputs</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluator_type</strong></td>
                            <td>Professional translation experts (5 distinct annotators per language pair) using source-based sentence-level contrastive Direct Assessment + Scalar Quality Metric (contrastive DA+SQM)</td>
                        </tr>
                        <tr>
                            <td><strong>agreement_metric</strong></td>
                            <td>qualitative consistency / reported alignment (no numeric correlation coefficient reported)</td>
                        </tr>
                        <tr>
                            <td><strong>agreement_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_loss_aspects</strong></td>
                            <td>lexical metrics (BLEU/ChrF) fail to capture GPT strengths; reference and lexical bias of traditional metrics; lack of explicit numeric agreement reported between COMETkiwi and humans</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>Authors report that human evaluation results are "highly consistent" with COMETkiwi scores (aggregated comparisons shown in Figures 4/5) and that COMETkiwi captures GPT strengths that lexical metrics miss; no explicit numeric correlation or statistical agreement value is provided in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>advantages_of_llm_judge</strong></td>
                            <td>COMETkiwi (neural judge) is reference-less (can score without reference), scales to large testsets, is robust to domain shift per authors' discussion, and empirically aligns well with the professional human DA+SQM annotations on the examined samples.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_setting</strong></td>
                            <td>Human evaluation compared GPT (text-davinci-003, 5-shot QR) vs WMT-Best systems; for each language pair 425 non-identical item pairs were sampled and annotated by 5 professional annotators with contrastive DA+SQM; COMETkiwi scores were computed on the same items and aggregated for comparison (figures show aggregated human vs COMETkiwi results). The paper states consistency qualitatively but does not report correlation coefficients or inter-annotator agreement numbers.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'How Good Are GPT Models at Machine Translation? A Comprehensive Evaluation', 'publication_date_yy_mm': '2023-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8058.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8058.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of comparisons between LLM-as-a-judge evaluations and human evaluations, including reported differences, limitations, failure modes, and any quantitative agreement metrics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>COMET-22</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>COMET-22 (wmt22-COMET-da)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A reference-based neural MT evaluation metric (top-ranked in WMT22) combining direct assessments and multidimensional tags; used in the paper for sentence- and adapted document-level evaluation and compared qualitatively to human judgments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>How Good Are GPT Models at Machine Translation? A Comprehensive Evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_task</strong></td>
                            <td>Machine translation quality evaluation (reference-based scoring of MT outputs)</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>WMT testsets (WMT22/WMT21); document-level News Commentary subset for document experiments</td>
                        </tr>
                        <tr>
                            <td><strong>judge_model_name</strong></td>
                            <td>COMET-22 (reference-based neural metric)</td>
                        </tr>
                        <tr>
                            <td><strong>judge_model_details</strong></td>
                            <td>WMT22 top-ranked reference-based neural metric (wmt22-COMET-da) combining DA signals and MQM-derived annotations; authors also adapt COMET for document-level evaluation (Doc-COMETkiwi / doc-COMET adaptations using sliding windows)</td>
                        </tr>
                        <tr>
                            <td><strong>human_evaluator_type</strong></td>
                            <td>Professional translation experts (5 distinct annotators per language pair) using source-based contrastive DA+SQM</td>
                        </tr>
                        <tr>
                            <td><strong>agreement_metric</strong></td>
                            <td>qualitative comparison (COMET-22 used alongside human DA+SQM; no numeric agreement coefficient reported)</td>
                        </tr>
                        <tr>
                            <td><strong>agreement_score</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_loss_aspects</strong></td>
                            <td>lexical metrics (BLEU/ChrF) show consistent degradation for GPT and therefore do not align with human judgments; standard sentence-level metrics may be inadequate for document-level GPT outputs without adaptation</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>COMET-22 (and COMETkiwi) provide more robust signals aligned with human judgments than lexical metrics; authors adapted COMET for document-level evaluation and argue existing metrics may be inadequate for some GPT document behaviors.</td>
                        </tr>
                        <tr>
                            <td><strong>advantages_of_llm_judge</strong></td>
                            <td>As a neural reference-based metric, COMET-22 better correlates with human judgments than lexical metrics in the authors' experience and can be adapted to document-level scoring (sliding-window averaging) to compare document outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_setting</strong></td>
                            <td>COMET-22 used for sentence-level evaluations across 18 language pairs and adapted for document-level evaluation by sliding-window segmentation (Doc-COMETkiwi/doc-COMET adaptations). Human DA+SQM annotations were used as the gold standard on sampled items; comparisons are reported qualitatively (figures/tables), with no explicit numeric correlation values reported between COMET-22 and human scores.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'How Good Are GPT Models at Machine Translation? A Comprehensive Evaluation', 'publication_date_yy_mm': '2023-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8058",
    "paper_id": "paper-ae3d869719c15099889c02c03b922516b3b60aa0",
    "extraction_schema_id": "extraction-schema-146",
    "extracted_data": [
        {
            "name_short": "COMETkiwi",
            "name_full": "COMETkiwi (wmt22-COMETkiwi-da)",
            "brief_description": "A reference-less neural quality-estimation metric from the WMT22 metrics suite used to score MT outputs without references; in this paper it is used to judge GPT and NMT translations and compared against professional human DA+SQM judgments.",
            "citation_title": "",
            "mention_or_use": "use",
            "paper_title": "How Good Are GPT Models at Machine Translation? A Comprehensive Evaluation",
            "evaluation_task": "Machine translation quality evaluation (quality estimation / ranking of MT outputs)",
            "dataset_name": "WMT testsets (WMT22 for most languages; WMT21 for Icelandic and Hausa); human evaluation subset: 425 sampled non-identical item pairs per language pair",
            "judge_model_name": "COMETkiwi (neural reference-less metric)",
            "judge_model_details": "WMT22 reference-less neural metric (wmt22-COMETkiwi-da) used for quality estimation; trained to predict human Direct Assessment style scores and used here as an automatic judge for MT outputs",
            "human_evaluator_type": "Professional translation experts (5 distinct annotators per language pair) using source-based sentence-level contrastive Direct Assessment + Scalar Quality Metric (contrastive DA+SQM)",
            "agreement_metric": "qualitative consistency / reported alignment (no numeric correlation coefficient reported)",
            "agreement_score": null,
            "reported_loss_aspects": "lexical metrics (BLEU/ChrF) fail to capture GPT strengths; reference and lexical bias of traditional metrics; lack of explicit numeric agreement reported between COMETkiwi and humans",
            "qualitative_findings": "Authors report that human evaluation results are \"highly consistent\" with COMETkiwi scores (aggregated comparisons shown in Figures 4/5) and that COMETkiwi captures GPT strengths that lexical metrics miss; no explicit numeric correlation or statistical agreement value is provided in the paper.",
            "advantages_of_llm_judge": "COMETkiwi (neural judge) is reference-less (can score without reference), scales to large testsets, is robust to domain shift per authors' discussion, and empirically aligns well with the professional human DA+SQM annotations on the examined samples.",
            "experimental_setting": "Human evaluation compared GPT (text-davinci-003, 5-shot QR) vs WMT-Best systems; for each language pair 425 non-identical item pairs were sampled and annotated by 5 professional annotators with contrastive DA+SQM; COMETkiwi scores were computed on the same items and aggregated for comparison (figures show aggregated human vs COMETkiwi results). The paper states consistency qualitatively but does not report correlation coefficients or inter-annotator agreement numbers.",
            "uuid": "e8058.0",
            "source_info": {
                "paper_title": "How Good Are GPT Models at Machine Translation? A Comprehensive Evaluation",
                "publication_date_yy_mm": "2023-02"
            }
        },
        {
            "name_short": "COMET-22",
            "name_full": "COMET-22 (wmt22-COMET-da)",
            "brief_description": "A reference-based neural MT evaluation metric (top-ranked in WMT22) combining direct assessments and multidimensional tags; used in the paper for sentence- and adapted document-level evaluation and compared qualitatively to human judgments.",
            "citation_title": "",
            "mention_or_use": "use",
            "paper_title": "How Good Are GPT Models at Machine Translation? A Comprehensive Evaluation",
            "evaluation_task": "Machine translation quality evaluation (reference-based scoring of MT outputs)",
            "dataset_name": "WMT testsets (WMT22/WMT21); document-level News Commentary subset for document experiments",
            "judge_model_name": "COMET-22 (reference-based neural metric)",
            "judge_model_details": "WMT22 top-ranked reference-based neural metric (wmt22-COMET-da) combining DA signals and MQM-derived annotations; authors also adapt COMET for document-level evaluation (Doc-COMETkiwi / doc-COMET adaptations using sliding windows)",
            "human_evaluator_type": "Professional translation experts (5 distinct annotators per language pair) using source-based contrastive DA+SQM",
            "agreement_metric": "qualitative comparison (COMET-22 used alongside human DA+SQM; no numeric agreement coefficient reported)",
            "agreement_score": null,
            "reported_loss_aspects": "lexical metrics (BLEU/ChrF) show consistent degradation for GPT and therefore do not align with human judgments; standard sentence-level metrics may be inadequate for document-level GPT outputs without adaptation",
            "qualitative_findings": "COMET-22 (and COMETkiwi) provide more robust signals aligned with human judgments than lexical metrics; authors adapted COMET for document-level evaluation and argue existing metrics may be inadequate for some GPT document behaviors.",
            "advantages_of_llm_judge": "As a neural reference-based metric, COMET-22 better correlates with human judgments than lexical metrics in the authors' experience and can be adapted to document-level scoring (sliding-window averaging) to compare document outputs.",
            "experimental_setting": "COMET-22 used for sentence-level evaluations across 18 language pairs and adapted for document-level evaluation by sliding-window segmentation (Doc-COMETkiwi/doc-COMET adaptations). Human DA+SQM annotations were used as the gold standard on sampled items; comparisons are reported qualitatively (figures/tables), with no explicit numeric correlation values reported between COMET-22 and human scores.",
            "uuid": "e8058.1",
            "source_info": {
                "paper_title": "How Good Are GPT Models at Machine Translation? A Comprehensive Evaluation",
                "publication_date_yy_mm": "2023-02"
            }
        }
    ],
    "potentially_relevant_new_papers": [],
    "cost": 0.013625499999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>How Good Are GPT Models at Machine Translation? A Comprehensive Evaluation</h1>
<p>Amr Hendy, Mohamed Abdelrehim, Amr Sharaf, Vikas Raunak, Mohamed Gabr, Hitokazu Matsushita, Young Jin Kim, Mohamed Afify, Hany Hassan Awadalla*<br>Microsoft</p>
<h4>Abstract</h4>
<p>Generative Pre-trained Transformer (GPT) models have shown remarkable capabilities for natural language generation, but their performance for machine translation has not been thoroughly investigated. In this paper, we present a comprehensive evaluation of GPT models for machine translation, covering various aspects such as quality of different GPT models in comparison with state-of-the-art research and commercial systems, effect of prompting strategies, robustness towards domain shifts and document-level translation. We experiment with eighteen different translation directions involving high and low resource languages, as well as non English-centric translations, and evaluate the performance of three GPT models: ChatGPT, GPT3.5 (text-davinci-003), and text-davinci002. Our results show that GPT models achieve very competitive translation quality for high resource languages, while having limited capabilities for low resource languages. We also show that hybrid approaches, which combine GPT models with other translation systems, can further enhance the translation quality. We perform comprehensive analysis and human evaluation to further understand the characteristics of GPT translations. We hope that our paper provides valuable insights for researchers and practitioners in the field and helps to better understand the potential and limitations of GPT models for translation.</p>
<h2>1 Introduction</h2>
<p>Recent advancements in natural language processing (NLP), particularly the development of largescale language modeling techniques, have brought remarkable improvements in machine translation as well as in other NLP tasks (Fan et al., 2021; Kim et al., 2021; Costa-jussà et al., 2022). The emergence of large language models with diverse capabilities, including machine translation, has opened</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>up new possibilities for building more effective translation systems (Brown et al., 2020; Chowdhery et al., 2022). Among these models, the latest Generative Pre-trained Transformer (GPT) models (Brown et al., 2020) have gained significant attention for their ability to generate coherent and context-aware text. We present a comprehensive evaluation of GPT models for machine translation, exploring their strengths and limitations, and providing insights for researchers and practitioners working in the area of machine translation.</p>
<p>GPT models and the conventional Neural Machine Translation (NMT) systems are both based on the transformer architecture (Vaswani et al., 2017), but they differ in several aspects. First, GPT models are decoder-only models that use the same parameters to process the context and the source as a single input for generating the next output. On the other hand, NMT models usually have an encoderdecoder architecture that encodes the source sentence in the encoder network and decodes the target sentence conditioned on the previous outputs in the decoder network. Second, GPT models are mainly trained on monolingual data, with a strong bias towards English ${ }^{1}$, whereas NMT models rely on large amounts of highly curated parallel data. Third, GPT models need a much larger number of parameters to achieve multilingual in-context capabilities. We have observed that GPT models exhibit promising translation capabilities, even with these differences in architecture and training data.</p>
<p>The performance of GPT models in machine translation, despite their promising potential, remains under-investigated relative to commercial and state-of-the-art research systems. This study aims to address this research gap by systematically assessing the efficacy of GPT models for machine translation, with a focus on their performance,</p>
<p><sup id="fnref:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<p>prompts, document-level translation, domain robustness and possible advantages of integrating them with conventional NMT systems.</p>
<p>To explore the potential of GPT models for translation, we perform comprehensive experiments to examine their translation abilities. Specifically, we investigate the performance of GPT models for machine translation across 18 language pairs, covering both high and low-resource languages, as well as English-centric and non-English-centric directions. We compare the quality of three GPT models: text-davinci-002, text-davinci-003 (GPT3.5), and ChatGPT, and show that they differ significantly in their translation capabilities.</p>
<p>We also explore the impact of prompting strategies on the performance of GPT models for machine translation. We examine both the content and the form of the prompts, and identify the best practices for obtaining optimal results. Furthermore, we test the hypothesis that GPT models would enhance document-level translation, as they could exploit the context and coherence of the entire document to generate more accurate and fluent translations. We evaluate this hypothesis on various language pairs using several metrics. Additionally, we evaluate the cross-domain generalization ability of GPT models for translation tasks and examine their robustness under domain shift.</p>
<p>Moreover, we conduct extensive human evaluations and analyses to provide valuable insights into the strengths and weaknesses of GPT models for machine translation, and to suggest directions for future work. We also perform comprehensive analyses to understand whether GPT and NMT models have complementary characteristics, and we propose several ideas to combine the advantages of the two paradigms. Finally, we touch on the effectiveness of GPT models on cross-lingual natural language tasks beyond translation, and explore their multilingual capabilities and limitations.</p>
<p>To explore the research questions above, we organize the paper as follows:</p>
<ul>
<li>We provide a detailed experimental setup (§2), which includes the datasets used (§2.1), the machine translation systems used in the comparison(§ 2.2), the GPT systems (§ 2.3), and the evaluation methods (§2.4).</li>
<li>We present a series of experiments (§3) that investigate different aspects of GPT models for machine translation. These experiments cover
prompt selection strategies (§3.1), zero-shot translation capabilities of GPT models (§3.2), GPT performance on high-resource languages (§ 3.3), GPT performance on low-resource and non-English-centric languages (§ 3.4), document-level MT with GPT (§3.5), translation robustness toward domain shift (§3.6), and hybrid GPT and NMT translation (§3.7).</li>
<li>We then present the human evaluation and analysis that provides insights into the quality of GPT translations (§4).</li>
<li>We discuss the characteristics of GPT translations (§5) vis-à-vis NMT and analyze the differentiating aspects of GPT translations (§5.1) by quantitatively enumerating language modeling bias artifacts (§5.2), the characteristics of translation across various language directions (§5.3-§5.5), as well as parallel data bias artifacts (§5.6).</li>
<li>We explore the multilingual capabilities of GPT models beyond translation (§6).</li>
<li>We conclude by summarizing our findings and suggesting future directions for research (§7).</li>
</ul>
<h2>2 Experimental Setup</h2>
<h3>2.1 Datasets</h3>
<p>We considered 18 different translation directions across a diverse set of languages for our comprehensive evaluation. The evaluation covers both high- and low-resource languages, as well as English-centric and non-English-centric direct translations. The languages considered in this study include European (English-EN, French-FR, German-DE, Czech-CS and Icelandic-IS), Asian (Chinese-ZH and Japanese-JA), Cyrillic (Russian$R U$ and Ukrainian-UK) and African (Hausa-HA).</p>
<p>We use publicly available datasets to facilitate reproducibility and data sharing. We use the WMT22 testsets ${ }^{2}$ for all languages except for Icelandic and Hausa, for which we use the WMT21 testsets ${ }^{3}$. We use WMT22 datasets for two reasons: first, they are recent and less likely to overlap with the GPT models training data that was collected until June</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>2021 ${ }^{4}$. Second, they have natural source texts and translated target texts, which avoid the problems of using "translationese" testsets with unnatural source texts in the original language that may result in inaccurate evaluation (Zhang and Toral, 2019).</p>
<p>Table 1 summarizes the datasets and sizes used in this paper. We focus on the most recent datasets with directional translation, as older datasets may have influenced the training data of the GPT models. We make all data and analysis in this paper publicly available to promote further research. ${ }^{5}$.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Lang-Pair</th>
<th style="text-align: center;">Dataset</th>
<th style="text-align: center;">Number of <br> sentences</th>
<th style="text-align: center;">WMT-Best System</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">CS-EN</td>
<td style="text-align: center;">WMT22</td>
<td style="text-align: center;">1448</td>
<td style="text-align: center;">Online-W</td>
</tr>
<tr>
<td style="text-align: center;">EN-CS</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">2037</td>
<td style="text-align: center;">Online-W</td>
</tr>
<tr>
<td style="text-align: center;">DE-EN</td>
<td style="text-align: center;">WMT22</td>
<td style="text-align: center;">1984</td>
<td style="text-align: center;">Lan-Bridge</td>
</tr>
<tr>
<td style="text-align: center;">EN-DE</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">2037</td>
<td style="text-align: center;">Online-B</td>
</tr>
<tr>
<td style="text-align: center;">IS-EN</td>
<td style="text-align: center;">WMT21</td>
<td style="text-align: center;">1000</td>
<td style="text-align: center;">Facebook-AI</td>
</tr>
<tr>
<td style="text-align: center;">EN-IS</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">1000</td>
<td style="text-align: center;">Facebook-AI</td>
</tr>
<tr>
<td style="text-align: center;">JA-EN</td>
<td style="text-align: center;">WMT22</td>
<td style="text-align: center;">2008</td>
<td style="text-align: center;">DLUT</td>
</tr>
<tr>
<td style="text-align: center;">EN-JA</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">2037</td>
<td style="text-align: center;">NT5</td>
</tr>
<tr>
<td style="text-align: center;">ZH-EN</td>
<td style="text-align: center;">WMT22</td>
<td style="text-align: center;">1875</td>
<td style="text-align: center;">JDExploreAcademy</td>
</tr>
<tr>
<td style="text-align: center;">EN-ZH</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">2037</td>
<td style="text-align: center;">Online-W</td>
</tr>
<tr>
<td style="text-align: center;">UK-EN</td>
<td style="text-align: center;">WMT22</td>
<td style="text-align: center;">2018</td>
<td style="text-align: center;">Lan-Bridge</td>
</tr>
<tr>
<td style="text-align: center;">EN-UK</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">2037</td>
<td style="text-align: center;">Online-B</td>
</tr>
<tr>
<td style="text-align: center;">RU-EN</td>
<td style="text-align: center;">WMT22</td>
<td style="text-align: center;">2016</td>
<td style="text-align: center;">JDExploreAcademy</td>
</tr>
<tr>
<td style="text-align: center;">EN-RU</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">2037</td>
<td style="text-align: center;">Online-W</td>
</tr>
<tr>
<td style="text-align: center;">HA-EN</td>
<td style="text-align: center;">WMT21</td>
<td style="text-align: center;">997</td>
<td style="text-align: center;">Facebook-AI</td>
</tr>
<tr>
<td style="text-align: center;">EN-HA</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">1000</td>
<td style="text-align: center;">Facebook-AI</td>
</tr>
<tr>
<td style="text-align: center;">FR-DE</td>
<td style="text-align: center;">WMT22</td>
<td style="text-align: center;">2006</td>
<td style="text-align: center;">Online-W</td>
</tr>
<tr>
<td style="text-align: center;">DE-FR</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">1984</td>
<td style="text-align: center;">Online-B</td>
</tr>
</tbody>
</table>
<p>Table 1: Test datasets used in the evaluation and best systems used for comparison as reported in WMT by Kocmi et al. (2022b) and Barrault et al. (2021).</p>
<h3>2.2 Neural Machine Translation Systems</h3>
<p>In this study, we compare the performance of GPT systems against both state-of-the-art (SoTA) research and commercial systems. We use the top ranked systems (WMT-Best) in the WMT evaluation campaigns for each language pair, which we use as a baseline for comparison. WMT-Best systems are a mix of top ranked commercial and research systems. We use the system outputs as provided by the evaluation campaigns (Kocmi et al., 2022b; Barrault et al., 2021). Table 1 shows the list of top ranked system for each language pair. We also utilize Microsoft Translator which we access through the public API available on Azure</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup>Cognitive Services ${ }^{6}$.</p>
<h3>2.3 GPT Systems</h3>
<p>We assess the latest three variants of the largest GPT models available, as listed at OpenAI's documentation ${ }^{7}$. These models are:</p>
<ul>
<li>text-davinci-002 - an InstructGPT model (Ouyang et al., 2022) which utilizes Reinforcement Learning with reward models trained based on human comparisons.</li>
<li>text-davinci-003 - an improved version of text-davinci-002.</li>
<li>ChatGPT - a model that is similar to the previous two and optimized specifically for conversational purposes ${ }^{8}$.</li>
</ul>
<p>All GPT models have been accessed through APIs on Microsoft Azure OpenAI Service ${ }^{9}$.</p>
<h3>2.4 Evaluation Methods</h3>
<p>Sentence-Level Evaluation The MT Metrics shared task (Freitag et al., 2022) recommends the use of neural network-based metrics in machine translation evaluation, as they have demonstrated a high correlation with human evaluation and are resilient to domain shift. Following these recommendations, we employ the top-ranked metrics from Unbabel in the shared task ${ }^{10}$. Specifically, we use COMET-22 (wmt22-COMET-da) (Rei et al., 2022a), a reference-based metric that combines direct assessments (DA), sentence-level scores, and word-level tags from Multidimensional Quality Metrics (MQM) error annotations. For referenceless quality estimation, we adopt COMETkiwi (wmt22-COMETkiwi-da) (Rei et al., 2022b). Additionally, we report results using SacreBLEU ${ }^{11}$ and Chrf(Popović, 2015) for completeness, although we note that these metrics are not extensively used in our analysis.</p>
<p>Document-Level Evaluation For the experiments on document-level translation using GPT, we face a challenge in evaluating performance due</p>
<p><sup id="fnref2:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<p>to the lack of metrics that can handle the non one-to-one sentence mapping that the systems may produce. To address this challenge, we have adapted the COMET metrics to better suit document-level evaluation. The adaptation involves splitting the document into multiple segments with an overlapping sliding window and computing the average score across these segments to compare two documents. We use Doc-COMETkiwi to refer to the modified metric throughout the evaluation.</p>
<p>This simple modification has three clear design advantages over a pure sentence-level evaluation. First, it allows each sentence to be evaluated within its context. Second, it enables each sentence to be evaluated across multiple contexts due to the overlapping nature of the sliding window. Lastly, it avoids the limited context window of the evaluation models that could hinder quality assessment over longer static windows on documents. We do not claim that this is an optimal metric for evaluating document-level translation, but it overcomes the limitation of the one-to-one sentence mapping and may capture the quality of translation in ambiguous contexts better than sentence-level representation. We argue that developing more robust documentlevel metrics is still essential.</p>
<p>The current metrics for evaluating machine translation performance may not be adequate for measuring the performance of GPT models, and it may be necessary to develop new metrics that take into account the unique characteristics of these models.</p>
<p>Human Evaluation and Analysis We perform human evaluation (§ 4) using source-based sentence-level contrastive Direct Assessment + Scalar Quality Metric (contrastive DA+SQM; Akhbardeh et al. 2021, Kocmi et al. 2022a), with annotations provided by professional annotators. We also conduct thorough analysis on various characteristics of the translation (§5).</p>
<h2>3 Experiments</h2>
<p>In this section, we present various experiments. In $\S 3.1$, we describe several prompt selection strategies. In $\S 3.2$, we evaluate various GPT models in a zero-shot setup. In $\S 3.3$, we show results for highresource language pairs, followed by results for low-resource and non-English pairs in §3.4. §3.5 provides document translation results. $\S 3.6$ examines the robustness of GPT models under domain shift. Finally, in $\S 3.7$, we discuss the potential of combining the benefits of GPT and NMT models.</p>
<h3>3.1 Prompt Selection Strategies</h3>
<p>It has been shown that the performance of LLMs can be enhanced through in-context learning by providing few labelled examples (prompts) in addition to the test input (Brown et al., 2020). This few-shot paradigm has demonstrated strong performance across multiple natural language processing (NLP) tasks (Ouyang et al., 2022; Goyal et al., 2022; Wei et al., 2022; Chowdhery et al., 2022). There has also been a series of recent works on incontext learning for machine translation (MT) with rather mixed results and various ways of shot selection. Recently, Zhang et al. (2023) use GLM-130B and show consistent but rather low correlation between the performance of MT and shot selection as compared to random. They use different features that show varying level of correlation to the performance. In the same spirit, Vilar et al. (2022) use different prompt selection schemes with PaLM540B model with the main conclusion that shot selection is not necessarily better than random but they point out the importance of using high quality shots. In the same vein, Agrawal et al. (2022) use a much smaller model XGLM-7.5B and multiple selection criteria for the shots. They show that a combination of a retrieval and task metrics are consistently better than the random baseline across different translation directions.</p>
<p>In this paper, we explore prompt selection strategies along two dimensions: quality and relevance. Our pool to select few-shot examples is the cleaned WMT training data for each direction. This is obtained by filtering the full training data using language identification and length ratio. The size of the full and cleaned training data is shown in Table 12 for each direction. We do not use the development data from WMT shared tasks, despite its high quality, for shot selection to avoid any small chance of leaking information about the test set. In all cases, we test the performance with 0,1 and 5 shots. In our preliminary experiments, we found that increasing beyond 5 shots did not result in any meaningful improvement. We show below how we select shots based on quality and relevance.</p>
<ul>
<li>
<p>Quality: To ensure high quality shots we sort our training data using LaBSE (Feng et al., 2020). We consider high quality shots that are randomly chosen from the top 1 million pairs as opposed to the full data. We also found it useful to select sentences that are longer than 50 tokens.</p>
</li>
<li>
<p>Relevance: We consider relevant shots that are close to the input sentence. Based on preliminary experiments ${ }^{12}$ we use the cosine distance between LaBSE embeddings as a measure of closeness. We always select relevant pairs from high quality ones (the top 1 M pairs from LaBSE-scored training data). For computational efficiency, we adopt a two stage approach. We first use the input text and apply elastic search ${ }^{13}$ to retrieve the top 64 pairs then return the top 1 or 5 shots based on the LaBSE distance.</p>
</li>
</ul>
<p>In the results, we refer to full random as $R R$ (Random) while high quality are referred to as $Q R$ (Quality Random). The high quality shots selected through relevance are referred to as $Q S$ (Quality Selected).</p>
<h3>3.2 Zero-Shot Translation Capabilities of GPT Models</h3>
<p>We compare the general zero-shot translation capabilities of the three GPT models on four language pairs, in eight distinct translation directions. The selected languages were chosen with a focus on balancing representation. The languages include 1) German, which is one of the most represented non-English languages in GPT training data, 2) Russian, a large-scale non-Latin language, 3) Chinese, which represents a large-scale language with a script distinct from that of the majority of training data languages, and 4) French-German pair as non English-centric use case.</p>
<p>In this experiment, we compare the performance of three GPT models text-davinci-002, text-davinci003, and ChatGPT with the top ranked systems in WMT22, as shown in Table 2. Remarkably, text-davinci-002 shows lower performance, underperforming across all language pairs compared to the other two GPT models. On the other hand, text-davinci-003 clearly shows better translation performance across all languages in this evaluation. Its zero-shot performance is comparable to the best performing WMT DE-EN system and outperforms the best ZH-EN WMT system.</p>
<p>ChatGPT shows a storng performance in the DE-EN language pair, while performing similarly to text-davinci-003 when translating to English as well as French-German pairs. In terms of translat-</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup>ing from English to other languages, text-davinci003 shows better performance than the other two GPT models. It is noteworthy that the translation between French and German, which is not Englishcentric, exhibits surprising competitiveness with state-of-the-art systems, despite the fact that the majority of the training data used for the GPT model is English-centric.</p>
<p>While both COMETkiwi and COMET-22 show relevant results, both lexical metrics (BLEU and ChrF) show consistent degradation with GPT models. This is consistent with similar findings from (Vilar et al., 2022) on PALM-540B model. We conducted human evaluation and more thorough analysis to further understand such results.</p>
<p>From these results, we can see that the three variants of GPT models exhibit different characteristics. However, the nature and extent of these differences remain unclear and require further investigation, depending on the availability of more information regarding the models, their training data, and their training methods. This superior performance of text-davinci-003, which is achieved in a zero-shot setting, motivates further investigation into the effect of few-shot in-context learning and shot selection strategies. We investigate these questions further in the sections below.</p>
<h3>3.3 GPT Performance on High-resource Languages</h3>
<p>Given the results in the previous section, we focus on evaluating text-davinci-003 model, expanding the scope of the study to 18 language pairs and comparing its performance with that of a commercial system (Microsoft Translator) in addition to WMT SoTA systems. For consistency, in all the subsequent results, we use the term "GPT" to denote the text-davinci-003 model, unless explicitly stated otherwise.</p>
<p>We experiment with various shot selection strategies: zero-shot, random (RR), quality (QR) and relevance selected (QS) prompts as described in $\S 3.1$. We report results for 1 and 5 shots along with the best WMT systems and MS-Translator.</p>
<p>Table 3 shows the performance of GPT text-davinci-003 with few-shot setups on high-resource languages from WMT Testsets. With both reference and reference-less COMET scores, the model achieved impressive zero-shot results for all languages when translating into English. However, the few-shot configurations did not yield signifi-</p>
<table>
<thead>
<tr>
<th style="text-align: center;">System</th>
<th style="text-align: center;">COMET-22</th>
<th style="text-align: center;">COMETkiwi</th>
<th style="text-align: center;">ChrF</th>
<th style="text-align: center;">BLEU</th>
<th style="text-align: center;">COMET-22</th>
<th style="text-align: center;">COMETkiwi</th>
<th style="text-align: center;">ChrF</th>
<th style="text-align: center;">BLEU</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">DE-EN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">EN-DE</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">WMT-Best</td>
<td style="text-align: center;">85.0</td>
<td style="text-align: center;">81.4</td>
<td style="text-align: center;">58.5</td>
<td style="text-align: center;">33.4</td>
<td style="text-align: center;">87.2</td>
<td style="text-align: center;">83.6</td>
<td style="text-align: center;">64.6</td>
<td style="text-align: center;">38.4</td>
</tr>
<tr>
<td style="text-align: center;">text-davinci-002</td>
<td style="text-align: center;">73.2</td>
<td style="text-align: center;">73.1</td>
<td style="text-align: center;">46.1</td>
<td style="text-align: center;">23.3</td>
<td style="text-align: center;">82.0</td>
<td style="text-align: center;">79.0</td>
<td style="text-align: center;">56.0</td>
<td style="text-align: center;">28.6</td>
</tr>
<tr>
<td style="text-align: center;">text-davinci-003</td>
<td style="text-align: center;">$84.8^{*}$</td>
<td style="text-align: center;">$81.2^{*}$</td>
<td style="text-align: center;">56.8</td>
<td style="text-align: center;">30.9</td>
<td style="text-align: center;">$85.6^{*}$</td>
<td style="text-align: center;">$82.8^{*}$</td>
<td style="text-align: center;">$60.2^{*}$</td>
<td style="text-align: center;">$31.8^{*}$</td>
</tr>
<tr>
<td style="text-align: center;">ChatGPT</td>
<td style="text-align: center;">$84.8^{*}$</td>
<td style="text-align: center;">81.1</td>
<td style="text-align: center;">$58.3^{*}$</td>
<td style="text-align: center;">$33.4^{*}$</td>
<td style="text-align: center;">84.2</td>
<td style="text-align: center;">81.0</td>
<td style="text-align: center;">59.6</td>
<td style="text-align: center;">30.9</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ZH-EN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">EN-ZH</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">WMT-Best</td>
<td style="text-align: center;">81.0</td>
<td style="text-align: center;">77.7</td>
<td style="text-align: center;">61.1</td>
<td style="text-align: center;">33.5</td>
<td style="text-align: center;">86.7</td>
<td style="text-align: center;">82.0</td>
<td style="text-align: center;">41.1</td>
<td style="text-align: center;">44.8</td>
</tr>
<tr>
<td style="text-align: center;">text-davinci-002</td>
<td style="text-align: center;">74.1</td>
<td style="text-align: center;">73.1</td>
<td style="text-align: center;">49.6</td>
<td style="text-align: center;">20.6</td>
<td style="text-align: center;">84.0</td>
<td style="text-align: center;">79.0</td>
<td style="text-align: center;">32.1</td>
<td style="text-align: center;">36.4</td>
</tr>
<tr>
<td style="text-align: center;">text-davinci-003</td>
<td style="text-align: center;">81.6*</td>
<td style="text-align: center;">78.9*</td>
<td style="text-align: center;">$56.0^{*}$</td>
<td style="text-align: center;">25.0</td>
<td style="text-align: center;">$85.8^{*}$</td>
<td style="text-align: center;">$81.3^{*}$</td>
<td style="text-align: center;">34.6</td>
<td style="text-align: center;">38.3</td>
</tr>
<tr>
<td style="text-align: center;">ChatGPT</td>
<td style="text-align: center;">81.2</td>
<td style="text-align: center;">78.3</td>
<td style="text-align: center;">56.0</td>
<td style="text-align: center;">$25.9^{*}$</td>
<td style="text-align: center;">84.4</td>
<td style="text-align: center;">78.7</td>
<td style="text-align: center;">$36.0^{*}$</td>
<td style="text-align: center;">$40.3^{*}$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">RU-EN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">EN-RU</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">WMT-Best</td>
<td style="text-align: center;">86.0</td>
<td style="text-align: center;">81.7</td>
<td style="text-align: center;">68.9</td>
<td style="text-align: center;">45.1</td>
<td style="text-align: center;">89.5</td>
<td style="text-align: center;">84.4</td>
<td style="text-align: center;">58.3</td>
<td style="text-align: center;">32.4</td>
</tr>
<tr>
<td style="text-align: center;">text-davinci-002</td>
<td style="text-align: center;">77.5</td>
<td style="text-align: center;">76</td>
<td style="text-align: center;">58.7</td>
<td style="text-align: center;">34.9</td>
<td style="text-align: center;">85.4</td>
<td style="text-align: center;">80.9</td>
<td style="text-align: center;">51.6</td>
<td style="text-align: center;">25.1</td>
</tr>
<tr>
<td style="text-align: center;">text-davinci-003</td>
<td style="text-align: center;">$84.8^{*}$</td>
<td style="text-align: center;">$81.1^{*}$</td>
<td style="text-align: center;">64.6</td>
<td style="text-align: center;">38.5</td>
<td style="text-align: center;">$86.7^{*}$</td>
<td style="text-align: center;">$82.2^{*}$</td>
<td style="text-align: center;">$54.0^{*}$</td>
<td style="text-align: center;">$27.5^{*}$</td>
</tr>
<tr>
<td style="text-align: center;">ChatGPT</td>
<td style="text-align: center;">$84.8^{*}$</td>
<td style="text-align: center;">81.0</td>
<td style="text-align: center;">$66.5^{*}$</td>
<td style="text-align: center;">$41.0^{*}$</td>
<td style="text-align: center;">77.6</td>
<td style="text-align: center;">70.4</td>
<td style="text-align: center;">41.1</td>
<td style="text-align: center;">19.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">FR-DE</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">DE-FR</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">WMT-Best</td>
<td style="text-align: center;">89.5</td>
<td style="text-align: center;">80.7</td>
<td style="text-align: center;">81.2</td>
<td style="text-align: center;">64.8</td>
<td style="text-align: center;">85.7</td>
<td style="text-align: center;">79.5</td>
<td style="text-align: center;">74.6</td>
<td style="text-align: center;">58.4</td>
</tr>
<tr>
<td style="text-align: center;">text-davinci-002</td>
<td style="text-align: center;">66.6</td>
<td style="text-align: center;">67.9</td>
<td style="text-align: center;">45.8</td>
<td style="text-align: center;">25.9</td>
<td style="text-align: center;">64.2</td>
<td style="text-align: center;">67.6</td>
<td style="text-align: center;">44.6</td>
<td style="text-align: center;">24.5</td>
</tr>
<tr>
<td style="text-align: center;">text-davinci-003</td>
<td style="text-align: center;">84.6</td>
<td style="text-align: center;">77.9</td>
<td style="text-align: center;">$65.7^{*}$</td>
<td style="text-align: center;">$42.5^{*}$</td>
<td style="text-align: center;">78.5</td>
<td style="text-align: center;">76.1</td>
<td style="text-align: center;">58.9</td>
<td style="text-align: center;">35.6</td>
</tr>
<tr>
<td style="text-align: center;">ChatGPT</td>
<td style="text-align: center;">$84.7^{*}$</td>
<td style="text-align: center;">$78.5^{*}$</td>
<td style="text-align: center;">65.2</td>
<td style="text-align: center;">42.0</td>
<td style="text-align: center;">$81.6^{*}$</td>
<td style="text-align: center;">79.8*</td>
<td style="text-align: center;">$60.7^{*}$</td>
<td style="text-align: center;">$37.3^{*}$</td>
</tr>
</tbody>
</table>
<p>Table 2: Zero-Shot evaluation results with three GPT models on 8 language pairs from WMT22 Testset. The best scores across different systems are marked bold. * denotes the best results among GPT systems.
cant improvements over the zero-shot setup. GPT surpassed both the WMT-Best and MS-Translator systems for DE-EN, JA-EN and ZH-EN language pairs, and almost matched the best systems for the other three language pairs. On the other hand, when translating from English to other languages, the few-shot setup consistently improved over the zeroshot setup, with most gains obtained from a single high-quality shot. GPT outperformed both the WMT-Best and MS-Translator systems for EN-JA and EN-ZH language pairs. We experimented with high quality shots with relevance scores (QS) for three languages (German, Russian and Chinese), but we observed no improvements over quality shots alone. This result emphasises the importance of fewer quality shots especially when translating from English. This difference in behavior is consistent with the observations that the critical role of demonstrations within in-context learning is to provide specifications of the output space (Min et al., 2022; Anonymous, 2023a), with a denser in-context learning signal being preferred when translating from English to other languages.</p>
<p>Similar to the Zero-Shot results form §3.2, we observe that the lexical metrics are showing consistent degradation with all GPT models and configurations.</p>
<h3>3.4 GPT Performance on Low-resource and non English-centric Languages</h3>
<p>We evaluated low-resource and non English-centric languages by conducting experiments with Icelandic and Hausa as two low-resource languages
and French and German as direct translation languages. Table 4 presents the results. The few-shot setup yields modest gains, especially when translating out of English. Similar to the high-resource case, most of the gains were obtained from a single high-quality shot. The systems for both lowresource languages did not surpass the WMT-Best systems. The DE-FR and FR-DE language pairs show remarkable results, as a single-shot setup outperforms the zero-shot setup significantly. This is consistent with the previous finding of translating from English to other languages; a more dense in-context signal is essential for direct translation as well, as it enables the model to generate in the correct language better than the zero-shot behavior. Both direct systems surpasses their commercial counterparts in terms of COMET scores, but they slightly trail behind the WMT-Best systems on the COMET-22 reference-based metric.</p>
<p>Similar to the high-resource language pairs, both lexical metrics (BLEU and ChrF) showed a significant and consistent degradation. To gain further insights into this, we conducted human evaluation and performed a more in-depth analysis as discussed in $\S 4$ and $\S 5$.</p>
<h3>3.5 Document-Level MT with GPT</h3>
<p>This section explores the application of GPT to document-level machine translation. Previous studies on MT with LLMs have mainly concentrated on sentence-level translation, with only a brief mention of document translation for transfer learning by Zhang et al. (2023). Document translation, on</p>
<table>
<thead>
<tr>
<th style="text-align: center;">System</th>
<th style="text-align: center;">COMET-22</th>
<th style="text-align: center;">COMETkiwi</th>
<th style="text-align: center;">ChrF</th>
<th style="text-align: center;">BLEU</th>
<th style="text-align: center;">COMET-22</th>
<th style="text-align: center;">COMETkiwi</th>
<th style="text-align: center;">ChrF</th>
<th style="text-align: center;">BLEU</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">DE-EN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">EN-DE</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">WMT-Best</td>
<td style="text-align: center;">85.0</td>
<td style="text-align: center;">81.4</td>
<td style="text-align: center;">58.5</td>
<td style="text-align: center;">33.4</td>
<td style="text-align: center;">87.2</td>
<td style="text-align: center;">83.6</td>
<td style="text-align: center;">64.6</td>
<td style="text-align: center;">38.4</td>
</tr>
<tr>
<td style="text-align: center;">MS-Translator</td>
<td style="text-align: center;">84.7</td>
<td style="text-align: center;">81.0</td>
<td style="text-align: center;">58.5</td>
<td style="text-align: center;">33.5</td>
<td style="text-align: center;">86.8</td>
<td style="text-align: center;">83.4</td>
<td style="text-align: center;">64.2</td>
<td style="text-align: center;">37.3</td>
</tr>
<tr>
<td style="text-align: center;">GPT Zeroshot</td>
<td style="text-align: center;">84.8</td>
<td style="text-align: center;">81.2</td>
<td style="text-align: center;">56.8</td>
<td style="text-align: center;">30.9</td>
<td style="text-align: center;">85.6</td>
<td style="text-align: center;">82.8</td>
<td style="text-align: center;">60.2</td>
<td style="text-align: center;">31.8</td>
</tr>
<tr>
<td style="text-align: center;">GPT 1-Shot RR</td>
<td style="text-align: center;">84.9</td>
<td style="text-align: center;">81.3</td>
<td style="text-align: center;">56.1</td>
<td style="text-align: center;">30.4</td>
<td style="text-align: center;">86.1</td>
<td style="text-align: center;">83.0</td>
<td style="text-align: center;">60.7</td>
<td style="text-align: center;">31.9</td>
</tr>
<tr>
<td style="text-align: center;">GPT 1-Shot QR</td>
<td style="text-align: center;">84.9</td>
<td style="text-align: center;">81.3</td>
<td style="text-align: center;">56.7</td>
<td style="text-align: center;">31.1</td>
<td style="text-align: center;">85.8</td>
<td style="text-align: center;">82.8</td>
<td style="text-align: center;">60.7</td>
<td style="text-align: center;">32.4</td>
</tr>
<tr>
<td style="text-align: center;">GPT 5-Shot RR</td>
<td style="text-align: center;">85.2</td>
<td style="text-align: center;">81.5</td>
<td style="text-align: center;">56.5</td>
<td style="text-align: center;">31.2</td>
<td style="text-align: center;">$86.5^{*}$</td>
<td style="text-align: center;">$83.2^{*}$</td>
<td style="text-align: center;">61.0</td>
<td style="text-align: center;">32.4</td>
</tr>
<tr>
<td style="text-align: center;">GPT 5-Shot QR</td>
<td style="text-align: center;">$85.4^{*}$</td>
<td style="text-align: center;">$81.5^{*}$</td>
<td style="text-align: center;">57.7</td>
<td style="text-align: center;">32.4</td>
<td style="text-align: center;">86.4</td>
<td style="text-align: center;">83.1</td>
<td style="text-align: center;">$61.3^{*}$</td>
<td style="text-align: center;">$33.2^{*}$</td>
</tr>
<tr>
<td style="text-align: center;">GPT 5-Shot QS</td>
<td style="text-align: center;">85.0</td>
<td style="text-align: center;">81.3</td>
<td style="text-align: center;">$57.8^{*}$</td>
<td style="text-align: center;">$32.5^{*}$</td>
<td style="text-align: center;">85.9</td>
<td style="text-align: center;">82.9</td>
<td style="text-align: center;">60.8</td>
<td style="text-align: center;">32.7</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">CS-EN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">EN-CS</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">WMT-Best</td>
<td style="text-align: center;">89.0</td>
<td style="text-align: center;">82.5</td>
<td style="text-align: center;">79.3</td>
<td style="text-align: center;">64.2</td>
<td style="text-align: center;">91.9</td>
<td style="text-align: center;">85.3</td>
<td style="text-align: center;">68.2</td>
<td style="text-align: center;">45.8</td>
</tr>
<tr>
<td style="text-align: center;">MS-Translator</td>
<td style="text-align: center;">87.4</td>
<td style="text-align: center;">82.2</td>
<td style="text-align: center;">74.0</td>
<td style="text-align: center;">54.9</td>
<td style="text-align: center;">90.6</td>
<td style="text-align: center;">84.2</td>
<td style="text-align: center;">65.6</td>
<td style="text-align: center;">42.1</td>
</tr>
<tr>
<td style="text-align: center;">GPT Zeroshot</td>
<td style="text-align: center;">86.2</td>
<td style="text-align: center;">82.0</td>
<td style="text-align: center;">67.5</td>
<td style="text-align: center;">44.5</td>
<td style="text-align: center;">88.6</td>
<td style="text-align: center;">82.9</td>
<td style="text-align: center;">57.9</td>
<td style="text-align: center;">31.3</td>
</tr>
<tr>
<td style="text-align: center;">GPT 1-Shot RR</td>
<td style="text-align: center;">86.6</td>
<td style="text-align: center;">82.3</td>
<td style="text-align: center;">67.9</td>
<td style="text-align: center;">45.4</td>
<td style="text-align: center;">$89.7^{*}$</td>
<td style="text-align: center;">$84.0^{*}$</td>
<td style="text-align: center;">58.3</td>
<td style="text-align: center;">31.6</td>
</tr>
<tr>
<td style="text-align: center;">GPT 1-Shot QR</td>
<td style="text-align: center;">86.4</td>
<td style="text-align: center;">82.3</td>
<td style="text-align: center;">67.8</td>
<td style="text-align: center;">45.0</td>
<td style="text-align: center;">89.2</td>
<td style="text-align: center;">83.6</td>
<td style="text-align: center;">58.6</td>
<td style="text-align: center;">32.5</td>
</tr>
<tr>
<td style="text-align: center;">GPT 5-Shot RR</td>
<td style="text-align: center;">86.6</td>
<td style="text-align: center;">82.3</td>
<td style="text-align: center;">66.4</td>
<td style="text-align: center;">44.2</td>
<td style="text-align: center;">89.4</td>
<td style="text-align: center;">83.8</td>
<td style="text-align: center;">58.6</td>
<td style="text-align: center;">32.0</td>
</tr>
<tr>
<td style="text-align: center;">GPT 5-Shot QR</td>
<td style="text-align: center;">$86.9^{*}$</td>
<td style="text-align: center;">$82.5^{*}$</td>
<td style="text-align: center;">$69.2^{*}$</td>
<td style="text-align: center;">$47.5^{*}$</td>
<td style="text-align: center;">89.0</td>
<td style="text-align: center;">83.3</td>
<td style="text-align: center;">$59.0^{*}$</td>
<td style="text-align: center;">$32.9^{*}$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">JA-EN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">EN-JA</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">WMT-Best</td>
<td style="text-align: center;">81.6</td>
<td style="text-align: center;">80.3</td>
<td style="text-align: center;">49.8</td>
<td style="text-align: center;">24.8</td>
<td style="text-align: center;">89.3</td>
<td style="text-align: center;">85.8</td>
<td style="text-align: center;">36.8</td>
<td style="text-align: center;">27.6</td>
</tr>
<tr>
<td style="text-align: center;">MS-Translator</td>
<td style="text-align: center;">81.5</td>
<td style="text-align: center;">80.1</td>
<td style="text-align: center;">49.6</td>
<td style="text-align: center;">24.5</td>
<td style="text-align: center;">88.0</td>
<td style="text-align: center;">85.3</td>
<td style="text-align: center;">34.9</td>
<td style="text-align: center;">25.1</td>
</tr>
<tr>
<td style="text-align: center;">GPT Zeroshot</td>
<td style="text-align: center;">81.5</td>
<td style="text-align: center;">80.7</td>
<td style="text-align: center;">47.7</td>
<td style="text-align: center;">21.1</td>
<td style="text-align: center;">87.8</td>
<td style="text-align: center;">84.8</td>
<td style="text-align: center;">31.2</td>
<td style="text-align: center;">21.2</td>
</tr>
<tr>
<td style="text-align: center;">GPT 1-Shot RR</td>
<td style="text-align: center;">81.7</td>
<td style="text-align: center;">80.7</td>
<td style="text-align: center;">46.8</td>
<td style="text-align: center;">20.2</td>
<td style="text-align: center;">88.3</td>
<td style="text-align: center;">85.1</td>
<td style="text-align: center;">31.8</td>
<td style="text-align: center;">22.0</td>
</tr>
<tr>
<td style="text-align: center;">GPT 1-Shot QR</td>
<td style="text-align: center;">81.6</td>
<td style="text-align: center;">80.8</td>
<td style="text-align: center;">$48.3^{*}$</td>
<td style="text-align: center;">22.1</td>
<td style="text-align: center;">$88.4^{*}$</td>
<td style="text-align: center;">85.3</td>
<td style="text-align: center;">$32.2^{*}$</td>
<td style="text-align: center;">$22.5^{*}$</td>
</tr>
<tr>
<td style="text-align: center;">GPT 5-Shot RR</td>
<td style="text-align: center;">$82.0^{*}$</td>
<td style="text-align: center;">$80.9^{*}$</td>
<td style="text-align: center;">48.2</td>
<td style="text-align: center;">$22.4^{*}$</td>
<td style="text-align: center;">88.2</td>
<td style="text-align: center;">$85.4^{*}$</td>
<td style="text-align: center;">31.7</td>
<td style="text-align: center;">21.4</td>
</tr>
<tr>
<td style="text-align: center;">GPT 5-Shot QR</td>
<td style="text-align: center;">81.8</td>
<td style="text-align: center;">80.8</td>
<td style="text-align: center;">47.2</td>
<td style="text-align: center;">21.0</td>
<td style="text-align: center;">88.2</td>
<td style="text-align: center;">85.3</td>
<td style="text-align: center;">31.1</td>
<td style="text-align: center;">21.6</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ZH-EN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">EN-ZH</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">WMT-Best</td>
<td style="text-align: center;">81.0</td>
<td style="text-align: center;">77.7</td>
<td style="text-align: center;">61.1</td>
<td style="text-align: center;">33.5</td>
<td style="text-align: center;">86.7</td>
<td style="text-align: center;">82.0</td>
<td style="text-align: center;">41.1</td>
<td style="text-align: center;">44.8</td>
</tr>
<tr>
<td style="text-align: center;">MS-Translator</td>
<td style="text-align: center;">80.4</td>
<td style="text-align: center;">77.6</td>
<td style="text-align: center;">57.7</td>
<td style="text-align: center;">27.9</td>
<td style="text-align: center;">86.1</td>
<td style="text-align: center;">81.4</td>
<td style="text-align: center;">43.1</td>
<td style="text-align: center;">48.1</td>
</tr>
<tr>
<td style="text-align: center;">GPT Zeroshot</td>
<td style="text-align: center;">$81.6^{*}$</td>
<td style="text-align: center;">$78.9^{*}$</td>
<td style="text-align: center;">$56.0^{*}$</td>
<td style="text-align: center;">$25.0^{*}$</td>
<td style="text-align: center;">85.8</td>
<td style="text-align: center;">81.3</td>
<td style="text-align: center;">34.6</td>
<td style="text-align: center;">38.3</td>
</tr>
<tr>
<td style="text-align: center;">GPT 1-Shot RR</td>
<td style="text-align: center;">80.9</td>
<td style="text-align: center;">78.2</td>
<td style="text-align: center;">55.2</td>
<td style="text-align: center;">24.2</td>
<td style="text-align: center;">86.7</td>
<td style="text-align: center;">81.8</td>
<td style="text-align: center;">38.7</td>
<td style="text-align: center;">42.8</td>
</tr>
<tr>
<td style="text-align: center;">GPT 1-Shot QR</td>
<td style="text-align: center;">81.2</td>
<td style="text-align: center;">78.8</td>
<td style="text-align: center;">55.3</td>
<td style="text-align: center;">24.2</td>
<td style="text-align: center;">86.1</td>
<td style="text-align: center;">81.5</td>
<td style="text-align: center;">35.5</td>
<td style="text-align: center;">38.8</td>
</tr>
<tr>
<td style="text-align: center;">GPT 5-Shot RR</td>
<td style="text-align: center;">81.1</td>
<td style="text-align: center;">78.8</td>
<td style="text-align: center;">55.0</td>
<td style="text-align: center;">24.4</td>
<td style="text-align: center;">87.0</td>
<td style="text-align: center;">82.0</td>
<td style="text-align: center;">37.1</td>
<td style="text-align: center;">41.3</td>
</tr>
<tr>
<td style="text-align: center;">GPT 5-Shot QR</td>
<td style="text-align: center;">81.1</td>
<td style="text-align: center;">78.7</td>
<td style="text-align: center;">54.7</td>
<td style="text-align: center;">23.8</td>
<td style="text-align: center;">$87.0^{*}$</td>
<td style="text-align: center;">$82.2^{*}$</td>
<td style="text-align: center;">$39.8^{*}$</td>
<td style="text-align: center;">$43.7^{*}$</td>
</tr>
<tr>
<td style="text-align: center;">GPT 5-Shot QS</td>
<td style="text-align: center;">81.0</td>
<td style="text-align: center;">78.5</td>
<td style="text-align: center;">55.5</td>
<td style="text-align: center;">24.6</td>
<td style="text-align: center;">86.2</td>
<td style="text-align: center;">81.5</td>
<td style="text-align: center;">38.3</td>
<td style="text-align: center;">41.8</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">RU-EN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">EN-RU</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">WMT-Best</td>
<td style="text-align: center;">86.0</td>
<td style="text-align: center;">81.7</td>
<td style="text-align: center;">68.9</td>
<td style="text-align: center;">45.1</td>
<td style="text-align: center;">89.5</td>
<td style="text-align: center;">84.4</td>
<td style="text-align: center;">58.3</td>
<td style="text-align: center;">32.4</td>
</tr>
<tr>
<td style="text-align: center;">MS-Translator</td>
<td style="text-align: center;">85.2</td>
<td style="text-align: center;">80.7</td>
<td style="text-align: center;">68.3</td>
<td style="text-align: center;">43.9</td>
<td style="text-align: center;">87.4</td>
<td style="text-align: center;">82.9</td>
<td style="text-align: center;">58.1</td>
<td style="text-align: center;">33.1</td>
</tr>
<tr>
<td style="text-align: center;">GPT Zeroshot</td>
<td style="text-align: center;">84.8</td>
<td style="text-align: center;">81.1</td>
<td style="text-align: center;">64.6</td>
<td style="text-align: center;">38.5</td>
<td style="text-align: center;">86.7</td>
<td style="text-align: center;">82.2</td>
<td style="text-align: center;">54.0</td>
<td style="text-align: center;">27.5</td>
</tr>
<tr>
<td style="text-align: center;">GPT 1-Shot RR</td>
<td style="text-align: center;">84.1</td>
<td style="text-align: center;">80.6</td>
<td style="text-align: center;">63.3</td>
<td style="text-align: center;">37.9</td>
<td style="text-align: center;">86.4</td>
<td style="text-align: center;">81.9</td>
<td style="text-align: center;">54.3</td>
<td style="text-align: center;">28.1</td>
</tr>
<tr>
<td style="text-align: center;">GPT 1-Shot QR</td>
<td style="text-align: center;">84.9</td>
<td style="text-align: center;">$81.2^{*}$</td>
<td style="text-align: center;">$65.4^{*}$</td>
<td style="text-align: center;">40.1</td>
<td style="text-align: center;">86.9</td>
<td style="text-align: center;">82.4</td>
<td style="text-align: center;">53.8</td>
<td style="text-align: center;">27.5</td>
</tr>
<tr>
<td style="text-align: center;">GPT 5-Shot RR</td>
<td style="text-align: center;">84.9</td>
<td style="text-align: center;">$81.2^{*}$</td>
<td style="text-align: center;">63.9</td>
<td style="text-align: center;">39.0</td>
<td style="text-align: center;">86.8</td>
<td style="text-align: center;">82.3</td>
<td style="text-align: center;">54.3</td>
<td style="text-align: center;">27.9</td>
</tr>
<tr>
<td style="text-align: center;">GPT 5-Shot QR</td>
<td style="text-align: center;">84.9</td>
<td style="text-align: center;">81.0</td>
<td style="text-align: center;">$65.4^{*}$</td>
<td style="text-align: center;">40.0</td>
<td style="text-align: center;">$87.0^{*}$</td>
<td style="text-align: center;">$82.4^{*}$</td>
<td style="text-align: center;">$54.4^{*}$</td>
<td style="text-align: center;">$28.2^{*}$</td>
</tr>
<tr>
<td style="text-align: center;">GPT 5-Shot QS</td>
<td style="text-align: center;">$85.0^{*}$</td>
<td style="text-align: center;">$81.2^{*}$</td>
<td style="text-align: center;">65.3</td>
<td style="text-align: center;">$40.2^{*}$</td>
<td style="text-align: center;">86.4</td>
<td style="text-align: center;">82.2</td>
<td style="text-align: center;">$54.4^{*}$</td>
<td style="text-align: center;">28.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">UK-EN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">EN-UK</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">WMT-Best</td>
<td style="text-align: center;">86.0</td>
<td style="text-align: center;">81.5</td>
<td style="text-align: center;">67.3</td>
<td style="text-align: center;">44.6</td>
<td style="text-align: center;">88.8</td>
<td style="text-align: center;">83.4</td>
<td style="text-align: center;">59.3</td>
<td style="text-align: center;">32.5</td>
</tr>
<tr>
<td style="text-align: center;">MS-Translator</td>
<td style="text-align: center;">83.5</td>
<td style="text-align: center;">79.7</td>
<td style="text-align: center;">65.3</td>
<td style="text-align: center;">42.4</td>
<td style="text-align: center;">86.1</td>
<td style="text-align: center;">81.9</td>
<td style="text-align: center;">56.1</td>
<td style="text-align: center;">28.2</td>
</tr>
<tr>
<td style="text-align: center;">GPT Zeroshot</td>
<td style="text-align: center;">83.5</td>
<td style="text-align: center;">80.1</td>
<td style="text-align: center;">59.8</td>
<td style="text-align: center;">34.8</td>
<td style="text-align: center;">83.7</td>
<td style="text-align: center;">79.5</td>
<td style="text-align: center;">49.6</td>
<td style="text-align: center;">21.1</td>
</tr>
<tr>
<td style="text-align: center;">GPT 1-Shot RR</td>
<td style="text-align: center;">83.5</td>
<td style="text-align: center;">80.3</td>
<td style="text-align: center;">60.3</td>
<td style="text-align: center;">35.6</td>
<td style="text-align: center;">84.7</td>
<td style="text-align: center;">80.2</td>
<td style="text-align: center;">50.1</td>
<td style="text-align: center;">21.2</td>
</tr>
<tr>
<td style="text-align: center;">GPT 1-Shot QR</td>
<td style="text-align: center;">83.8</td>
<td style="text-align: center;">80.3</td>
<td style="text-align: center;">61.4</td>
<td style="text-align: center;">37.5</td>
<td style="text-align: center;">85.1</td>
<td style="text-align: center;">80.5</td>
<td style="text-align: center;">50.5</td>
<td style="text-align: center;">21.9</td>
</tr>
<tr>
<td style="text-align: center;">GPT 5-Shot RR</td>
<td style="text-align: center;">83.6</td>
<td style="text-align: center;">80.3</td>
<td style="text-align: center;">58.8</td>
<td style="text-align: center;">34.4</td>
<td style="text-align: center;">$85.4^{*}$</td>
<td style="text-align: center;">$80.8^{*}$</td>
<td style="text-align: center;">$50.9^{*}$</td>
<td style="text-align: center;">$22.6^{*}$</td>
</tr>
<tr>
<td style="text-align: center;">GPT 5-Shot QR</td>
<td style="text-align: center;">$83.9^{*}$</td>
<td style="text-align: center;">$80.3^{*}$</td>
<td style="text-align: center;">$62.1^{*}$</td>
<td style="text-align: center;">$38.4^{*}$</td>
<td style="text-align: center;">85.4</td>
<td style="text-align: center;">80.6</td>
<td style="text-align: center;">50.6</td>
<td style="text-align: center;">22.1</td>
</tr>
</tbody>
</table>
<p>Table 3: Zero-Shot and Few-Shots evaluteion results with GPT(text-davinci-003) on high resource languages from WMT Testsets. The best scores across different systems are marked bold. * denotes the best results among GPT systems.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">System</th>
<th style="text-align: center;">COMET-22</th>
<th style="text-align: center;">COMETkiwi</th>
<th style="text-align: center;">ChrF</th>
<th style="text-align: center;">BLEU</th>
<th style="text-align: center;">COMET-22</th>
<th style="text-align: center;">COMETkiwi</th>
<th style="text-align: center;">ChrF</th>
<th style="text-align: center;">BLEU</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">IS-EN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">EN-IS</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">WMT-Best</td>
<td style="text-align: center;">87.0</td>
<td style="text-align: center;">81.4</td>
<td style="text-align: center;">62.3</td>
<td style="text-align: center;">41.7</td>
<td style="text-align: center;">86.8</td>
<td style="text-align: center;">81.8</td>
<td style="text-align: center;">59.6</td>
<td style="text-align: center;">33.3</td>
</tr>
<tr>
<td style="text-align: center;">MS-Translator</td>
<td style="text-align: center;">85.9</td>
<td style="text-align: center;">80.3</td>
<td style="text-align: center;">62.8</td>
<td style="text-align: center;">40.5</td>
<td style="text-align: center;">84.3</td>
<td style="text-align: center;">80.2</td>
<td style="text-align: center;">56.8</td>
<td style="text-align: center;">28.7</td>
</tr>
<tr>
<td style="text-align: center;">GPT Zeroshot</td>
<td style="text-align: center;">82.1</td>
<td style="text-align: center;">78.7</td>
<td style="text-align: center;">55.6</td>
<td style="text-align: center;">31.9</td>
<td style="text-align: center;">76.3</td>
<td style="text-align: center;">74.0</td>
<td style="text-align: center;">43.5</td>
<td style="text-align: center;">15.9</td>
</tr>
<tr>
<td style="text-align: center;">GPT 1-Shot RR</td>
<td style="text-align: center;">84.1</td>
<td style="text-align: center;">80.2</td>
<td style="text-align: center;">57.8</td>
<td style="text-align: center;">34.7</td>
<td style="text-align: center;">77.0</td>
<td style="text-align: center;">74.6</td>
<td style="text-align: center;">43.7</td>
<td style="text-align: center;">15.3</td>
</tr>
<tr>
<td style="text-align: center;">GPT 1-Shot QR</td>
<td style="text-align: center;">83.5</td>
<td style="text-align: center;">79.7</td>
<td style="text-align: center;">56.7</td>
<td style="text-align: center;">33.3</td>
<td style="text-align: center;">77.4</td>
<td style="text-align: center;">75.1</td>
<td style="text-align: center;">44.5</td>
<td style="text-align: center;">16.2</td>
</tr>
<tr>
<td style="text-align: center;">GPT 5-Shot RR</td>
<td style="text-align: center;">$84.4^{*}$</td>
<td style="text-align: center;">$80.4^{*}$</td>
<td style="text-align: center;">$58.1^{*}$</td>
<td style="text-align: center;">$35.0^{*}$</td>
<td style="text-align: center;">$77.9^{*}$</td>
<td style="text-align: center;">$75.2^{*}$</td>
<td style="text-align: center;">$45.1^{*}$</td>
<td style="text-align: center;">$16.8^{*}$</td>
</tr>
<tr>
<td style="text-align: center;">GPT 5-Shot QR</td>
<td style="text-align: center;">84.2</td>
<td style="text-align: center;">80.2</td>
<td style="text-align: center;">58.0</td>
<td style="text-align: center;">35.2</td>
<td style="text-align: center;">76.0</td>
<td style="text-align: center;">74.1</td>
<td style="text-align: center;">44.1</td>
<td style="text-align: center;">16.3</td>
</tr>
<tr>
<td style="text-align: center;">HA-EN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">EN-HA</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">WMT-Best</td>
<td style="text-align: center;">80.0</td>
<td style="text-align: center;">74.5</td>
<td style="text-align: center;">48.7</td>
<td style="text-align: center;">21.0</td>
<td style="text-align: center;">79.8</td>
<td style="text-align: center;">61.5</td>
<td style="text-align: center;">51.1</td>
<td style="text-align: center;">20.1</td>
</tr>
<tr>
<td style="text-align: center;">MS-Translator</td>
<td style="text-align: center;">73.3</td>
<td style="text-align: center;">68.5</td>
<td style="text-align: center;">43.4</td>
<td style="text-align: center;">16.2</td>
<td style="text-align: center;">72.5</td>
<td style="text-align: center;">57.2</td>
<td style="text-align: center;">38.4</td>
<td style="text-align: center;">10.3</td>
</tr>
<tr>
<td style="text-align: center;">GPT Zeroshot</td>
<td style="text-align: center;">76.1</td>
<td style="text-align: center;">73.1</td>
<td style="text-align: center;">45.5</td>
<td style="text-align: center;">17.3</td>
<td style="text-align: center;">73.3</td>
<td style="text-align: center;">58.6</td>
<td style="text-align: center;">$38.4^{*}$</td>
<td style="text-align: center;">$9.4^{*}$</td>
</tr>
<tr>
<td style="text-align: center;">GPT 1-Shot RR</td>
<td style="text-align: center;">75.7</td>
<td style="text-align: center;">72.7</td>
<td style="text-align: center;">45.7</td>
<td style="text-align: center;">17.3</td>
<td style="text-align: center;">74.0</td>
<td style="text-align: center;">59.0</td>
<td style="text-align: center;">$38.4^{*}$</td>
<td style="text-align: center;">8.8</td>
</tr>
<tr>
<td style="text-align: center;">GPT 1-Shot QR</td>
<td style="text-align: center;">78.1</td>
<td style="text-align: center;">74.4</td>
<td style="text-align: center;">$47.5^{*}$</td>
<td style="text-align: center;">$19.1^{*}$</td>
<td style="text-align: center;">$74.1^{*}$</td>
<td style="text-align: center;">$59.7^{*}$</td>
<td style="text-align: center;">37.8</td>
<td style="text-align: center;">8.9</td>
</tr>
<tr>
<td style="text-align: center;">GPT 5-Shot RR</td>
<td style="text-align: center;">75.5</td>
<td style="text-align: center;">72.2</td>
<td style="text-align: center;">45.9</td>
<td style="text-align: center;">17.8</td>
<td style="text-align: center;">72.1</td>
<td style="text-align: center;">57.7</td>
<td style="text-align: center;">36.0</td>
<td style="text-align: center;">8.0</td>
</tr>
<tr>
<td style="text-align: center;">GPT 5-Shot QR</td>
<td style="text-align: center;">$78.2^{*}$</td>
<td style="text-align: center;">$74.5^{*}$</td>
<td style="text-align: center;">$47.5^{*}$</td>
<td style="text-align: center;">18.9</td>
<td style="text-align: center;">72.6</td>
<td style="text-align: center;">58.5</td>
<td style="text-align: center;">36.9</td>
<td style="text-align: center;">8.5</td>
</tr>
<tr>
<td style="text-align: center;">FR-DE</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">DE-FR</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">WMT-Best</td>
<td style="text-align: center;">89.5</td>
<td style="text-align: center;">80.7</td>
<td style="text-align: center;">81.2</td>
<td style="text-align: center;">64.8</td>
<td style="text-align: center;">85.7</td>
<td style="text-align: center;">79.5</td>
<td style="text-align: center;">74.6</td>
<td style="text-align: center;">58.4</td>
</tr>
<tr>
<td style="text-align: center;">MS-Translator</td>
<td style="text-align: center;">85.4</td>
<td style="text-align: center;">78.9</td>
<td style="text-align: center;">67.5</td>
<td style="text-align: center;">45.3</td>
<td style="text-align: center;">82.7</td>
<td style="text-align: center;">79.0</td>
<td style="text-align: center;">65.0</td>
<td style="text-align: center;">42.0</td>
</tr>
<tr>
<td style="text-align: center;">GPT Zeroshot</td>
<td style="text-align: center;">84.6</td>
<td style="text-align: center;">77.9</td>
<td style="text-align: center;">65.7</td>
<td style="text-align: center;">42.5</td>
<td style="text-align: center;">78.5</td>
<td style="text-align: center;">76.1</td>
<td style="text-align: center;">58.9</td>
<td style="text-align: center;">35.6</td>
</tr>
<tr>
<td style="text-align: center;">GPT 1-Shot RR</td>
<td style="text-align: center;">86.1</td>
<td style="text-align: center;">79.6</td>
<td style="text-align: center;">65.1</td>
<td style="text-align: center;">41.0</td>
<td style="text-align: center;">83.1</td>
<td style="text-align: center;">80.5</td>
<td style="text-align: center;">60.3</td>
<td style="text-align: center;">36.9</td>
</tr>
<tr>
<td style="text-align: center;">GPT 1-Shot QR</td>
<td style="text-align: center;">86.4</td>
<td style="text-align: center;">80.0</td>
<td style="text-align: center;">67.0</td>
<td style="text-align: center;">43.9</td>
<td style="text-align: center;">83.2</td>
<td style="text-align: center;">80.8</td>
<td style="text-align: center;">61.2</td>
<td style="text-align: center;">38.1</td>
</tr>
<tr>
<td style="text-align: center;">GPT 5-Shot RR</td>
<td style="text-align: center;">86.6</td>
<td style="text-align: center;">80.0</td>
<td style="text-align: center;">65.2</td>
<td style="text-align: center;">41.6</td>
<td style="text-align: center;">$83.6^{*}$</td>
<td style="text-align: center;">$\mathbf{8 0 . 9}^{*}$</td>
<td style="text-align: center;">60.1</td>
<td style="text-align: center;">37.1</td>
</tr>
<tr>
<td style="text-align: center;">GPT 5-Shot QR</td>
<td style="text-align: center;">$86.7^{*}$</td>
<td style="text-align: center;">$80.2^{*}$</td>
<td style="text-align: center;">$67.7^{*}$</td>
<td style="text-align: center;">$44.8^{*}$</td>
<td style="text-align: center;">83.2</td>
<td style="text-align: center;">80.7</td>
<td style="text-align: center;">$62.1^{*}$</td>
<td style="text-align: center;">$39.3^{*}$</td>
</tr>
</tbody>
</table>
<p>Table 4: Zero-Shot and Few-Shots evaluation results with GPT (text-davinci-003) on low resources and nonEnglish centric translation directions from WMT Testsets. The best scores across different systems are marked bold. * denotes the best results among GPT systems.
the other hand, has received considerable attention for transformer models, with inconclusive findings as to the efficacy of the additional context. Sun et al. (2020) challenge some of the prior studies and demonstrate that a simple modification of the training to vary the document lengths can significantly enhance the performance of a standard transformer architecture for document-to-document translation. We hypothesize that GPT can excel at document-to-document translation, as it is trained on large contexts. Moreover, translating entire documents can reduce the number of API calls and thus improve the computational efficiency and latency. We argue that document translation improvements may need better metrics to capture its potential. Hence, in this section, we report results using doc-BLEU (Liu et al., 2020) and doc-COMET metrics as described in $\S 2.4$, in addition to our sentence-level metrics.</p>
<p>Evaluating Document-level Translations A document-level translation does not necessarily keep sentence-level alignments intact. We try to prompt GPT to keep sentence-level alignment intact by emphasizing sentence separation in the prompt. Our prompt template can be found in Figure 18 from the appendix. However, we find that we still need to restore sentence-level alignment with source for some of the documents in the test set. In all cases, we find two types of mismatch
that we need to restore. First, sentences that were written in the source over two lines and their translation is one line. In that case, we insert a new line break to match the position of the new line break in the source sentences. Second, sentences that are skipped. In that case, we replace empty lines at the end of the documents with empty lines in place of the skipped sentences.</p>
<p>We need to restore sentence-level alignment to calculate metrics that were mainly developed for sentence-level evaluation such as the COMET-22 and COMETkiwi models that we are using. We also follow (Liu et al., 2020) and report SacreBLEU calculated on the document level. For neural network based metrics, we extend the COMETkiwi model for document level evaluation as described in $\S 2.4$.</p>
<p>Experiment 1: We conduct a series of experiments on zero-shot MT using News Commentary dataset, varying the window length from 1 (sentence-level) to 32 in powers of two ${ }^{14}$. Table 5 shows that increasing the window size leads to improvements across all metrics. However, the gains in lexical metrics (BLEU and ChrF) are larger than in neural metrics (COMET-22 and COMETkiwi). The document-based metric (doc-BLEU and docCOMETkiwi) also exhibit similar improvements</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>to the sentence-based metric. Remarkably, as the window size grows, the performance surpasses MSTranslator model and approaches the WMT-Best systems. This is consistent with the findings of Sun et al. (2020) for conventional MT models. The table also displays the total number of requests for each window size. We observe that the number of requests decreases dramatically as the window size increases, while the performance either improves significantly or remains relatively stable depending on the metric used. Therefore, this document-level setup achieves high efficiency without compromising the quality.</p>
<p>Experiment 2: The second set of experiments investigates few-shot translation for the document setting. Following the sentence experiments, we focus on using 5 -shots. We also use the News Commentary dataset, which has document-level annotations. Table 6 summarizes the results. The first two rows show the best WMT22 and the MSTranslator results for reference.</p>
<p>The following rows are named GPT-XX-YY where XX stands for the scope of translation (sentence or document) and YY stands for the source of the 5 shots (QR,DR,DF or DH as explained below). Rows GPT-Sent-QR and GPT-Sent-DR show results for sentence-level translation. The former uses the same quality-based shots from Table 3, while the latter uses 5 randomly selected shots from the document set, excluding the test data. We perform document translation (referred to as Doc in the table) for a window of 10 sentences in the following rows. Rows named GPT-Doc-QR and GPT-Doc-DR use the same shots as the sentence case. For row GPT-Doc-DF, we select a random document from the document data pool and use the first 5 sentences of the document as shots (i.e. document first DF). For row GPT-Doc-DH, we store GPT outputs in history for use in shots. We translate the first document 0 -shot, and the subsequent documents 5 -shots. For shot selection, we pick a random document from the previously translated documents and use the first 5 sentences as shots (i.e. document history DH). The results indicate that document translation outperforms sentence translation across metrics. However, while few-shots yield some consistent gains for sentence translation, this is not the case for document translation. This may be explained by the fact that document translation provides enough context, making few-shots redundant. It can be also observed from the table
that the Doc-COMETKiwi shows more gain than the sentence level metrics but this might need more indepth analysis to verify.</p>
<h3>3.6 Robustness Toward Domain Shift</h3>
<p>We use the WMT datasets to examine how domain shift affects the performance of GPT models on German and Chinese, both from and to English. The WMT22 datasets span four domains: Conversational, News, e-Commerce and Social. Table 7 shows the scores of the four domains on the WMT testsets.</p>
<p>GPT achieves remarkable improvements on the conversational domain for DE-EN, ZH-EN and EN-ZH, as evidenced by both COMET and lexical scores (BLEU and ChrF). This contrasts with previous observations where lexical scores consistently deteriorate with GPT models.</p>
<p>GPT performs comparably to the other systems on the news domain according to COMET scores for all directions. It surpasses both other systems on DE-EN, while slightly trailing behind on ENDE. For ZH-EN and EN-ZH, GPT exceeds MSTranslator, but falls slightly short of WMT-Best system. However, GPT scores significantly lower in terms of BLEU metric for both ZH-EN and ENDE.</p>
<p>GPT clearly outperforms both systems on ZHEN and matches WMT-Best on DE-EN for the ecommerce domain. It slightly lags behind on other directions. In this domain, we observe consistent lower scores in BLEU metric for all directions even for ZH-EN which outperforms significantly on both COMET metrics.</p>
<p>GPT outperforms both systems on DE-EN for the social domain. However, on ZH-EN and ENZH, GPT only surpasses them on COMETkiwi, while showing lower BLEU score for all directions with a significant difference in ZH-EN which exhibits substantial gains on COMETkiwi.</p>
<p>The results demonstrate GPT's robust translation capabilities across different domains and languages. It performs well on DE-EN, ZH-EN and EN-ZH for all domains. However, we observe a discrepancy on lexical metrics for ZH-EN and DE-EN on News and Social domains even with GPT's high performance on those languages. We conduct a further examination of the ZH-EN results to gain more insights. We find that the news from Chinese outlets follows a more templatic style especially in the prefix of the news. For NMT systems that are trained</p>
<table>
<thead>
<tr>
<th style="text-align: center;">System</th>
<th style="text-align: center;">COMET-22</th>
<th style="text-align: center;">COMETkiwi</th>
<th style="text-align: center;">Doc-COMETkiwi</th>
<th style="text-align: center;">ChrF</th>
<th style="text-align: center;">BLEU</th>
<th style="text-align: center;">Doc-BLEU</th>
<th style="text-align: center;">GPT Requests</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">DE-EN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">WMT-Best</td>
<td style="text-align: center;">85.0</td>
<td style="text-align: center;">81.4</td>
<td style="text-align: center;">79.9</td>
<td style="text-align: center;">58.5</td>
<td style="text-align: center;">33.4</td>
<td style="text-align: center;">35.2</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">MS-Translator</td>
<td style="text-align: center;">84.7</td>
<td style="text-align: center;">81.0</td>
<td style="text-align: center;">79.5</td>
<td style="text-align: center;">58.5</td>
<td style="text-align: center;">33.5</td>
<td style="text-align: center;">35.2</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">GPT Sent ZS</td>
<td style="text-align: center;">84.8</td>
<td style="text-align: center;">81.2</td>
<td style="text-align: center;">79.5</td>
<td style="text-align: center;">56.8</td>
<td style="text-align: center;">30.9</td>
<td style="text-align: center;">32.3</td>
<td style="text-align: center;">1984</td>
</tr>
<tr>
<td style="text-align: center;">GPT Doc ZS w=2</td>
<td style="text-align: center;">85.1</td>
<td style="text-align: center;">81.4*</td>
<td style="text-align: center;">80.0</td>
<td style="text-align: center;">57.8</td>
<td style="text-align: center;">32.6</td>
<td style="text-align: center;">34.4</td>
<td style="text-align: center;">1055</td>
</tr>
<tr>
<td style="text-align: center;">GPT Doc ZS w=4</td>
<td style="text-align: center;">85.2*</td>
<td style="text-align: center;">81.3</td>
<td style="text-align: center;">80.2*</td>
<td style="text-align: center;">57.9</td>
<td style="text-align: center;">32.8</td>
<td style="text-align: center;">34.5</td>
<td style="text-align: center;">607</td>
</tr>
<tr>
<td style="text-align: center;">GPT Doc ZS w=8</td>
<td style="text-align: center;">85.1</td>
<td style="text-align: center;">81.2</td>
<td style="text-align: center;">80.2</td>
<td style="text-align: center;">57.9</td>
<td style="text-align: center;">33.0</td>
<td style="text-align: center;">34.7</td>
<td style="text-align: center;">401</td>
</tr>
<tr>
<td style="text-align: center;">GPT Doc ZS w=16</td>
<td style="text-align: center;">85.2</td>
<td style="text-align: center;">81.2</td>
<td style="text-align: center;">80.2</td>
<td style="text-align: center;">58.0*</td>
<td style="text-align: center;">33.1*</td>
<td style="text-align: center;">34.8*</td>
<td style="text-align: center;">310</td>
</tr>
<tr>
<td style="text-align: center;">GPT Doc ZS w=32</td>
<td style="text-align: center;">85.1</td>
<td style="text-align: center;">81.2</td>
<td style="text-align: center;">80.2</td>
<td style="text-align: center;">57.9</td>
<td style="text-align: center;">33.1</td>
<td style="text-align: center;">34.8</td>
<td style="text-align: center;">274</td>
</tr>
<tr>
<td style="text-align: center;">EN-DE</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">WMT-Best</td>
<td style="text-align: center;">87.2</td>
<td style="text-align: center;">83.6</td>
<td style="text-align: center;">83.1</td>
<td style="text-align: center;">64.6</td>
<td style="text-align: center;">38.4</td>
<td style="text-align: center;">40</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">MS-Translator</td>
<td style="text-align: center;">86.8</td>
<td style="text-align: center;">83.4</td>
<td style="text-align: center;">83</td>
<td style="text-align: center;">64.2</td>
<td style="text-align: center;">37.3</td>
<td style="text-align: center;">38.8</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">GPT Sent ZS</td>
<td style="text-align: center;">85.6</td>
<td style="text-align: center;">82.8</td>
<td style="text-align: center;">82.2</td>
<td style="text-align: center;">60.2</td>
<td style="text-align: center;">31.8</td>
<td style="text-align: center;">33.1</td>
<td style="text-align: center;">2037</td>
</tr>
<tr>
<td style="text-align: center;">GPT Doc ZS w=2</td>
<td style="text-align: center;">86.1</td>
<td style="text-align: center;">82.7</td>
<td style="text-align: center;">82.4</td>
<td style="text-align: center;">60.9</td>
<td style="text-align: center;">32.8</td>
<td style="text-align: center;">34.4</td>
<td style="text-align: center;">1058</td>
</tr>
<tr>
<td style="text-align: center;">GPT Doc ZS w=4</td>
<td style="text-align: center;">86.3</td>
<td style="text-align: center;">82.6</td>
<td style="text-align: center;">82.6</td>
<td style="text-align: center;">61.3</td>
<td style="text-align: center;">33.6</td>
<td style="text-align: center;">35.2</td>
<td style="text-align: center;">579</td>
</tr>
<tr>
<td style="text-align: center;">GPT Doc ZS w=8</td>
<td style="text-align: center;">86.4</td>
<td style="text-align: center;">82.6</td>
<td style="text-align: center;">82.6</td>
<td style="text-align: center;">60.9</td>
<td style="text-align: center;">33.4</td>
<td style="text-align: center;">35.2</td>
<td style="text-align: center;">349</td>
</tr>
<tr>
<td style="text-align: center;">GPT Doc ZS w=16</td>
<td style="text-align: center;">$86.5^{*}$</td>
<td style="text-align: center;">$82.6^{*}$</td>
<td style="text-align: center;">$82.6^{*}$</td>
<td style="text-align: center;">$61.3^{*}$</td>
<td style="text-align: center;">$34.2^{*}$</td>
<td style="text-align: center;">$36.1^{*}$</td>
<td style="text-align: center;">235</td>
</tr>
<tr>
<td style="text-align: center;">GPT Doc ZS w=32</td>
<td style="text-align: center;">86.4</td>
<td style="text-align: center;">82.6</td>
<td style="text-align: center;">82.7</td>
<td style="text-align: center;">61.3</td>
<td style="text-align: center;">34.1</td>
<td style="text-align: center;">36.1</td>
<td style="text-align: center;">187</td>
</tr>
</tbody>
</table>
<p>Table 5: Evaluation results of document-level translation with GPT on DE&lt;&gt;DE WMT22 testset. The table shows the effect of increasing context length $w$ in document to document translation with a zero-shot setting.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">System</th>
<th style="text-align: center;">COMET-22</th>
<th style="text-align: center;">COMETkiwi</th>
<th style="text-align: center;">Doc-COMETkiwi</th>
<th style="text-align: center;">ChrF</th>
<th style="text-align: center;">BLEU</th>
<th style="text-align: center;">Doc-BLEU</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">DE-EN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">WMT-Best</td>
<td style="text-align: center;">85.0</td>
<td style="text-align: center;">81.4</td>
<td style="text-align: center;">79.9</td>
<td style="text-align: center;">58.5</td>
<td style="text-align: center;">33.4</td>
<td style="text-align: center;">35.2</td>
</tr>
<tr>
<td style="text-align: center;">MS-Translator</td>
<td style="text-align: center;">84.7</td>
<td style="text-align: center;">81.0</td>
<td style="text-align: center;">79.5</td>
<td style="text-align: center;">58.5</td>
<td style="text-align: center;">33.5</td>
<td style="text-align: center;">35.2</td>
</tr>
<tr>
<td style="text-align: center;">GPT-Sent-QR</td>
<td style="text-align: center;">85.4*</td>
<td style="text-align: center;">81.5*</td>
<td style="text-align: center;">80.2</td>
<td style="text-align: center;">57.7</td>
<td style="text-align: center;">32.4</td>
<td style="text-align: center;">34.0</td>
</tr>
<tr>
<td style="text-align: center;">GPT-Sent-DR</td>
<td style="text-align: center;">84.9</td>
<td style="text-align: center;">81.4</td>
<td style="text-align: center;">80.0</td>
<td style="text-align: center;">55.3</td>
<td style="text-align: center;">29.6</td>
<td style="text-align: center;">31.3</td>
</tr>
<tr>
<td style="text-align: center;">GPT-Doc-QR</td>
<td style="text-align: center;">85.2</td>
<td style="text-align: center;">81.2</td>
<td style="text-align: center;">80.2</td>
<td style="text-align: center;">58.1</td>
<td style="text-align: center;">33.3</td>
<td style="text-align: center;">35.0</td>
</tr>
<tr>
<td style="text-align: center;">GPT-Doc-DR</td>
<td style="text-align: center;">85.2</td>
<td style="text-align: center;">81.3</td>
<td style="text-align: center;">80.5*</td>
<td style="text-align: center;">57.6</td>
<td style="text-align: center;">32.7</td>
<td style="text-align: center;">34.3</td>
</tr>
<tr>
<td style="text-align: center;">GPT-Doc-DF</td>
<td style="text-align: center;">85.1</td>
<td style="text-align: center;">81.3</td>
<td style="text-align: center;">80.4</td>
<td style="text-align: center;">57.3</td>
<td style="text-align: center;">32.6</td>
<td style="text-align: center;">34.1</td>
</tr>
<tr>
<td style="text-align: center;">GPT-Doc-DH</td>
<td style="text-align: center;">85.3</td>
<td style="text-align: center;">81.2</td>
<td style="text-align: center;">80.3</td>
<td style="text-align: center;">58.2*</td>
<td style="text-align: center;">33.5*</td>
<td style="text-align: center;">35.1*</td>
</tr>
<tr>
<td style="text-align: center;">EN-DE</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">WMT-Best</td>
<td style="text-align: center;">87.2</td>
<td style="text-align: center;">83.6</td>
<td style="text-align: center;">83.1</td>
<td style="text-align: center;">64.6</td>
<td style="text-align: center;">38.4</td>
<td style="text-align: center;">40.0</td>
</tr>
<tr>
<td style="text-align: center;">MS-Translator</td>
<td style="text-align: center;">86.8</td>
<td style="text-align: center;">83.4</td>
<td style="text-align: center;">83.0</td>
<td style="text-align: center;">64.2</td>
<td style="text-align: center;">37.3</td>
<td style="text-align: center;">38.2</td>
</tr>
<tr>
<td style="text-align: center;">GPT-Sent-QR</td>
<td style="text-align: center;">86.4</td>
<td style="text-align: center;">83.1</td>
<td style="text-align: center;">82.7</td>
<td style="text-align: center;">61.3</td>
<td style="text-align: center;">33.2</td>
<td style="text-align: center;">34.8</td>
</tr>
<tr>
<td style="text-align: center;">GPT-Sent-DR</td>
<td style="text-align: center;">86.7</td>
<td style="text-align: center;">83.5*</td>
<td style="text-align: center;">83.0*</td>
<td style="text-align: center;">61.2</td>
<td style="text-align: center;">32.8</td>
<td style="text-align: center;">34.3</td>
</tr>
<tr>
<td style="text-align: center;">GPT-Doc-QR</td>
<td style="text-align: center;">86.6</td>
<td style="text-align: center;">83.0</td>
<td style="text-align: center;">82.7</td>
<td style="text-align: center;">61.6</td>
<td style="text-align: center;">34.0</td>
<td style="text-align: center;">35.7</td>
</tr>
<tr>
<td style="text-align: center;">GPT-Doc-DR</td>
<td style="text-align: center;">86.9</td>
<td style="text-align: center;">83.0</td>
<td style="text-align: center;">82.9</td>
<td style="text-align: center;">61.9</td>
<td style="text-align: center;">34.4</td>
<td style="text-align: center;">36.1</td>
</tr>
<tr>
<td style="text-align: center;">GPT-Doc-DF</td>
<td style="text-align: center;">87.0*</td>
<td style="text-align: center;">83.1</td>
<td style="text-align: center;">82.9</td>
<td style="text-align: center;">62.0*</td>
<td style="text-align: center;">34.5*</td>
<td style="text-align: center;">36.2*</td>
</tr>
<tr>
<td style="text-align: center;">GPT-Doc-DH</td>
<td style="text-align: center;">86.6</td>
<td style="text-align: center;">82.9</td>
<td style="text-align: center;">82.8</td>
<td style="text-align: center;">61.7</td>
<td style="text-align: center;">33.9</td>
<td style="text-align: center;">35.7</td>
</tr>
</tbody>
</table>
<p>Table 6: Effect of shot selection for document-level translation on WMT22 DE&lt;&gt;EN testset.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">System</th>
<th style="text-align: center;">COMET-22</th>
<th style="text-align: center;">COMETkiwi</th>
<th style="text-align: center;">ChrF</th>
<th style="text-align: center;">BLEU</th>
<th style="text-align: center;">COMET-22</th>
<th style="text-align: center;">COMETkiwi</th>
<th style="text-align: center;">ChrF</th>
<th style="text-align: center;">BLEU</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Combined All Domains</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">WMT-Best</td>
<td style="text-align: center;">85.0</td>
<td style="text-align: center;">DE-EN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">EN-DE</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">84.7</td>
<td style="text-align: center;">81.4</td>
<td style="text-align: center;">58.5</td>
<td style="text-align: center;">33.4</td>
<td style="text-align: center;">87.2</td>
<td style="text-align: center;">83.6</td>
<td style="text-align: center;">64.6</td>
<td style="text-align: center;">38.4</td>
</tr>
<tr>
<td style="text-align: center;">MS-Translator</td>
<td style="text-align: center;">84.7</td>
<td style="text-align: center;">81.0</td>
<td style="text-align: center;">58.5</td>
<td style="text-align: center;">33.5</td>
<td style="text-align: center;">86.8</td>
<td style="text-align: center;">83.4</td>
<td style="text-align: center;">64.2</td>
<td style="text-align: center;">37.3</td>
</tr>
<tr>
<td style="text-align: center;">GPT</td>
<td style="text-align: center;">85.4</td>
<td style="text-align: center;">81.5</td>
<td style="text-align: center;">57.7</td>
<td style="text-align: center;">32.4</td>
<td style="text-align: center;">86.4</td>
<td style="text-align: center;">83.1</td>
<td style="text-align: center;">61.3</td>
<td style="text-align: center;">33.2</td>
</tr>
<tr>
<td style="text-align: center;">WMT-Best</td>
<td style="text-align: center;">81.0</td>
<td style="text-align: center;">ZH-EN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">EN-ZH</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">80.4</td>
<td style="text-align: center;">77.7</td>
<td style="text-align: center;">61.1</td>
<td style="text-align: center;">33.5</td>
<td style="text-align: center;">86.7</td>
<td style="text-align: center;">82.0</td>
<td style="text-align: center;">41.1</td>
<td style="text-align: center;">44.8</td>
</tr>
<tr>
<td style="text-align: center;">MS-Translator</td>
<td style="text-align: center;">80.4</td>
<td style="text-align: center;">77.6</td>
<td style="text-align: center;">57.7</td>
<td style="text-align: center;">27.9</td>
<td style="text-align: center;">86.1</td>
<td style="text-align: center;">81.4</td>
<td style="text-align: center;">43.1</td>
<td style="text-align: center;">48.1</td>
</tr>
<tr>
<td style="text-align: center;">GPT</td>
<td style="text-align: center;">81.1</td>
<td style="text-align: center;">78.7</td>
<td style="text-align: center;">54.7</td>
<td style="text-align: center;">23.8</td>
<td style="text-align: center;">87.0</td>
<td style="text-align: center;">82.2</td>
<td style="text-align: center;">39.8</td>
<td style="text-align: center;">43.7</td>
</tr>
<tr>
<td style="text-align: center;">Conversational Domain</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">WMT-Best</td>
<td style="text-align: center;">85.7</td>
<td style="text-align: center;">DE-EN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">EN-DE</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">85.1</td>
<td style="text-align: center;">81.4</td>
<td style="text-align: center;">54.9</td>
<td style="text-align: center;">35.1</td>
<td style="text-align: center;">89.1</td>
<td style="text-align: center;">83.3</td>
<td style="text-align: center;">67.7</td>
<td style="text-align: center;">42.8</td>
</tr>
<tr>
<td style="text-align: center;">MS-Translator</td>
<td style="text-align: center;">85.1</td>
<td style="text-align: center;">81.0</td>
<td style="text-align: center;">55.2</td>
<td style="text-align: center;">35.3</td>
<td style="text-align: center;">88.8</td>
<td style="text-align: center;">83.1</td>
<td style="text-align: center;">67.3</td>
<td style="text-align: center;">40.7</td>
</tr>
<tr>
<td style="text-align: center;">GPT</td>
<td style="text-align: center;">86.1</td>
<td style="text-align: center;">81.5</td>
<td style="text-align: center;">55.0</td>
<td style="text-align: center;">35.6</td>
<td style="text-align: center;">88.5</td>
<td style="text-align: center;">83.4</td>
<td style="text-align: center;">62.9</td>
<td style="text-align: center;">35.7</td>
</tr>
<tr>
<td style="text-align: center;">WMT-Best</td>
<td style="text-align: center;">81.6</td>
<td style="text-align: center;">ZH-EN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">EN-ZH</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">80.6</td>
<td style="text-align: center;">77.7</td>
<td style="text-align: center;">48.8</td>
<td style="text-align: center;">25.6</td>
<td style="text-align: center;">86.9</td>
<td style="text-align: center;">81.3</td>
<td style="text-align: center;">36.7</td>
<td style="text-align: center;">37.6</td>
</tr>
<tr>
<td style="text-align: center;">MS-Translator</td>
<td style="text-align: center;">80.6</td>
<td style="text-align: center;">77.4</td>
<td style="text-align: center;">46.7</td>
<td style="text-align: center;">22.9</td>
<td style="text-align: center;">87.6</td>
<td style="text-align: center;">81.3</td>
<td style="text-align: center;">42</td>
<td style="text-align: center;">44.0</td>
</tr>
<tr>
<td style="text-align: center;">GPT</td>
<td style="text-align: center;">82.0</td>
<td style="text-align: center;">78.1</td>
<td style="text-align: center;">48.0</td>
<td style="text-align: center;">26.3</td>
<td style="text-align: center;">88.9</td>
<td style="text-align: center;">82.4</td>
<td style="text-align: center;">40.5</td>
<td style="text-align: center;">41.9</td>
</tr>
<tr>
<td style="text-align: center;">News Domain</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">WMT-Best</td>
<td style="text-align: center;">84.9</td>
<td style="text-align: center;">DE-EN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">EN-DE</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">84.7</td>
<td style="text-align: center;">82.0</td>
<td style="text-align: center;">58.8</td>
<td style="text-align: center;">31.4</td>
<td style="text-align: center;">87.0</td>
<td style="text-align: center;">84.5</td>
<td style="text-align: center;">65.6</td>
<td style="text-align: center;">37.8</td>
</tr>
<tr>
<td style="text-align: center;">MS-Translator</td>
<td style="text-align: center;">84.7</td>
<td style="text-align: center;">81.9</td>
<td style="text-align: center;">59.0</td>
<td style="text-align: center;">31.6</td>
<td style="text-align: center;">87.0</td>
<td style="text-align: center;">84.3</td>
<td style="text-align: center;">65.3</td>
<td style="text-align: center;">36.8</td>
</tr>
<tr>
<td style="text-align: center;">GPT</td>
<td style="text-align: center;">85.3</td>
<td style="text-align: center;">82.3</td>
<td style="text-align: center;">58.7</td>
<td style="text-align: center;">31.4</td>
<td style="text-align: center;">85.9</td>
<td style="text-align: center;">83.7</td>
<td style="text-align: center;">62.4</td>
<td style="text-align: center;">31.7</td>
</tr>
<tr>
<td style="text-align: center;">WMT-Best</td>
<td style="text-align: center;">82.1</td>
<td style="text-align: center;">ZH-EN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">EN-ZH</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">81.8</td>
<td style="text-align: center;">79.6</td>
<td style="text-align: center;">62.2</td>
<td style="text-align: center;">31.3</td>
<td style="text-align: center;">87.6</td>
<td style="text-align: center;">83.1</td>
<td style="text-align: center;">45.6</td>
<td style="text-align: center;">51.7</td>
</tr>
<tr>
<td style="text-align: center;">MS-Translator</td>
<td style="text-align: center;">81.8</td>
<td style="text-align: center;">80.0</td>
<td style="text-align: center;">59.7</td>
<td style="text-align: center;">28.2</td>
<td style="text-align: center;">87</td>
<td style="text-align: center;">82.3</td>
<td style="text-align: center;">48.2</td>
<td style="text-align: center;">53.8</td>
</tr>
<tr>
<td style="text-align: center;">GPT</td>
<td style="text-align: center;">81.7</td>
<td style="text-align: center;">80.2</td>
<td style="text-align: center;">56.9</td>
<td style="text-align: center;">23.3</td>
<td style="text-align: center;">87.2</td>
<td style="text-align: center;">82.5</td>
<td style="text-align: center;">42.2</td>
<td style="text-align: center;">48.7</td>
</tr>
<tr>
<td style="text-align: center;">e-Commerce Domain</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">WMT-Best</td>
<td style="text-align: center;">85.6</td>
<td style="text-align: center;">DE-EN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">EN-DE</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">85.3</td>
<td style="text-align: center;">81.2</td>
<td style="text-align: center;">61.3</td>
<td style="text-align: center;">35.3</td>
<td style="text-align: center;">88.7</td>
<td style="text-align: center;">84.1</td>
<td style="text-align: center;">65.3</td>
<td style="text-align: center;">38.4</td>
</tr>
<tr>
<td style="text-align: center;">MS-Translator</td>
<td style="text-align: center;">85.3</td>
<td style="text-align: center;">80.9</td>
<td style="text-align: center;">61.3</td>
<td style="text-align: center;">35.2</td>
<td style="text-align: center;">88.2</td>
<td style="text-align: center;">83.8</td>
<td style="text-align: center;">64.9</td>
<td style="text-align: center;">38.1</td>
</tr>
<tr>
<td style="text-align: center;">GPT</td>
<td style="text-align: center;">85.6</td>
<td style="text-align: center;">81.2</td>
<td style="text-align: center;">60.5</td>
<td style="text-align: center;">34</td>
<td style="text-align: center;">87.6</td>
<td style="text-align: center;">83.6</td>
<td style="text-align: center;">62</td>
<td style="text-align: center;">34</td>
</tr>
<tr>
<td style="text-align: center;">WMT-Best</td>
<td style="text-align: center;">77.6</td>
<td style="text-align: center;">ZH-EN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">EN-ZH</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">77.8</td>
<td style="text-align: center;">75.1</td>
<td style="text-align: center;">52.2</td>
<td style="text-align: center;">22.2</td>
<td style="text-align: center;">88.0</td>
<td style="text-align: center;">83.0</td>
<td style="text-align: center;">40.8</td>
<td style="text-align: center;">43.5</td>
</tr>
<tr>
<td style="text-align: center;">MS-Translator</td>
<td style="text-align: center;">77.8</td>
<td style="text-align: center;">75.0</td>
<td style="text-align: center;">51.5</td>
<td style="text-align: center;">20.3</td>
<td style="text-align: center;">87.8</td>
<td style="text-align: center;">82.6</td>
<td style="text-align: center;">41.9</td>
<td style="text-align: center;">46.6</td>
</tr>
<tr>
<td style="text-align: center;">GPT</td>
<td style="text-align: center;">79.0</td>
<td style="text-align: center;">76.7</td>
<td style="text-align: center;">49.4</td>
<td style="text-align: center;">18.7</td>
<td style="text-align: center;">87.9</td>
<td style="text-align: center;">82.8</td>
<td style="text-align: center;">40.3</td>
<td style="text-align: center;">42.9</td>
</tr>
<tr>
<td style="text-align: center;">Social Domain</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">WMT-Best</td>
<td style="text-align: center;">84.1</td>
<td style="text-align: center;">DE-EN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">EN-DE</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">83.7</td>
<td style="text-align: center;">80.9</td>
<td style="text-align: center;">56.5</td>
<td style="text-align: center;">32.6</td>
<td style="text-align: center;">84.0</td>
<td style="text-align: center;">82.3</td>
<td style="text-align: center;">59.8</td>
<td style="text-align: center;">35.8</td>
</tr>
<tr>
<td style="text-align: center;">MS-Translator</td>
<td style="text-align: center;">83.7</td>
<td style="text-align: center;">80.5</td>
<td style="text-align: center;">56.2</td>
<td style="text-align: center;">32.5</td>
<td style="text-align: center;">83.2</td>
<td style="text-align: center;">82.2</td>
<td style="text-align: center;">59.1</td>
<td style="text-align: center;">34.6</td>
</tr>
<tr>
<td style="text-align: center;">GPT</td>
<td style="text-align: center;">84.5</td>
<td style="text-align: center;">81.1</td>
<td style="text-align: center;">54.7</td>
<td style="text-align: center;">29.9</td>
<td style="text-align: center;">83.6</td>
<td style="text-align: center;">81.7</td>
<td style="text-align: center;">57.7</td>
<td style="text-align: center;">32.5</td>
</tr>
<tr>
<td style="text-align: center;">WMT-Best</td>
<td style="text-align: center;">83.0</td>
<td style="text-align: center;">ZH-EN</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">EN-ZH</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">81.4</td>
<td style="text-align: center;">78.2</td>
<td style="text-align: center;">69.4</td>
<td style="text-align: center;">46.8</td>
<td style="text-align: center;">84.2</td>
<td style="text-align: center;">80.7</td>
<td style="text-align: center;">36.4</td>
<td style="text-align: center;">40.2</td>
</tr>
<tr>
<td style="text-align: center;">MS-Translator</td>
<td style="text-align: center;">81.4</td>
<td style="text-align: center;">78.0</td>
<td style="text-align: center;">62.3</td>
<td style="text-align: center;">34.6</td>
<td style="text-align: center;">82.0</td>
<td style="text-align: center;">79.4</td>
<td style="text-align: center;">36.1</td>
<td style="text-align: center;">40.9</td>
</tr>
<tr>
<td style="text-align: center;">GPT</td>
<td style="text-align: center;">81.9</td>
<td style="text-align: center;">79.7</td>
<td style="text-align: center;">57.4</td>
<td style="text-align: center;">28</td>
<td style="text-align: center;">84.0</td>
<td style="text-align: center;">81.0</td>
<td style="text-align: center;">34.2</td>
<td style="text-align: center;">37.7</td>
</tr>
</tbody>
</table>
<p>Table 7: Evaluation results of $\mathrm{DE} \triangleleft \mathrm{EN}$ and $\mathrm{ZH} \triangleleft \mathrm{EN}$ translations across four domains.</p>
<p>heavily on similar data, it is easier to reproduce the same patterns, e.g., WMT-Best scores 31.3 BLEU. For more general commercial scale systems that are trained on much larger and diverse data, it is harder to produce the same exact patterns, as such, MS-Translator scores 28.2 BLEU. For GPT, which is mostly trained on English, it is harder to get the lexical matches and it mostly produces the English news style, scoring 23.3 BLEU. However, COMET22, using the same reference, seems to provide a more robust signal with all three systems being almost on the same level. This confirms the robustness of neural metrics across domains (Freitag et al., 2022) and GPT's ability to handle diverse domains while being more robust towards parallel data biases, which we will explore further in $\S 5$. Therein, we show that in general, GPT performs better in cases where the input resonates with the noisy parts of parallel data.</p>
<h3>3.7 Hybrid GPT and NMT Translation</h3>
<p>To explore the possibility of leveraging the strong performance of GPT on various languages, we propose and evaluate several hybrid approaches that combine the strengths of NMT and GPT systems. The basic idea is to use Microsoft Translator (MSTranslator) system as the primary translation system, and then use GPT as a fallback system when the quality of MS-Translator is unsatisfactory.</p>
<p>We use COMETkiwi as the quality estimation model and COMET-22 as the performance evaluation metric. We first establish an upper bound by selecting the best translation from either systems according to COMETkiwi, which we call the "Max-Routing" approach. Then we experiment with a more practical approach where we use GPT only when the COMETkiwi score of MS-Translator falls below a predefined threshold. In this experiment, we set the threshold to the 50-th percentile of the COMETkiwi scores of MS-Translator, meaning that we use GPT for any translation that has a COMETkiwi score lower than the median MSTranslator COMETKiwi score, which can be easily estimated from previous translation requests.</p>
<p>Figure 1 presents the results of our experiments on 12 language pairs. Firstly, we observe that in all language pairs, the "Hybrid Max-Routing" approach consistently achieves the highest COMET22 scores, surpassing both the individual systems. "Hybrid Max-Routing" achieves a maximum gain of 1.6 Comet-22 points in the EN-UK language pair
which is not among top performance language for GPT. This indicates that combining the strengths of NMT and GPT systems can lead to a significant improvement in translation quality.</p>
<p>Next, we compare the performance of the individual systems. In general, MS-Translator achieves higher scores than GPT on most language pairs, which is expected given that MS-Translator is an NMT system specifically optimized for translation tasks. However, GPT outperforms MS-Translator on certain language pairs, such as DE-EN, EN-JA, and EN-ZH. This suggests that GPT can be a valuable fallback system in cases where the quality of the primary system is unsatisfactory.</p>
<p>We also compare the performance of the two hybrid approaches. The "Hybrid Max-Routing" approach achieves slightly higher scores than the "Hybrid Threshold" approach on most language pairs, indicating that routing to GPT only when the quality of MS-Translator falls below a certain threshold may not always be the optimal strategy. However, the "Hybrid Threshold" approach still achieves comparable results to the upper bound on all language pairs, while using GPT for only $50 \%$ of the instances. This suggests that it can be a more practical approach in scenarios where computational resources are limited.</p>
<p>Figure 2 demonstrates that hybrid approaches achieve larger and more consistent improvements than shots selection across all languages and directions. Figure 3 zooms in on the high-performing DE-EN and EN-DE systems. The hybrid system outperforms both WMT-Best and MS-Translator systems in both directions, even though the GPT system only outperforms them in DE-EN with 5shot setup.</p>
<p>In summary, our experiments demonstrate the potential of combining NMT and GPT systems to improve machine translation quality. The results suggest that a hybrid approach that uses GPT as a fallback system can achieve higher performance than either individual systems. Future research can explore more advanced techniques that can leverage the strengths of both systems and optimize the hybrid approach.</p>
<h2>4 Human Evaluation and Analysis</h2>
<p>We use source-based sentence-level contrastive Direct Assessment + Scalar Quality Metric (contrastive DA+SQM; Akhbardeh et al. 2021, Kocmi et al. 2022a) to perform human evaluation of the</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Comparing COMET-22 scores of hybrid MS-Translator and GPT systems with GPT and MS-Translator systems.
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: COMET-22 and COMETKiwi scores for GPT based systems with different approaches.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: COMET-22 and COMETKiwi scores for GPT based systems compared to WMT-Best and MS-Translator systems to translate between English (EN) and German (DE).</p>
<p>WMT-Best systems from Table 1 and GPT with 5 shots QR as shown in Table 3. For each language pair, we randomly sample 425 non-identical translation item pairs and have them annotated with the contrastive DA+SQM annotation method by 5 distinct professional translation experts per language pair. Figure 4 and Figure 5 report aggregated human and corresponding COMETkiwi scores. Surprisingly, GPT outperforms Best-WMT systems on CS-EN, ZH-EN, EN-ZH and DE-FR, and achieves comparable results on most of the high-resource languages. On the other hand, the two low-resource languages, Hausa and Icelandic, lag behind significantly. Full details of the scores can be found in the appendix, Table 13.</p>
<p>We observe that the human evaluation results are highly consistent with the COMETkiwi results. This highlights the importance of neural reference-less metrics for evaluating MT in general and this family of models in particular. As we have seen in the previous results, all lexical metrics fail to capture the strong performance of GPT and exhibit lexical and reference bias. While we believe quality estimation is becoming more essential for MT in general, it is reassuring to know that COMETkiwi performs well on GPT models as well as on NMT models. Moreover, as shown on Figure 6, highly performing GPT languages pairs demonstrate higher win rate which is reflected on both Human Evaluation results and COMETkiwi scores.</p>
<p>We conducted a manual analysis of humanevaluated GPT translations for English-Japanese and Japanese-English directions to identify their strengths and weaknesses. In Table 14 in the appendix, we present some of the observed characteristics along with examples of GPT and WMT outputs. A notable characteristic is that GPT performs better and more robustly than WMT for source sentences that are erroneous, short, or colloquial. We found that GPT can handle misspellings or unclosed quotation marks and produce translations that do not omit any semantic information. Moreover, GPT can generate reasonable translations for partial or incomplete colloquial source sentences while WMT-Best often adds or omits content. However, GPT tends to produce unnatural translations for sentences with uncommon or complex expressions.</p>
<h1>5 GPT Translation Characteristics</h1>
<p>In this section, we try to comprehensively analyze the characteristics of the translations obtained from GPT. Our goal here is to better differentiate GPT</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Human Evaluation of WMT-Best Systems vs GPT translations for non-English to English</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: Human Evaluation of WMT Best Systems vs GPT translations to non-English</p>
<p>translations from its NMT counterpart.</p>
<h3>5.1 Situating GPT Translations</h3>
<p>We posit that there are two key biases due to which the computation of translation done by LLMs might be different from the same computation done by NMT models, namely the <em>Parallel Data Bias</em> and the <em>Language Modeling Bias</em>.</p>
<p><strong>Parallel Data Bias:</strong> Compared to NMT models trained on parallel data, which is typically web-mined (and noisy), LLMs such as GPT are trained on monolingual data only with no explicit supervisory signal for the translation task. This creates interesting implications on the nature of the emergent computational abilities leveraged for our task of interest, translation. First, not using parallel data might imply that LLMs are protected against the noise associated with parallel data, which leads to problems such as the memorization of noisy/atypical (Raunak et al., 2021) or low-quality samples (Raunak and Menezes, 2022) and biases towards particular language characteristics predominant in the parallel data (Garcia et al., 2023). These <em>parallel data biases</em> can also manifest in the form of long-tailed errors such as the translations of physical units or currencies (Raunak et al., 2022), owing to a preponderance of such incorrect token pairings in the parallel data. On the other hand, the lack of explicit supervisory signals</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6: Human Evaluation: GPT Win Rates (%) based on Item Scores per language pair.</p>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 7: Fluency Comparisons for the X-E language pairs. On 7 out of 8 language pairs, GPT translations obtain lower perplexity, thereby producing more fluent translations. The magnitude of the difference is higher for Zh-En and Ja-En language pairs.</p>
<p><img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 8: Comparisons of Punctuation Insertions for the X-E language pairs. On 8 out of 8 language pairs, GPT translations show a greater bias towards inserting unsupported end of sentence markers in translation.</p>
<p>for the task could also mean that LLM-based translations might not track the desired characteristics of translations such as faithfulness to the source as well as the NMT models trained with explicit teacher-forced supervision [Anonymous, 2023b].</p>
<p><strong>Language Modeling Bias:</strong> Despite the impressive performance of in-context learning, constraining LLM behavior to explicitly follow the specifications of a desired task is a non-trivial problem. Analyses of in-context learning have revealed how the <em>implicit</em> zero-shot performance of LLMs might be higher than their <em>observed</em> zero-shot performance, with the demonstrations within in-context learning themselves providing only limited learning signals [Min et al., 2022; Kojima et al., 2022; Anonymous, 2023a]. A direct implication of these results for translation is that the demonstrations used for in-context learning might <em>fail</em> to override the underlying computational bias of language modeling which is likely to favor greater fluency at the cost of adequacy. Such <em>language modeling bias</em> might also introduce undesirable artifacts, e.g., punctuation insertions, acronym expansions, world knowledge insertion, etc. in the translations which could cause it to veer off from a faithful cross-lingual representation of the input.</p>
<p>In the next subsection, we propose properties along which finer-grained characteristics of GPT translations could be enumerated. These measures are designed to provide indirect measurements of the language modeling bias as well as the parallel data bias, which could allow a better differentiation of GPT translations against translations from</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Sequence Type</th>
<th style="text-align: center;">Translation Instance</th>
<th style="text-align: center;">Phenomenon</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Source</td>
<td style="text-align: center;">Bis auf die E 9502 wurden alle Lokomotiven zerlegt.</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">MS Translator</td>
<td style="text-align: center;">With the exception of E 9502 , all locomotives were dismantled.</td>
<td style="text-align: center;">Non-Monotonicity (NM)</td>
</tr>
<tr>
<td style="text-align: center;">GPT</td>
<td style="text-align: center;">All locomotives were dismantled except for the E 9502.</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Source</td>
<td style="text-align: center;">Oder ist sie ganz aus dem Sortiment genommen?</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">MS Translator</td>
<td style="text-align: center;">Or is it completely removed from the range?</td>
<td style="text-align: center;">Fluency (F)</td>
</tr>
<tr>
<td style="text-align: center;">GPT</td>
<td style="text-align: center;">Or has it been completely removed from the range?</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Source</td>
<td style="text-align: center;">Sehen Sie bitte im Screenshot was der Kollege geschrieben hat</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">MS Translator</td>
<td style="text-align: center;">Please see in the screenshot what the colleague wrote</td>
<td style="text-align: center;">Punctuation Insertion (PI)</td>
</tr>
<tr>
<td style="text-align: center;">GPT</td>
<td style="text-align: center;">Please see the screenshot for what the colleague wrote.</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Source</td>
<td style="text-align: center;">Die Email zur Stornierung wurde am 26.12.#NUMBER# versendet.</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">MS Translator</td>
<td style="text-align: center;">The cancellation email was sent on 26.12.#NUMBER#</td>
<td style="text-align: center;">Dropped Content (USW)</td>
</tr>
<tr>
<td style="text-align: center;">GPT</td>
<td style="text-align: center;">The cancellation email was sent on December 26th.</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Source</td>
<td style="text-align: center;">"We won't accept the CAA and that is for sure.</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">MS Translator</td>
<td style="text-align: center;">"我们不会接受CAA，这是肯定的。</td>
<td style="text-align: center;">Inserted Content (UTW)</td>
</tr>
<tr>
<td style="text-align: center;">GPT</td>
<td style="text-align: center;">"我们不会接受《公民法》，这是肯定的。</td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>Table 8: Illustrated Examples of the Phenomena as described in Section 5. The origin of these differences between translations lie in the computational mechanism leveraged for translations: When controlled for quality, higher translation non-monotonicity suggests a more abstractive computation used for obtaining the translations. Similarly, Fluency, Punctuation Insertion, Dropped and Inserted Content measure different translation characteristics.
<img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<p>Figure 9: Comparisons of Unaligned Source Words for the X-E language pairs. GPT Translations consistently incur greater number of unaligned source words.</p>
<p>NMT systems. We first discuss the measurements designed to elicit artifacts associated with the language modeling bias.</p>
<h3>5.2 Language Modeling Bias Artifacts</h3>
<p>We propose and use five measurements over the test sets to quantitatively explore language modeling bias, in order to enumerate the differences in translations obtained from traditional NMT systems and GPT. Below, we describe the properties as well as the algorithms used for quantifying them (corresponding illustrative examples of the phenomena are presented in Table 8):</p>
<ol>
<li>Translation Non-Monotonicity (NM): We aim to measure how closely the translation
<img alt="img-9.jpeg" src="img-9.jpeg" /></li>
</ol>
<p>Figure 10: Comparisons of Unaligned Translation Words for the X-E language pairs. GPT Translations consistently incur greater number of unaligned target words.
tracks the source sentence. A more paraphrastic or a less literal translation is likely to deviate from a close tracking of the source word order (across language pairs). We use the nonmonotonicity metric proposed in Schioppa et al. (2021), which computes the deviation from the diagonal in the word to word alignment as the non-monotonicity measure. This measurement could also be interpreted as a normalized measure of alignment crossings, which has been shown to correlate with translation non-literalness (Schaeffer and Carl, 2014). This measurement has also been used in Anonymous (2023b) for investigating translation literalness.</p>
<p><img alt="img-10.jpeg" src="img-10.jpeg" /></p>
<p>Figure 11: Comparisons of Translation Non-Monotonicity for the X-E language pairs. GPT Translations consistently score higher on the non-monotonicity of translations.</p>
<p><img alt="img-11.jpeg" src="img-11.jpeg" /></p>
<p>Figure 12: Comparisons of Punctuation Insertions for the E-X language pairs. On 8 out of 8 language pairs, GPT translations obtain higher scores.</p>
<ol>
<li>
<p>Translation Fluency (TF): We measure translation fluency using a strong, independently trained language model ('gpt2-large', Radford et al. (2019)). We restrict this measurement to X-E direction, since GPT-2 has only been trained on English text (Radford et al., 2019).</p>
</li>
<li>
<p>Punctuation Insertion (PI): Language modeling bias can prefer one mode of sentence completion in contrast to others. This can reveal itself in the presence of not well-formed inputs such as sentences that do not end with typical end of sentence markers (comma, period and exclamation). We measure the fraction of input sentences for which the translation contains an end of sentence marker but the source does not. The insertion of an end of sentence marker in such instances is inadequate for translation, a task which strives for</p>
</li>
</ol>
<p><img alt="img-12.jpeg" src="img-12.jpeg" /></p>
<p>Figure 13: Comparisons of Unaligned Source Words for the E-X language pairs. GPT Translations, on average, incur greater number of unaligned source words.</p>
<p><img alt="img-13.jpeg" src="img-13.jpeg" /></p>
<p>Figure 14: Comparisons of Unaligned Translation Words for the E-X language pairs. GPT Translations consistently incur greater number of unaligned target words.</p>
<p>bitext equivalency.</p>
<ol>
<li>
<p>Unaligned Source Words (USW): We measure the number of source words left unaligned in a word to word alignment obtained over the source and output translations. When controlled for quality, a more paraphrastic translation is likely to contain more words that do not align with the words in the source sentence. This measurement was used in Anonymous (2023b) as a measure of translation literalness and we use it similarly to obtain a measurement of content that is dropped in a translation – an untranslated word or phrase in a source sentence is likely to find no alignments in the output. For obtaining word to word alignments, we use a multilingual-bert based aligner (Devlin et al., 2019; Dou and Neubig, 2021).</p>
</li>
<li>
<p>Unaligned Translation Words (UTW): We</p>
</li>
</ol>
<p><img alt="img-14.jpeg" src="img-14.jpeg" /></p>
<p>Figure 15: Comparisons of Translation Non-Monotonicity for the E-X language pairs. GPT Translations score higher on translation non-monotonicity for 3 out of 4 high-resource language pairs.</p>
<p>Measure the number of unaligned words in the translation using the same word to word alignments as in the previous measurement. This indicates the presence of words that have no support in the source and is included to measure words that are potentially inserted in the translation without any basis in the input.</p>
<p>We collect the measurements on these properties over the test sets for all the language pairs under investigation. We compare MS Translator with GPT throughout. We report the results in the next section and present our analysis grouped by the translation direction.</p>
<h3>5.3 X-E Translation characteristics</h3>
<p>Figures 7, 8, 9, 10 and 11 represent the comparisons of GPT translations against MS Translator for X-E language pairs. Figure 7 shows that GPT translations obtain lower perplexities, thereby demonstrating greater fluency. Figure 8 shows that GPT translations suffer from the problem of punctuation insertion with a much higher frequency than MS Translator. We attribute this to the language modeling bias, which would prefer to generate a well-formed sentence, even if such well-formedness is unsupported in the input. Figure 9 shows that GPT translations incur slightly higher number of unaligned source words on 7 out of 8 eight language pairs. Greater unaligned source words would imply either the presence of greater paraphrasticity in the translations or greater inadequacy (dropped or inserted content). Figure 10 shows that GPT translations incur almost similar number of unaligned target words, suggesting that the GPT</p>
<table>
<thead>
<tr>
<th>Lang-Pair</th>
<th>System</th>
<th>PI ↓</th>
<th>NM ↓</th>
<th>USW ↓</th>
<th>UTW ↓</th>
</tr>
</thead>
<tbody>
<tr>
<td>De-Fr</td>
<td>MS-Translator</td>
<td>3.61</td>
<td>17.68</td>
<td>10.91</td>
<td>25.39</td>
</tr>
<tr>
<td></td>
<td>GPT</td>
<td>42.98</td>
<td>17.21</td>
<td>11.42</td>
<td>25.11</td>
</tr>
<tr>
<td>Fr-De</td>
<td>MS-Translator</td>
<td>2.63</td>
<td>14.63</td>
<td>21.87</td>
<td>14.63</td>
</tr>
<tr>
<td></td>
<td>GPT</td>
<td>60.30</td>
<td>14.52</td>
<td>21.77</td>
<td>14.52</td>
</tr>
</tbody>
</table>
<p>Table 9: Translation Characteristics Comparisons for De-Fr and Fr-De: GPT shows a much higher tendency to add an end of sentence marker into the translation when it is absent in the source.</p>
<p>Translations are similarly adequate in terms of potential insertions. Another measurement, presented in Figure 11 shows that GPT translations are more non-monotonic than its NMT counterpart.</p>
<h3>5.4 E-X Translation characteristics</h3>
<p>Figures 12, 13, 14 and 15 represent the comparisons of GPT translations against MS Translator for E-X language pairs. Figure 12 shows that similar to X-E translations, GPT E-X translations also suffer from a higher frequency of punctuation insertions. The magnitude of the difference however, is smaller than the X-E translations, suggesting a weaker language modeling bias for these languages. Figure 13 shows that in general, GPT translations incur greater number of unaligned source words than its NMT counterpart. Figure 14 shows that the number of unaligned translation words for GPT translations do not differ greatly from MS Translator. Similarly, Figure 15, which compares translation non-monotonicity shows no aggregate trends. As such, we find that the translation characteristics for E-X language language pairs depends heavily on the individual language pair under consideration.</p>
<h3>5.5 X-Y Translation characteristics</h3>
<p>Table 9 reports the results of the five measurements for De-Fr and Fr-De translation directions. The results for direct translation pairs are quite different from the X-E and E-X cases, since typically non-English centric translations are done through pivoting. As such, the trends for measurements over Fluency (F), Unaligned Source Words (USW), Unaligned Translation Words (UTW) and Translation Non-Monotonicity (NM) do not show any conclusive evidence of greater paraphrasticity of GPT translations. However, GPT translations still produce greater number of punctuation insertions than the MS Translator system.</p>
<h3>5.6 Parallel Data Bias Artifacts</h3>
<p>To illustrate the parallel data bias, we analyze the translations on low-quality inputs. The intuition behind our experiment is that low-quality inputs are more likely to correspond to the noisy parts of the parallel data that underlie NMT systems trained on large-scale datasets mined from the web. As such, GPT should outperform NMT systems on such low-quality inputs.</p>
<p>Experiment: We split the test sets into 3 buckets based on perplexity of the source sentence. We notice that the highest perplexity inputs typically correspond to ill-formatted texts, with many inputs pertaining to the e-commerce domain. Such inputs are more likely to resonate with the noisy parts of the parallel corpora on which NMT models are typically trained. For example, such high-perplexity inputs might correspond to ill-formed texts scraped from e-commerce websites usually present in parallel corpora. Since we use GPT-2 for obtaining perplexities, we conduct this experiment for E-X language pairs only.</p>
<p>Results: Table 10 presents the results of the experiment across different language pairs. The measurement reported is the average difference in the quality between GPT and MS Translator as measured using COMET-KIWI. We observe that on English to Chinese, English to Japanese and English to Russian language pairs, on which parallel data mining is typically harder owing to a change in script, GPT translations obtain higher performance than MS Translator on the highest perplexity bucket. For low-resource language pairs, GPT gains proportionally in even the lowest perplexity buckets.</p>
<p>Overall, we find that that in four out of five high resource language pairs in Table 10, GPT obtains higher improvements in the bucket with the highest input perplexity, when compared to the other lower-perplexity buckets. In the cases of English (Latin script) to Chinese, English to Japanese and English to Russian (Cyrillic script), the differences follow a monotonic order with respect to input perplexity. The results suggest that for these language pairs, GPT does obtain better performance on the lower quality inputs. We attribute this behavior to the parallel data bias. Such parallel data noise biases are likely to be correlated with input domains as well, but we leave such an exploration to future work.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Split</th>
<th style="text-align: center;">En-De</th>
<th style="text-align: center;">En-Ru</th>
<th style="text-align: center;">En-Cs</th>
<th style="text-align: center;">En-Zh</th>
<th style="text-align: center;">En-Ja</th>
<th style="text-align: center;">En-Is</th>
<th style="text-align: center;">En-Ha</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Lowest</td>
<td style="text-align: center;">$\mathbf{- 0 . 0 2}$</td>
<td style="text-align: center;">$-0.68$</td>
<td style="text-align: center;">$\mathbf{- 0 . 4 3}$</td>
<td style="text-align: center;">0.22</td>
<td style="text-align: center;">$-0.04$</td>
<td style="text-align: center;">$\mathbf{- 6 . 3 4}$</td>
<td style="text-align: center;">$\mathbf{1 . 6 3}$</td>
</tr>
<tr>
<td style="text-align: center;">Medium</td>
<td style="text-align: center;">$-0.48$</td>
<td style="text-align: center;">$-0.41$</td>
<td style="text-align: center;">$-0.97$</td>
<td style="text-align: center;">0.47</td>
<td style="text-align: center;">$-0.18$</td>
<td style="text-align: center;">$-5.71$</td>
<td style="text-align: center;">1.21</td>
</tr>
<tr>
<td style="text-align: center;">Highest</td>
<td style="text-align: center;">$-0.18$</td>
<td style="text-align: center;">$\mathbf{- 0 . 1 4}$</td>
<td style="text-align: center;">$-1.10$</td>
<td style="text-align: center;">$\mathbf{1 . 6 3}$</td>
<td style="text-align: center;">$\mathbf{0 . 3 8}$</td>
<td style="text-align: center;">$-6.15$</td>
<td style="text-align: center;">1.11</td>
</tr>
</tbody>
</table>
<p>Table 10: Exploring Parallel Data Bias: On English to Chinese, Japanese and Russian language pairs, GPT translations obtain higher performance than MS Translator in the highest perplexity bucket. For low-resource language pairs, GPT gains proportionally in even the lowest perplexity buckets.</p>
<h3>5.7 Summary</h3>
<p>We demonstrated that the computational mechanisms operating behind LLMs and NMT models produce translation artifacts that can be quantitatively differentiated. In this subsection, we summarize our comprehensive characterization of the translations produced by GPT.</p>
<p>Improvements Produced by GPT: For X-E translations, the translations produced by GPT are more fluent, obtaining consistently lower perplexity (as shown in Figure 7). At the same time, GPT translations for X-E language pairs generally incur higher number of unaligned source words (Figure 9) and in general, similar number of unaligned target words (Figure 10). GPT translations are also more non-monotonic, producing translations that involve longer range reorderings (Figure 11). The combination of these results yields an interesting conclusion: that X-E translations by GPT are more fluent and more paraphrastic than the NMT system under investigation (MS Translator), while being faithful to the source. The greater paraphrasticity is not accompanied by content that is unsupported by the source, i.e., the problem of inserted factual content is not a prominent issue in these language pairs.</p>
<p>For E-X translations, GPT incurs a greater number of unaligned source words (USW, Figure 14), along with greater translation non-monotonicity in general (NM, Figure 15), suggesting greater paraphrasticity. However, at the same time, GPT translations incur a slightly higher number of unaligned translation words as well. This suggests that greater paraphrasticity is not the only cause behind the higher USW and NM measurements, and a less adequate translation than the NMT system under investigation is a plausible cause behind these observations as well. This is corroborated</p>
<p>by the lower quality measurements for E-X GPT translations obtained previously. In general, we find that for deriving conclusions about GPT translation quality for E-X, it is more important to focus on the single language pair under consideration, i.e. the target non-English language is of critical importance and the effects of language modeling bias cannot be generalized as in the case of X-E translations.</p>
<p>Areas of Improvements: One artifact of the language modeling bias is that GPT inserts end of sentence markers not present in the source with a far greater frequency than the NMT system under investigation. This holds true across both X-E, E-X and X-Y translation directions. Such a proclivity towards greater fluency might not be appropriate for domains wherein a very literal (and faithful) translation is desired. Similarly, greater paraphrasticity might not be appropriate for certain domains. Also, a related area of improvement for future evaluations would be to conduct separate evaluations of fluency and adequacy, in addition to joint adequacy and fluency quality estimation done presently. Instituting a norm of using multi-dimensional automatic quality measurements (Raunak et al., 2022) can provide very targeted signals on differentiating aspects of translation quality, useful especially when there are competing state-of-the-art approaches.</p>
<p>Areas of Application: Our results also suggest that the greater paraphrastic nature of GPT translations could have applications in improving NMT models on the translation of figurative text. Similarly, the greater gains obtained by GPT translations in the highest perplexity buckets of multiple E-X the test sets suggest that GPT translations might be favored over NMT models when the input domain is likely to contain noisy, ill-formed sentences. These two application areas, based on the demonstrated characteristics of GPT translations, offer two avenues that could benefit from a combination of NMT models with GPT. For example, based on the results in Table 10, a hybrid EnglishJapanese system that could improve upon both MS Translator and GPT translations would be the one wherein the highest perplexity inputs are routed to be translated by GPT whereas the lower perplexity inputs are translated through NMT models (e.g., MS Translator). Such a composition might be able to leverage complementary strengths of NMT and LLM systems for translation.</p>
<h2>6 Multilingual Capabilities beyond Translation</h2>
<p>In this section, we investigate the multilingual capabilities of GPT models beyond translation. Specifically, we aim to assess how well the models perform on emerging reasoning tasks ${ }^{15}$ for various languages compared to English. We are interested in understanding the degree of multilingual support that GPT models can offer given their translation performance. That is, can we use the translation performance as a proxy for the multilingual performance on other tasks?</p>
<p>We use MGSM Benchmark(Shi et al., 2022) which is a Multilingual Grade School Math (MGSM) arithmetic reasoning benchmark. The multilingual problems are human translated from the English dataset GSM8K which is Englishlanguage human-annotated grade-school math problem dataset. The dataset supports a set of ten languages other than English (EN): Bengali (BN), Chinese (ZH), French (FR), German (DE), Japanese (JA), Russian (RU), Spanish (ES), Swahili (SW), Telugu (TE), and Thai (TH).</p>
<p>Table 11 presents the results on the MSGM benchmark. We first use Native-CoT, which uses prompts and CoT in the native language of each dataset. We observe that text-davinci-003 surpasses text-davinci-002 for all languages, highlighting the effectiveness of text-davinci-003 on multilingual tasks. The performance is especially high on EN, DE, FR and ES, while RU, JA and ZH exhibit lower scores than the Latin languages. The low-resource languages, however, achieve limited performance, indicating the need for better approaches to attain truly multilingual support.</p>
<p>We then use Translate-EN, which translates all prompts and CoT into English. We find that this setup enhances the performance on the non-Latin group (RU, JA and ZH) as well as the low-resource group (TH, TE, BN and SW), although the enhancements are not uniform across languages. Surprisingly, this setup shows a deterioration on the Latin languages.</p>
<p>Our third and final setup is Translate-EN+, which is similar to Translate-EN, but keeps the template in English for all sentences instead of translating it. Stabilizing the template improved results significantly in some languages such as French, Spanish and Russian, and gave comparable scores to Translate-EN in others.</p>
<p><sup id="fnref6:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{15}$ as recently studied in the chain of thought paradigm&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref6:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:1">
<p>${ }^{6}$ https://azure.microsoft.com/en-us/products/ cognitive-services/translator
${ }^{7}$ https://beta.openai.com/docs/ model-index-for-researchers
${ }^{8}$ https://openai.com/blog/chatgpt
${ }^{9}$ https://azure.microsoft.com/en-us/products/ cognitive-services/openai-service
${ }^{10}$ https://github.com/Unbabel/COMET
${ }^{11}$ https://github.com/mjpost/sacrebleu&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 2 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:1" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>