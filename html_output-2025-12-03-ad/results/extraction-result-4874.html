<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4874 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4874</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4874</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-106.html">extraction-schema-106</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs or neural language models) being used to solve puzzle games that require spatial knowledge (such as Sudoku or other spatial reasoning tasks). Include details about the models, the puzzles, the mechanisms or strategies used, performance metrics, evidence of spatial reasoning, limitations, and comparisons.</div>
                <p><strong>Paper ID:</strong> paper-46208513</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/1711.08028v4.pdf" target="_blank">Recurrent Relational Networks</a></p>
                <p><strong>Paper Abstract:</strong> This paper is concerned with learning to solve tasks that require a chain of interdependent steps of relational inference, like answering complex questions about the relationships between objects, or solving puzzles where the smaller elements of a solution mutually constrain each other. We introduce the recurrent relational network, a general purpose module that operates on a graph representation of objects. As a generalization of Santoro et al. [2017]'s relational network, it can augment any neural network model with the capacity to do many-step relational reasoning. We achieve state of the art results on the bAbI textual question-answering dataset with the recurrent relational network, consistently solving 20/20 tasks. As bAbI is not particularly challenging from a relational reasoning point of view, we introduce Pretty-CLEVR, a new diagnostic dataset for relational reasoning. In the Pretty-CLEVR set-up, we can vary the question to control for the number of relational reasoning steps that are required to obtain the answer. Using Pretty-CLEVR, we probe the limitations of multi-layer perceptrons, relational and recurrent relational networks. Finally, we show how recurrent relational networks can learn to solve Sudoku puzzles from supervised training data, a challenging task requiring upwards of 64 steps of relational reasoning. We achieve state-of-the-art results amongst comparable methods by solving 96.6% of the hardest Sudoku puzzles.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e4874.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e4874.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs or neural language models) being used to solve puzzle games that require spatial knowledge (such as Sudoku or other spatial reasoning tasks). Include details about the models, the puzzles, the mechanisms or strategies used, performance metrics, evidence of spatial reasoning, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RRN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Recurrent Relational Network</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A learned message-passing graph neural network module that performs many-step relational reasoning by iteratively exchanging learned messages between object nodes and updating node hidden states with an LSTM-based node function; introduced and evaluated in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Recurrent Relational Network (RRN, this work)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Graph neural network / learned message-passing module: nodes represent objects (e.g., Sudoku cells or CLEVR objects). Messages m_{ij} computed by an MLP f(h_i, h_j) and summed per receiver; node update g is implemented as an MLP feeding an LSTM (h_tj, s_tj = LSTM( MLP(concat(x_j, m_tj)), s_{t-1,j} )). Output r is an MLP mapping node hidden states to logits. Hidden sizes used: 96 units (Sudoku experiments) and 128 units (bAbI/Pretty-CLEVR experiments); MLPs typically 3 ReLU layers + linear. Trained with Adam (lr 2e-4 typically), batch sizes and regularization as reported (e.g., batch 256, L2 1e-4 for Sudoku). The model is run for multiple recurrent steps (32 steps in main Sudoku training; tested at 64 steps at test time). Loss applied at every step (cross-entropy per node).</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>Sudoku; Pretty-CLEVR (spatial "jump" reasoning); bAbI (textual QA, includes spatial/temporal)</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_description</strong></td>
                            <td>Sudoku: 9x9 grid fill-in puzzle where each digit 1-9 must appear exactly once per row, column, and 3x3 box (requires propagation of constraints between spatially arranged cells). Pretty-CLEVR: synthetic spatial scenes with 8 objects (position, color, shape) and questions of the form "starting at object X which object is N jumps away?" where jumps are defined by nearest-unvisited neighbor—tests multi-step spatial relational reasoning. bAbI: textual QA tasks including some spatial reasoning questions.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_strategy</strong></td>
                            <td>Iterative learned message passing on an explicit graph encoding object adjacency/relations: for Sudoku, nodes = cells, edges connect same row/column/box; at each step nodes send learned messages to neighbors, update hidden states via LSTM, and emit per-node digit distributions; training imposes cross-entropy loss at every step to encourage convergent, multi-step inference. For Pretty-CLEVR the graph is fully connected with edge features (euclidean distances) provided; the same recurrent message-passing is used for multi-step 'jumps' reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>Multiple lines of evidence in the paper show spatial relational reasoning rather than shallow pattern matching: (1) task design (Sudoku/Pretty-CLEVR) requires propagation of constraints across spatial neighbors; (2) performance improves as the number of RRN steps increases, matching the number of relational steps required (e.g., Pretty-CLEVR accuracy improves with steps and RRN performs well when steps >= jumps); (3) ablation that zeros row/column embeddings has little effect at test time for some metrics (authors tested row/col embedding importance), and visualizations of per-step output probabilities for Sudoku show the network eliminating digits from neighboring cells over steps (fig.3), demonstrating iterative constraint propagation; (4) single-step baselines (Relational Network / MLP) fail on multi-step spatial tasks (RN node-centric gets 0% on hardest Sudokus), showing the need for multi-step relational mechanism; (5) loss-per-step training yields a convergent iterative algorithm detectable by running more steps at test time (accuracy improves from 32 to 64 steps for hardest Sudokus).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Sudoku (17 givens hardest subset): 94.1% of puzzles solved after 32 recurrent steps (full correctness required); when run for 64 steps at test time accuracy increases to 96.6% (paper also reports 96.7% in one run). For easier Sudokus (more givens) accuracy rapidly approaches 100%. Pretty-CLEVR: RRN trained for 4 steps; it achieves near-perfect accuracy on non-relational (0-jump) and single-jump questions, and maintains good accuracy when the number of RRN steps >= required jumps (detailed per-step accuracy plotted in paper; exact per-jump numbers in figure 2b). bAbI: RRN trained jointly solves 20/20 bAbI tasks in 13/15 runs (state-of-the-art reported for this setting).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Requires supervised training on target solutions (not a symbolic solver); needs many recurrent steps for hard instances (authors trained for 32 steps and still gained by testing at 64); not guaranteed to match efficiency or formal guarantees of symbolic solvers (e.g., constraint propagation/search or dancing links are faster and exact); potential risk of learning greedy/local-minima algorithms due to per-step loss (authors discuss this and architectural mitigations); scaling beyond tasks with explicit graph structure may require learning edges (paper uses known Sudoku adjacency); does not replace hand-crafted inference algorithms when exactness and compute-efficiency are required.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Outperforms comparable differentiable methods listed in the paper: modified loopy belief propagation specialized for Sudoku reported 92.5% (17 givens) vs RRN 96.6%; loopy BP random/parallel variants reported 61.7% and 53.2%; learned-message variants (Lin et al. style) could not solve any 17-given Sudoku in authors' attempts (reported 0%); node-centric (single-step) relational network and graph-centric RN baselines got 0% on 17-givens; Park (deep convolutional network, Park 2016) achieved ~70% but on easier Sudokus (24-36 givens). On Pretty-CLEVR, the RRN outperforms an MLP baseline (which solves non-relational but fails at relational jumps) and matches or exceeds the single-step RN when multiple steps are required.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4874.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e4874.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs or neural language models) being used to solve puzzle games that require spatial knowledge (such as Sudoku or other spatial reasoning tasks). Include details about the models, the puzzles, the mechanisms or strategies used, performance metrics, evidence of spatial reasoning, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Relational Network (Santoro et al., 2017)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A single-step relational reasoning module that computes pairwise relations via an MLP over object pair encodings and aggregates them to answer relational queries; used here as a baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A simple neural network module for relational reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Relational Network (single-step)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Single-step relation module: computes g_theta(o_i, o_j) for object pairs via an MLP and aggregates (typically sum) to a fixed-size vector then passes through final MLP(s). In the paper two variants were run: node-centric (single-step equivalent to RRN with 1 step) and graph-centric (sum over nodes then large MLP). The graph-centric baseline had larger hidden states (256) and many more parameters (paper reports graph-centric ~944,874 params vs RRN ~201,194).</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>Sudoku; Pretty-CLEVR</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_description</strong></td>
                            <td>Same puzzles as above: Sudoku requires multi-step constraint propagation across spatially arranged cells; Pretty-CLEVR requires sequential nearest-neighbor jumps among spatial object positions.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_strategy</strong></td>
                            <td>Single forward pass relational aggregation (no recurrence). Compresses pairwise relations into fixed-size vector and relies on final MLP to produce answers (i.e., attempts to compress multi-step reasoning into one feedforward computation).</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>Solves non-relational and single-jump Pretty-CLEVR questions, indicating it can capture some local relational structure; however, it fails on tasks requiring many sequential relational steps like hard Sudokus (0% on 17-givens Sudoku reported), showing lack of multi-step spatial reasoning capability.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Sudoku (17 givens): node-centric RN and graph-centric RN baselines reported 0% solved. Pretty-CLEVR: RN solved non-relational and single-jump questions well but accuracy drops sharply as number of jumps increases (detailed per-jump curves in figure 2b).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Single-step nature prevents solving problems needing many chained relational inferences; must compress relations into a fixed-length vector which is insufficient for complex multi-step constraints; graph-centric model had many more parameters yet still underperformed.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>RRN (multi-step) substantially outperforms RN on tasks needing sequential relational reasoning (e.g., Sudoku). MLP baseline outperforms RN on some trivial non-relational cases but RN is better than MLP on single-step relational cases.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4874.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e4874.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs or neural language models) being used to solve puzzle games that require spatial knowledge (such as Sudoku or other spatial reasoning tasks). Include details about the models, the puzzles, the mechanisms or strategies used, performance metrics, evidence of spatial reasoning, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MLP/CNN baselines</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Multilayer Perceptron and Deep Convolutional Network baselines (Park 2016 and custom MLP baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Non-graph baselines: an MLP taking whole-scene state (Pretty-CLEVR) or a deep convolutional network treating Sudoku as an image (Park 2016) used for comparison; generally fail on multi-step relational spatial tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>MLP baseline; Deep Convolutional Network (Park 2016)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Pretty-CLEVR MLP baseline: 4 ReLU layers with 256 hidden units, dropout 0.5 on last layer, followed by linear layer; input is concatenated scene state plus pairwise distances (261,136 parameters, ~87% more parameters than RRN baseline). Park (2016) CNN: 10 convolutional layers (as described in Park 2016) treating Sudoku as 9x9 image and iteratively picking most probable digit.</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>Pretty-CLEVR; Sudoku (Park 2016 evaluated on easier 24-36-given Sudokus)</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_description</strong></td>
                            <td>Pretty-CLEVR: spatial objects + jumps questions; Sudoku: spatially-structured constraints across grid cells.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_strategy</strong></td>
                            <td>MLP baseline flattens entire scene state and learns to map to answers in a single feedforward pass; CNN treats Sudoku grid as image and iteratively picks digits based on network outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>MLP baseline perfectly solves non-relational (0-jump) Pretty-CLEVR questions (consistent with its ability to memorize/learn non-relational mapping), but fails on single- and multi-jump relational questions. Park CNN obtains moderate performance on easier Sudokus (70% for 24-36 givens) but is not competitive on hardest puzzles.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Pretty-CLEVR: MLP baseline solves non-relational questions but performs poorly on relational jump questions (detailed curves in paper). Sudoku: Park (2016) deep convolutional network ~70% on 24-36 givens (easier puzzles) as reported in the comparison table; authors' MLP baseline is notably worse than RRN on multi-step relational tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Flattening the scene (MLP) removes explicit relational inductive bias, making it ineffective at chained spatial reasoning; CNN approach by Park struggles on hardest Sudokus and is evaluated on easier instances; both approaches lack explicit iterative relational propagation and therefore fail on many multi-step spatial puzzles.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>RRN outperforms both MLP and Park's CNN for tasks requiring many sequential relational steps (Pretty-CLEVR with many jumps, 17-givens Sudoku).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4874.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e4874.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs or neural language models) being used to solve puzzle games that require spatial knowledge (such as Sudoku or other spatial reasoning tasks). Include details about the models, the puzzles, the mechanisms or strategies used, performance metrics, evidence of spatial reasoning, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Loopy BP and learned-message variants</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Loopy Belief Propagation (and learned message-passing variants, e.g., Lin et al. 2015)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Classical probabilistic message-passing (loopy belief propagation) and approaches that attempt to learn message updates for structured prediction; used as comparisons on Sudoku.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Loopy Belief Propagation (various variants) and learned-message message-passing (Deeply Learned Messages)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Loopy BP: hand-crafted message passing for factor graphs; variants tested include parallel and random update schedules and a modified loopy BP tuned for Sudoku (Khan et al. 2014) that uses many iterations and heuristics (e.g., sinkhorn balancing, iterative pick). Learned-message variants (Lin et al.) attempt to learn message functions with neural nets.</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>Sudoku</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_description</strong></td>
                            <td>Same 9x9 Sudoku tasks requiring propagation of exclusion constraints across rows/columns/boxes.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_strategy</strong></td>
                            <td>Loopy BP uses probabilistic marginal propagation through factor graph; modified versions incorporate heuristics and many iterations; learned-message approaches replace message arithmetic with learned neural modules but follow the BP-style iterative schedule.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>Loopy BP explicitly uses graph structure corresponding to Sudoku adjacency, performing constraint propagation across spatial neighbors. Paper reports empirical performance comparisons on 17-given Sudoku instances.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Modified loopy BP for Sudoku (Khan et al. 2014) reported 92.5% accuracy on 17-givens; loopy BP random and parallel updates reported 61.7% and 53.2% respectively. Learned-message approaches (authors' attempts) reported 0% on 17-givens in their experiments when configured similarly.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Hand-crafted loopy BP lacks differentiable interface for end-to-end perceptual front-ends; some learned-message variants failed to solve hardest Sudoku instances in the authors' hands (0%); loopy BP is not guaranteed to converge or be exact on graphs with cycles though it can perform well empirically.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>RRN outperforms modified loopy BP (96.6% vs 92.5% on 17-givens) and substantially outperforms other loopy BP variants; learned-message attempts could not match RRN performance in the reported experiments.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4874.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e4874.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs or neural language models) being used to solve puzzle games that require spatial knowledge (such as Sudoku or other spatial reasoning tasks). Include details about the models, the puzzles, the mechanisms or strategies used, performance metrics, evidence of spatial reasoning, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>OptNet</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>OptNet: Differentiable optimization as a layer in neural networks</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A differentiable optimization layer (quadratic program solver) that can be embedded in neural networks and used for structured problems; mentioned as prior work that successfully solved small Sudoku variants but does not scale easily to 9x9.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>OptNet: Differentiable optimization as a layer in neural networks.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>OptNet (quadratic-program solver layer)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Differentiable quadratic-program solver integrated as a neural network layer (Amos & Kolter, 2017). Demonstrated on small combinatorial tasks (e.g., 4x4 Sudoku), trained end-to-end.</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>Small Sudoku (4x4); mentioned relative to 9x9 scaling</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_description</strong></td>
                            <td>4x4 Sudoku: smaller-scale variant of Sudoku solvable with quadratic-program-based differentiable layer; 9x9 scaling cited as problematic.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_strategy</strong></td>
                            <td>Uses a differentiable optimization solver as a layer (solves QP) trained end-to-end to produce structured outputs, effectively embedding constrained optimization in the network.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>OptNet exploits constrained optimization representing Sudoku constraints explicitly, which is an explicit structured (spatial) formulation; authors cite Amos & Kolter 2017 as beating Park 2016 on 4x4 Sudoku but unable to scale to 9x9 due to computational issues (personal communication).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported to beat the deep convolutional baseline on 4x4 Sudoku in the referenced work; no 9x9 results due to scaling issues (authors note inability to compare directly for 9x9).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Computational scaling limits prevent straightforward application to full 9x9 Sudoku; not used in main experiments in this paper for 9x9.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Mentioned as outperforming a deep convolutional baseline on 4x4 Sudoku in prior work, but not comparable on full 9x9 tasks due to scaling constraints.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>A simple neural network module for relational reasoning. <em>(Rating: 2)</em></li>
                <li>Interaction networks for learning about objects, relations and physics. <em>(Rating: 2)</em></li>
                <li>Solving Sudoku using probabilistic graphical models. <em>(Rating: 2)</em></li>
                <li>Deeply learning the messages in message passing inference. <em>(Rating: 2)</em></li>
                <li>Can neural networks crack Sudoku? <em>(Rating: 2)</em></li>
                <li>The graph neural network model. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4874",
    "paper_id": "paper-46208513",
    "extraction_schema_id": "extraction-schema-106",
    "extracted_data": [
        {
            "name_short": "RRN",
            "name_full": "Recurrent Relational Network",
            "brief_description": "A learned message-passing graph neural network module that performs many-step relational reasoning by iteratively exchanging learned messages between object nodes and updating node hidden states with an LSTM-based node function; introduced and evaluated in this paper.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Recurrent Relational Network (RRN, this work)",
            "model_description": "Graph neural network / learned message-passing module: nodes represent objects (e.g., Sudoku cells or CLEVR objects). Messages m_{ij} computed by an MLP f(h_i, h_j) and summed per receiver; node update g is implemented as an MLP feeding an LSTM (h_tj, s_tj = LSTM( MLP(concat(x_j, m_tj)), s_{t-1,j} )). Output r is an MLP mapping node hidden states to logits. Hidden sizes used: 96 units (Sudoku experiments) and 128 units (bAbI/Pretty-CLEVR experiments); MLPs typically 3 ReLU layers + linear. Trained with Adam (lr 2e-4 typically), batch sizes and regularization as reported (e.g., batch 256, L2 1e-4 for Sudoku). The model is run for multiple recurrent steps (32 steps in main Sudoku training; tested at 64 steps at test time). Loss applied at every step (cross-entropy per node).",
            "puzzle_name": "Sudoku; Pretty-CLEVR (spatial \"jump\" reasoning); bAbI (textual QA, includes spatial/temporal)",
            "puzzle_description": "Sudoku: 9x9 grid fill-in puzzle where each digit 1-9 must appear exactly once per row, column, and 3x3 box (requires propagation of constraints between spatially arranged cells). Pretty-CLEVR: synthetic spatial scenes with 8 objects (position, color, shape) and questions of the form \"starting at object X which object is N jumps away?\" where jumps are defined by nearest-unvisited neighbor—tests multi-step spatial relational reasoning. bAbI: textual QA tasks including some spatial reasoning questions.",
            "mechanism_or_strategy": "Iterative learned message passing on an explicit graph encoding object adjacency/relations: for Sudoku, nodes = cells, edges connect same row/column/box; at each step nodes send learned messages to neighbors, update hidden states via LSTM, and emit per-node digit distributions; training imposes cross-entropy loss at every step to encourage convergent, multi-step inference. For Pretty-CLEVR the graph is fully connected with edge features (euclidean distances) provided; the same recurrent message-passing is used for multi-step 'jumps' reasoning.",
            "evidence_of_spatial_reasoning": "Multiple lines of evidence in the paper show spatial relational reasoning rather than shallow pattern matching: (1) task design (Sudoku/Pretty-CLEVR) requires propagation of constraints across spatial neighbors; (2) performance improves as the number of RRN steps increases, matching the number of relational steps required (e.g., Pretty-CLEVR accuracy improves with steps and RRN performs well when steps &gt;= jumps); (3) ablation that zeros row/column embeddings has little effect at test time for some metrics (authors tested row/col embedding importance), and visualizations of per-step output probabilities for Sudoku show the network eliminating digits from neighboring cells over steps (fig.3), demonstrating iterative constraint propagation; (4) single-step baselines (Relational Network / MLP) fail on multi-step spatial tasks (RN node-centric gets 0% on hardest Sudokus), showing the need for multi-step relational mechanism; (5) loss-per-step training yields a convergent iterative algorithm detectable by running more steps at test time (accuracy improves from 32 to 64 steps for hardest Sudokus).",
            "performance_metrics": "Sudoku (17 givens hardest subset): 94.1% of puzzles solved after 32 recurrent steps (full correctness required); when run for 64 steps at test time accuracy increases to 96.6% (paper also reports 96.7% in one run). For easier Sudokus (more givens) accuracy rapidly approaches 100%. Pretty-CLEVR: RRN trained for 4 steps; it achieves near-perfect accuracy on non-relational (0-jump) and single-jump questions, and maintains good accuracy when the number of RRN steps &gt;= required jumps (detailed per-step accuracy plotted in paper; exact per-jump numbers in figure 2b). bAbI: RRN trained jointly solves 20/20 bAbI tasks in 13/15 runs (state-of-the-art reported for this setting).",
            "limitations_or_failure_cases": "Requires supervised training on target solutions (not a symbolic solver); needs many recurrent steps for hard instances (authors trained for 32 steps and still gained by testing at 64); not guaranteed to match efficiency or formal guarantees of symbolic solvers (e.g., constraint propagation/search or dancing links are faster and exact); potential risk of learning greedy/local-minima algorithms due to per-step loss (authors discuss this and architectural mitigations); scaling beyond tasks with explicit graph structure may require learning edges (paper uses known Sudoku adjacency); does not replace hand-crafted inference algorithms when exactness and compute-efficiency are required.",
            "comparison_baseline": "Outperforms comparable differentiable methods listed in the paper: modified loopy belief propagation specialized for Sudoku reported 92.5% (17 givens) vs RRN 96.6%; loopy BP random/parallel variants reported 61.7% and 53.2%; learned-message variants (Lin et al. style) could not solve any 17-given Sudoku in authors' attempts (reported 0%); node-centric (single-step) relational network and graph-centric RN baselines got 0% on 17-givens; Park (deep convolutional network, Park 2016) achieved ~70% but on easier Sudokus (24-36 givens). On Pretty-CLEVR, the RRN outperforms an MLP baseline (which solves non-relational but fails at relational jumps) and matches or exceeds the single-step RN when multiple steps are required.",
            "uuid": "e4874.0"
        },
        {
            "name_short": "RN",
            "name_full": "Relational Network (Santoro et al., 2017)",
            "brief_description": "A single-step relational reasoning module that computes pairwise relations via an MLP over object pair encodings and aggregates them to answer relational queries; used here as a baseline.",
            "citation_title": "A simple neural network module for relational reasoning.",
            "mention_or_use": "use",
            "model_name": "Relational Network (single-step)",
            "model_description": "Single-step relation module: computes g_theta(o_i, o_j) for object pairs via an MLP and aggregates (typically sum) to a fixed-size vector then passes through final MLP(s). In the paper two variants were run: node-centric (single-step equivalent to RRN with 1 step) and graph-centric (sum over nodes then large MLP). The graph-centric baseline had larger hidden states (256) and many more parameters (paper reports graph-centric ~944,874 params vs RRN ~201,194).",
            "puzzle_name": "Sudoku; Pretty-CLEVR",
            "puzzle_description": "Same puzzles as above: Sudoku requires multi-step constraint propagation across spatially arranged cells; Pretty-CLEVR requires sequential nearest-neighbor jumps among spatial object positions.",
            "mechanism_or_strategy": "Single forward pass relational aggregation (no recurrence). Compresses pairwise relations into fixed-size vector and relies on final MLP to produce answers (i.e., attempts to compress multi-step reasoning into one feedforward computation).",
            "evidence_of_spatial_reasoning": "Solves non-relational and single-jump Pretty-CLEVR questions, indicating it can capture some local relational structure; however, it fails on tasks requiring many sequential relational steps like hard Sudokus (0% on 17-givens Sudoku reported), showing lack of multi-step spatial reasoning capability.",
            "performance_metrics": "Sudoku (17 givens): node-centric RN and graph-centric RN baselines reported 0% solved. Pretty-CLEVR: RN solved non-relational and single-jump questions well but accuracy drops sharply as number of jumps increases (detailed per-jump curves in figure 2b).",
            "limitations_or_failure_cases": "Single-step nature prevents solving problems needing many chained relational inferences; must compress relations into a fixed-length vector which is insufficient for complex multi-step constraints; graph-centric model had many more parameters yet still underperformed.",
            "comparison_baseline": "RRN (multi-step) substantially outperforms RN on tasks needing sequential relational reasoning (e.g., Sudoku). MLP baseline outperforms RN on some trivial non-relational cases but RN is better than MLP on single-step relational cases.",
            "uuid": "e4874.1"
        },
        {
            "name_short": "MLP/CNN baselines",
            "name_full": "Multilayer Perceptron and Deep Convolutional Network baselines (Park 2016 and custom MLP baseline)",
            "brief_description": "Non-graph baselines: an MLP taking whole-scene state (Pretty-CLEVR) or a deep convolutional network treating Sudoku as an image (Park 2016) used for comparison; generally fail on multi-step relational spatial tasks.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "MLP baseline; Deep Convolutional Network (Park 2016)",
            "model_description": "Pretty-CLEVR MLP baseline: 4 ReLU layers with 256 hidden units, dropout 0.5 on last layer, followed by linear layer; input is concatenated scene state plus pairwise distances (261,136 parameters, ~87% more parameters than RRN baseline). Park (2016) CNN: 10 convolutional layers (as described in Park 2016) treating Sudoku as 9x9 image and iteratively picking most probable digit.",
            "puzzle_name": "Pretty-CLEVR; Sudoku (Park 2016 evaluated on easier 24-36-given Sudokus)",
            "puzzle_description": "Pretty-CLEVR: spatial objects + jumps questions; Sudoku: spatially-structured constraints across grid cells.",
            "mechanism_or_strategy": "MLP baseline flattens entire scene state and learns to map to answers in a single feedforward pass; CNN treats Sudoku grid as image and iteratively picks digits based on network outputs.",
            "evidence_of_spatial_reasoning": "MLP baseline perfectly solves non-relational (0-jump) Pretty-CLEVR questions (consistent with its ability to memorize/learn non-relational mapping), but fails on single- and multi-jump relational questions. Park CNN obtains moderate performance on easier Sudokus (70% for 24-36 givens) but is not competitive on hardest puzzles.",
            "performance_metrics": "Pretty-CLEVR: MLP baseline solves non-relational questions but performs poorly on relational jump questions (detailed curves in paper). Sudoku: Park (2016) deep convolutional network ~70% on 24-36 givens (easier puzzles) as reported in the comparison table; authors' MLP baseline is notably worse than RRN on multi-step relational tasks.",
            "limitations_or_failure_cases": "Flattening the scene (MLP) removes explicit relational inductive bias, making it ineffective at chained spatial reasoning; CNN approach by Park struggles on hardest Sudokus and is evaluated on easier instances; both approaches lack explicit iterative relational propagation and therefore fail on many multi-step spatial puzzles.",
            "comparison_baseline": "RRN outperforms both MLP and Park's CNN for tasks requiring many sequential relational steps (Pretty-CLEVR with many jumps, 17-givens Sudoku).",
            "uuid": "e4874.2"
        },
        {
            "name_short": "Loopy BP and learned-message variants",
            "name_full": "Loopy Belief Propagation (and learned message-passing variants, e.g., Lin et al. 2015)",
            "brief_description": "Classical probabilistic message-passing (loopy belief propagation) and approaches that attempt to learn message updates for structured prediction; used as comparisons on Sudoku.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "Loopy Belief Propagation (various variants) and learned-message message-passing (Deeply Learned Messages)",
            "model_description": "Loopy BP: hand-crafted message passing for factor graphs; variants tested include parallel and random update schedules and a modified loopy BP tuned for Sudoku (Khan et al. 2014) that uses many iterations and heuristics (e.g., sinkhorn balancing, iterative pick). Learned-message variants (Lin et al.) attempt to learn message functions with neural nets.",
            "puzzle_name": "Sudoku",
            "puzzle_description": "Same 9x9 Sudoku tasks requiring propagation of exclusion constraints across rows/columns/boxes.",
            "mechanism_or_strategy": "Loopy BP uses probabilistic marginal propagation through factor graph; modified versions incorporate heuristics and many iterations; learned-message approaches replace message arithmetic with learned neural modules but follow the BP-style iterative schedule.",
            "evidence_of_spatial_reasoning": "Loopy BP explicitly uses graph structure corresponding to Sudoku adjacency, performing constraint propagation across spatial neighbors. Paper reports empirical performance comparisons on 17-given Sudoku instances.",
            "performance_metrics": "Modified loopy BP for Sudoku (Khan et al. 2014) reported 92.5% accuracy on 17-givens; loopy BP random and parallel updates reported 61.7% and 53.2% respectively. Learned-message approaches (authors' attempts) reported 0% on 17-givens in their experiments when configured similarly.",
            "limitations_or_failure_cases": "Hand-crafted loopy BP lacks differentiable interface for end-to-end perceptual front-ends; some learned-message variants failed to solve hardest Sudoku instances in the authors' hands (0%); loopy BP is not guaranteed to converge or be exact on graphs with cycles though it can perform well empirically.",
            "comparison_baseline": "RRN outperforms modified loopy BP (96.6% vs 92.5% on 17-givens) and substantially outperforms other loopy BP variants; learned-message attempts could not match RRN performance in the reported experiments.",
            "uuid": "e4874.3"
        },
        {
            "name_short": "OptNet",
            "name_full": "OptNet: Differentiable optimization as a layer in neural networks",
            "brief_description": "A differentiable optimization layer (quadratic program solver) that can be embedded in neural networks and used for structured problems; mentioned as prior work that successfully solved small Sudoku variants but does not scale easily to 9x9.",
            "citation_title": "OptNet: Differentiable optimization as a layer in neural networks.",
            "mention_or_use": "mention",
            "model_name": "OptNet (quadratic-program solver layer)",
            "model_description": "Differentiable quadratic-program solver integrated as a neural network layer (Amos & Kolter, 2017). Demonstrated on small combinatorial tasks (e.g., 4x4 Sudoku), trained end-to-end.",
            "puzzle_name": "Small Sudoku (4x4); mentioned relative to 9x9 scaling",
            "puzzle_description": "4x4 Sudoku: smaller-scale variant of Sudoku solvable with quadratic-program-based differentiable layer; 9x9 scaling cited as problematic.",
            "mechanism_or_strategy": "Uses a differentiable optimization solver as a layer (solves QP) trained end-to-end to produce structured outputs, effectively embedding constrained optimization in the network.",
            "evidence_of_spatial_reasoning": "OptNet exploits constrained optimization representing Sudoku constraints explicitly, which is an explicit structured (spatial) formulation; authors cite Amos & Kolter 2017 as beating Park 2016 on 4x4 Sudoku but unable to scale to 9x9 due to computational issues (personal communication).",
            "performance_metrics": "Reported to beat the deep convolutional baseline on 4x4 Sudoku in the referenced work; no 9x9 results due to scaling issues (authors note inability to compare directly for 9x9).",
            "limitations_or_failure_cases": "Computational scaling limits prevent straightforward application to full 9x9 Sudoku; not used in main experiments in this paper for 9x9.",
            "comparison_baseline": "Mentioned as outperforming a deep convolutional baseline on 4x4 Sudoku in prior work, but not comparable on full 9x9 tasks due to scaling constraints.",
            "uuid": "e4874.4"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "A simple neural network module for relational reasoning.",
            "rating": 2,
            "sanitized_title": "a_simple_neural_network_module_for_relational_reasoning"
        },
        {
            "paper_title": "Interaction networks for learning about objects, relations and physics.",
            "rating": 2,
            "sanitized_title": "interaction_networks_for_learning_about_objects_relations_and_physics"
        },
        {
            "paper_title": "Solving Sudoku using probabilistic graphical models.",
            "rating": 2,
            "sanitized_title": "solving_sudoku_using_probabilistic_graphical_models"
        },
        {
            "paper_title": "Deeply learning the messages in message passing inference.",
            "rating": 2,
            "sanitized_title": "deeply_learning_the_messages_in_message_passing_inference"
        },
        {
            "paper_title": "Can neural networks crack Sudoku?",
            "rating": 2,
            "sanitized_title": "can_neural_networks_crack_sudoku"
        },
        {
            "paper_title": "The graph neural network model.",
            "rating": 1,
            "sanitized_title": "the_graph_neural_network_model"
        }
    ],
    "cost": 0.0161805,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Recurrent Relational Networks
29 Nov 2018</p>
<p>Rasmus Berg Palm 
Technical University of Denmark</p>
<p>Ulrich Paquet 
Technical University of Denmark</p>
<p>Ole Winther 
MontréalCanada</p>
<p>Recurrent Relational Networks
29 Nov 2018B051F37279928CFF2A901074E47251DBarXiv:1711.08028v4[cs.AI]
This paper is concerned with learning to solve tasks that require a chain of interdependent steps of relational inference, like answering complex questions about the relationships between objects, or solving puzzles where the smaller elements of a solution mutually constrain each other.We introduce the recurrent relational network, a general purpose module that operates on a graph representation of objects.As a generalization ofSantoro et al. [2017]'s relational network, it can augment any neural network model with the capacity to do many-step relational reasoning.We achieve state of the art results on the bAbI textual question-answering dataset with the recurrent relational network, consistently solving 20/20 tasks.As bAbI is not particularly challenging from a relational reasoning point of view, we introduce Pretty-CLEVR, a new diagnostic dataset for relational reasoning.In the Pretty-CLEVR set-up, we can vary the question to control for the number of relational reasoning steps that are required to obtain the answer.Using Pretty-CLEVR, we probe the limitations of multi-layer perceptrons, relational and recurrent relational networks.Finally, we show how recurrent relational networks can learn to solve Sudoku puzzles from supervised training data, a challenging task requiring upwards of 64 steps of relational reasoning.We achieve state-of-the-art results amongst comparable methods by solving 96.6% of the hardest Sudoku puzzles. 1 We invite the reader to solve the Sudoku in the supplementary material to appreciate the difficulty of solving a Sudoku in which 17 cells are initially filled.32nd Conference on Neural Information Processing Systems (NeurIPS 2018),</p>
<p>Introduction</p>
<p>A central component of human intelligence is the ability to abstractly reason about objects and their interactions [Spelke et al., 1995, Spelke andKinzler, 2007].As an illustrative example, consider solving a Sudoku.A Sudoku consists of 81 cells that are arranged in a 9-by-9 grid, which must be filled with digits 1 to 9 so that each digit appears exactly once in each row, column and 3-by-3 non-overlapping box, with a number of digits given 1 .To solve a Sudoku, one methodically reasons about the puzzle in terms of its cells and their interactions over many steps.One tries placing digits in cells and see how that affects other cells, iteratively working toward a solution.</p>
<p>Contrast this with the canonical deep learning approach to solving problems, the multilayer perceptron (MLP), or multilayer convolutional neural net (CNN).These architectures take the entire Sudoku as an input and output the entire solution in a single forward pass, ignoring the inductive bias that objects exists in the world, and that they affect each other in a consistent manner.Not surprisingly these models fall short when faced with problems that require even basic relational reasoning [Lake et al., 2016, Santoro et al., 2017].</p>
<p>The relational network of Santoro et al. [2017] is an important first step towards a simple module for reasoning about objects and their interactions but it is limited to performing a single relational operation, and was evaluated on datasets that require a maximum of three steps of reasoning (which, surprisingly, can be solved by a single relational reasoning step as we show).Looking beyond relational networks, there is a rich literature on logic and reasoning in artificial intelligence and machine learning, which we discuss in section 5.</p>
<p>Toward generally realizing the ability to methodically reason about objects and their interactions over many steps, this paper introduces a composite function, the recurrent relational network.It serves as a modular component for many-step relational reasoning in end-to-end differentiable learning systems.It encodes the inductive biases that 1) objects exists in the world 2) they can be sufficiently described by properties 3) properties can change over time 4) objects can affect each other and 5) given the properties, the effects object have on each other is invariant to time.</p>
<p>An important insight from the work of Santoro et al. [2017] is to decompose a function for relational reasoning into two components or "modules": a perceptual front-end, which is tasked to recognize objects in the raw input and represent them as vectors, and a relational reasoning module, which uses the representation to reason about the objects and their interactions.Both modules are trained jointly end-to-end.In computer science parlance, the relational reasoning module implements an interface: it operates on a graph of nodes and directed edges, where the nodes are represented by real valued vectors, and is differentiable.This paper chiefly develops the relational reasoning side of that interface.</p>
<p>Some of the tasks we evaluate on can be efficiently and perfectly solved by hand-crafted algorithms that operate on the symbolic level.For example, 9-by-9 Sudokus can be solved in a fraction of a second with constraint propagation and search [Norvig, 2006] or with dancing links [Knuth, 2000].These symbolic algorithms are superior in every respect but one: they don't comply with the interface, as they are not differentiable and don't work with real-valued vector descriptions.They therefore cannot be used in a combined model with a deep learning perceptual front-end and learned end-to-end.</p>
<p>Following Santoro et al. [2017], we use the term "relational reasoning" liberally for an object-and interaction-centric approach to problem solving.Although the term "relational reasoning" is similar to terms in other branches of science, like relational logic or first order logic, no direct parallel is intended.</p>
<p>This paper considers many-step relational reasoning, a challenging task for deep learning architectures.We develop a recurrent relational reasoning module, which constitutes our main contribution.We show that it is a powerful architecture for many-step relational reasoning on three varied datasets, achieving state-of-the-art results on bAbI and Sudoku.</p>
<p>Recurrent Relational Networks</p>
<p>We ground the discussion of a recurrent relational network in something familiar, solving a Sudoku puzzle.A simple strategy works by noting that if a certain Sudoku cell is given as a "7", one can safely remove "7" as an option from other cells in the same row, column and box.In a message passing framework, that cell needs to send a message to each other cell in the same row, column, and box, broadcasting it's value as "7", and informing those cells not to take the value "7".In an iteration t, these messages are sent simultaneously, in parallel, between all cells.Each cell i should then consider all incoming messages, and update its internal state h t i to h t+1 i .With the updated state each cell should send out new messages, and the process repeats.</p>
<p>Message passing on a graph.The recurrent relational network will learn to pass messages on a graph.For Sudoku, the graph has i ∈ {1, 2, ..., 81} nodes, one for each cell in the Sudoku.Each node has an input feature vector x i , and edges to and from all nodes that are in the same row, column and box in the Sudoku.The graph is the input to the relational reasoning module, and vectors x i would generally be the output of a perceptual front-end, for instance a convolutional neural network.Keeping with our Sudoku example, each x i encodes the initial cell content (empty or given) and the row and column position of the cell.</p>
<p>At each step t each node has a hidden state vector h t i , which is initialized to the features, such that h 0 i = x i .At each step t, each node sends a message to each of its neighboring nodes.We define the message m t ij from node i to node j at step t by where f , the message function, is a multi-layer perceptron.This allows the network to learn what kind of messages to send.In our experiments, MLPs with linear outputs were used.Since a node needs to consider all the incoming messages we sum them with
m t ij = f h t−1 i , h t−1 j ,(1)h t 1 x 1 o t 1 h t 2 x 2 o t 2 h t 3 x 3 o t 3 m tm t j = i∈N (j) m t ij ,(2)
where N (j) are all the nodes that have an edge into node j.For Sudoku, N (j) contains the nodes in the same row, column and box as j.In our experiments, since the messages in (1) are linear, this is similar to how log-probabilities are summed in belief propagation [Murphy et al., 1999].</p>
<p>Recurrent node updates.Finally we update the node hidden state via
h t j = g h t−1 j , x j , m t j ,(3)
where g, the node function, is another learned neural network.The dependence on the previous node hidden state h t−1 j allows the network to iteratively work towards a solution instead of starting with a blank slate at every step.Injecting the feature vector x j at each step like this allows the node function to focus on the messages from the other nodes instead of trying to remember the input.</p>
<p>Supervised training.The above equations for sending messages and updating node states define a recurrent relational network's core.To train a recurrent relational network in a supervised manner to solve a Sudoku we introduce an output probability distribution over the digits 1-9 for each of the nodes in the graph.The output distribution o t i for node i at step t is given by
o t i = r h t i ,(4)
where r is a MLP that maps the node hidden state to the output probabilities, e.g. using a softmax nonlinearity.Given the target digits y = {y 1 , y 2 , ..., y 81 } the loss at step t, is then the sum of cross-entropy terms, one for each node: 1) to (4) are illustrated in figure 1.
l t = − I i=1 log o t i [y i ], where o i [y i ] is the y i 'th component of o i . Equations (</p>
<p>Convergent message passing.</p>
<p>A distinctive feature of our proposed model is that we minimize the cross entropy between the output and target distributions at every step.</p>
<p>At test time we only consider the output probabilities at the last step, but having a loss at every step during training is beneficial.Since the target digits y i are constant over the steps, it encourages the network to learn a convergent message passing algorithm.Secondly, it helps with the vanishing gradient problem.</p>
<p>Variations.If the edges are unknown, the graph can be assumed to be fully connected.In this case the network will need to learn which objects interact with each other.If the edges have attributes, e ij , the message function in equation 1 can be modified such that m t ij = f h t−1 i , h t−1 j , e ij .If the output of interest is for the whole graph instead of for each node the output in equation 4 can be modified such that there's a single output o t = r ( i h t i ).The loss can be modified accordingly.</p>
<p>Experiments</p>
<p>Code to reproduce all experiments can be found at github.com/rasmusbergpalm/recurrent-relationalnetworks.[Rae et al., 2016] 15 6.4 ± 2.5 4.1 ± 1.6 DAM [Rae et al., 2016] 15 8.7 ± 6.4 5.4 ± 3.4 SAM [Rae et al., 2016] 15 11.5 ± 5.9 7.1 ± 3.4 DNC [Rae et al., 2016] 15 12.8 ± 4.7 8.2 ± 2.5 NTM [Rae et al., 2016] 15 26.6 ± 3.7 15.5 ± 1.7 LSTM [Rae et al., 2016] 15 28.7 ± 0.5 17.1 ± 0.8 EntNet [Henaff et al., 2016] 5 9.7 ± 2.6 5 ± 1.2 ReMo [Yang et al., 2018] 1 1.2 1 RN [Santoro et al., 2017] 1 N/A 2 MemN2N [Sukhbaatar et al., 2015] 1 7.5 6 bAbI is a text based QA dataset from Facebook [Weston et al., 2015] designed as a set of prerequisite tasks for reasoning.It consists of 20 types of tasks, with 10,000 questions each, including deduction, induction, spatial and temporal reasoning.Each question, e.g."Where is the milk?" is preceded by a number of facts in the form of short sentences, e.g."Daniel journeyed to the garden.Daniel put down the milk."The target is a single word, in this case "garden", one-hot encoded over the full bAbI vocabulary of 177 words.A task is considered solved if a model achieves greater than 95% accuracy.The most difficult tasks require reasoning about three facts.</p>
<p>bAbI question-answering tasks</p>
<p>To map the questions into a graph we treat the facts related to a question as the nodes in a fully connected graph up to a maximum of the last 20 facts.The fact and question sentences are both encoded by Long Short Term Memory (LSTM) [Hochreiter and Schmidhuber, 1997] layers with 32 hidden units each.We concatenate the last hidden state of each LSTM and pass that through a MLP.</p>
<p>The output is considered the node features x i .Following [Santoro et al., 2017] all edge features e ij are set to the question encoding.We train the network for three steps.At each step, we sum the node hidden states and pass that through a MLP to get a single output for the whole graph.For details see the supplementary material.</p>
<p>Our trained network solves 20 of 20 tasks in 13 out of 15 runs.This is state-of-the-art and markedly more stable than competing methods.See table 1.We perform ablation experiment to see which parts of the model are important, including varying the number of steps.We find that using dropout and appending the question encoding to the fact encodings is important for the performance.See the supplementary material for details.</p>
<p>Surprisingly, we find that we only need a single step of relational reasoning to solve all the bAbI tasks.This is surprising since the hardest tasks requires reasoning about three facts.It's possible that there are superficial correlations in the tasks that the model learns to exploit.Alternatively the model learns to compress all the relevant fact-relations into the 128 floats resulting from the sum over the node hidden states, and perform the remaining reasoning steps in the output MLP.Regardless, it appears multiple steps of relational reasoning are not important for the bAbI dataset.</p>
<p>Pretty-CLEVR</p>
<p>Given that bAbI did not require multiple steps of relational reasoning and in order to test our hypothesis that our proposed model is better suited for tasks requiring more steps of relational reasoning we create a diagnostic dataset "Pretty-CLEVER".It can be seen as an extension of the "Sort-of-CLEVR" data set by [Santoro et al., 2017] which has questions of a non-relational and relational nature."Pretty-CLEVR" takes this a step further and has non-relational questions as well as questions requiring varying degrees of relational reasoning.For the topmost sample the solution to the question: "green, 3 jumps", which is "plus", is shown with arrows.2b Random corresponds to picking one of the eight possible outputs at random (colors or shapes, depending on the input).The RRN is trained for four steps but since it predicts at each step we can evaluate the performance for each step.The the number of steps is stated in parentheses.</p>
<p>Pretty-CLEVR consists of scenes with eight colored shapes and associated questions.Questions are of the form: "Starting at object X which object is N jumps away?".Objects are uniquely defined by their color or shape.If the start object is defined by color, the answer is a shape, and vice versa.Jumps are defined as moving to the closest object, without going to an object already visited.See figure 2a.Questions with zero jumps are non-relational and correspond to: "What color is shape X?" or "What shape is color X?".We create 100,000 random scenes, and 128 questions for each (8 start objects, 0-7 jumps, output is color or shape), resulting in 12.8M questions.We also render the scenes as images.The "jump to nearest" type question is chosen in an effort to eliminate simple correlations between the scene state and the answer.It is highly non-linear in the sense that slight differences in the distance between objects can cause the answer to change drastically.It is also asymmetrical, i.e. if the question "x, n jumps" equals "y", there is no guarantee that "y, n jumps" equals "x".We find it is a surprisingly difficult task to solve, even with a powerful model such as the RRN.We hope others will use it to evaluate their relational models. 2ince we are solely interested in examining the effect of multiple steps of relational reasoning we train on the state descriptions of the scene.We consider each scene as a fully connected undirected graph with 8 nodes.The feature vector for each object consists of the position, shape and color.We encode the question as the start object shape or color and the number of jumps.As we did for bAbI we concatenate the question and object features and pass it through a MLP to get the node features x i .To make the task easier we set the edge features to the euclidean distance between the objects.We train our network for four steps and compare to a single step relational network and a baseline MLP that considers the entire scene state, all pairwise distances, and the question as a single vector.For details see the supplementary material.</p>
<p>Mirroring the results from the "Sort-of-CLEVR" dataset the MLP perfectly solves the non-relational questions, but struggle with even single jump questions and seem to lower bound the performance of the relational networks.The relational network solves the non-relational questions as well as the ones requiring a single jump, but the accuracy sharply drops off with more jumps.This matches the performance of the recurrent relational network which generally performs well as long as the number of steps is greater than or equal to the number of jumps.See fig 2b.It seems that, despite our best efforts, there are spurious correlations in the data such that questions with six to seven jumps are easier to solve than those with four to five jumps.</p>
<p>Sudoku</p>
<p>We create training, validation and testing sets totaling 216,000 Sudoku puzzles with a uniform distribution of givens between 17 and 34.We consider each of the 81 cells in the 9x9 Sudoku grid a node in a graph, with edges to and from each other cell in the same row, column and box.The node features x i are the output of a MLP which takes as input the digit for the cell (0-9, 0 if not given), and the row and column position (1-9).Edge features are not used.We run the network for 32 steps and at every step the output function r maps each node hidden state to nine output logits corresponding to the nine possible digits.For details see the supplementary material.Our network learns to solve 94.1% of even the hardest 17-givens Sudokus after 32 steps.We only consider a puzzled solved if all the digits are correct, i.e. no partial credit is given for getting individual digits correct.For more givens the accuracy (fraction of test puzzles solved) quickly approaches 100%.Since the network outputs a probability distribution for each step, we can visualize how the network arrives at the solution step by step.For an example of this see figure 3.</p>
<p>To examine our hypothesis that multiple steps are required we plot the accuracy as a function of the number of steps.See figure 4. We can see that even simple Sudokus with 33 givens require upwards of 10 steps of relational reasoning, whereas the harder 17 givens continue to improve even after 32 steps.Figure 4 also shows that the model has learned a convergent algorithm.The model was trained for 32 steps, but seeing that the accuracy increased with more steps, we ran the model for 64 steps during testing.At 64 steps the accuracy for the 17 givens puzzles increases to 96.6%.</p>
<p>We also examined the importance of the row and column features by multiplying the row and column embeddings by zero and re-tested our trained network.We compare our network to several other differentiable methods.See table 2. We train two relational networks: a node and a graph centric.For details see the supplementary material.Of the two, the node centric was considerably better.The node centric correspond exactly to our proposed network with a single step, yet fails to solve any Sudoku.This shows that multiple steps are crucial for complex relational reasoning.Our network outperforms loopy belief propagation, with parallel and random messages passing updates [Bauke, 2008].It also outperforms a version of loopy belief propagation modified specifically for solving Sudokus that uses 250 steps, Sinkhorn balancing every two steps and iteratively picks the most probable digit [Khan et al., 2014].We also compare to learning the messages in parallel loopy BP as presented in Lin et al. [2015].We tried a few variants including a single step as presented and 32 steps with and without a loss on every step, but could not get it to solve any 17 given Sudokus.Finally we outperform Park [2016] which treats the Sudoku as a 9x9 image, uses 10 convolutional layers, iteratively picks the most probable digit, and evaluate on easier Sudokus with 24-36 givens.We also tried to train a version of our network that only had a loss at the last step.It was harder to train, performed worse and didn't learn a convergent algorithm.[Khan et al., 2014] 17 92.5% Loopy BP, random [Bauke, 2008] 17 61.7%Loopy BP, parallel [Bauke, 2008] 17 53.2%Deeply Learned Messages<em> [Lin et al., 2015] 17 0% Relational Network, node</em> [Santoro et al., 2017] 17 0% Relational Network, graph* [Santoro et al., 2017] 17 0% Deep Convolutional Network [Park, 2016] 24-36 70%</p>
<p>Age arithmetic</p>
<p>Anonymous reviewer 2 suggested the following task which we include here.The task is to infer the age of a person given a single absolute age and a set of age differences, e.g."Alice is 20 years old.</p>
<p>Alice is 4 years older than Bob.Charlie is 6 years younger than Bob.How old is Charlie?".Please see the supplementary material for details on the task and results.</p>
<p>Discussion</p>
<p>We have proposed a general relational reasoning model for solving tasks requiring an order of magnitude more complex relational reasoning than the current state-of-the art.BaBi and Sort-of-CLEVR require a few steps, Pretty-CLEVR requires up to eight steps and Sudoku requires more than ten steps.Our relational reasoning module can be added to any deep learning model to add a powerful relational reasoning capacity.We get state-of-the-art results on Sudokus solving 96.6% of the hardest Sudokus with 17 givens.We also markedly improve state-of-the-art on the BaBi dataset solving 20/20 tasks in 13 out of 15 runs with a single model trained jointly on all tasks.</p>
<p>One potential issue with having a loss at every step is that it might encourage the network to learn a greedy algorithm that gets stuck in a local minima.However, the output function r separates the node hidden states and messages from the output probability distributions.The network therefore has the capacity to use a small part of the hidden state for retaining a current best guess, which can remain constant over several steps, and other parts of the hidden state for running a non-greedy multi-step algorithm.</p>
<p>Sending messages for all nodes in parallel and summing all the incoming messages might seem like an unsophisticated approach that risk resulting in oscillatory behavior and drowning out the important messages.However, since the receiving node hidden state is an input to the message function, the receiving node can in a sense determine which messages it wishes to receive.As such, the sum can be seen as an implicit attention mechanism over the incoming messages.Similarly the network can learn an optimal message passing schedule, by ignoring messages based on the history and current state of the receiving and sending node.</p>
<p>Related work</p>
<p>Relational networks [Santoro et al., 2017] and interaction networks [Battaglia et al., 2016] are the most directly comparable to ours.These models correspond to using a single step of equation 3.</p>
<p>Since it only does one step it cannot naturally do complex multi-step relational reasoning.In order to solve the tasks that require more than a single step it must compress all the relevant relations into a fixed size vector, then perform the remaining relational reasoning in the last forward layers.Relational networks, interaction networks and our proposed model can all be seen as an instance of Graph Neural Networks [Scarselli et al., 2009, Gilmer et al., 2017].</p>
<p>Graph neural networks with message passing computations go back to Scarselli et al. [2009].However, there are key differences that we found important for implementing stable multi-step relational reasoning.Including the node features x j at every step in eq. 3 is important to the stability of the network.Scarselli et al. [2009], eq. 3 has the node features, l n , inside the message function.Battaglia et al. [2016] use an x j in the node update function, but this is an external driving force.Sukhbaatar et al. [2016] also proposed to include the node features at every step.Optimizing the loss at every step in order to learn a convergent message passing algorithm is novel to the best of our knowledge.Scarselli et al. [2009] introduces an explicit loss term to ensure convergence.Ross et al. [2011] trains the inference machine predictors on every step, but there are no hidden states; the node states are the output marginals directly, similar to how belief propagation works.</p>
<p>Our model can also be seen as a completely learned message passing algorithm.Belief propagation is a hand-crafted message passing algorithm for performing exact inference in directed acyclic graphical models.If the graph has cycles, one can use a variant, loopy belief propagation, but it is not guaranteed to be exact, unbiased or converge.Empirically it works well though and it is widely used [Murphy et al., 1999].Several works have proposed replacing parts of belief propagation with learned modules [Heess et al., 2013, Lin et al., 2015].Our work differs by not being rooted in loopy BP, and instead learning all parts of a general message passing algorithm.Ross et al. [2011] proposes Inference Machines which ditch the belief propagation algorithm altogether and instead train a series of regressors to output the correct marginals by passing messages on a graph.Wei et al. [2016] applies this idea to pose estimation using a series of convolutional layers and Deng et al. [2016] introduces a recurrent node update for the same domain.</p>
<p>There is rich literature on combining symbolic reasoning and logic with sub-symbolic distributed representations which goes all the way back to the birth of the idea of parallel distributed processing McCulloch and Pitts [1943].See [Raedt et al., 2016, Besold et al., 2017] for two recent surveys.</p>
<p>Here we describe only a few recent methods.Serafini and Garcez [2016] introduces the Logic Tensor Network (LTN) which describes a first order logic in which symbols are grounded as vector embeddings, and predicates and functions are grounded as tensor networks.The embeddings and tensor networks are then optimized jointly to maximize a fuzzy satisfiability measure over a set of known facts and fuzzy constraints.Šourek et al. [2015] introduces the Lifted Relational Network which combines relational logic with neural networks by creating neural networks from lifted rules and training examples, such that the connections between neurons created from the same lifted rules shares weights.Our approach differs fundamentally in that we do not aim to bridge symbolic and sub-symbolic methods.Instead we stay completely in the sub-symbolic realm.We do not introduce or consider any explicit logic, aim to discover (fuzzy) logic rules, or attempt to include prior knowledge in the form of logical constraints.Amos and Kolter [2017] Introduces OptNet, a neural network layer that solve quadratic programs using an efficient differentiable solver.OptNet is trained to solve 4x4 Sudokus amongst other problems and beats the deep convolutional network baseline as described in Park [2016].Unfortunately we cannot compare to OptNet directly as it has computational issues scaling to 9x9 Sudokus (Brandon Amos, 2018, personal communication).Sukhbaatar et al. [2016] proposes the Communication Network (CommNet) for learning multi-agent cooperation and communication using back-propagation.It is similar to our recurrent relational network, but differs in key aspects.The messages passed between all nodes at a given step are the same, corresponding to the average of all the node hidden states.Also, it is not trained to minimize the loss on every step of the algorithm.</p>
<p>6 Supplementary Material</p>
<p>bAbI experimental details</p>
<p>Unless otherwise specified we use 128 hidden units for all layers and all MLPs are 3 ReLU layers followed by a linear layer.</p>
<p>We compute each node feature vector as
x i = MLP(concat(last(LSTM S (s i )), last(LSTM Q (q)), onehot(p i + o)))
where s i is fact i, q is the question, p i is the sentence position (1-20) of fact i and o is a random offset per question (1-20), such that the onehot output is 40 dimensional.The offset is constant for all facts related to a single question to avoid changing the relative order of the facts.The random offset prevents the network from memorizing the position of the facts and rather reason about their ordering.Our message function f is a MLP.Our node function g uses an LSTM over reasoning steps
h t j , s t j = LSTM G (MLP(concat(x j , m t j )), s t−1 j ) ,
where s t j is the cell state of the LSTM for unit j at time t.s 0 j is initialized to zero.We run our network for three steps.To get a graph level output, we use a MLP over the sum of the node hidden states, o t = MLP ( i h t i ) with 3 layers, the final being a linear layer that maps to the output logits.The last two layers uses dropout of 50%.We train and validate on all 20 tasks jointly using the 9,000 training and 1,000 validation samples defined in the en_valid_10k split.We use the Adam optimizer with a batch size of 512, a learning rate of 2e-4 and L2 regularization with a rate of 1e-5.We train for 5M gradient steps.</p>
<p>bAbI ablation experiments</p>
<p>To test which parts of the proposed model is important to solving the bAbI tasks we perform ablation experiments.One of the main differences between the relational network and our proposed model, aside from the recurrent steps, is that we encode the sentences and question together.We ablate the model in two ways to test how important this is. 1) Using a single linear layer instead of the 4-layer MLP baseline, and 2) Not encoding them together.In this case the node hidden states are initialized to the fact encodings.We found dropout to be important, so we also perform an ablation experiment without dropout.We run each ablation experiment eight times.We also do pseudo-ablation experiments with fewer steps by measuring at each step of the RRN.See table 3 3: BaBi ablation results.</p>
<p>Pretty-CLEVR experimental details</p>
<p>Our setup for Pretty-CLEVR is a bit simpler than for bAbI.Unless otherwise specified we use 128 hidden units for all hidden layers and all MLPs are 1 ReLU layer followed by a linear layer.</p>
<p>We compute each node feature vector x i as
o i = concat(p i , onehot(c i ), onehot(m i )) q = concat(onehot(s), onehot(n)) x i = MLP(concat(o i , q))
where p i ∈ [0, 1] 2 is the position, N n ≡ {0, ..., n − 1}, c i ∈ N 8 is the color, m i ∈ N 8 is the marker, s ∈ N 16 is the marker or color of the start object, and n ∈ N 8 is the number of jumps.</p>
<p>Our message function f is a MLP.Our node function g is,
h t j = MLP(concat(h t−1 j , x j , m t j ))
Our output function r is a MLP with a dropout fraction of 0.5 in the penultimate layer.The last layer has 16 hidden linear units.We run our recurrent relational network for 4 steps.</p>
<p>We train on the 12.8M training questions, and augment the data by scaling and rotating the scenes randomly.We use separate validation and test sets of 128.000 questions each.We use the Adam optimizer with a learning rate of 1e-4 and train for 10M gradient updates with a batch size of 128.</p>
<p>The baseline RN is identical to the described RRN, except it only does a single step of relational reasoning.</p>
<p>The baseline MLP takes the entire scene state, x, as an input, such that x = concat(o 0 , ..., o 7 , d 00 , ..., d 77 , q)</p>
<p>where d ij ∈ R is the euclidean distance from object i to j.</p>
<p>The baseline MLP has 4 ReLu layers with 256 hidden units, with dropout of 0.5 on the last layer, followed by a linear layer with 16 hidden units.The baseline MLP has 87% more parameters than the RRN and RN (261,136 vs 139,536).</p>
<p>Sudoku dataset</p>
<p>To generate our dataset the starting point is the collection of 49,151 unique 17-givens puzzles gathered by Royle [2014] which we solve using the solver from Norvig [2006].Then we split the puzzles into a test, validation and training pool, with 10,000, 1,000 and 38,151 samples respectively.To generate the sets we train, validate and test on we do the following: for each n ∈ {0, ..., 17} we sample k puzzles from the respective pool, with replacement.For each sampled puzzle we add n random digits from the solution.We then swap the digits according to a random permutation, e.g. 1 → 5, 2 → 3, etc.The resulting puzzle is added to the respective set.For the test, validation and training sets we sample k = 1, 000, k = 1, 000 and k = 10, 000 puzzles in this way.</p>
<p>Sudoku experimental details</p>
<p>Unless otherwise specified we use 96 hidden units for all hidden layers and all MLPs are 3 ReLU layers followed by a linear layer.</p>
<p>Denote the digit for cell j d j (0-9, 0 if not given), and the row and column position row j (1-9) and column j (1-9) respectively.. The node features are then
x j = MLP(concat(embed(d j ), embed(row j ), embed(column j )))
where each embed is a 16 dimensional learned embedding.We could probably have used one-hot encoding instead of the embeddings, embedding was just the first thing we tried.Edge features were not used.The message function f is an MLP.The node function g, is identical to the setup for bAbI, i.e.</p>
<p>h t j , s t j = LSTM G (MLP(concat(x j , m t j )), s t−1 j ) .The LSTM cell state is initialized to zeros.</p>
<p>The output function r is a linear layer with nine outputs to produce the output logits o t i .We run the network for 32 steps with a loss on every step.We train the model for 300.000 gradient updates with a batch size of 256 using Adam with a learning rate of 2e-4 and L2 regularization of 1e-4 on all weight matrices.</p>
<p>Sudoku relational network baseline details</p>
<p>The node centric corresponds exactly to a single step of our network.The graph centric approach is closer to the original relational network.It does one step of relational reasoning as our network, then sums all the node hidden states.The sum is then passed through a 4 layer MLP with 81 • 9 outputs, one for each cell and digit.The graph centric model has larger hidden states of 256 in all layers to compensate somewhat for the sum squashing the entire graph into a fixed size vector.Otherwise both networks are identical to our network.The graph centric has over 4 times as many parameters as our model (944,874 vs. 201,194) but performs worse than the node centric.</p>
<p>Age arithmetic task details</p>
<p>We generated all 262,144 unique trees with 8 nodes and split them 90%/10% into training and test graphs.The nodes represent the persons, and the edges which age differences will be given to the network.During training and testing we sample a batch of graphs from the respective set and sample 8 random ages (0-99) for each.We compute the absolute difference as well as the sign for each edge in the graphs.This gives us 7 relative facts on the form "person A (0-7), person B (0-7), younger/older (-1,1), absolute age difference (0-99)".Then we add the final fact which is the age of one of the nodes at random, e.g."3, 3, 0, 47", using the zero sign to indicate this fact is absolute and not relative.The question is the age of one of the persons at random (0-7).For each graph we compute the shortest path from the anchor person to the person in question.This is the minimum number of arithmetic computations that must be performed to infer the persons age from the given facts.</p>
<p>The 8 facts (1 anchor, 7 relative) are given to the network as a fully connected graph of 8 nodes.Note, this graph is different from the tree used to generate the facts.The network never sees the tree.The input vector for each fact are the four fact integers and the question integer one-hot encoded and concatenated.We use the same architecture as for the bAbI experiments except all MLPs are 3 dense layers with 128 ReLu units followed by one linear layer.We train the network for 8 steps, and test it for each step.See figure 5 for results.x 1 An example Sudoku.Each of the 81 cells contain each digit 1-9, which is useful if the reader wishes to try to solve the Sudoku as they can be crossed out or highlighted, etc.The digit font size corresponds to the probability our model assigns to each digit at step 0, i.e. before any steps are taken.Subsequent pages contains the Sudoku as it evolves with more steps of our model.
x 2 x 3 x 1 x 2 x 3 x 1 x 2 x 3 h 0 1 o 0 1 h 0 2 o 0 2 h 0 3 o 0 3 h 1 1 o 1 1 h 1 2 o 1 2 h 1 3 o 1 3 h 2 1 o 2 1 h 2 2 o 2
Figure 2 :
2
Figure2: 2a Two samples of the Pretty-CLEVR diagnostic dataset.Each sample has 128 questions associated, exhibiting varying levels of relational reasoning difficulty.For the topmost sample the solution to the question: "green, 3 jumps", which is "plus", is shown with arrows.2b Random corresponds to picking one of the eight possible outputs at random (colors or shapes, depending on the input).The RRN is trained for four steps but since it predicts at each step we can evaluate the performance for each step.The the number of steps is stated in parentheses.</p>
<p>Figure 3 :
3
Figure3: Example of how the trained network solves part of a Sudoku.Only the top row of a full 9x9 Sudoku is shown for clarity.From top to bottom steps 0, 1, 8 and 24 are shown.See the supplementary material for a full Sudoku.Each cell displays the digits 1-9 with the font size scaled (non-linearly for legibility) to the probability the network assigns to each digit.Notice how the network eliminates the given digits 6 and 4 from the other cells in the first step.Animations showing how the trained network solves Sodukos, including a failure case can be found at imgur.com/a/ALsfB.</p>
<p>Figure 5 :
5
Figure 5: Results for the age arithmetic task.The number in parenthesis indicate how many steps the RRN was run during testing.Random corresponds to picking one of the 100 possible ages randomly.</p>
<p>on a fully connected graph with 3 nodes.Subscripts denote node indices and superscripts denote steps t.The dashed lines indicate the recurrent connections.</p>
<p>recurrent relational network on a fully connected graph with 3 nodes.The nodes' hidden states h t i are highlighted with green, the inputs x i with red, and the outputs o t i with blue.The dashed lines indicate the recurrent connections.Subscripts denote node indices and superscripts denote steps t.For a figure of the same graph unrolled over 2 steps see the supplementary material.
m t 13m t 32m t 31m t 2312m t 21Figure 1: A</p>
<p>Table 1
1: bAbI results. Trained jointly on all 20 tasks using the 10,000 training samples. Entriesmarked with an asterix are our own experiments, the rest are from the respective papers.MethodN Mean Error (%) Failed tasks (err. &gt;5%)RRN* (this work)150.46 ± 0.770.13 ± 0.35SDNC</p>
<p>At 64 steps with 17 givens, the accuracy changed to 96.7%.It thus seems the network does not use the row and column position information to solve the task.Fraction of test puzzles solved as a function of number of steps.Even simple Sudokus with 33 givens require about 10 steps of relational reasoning to be solved.The dashed vertical line indicates the 32 steps the network was trained for.The network appears to have learned a convergent relational reasoning algorithm such that more steps beyond 32 improve on the hardest Sudokus.
1.00.8Accuracy0.0 0.2 0.4 0.617 givens 19 givens 21 givens 23 givens 25 givens 27 givens 29 givens 31 givens 33 givens0102030 Steps405060Figure 4:</p>
<p>Table 2 :
2
Comparison of methods for solving Sudoku puzzles.Only methods that are differentiable are included in the comparison.Entries marked with an asterix are our own experiments, the rest are from the respective papers.
MethodGivens AccuracyRecurrent Relational Network* (this work)1796.6%Loopy BP, modified</p>
<p>.
ModelRuns Mean Error (%) Failed tasks (err. &gt;5%) Mean error @ 1M updates (%)Baseline, 3 steps150.46 ± 0.770.13 ± 0.351.83 ± 1.06Baseline, 2 steps150.46 ± 0.760.13 ± 0.351.83 ± 1.06Baseline, 1 step150.48 ± 0.790.13 ± 0.351.84 ± 1.06linear encoding80.20 ± 0.010 ± 00.63 ± 0.69no encoding80.53 ± 0.910.13 ± 0.352.39 ± 1.73no dropout81.74 ± 1.280.63 ± 0.522.57 ± 0.95Table
Pretty-CLEVR is available online as part of the code for reproducing experiments.
AcknowledgmentsWe'd like to thank the anonymous reviewers for the valuable comments and suggestions, especially reviewer 2 who suggested the age arithmetic task.This research was supported by the NVIDIA Corporation with the donation of TITAN X GPUs.Step 12
Brandon Amos, Kolter Zico, arXiv:1703.00443Optnet: Differentiable optimization as a layer in neural networks. 2017arXiv preprint</p>
<p>Interaction networks for learning about objects, relations and physics. Peter Battaglia, Razvan Pascanu, Matthew Lai, Danilo Jimenez Rezende, Advances in Neural Information Processing Systems. 2016</p>
<p>Passing messages to lonely numbers. Heiko Bauke, Computing in Science &amp; Engineering. 1022008</p>
<p>Neural-symbolic learning and reasoning: A survey and interpretation. Artur D'avila Tarek R Besold, Sebastian Garcez, Howard Bader, Pedro Bowman, Pascal Domingos, Kai-Uwe Hitzler, Luis C Kühnberger, Daniel Lamb, Priscila Machado Lowd, Vieira Lima, arXiv:1711.039022017arXiv preprint</p>
<p>Structure inference machines: Recurrent neural networks for analyzing relations in group activity recognition. Zhiwei Deng, Arash Vahdat, Hexiang Hu, Greg Mori, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition2016</p>
<p>Justin Gilmer, Patrick F Samuel S Schoenholz, Oriol Riley, George E Vinyals, Dahl, arXiv:1704.01212Neural message passing for quantum chemistry. 2017arXiv preprint</p>
<p>Learning to pass expectation propagation messages. Nicolas Heess, Daniel Tarlow, John Winn, Advances in Neural Information Processing Systems. 2013</p>
<p>Tracking the world state with recurrent entity networks. Mikael Henaff, Jason Weston, Arthur Szlam, Antoine Bordes, Yann Lecun, arXiv:1612.039692016arXiv preprint</p>
<p>Long short-term memory. Sepp Hochreiter, Jürgen Schmidhuber, Neural computation. 981997</p>
<p>Solving Sudoku using probabilistic graphical models. Sheehan Khan, Shahab Jabbari, Shahin Jabbari, Majid Ghanbarinejad, 2014</p>
<p>Dancing links. Donald E Knuth, arXiv preprint cs/00110472000</p>
<p>Building machines that learn and think like people. Brenden M Lake, Joshua B Tomer D Ullman, Samuel J Tenenbaum, Gershman, Behavioral and Brain Sciences. 2016</p>
<p>Ian Reid, and Anton van den Hengel. Deeply learning the messages in message passing inference. Guosheng Lin, Chunhua Shen, Advances in Neural Information Processing Systems. 2015</p>
<p>A logical calculus of the ideas immanent in nervous activity. S Warren, Walter Mcculloch, Pitts, The bulletin of mathematical biophysics. 541943</p>
<p>Loopy belief propagation for approximate inference: An empirical study. Kevin P Murphy, Yair Weiss, Michael I Jordan, Proceedings of the Fifteenth conference on Uncertainty in artificial intelligence. the Fifteenth conference on Uncertainty in artificial intelligenceMorgan Kaufmann Publishers Inc1999</p>
<p>Kyubyong Park. Can neural networks crack Sudoku?. Peter Norvig, 2006. 2016Solving every Sudoku puzzle</p>
<p>Scaling memory-augmented neural networks with sparse reads and writes. Jack Rae, Jonathan J Hunt, Ivo Danihelka, Timothy Harley, Andrew W Senior, Gregory Wayne, Alex Graves, Tim Lillicrap, Advances in Neural Information Processing Systems. 2016</p>
<p>Statistical relational artificial intelligence: Logic, probability, and computation. Luc De Raedt, Kristian Kersting, Sriraam Natarajan, David Poole, Synthesis Lectures on Artificial Intelligence and Machine Learning. 201610</p>
<p>Learning message-passing inference machines for structured prediction. Stephane Ross, Daniel Munoz, Martial Hebert, Andrew Bagnell, Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on. IEEE2011</p>
<p>Gordon Royle, Minimum Sudoku. 2014</p>
<p>Adam Santoro, David Raposo, G T David, Mateusz Barrett, Razvan Malinowski, Peter Pascanu, Timothy Battaglia, Lillicrap, arXiv:1706.01427A simple neural network module for relational reasoning. 2017arXiv preprint</p>
<p>The graph neural network model. Franco Scarselli, Marco Gori, Chung Ah, Markus Tsoi, Gabriele Hagenbuchner, Monfardini, IEEE Transactions on Neural Networks. 2012009</p>
<p>Learning and reasoning with logic tensor networks. Luciano Serafini, Artur S D'avila Garcez, AI* IA 2016 Advances in Artificial Intelligence. Springer2016</p>
<p>Lifted relational neural networks. Gustav Šourek, Vojtech Aschenbrenner, Filip Železny, Ondřej Kuželka, Proceedings of the 2015th International Conference on Cognitive Computation: Integrating Neural and Symbolic Approaches. the 2015th International Conference on Cognitive Computation: Integrating Neural and Symbolic ApproachesCEUR-WS. org20151583</p>
<p>Core knowledge. S Elizabeth, Katherine D Spelke, Kinzler, Developmental science. 1012007</p>
<p>Sainbayar Sukhbaatar, Jason Weston, Rob Fergus, et al. End-to-end memory networks. Grant Elizabeth S Spelke, Gretchen Gutheil, Van De Walle, Advances in neural information processing systems. 1995. 2015The development of object perception</p>
<p>Learning multiagent communication with backpropagation. Sainbayar Sukhbaatar, Rob Fergus, Advances in Neural Information Processing Systems. 2016</p>
<p>Convolutional pose machines. Shih-En Wei, Varun Ramakrishna, Takeo Kanade, Yaser Sheikh, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition2016</p>
<p>Jason Weston, Antoine Bordes, Sumit Chopra, Alexander M Rush, Bart Van Merriënboer, Armand Joulin, Tomas Mikolov, arXiv:1502.05698Towards AI-complete question answering: A set of prerequisite toy tasks. 2015arXiv preprint</p>
<p>Finding remo (related memory object): A simple neural architecture for text based reasoning. Hyochang Yang, Sungzoon Cho, arXiv:1801.084592018arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>