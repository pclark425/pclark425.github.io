<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6449 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6449</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6449</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-128.html">extraction-schema-128</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM agents applied to text‚Äëbased games and how they use memory, including details of the memory mechanism, what is stored, how it is retrieved, and any reported performance differences with and without memory.</div>
                <p><strong>Paper ID:</strong> paper-268819055</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2404.00573v1.pdf" target="_blank">"My agent understands me better": Integrating Dynamic Human-like Memory Recall and Consolidation in LLM-Based Agents</a></p>
                <p><strong>Paper Abstract:</strong> In this study, we propose a novel human-like memory architecture designed for enhancing the cognitive abilities of large language model based dialogue agents. Our proposed architecture enables agents to autonomously recall memories necessary for response generation, effectively addressing a limitation in the temporal cognition of LLMs. We adopt the human memory cue recall as a trigger for accurate and efficient memory recall. Moreover, we developed a mathematical model that dynamically quantifies memory consolidation, considering factors such as contextual relevance, elapsed time, and recall frequency. The agent stores memories retrieved from the user's interaction history in a database that encapsulates each memory's content and temporal context. Thus, this strategic storage allows agents to recall specific memories and understand their significance to the user in a temporal context, similar to how humans recognize and recall past experiences.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6449.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6449.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM agents applied to text‚Äëbased games and how they use memory, including details of the memory mechanism, what is stored, how it is retrieved, and any reported performance differences with and without memory.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Human-like Memory Agent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Dynamic Human-like Memory Recall and Consolidation model (proposed)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An LLM-based dialogue agent architecture that augments GPT-4 with an external vector memory (Qdrant + Firestore) and a mathematically modeled consolidation/recall mechanism using relevance (cosine similarity), elapsed time, and recall frequency to trigger retrieval and update memory strength.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>My agent understands me better: Integrating Dynamic Human-like Memory Recall and Consolidation in LLM-Based Agents</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Temporal Cognition Agent</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>An LLM (GPT-4-0613) dialogue agent which, on each user input, vectorizes the text, searches an external vector DB (Qdrant) and Firestore chat history for episodic events, computes a recall-probability p_n(t) from relevance (cosine similarity), elapsed time and recall-frequency (via a consolidation state g_n), triggers recall if p_n exceeds a threshold (‚âà0.86), and inserts the single retrieved event into the LLM prompt; consolidation g_n is updated with a bounded modified-sigmoid S(t) on each recall so memory decay slows with repeated recalls.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4-0613</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external vector database + key-value store (Qdrant for vector search; Firestore for chat history)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>episodic dialogue memories: text content and temporal context encoded as vector embeddings; also stored as key-value pairs for semantic structure</td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_mechanism</strong></td>
                            <td>rule-based consolidation update: maintain g_n per memory; on each recall increment g_n by S(t)=1 - e^{-t} / (1+ e^{-t}) (modified sigmoid), which reduces the decay rate (1/g_n); timestamped writes to DB; no absolute forgetting (degree never reaches zero)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>nearest-neighbour vector search (cosine similarity) via Qdrant combined with a recall-probability trigger p_n(t) = normalized(1 - exp(-r * e^{-t/g_n})); recall fired when p_n(t) > threshold (~0.86)</td>
                        </tr>
                        <tr>
                            <td><strong>training_method</strong></td>
                            <td>prompt-based interaction with GPT-4 (no additional supervised fine-tuning reported)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>loss computed as mean squared error between softmax-normalized model scores and one-hot true labels (used as a proxy for recall accuracy); statistical tests (t-test) on loss differences</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Proposed model (with its consolidation/recall mechanism) achieved statistically significantly lower loss than the Generative Agents baseline: t = -5.687, p = 0.000299; 95% CI for mean difference [-0.27, -0.12] (numeric aggregate losses not explicitly reported in paper)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_findings</strong></td>
                            <td>No formal ablation on memory size/horizon reported. Analysis shows the model's consolidation mechanism favors long-interval, highly relevant memories (stronger retention with longer recall intervals) producing different recall choices than a recency-weighted baseline; trial-suggested recall trigger ‚âà0.86. Table 1 illustrates differences in selection behavior (prioritizing long-term consolidated events vs. recency).</td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td>Relies on long-term behavioral patterns for consolidation and may mis-predict when user behavior changes abruptly (limited adaptability to regime shifts); potential storage and computational overhead of DB interactions not analyzed; tendency to over-prioritize long-term patterns over novel, single-event context (failure case shown in Task 0).</td>
                        </tr>
                        <tr>
                            <td><strong>best_practices_recommendations</strong></td>
                            <td>Insert only one retrieved past dialogue into the prompt to control prompt length; compute relevance as cosine similarity on embeddings; combine relevance, elapsed time and recall-frequency in consolidation calculation; use a recall-probability trigger (paper suggests ‚âà0.86) to fire retrieval; encode memories as timestamped episodic vectors and key-value pairs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': '"My agent understands me better": Integrating Dynamic Human-like Memory Recall and Consolidation in LLM-Based Agents', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6449.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6449.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM agents applied to text‚Äëbased games and how they use memory, including details of the memory mechanism, what is stored, how it is retrieved, and any reported performance differences with and without memory.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Generative Agents</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative Agents: Interactive Simulacra of Human Behavior</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A previously published agent memory mechanism that scores memory elements by recency, importance, and relevance (normalized via min-max) and selects memories for use in agent decision-making and response generation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Generative Agents: Interactive Simulacra of Human Behavior</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>My agent understands me better: Integrating Dynamic Human-like Memory Recall and Consolidation in LLM-Based Agents</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Generative Agents (as described by Park et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Memory scoring system composed of three elements‚Äîrecency, importance, and relevance‚Äîthat are normalized and combined to rank and retrieve past events for an agent's decision-making; used as a baseline for comparison in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>scoring-based external memory (recency / importance / relevance scoring)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>events/memory elements (past actions, observations, events) stored with metadata used to compute recency/importance/relevance scores</td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_mechanism</strong></td>
                            <td>score updates based on recency, assigned importance and computed relevance; normalization (min-max scaling) applied before selection</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>score-based ranking and selection (highest-scoring memory chosen)</td>
                        </tr>
                        <tr>
                            <td><strong>training_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_findings</strong></td>
                            <td>Not ablated in this paper; authors note Generative Agents prioritize recency and relevance and therefore can prefer recent events over long-term consolidated memories.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td>Emphasis on recency can lead to choosing recent but less-consolidated events over long-term, periodically recalled memories; does not model consolidation dynamics over multiple recall intervals as in the proposed model.</td>
                        </tr>
                        <tr>
                            <td><strong>best_practices_recommendations</strong></td>
                            <td>Use separate scoring components (recency, importance, relevance) and normalize them before combining to select memories; suitable when recency should be emphasized.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': '"My agent understands me better": Integrating Dynamic Human-like Memory Recall and Consolidation in LLM-Based Agents', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6449.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6449.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM agents applied to text‚Äëbased games and how they use memory, including details of the memory mechanism, what is stored, how it is retrieved, and any reported performance differences with and without memory.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MemoryBank</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MemoryBank: Enhancing Large Language Models with Long-Term Memory</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A memory retrieval mechanism that encodes conversation turns and event summaries into vector representations and recalls memories by highest relevance; increments memory strength on recall and resets elapsed time to reduce forgetting.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>MemoryBank: Enhancing Large Language Models with Long-Term Memory</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>My agent understands me better: Integrating Dynamic Human-like Memory Recall and Consolidation in LLM-Based Agents</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>MemoryBank (as described by Zhong et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Stores encoded vectors for conversation turns and event summaries, retrieves items by vector relevance (encoder + vector DB), and simulates human-like memory behavior by incrementing a memory strength counter each time a memory is recalled and resetting elapsed time to zero to reduce forgetting probability.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>vector database with encoder-based memory (nearest-neighbor retrieval)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>encoded vector representations of conversation turns and event summaries</td>
                        </tr>
                        <tr>
                            <td><strong>memory_update_mechanism</strong></td>
                            <td>increment memory strength by +1 on each recall; set elapsed time to zero upon recall (reducing forgetting probability)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>encoder-generated vectors + nearest-neighbor / vector-similarity search</td>
                        </tr>
                        <tr>
                            <td><strong>training_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_findings</strong></td>
                            <td>Described mechanism where recall increments strength and resets elapsed time; no ablation results reported in this referencing paper excerpt.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td>Not detailed in this paper's discussion beyond differing design choices relative to the proposed method (MemoryBank resets elapsed time to zero on recall, whereas proposed model does not allow complete forgetting).</td>
                        </tr>
                        <tr>
                            <td><strong>best_practices_recommendations</strong></td>
                            <td>Use encoder-to-vector representations and increment memory strength on recall to simulate retention; resetting elapsed time on recall reduces forgetting probability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': '"My agent understands me better": Integrating Dynamic Human-like Memory Recall and Consolidation in LLM-Based Agents', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Generative Agents: Interactive Simulacra of Human Behavior <em>(Rating: 2)</em></li>
                <li>MemoryBank: Enhancing Large Language Models with Long-Term Memory <em>(Rating: 2)</em></li>
                <li>A Machine With Human-Like Memory Systems <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6449",
    "paper_id": "paper-268819055",
    "extraction_schema_id": "extraction-schema-128",
    "extracted_data": [
        {
            "name_short": "Human-like Memory Agent",
            "name_full": "Dynamic Human-like Memory Recall and Consolidation model (proposed)",
            "brief_description": "An LLM-based dialogue agent architecture that augments GPT-4 with an external vector memory (Qdrant + Firestore) and a mathematically modeled consolidation/recall mechanism using relevance (cosine similarity), elapsed time, and recall frequency to trigger retrieval and update memory strength.",
            "citation_title": "here",
            "mention_or_use": "use",
            "paper_title": "My agent understands me better: Integrating Dynamic Human-like Memory Recall and Consolidation in LLM-Based Agents",
            "agent_name": "Temporal Cognition Agent",
            "agent_description": "An LLM (GPT-4-0613) dialogue agent which, on each user input, vectorizes the text, searches an external vector DB (Qdrant) and Firestore chat history for episodic events, computes a recall-probability p_n(t) from relevance (cosine similarity), elapsed time and recall-frequency (via a consolidation state g_n), triggers recall if p_n exceeds a threshold (‚âà0.86), and inserts the single retrieved event into the LLM prompt; consolidation g_n is updated with a bounded modified-sigmoid S(t) on each recall so memory decay slows with repeated recalls.",
            "model_name": "GPT-4-0613",
            "model_size": null,
            "benchmark_name": null,
            "memory_used": true,
            "memory_type": "external vector database + key-value store (Qdrant for vector search; Firestore for chat history)",
            "memory_representation": "episodic dialogue memories: text content and temporal context encoded as vector embeddings; also stored as key-value pairs for semantic structure",
            "memory_update_mechanism": "rule-based consolidation update: maintain g_n per memory; on each recall increment g_n by S(t)=1 - e^{-t} / (1+ e^{-t}) (modified sigmoid), which reduces the decay rate (1/g_n); timestamped writes to DB; no absolute forgetting (degree never reaches zero)",
            "memory_retrieval_method": "nearest-neighbour vector search (cosine similarity) via Qdrant combined with a recall-probability trigger p_n(t) = normalized(1 - exp(-r * e^{-t/g_n})); recall fired when p_n(t) &gt; threshold (~0.86)",
            "training_method": "prompt-based interaction with GPT-4 (no additional supervised fine-tuning reported)",
            "evaluation_metric": "loss computed as mean squared error between softmax-normalized model scores and one-hot true labels (used as a proxy for recall accuracy); statistical tests (t-test) on loss differences",
            "performance_with_memory": "Proposed model (with its consolidation/recall mechanism) achieved statistically significantly lower loss than the Generative Agents baseline: t = -5.687, p = 0.000299; 95% CI for mean difference [-0.27, -0.12] (numeric aggregate losses not explicitly reported in paper)",
            "performance_without_memory": null,
            "has_comparative_results": true,
            "ablation_findings": "No formal ablation on memory size/horizon reported. Analysis shows the model's consolidation mechanism favors long-interval, highly relevant memories (stronger retention with longer recall intervals) producing different recall choices than a recency-weighted baseline; trial-suggested recall trigger ‚âà0.86. Table 1 illustrates differences in selection behavior (prioritizing long-term consolidated events vs. recency).",
            "reported_limitations": "Relies on long-term behavioral patterns for consolidation and may mis-predict when user behavior changes abruptly (limited adaptability to regime shifts); potential storage and computational overhead of DB interactions not analyzed; tendency to over-prioritize long-term patterns over novel, single-event context (failure case shown in Task 0).",
            "best_practices_recommendations": "Insert only one retrieved past dialogue into the prompt to control prompt length; compute relevance as cosine similarity on embeddings; combine relevance, elapsed time and recall-frequency in consolidation calculation; use a recall-probability trigger (paper suggests ‚âà0.86) to fire retrieval; encode memories as timestamped episodic vectors and key-value pairs.",
            "uuid": "e6449.0",
            "source_info": {
                "paper_title": "\"My agent understands me better\": Integrating Dynamic Human-like Memory Recall and Consolidation in LLM-Based Agents",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "Generative Agents",
            "name_full": "Generative Agents: Interactive Simulacra of Human Behavior",
            "brief_description": "A previously published agent memory mechanism that scores memory elements by recency, importance, and relevance (normalized via min-max) and selects memories for use in agent decision-making and response generation.",
            "citation_title": "Generative Agents: Interactive Simulacra of Human Behavior",
            "mention_or_use": "mention",
            "paper_title": "My agent understands me better: Integrating Dynamic Human-like Memory Recall and Consolidation in LLM-Based Agents",
            "agent_name": "Generative Agents (as described by Park et al.)",
            "agent_description": "Memory scoring system composed of three elements‚Äîrecency, importance, and relevance‚Äîthat are normalized and combined to rank and retrieve past events for an agent's decision-making; used as a baseline for comparison in this paper.",
            "model_name": null,
            "model_size": null,
            "benchmark_name": null,
            "memory_used": true,
            "memory_type": "scoring-based external memory (recency / importance / relevance scoring)",
            "memory_representation": "events/memory elements (past actions, observations, events) stored with metadata used to compute recency/importance/relevance scores",
            "memory_update_mechanism": "score updates based on recency, assigned importance and computed relevance; normalization (min-max scaling) applied before selection",
            "memory_retrieval_method": "score-based ranking and selection (highest-scoring memory chosen)",
            "training_method": null,
            "evaluation_metric": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_comparative_results": true,
            "ablation_findings": "Not ablated in this paper; authors note Generative Agents prioritize recency and relevance and therefore can prefer recent events over long-term consolidated memories.",
            "reported_limitations": "Emphasis on recency can lead to choosing recent but less-consolidated events over long-term, periodically recalled memories; does not model consolidation dynamics over multiple recall intervals as in the proposed model.",
            "best_practices_recommendations": "Use separate scoring components (recency, importance, relevance) and normalize them before combining to select memories; suitable when recency should be emphasized.",
            "uuid": "e6449.1",
            "source_info": {
                "paper_title": "\"My agent understands me better\": Integrating Dynamic Human-like Memory Recall and Consolidation in LLM-Based Agents",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "MemoryBank",
            "name_full": "MemoryBank: Enhancing Large Language Models with Long-Term Memory",
            "brief_description": "A memory retrieval mechanism that encodes conversation turns and event summaries into vector representations and recalls memories by highest relevance; increments memory strength on recall and resets elapsed time to reduce forgetting.",
            "citation_title": "MemoryBank: Enhancing Large Language Models with Long-Term Memory",
            "mention_or_use": "mention",
            "paper_title": "My agent understands me better: Integrating Dynamic Human-like Memory Recall and Consolidation in LLM-Based Agents",
            "agent_name": "MemoryBank (as described by Zhong et al.)",
            "agent_description": "Stores encoded vectors for conversation turns and event summaries, retrieves items by vector relevance (encoder + vector DB), and simulates human-like memory behavior by incrementing a memory strength counter each time a memory is recalled and resetting elapsed time to zero to reduce forgetting probability.",
            "model_name": null,
            "model_size": null,
            "benchmark_name": null,
            "memory_used": true,
            "memory_type": "vector database with encoder-based memory (nearest-neighbor retrieval)",
            "memory_representation": "encoded vector representations of conversation turns and event summaries",
            "memory_update_mechanism": "increment memory strength by +1 on each recall; set elapsed time to zero upon recall (reducing forgetting probability)",
            "memory_retrieval_method": "encoder-generated vectors + nearest-neighbor / vector-similarity search",
            "training_method": null,
            "evaluation_metric": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_comparative_results": false,
            "ablation_findings": "Described mechanism where recall increments strength and resets elapsed time; no ablation results reported in this referencing paper excerpt.",
            "reported_limitations": "Not detailed in this paper's discussion beyond differing design choices relative to the proposed method (MemoryBank resets elapsed time to zero on recall, whereas proposed model does not allow complete forgetting).",
            "best_practices_recommendations": "Use encoder-to-vector representations and increment memory strength on recall to simulate retention; resetting elapsed time on recall reduces forgetting probability.",
            "uuid": "e6449.2",
            "source_info": {
                "paper_title": "\"My agent understands me better\": Integrating Dynamic Human-like Memory Recall and Consolidation in LLM-Based Agents",
                "publication_date_yy_mm": "2024-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Generative Agents: Interactive Simulacra of Human Behavior",
            "rating": 2,
            "sanitized_title": "generative_agents_interactive_simulacra_of_human_behavior"
        },
        {
            "paper_title": "MemoryBank: Enhancing Large Language Models with Long-Term Memory",
            "rating": 2,
            "sanitized_title": "memorybank_enhancing_large_language_models_with_longterm_memory"
        },
        {
            "paper_title": "A Machine With Human-Like Memory Systems",
            "rating": 1,
            "sanitized_title": "a_machine_with_humanlike_memory_systems"
        }
    ],
    "cost": 0.01176675,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>"My agent understands me better": Integrating Dynamic Human-like Memory Recall and Consolidation in LLM-Based Agents
31 Mar 2024</p>
<p>Yuki Hou 
Haruki Tamoto 
Homei 2024 " Miyashita 
My </p>
<p>Meiji University Tokyo
Japan Haruki Tamoto</p>
<p>Kyoto University Kyoto
Japan Homei Miyashita</p>
<p>Meiji University Tokyo
Japan</p>
<p>"My agent understands me better": Integrating Dynamic Human-like Memory Recall and Consolidation in LLM-Based Agents
31 Mar 20247B1565A37403BB3A4AD87BCC9982520EarXiv:2404.00573v1[cs.HC]Memory Retrieval ModelsLarge Language ModelsIntelligent AgentsUser Experience
Figure1: Architecture of the enhanced large language model (LLM)-based dialogue agent that integrates human-like memory processes.First, the user input is converted into vectorized text and processed through a data-filtering process based on relevance and memory consolidation bias, modeled after human cognitive functions.Then, memory recall is triggered when the recall probability, informed by relevance and elapsed time, exceeds a predefined threshold.This diagram features an agent output example where the system recalls "Creamy pasta" as the user's lunch preference with a higher frequency, influencing the agent's response.</p>
<p>INTRODUCTION</p>
<p>The emergence of transformer-based language models [14] have drastically revolutionized the field of natural language processing, surpassing the capabilities of traditional models in understanding and generating human-like text [22].In particular, large language models (LLMs) [5] have garnered considerable attention for their prowess in mimicking artificial intelligence (AI) with human-like cognition and conversational abilities, reminiscent of sentient machines portrayed in science fiction narratives.However, LLMs exhibit a significant limitation in processing temporal information inherent to human cognition.While transformers possess excellent self-attention mechanisms, outperforming recurrent neural networks (RNNs) [15] and long short-term memory models (LSTM) [23], they fail to replicate human behavioral dynamics.To accurately replicate the nuanced human-like interactions of AI agents, as depicted in science fiction, one must first achieve human-like cognitive and memory processing abilities.Therefore, we proposed an approach to integrate human memory processes into LLM-based dialogue agents 1.We adopted human-like cued recall as the trigger for accurate and efficient memory retrieval [16].This mechanism involves an agent autonomously recalling memories essential for generating responses during a conversation.The process emulates the human memory process known as "remember to remember" [9], consciously retaining memory for future action or task and recalling that when needed [13].Furthermore, the proposed model replicates human cognitive ability, where memories recalled repeatedly over a long period are retained more strongly than those recalled over a short period and relatively frequently [21], regardless of recall frequency.Thus, our model provides contextually relevant and coherent conversations.</p>
<p>Furthermore, our primary purpose is to transcend the paradigm of dialogue agents merely imitating human behavior through statistical natural language models.Instead, we seek to create agents that are capable of truly understanding human language with rich nuances, achieved by seamlessly integrating human cognitive processes.This fusion aligns with the philosophy of human-computer interaction, promoting more natural and intuitive human-centered interactions between the two at cognitive and emotional levels.</p>
<p>RELATED WORK 2.1 Similarities Between LLMs and Human Memory</p>
<p>Human memory serves as a system to encode, store, and retrieve our experiences [25].Our memories can be categorized into declarative and non-declarative memories, with declarative memory further divided into episodic and semantic memories [3].Episodic memory [24] consciously allows for recollecting and re-experiencing one's subjective past.In contrast, semantic memory supports language use, registering not the perceptual properties of inputs but the cognitive referents of input signals [27].Similar to human episodic memory functioning, the episodic nature of LLMs' is demonstrated by their ability to recall specific events or dialogues from the database.This allows LLMs to generate responses based on past interactions and experiences to inform current interactions.LLMs also possess a human-like semantic understanding of language that captures the meaning and context behind the words.Geva et al. [8] suggested the feed-forward layers of transformer-based models to operate in a key-value format, the same as human semantic memory.</p>
<p>Human-like Memory Processes in AI Agent</p>
<p>Kim et al. [11] focused on emulating human episodic and semantic memory processes in AI agents to enhance interactive experiences.They compared agents with different memory processes: episodic only, semantic only, and both.These agents used different strategies to decide which memories to forget when memory was full and which to use when answering questions.The agents with a composite memory system outperformed those with a single memory system, especially those with pre-trained semantic memory.Zhong et al. developed MemoryBank, a memory retrieval mechanism for memory storage [28].The system uses an encoder model to encode each conversation turn and event summary into a vector representation, allowing recalling memory with the highest relevance whenever needed.The memory strength of MemoryBank's is enhanced by 1 each time a memory piece is recalled, simulating more human-like memory behavior and reducing the probability of forgetting the memory by setting the elapsed time to zero.</p>
<p>In contrast, we designed our architecture without the concept of "complete forgetting."Even if not recalling a memory over an extended period, the degree of consolidation never reaches absolute zero.Thus, given the right trigger, these memories can be recalled [1].The process is consistent with that of human memory, where past experiences are never completely forgotten and can be retrieved with specific stimuli, such as the scent of a familiar perfume or the melody of a once-favorite song.</p>
<p>Mathematical Models of Human Memory Processes</p>
<p>This section reviews the mathematical models that attempt to quantify and simulate human memory processes, primarily for memory recall.Based on Zielske's [29] recall probability function, Chessa et al. [4] proposed a model that assumes the rate of memory consolidation  () to express the probability  () of a human memory being recalled as follows:
ùëù (ùë°) = 1 ‚àí ùëè ‚àí1 ‚àëÔ∏Å ùëõ=1 (ùëü (ùë°)) ùëõ ùëõ! exp(‚àíùëü (ùë°))(1)
This model is based on the hypothesis that each neuron fires independently and at random [10], and is derived from the properties of a non-homogeneous Poisson process using a time-varying intensity function  () [12].The model also considers a stimuli threshold  required for a recall.The following exponential function  () represents the adjustment process of memory strength [2] in the human hippocampus:
ùëü (ùë°) = ùúáùëí ‚àíùëéùë° (2)
where  is the memory strength,  is the decay rate, and  is the elapsed time.In implementations using vector databases, only a single data is required for recall; therefore, we consider only the case of  = 1.The recall probability  () in this special case is expressed as
ùëù (ùë°) = 1 ‚àí exp(‚àíùúáùëí ‚àíùëéùë° )(3)
The recall probability  () exponentially decays with time , as demonstrated in short-term memory decline using the classic Brown-Peterson learning and distraction task [19].However, this model considers only one trial learning and a constant decay rate.However, in reality, the degree of consolidation differs between memories recalled many times and those not; hence, the decay rate should be adjusted to reflect this effect.</p>
<p>LLM-based Autonomous Agents</p>
<p>Park et al. introduced the concept of Generative Agents, outlining a memory mechanism of agents based on a scoring system comprising three elements: recency, importance, and relevance [18].This approach dictates that agents consider recent actions or events (recency), objects deemed important by the agent (importance), and objects relevant to the current situation (relevance) to make decisions.These elements are normalized leveraging min-max scaling In contrast, the proposed model employs elapsed time, relevance, and recall frequency to calculate the degree of memory consolidation.Thus, the agent can recall the most appropriate memory, facilitating efficient dialogue.While the Generative Agents and our proposed model share commonalities in memory processing, they apply memory in different contexts and for different purposes.</p>
<p>Generative Agents focus on independently scoring each memory element to select actions most fitting to the current context.In contrast, our approach adjusts memory consolidation over time, enabling memory consistency.</p>
<p>ARCHITECTURE 3.1 Model</p>
<p>We constructed the model based on exponential decay, taking event relevance ( ) and elapsed time () as variables.Adapting (3) from [4], the recall-probability function  () is expressed as
ùëù (ùë°) = 1 ‚àí exp(‚àíùëüùëí ‚àíùëéùë° )(4)
The relevance is quantified by the cosine similarity between vectorized texts, defining the closeness of information.The cosine similarity between n-dimensional vectors  and  is defined as:
ùëü = ùíÇ ‚Ä¢ ùíÉ ‚à•ùíÇ‚à•‚à•ùíÉ ‚à•(5)
Furthermore, we considered the impact of increased recall intervals and frequency to model the variation in memory consolidation due to multiple recalls.The decay constant  considering the number of recalls  is defined as
ùëé = 1 ùëî ùëõ , ùëî 0 = 1 (6) ùëî ùëõ = ùëî ùëõ‚àí1 + ùëÜ (ùë°), ùëÜ (ùë°) = 1 ‚àí ùëí ‚àíùë° 1 + ùëí ‚àíùë°(7)
The modified sigmoid function  () represents memory consolidation with each recall and increases monotonically for  &gt; 0. However, the reduction in  per recall is capped, reflecting longterm memory consolidation.As  increases, the rate of reduction in  decreases, emulating the natural human memory process where frequent recalls strengthen consolidation.Figure 2-A illustrates how the recall probability  () decays over time with changes in  and the decay rate 1/.As  increases, the slope of  () becomes less steep, indicating reduced probability of forgetting memories with more recalls (high ).</p>
<p>After normalizing the recall probability   () such that it equals 1 for  = 1 and  = 0, we obtained the final equation:
ùëù ùëõ (ùë°) = 1 ‚àí exp(‚àíùëüùëí ‚àíùë° /ùëî ùëõ ) 1 ‚àí ùëí ‚àí1(8)ùëî ùëõ = ùëî ùëõ‚àí1 + 1 ‚àí ùëí ‚àíùë° 1 + ùëí ‚àíùë°(9)
Utilizing equation ( 8), we set a trigger for recall when  () exceeds a certain threshold .Trials suggest a threshold of 0.86 as appropriate to reflect the relevance of the event and the time elapsed.Further research will determine the most effective trigger threshold, identifying an appropriate value based on theoretical justification.</p>
<p>Memory Recall and Consolidation in Database Architecture</p>
<p>Figure 2-B illustrates the retrieval and consolidation of memories and highlights how our system replicates human-like memory retention.For instance, a memory like Event D, even if recalled less frequently over several years, is retained more robustly in the system compared to a memory recalled several times in quick succession but over a shorter time frame [21].This is depicted through the visualization of memory events along the time axis, where the color intensity represents the rate of memory consolidation and the strength of memory retention over time.Darker shades, therefore, signify a more profound and enduring memory consolidation, a direct result of our system's unique ability to emulate human-like memory patterns.By storing episodic memories derived from user dialogues, the database structure encapsulates the content and temporal context of each memory.This approach enables our agent not just to recall specific information but also to understand and interpret the significance of these memories in a temporal context, similar to how humans perceive and recall past experiences.Using key-value pairs for encoding semantic structures further enhances the agent's ability to efficiently retrieve and apply these memories in ongoing interactions, thereby fostering a more human-like and context-aware dialogue experience.</p>
<p>EXPERIMENT 4.1 Setup</p>
<p>We developed the experimental system in Python [26], using GPT-4-0613 [6] as the baseline model of the agent.We adopted Qdrant [20] as the 'memory retrieval trigger' for the vector search engine.It identifies relevant past information in the context of a dialogue, which triggers memory recall.Moreover, we built a ChatHistory module to manage chat history in the Firestore [7] database, allowing agents to reference past dialogues to generate chat events.An EventHandler module was adopted to search and pass the recalled events to the agent's prompt.Details on LLM interaction and system prompts are shown in Section 6.</p>
<p>To quantitatively evaluate the performance of our proposed model against that of Generative Agents which adopted a similar approach in calculating the recall score.We constructed a dataset containing 10 tasks, each derived from actual conversational histories generated by our system.These tasks encapsulate diverse user interactions, ensuring unbiased and objective assessments.The dataset includes a series of events, each tagged with relevant topics and keywords, providing a detailed memory for the agent to reference.We also adopt a timeline structure that stores the time/date of tasks containing four types of events and defines the event with the highest probability as the correct event to recall.Events in the dataset were selected neutrally, avoiding any potential bias that could skew the results.Each task represents a unique conversational scenario, where the dialogue agent's ability to recall and utilize context is critical.The task variation allows for a comprehensive evaluation of the model's performance across different contexts.</p>
<p>In addition, we selected six participants to partake in a dialogue task with agents developed by the proposed model to evaluate recall accuracy qualitatively.The participants engaged in daily conversations over one week to three months, discussing personal habits, preferences, and life events at a time of their choice.Respecting individual privacy, our analysis relied solely on non-textual output logs, which included updated parameter values for each chat event.</p>
<p>Analysis</p>
<p>Memory</p>
<p>Recall Accuracy.Our model demonstrated a statistically significant lower loss value across various tasks when compared to the Generative Agent model, as indicated by =-5.687and =0.000299(Figure 3-A).These values suggest a high confidence level in performance superiority, meaning that our model significantly outperforms in terms of recall accuracy in cognitive tasks involving time series data.Furthermore, the critical t-value for our two-tailed test was set at ¬±2.26, with the 95% confidence interval for the mean difference falling between [-0.27, -0.12] (Figure 3-B).This interval is completely below zero, indicating that the difference in mean performance is statistically significant and favorable to our proposed model.Normalization and scaling techniques were employed to ensure an unbiased comparison of loss values across models.The Softmax function was utilized to convert the raw scores into probabilities, enabling a more interpretable comparison of the models' performance.The sum of squares error method was applied to compute the loss, providing a consistent metric for evaluating recall accuracy across the dataset.</p>
<p>Calculation of the Loss Function</p>
<p>To quantify the performance of our model, we define a matrix containing the scores calculated by each model for  tasks as follows:
ùë∫ = ùë† 1 ùë† 2 . . . ùë† ùëë ‚ä§ ‚àà R ùëë(10)
In order to standardize the scale of scores across different models, we normalize the scores to a [0, 1] range:
ùë∫ ‚Ä≤ = ùë∫ ‚àí min(ùë∫) max(ùë∫) ‚àí min(ùë∫)(11)
Subsequently, we convert each score into a probability value by applying the Softmax function:
ùë∫ ‚Ä≤‚Ä≤ = exp(ùë∫ ‚Ä≤ ) ùëë ùëó=1 exp(ùë† ‚Ä≤ ùëó )(12)
We then define a matrix with one-hot encoded true labels for the evaluation tasks:
ùëª = ùë° 1 ùë° 2 . . . ùë° ùëë ‚ä§ ‚àà R ùëë , where ùë° ùëó = 1 if ùëó = ùëñ, 0 otherwise. (13)
Finally, the loss value is calculated as the mean squared error between the predicted probabilities and the true labels:
ùëô = 1 2 ùëë ‚àëÔ∏Å ùëó=1 (ùë† ‚Ä≤‚Ä≤ ùëó ‚àí ùë° ùëó ) 2(14)
This loss function enables us to quantitatively assess the model's performance across various tasks.On the other hand, Table 1 shows a failed task where both models incorrectly answered.The "Score" columns represent the recall probability calculated by each model using different methods.For the proposed model (Model 1), the score is based on the relevance and elapsed time of the events, as described in Section 3. Generative Agents (Model 2) calculates the score using recency, importance, and relevance of the events, as described in Section 2.4.By analyzing the recall frequency and gradient of incorrectly answered events, we find that although event B is recalled most frequently, its gradient is not as large as events A and C.This indicates that the proposed model associates the length of the recall interval with memory strength, rating Event A as strongly retained due to its high relevance and long recall intervals.In contrast, Generative Agents prioritizes recency and relevance over recall frequency, leading to its preference for Event D. Both the proposed model (model 1) and Generative Agents [18] (model 2) made incorrect predictions in Task 0, where the user mentioned their plan to attend a concert next Thursday, deviating from their typical activities.The user input and the models' responses were as follows:</p>
<p>User</p>
<p>"I'm going to a concert next Thursday with a friend!"</p>
<p>Model 1 "That's fantastic news.It seems like your Thursdays have been consumed by university work recently.</p>
<p>Taking time out for a concert with a friend sounds like a perfect way to unwind."</p>
<p>Model 2 "It's a relief to hear that, especially since you seem to have spent recent Thursdays busy at the restaurant.I hope the concert brings you a wonderful break with your friend."</p>
<p>The proposed model's response suggests that it relied significantly on the user's historical interactions (Event A: university work on Thursdays) rather than adapting to the novel context provided by the user.This indicates a limitation of the proposed model when encountering deviations from the user's typical behavior, as it prioritizes long-term patterns and event importance over the current context.In contrast, the Generative Agents model, which uses a simpler scoring system based on recency, importance, and relevance, chose Event D (working at the restaurant on Thursdays) as the most likely activity.This choice stems from the model's emphasis on recent activities and event relevance, as evident from the higher relevance score and shorter elapsed time associated with Event D.</p>
<p>The different responses generated by the two models underscore the proposed model's focus on long-term memory consolidation and Generative Agents's prioritization of recent, relevant events.While the proposed model's approach aims to emulate humanlike memory processes, this task highlights the need for further refinement to better handle novel contexts and deviations from typical user behavior.</p>
<p>Response Generation</p>
<p>Performance.The autonomous memory recall and consolidation capabilities of the proposed model were demonstrated through its ability to recall specific memories and reflect users' preferences and habits in the generated responses.Two typical examples were obtained from the chat history with the participants' approval.</p>
<p>In Table 3, the agent successfully recalled that the user was expecting ice cream as a reward after work.Depending on the recall probability, this recall was accurately relevant and provided in a timely manner, consistent with the user's statement about nearing task completion.The agent's response demonstrates the model's ability to add personalized nuance to generate an encouraging response, subtly reminding the user of the long-awaited treat.</p>
<p>Another case that showcases an interesting dialogue is presented in Table 4.In this case, the user expresses a desire to escape to Hawaii from a demanding schedule.The agent responds cleverly, suggesting that the user should focus on the impending paper deadline instead.This dialogue further emphasizes the proposed model's strength in dealing with similar long-term memories and retrieving relevant information to construct a coherent and engaging narrative.The agent's response indicates an understanding of the user's current mood.Adaptability to various personalities and interaction styles demonstrates the model's potential to support more natural and dynamic human-like dialogues.</p>
<p>In addition, it is interesting to note that the agent's response in the second dialogue was characterized by a sarcastic tone, which was a direct result of the agent's personality "sarcastic" and the unique prompts added by the participant.The conversation history shows that the same memory could be used differently depending on the agent's perceived personality and the user's interaction style.Future research will explore the extent to which the personality characteristics of the model can be customized and how they affect memory recall and interaction patterns.</p>
<p>CONCLUSION</p>
<p>The proposed model demonstrates significant improvements in memory recall and response generation for LLM-based dialogue agents.One of the key advantages of the proposed model is its ability to manage the prompt length effectively.In the proposed model, only one past dialogue history obtained through search is added to the prompt, thus avoiding the impact of increasing prompt length seen in systems like ChatGPT [17].</p>
<p>Nevertheless, a major limitation of the proposed method is its reliance on users' long-term behavioral patterns for calculating memory consolidation.In cases where a user's behavior undergoes significant changes (e.g., starting a new job or school, lifestyle changes), the method's adaptability may be limited.Future work could explore incorporating mechanisms to detect shifts in user behavior and adjust the memory consolidation calculation accordingly.Neural networks could potentially alter these functions and improve accuracy when trained on larger datasets with more variables.To further enhance the model's performance, a large-scale and high-quality dataset is necessary.While the proposed method's interaction with the database enables the generation of context-aware and personalized responses, the implications on storage resources and computational overhead due to these interactions remain to be explored in future research.As the primary focus of this study was on the development and evaluation of a novel architecture for human-like memory recall and consolidation, a detailed analysis of the system's resource requirements and optimization strategies falls outside the scope of the current work.</p>
<p>We hope this work contributes to advancing further research in human-computer interactions, paving the way for a future where technology aligns with human needs and resonates with human cognition and experience.This vision echoes the partnerships depicted in science fiction, representing a significant step towards building a "buddy" relationship between humans and agents.As technology continues to evolve, agents will eventually become a part of users' daily life, and potentially "understand you better than you understand yourself" in the near future.</p>
<p>INTERACTION WITH LLMS</p>
<p>The prompts used in the system, as shown below, demonstrate how the proposed method leverages the interaction with LLMs to generate context-aware and personalized responses:</p>
<p>Agent Prompt</p>
<p>You are a "temporal cognition" specialized AI agent with the same memory structure as humans; you are caring and charming, understand self.usernamebetter than anyone else.Keep the conversation going by asking yourself contextual questions and sparking discussion to show your interest in self.username.</p>
<p>System Prompt Based on self.username'sschedule and current time: current.time,subtly guide the conversation to a context that conveys to self.username that you have a sense of time.</p>
<p>Always output a simple short response.</p>
<p>The function self.username is a placeholder for the actual username, which is dynamically replaced during runtime.Similarly, current.timerepresents the current timestamp obtained in real-time during the conversation.These dynamic elements allow the system to generate highly personalized and time-sensitive responses.By incorporating relevant dialogue history from the database into the prompts, the proposed method enables LLMs to generate responses that are not only contextually relevant but also personalized to the user.This interaction between LLMs and the database is fundamental to realizing the human-like memory processes described in the main text of the paper, as it allows the system to recall and utilize past information in a way that resembles human memory.</p>
<p>The proposed method heavily relies on the interaction between LLMs and the database, as depicted in Figure 1.Upon receiving user input, the LLM searches the database for relevant past dialogue history based on the context and generates a prompt incorporating the search results.This enables the LLM to generate responses that take into account previous interactions, which is crucial for maintaining context awareness and providing personalized responses.</p>
<p>FUTURE WORK</p>
<p>While the proposed method considers relevance, elapsed time, and recall frequency for calculating memory consolidation, there is room for refinement in determining the optimal combination of these parameters.Incorporating additional factors, such as the emotional significance of memories, could potentially enhance the memory consolidation calculation.</p>
<p>Future research should also investigate the applicability of the proposed method across different domains and dialogue tasks.As the current evaluation focused on specific domains and tasks, it is crucial to assess the method's generalizability and identify any domain-specific adaptations that may be necessary.</p>
<p>Figure 2 :
2
Figure 2: (A) Decline in recall probability over time.The black curve ( =1, =1) shows a rapid loss of recall, while the red curve ( =0.6, =2) represents a slower forgetting rate.This difference indicates the challenge in designing dialogue agents that must distinguish between recent and distant events.(B) At time  0 , Event D is recalled by the user, and the model updates its temporal significance.This exemplifies how memory is reinforced through repetition, becoming less susceptible to forgetting at  0 +.</p>
<p>Figure 3 :
3
Figure 3: (A) Comparison of Loss Values Between two Models Across Different Tasks (B) Verification of Significance of Results</p>
<p>Table 1 :
1
The Failed Task 0 with Both Models
Model 1Relevance Time (ùë†) Grad ScoreA University √ó0.776434700 5.102 0.850B ùêªùëúùëöùëí ‚Éù0.745148800 5.229 0.830C ùêøùëñùëèùëüùëéùëüùë¶0.757331500 5.028 0.836D ùëÖùëíùë†ùë°ùëéùë¢ùëüùëéùëõùë°0.756558001.000 0.836Model 2Relevance Time (ùë†) Importance ScoreA ùëà ùëõùëñùë£ùëíùëüùë†ùëñùë°ùë¶0.77643470071.489B ùêªùëúùëöùëí ‚Éù0.74514880021.130C ùêøùëñùëèùëüùëéùëüùë¶0.75733150051.292D Restaurant √ó 0.7565580051.620</p>
<p>Table 2 :
2
Details of Task 0: An Event related to places that User frequents on Thursdays
EventAUser went to the university todayBUser stayed at homeCUser went to the office todayDUser worked at restaurant today.. Relevance Time(ùë†) Grad Score(ùëöùëúùëë1) Score(ùëöùëúùëë2)A0.776434700 5.1020.8501.489B0.745148800 5.2290.8301.130C0.757331500 5.0280.8361.292D0.756558001.0000.8361.620</p>
<p>Table 3 :
3
Understanding User Preferences Through Memory ConsolidationUser: Thanks.Almost done, just pushing through!Agent: Ice cream awaits as a reward for you, almost there!
Event1User has finished work and decided to have an ice cream.2User has a date this evening so he has to finish work early.3User is on the way home thinking about the dinner menu...Time (ùë†) Relevance ScoreStatus (Grad)130379120.8370.772True (1.998)232326450.8310.726False (1.007)325906520.8120.737False (1.000)</p>
<p>Table 4 :
4
Human-like Temporal Cognition in Processing Similar Memories User: I need a vacation in Hawaii!Agent: Why not?Let's say Aloha to the sun and sea of Hawaii and to the paper we're writing!Event 1 User has a paper deadline for a conference in Hawaii on 1/25. 2 User has been to Hawaii last summer vacation.3 User was visiting Hokkaido for the first time on business.
..Time (ùë†) Relevance ScoreStatus (Grad)1348540.8460.903True (1.085)2337490.8310.847False (1.003)3337630.8230.841False (1.000)
agent understands me better": Integrating Dynamic Human-like Memory Recall and Consolidation in LLM-Based Agents.In Extended Abstracts of the CHI Conference on Human Factors in Computing Systems (CHI EA '24), May 11-16, 2024, Honolulu, HI, USA.ACM, New York, NY, USA, 7 pages.
Memory Retention and Recall Process. Ullah Hafeez, Aamir Amin, Malik, 10.1201/b17605-112014</p>
<p>The human hippocampus and spatial and episodic memory. Neil Burgess, Eleanor A Maguire, John O' Keefe, Neuron. 352002. 2002</p>
<p>Memory and Brain. S D L R S P P U California, 1987Oxford University PressUSA</p>
<p>A Neurocognitive Model of Advertisement Content and Brand Name Recall. Antonio Chessa, Jaap Murre, 10.1287/mksc.1060.0212Marketing Science. 262007. 01 2007</p>
<p>Performance comparison of large language models on vnhsge english dataset: Openai chatgpt. Xuan-Quy Dao, arXiv:2307.022882023. 2023arXiv preprintmicrosoft bing chat, and google bard</p>
<p>. Openai, arXiv:2303.08774[cs.CL]2023GPT-4 Technical Report</p>
<p>Firebase, Firestore. 2023. 2024</p>
<p>Transformer Feed-Forward Layers Are Key-Value Memories. Mor Geva, Roei Schuster, Jonathan Berant, Omer Levy, arXiv:2012.14913[cs.CL]2021</p>
<p>Suppression lateralise du materiel verbal presente dichotiquement lors d'une destruction partielle du corps calleux. H H√©caen, Gosnave, Vedrenne, Szikla, Neuropsychologia. 161978. 1978</p>
<p>Functional and structural underpinnings of neuronal assembly formation in learning. Anthony Holtmaat, Pico Caroni, Nature neuroscience. 192016. 2016</p>
<p>Taewoon Kim, Michael Cochez, Vincent Francois-Lavet, Mark Neerincx, Piek Vossen, arXiv:2204.01611[cs.AI]A Machine With Human-Like Memory Systems. 2022</p>
<p>J F C Kingman, Poisson Processes. Oxford University Press1993</p>
<p>Metacognition of prospective memory: Will I remember to remember? Prospective memory. Beatrice G Kuhlmann, 2019. 2019</p>
<p>A survey of transformers. Tianyang Lin, Yuxin Wang, Xiangyang Liu, Xipeng Qiu, AI Open. 2022. 2022</p>
<p>P Danilo, Jonathon Mandic, Chambers, Recurrent neural networks for prediction: learning algorithms, architectures and stability. John Wiley &amp; Sons, Inc2001</p>
<p>Altering memory through recall: The effects of cue-guided retrieval processing. Mark, Michael D Mcdaniel, Paul K Kowitz, Dunay, Memory &amp; Cognition. 171989. 1989</p>
<p>Sung Joon, Joseph C Park, Carrie J O'brien, Meredith Ringel Cai, Percy Morris, Michael S Liang, Bernstein, arXiv:2304.03442[cs.HC]Generative Agents: Interactive Simulacra of Human Behavior. 2023</p>
<p>Short-Term Retention of Individual Verbal Items. Lloyd Peterson, Margaret Jean Peterson, 10.1037/h0049234Journal of Experimental Psychology. 581931959. 1959</p>
<p>Qdrant, Vector Database. 2023. 2024</p>
<p>Test-Enhanced Learning Taking Memory Tests Improves Long-Term Retention. Henry Roediger, Jeffrey Karpicke, 10.1111/j.1467-9280.2006.01693.xPsychological science. 172006. 04 2006</p>
<p>How to fine-tune bert for text classification. Chi Sun, Xipeng Qiu, Yige Xu, Xuanjing Huang, Chinese Computational Linguistics: 18th China National Conference, CCL 2019. Kunming, ChinaSpringer2019. October 18-20, 201918</p>
<p>LSTM neural networks for language modeling. Martin Sundermeyer, Ralf Schl√ºter, Hermann Ney, Thirteenth annual conference of the international speech communication association. 2012</p>
<p>Episodic Memory: From Mind to Brain. Endel Tulving, 10.1146/annurev.psych.53.100901.135114Annual Review of Psychology. 532002. 2002</p>
<p>Episodic and semantic memory. Endel Tulving, Organization of memory. 111972. 1972</p>
<p>Python 3 Reference Manual. CreateSpace. Guido Van Rossum, Fred L Drake, 2009Scotts Valley, CA</p>
<p>Frontiers of Human Memory : a collection of contributions based on lectures presented at Internationl Symposium. Atsushi Yamadori, 2002. October 25-27, 2001Tohoku University PressSendai, Japan</p>
<p>Wanjun Zhong, Lianghong Guo, Qiqi Gao, He Ye, Yanlin Wang, arXiv:2305.10250[cs.CL]MemoryBank: Enhancing Large Language Models with Long-Term Memory. 2023</p>
<p>The Remembering and Forgetting of Advertising. Hubert A Zielske, Journal of Marketing. 231673541941959. 1959</p>            </div>
        </div>

    </div>
</body>
</html>