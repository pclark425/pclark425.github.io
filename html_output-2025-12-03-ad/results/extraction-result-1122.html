<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1122 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1122</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1122</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-25.html">extraction-schema-25</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <p><strong>Paper ID:</strong> paper-264128187</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2310.08751v1.pdf" target="_blank">Constrained Bayesian Optimization with Adaptive Active Learning of Unknown Constraints</a></p>
                <p><strong>Paper Abstract:</strong> Optimizing objectives under constraints, where both the objectives and constraints are black box functions, is a common scenario in real-world applications such as scientific experimental design, design of medical therapies, and industrial process optimization. One popular approach to handling these complex scenarios is Bayesian Optimization (BO). In terms of theoretical behavior, BO is relatively well understood in the unconstrained setting, where its principles have been well explored and validated. However, when it comes to constrained Bayesian optimization (CBO), the existing framework often relies on heuristics or approximations without the same level of theoretical guarantees. In this paper, we delve into the theoretical and practical aspects of constrained Bayesian optimization, where the objective and constraints can be independently evaluated and are subject to noise. By recognizing that both the objective and constraints can help identify high-confidence regions of interest (ROI), we propose an efficient CBO framework that intersects the ROIs identified from each aspect to determine the general ROI. The ROI, coupled with a novel acquisition function that adaptively balances the optimization of the objective and the identification of feasible regions, enables us to derive rigorous theoretical justifications for its performance. We showcase the efficiency and robustness of our proposed CBO framework through empirical evidence and discuss the fundamental challenge of deriving practical regret bounds for CBO algorithms.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1122.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1122.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>COBALT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>COnstrained Bayesian optimization with Adaptive active Learning of unknown constraints (COBALT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A constrained Bayesian optimization algorithm that integrates active level-set estimation for unknown constraints with UCB-style optimization of the objective, maintaining independent GPs for objective and each constraint and adaptively trading off learning feasibility vs objective improvement.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>COBALT</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Maintains Gaussian process (GP) surrogates for the objective f and each constraint C_k, computes pointwise UCB/LCB confidence bounds, identifies Regions of Interest (ROIs) by intersecting constraint ROIs and objective ROI, and selects queries by maximizing a pooled acquisition set (objective UCB-based acquisition and constraint uncertainty-width acquisition). Key components: independent GPs, ROI identification via confidence intervals, two acquisition functions (α_f for objective, α_Ck for constraints), and a master selection that picks the highest acquisition across aspects.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptive_design_method</strong></td>
                            <td>Bayesian optimization combined with active learning for level-set estimation (UCB/LCB-based acquisition; information-aware ROI shrinking)</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_strategy_description</strong></td>
                            <td>At each iteration COBALT updates GP posteriors, computes UCB/LCB for objective and constraints, forms per-function ROIs (superlevel sets and undecided sets), proposes candidate points maximizing (a) α_f(x)=UCB_f(x)-LCB_f,max for optimizing objective in X_f,t and (b) α_Ck(x)=UCB_Ck(x)-LCB_Ck(x) on undecided constraint regions to reduce epistemic uncertainty; then picks the single candidate with maximal acquisition across all aspects—thus adaptively trading off exploration of constraints vs exploitation of objective based on current confidence intervals and ROI intersections.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Constrained Bayesian optimization benchmark tasks (synthetic benchmarks: Rastrigin-1D-1C, Ackley-5D-2C; real-world: Vessel-4D-3C, Spring-3D-6C, Car-7D-8C, UCI Converter-32D-3C)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_characteristics</strong></td>
                            <td>Black-box objective and one or more black-box constraints; observation noise (additive Gaussian, e.g., N(0,0.1) in experiments); continuous input spaces (compact subsets of R^d) often discretized for evaluation; partially observable feasibility (constraints unknown and must be actively learned); coupled or decoupled evaluation settings supported.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_complexity</strong></td>
                            <td>Varies by task: examples include 1D with 1 constraint (Rastrigin-1D-1C, 1000 discrete points), 5D with 2 constraints (Ackley-5D-2C), 4D with 3 constraints (pressure vessel), 3D with 6 constraints (spring), 7D with 8 constraints (car), 32D with 3 constraints (UCI WEC); feasible-region fractions range from ≈0.38% (spring) to ≈78% (vessel).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_adaptive_design</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_adaptation</strong></td>
                            <td>Qualitative: COBALT achieves consistently superior simple-regret performance after sufficient iterations across diverse CBO tasks; on Rastrigin-1D-1C (1000-point discrete space, noisy observations N(0,0.1)) COBALT consistently reaches the global optimum within 2000 iterations while baselines often fail; in many higher-dimensional/real-world tasks COBALT outperforms baselines in final simple regret (plots show averaged standardized simple regret over ≥15 trials with 95% CI). Numerical theoretical bound: the paper proves that with β_t chosen appropriately there exists ε s.t. after at most T ≥ β_T γ_T C1 ε^2 iterations the high-confidence interval width for f* is ≤ ε with probability ≥1−δ (γ_T = cumulative information gain, C1 = 8 / log(1+σ^{−2})).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_adaptation</strong></td>
                            <td>Baselines (cEI, cMES-IBO, SCBO) often get trapped in local optima or exhibit worse final simple regret; no single numeric baseline value is reported in the paper (comparisons are via simple-regret curves), but authors report COBALT sometimes lags early but surpasses baselines and attains superior final performance.</td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td>Empirical: on the discrete Rastrigin-1D-1C experiment COBALT reaches the global optimum within 2000 iterations (15 independent trials, noise N(0,0.1)); theoretical: sample complexity bound depends on information gain γ_T and confidence parameter β_T via T ≥ β_T γ_T C1 ε^2 (as reported in paper).</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_tradeoff</strong></td>
                            <td>Explicit trade-off by design: constraint-acquisition α_Ck(x) targets reduction of constraint epistemic uncertainty (width UCB−LCB) on undecided sets, while objective-acquisition α_f(x) targets maximizing UCB relative to LCB_f,max within objective ROI; master selection picks highest acquisition across these, so the algorithm adaptively favors constraint learning when feasibility uncertainty is high and favors objective optimization when ROIs are well-identified.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_methods</strong></td>
                            <td>Compared experimentally against cEI (Gelbart et al., 2014), cMES-IBO (Takeno et al., 2022), and SCBO (Eriksson & Poloczek, 2021).</td>
                        </tr>
                        <tr>
                            <td><strong>key_results</strong></td>
                            <td>1) Adaptive active learning of constraints combined with UCB-style objective optimization and ROI intersection yields reliable identification of feasible ROIs and improved final simple regret across synthetic and real-world CBO tasks; 2) Theoretical guarantee: with appropriate β_t, COBALT keeps the global optimum in the ROI with high probability and bounds the high-confidence interval width for f* after a T that scales with β_T and the information gain γ_T; 3) Empirically more robust to varying feasible-region sizes (Rastrigin experiments) and avoids being trapped at local optima where baselines fail.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Reported limitations include: (1) potential insufficiency due to pointwise ROI comparisons (may miss structured/regionwise information), (2) lack of explicit handling of correlated unknowns (constraints assumed independent GPs), (3) early-stage lag in some tasks where active constraint learning initially reduces objective-focused evaluations (COBALT sometimes performs worse than baselines early but improves later), and (4) empirical results are averaged simple regret curves without absolute numeric performance tables for all tasks.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1122.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1122.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>COBALT-Decoupled</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>COnstrained Bayesian optimization with Adaptive active Learning of decoupled unknown constraints (COBALT-Decoupled)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A variant of COBALT designed for the decoupled evaluation setting where objective and constraints can be evaluated independently; selects both a candidate input x and which function g (objective or specific constraint) to evaluate at that x using the same acquisition-selection machinery.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>COBALT-Decoupled</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Same GP-based architecture as COBALT but adapted: after proposing candidate points x_g,t for each aspect g∈{f}∪{C_k}, the algorithm selects which function g_t to evaluate at the chosen x_t (decoupled evaluation), updating only the corresponding GP posterior per query.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptive_design_method</strong></td>
                            <td>Bayesian optimization + active level-set estimation with per-aspect acquisition and explicit selection of which function to query (decoupled active learning/experimental design).</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_strategy_description</strong></td>
                            <td>Generates per-aspect candidates as in COBALT (α_f and α_Ck), then selects g_t = argmax_g α_g,t(x_g,t) and queries x_g,t for that particular function g_t, thereby adapting both location and modality of the experiment (which function to measure) based on current uncertainty and ROIs.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Same CBO benchmark tasks as COBALT; decoupled evaluation scenarios where objective and constraints can be measured independently.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_characteristics</strong></td>
                            <td>Black-box objective and constraints; possibly decoupled (can measure any single function at chosen x); observation noise Gaussian; continuous input spaces; partially observable constraint feasibility.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_complexity</strong></td>
                            <td>Same variety as COBALT (1D–32D tasks with 1–8 constraints), with the total number of function evaluations split across f and C_k as T = sum_g T_g. Information gain γ_T is computed per-function and summed.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_adaptive_design</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_adaptation</strong></td>
                            <td>Paper states analogous theoretical guarantee to coupled COBALT: after at most T ≥ β_T γ_T C1 ε^2 iterations the high-confidence interval for f* is bounded by ε with high probability; empirically the decoupled variant is suggested to require minimal adaptation and retain similar performance guarantees, though specific empirical decoupled-experiment curves are not detailed in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_adaptation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td>Theoretical sample complexity similar to COBALT but accounting for per-function information gains: T must satisfy T ≥ β_T γ_T C1 ε^2 (γ_T now sums per-function gains). No explicit empirical sample counts for decoupled runs provided.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_tradeoff</strong></td>
                            <td>Same mechanism as COBALT but extended: the selection of which function to evaluate provides additional control—when constraint uncertainty dominates, algorithm tends to select constraint queries; when objective ROI uncertainty dominates, selects objective evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_methods</strong></td>
                            <td>Compared conceptually/theoretically to coupled-COBALT and baselines in discussion; no distinct empirical baseline run reported specifically for decoupled variant in main experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>key_results</strong></td>
                            <td>COBALT adapts naturally to decoupled evaluation with similar theoretical guarantees; the acquisition-selection mechanism can also choose which function to evaluate, enabling adaptive experimental design in settings where measurements can be targeted to objective or individual constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>No distinct empirical results provided; theoretical bounds depend on distribution of evaluations across functions via γ_T and require proper choice of β_t; practical performance may hinge on allocation strategy across functions, which is not deeply explored.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1122.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1122.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>cEI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Constrained Expected Improvement (cEI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An extension of the Expected Improvement acquisition for constrained BO that multiplies expected improvement by probability of feasibility at a candidate point.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Bayesian optimization with unknown constraints</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>cEI</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Uses GP surrogates for objective and constraints and evaluates acquisition α(x) = EI(x) * P[feasible(x)] (or variants); typically evaluates both objective and constraints at queried points (coupled setting) and relies on Monte Carlo approximations in noisy settings.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptive_design_method</strong></td>
                            <td>Expected Improvement modulated by feasibility probability (BO with feasibility-calibrated acquisition).</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_strategy_description</strong></td>
                            <td>Passively learns constraints via GP posteriors and weights EI by current probability of feasibility; hence adapts exploration toward promising and likely-feasible regions but does not proactively reduce constraint uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Same CBO benchmark tasks used in paper for comparison (Rastrigin, Ackley, vessel, spring, car, UCI 32D).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_characteristics</strong></td>
                            <td>Black-box objective and constraints, Gaussian observation noise in experiments, continuous input spaces; feasibility may be sparse depending on chosen thresholds.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_complexity</strong></td>
                            <td>Varies across the benchmark tasks (1D–32D, multiple constraints).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_adaptive_design</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_adaptation</strong></td>
                            <td>Empirically used as a baseline; reported to sometimes be trapped or perform worse when no feasible points exist or when feasibility is critical—paper reports cEI is outperformed by COBALT on several tasks (COBALT attains better final simple regret and robustness to feasible-region size). No absolute numerical metrics provided in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_adaptation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td>Not quantitatively reported in this paper; in experiments cEI often converges more slowly or to worse local optima compared to COBALT in tasks where explicit constraint learning matters.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_tradeoff</strong></td>
                            <td>Balances exploitation via EI with exploration driven indirectly by feasibility uncertainty through P[feasible(x)], but does not explicitly target constraint-uncertainty reduction.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_methods</strong></td>
                            <td>Compared against COBALT, cMES-IBO, and SCBO in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>key_results</strong></td>
                            <td>cEI can be inferior in problems where feasibility identification is crucial because it passively learns constraints rather than actively reducing constraint uncertainty; authors cite scenarios where it fails if feasible points are absent or rare.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Known failure when feasible region is empty or very small; passive constraint learning can lead to poor performance when feasibility matters more than objective optimization.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1122.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1122.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>cMES-IBO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Constrained Max-Value Entropy Search with Information Lower Bound (cMES-IBO)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An information-theoretic constrained BO method that extends Max-value Entropy Search to constrained problems using a lower bound on mutual information to guide queries.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Sequential and parallel constrained max-value entropy search via information lower bound</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>cMES-IBO</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Information-based acquisition aiming to reduce entropy about the maximum value (or location) under constraints by estimating mutual information between observations and the optimizer, using approximations/lower bounds to make computation feasible.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptive_design_method</strong></td>
                            <td>Information gain maximization (entropy-based BO / max-value entropy search adapted for constraints).</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_strategy_description</strong></td>
                            <td>Selects queries that maximize information about the constrained optimum (reducing entropy of the max value or optimum location), approximated via sampling/variational methods; adapts to current posterior uncertainty to prioritize informative queries.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Same benchmark tasks used for experimental comparison in paper.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_characteristics</strong></td>
                            <td>Black-box objective and constraints; noisy observations; continuous domains; feasibility may be rare (e.g., spring task).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_complexity</strong></td>
                            <td>Varied (1D–32D tasks with multiple constraints).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_adaptive_design</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_adaptation</strong></td>
                            <td>Reported as a strong baseline in experiments; in the paper cMES-IBO performs well but is outperformed by COBALT on several tasks in final regret; specific numeric metrics not provided in main text.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_adaptation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td>Not numerically reported here; typically information-theoretic methods are sample-efficient but computationally heavier; paper remarks approximations/sampling are used and theoretical guarantees are challenging.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_tradeoff</strong></td>
                            <td>Implicitly handled via information-theoretic objective that trades off learning about the constrained optimum (exploration) vs reducing uncertainty near promising optima (exploitation).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_methods</strong></td>
                            <td>Compared experimentally against COBALT, cEI, and SCBO.</td>
                        </tr>
                        <tr>
                            <td><strong>key_results</strong></td>
                            <td>Strong empirical performance but relies on approximations and sampling; the paper positions COBALT as providing more principled ROI-based filtering and theoretical guarantees while achieving competitive or better empirical performance.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Computationally intensive due to entropy estimation and sampling approximations; theoretical guarantees for constrained extensions remain challenging according to the paper.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1122.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1122.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI agents using adaptive experimental design methods in unknown or partially observable environments, including the specific adaptation strategies, environment characteristics, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SCBO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Scalable Constrained Bayesian Optimization (SCBO)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A scalable Thompson-sampling-like constrained BO approach that uses a Gaussian copula to address heteroskedasticity and samples from posterior-constrained functions to weight objective samples; extends TuRBO-style trust regions for large search spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Scalable constrained bayesian optimization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>SCBO</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Extends posterior sampling / Thompson sampling to constrained settings by transforming observations (Gaussian copula) to handle heteroskedastic functions, using axis-aligned trust regions (TuRBO) for scalability, and sampling constraint posteriors to weigh objective samples when selecting candidates.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptive_design_method</strong></td>
                            <td>Thompson sampling / posterior sampling tailored for constrained problems, with trust-region (local) adaptation.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_strategy_description</strong></td>
                            <td>Adapts exploration via randomized posterior samples and trust-region mechanisms: samples from GP posteriors of objective and constraints, constructs candidate sets within trust region(s), and weights/filters candidates by sampled feasibility, adapting locality (trust region) based on observed progress.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Same CBO benchmark tasks used in experiments (paper uses SCBO as a baseline).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_characteristics</strong></td>
                            <td>Black-box objective and constraints, possibly heteroskedastic across domain, noisy observations, continuous high-dimensional spaces where local search/trust-regions are beneficial.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_complexity</strong></td>
                            <td>Designed for scalability to higher dimensions and large search spaces (TuRBO-style local trust regions); evaluated on tasks including 32D UCI converter problem in the paper's comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_adaptive_design</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_adaptation</strong></td>
                            <td>Used as a competitive baseline; paper indicates SCBO performs well in some settings but is outperformed by COBALT on several tasks—especially where explicit active constraint learning and ROI shrinking are important; no absolute numeric metrics provided.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_adaptation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sample_efficiency</strong></td>
                            <td>Not numerically specified here; SCBO is designed for sample efficiency in high-dimensional/heteroskedastic settings but comparative sample-efficiency versus COBALT is expressed qualitatively via regret curves in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_tradeoff</strong></td>
                            <td>Achieved via randomized posterior sampling (Thompson sampling) which naturally balances exploration/exploitation, combined with trust-region adjustments that focus sampling locally when progress is promising.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_methods</strong></td>
                            <td>Compared experimentally against COBALT, cEI, and cMES-IBO.</td>
                        </tr>
                        <tr>
                            <td><strong>key_results</strong></td>
                            <td>SCBO is a strong scalable baseline that handles heteroskedasticity and large search spaces via trust regions, but may underperform when explicit, targeted active learning of constraints and ROI-based search-space shrinking (as in COBALT) are critical to finding feasible optima.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>May be less effective in problems where constraint identification (level-set estimation) is the primary bottleneck; relies on local trust-region heuristics and posterior sampling which can be trapped if feasibility is not adequately explored.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Active learning for level set estimation <em>(Rating: 2)</em></li>
                <li>Truncated variance reduction: A unified approach to bayesian optimization and level-set estimation <em>(Rating: 2)</em></li>
                <li>Bayesian optimization with unknown constraints <em>(Rating: 2)</em></li>
                <li>Sequential and parallel constrained max-value entropy search via information lower bound <em>(Rating: 2)</em></li>
                <li>Scalable constrained bayesian optimization <em>(Rating: 2)</em></li>
                <li>Gaussian process optimization in the bandit setting: No regret and experimental design <em>(Rating: 1)</em></li>
                <li>Predictive entropy search for bayesian optimization with unknown constraints <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1122",
    "paper_id": "paper-264128187",
    "extraction_schema_id": "extraction-schema-25",
    "extracted_data": [
        {
            "name_short": "COBALT",
            "name_full": "COnstrained Bayesian optimization with Adaptive active Learning of unknown constraints (COBALT)",
            "brief_description": "A constrained Bayesian optimization algorithm that integrates active level-set estimation for unknown constraints with UCB-style optimization of the objective, maintaining independent GPs for objective and each constraint and adaptively trading off learning feasibility vs objective improvement.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "COBALT",
            "agent_description": "Maintains Gaussian process (GP) surrogates for the objective f and each constraint C_k, computes pointwise UCB/LCB confidence bounds, identifies Regions of Interest (ROIs) by intersecting constraint ROIs and objective ROI, and selects queries by maximizing a pooled acquisition set (objective UCB-based acquisition and constraint uncertainty-width acquisition). Key components: independent GPs, ROI identification via confidence intervals, two acquisition functions (α_f for objective, α_Ck for constraints), and a master selection that picks the highest acquisition across aspects.",
            "adaptive_design_method": "Bayesian optimization combined with active learning for level-set estimation (UCB/LCB-based acquisition; information-aware ROI shrinking)",
            "adaptation_strategy_description": "At each iteration COBALT updates GP posteriors, computes UCB/LCB for objective and constraints, forms per-function ROIs (superlevel sets and undecided sets), proposes candidate points maximizing (a) α_f(x)=UCB_f(x)-LCB_f,max for optimizing objective in X_f,t and (b) α_Ck(x)=UCB_Ck(x)-LCB_Ck(x) on undecided constraint regions to reduce epistemic uncertainty; then picks the single candidate with maximal acquisition across all aspects—thus adaptively trading off exploration of constraints vs exploitation of objective based on current confidence intervals and ROI intersections.",
            "environment_name": "Constrained Bayesian optimization benchmark tasks (synthetic benchmarks: Rastrigin-1D-1C, Ackley-5D-2C; real-world: Vessel-4D-3C, Spring-3D-6C, Car-7D-8C, UCI Converter-32D-3C)",
            "environment_characteristics": "Black-box objective and one or more black-box constraints; observation noise (additive Gaussian, e.g., N(0,0.1) in experiments); continuous input spaces (compact subsets of R^d) often discretized for evaluation; partially observable feasibility (constraints unknown and must be actively learned); coupled or decoupled evaluation settings supported.",
            "environment_complexity": "Varies by task: examples include 1D with 1 constraint (Rastrigin-1D-1C, 1000 discrete points), 5D with 2 constraints (Ackley-5D-2C), 4D with 3 constraints (pressure vessel), 3D with 6 constraints (spring), 7D with 8 constraints (car), 32D with 3 constraints (UCI WEC); feasible-region fractions range from ≈0.38% (spring) to ≈78% (vessel).",
            "uses_adaptive_design": true,
            "performance_with_adaptation": "Qualitative: COBALT achieves consistently superior simple-regret performance after sufficient iterations across diverse CBO tasks; on Rastrigin-1D-1C (1000-point discrete space, noisy observations N(0,0.1)) COBALT consistently reaches the global optimum within 2000 iterations while baselines often fail; in many higher-dimensional/real-world tasks COBALT outperforms baselines in final simple regret (plots show averaged standardized simple regret over ≥15 trials with 95% CI). Numerical theoretical bound: the paper proves that with β_t chosen appropriately there exists ε s.t. after at most T ≥ β_T γ_T C1 ε^2 iterations the high-confidence interval width for f* is ≤ ε with probability ≥1−δ (γ_T = cumulative information gain, C1 = 8 / log(1+σ^{−2})).",
            "performance_without_adaptation": "Baselines (cEI, cMES-IBO, SCBO) often get trapped in local optima or exhibit worse final simple regret; no single numeric baseline value is reported in the paper (comparisons are via simple-regret curves), but authors report COBALT sometimes lags early but surpasses baselines and attains superior final performance.",
            "sample_efficiency": "Empirical: on the discrete Rastrigin-1D-1C experiment COBALT reaches the global optimum within 2000 iterations (15 independent trials, noise N(0,0.1)); theoretical: sample complexity bound depends on information gain γ_T and confidence parameter β_T via T ≥ β_T γ_T C1 ε^2 (as reported in paper).",
            "exploration_exploitation_tradeoff": "Explicit trade-off by design: constraint-acquisition α_Ck(x) targets reduction of constraint epistemic uncertainty (width UCB−LCB) on undecided sets, while objective-acquisition α_f(x) targets maximizing UCB relative to LCB_f,max within objective ROI; master selection picks highest acquisition across these, so the algorithm adaptively favors constraint learning when feasibility uncertainty is high and favors objective optimization when ROIs are well-identified.",
            "comparison_methods": "Compared experimentally against cEI (Gelbart et al., 2014), cMES-IBO (Takeno et al., 2022), and SCBO (Eriksson & Poloczek, 2021).",
            "key_results": "1) Adaptive active learning of constraints combined with UCB-style objective optimization and ROI intersection yields reliable identification of feasible ROIs and improved final simple regret across synthetic and real-world CBO tasks; 2) Theoretical guarantee: with appropriate β_t, COBALT keeps the global optimum in the ROI with high probability and bounds the high-confidence interval width for f* after a T that scales with β_T and the information gain γ_T; 3) Empirically more robust to varying feasible-region sizes (Rastrigin experiments) and avoids being trapped at local optima where baselines fail.",
            "limitations_or_failures": "Reported limitations include: (1) potential insufficiency due to pointwise ROI comparisons (may miss structured/regionwise information), (2) lack of explicit handling of correlated unknowns (constraints assumed independent GPs), (3) early-stage lag in some tasks where active constraint learning initially reduces objective-focused evaluations (COBALT sometimes performs worse than baselines early but improves later), and (4) empirical results are averaged simple regret curves without absolute numeric performance tables for all tasks.",
            "uuid": "e1122.0"
        },
        {
            "name_short": "COBALT-Decoupled",
            "name_full": "COnstrained Bayesian optimization with Adaptive active Learning of decoupled unknown constraints (COBALT-Decoupled)",
            "brief_description": "A variant of COBALT designed for the decoupled evaluation setting where objective and constraints can be evaluated independently; selects both a candidate input x and which function g (objective or specific constraint) to evaluate at that x using the same acquisition-selection machinery.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "COBALT-Decoupled",
            "agent_description": "Same GP-based architecture as COBALT but adapted: after proposing candidate points x_g,t for each aspect g∈{f}∪{C_k}, the algorithm selects which function g_t to evaluate at the chosen x_t (decoupled evaluation), updating only the corresponding GP posterior per query.",
            "adaptive_design_method": "Bayesian optimization + active level-set estimation with per-aspect acquisition and explicit selection of which function to query (decoupled active learning/experimental design).",
            "adaptation_strategy_description": "Generates per-aspect candidates as in COBALT (α_f and α_Ck), then selects g_t = argmax_g α_g,t(x_g,t) and queries x_g,t for that particular function g_t, thereby adapting both location and modality of the experiment (which function to measure) based on current uncertainty and ROIs.",
            "environment_name": "Same CBO benchmark tasks as COBALT; decoupled evaluation scenarios where objective and constraints can be measured independently.",
            "environment_characteristics": "Black-box objective and constraints; possibly decoupled (can measure any single function at chosen x); observation noise Gaussian; continuous input spaces; partially observable constraint feasibility.",
            "environment_complexity": "Same variety as COBALT (1D–32D tasks with 1–8 constraints), with the total number of function evaluations split across f and C_k as T = sum_g T_g. Information gain γ_T is computed per-function and summed.",
            "uses_adaptive_design": true,
            "performance_with_adaptation": "Paper states analogous theoretical guarantee to coupled COBALT: after at most T ≥ β_T γ_T C1 ε^2 iterations the high-confidence interval for f* is bounded by ε with high probability; empirically the decoupled variant is suggested to require minimal adaptation and retain similar performance guarantees, though specific empirical decoupled-experiment curves are not detailed in the paper.",
            "performance_without_adaptation": null,
            "sample_efficiency": "Theoretical sample complexity similar to COBALT but accounting for per-function information gains: T must satisfy T ≥ β_T γ_T C1 ε^2 (γ_T now sums per-function gains). No explicit empirical sample counts for decoupled runs provided.",
            "exploration_exploitation_tradeoff": "Same mechanism as COBALT but extended: the selection of which function to evaluate provides additional control—when constraint uncertainty dominates, algorithm tends to select constraint queries; when objective ROI uncertainty dominates, selects objective evaluations.",
            "comparison_methods": "Compared conceptually/theoretically to coupled-COBALT and baselines in discussion; no distinct empirical baseline run reported specifically for decoupled variant in main experiments.",
            "key_results": "COBALT adapts naturally to decoupled evaluation with similar theoretical guarantees; the acquisition-selection mechanism can also choose which function to evaluate, enabling adaptive experimental design in settings where measurements can be targeted to objective or individual constraints.",
            "limitations_or_failures": "No distinct empirical results provided; theoretical bounds depend on distribution of evaluations across functions via γ_T and require proper choice of β_t; practical performance may hinge on allocation strategy across functions, which is not deeply explored.",
            "uuid": "e1122.1"
        },
        {
            "name_short": "cEI",
            "name_full": "Constrained Expected Improvement (cEI)",
            "brief_description": "An extension of the Expected Improvement acquisition for constrained BO that multiplies expected improvement by probability of feasibility at a candidate point.",
            "citation_title": "Bayesian optimization with unknown constraints",
            "mention_or_use": "use",
            "agent_name": "cEI",
            "agent_description": "Uses GP surrogates for objective and constraints and evaluates acquisition α(x) = EI(x) * P[feasible(x)] (or variants); typically evaluates both objective and constraints at queried points (coupled setting) and relies on Monte Carlo approximations in noisy settings.",
            "adaptive_design_method": "Expected Improvement modulated by feasibility probability (BO with feasibility-calibrated acquisition).",
            "adaptation_strategy_description": "Passively learns constraints via GP posteriors and weights EI by current probability of feasibility; hence adapts exploration toward promising and likely-feasible regions but does not proactively reduce constraint uncertainty.",
            "environment_name": "Same CBO benchmark tasks used in paper for comparison (Rastrigin, Ackley, vessel, spring, car, UCI 32D).",
            "environment_characteristics": "Black-box objective and constraints, Gaussian observation noise in experiments, continuous input spaces; feasibility may be sparse depending on chosen thresholds.",
            "environment_complexity": "Varies across the benchmark tasks (1D–32D, multiple constraints).",
            "uses_adaptive_design": true,
            "performance_with_adaptation": "Empirically used as a baseline; reported to sometimes be trapped or perform worse when no feasible points exist or when feasibility is critical—paper reports cEI is outperformed by COBALT on several tasks (COBALT attains better final simple regret and robustness to feasible-region size). No absolute numerical metrics provided in the paper.",
            "performance_without_adaptation": null,
            "sample_efficiency": "Not quantitatively reported in this paper; in experiments cEI often converges more slowly or to worse local optima compared to COBALT in tasks where explicit constraint learning matters.",
            "exploration_exploitation_tradeoff": "Balances exploitation via EI with exploration driven indirectly by feasibility uncertainty through P[feasible(x)], but does not explicitly target constraint-uncertainty reduction.",
            "comparison_methods": "Compared against COBALT, cMES-IBO, and SCBO in experiments.",
            "key_results": "cEI can be inferior in problems where feasibility identification is crucial because it passively learns constraints rather than actively reducing constraint uncertainty; authors cite scenarios where it fails if feasible points are absent or rare.",
            "limitations_or_failures": "Known failure when feasible region is empty or very small; passive constraint learning can lead to poor performance when feasibility matters more than objective optimization.",
            "uuid": "e1122.2"
        },
        {
            "name_short": "cMES-IBO",
            "name_full": "Constrained Max-Value Entropy Search with Information Lower Bound (cMES-IBO)",
            "brief_description": "An information-theoretic constrained BO method that extends Max-value Entropy Search to constrained problems using a lower bound on mutual information to guide queries.",
            "citation_title": "Sequential and parallel constrained max-value entropy search via information lower bound",
            "mention_or_use": "use",
            "agent_name": "cMES-IBO",
            "agent_description": "Information-based acquisition aiming to reduce entropy about the maximum value (or location) under constraints by estimating mutual information between observations and the optimizer, using approximations/lower bounds to make computation feasible.",
            "adaptive_design_method": "Information gain maximization (entropy-based BO / max-value entropy search adapted for constraints).",
            "adaptation_strategy_description": "Selects queries that maximize information about the constrained optimum (reducing entropy of the max value or optimum location), approximated via sampling/variational methods; adapts to current posterior uncertainty to prioritize informative queries.",
            "environment_name": "Same benchmark tasks used for experimental comparison in paper.",
            "environment_characteristics": "Black-box objective and constraints; noisy observations; continuous domains; feasibility may be rare (e.g., spring task).",
            "environment_complexity": "Varied (1D–32D tasks with multiple constraints).",
            "uses_adaptive_design": true,
            "performance_with_adaptation": "Reported as a strong baseline in experiments; in the paper cMES-IBO performs well but is outperformed by COBALT on several tasks in final regret; specific numeric metrics not provided in main text.",
            "performance_without_adaptation": null,
            "sample_efficiency": "Not numerically reported here; typically information-theoretic methods are sample-efficient but computationally heavier; paper remarks approximations/sampling are used and theoretical guarantees are challenging.",
            "exploration_exploitation_tradeoff": "Implicitly handled via information-theoretic objective that trades off learning about the constrained optimum (exploration) vs reducing uncertainty near promising optima (exploitation).",
            "comparison_methods": "Compared experimentally against COBALT, cEI, and SCBO.",
            "key_results": "Strong empirical performance but relies on approximations and sampling; the paper positions COBALT as providing more principled ROI-based filtering and theoretical guarantees while achieving competitive or better empirical performance.",
            "limitations_or_failures": "Computationally intensive due to entropy estimation and sampling approximations; theoretical guarantees for constrained extensions remain challenging according to the paper.",
            "uuid": "e1122.3"
        },
        {
            "name_short": "SCBO",
            "name_full": "Scalable Constrained Bayesian Optimization (SCBO)",
            "brief_description": "A scalable Thompson-sampling-like constrained BO approach that uses a Gaussian copula to address heteroskedasticity and samples from posterior-constrained functions to weight objective samples; extends TuRBO-style trust regions for large search spaces.",
            "citation_title": "Scalable constrained bayesian optimization",
            "mention_or_use": "use",
            "agent_name": "SCBO",
            "agent_description": "Extends posterior sampling / Thompson sampling to constrained settings by transforming observations (Gaussian copula) to handle heteroskedastic functions, using axis-aligned trust regions (TuRBO) for scalability, and sampling constraint posteriors to weigh objective samples when selecting candidates.",
            "adaptive_design_method": "Thompson sampling / posterior sampling tailored for constrained problems, with trust-region (local) adaptation.",
            "adaptation_strategy_description": "Adapts exploration via randomized posterior samples and trust-region mechanisms: samples from GP posteriors of objective and constraints, constructs candidate sets within trust region(s), and weights/filters candidates by sampled feasibility, adapting locality (trust region) based on observed progress.",
            "environment_name": "Same CBO benchmark tasks used in experiments (paper uses SCBO as a baseline).",
            "environment_characteristics": "Black-box objective and constraints, possibly heteroskedastic across domain, noisy observations, continuous high-dimensional spaces where local search/trust-regions are beneficial.",
            "environment_complexity": "Designed for scalability to higher dimensions and large search spaces (TuRBO-style local trust regions); evaluated on tasks including 32D UCI converter problem in the paper's comparisons.",
            "uses_adaptive_design": true,
            "performance_with_adaptation": "Used as a competitive baseline; paper indicates SCBO performs well in some settings but is outperformed by COBALT on several tasks—especially where explicit active constraint learning and ROI shrinking are important; no absolute numeric metrics provided.",
            "performance_without_adaptation": null,
            "sample_efficiency": "Not numerically specified here; SCBO is designed for sample efficiency in high-dimensional/heteroskedastic settings but comparative sample-efficiency versus COBALT is expressed qualitatively via regret curves in experiments.",
            "exploration_exploitation_tradeoff": "Achieved via randomized posterior sampling (Thompson sampling) which naturally balances exploration/exploitation, combined with trust-region adjustments that focus sampling locally when progress is promising.",
            "comparison_methods": "Compared experimentally against COBALT, cEI, and cMES-IBO.",
            "key_results": "SCBO is a strong scalable baseline that handles heteroskedasticity and large search spaces via trust regions, but may underperform when explicit, targeted active learning of constraints and ROI-based search-space shrinking (as in COBALT) are critical to finding feasible optima.",
            "limitations_or_failures": "May be less effective in problems where constraint identification (level-set estimation) is the primary bottleneck; relies on local trust-region heuristics and posterior sampling which can be trapped if feasibility is not adequately explored.",
            "uuid": "e1122.4"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Active learning for level set estimation",
            "rating": 2,
            "sanitized_title": "active_learning_for_level_set_estimation"
        },
        {
            "paper_title": "Truncated variance reduction: A unified approach to bayesian optimization and level-set estimation",
            "rating": 2,
            "sanitized_title": "truncated_variance_reduction_a_unified_approach_to_bayesian_optimization_and_levelset_estimation"
        },
        {
            "paper_title": "Bayesian optimization with unknown constraints",
            "rating": 2,
            "sanitized_title": "bayesian_optimization_with_unknown_constraints"
        },
        {
            "paper_title": "Sequential and parallel constrained max-value entropy search via information lower bound",
            "rating": 2,
            "sanitized_title": "sequential_and_parallel_constrained_maxvalue_entropy_search_via_information_lower_bound"
        },
        {
            "paper_title": "Scalable constrained bayesian optimization",
            "rating": 2,
            "sanitized_title": "scalable_constrained_bayesian_optimization"
        },
        {
            "paper_title": "Gaussian process optimization in the bandit setting: No regret and experimental design",
            "rating": 1,
            "sanitized_title": "gaussian_process_optimization_in_the_bandit_setting_no_regret_and_experimental_design"
        },
        {
            "paper_title": "Predictive entropy search for bayesian optimization with unknown constraints",
            "rating": 1,
            "sanitized_title": "predictive_entropy_search_for_bayesian_optimization_with_unknown_constraints"
        }
    ],
    "cost": 0.01536125,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>CONSTRAINED BAYESIAN OPTIMIZATION WITH ADAP-TIVE ACTIVE LEARNING OF UNKNOWN CONSTRAINTS
12 Oct 2023</p>
<p>Fengxue Zhang zhangfx@uchicago.edu 
Dept. of Computer Science
The University of Chicago Chicago
IllinoisUSA</p>
<p>Zejie Zhu zejie.zhuu@gmail.com 
Dept. of Statistics
The University of Chicago Chicago
IllinoisUSA</p>
<p>Yuxin Chen chenyuxin@uchicago.edu 
Dept. of Computer Science
The University of Chicago Chicago
IllinoisUSA</p>
<p>CONSTRAINED BAYESIAN OPTIMIZATION WITH ADAP-TIVE ACTIVE LEARNING OF UNKNOWN CONSTRAINTS
12 Oct 20231E8B8578C2452F1FE6C80E80DC6AA7DEarXiv:2310.08751v1[cs.LG]
Optimizing objectives under constraints, where both the objectives and constraints are black box functions, is a common scenario in real-world applications such as the design of medical therapies, industrial process optimization, and hyperparameter optimization.One popular approach to handling these complex scenarios is Bayesian Optimization (BO).In terms of theoretical behavior, BO is relatively well understood in the unconstrained setting, where its principles have been well explored and validated.However, when it comes to constrained Bayesian optimization (CBO), the existing framework often relies on heuristics or approximations without the same level of theoretical guarantees.In this paper, we delve into the theoretical and practical aspects of constrained Bayesian optimization, where the objective and constraints can be independently evaluated and are subject to noise.By recognizing that both the objective and constraints can help identify high-confidence regions of interest (ROI), we propose an efficient CBO framework that intersects the ROIs identified from each aspect to determine the general ROI.The ROI, coupled with a novel acquisition function that adaptively balances the optimization of the objective and the identification of feasible regions, enables us to derive rigorous theoretical guarantees for its performance.We showcase the efficiency and robustness of our proposed CBO framework through extensive empirical evidence and discuss the fundamental challenge of deriving practical regret bounds for CBO algorithms.</p>
<p>INTRODUCTION</p>
<p>Bayesian optimization (BO) has been widely studied as a powerful framework for expensive black-box optimization tasks in machine learning, engineering, and science in the past decades.Additionally, many real-world applications often involve black-box constraints that are costly to evaluate.Examples include choosing from a plethora of untested medical therapies under safety constraints (Sui et al., 2015); determining optimal pumping rates in hydrology to minimize operational costs under constraints on plume boundaries (Gramacy et al., 2016); or tuning hyperparameters of a neural network under memory constraints (Gelbart et al., 2014).To incorporate the constraints into the BO framework, it is common to model constraints analogously to the objectives via Gaussian processes (GP) and then utilize an acquisition function to trade off the learning and optimization to decide subsequent query points.</p>
<p>Over the past decade, advancements have been made in several directions trying to address constrained BO (CBO).However, limitations remain in each direction.For instance, extended Expected Improvement (Gelbart et al., 2014;Gardner et al., 2014) approaches learn the constraints passively In the left box, we maintain a Gaussian process as the surrogate model for the unknown objective and each constraint.The dotted curve shows the actual function, the red curve shows the predicted mean, and the shaded area denotes the confidence interval.In the right box, we first derive the acquisitions from each Gaussian process defined on a corresponding region of interests and define the general acquisition function by combining them all.Each time, the algorithm maintains the model, maximizes the general acquisition function to pick the candidate to evaluate, and then updates the model with the new observation.In later sections, we will elaborate on the filtered gray gap in the acquisition.</p>
<p>and can lead to inferior performance where the feasibility matters more than the objective optimization.The augmented lagrangian (AL) methods (Gramacy et al., 2016;Picheny et al., 2016;Ariafar et al., 2019) convert constrained optimization into unconstrained optimization with additional hyperparameters that are decisive for its performance while lacking theoretical guidance on the choice of its value.The entropy-based methods (Takeno et al., 2022) rely heavily on approximation and sampling, which violates the theoretical soundness of the method.In general, the current methods extend the unconstrained BO methods with approximation or heuristics to learn the constraints and optimize the objective simultaneously, lacking a rigorous performance guarantee as in the Bayesian optimization tasks without the need to learn unknown constraints.</p>
<p>The challenge and necessity of learning the unknown constraints for constrained BO motivate us to resort to active learning methods dealing with unknown constraints.Such methods have been studied under active learning for level-set estimation (AL-LSE).Much like BO, AL-LSE models the black-box function through a Gaussian process and pursues optimization via sequential queries.However, the distinction lies in the objectives: while BO focuses on finding the maximizer of an objective, AL-LSE seeks to classify points in the domain as lying above or below a specified threshold.This setting is particularly relevant in applications where a desirable region, rather than a single optimal point, is sought, as seen in environmental monitoring and sensor networks (Gotovos et al., 2013).Recent approaches, such as truncated variance reduction (Bogunovic et al., 2016) and an information-theoretic framework (Nguyen et al., 2021), aim to unify the theories of both sides.The unification inspires us to design a framework that adaptively balances the active feasible region identification and the unknown objective optimization.</p>
<p>In this paper, we propose a novel framework that integrates AL-LSE with BO for constrained Bayesian optimization.Our approach leverages the theoretical advantages of both paradigms, allowing for a rigorous performance analysis of the CBO method.A brief illustration of the framework design is shown in figure 1.The subsequent sections of this paper are structured as follows.In section 2, we provide a detailed overview of recent advancements in various facets of CBO.In section 3, we delve into the problem statement and discuss the definition of a probabilistic regret as a performance metric that enables rigorous performance analysis.In sections 4 and 5, we propose the novel CBO framework and offer the corresponding performance analysis.In section 6, we provide empirical evidence for the efficacy of the proposed algorithm.In section 7, we reflect on the key takeaways of our framework and discuss its potential implications for future work.</p>
<p>RELATED WORK</p>
<p>Feasibility-calibrated unconstrained methods.While the majority of the research in Bayesian optimization (BO) is concerned with unconstrained problems as summarized by Frazier (2018), there exists works that also consider black-box constraints.The pioneering work by Schonlau et al. (1998) first extended Expected Improvement (EI) to constrained cases by defining at a certain point the product of the expected improvement and the probability of the point being feasible.Later, this cEI algorithm was further advanced by Gelbart et al. (2014) andGardner et al. (2014), and the noisy setting was studied by Letham et al. (2019) using Monte Carlo integration while also introducing batch acquisition.The posterior sampling method (Thompson sampling) is extended to scalable CBO (SCBO) by Eriksson and Poloczek (2021).The proposed SCBO algorithm converts the original observation with a Gaussian copula.It addresses the heteroskedasticity of unknown functions over the large search space with axis-aligned trust region, extending the TuRBO Eriksson et al. (2019) in the unconstrained BO with additional sampling from the posterior of the constrained functions to weight the samples of the objective.The problem with the feasibility-calibrated methods is the scenario with no feasible point in the search space.Workarounds, including maximizing the feasibility or minimizing the constraint violation, are introduced, damaging the soundness of the algorithm.</p>
<p>Information-based criterion There has been a recent surge of interest in the field toward the information-theoretic framework within BO.Predictive entropy search (PES) (Hernández-Lobato et al., 2014) was extended to constraints (PESC) and detailed the entropy computations by Hernández-Lobato et al. (2015).Later, max-value entropy search was proposed by Wang and Jegelka (2017) to address the PES's expensive computations for estimating entropy, and the constrained adaptation was developed by Perrone et al. (2019).More recently, variants of the MES were developed, such as the methods based on a lower bound of mutual information (MI), which guarantees non-negativity.(Takeno et al., 2022) However, approximations, including sampling and variational inference, are introduced due to the intrinsic difficulty of the direct estimation of the entropy.Despite the strong empirical performance, the theoretical guarantee of these CBO extensions of entropy methods remains an open challenge.</p>
<p>Additive-structure methods Another direction in this field incorporates BO into the augmented Lagrangian framework by placing the constraint into the objective function and reducing the problem into solving a series of unconstrained optimization tasks using vanilla BO (Gramacy et al., 2016).The idea was developed further by Picheny et al. (2016) using slack variables to convert mixed constraints to only equality constraints, which achieve better performance, and by Ariafar et al. (2019) using ADMM algorithm to tackle an augmented Lagrangian relaxation.Similarly, in the risk-averse BO setting studied by Makarova et al. (2021), the unknown heteroscedastic risk corresponding to the reward is considered a penalty.It is added with a manually specified coefficient.Their method comes with a rigorous theoretical guarantee regarding the corresponding risk-regulated reward.However, in both the risk-averse method and the augmented Lagrangian frameworks, the appropriate coefficient of the additive structure is essential to the performance while lacking a prior theoretical justification.</p>
<p>Active learning of constraint(s) Active learning for Level-set estimation (AL-LSE) was initially proposed by Gotovos et al. (2013) to perform a classification task on the sample space which enjoys theoretical guarantees.As both AL-LSE and BO share GP features, the method was later extended to the BO domain by Bogunovic et al. (2016), in which they unify the two under truncated variance reduction and assume the kernel such that the variance reduction function is submodular.The problem with directly applying level-set estimation methods is their limitation on dealing with only one unknown function at one time and lack of a straightforward extension to trade-off the learning of multiple unknown functions, as typically seen in BO with unknown constraints.Malkomes et al. (2021); Komiyama et al. (2022) propose a novel acquisition function that prioritizes diversity in the active search.However, there is no straightforward extension to adaptively trade off the learning of constraints and the optimization of the objective.Incorporating its idea into our setting remains challenging.</p>
<p>PROBLEM STATEMENT</p>
<p>In this section, we introduce a few useful notations and formalize the problem.Consider a compact search space X ⊆ R. We aim to find a maximizer
x * ∈ arg max x∈X f (x) of a black-box function f : X → R, subject to K black-box constraints C k (x) (k ∈ K = {1
, 2, 3, ..., K}) such that each constraint is satisfied by staying above its corresponding threshold h k1 .Thus, formally, our goal can be formulated as finding:
max x∈X f (x) s.t. C k (x) &gt; h k , ∀k ∈ K
We maintain a Gaussian process (GP) as the surrogate model for each black-box function, pick a point x t ∈ X at iteration t by maximizing the acquisition function α : X → R, and observe the function values perturbed by additive noise: y f,t = f (x t ) + ϵ and y C k ,t = C k (x t ) + ϵ, with ϵ ∼ N (0, σ 2 ) being i.i.d.Gaussian noise.Each GP ( m(x), k(x, x ′ )) is fully specified by its prior mean m and kernel k.With the historical observations D t−1 = {(x i , y f,i , {y c K ,i } k∈K )} i=1,2,...t−1 , the posterior also takes the form of a GP, with mean
µ t (x) = k t (x) ⊤ (K t + σ 2 I) −1 y t (1)
and covariance
k t (x, x ′ ) = k(x, x ′ ) − k t (x) ⊤ (K t + σ 2 I) −1 k t (x ′ ) (2)
where
k t (x) ≜ [k(x 1 , x), . . . , k(x t , x)] ⊤ and K t ≜ [k(x, x ′ )] x,x ′ ∈Dt−1 is a positive definite kernel
matrix (Rasmussen and Williams, 2006).</p>
<p>The definition of reward plays an important role in analyzing online learning algorithms.Throughout the rest of the paper, we define the reward of CBO as the following and defer the detailed discussion to Appendix C.
r(x) = f (x) if I(C k (x) &gt; h k ) ∀k ∈ K − inf o.w. (3)
For simplicity and without loss of generality, we stick to the definition in equation 3 and let all h k = 0. We want to locate the global maximizer efficiently
x * = arg max x∈X,∀k∈K,C k (x)&gt;0 f (x)
Equivalently, we seek to achieve the performance guarantee in terms of simple regret at certain time t,
R t := r(x * ) − max x∈{x1,x2,...xt} r(x)
with a certain probability guarantee.Formally, given a certain confidence level δ and constant ϵ, we want to guarantee that after using up certain budget T dependent on δ and ϵ, we could achieve a high probability upper bound of the simple regret on the identified area X which is the subset of X.
P (max x∈ X R T (x) ≥ ϵ) ≤ 1 − δ</p>
<p>THE COBALT ALGORITHM</p>
<p>We start with necessary concepts from the active learning for level-set estimation and delve into the framework design.</p>
<p>ACTIVE LEARNING FOR LEVEL-SET ESTIMATION</p>
<p>We follow the common practice and assume each unknown constraint or objective is sampled from a corresponding independent Gaussian process (GP) (Hernández-Lobato et al., 2015;Gelbart et al., 2014;Gotovos et al., 2013) to treat the epistemic uncertainty.
C k ∼ GP C k ∀k ∈ K f ∼ GP f
We could derive pointwise confidence interval estimation with the GP for each black-box function.</p>
<p>We define the upper confidence bound UCB t (x)
≜ µ t−1 (x) + β 1/2 t σ t−1 (x) and lower confidence bound LCB t (x) ≜ µ t−1 (x) − β 1/2 t σ t−1 (x), where σ t−1 (x) = k t−1 (x, x) 1/2
and β acts as a scaling factor corresponding to certain confidence.For each unknown constraint C k , we follow the notations from Gotovos et al. (2013) and define the superlevel-set to be the areas that meet the constraint C k with high confidence
S C k ,t ≜ {x ∈ X|LCB C k ,t (x) &gt; 0}
We define the sublevel-set to be the areas that do not meet the constraint C k with high confidence
L C k ,t ≜ {x ∈ X|UCB C k ,t (x) &lt; 0}
and the undecided set is defined as
U C k ,t ≜ {x ∈ X|UCB C k ,t (x) ≥ 0, LCB C k ,t (x) ≤ 0}
where the points remain to be classified.</p>
<p>REGION OF INTEREST IDENTIFICATION FOR EFFICIENT CBO</p>
<p>In the CBO setting, we only care about the superlevel-set S C k ,t and undecided-set U C k ,t , where the global optimum is likely to lie in.Hence, we define the region of interest for each constraint function
C k as XC k ,t ≜ S C k ,t ∪ U C k ,t = {x ∈ X|UCB C k ,t (x) ≥ 0}
Similarly, for the objective function, though there is no pre-specified threshold, we could use the maximum of LCB f (x) on the intersection of superlevel-set
S C,t ≜ K k S C k ,t LCB f,t,max ≜ max x∈S C,t LCB f,t (x), if S C,t ̸ = ∅ −∞, o.w.
as the high confidence threshold for the UCB f,t (x) to identify a region of interest for the optimization of the objective.Given that UCB f,t
(x * ) ≥ f * ≥ f (x) ≥ LCB f,t (x)
with the probability specified by the choice of β f,t and β C,t , we define the ROI for the objective optimization as
Xf,t ≜ {x ∈ X|UCB f,t (x) ≥ LCB f,t,max }
By taking the intersection of the ROI of each constraint, we could identify the ROI for identifying the feasible region
XC,t ≜ K k XC k ,t
The combined ROI for CBO is determined by intersecting the ROIs of constraints and the objective:
Xt ≜ Xf,t ∩ XC,t(4)</p>
<p>COMBINING ACQUISITION FUNCTIONS FOR CBO</p>
<p>Acquisition function for optimizing the objective To optimize the unknown objective f when Xf,t is established, we can employ the following acquisition function2
α f,t (x) ≜ UCB f,t (x) − LCB f,t,max LCB f,t,max ̸ = ∞ UCB f,t (x) − LCB f,t (x) LCB f,t,max = ∞ (5)
At given t, to efficiently optimize the black-box f we evaluate the point
x t = arg max x∈ Xf,t α f,t (x).
Since at a given t, when LCB f,t,max (x) is constant, the acquisition function is equivalent to UCB f,t (x).</p>
<p>Acquisition function for learning the constraints When we merely focus on identifying the feasible region defined by a certain unknown constraint C k , we could apply the following acquisition function that serves the purpose of active learning of the unknown constraint function.
α C k ,t (x) ≜ UCB C k ,t (x) − LCB C k ,t (x)(6)
At given t, we evaluate the point x t = arg max x∈U C k ,t α f,t (x) to efficiently identify the feasible region defined by C k .Note that the acquisition function α C k ,t (x) is not maximized on the full XC k ,t , but only on U C k ,t as is shown in figure 2. The active learning on the superlevel-set S C k ,t doesn't contribute to identifying the corresponding feasible region.The following two rows show the GP for f , the region of interest Xf , and the corresponding acquisition function α f,t (x) defined in equation 5. We show that after identifying S C , we could define the threshold for ROI identification of f accordingly.The bottom row demonstrates that the general ROI X as defined in equation 4 is identified by taking the intersection ROI for f and C. The general acquisition function is defined as the maximum of the acquisition for f and C and is maximized on the X.The scaling and length scale of the Gaussian processes are learned by maximizing the likelihood.</p>
<p>The COBALT acquisition criterion With the two acquisitions discussed above and the ROIs discussed in section 4.2, we propose the algorithm COnstrained BO with Adaptive active Learning of unknown constraints (COBALT). 3COBALT essentially picks a data point with the maximum acquisition function value across all the acquisition functions defined on different domains.The maximization of different acquisition functions allows an adaptive tradeoff between the active learning of the constraints and the Bayesian Optimization of the objective on the feasible region.The intersection of ROIs allows an efficient search space shrinking for CBO.The complete procedure is shown in algorithm 1.We also illustrate the procedure on a 1D toy example in figure 2. We construct the example to demonstrate that the explicit, active learning of the constraint doesn't necessarily hurt the optimization but could contribute directly to the simple regret improvement.</p>
<p>THEORETICAL ANALYSIS</p>
<p>We first state a few assumptions that provide insights into the convergence properties of COBALT.</p>
<p>Algorithm 1 COnstrained BO with Adaptive active Learning of unknown constraints (COBALT)</p>
<p>1: Input:Search space X, initial observation D 0 , horizon T ; 2: for t = 1 to T do 3:</p>
<p>Update the posteriors of GP f,t and GP C k ,t according to equation 1 and 2 4:</p>
<p>Identify ROIs Xt , and undecided sets U C k ,t 5:
for k ∈ K do 6: if U C k ,t ̸ = ∅ then 7:
Candidate for active learning of each constraint:
x C k ,t ← arg max x∈U C k ,t α C k ,t (x) as in equation 6 8: G ← G ∪ C k,t 9:
Candidate for optimizing the objective: x f,t ← arg max x∈ Xf,t α f,t (x) as in equation 510:
G ← G ∪ f 11:
Maximize the acquisition values from different aspects: g t ← arg max g∈G α g,t (x g,t )</p>
<p>12:</p>
<p>Pick the candidate to evaluate: x t ← x g,t 13:</p>
<p>Update the observation set with the candidate and corresponding new observations
D t ← D t−1 ∪ {(x t , y f,t , {y c k ,t } k∈K )}
Assumption 1 The objective and constraints are sampled from independent Gaussian processes.</p>
<p>Formally, for all t &lt; T and x ∈ X, f (x) is a sample from GP f,t , and
C k (x) is a sample from GP C k ,t , for all k ∈ K.
Assumption 2 A global optimum exists within the feasible region.The distance between this global optimum and the boundaries of the feasible regions is uniformly bounded below by ϵ C .More specifically, for all k ∈ K, it holds that
C k (x * ) &gt; ϵ C .
Assumption 3 Given a proper choice of β t that is non-increasing, the confidence interval shrinks monotonically.For all t 1 &lt; t 2 &lt; T and x ∈ X, if β t1 ≤ β t2 , then UCB t1 (x) ≥ UCB t2 (x) and LCB t1 (x) ≤ LCB t2 (x).</p>
<p>This is a mild assumption as long as β t is non-increasing, given recent work by Koepernik and Pfaff (2021) showing that if the kernel is continuous and the sequence of sampling points lies sufficiently dense, the variance of the posterior GP converges to zero almost surely monotonically if the function is in metric space.If the assumption is violated, the technique of taking the intersection of all historical confidence intervals introduced by Gotovos et al. ( 2013) could similarly guarantee a monotonically shrinking confidence interval.That is, when
∃t 1 &lt; t 2 &lt; T, x ∈ X, if we have UCB t1 (x) &lt; UCB t2 (x) or LCB t1 (x) &gt; LCB t2 (x), we let UCB t2 (x) = UCB t1 (x) or LCB t2 (x) = LCB t1 (x)
to guarantee the monotonocity.</p>
<p>The following lemma justifies the definition of the regions(s) of interest Xt defined in equation 4.</p>
<p>Lemma 1 Under the assumptions above, the regions of interest Xt , as defined in equation 4, contain the global optimum with high probability.Formally, for all δ ∈ (0, 1), t ≥ 1, and any finite discretization D of X that contains the optimum
x * = arg max x∈X f (x) where C k (x * ) &gt; ϵ C for all k ∈ K and β t = 2 log(2(K + 1)| D|π t /δ) with t≥1 π −1 t = 1, we have P x * ∈ Xt ≥ 1 − δ.
The lemma shows that with proper choice of prior and β, the Xf,t remains nonempty during optimization.</p>
<p>Subsequently, let's define the maximum information gain about function f after T rounds:
γ f,T = max A⊂ D:|A|=T I (y A ; f A ) and γ T = g∈{f }∪{C k } k∈K γ g,T(7)
For clarity, we denote D Xt = D ∩ Xt , and
CI f * ,t = [max x∈ D Xt LCB t (x), max x∈ D Xt UCB t (x)].
In the following, we show that we could bound the simple regret of COBALT after sufficient rounds.The second row shows corresponding simple regret curves.We test each method with 15 independent trails and impose observation noises sampled from N (0, 0.1) not shown in the first row.</p>
<p>Concretely, in Theorem 1 we provide an upper bound on the width of the confidence interval for the global optimum f * = f (x * ).</p>
<p>Theorem 1 Under the aforementioned assumptions, with a constant
β t = 2 log(2(K +1)| D Xt |π t /δ)
and the acquisition function from Algorithm 1, there exists an ϵ ≤ min k∈K ϵ k , such that after at most
T ≥ β T γ T C1 ϵ 2 iterations, we have P [|CI f * ,t | ≤ ϵ, f * ∈ CI f * ,t | t ≥ T ] ≥ 1 − δ Here, C 1 = 8/ log(1 + σ −2 ).</p>
<p>EXPERIMENTS</p>
<p>In this section, we empirically study the performance of COBALT against three baselines, including (1) cEI, the extension of EI into CBO from Gelbart et al. ( 2014), (2) cMES-IBO, a state-of-the-art information-based approach by Takeno et al. (2022), and (3) SCBO, a recent Thompson Sampling (TS) method tailored for scalable CBO from Eriksson and Poloczek (2021).We abstain from comparison against Augmented-Lagrangian methods, following the practice of Takeno et al. (2022), as past studies have illustrated its inferior performance against sampling methods (Eriksson and Poloczek, 2021) or information-based methods (Takeno et al., 2022;Hernández-Lobato et al., 2014).We begin by describing the optimization tasks, and then discuss the performances.</p>
<p>CBO TASKS</p>
<p>We compare COBALT against the aforementioned baselines across six CBO tasks.The first two synthetic CBO tasks are constructed from conventional BO benchmark tasks4 .Among the other four real-world CBO tasks, the first three are extracted from Tanabe and Ishibuchi (2020), offering a broad selection of multi-objective multi-constraints optimization tasks.The fourth one is a 32-dimensional optimization task extracted from the UCI Machine Learning repository (mis, 2019).Further details about the datasets are available in Appendix D.</p>
<p>• The Rastrigin function is a non-convex function used as a performance test problem for optimization algorithms.It was first proposed by Rastrigin (1974) and used as a popular benchmark dataset (Pohlheim).The feasible region takes up approximately 60% of the search space.We also vary the threshold to control the portion of the feasible region to study the robustness of COBALT.Figure 3 shows the distribution of the objective function and feasible regions.The input dimensionality, the number of constraints, and the approximate portion of the feasible region in the whole search space for each task are denoted on the titles.We run the algorithms on each task for at least 15 independent trials.The curves show the average simple regret after standardization, while the shaded area denotes the 95% confidence interval through the optimization.</p>
<p>• The Ackley function is another commonly used optimization benchmark.We construct two constraints to enforce a feasible area approximately taking up 14% of the search space.</p>
<p>• The pressure vessel design problem aims at optimizing the total cost of a cylindrical pressure vessel.The feasible regions take up approximately 78% of the whole search space.</p>
<p>• The coil compression spring design problem aims to optimize the volume of spring steel wire, which is used to manufacture the spring (Lampinen and Zelinka, 1999) under static loading.The feasible regions take up approximately 0.38% of the whole search space.</p>
<p>• The car cab design problem includes seven input variables and eight constraints.The feasible feasible region takes up approximately 13% of the whole search space.</p>
<p>• This UCI water converter problem consists of positions and absorbed power outputs of wave energy converters (WECs) from the southern coast of Sydney(mis, 2019).The feasible feasible region takes up approximately 27% of the whole search space.</p>
<p>RESULTS</p>
<p>We study the robustness of the algorithms with varying feasible region sizes on the Rastrigin-1D-1C task.Results are demonstrated in figure 3. Note that the discrete search space consists of the 1000 points shown in the first row of figure 3, and with the observation noises, only COBALT consistently reaches the global optimum within 2000 iterations.The convergence highlights the essential role of the active learning of the constraint in achieving robust optimization when unknown constraints are present.</p>
<p>We further study COBALT on the aforementioned optimization tasks and show the simple regret curves in figure 4. On Rastrigin-1D-1C and Car-Cabin-7D-8C, COBALT lags behind the baselines at the early stage of the optimization, potentially due to the active learning of the constraints outweighing the optimization.The steady improvement of COBALT through the optimization allows a consistently superior performance after sufficient iterations.In contrast, the baselines are trapped at the local optimum on these two tasks.The results show that COBALT is efficient and effective in various settings, including different dimensionalities of input space, different numbers of constraints, and different correlations between constraints.</p>
<p>CONCLUSION</p>
<p>Bayesian optimization with unknown constraints poses challenges in the adaptive tradeoff between optimizing the unknown objective and learning the constraints.We introduce COBALT, which is backed by rigorous theoretical guarantees, to efficiently address constrained Bayesian optimization.</p>
<p>Our key insights include: (1) the ROIs determined through adaptive level-set estimation can congregate and contribute to the overall Bayesian optimization task; (2) acquisition functions based on independent GPs can be unified in a principled way.Through extensive experiments, we validate the efficacy and robustness of our proposed method across various optimization tasks.</p>
<p>A PROOFS</p>
<p>A.1 PROOF OF LEMMA 1</p>
<p>Proof: Similar to lemma 5.1 of Srinivas et al. (2009), with probability at least
1−1/2δ, ∀x ∈ D, ∀t ≥ 1, ∀g ∈ {f } ∪ {C k } k∈K , |g(x) − µ g,t−1 (x)| ≤ β 1/2 t σ g,t−1 (x)
Note that we also take the union bound on g ∈ {f } ∪ {C k } k∈K .</p>
<p>First, by definition
S C,t ≜ K k S C k ,t , we have ∀t ≤ T, x ∈ S C,t , ∀k ∈ K P C k (x) ≥ LCB C k ,t (x) = µ C k ,t−1 (x) − β 1/2 t σ C k ,t−1 (x) &gt; 0 ≥ 1 − 1/2δ
meaning with probability at 1 − δ, x lies in the feasible region.At the same time, we have, ∀t ≤ T
P [UCB f,t (x * ) ≥ f (x * ) ≥ f (x) ≥ LCB f,t (x) | C k (x) &gt; 0, ∀k ∈ K] ≥ 1 − 1/2δ
Given the mutual independency between the objective f and the constraints C k , and by the definition of the threshold LCB f,t,max (x), we have ∀t ≤ T , when ∃x ∈ S C,t ,
P [UCB f,t (x * ) &gt; LCB f,t,max ] ≥ (1 − 1/2δ) 2 ≥ 1 − δ Note when S C,t = ∅, LCB f,t,max (x) = −∞, we have P [UCB f,t (x * ) &gt; LCB f,t,max (x)] = 1.
In summary, we've shown that with probability at least 1 − δ, x * ∈ Xf,t .</p>
<p>Next, by the definition of
x * = arg max x∈X f (x) s.t. C k (x * ) &gt; ϵ C we have ∀t ≤ T, ∀k ∈ K P UCB C k ,t (x * ) = µ C k ,t−1 (x * ) + β 1/2 t σ C k ,t−1 (x * ) ≥ C k (x * ) &gt; 0 ≥ 1 − 1/2δ
meaning with probability at least 1 − 1/2δ, x * ∈ XC k ,t .And in general, we have ∀t ≤ T, ∀k ∈ K
P x * ∈ Xt ≥ 1 − δ □ A.2 PROOF OF THEOREM 1
The following lemmas show that the maximum of the acquisition functions equation 5 and 6 are both bounded after sufficient evaluations.</p>
<p>Lemma A.1 Under the conditions assumed in Theorem 1, let α t = max g∈G α g,t (x g,t ) as in Algorithm 1, with
β t = 2 log(2| D Xt |π t /δ) that is non-increasing, after at most T ≥ β T γ T C1 ϵ 2 iterations, α T ≤ ϵ Here C 1 = 8/ log(1 + σ −2 ).
Proof: We first unify the notation in the acquisition functions.
∀T ≥ t ≥ 1, ∀g ∈ {C k } k∈K , when D Xt ∩ U g,t ̸ = ∅, max x∈ D Xt ∩Ug,t UCB g,t (x) − LCB g,t (x) = 2β 1/2 g,t σ g,t−1 (x g,t ) ≤ α t (8) ∀T ≥ t ≥ 1, ∀g ∈ {C k } k∈K , when D Xt ∩ U C k ,t = ∅, let max x∈ D Xt ∩Ug,t UCB g,t (x) − LCB g,t (x) = 2β 1/2 g,t σ g,t−1 (x g,t ) = 0 ≤ α t (9) ∀T ≥ t ≥ 1, g = f max x∈ D Xt UCB f,t (x) − LCB f,t,max ≤ UCB f,t (x g,t ) − LCB f,t (x g,t ) (10) = 2β 1/2 g,t σ g,t−1 (x g,t )(11)≤ α t(12)
By lemma 5.4 of Srinivas et al. (2009), with
β t = 2 log(2(K + 1)| D Xt |π t /δ), ∀g ∈ {f } ∪ C kk∈K and ∀x t ∈ D Xt , we have T t=1 (2β 1/2 t σ g,t−1 , (x t )) 2 ≤ C 1 β T γ g,T .
By definition of α t , we have the following
T t=1 α 2 t ≤ T t=1 g∈G (α g,t (x g,t )) 2 = T t=1 g∈G (2β 1/2 g,t σ g,t−1 (x g,t )) 2 ≤ g∈G C 1 β T γ g,T = C 1 β T γ T
The last line holds due to the defination in equation 7. By Cauchy-Schwaz, we have
1 T ( T t=1 α t ) 2 ≤ C 1 β T γ T
By the monotonocity assumed in Assumption 3, the defination of U g,t , ∀g ∈ {C k } k∈K , and the defination of Xt , for ∀1 ≤ t 1 &lt; t 2 ≤ T , ∀g ∈ {C k } k∈K , we have that U g,t2 ⊆ U g,t1 and Xt2 ⊆ Xt1 .</p>
<p>Meaning the search space is shrinking for all constraints and the objective.Together with the monotonocity of UCB and LCB, for ∀1 ≤ t 1 &lt; t 2 ≤ T , we have α t2 ≤ α t1 , and therefore
α T ≤ 1 T T t=1 α t ≤ C 1 β T γ T T As a result, after at most T ≥ β T γ T C1 ϵ 2
iterations, we have α T ≤ ϵ.</p>
<p>□</p>
<p>With Lemma A.1, we could first prove that after adequately T rounds of evaluations such that ϵ ≤ min k∈K ϵ k is sufficiently small, with certain probability, x * ∈ S C,T .Then LCB f,t,max ̸ = −∞, and therefore the width of
[max x∈ D Xt LCB f,T (x), max x∈ D Xt UCB f,T (x)],
which is a the high confidence interval of f * , is bounded by ϵ.</p>
<p>Proof: We first prove that after at most
T ≥ β T γ T C1 ϵ 2 iterations, P x * ∈ D Xt ∩ S C,T ≥ 1 − 1/2δ.
Given equation 8 and 9 and Lemma A.1, we have ∀g ∈ C kk∈K , t ≥ T
max x∈ D Xt ∩Ug,t UCB g,t (x) − LCB g,t (x) ≤ ϵ ≤ min k∈K ϵ k According to the definition of U g,t , ∀x ∈ D Xt ∩ U g,t , ∀g ∈ C kk∈K UCB g,t (x) ≤ min k∈K ϵ k + LCB g,t (x) ≤ min k∈K ϵ k
According to Assumption 2, and Lemma 1, we have ∀k ∈ K
P UCB C k ,T (x * ) ≥ C k (x * ) &gt; ϵ k ≥ max x∈ D Xt ∩U C k ,t UCB C k ,T (x) ≥ 1 − 1/2δ
Hence ∀t ≥ T
P x * ∈ D Xt ∩ S C,t = D Xt ∩ XC,t \ ∪ k∈K U C k ,t ≥ 1 − 1/2δ
As a result
P [LCB f,t,max ̸ = −∞] ≥ 1 − 1/2δ
Next, we prove the upper bound for the width of high-confidence interval of f * .Given that LCB f,t,max ̸ = −∞, we have
max x∈ D Xt UCB f,T (x) − max x∈ D Xt LCB f,T (x) ≤ max x∈ D Xt UCB T (x) − LCB f,T,max ≤ 2β 1/2 f,T σ f,T −1 (x f,T ) ≤ α T ≤ ϵ
Combining it with the fact that
P max x∈ D Xt LCB f,T (x) ≤ max x∈ D Xt f (x) = f * ≤ UCB f,T (x * ) ≤ max x∈ D Xt UCB f,T (x) ≥ 1 − 1/2δ
we attain the final result that after T ≥ β T γ T C1 ϵ 2 iterations,
P [|CI f * ,t | ≤ ϵ, f * ∈ CI f * ,t | t ≥ T ] ≥ 1 − δ □ B DECOUPLED SETTING
In the main paper, we assume both objective f and the constraints {C k } k∈K are revealed upon querying an input point.The setting is regarded as a coupling of the objective and constraints, to differentiate from the decoupled setting, where the objective and constraints may be evaluated independently.In the decoupled setting, acquisition functions need to explicitly tradeoff the evaluation of the different aspects and in addition to helping to pick the candidate x t ∈ X, suggest g t ∈ {f } ∪ {C k } k∈K for evaluation each time.This typically requires different acquisition from coupled setting (Gelbart et al., 2014).However, we will that our acquisition function and COBALT require minimum adaptation to the decoupled setting while bearing a similar performance guarantee.</p>
<p>B.1 ALGORITHM FOR DECOUPLED SETTING</p>
<p>When taking the g t ← arg max g∈G α g,t (x g,t ) in Algorithm 1, we explicitly choose the aspect that matters most at a certain iteration.Naturally, we could adapt COBALT to the decoupled setting by querying x g,t on this unknown function g t ∈ G ⊆ {f } ∪ {C k } k∈K at iteration t.The modified algorithm is shown below.</p>
<p>B.2 THOERETICAL GUARANTEE AND PROOF</p>
<p>We first denote the maximum mutual information gain after T rounds of evaluations as
γ T = g∈{f }∪{C k } k∈K γ g,Tg(13)
Where T g denotes the number of evaluations for g ∈ {f } ∪ {C k } k∈K before T .Therefore we have
T = g∈{f }∪{C k } k∈K T g
Then we have the following guarantee for the performane of COBALT-Decoupled.</p>
<p>Theorem 2 The width of the resulting confidence interval of the global optimum f * = f (x * ) is upper bounded.That is, under the same assumptions in Theorem 1, with β t = 2 log(2(K + 1)| D Xt |π t /δ) that is constant, and acquisition function in Algorithm 2, ∃ϵ ≤ min k∈K ϵ k , after at most
T ≥ β T γ T C1 ϵ 2 iterations, we have P [|CI f * ,t | ≤ ϵ, f * ∈ CI f * ,t | t ≥ T ] ≥ 1 − δ Here C 1 = 8/ log(1 + σ −2 ) .
Algorithm 2 COnstrained BO with Adaptive active Learning of decoupled unknown constraints (COBALT-Decoupled) 1: Input:Search space X, initial observation D 0 , horizon T ; 2: for t = 1 to T do 3:</p>
<p>Update the posteriors of GP f,t and GP C k ,t according to equation 1 and 2 4:</p>
<p>Identify ROIs Xt , and undecided sets U C k ,t 5:
for k ∈ K do 6: if U C k ,t ̸ = ∅ then 7:
Candidate for active learning of each constraints:
x C k ,t ← arg max x∈U C k ,t α C k ,t (x) as in equation 6 8: G ← G ∪ C k,t 9:
Candidate for optimizing the objective: x f,t ← arg max x∈ Xf,t α f,t (x) as in equation 510:
G ← G ∪ f 11:
Maximize the acquisition values from different aspects: g t ← arg max g∈G α g,t (x g,t )</p>
<p>12:</p>
<p>Pick the candidate to evaluate: x t ← x g,t</p>
<p>13:</p>
<p>Update the observation set with the candidate and corresponding new observations on g
t D t ← D t−1 ∪ {(x t , y g,t )}
The proof is similar to Appendix A, as the major difference is replacing the upper bound in Lemma A.1 to
α T ≤ 1 T T t=1 α t ≤ C 1 β T γ T T Proof:
We omit the shared part of the proof.Here is the critical difference.</p>
<p>T t=1
α 2 t = T t=1 α 2 g,t (x g,t ) = T t=1 (2β 1/2 g,t σ g,t−1 (x g,t )) 2 ≤ g∈G C 1 β T γ g,Tg = C 1 β T γ T □ C REWARD FUNCTION C.1 REWARD CHOICE 1: PRODUCT OF REWARD AND FEASIBILITY
The definition of reward plays an important role in online machine learning performance analysis.In the CBO setting, one possible definition of constrained reward derived from the constraint nature is r(x) = f (x) k 1 C k (x)&gt;h k when assuming the f (x) &gt; 0. Considering both the aleatoric and epistemic uncertainty on the constraints, we could transform the problem into finding the maximizer
arg max x∈X r(x) = arg max x∈X f (x) k P [Y C k (x) &gt; h k ]
Here Y C k (x) denotes the observation of the constraint C k at x.</p>
<p>The problem with this product reward, on one hand, is that it is likely to incur a Pareto front if we regard the problem as a multi-objective optimization where the objectives are composed of f (x) and
P [Y C k (x) &gt; h k ].
The multi-objective nature and resulting Pareto front indicate that the optimization could be more challenging to converge than the single-objective unconstrained BO problem, though the unique global optimum is not always expected there either.More critically, is that when the feasibility of reaching a certain threshold, we prefer to focus on optimizing the objective value rather than the product for the following reasons.</p>
<p>Firstly, the marginal gain on improving feasibility by increasing the value of the constraint function drops after the feasibility reaches 0.5 if assuming it follows a Gaussian.Especially in the tail region, improving the feasibility and then the product of feasibility and objective value by optimizing the constraint function is prohibitively difficult.</p>
<p>Secondly, in most real-world scenarios except for certain applications that focus on feasibility (where the feasibility should be treated as another objective and make it in nature a multi-objective optimization), the actual marginal gain, in general, increases the feasibility decay faster than the increase of objective value.(e.g., when choosing between doubling the feasibility from 0.25 to 0.5 or doubling the objective drop from 25 to 50, we probably favor the former as 0.25, meaning it is unlikely to happen.However, when choosing between increasing feasibility from .8 to .9 or increasing the objective drop from 80 to 90, there would be no such clear preference.)Then, the user would possibly favor the gain on the objective function after the feasibility reaches a certain level.Therefore, we propose the following reward for constrained optimization tasks according to this insight.
(x) = f (x) if I(C k (x) &gt; h k ) ∀k ∈ K −inf o.w(14)
Next, if the observation on the constraints is perturbed with a known Gaussian noise, namely Y C k (x) ∼ N (C k (x), σ), we could deal with the aleatoric uncertainty with a user-specific confidence level for each constraint µ k ∈ (0, 1), ∀k ∈ K. Then we could turn I(Y C k (x) &gt; h k ) into probabilistic constraints following the definiation proposed by Gelbart et al. (2014) and
P [Y C k (x) &gt; h k ] ≥ µ k
to explicitly deal with the aleatoric uncertainty.With the percentage point function (PPF), we could transform the probabilistic constraints into a deterministic constraint I(C k (x) &gt; ĥk ) with ĥk = PPF(h k , σ, µ k ), meaning ĥ is the µ k percent point of a Gaussian distribution with h k and σ as its mean and standard deviation.Hence, we could unify the form of rewards of noise-free and noisy observation on the constraints with the user-specified confidence levels.For simplicity and without loss of generalization, we stick to the definition in equation 3 and let all h k = 0.</p>
<p>Throughout the rest of the paper, we want to efficiently locate the global maximizer
x * = arg max x∈X,∀k∈K,C k (x)&gt;0 f (x)
Equivalently, we seek to achieve the performance guarantee in terms of simple regret at certain time t, with a certain probability guarantee.Formally, given a certain confidence level δ and constant ϵ, we want to guarantee that after using up certain budget T dependent on δ and ϵ, we could achieve a high probability upper bound of the simple regret on the identified area X which is the subset of X. Converter-32D-3C This UCI dataset we use consists of positions and absorbed power outputs of wave energy converters (WECs) from the southern coast of Sydney.The applied converter model is a fully submerged three-tether converter called CETO.16 WECs 2D-coordinates are placed and optimized in a size-constrained environment (mis, 2019).The input is therefore 32 dimensional.We place three constraints on the tasks, including the absorbed power of the first two converters being above a certain threshold 96000, and the general position being not too distant with the two-norm below 2000.The feasible feasible region takes up approximately 27% of the whole search space.</p>
<p>P (max</p>
<p>E DISCUSSIONS</p>
<p>Here we offer additional discussion over the concerns on COBALT.</p>
<p>E.1 EMPTY ROI(S)</p>
<p>It is possible that Xt could be empty at certain t when any intersection results in the empty set.However, according to the assumptions in section 5 and Lemma 1, the properly chosen β f,t and β C,t that does not result in over-aggressive filtering, the ROI is soundly defined.The algorithm is also robust to empty U C k ,t due to the domain where the acquisition functions defined in equation 6 and equation 5 are maximized.</p>
<p>E.2 COMPARABILITY</p>
<p>Despite both the acquisition function for optimization of the objective and active learning are confidence interval-based, it is possible they are not comparable.In practice, the objective and constraints could be of different scales.With prior knowledge of the scaling difference, one can choose to standardize the values, or equivalently, calibrate the acquisition function accordingly.</p>
<p>E.3 LIMITATIONS</p>
<p>The limitation of COBALT including (1) the insufficiency of identifying the ROIs due to the pointwise comparison in current implementation; (2) the lack of discussion over correlated unknowns, which are common in practice (e.g. two constraints are actually lower bound and upper bound of the same value).We expect the following work could further improve the algorithms efficiency and effectiveness accordingly.</p>
<p>Figure 1 :
1
Figure1: Pipeline of proposed algorithm COBALT.In the left box, we maintain a Gaussian process as the surrogate model for the unknown objective and each constraint.The dotted curve shows the actual function, the red curve shows the predicted mean, and the shaded area denotes the confidence interval.In the right box, we first derive the acquisitions from each Gaussian process defined on a corresponding region of interests and define the general acquisition function by combining them all.Each time, the algorithm maintains the model, maximizes the general acquisition function to pick the candidate to evaluate, and then updates the model with the new observation.In later sections, we will elaborate on the filtered gray gap in the acquisition.</p>
<p>Figure 2 :
2
Figure2: Illustration of COBALT on a synthetic noise-free 1D example.The first two rows show the GP for the C, the superlevel-set S C , the region of interest XC and the corresponding acquisition function α C k ,t (x) as defined in equation 6.The following two rows show the GP for f , the region of interest Xf , and the corresponding acquisition function α f,t (x) defined in equation 5. We show that after identifying S C , we could define the threshold for ROI identification of f accordingly.The bottom row demonstrates that the general ROI X as defined in equation 4 is identified by taking the intersection ROI for f and C. The general acquisition function is defined as the maximum of the acquisition for f and C and is maximized on the X.The scaling and length scale of the Gaussian processes are learned by maximizing the likelihood.</p>
<p>Figure 3 :
3
Figure3: Each column corresponds to a certain threshold choice for the single constraint c(x) = |x + 0.7| 1/2 in the Rastrigin-1D-1C task.The search space contains a certain portion of the feasible region, denoted on each figure and title.The first row shows the distribution of 1000 samples from the noise-free distribution objective function, and the figures are differentiated with different feasible regions.The second row shows corresponding simple regret curves.We test each method with 15 independent trails and impose observation noises sampled from N (0, 0.1) not shown in the first row.</p>
<p>Figure4: The input dimensionality, the number of constraints, and the approximate portion of the feasible region in the whole search space for each task are denoted on the titles.We run the algorithms on each task for at least 15 independent trials.The curves show the average simple regret after standardization, while the shaded area denotes the 95% confidence interval through the optimization.</p>
<p>C. 2
2
REWARD CHOICE 2: OBJECTIVE FUNCTION AFTER THE FEASIBILITY REACHING CERTAIN THRESHOLD Instead of defining the reward as the product of the objective value and feasibility, we have to look into the probabilistic constraints and distinguish the epistemic uncertainty and aleatoric uncertainty.First, when assuming the observation on the constraints are noise-free, namely Y C k (x) = C k (x), we could simply use the indicator function µ k for each constraint to turn the feasibility function into an indicator function.</p>
<p>r</p>
<p>x∈X</p>
<p>R T (x) ≥ ϵ) ≤ 1 − δ inTanabe and Ishibuchi (2020) and focus on the objective of minimizing the weight of the car while meeting the European enhanced Vehicle-Safety Committee (EEVC) safety performance constraints.The seven variables indicate the thickness of different parts of the car.The feasible feasible region takes up approximately 13% of the whole search space.</p>
<p>Note that the minimization problem and the case C k (x) &lt; h k are captured in this formalism, as f (x) and C k (x) can both be negated.
Such criterion has been studied under the unconstrained setting(Zhang et al., 2023).
We briefly discuss the possible extension to decoupled setting, where the objective and constraints may be evaluated independently, of COBALT in Appendix B.
Here, we rely on the implementation contained in BoTorch's(Balandat et al., 2020) test function module.
D DATASETHere we offer a more detailed discussion over the construction of the six CBO tasks studied in section 6.D.1 SYNTHETIC TASKSWe study two synthetic CBO tasks constructed from conventional BO benchmark tasks.Here we rely on the implementation contained in BoTorch's(Balandat et al., 2020)test function module.Rastrigin-1D-1CThe Rastrigin function is a non-convex function used as a performance test problem for optimization algorithms.It was first proposed byRastrigin (1974)and used as a popular benchmark dataset(Pohlheim).It is constructed to be highly multimodal with local optima being regularly distributed to trap optimization algorithms.Concretely, we negate the 1D Rastrigin function and try to find its maximum: fThe range of x is [−5, 5], and we construct the constraint to be c(x) = |x + 0.7| 1/2 .When setting the threshold as √ 2, we essentially excludes the global optimum from the feasible area.The constraint enforces the optimization algorithm to explore feasibility rather than allowing algorithms to improve the reward by merely optimizing the objective.Then the feasible region takes up approximately 60% of the search space.This one-dimensional task is designed to illustrate the necessity of adaptively trade-off learning of constraints and optimization of the objective.We also vary the threshold to control the portion of the feasible region to study the robustness of COBALT.Figure3shows the distribution of the objective function and feasible regions.Ackley-5D-2CThe Ackley function is also a popular benchmark for optimization algorithms.Compared with the Rastrigin function, it is highly multimodal similarly, while the region near the center is growingly steep.Same as what is done for Rastrigin, we negate the 5D Ackley function and try to find its maximum:The search space is restricted to [−5, 3] 5 .We construct two constraints to enforce a feasible area approximately taking up 14% of the search space.The first constraint (∥x − 1∥ 2 − 5.5) 2 − 1 &gt; 0 constructs two feasible regions with one in the center and the other close to the boundary of the search space.The second constraint −∥x∥ 2 ∞ + 9 allows one hypercube feasible region in the center.D.2 REAL-WORLD TASKSWe study four real-world CBO tasks.The first three are extracted fromTanabe and Ishibuchi (2020), which offers a broad selection of real-world multi-objective multi-constraints optimization tasks.The fourth one is a 32-dimensional optimization task extracted from the UCI Machine Learning repository (mis, 2019).Vessel-4D-3CThe pressure vessel design problem aims at optimizing the total cost of a cylindrical pressure vessel.The four variables represent the thicknesses of the shell, the head of a pressure vessel, the inner radius, and the length of the cylindrical section.The problem is originally studied inKannan and Kramer (1994), and we follow the formulation in RE2-4-3 inTanabe and Ishibuchi (2020).The feasible regions take up approximately 78% of the whole search space.Spring-3D-6C The coil compression spring design problem aims to optimize the volume of spring steel wire which is used to manufacture the spring(Lampinen and Zelinka, 1999)under static loading.The three input variables denote the number of spring coils, the outside diameter of the spring, and the spring wire diameter respectively.The constraints incorporate the mechanical characteristics of the spring in real-world applications.We follow the formulation in RE2-3-5 inTanabe and Ishibuchi (2020).The feasible regions take up approximately 0.38% of the whole search space.Car-7D-8C The car cab design problem includes seven input variables and eight constraints.The problem is originally studied inDeb and Jain (2013).We follow the problem formulation in RE9-7-1
10.24432/C5QS4VWave Energy Converters. UCI Machine Learning Repository. 2019</p>
<p>Admmbo: Bayesian optimization with unknown constraints using admm. Setareh Ariafar, Jaume Coll-Font, Dana H Brooks, Jennifer G Dy, J. Mach. Learn. Res. 201232019</p>
<p>Botorch: A framework for efficient monte-carlo bayesian optimization. Maximilian Balandat, Brian Karrer, Daniel Jiang, Samuel Daulton, Ben Letham, Andrew G Wilson, Eytan Bakshy, Advances in neural information processing systems. 202033</p>
<p>Truncated variance reduction: A unified approach to bayesian optimization and level-set estimation. Ilija Bogunovic, Jonathan Scarlett, Andreas Krause, Volkan Cevher, Advances in neural information processing systems. 292016</p>
<p>An evolutionary many-objective optimization algorithm using reference-point-based nondominated sorting approach, part i: solving problems with box constraints. Kalyanmoy Deb, Himanshu Jain, IEEE transactions on evolutionary computation. 1842013</p>
<p>Scalable constrained bayesian optimization. David Eriksson, Matthias Poloczek, International Conference on Artificial Intelligence and Statistics. PMLR2021</p>
<p>Scalable global optimization via local bayesian optimization. David Eriksson, Michael Pearce, Jacob Gardner, Ryan D Turner, Matthias Poloczek, Advances in neural information processing systems. 201932</p>
<p>Frazier Peter, arXiv:1807.02811A tutorial on bayesian optimization. 2018arXiv preprint</p>
<p>Bayesian optimization with inequality constraints. Matt J Jacob R Gardner, Zhixiang Kusner, Eddie Xu, Kilian Q Weinberger, John P Cunningham, ICML. 20142014</p>
<p>Jasper Michael A Gelbart, Ryan P Snoek, Adams, arXiv:1403.5607Bayesian optimization with unknown constraints. 2014arXiv preprint</p>
<p>Active learning for level set estimation. Alkis Gotovos, Nathalie Casati, Gregory Hitz, Andreas Krause, Proceedings of the Twenty-Third international joint conference on Artificial Intelligence. the Twenty-Third international joint conference on Artificial Intelligence2013</p>
<p>Modeling an augmented lagrangian for blackbox constrained optimization. Genetha A Robert B Gramacy, Sébastien Gray, Le Digabel, Pritam Herbert Kh Lee, Garth Ranjan, Stefan M Wells, Wild, Technometrics. 5812016</p>
<p>Predictive entropy search for efficient global optimization of black-box functions. José Miguel Hernández-Lobato, Matthew W Hoffman, Zoubin Ghahramani, Advances in neural information processing systems. 201427</p>
<p>Predictive entropy search for bayesian optimization with unknown constraints. José Miguel Hernández-Lobato, Michael Gelbart, Matthew Hoffman, Ryan Adams, Zoubin Ghahramani, International conference on machine learning. PMLR2015</p>
<p>An augmented lagrange multiplier based method for mixed integer discrete continuous optimization and its applications to mechanical design. Steven N Bk Kannan, Kramer, 1994</p>
<p>Consistency of gaussian process regression in metric spaces. Peter Koepernik, Florian Pfaff, The Journal of Machine Learning Research. 2212021</p>
<p>Bridging offline and online experimentation: Constraint active search for deployed performance optimization. Junpei Komiyama, Gustavo Malkomes, Bolong Cheng, Michael Mccourt, Transactions on Machine Learning Research. 2022</p>
<p>Mixed integer-discrete-continuous optimization by differential evolution. Jouni Lampinen, Ivan Zelinka, Proceedings of the 5th international conference on soft computing. the 5th international conference on soft computingCiteseer1999</p>
<p>Constrained bayesian optimization with noisy experiments. Benjamin Letham, Brian Karrer, Guilherme Ottoni, Eytan Bakshy, Bayesian Analysis. 1422019</p>
<p>Risk-averse heteroscedastic bayesian optimization. Anastasia Makarova, Ilnura Usmanova, Ilija Bogunovic, Andreas Krause, Advances in Neural Information Processing Systems. 202134</p>
<p>Beyond the pareto efficient frontier: Constraint active search for multiobjective experimental design. Gustavo Malkomes, Bolong Cheng, Eric H Lee, Mike Mccourt, International Conference on Machine Learning. PMLR2021</p>
<p>An information-theoretic framework for unifying active learning problems. Phong Quoc, Bryan Kian Hsiang Nguyen, Patrick Low, Jaillet, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence2021</p>
<p>Constrained bayesian optimization with max-value entropy search. Iaroslav Valerio Perrone, Rodolphe Shcherbatyi, Cedric Jenatton, Matthias Archambeau, Seeger, arXiv:1910.070032019arXiv preprint</p>
<p>Bayesian optimization under mixed constraints with a slack-variable augmented lagrangian. Victor Picheny, Robert B Gramacy, Stefan Wild, Sebastien Le Digabel, Advances in neural information processing systems. 292016</p>
<p>Geatbx examples examples of objective functions. Pohlheim, 2006</p>
<p>C E Rasmussen, C K I Williams, Gaussian Processes for Machine Learning. Leonard Andreevič Rastrigin. Systems of extremal control. Nauka2006. 1974</p>
<p>Global versus local search in constrained optimization of computer models. Lecture notes-monograph series. Matthias Schonlau, William J Welch, Donald R Jones, 1998</p>
<p>Gaussian process optimization in the bandit setting: No regret and experimental design. Niranjan Srinivas, Andreas Krause, Matthias Sham M Kakade, Seeger, arXiv:0912.39952009arXiv preprint</p>
<p>Safe exploration for optimization with gaussian processes. Yanan Sui, Alkis Gotovos, Joel Burdick, Andreas Krause, International conference on machine learning. PMLR2015</p>
<p>Sequential and parallel constrained max-value entropy search via information lower bound. Shion Takeno, Tomoyuki Tamura, Kazuki Shitara, Masayuki Karasuyama, International Conference on Machine Learning. PMLR2022</p>
<p>An easy-to-use real-world multi-objective optimization problem suite. Ryoji Tanabe, Hisao Ishibuchi, Applied Soft Computing. 891060782020</p>
<p>Max-value entropy search for efficient bayesian optimization. Zi Wang, Stefanie Jegelka, International Conference on Machine Learning. PMLR2017</p>
<p>Learning regions of interest for bayesian optimization with adaptive level-set estimation. Fengxue Zhang, Jialin Song, James Bowden, Alexander Ladd, Yisong Yue, Thomas A Desautels, Yuxin Chen, 2023</p>            </div>
        </div>

    </div>
</body>
</html>