<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9037 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9037</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9037</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-159.html">extraction-schema-159</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <p><strong>Paper ID:</strong> paper-276928016</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2503.07627v1.pdf" target="_blank">Psychological Counseling Ability of Large Language Models</a></p>
                <p><strong>Paper Abstract:</strong> With the development of science and the continuous progress of artificial intelligence technology, Large Language Models (LLMs) have begun to be widely utilized across various fields. However, in the field of psychological counseling, the ability of LLMs have not been systematically assessed. In this study, we assessed the psychological counseling ability of mainstream LLMs using 1096 psychological counseling skill questions which were selected from the Chinese National Counselor Level 3 Examination, including Knowledge-based, Analytical-based, and Application-based question types. The analysis showed that the correctness rates of the LLMs for Chinese questions, in descending order, were GLM-3 (46.5%), GPT-4 (46.1%), Gemini (45.0%), ERNIE-3.5 (45.7%) and GPT-3.5 (32.9%). The correctness rates of the LLMs for English questions, in descending order, were ERNIE-3.5 (43.9%), GPT-4 (40.6%), Gemini (36.6%), GLM-3 (29.9%) and GPT-3.5 (29.5%). A chi-square test indicated significant differences in the LLMs' performance on Chinese and English questions. Furthermore, we subsequently utilized the Counselor's Guidebook (Level 3) as a reference for ERNIE-3.5, resulting in a new correctness rate of 59.6%, a 13.8% improvement over its initial rate of 45.8%. In conclusion, the study assessed the psychological counseling ability of LLMs for the first time, which may provide insights for future enhancement and improvement of psychological counseling ability of LLMs.</p>
                <p><strong>Cost:</strong> 0.017</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9037.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9037.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A mainstream large language model evaluated in this study on a standardized Chinese counseling-skill exam; not specifically fine-tuned for psychological counseling in this work.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Described in the paper as a mainstream LLM trained on English and/or Chinese data; no architecture or training-data details provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>Chinese National Counselor Level 3 Exam — skill operation assessment (skill choice questions)</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>1096 multiple-choice counseling skill questions (single- and multi-choice) originally from the Chinese National Counselor Level 3 Exam, categorized into Knowledge-based (192), Analytical-based (455) and Application-based (449) items; administered in Chinese and an English translation.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Chinese accuracy 46.1% (505/1096 subset as reported for Chinese questions); English accuracy 40.6% (0.406).</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>Below professional passing threshold (exam pass defined as ≥60%); paper reports GPT-4 among the better-performing LLMs but still substantially below a professional pass standard and below unspecified human baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>Questions presented in two language versions (Chinese and English). Prompts instructed model to answer choice questions only (e.g., 'answer in form 1: B') without explanation. No additional fine-tuning applied for GPT-4 in the main comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>No direct human-subject baseline scores provided for this exam in the paper; translations may introduce bias; models were not domain-specialized for counseling which may reduce knowledge-based accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Psychological Counseling Ability of Large Language Models', 'publication_date_yy_mm': '2025-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9037.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9037.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A mainstream LLM evaluated on the counselor exam dataset; performed worst of the tested models on Chinese items in this study.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Described generically as a mainstream LLM trained on English and/or Chinese data; no architecture, training-data, or parameter-size details are provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>Chinese National Counselor Level 3 Exam — skill operation assessment (skill choice questions)</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Same 1096 multiple-choice counseling skill questions in three categories (Knowledge / Analytical / Application) tested in Chinese and English translations.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Chinese accuracy 32.9%; English accuracy ~29.5% (0.295). For English, performance on Knowledge-based questions was significantly lower than on Analytical-based questions for GPT-3.5.</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>Substantially below other tested LLMs on Chinese items and below professional pass threshold (60%); below implied human/professional competence though no human numbers provided.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>Same prompt templates and bilingual presentation as other models; simple direct Q&A prompts without chain-of-thought or explanation allowed.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>Paper notes GPT-3.5's poorer performance may reflect model/version differences and language-optimisation differences; no human baseline provided; results may be affected by translation quality to English.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Psychological Counseling Ability of Large Language Models', 'publication_date_yy_mm': '2025-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9037.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9037.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GLM-3</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GLM-3</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A mainstream LLM included in this study's comparison on counseling exam items; among top performers on the Chinese version.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GLM-3</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Reported as a mainstream LLM evaluated in both Chinese and English; no internal architecture or parameter-count specifics given in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>Chinese National Counselor Level 3 Exam — skill operation assessment (skill choice questions)</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>1096 counseling skill multiple-choice items divided into Knowledge-based (192), Analytical-based (455), and Application-based (449); administered in Chinese and translated English versions.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Chinese accuracy 46.5%; English accuracy 29.9% (0.299).</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>Among top performers on Chinese items (comparable to GPT-4 and ERNIE-3.5) but well below the 60% passing threshold and no human baseline reported.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>Standardized prompt instructions in Chinese/English asking the model to output the choice only; no specialized fine-tuning applied for counseling domain.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>Language differences (models optimized for Chinese vs English) likely affect cross-language performance; lack of human baseline and single-shot/simplified prompting constrain interpretability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Psychological Counseling Ability of Large Language Models', 'publication_date_yy_mm': '2025-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9037.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9037.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Gemini</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Gemini</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A mainstream LLM evaluated on the counseling exam dataset; performance intermediate among models for Chinese and English versions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Gemini</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Listed as one of the mainstream LLMs evaluated in this study; the paper does not provide architecture, training data, or size.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>Chinese National Counselor Level 3 Exam — skill operation assessment (skill choice questions)</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>1096 multiple-choice counseling skill questions split into Knowledge-based, Analytical-based, and Application-based categories, tested in Chinese and English.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Chinese accuracy 45.0%; English accuracy 36.6% (0.366).</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>Performance below the professional pass threshold and similar to other top LLMs on Chinese items, but below unspecified human baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>Administered with the same concise instruction prompts (answer choices only); no domain-specific retrieval or guidebook provided for Gemini in the main experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>As with other models, translation effects, lack of domain specialization, and simple prompting approach limit conclusions about real-world counseling competence.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Psychological Counseling Ability of Large Language Models', 'publication_date_yy_mm': '2025-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9037.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e9037.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ERNIE-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ERNIE-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A mainstream LLM evaluated on the counselor exam; additionally tested with Retrieval-Augmented Generation (RAG) using a Counseling Guidebook, which notably improved performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ERNIE-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Reported as a mainstream LLM evaluated in Chinese and English; the paper notes it was provided with a domain reference document (Psychological Counselor's Guidebook) in an augmented condition.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>Chinese National Counselor Level 3 Exam — skill operation assessment (skill choice questions)</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>1096 counseling skill multiple-choice questions (Knowledge/Analytical/Application) presented in Chinese and English translations.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Baseline Chinese accuracy 45.8%; baseline English accuracy 43.9% (0.439). With Retrieval-Augmented Generation (provided the Psychological Counselor's Guidebook), Chinese accuracy improved to 59.6% (an absolute increase of 13.8 percentage points). Per-type post-RAG accuracies: Knowledge-based 59.4%, Analytical-based 60.9%, Application-based 58.4%.</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>Baseline ERNIE-3.5 was below the 60% pass threshold; after RAG it approached but did not consistently exceed the 60% pass threshold (overall 59.6%). No direct human baseline scores provided; authors suggest RAG substantially mitigates lack of domain knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>Main experiment: concise 'answer choice only' prompts in Chinese/English. RAG experiment: Psychological Counselor's Guidebook (Ji, 2016) provided as a reference document for ERNIE-3.5 before answering Chinese questions; statistical comparisons used chi-square tests.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>No human participant performance on this specific exam reported; improvement with RAG indicates domain knowledge gap rather than general reasoning failure but RAG used only for ERNIE-3.5; potential overfit to exam-style material and inability to engage in interactive counseling not assessed.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Psychological Counseling Ability of Large Language Models', 'publication_date_yy_mm': '2025-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9037.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e9037.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ERNIE-3.5 (RAG)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ERNIE-3.5 with Retrieval-Augmented Generation (Psychological Counselor's Guidebook)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>ERNIE-3.5 augmented with an external counseling guidebook (RAG) showed a large, statistically significant accuracy improvement on the Chinese counseling exam questions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ERNIE-3.5 (RAG)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>ERNIE-3.5 provided with the Psychological Counselor's Guidebook (Ji, 2016) as retrieval/reference material prior to answering; the paper frames this as RAG-style augmentation.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>Chinese National Counselor Level 3 Exam — skill operation assessment (skill choice questions)</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Same 1096 counseling skill multiple-choice items; RAG experiment applied to Chinese-version questions.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Chinese accuracy increased from 45.8% (pre-RAG) to 59.6% (post-RAG), an absolute improvement of 13.8 percentage points; per-type improvements were statistically significant.</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>Post-RAG performance nearly reached the exam pass threshold (60%) but did not clearly exceed it; no human baseline scores reported for a formal comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>RAG implemented by providing the Psychological Counselor's Guidebook as a reference document to ERNIE-3.5 before answering Chinese questions; significance tested with chi-square tests comparing pre- and post-RAG correctness rates by question type.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>RAG experiment only applied to ERNIE-3.5; while accuracy improved substantially, the study does not evaluate whether RAG-enabled outputs would translate to safe/effective real-world counseling; no human comparison scores provided; possible exam-format overfitting.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Psychological Counseling Ability of Large Language Models', 'publication_date_yy_mm': '2025-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9037.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e9037.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Kosinski 2023 (Theory of Mind)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Theory of mind might have spontaneously emerged in large language models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cited work claiming that LLMs show emergent theory-of-mind-like abilities; cited here as background rather than evaluated directly in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Theory of mind might have spontaneously emerged in large language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Mentioned as evidence that LLMs display properties similar to human cognitive abilities (theory of mind).</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>This paper only cites Kosinski (2023) in the introduction; no experimental details or results from that study are presented here.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Psychological Counseling Ability of Large Language Models', 'publication_date_yy_mm': '2025-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9037.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e9037.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Wang et al. 2023 (Emotional intelligence)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Emotional intelligence of large language models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cited paper asserting that LLMs display properties of emotional intelligence; referenced as related work in the introduction.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Emotional intelligence of large language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Referenced as evidence that LLMs can show emotional intelligence capabilities.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>Only cited; no performance details extracted in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Psychological Counseling Ability of Large Language Models', 'publication_date_yy_mm': '2025-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9037.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e9037.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Elyoseph et al. 2024 (Emotion recognition)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Capacity of generative AI to interpret human emotions from visual and textual data: pilot evaluation study</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cited pilot evaluation that assessed LLM/AI capacity for emotion recognition from text and visuals; mentioned as background evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Capacity of generative AI to interpret human emotions from visual and textual data: pilot evaluation study</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Mentioned as an example of LLMs/AI being evaluated on emotion recognition tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>Only cited in the introduction; no results or metrics from that study are reproduced here.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Psychological Counseling Ability of Large Language Models', 'publication_date_yy_mm': '2025-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9037.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e9037.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Suri et al. 2024 (Heuristic decision-making)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Do large language models show decision heuristics similar to humans? A case study using GPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cited case study that examined whether LLMs exhibit human-like decision heuristics, explicitly naming GPT-3.5.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Do large language models show decision heuristics similar to humans? A case study using GPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Mentioned as an example of cognitive-psychology-style evaluation (heuristics/decision-making) applied to an LLM (GPT-3.5).</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>Cited as related work; this paper does not present Suri et al.'s experimental results.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Psychological Counseling Ability of Large Language Models', 'publication_date_yy_mm': '2025-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9037.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e9037.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hagendorff et al. 2023 (Cognitive biases)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Thinking fast and slow in large language models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cited work addressing cognitive biases and heuristic decision-making in LLMs; used in introduction to motivate evaluation of cognitive-like functions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Thinking fast and slow in large language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Referenced as evidence that LLMs show cognitive-bias-like behavior in decision-making tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>Only cited for context; no experimental detail from that study is included here.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Psychological Counseling Ability of Large Language Models', 'publication_date_yy_mm': '2025-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9037.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e9037.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Peters & Matz 2024 (Trait inference)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Large language models can infer psychological dispositions of social media users</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cited paper indicating LLMs can infer psychological dispositions from text; referenced as background evidence of LLM psychological inferences.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Large language models can infer psychological dispositions of social media users</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Mentioned as an example of LLMs being evaluated on inferring psychological traits from text data.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>Only cited as related work; no details reproduced in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Psychological Counseling Ability of Large Language Models', 'publication_date_yy_mm': '2025-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9037.12">
                <h3 class="extraction-instance">Extracted Data Instance 12 (e9037.12)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hickman et al. 2024 (Quantitative & verbal ability)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>The performance of large language models on quantitative and verbal ability tests: Initial evidence and implications for unproctored high-stakes testing</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cited work that evaluated LLMs on quantitative and verbal ability tests, relevant to cognitive testing of LLMs; mentioned in the introduction.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The performance of large language models on quantitative and verbal ability tests: Initial evidence and implications for unproctored high-stakes testing</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Referenced as evidence of LLM evaluation on quantitative and verbal cognitive ability tests.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>Cited only; the present paper does not extract quantitative results from Hickman et al.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Psychological Counseling Ability of Large Language Models', 'publication_date_yy_mm': '2025-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9037.13">
                <h3 class="extraction-instance">Extracted Data Instance 13 (e9037.13)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Digutsch & Kosinski 2023 (Semantic priming)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Overlap in meaning is a stronger predictor of semantic activation in GPT-3 than in humans</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cited study investigating semantic priming/activation in GPT-3 compared to humans; mentioned as background evidence of cognitive-like behavior in LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Overlap in meaning is a stronger predictor of semantic activation in GPT-3 than in humans</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Referenced as an example of LLM cognitive/semantic experiments (semantic priming) compared to humans.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>Only cited for context; this paper does not reproduce the results.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Psychological Counseling Ability of Large Language Models', 'publication_date_yy_mm': '2025-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Theory of mind might have spontaneously emerged in large language models <em>(Rating: 2)</em></li>
                <li>Do large language models show decision heuristics similar to humans? A case study using GPT-3.5 <em>(Rating: 2)</em></li>
                <li>Thinking fast and slow in large language models <em>(Rating: 2)</em></li>
                <li>Overlap in meaning is a stronger predictor of semantic activation in GPT-3 than in humans <em>(Rating: 2)</em></li>
                <li>The performance of large language models on quantitative and verbal ability tests: Initial evidence and implications for unproctored high-stakes testing <em>(Rating: 2)</em></li>
                <li>Capacity of generative AI to interpret human emotions from visual and textual data: pilot evaluation study <em>(Rating: 2)</em></li>
                <li>Emotional intelligence of large language models <em>(Rating: 2)</em></li>
                <li>Large language models can infer psychological dispositions of social media users <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9037",
    "paper_id": "paper-276928016",
    "extraction_schema_id": "extraction-schema-159",
    "extracted_data": [
        {
            "name_short": "GPT-4",
            "name_full": "GPT-4",
            "brief_description": "A mainstream large language model evaluated in this study on a standardized Chinese counseling-skill exam; not specifically fine-tuned for psychological counseling in this work.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_description": "Described in the paper as a mainstream LLM trained on English and/or Chinese data; no architecture or training-data details provided in this paper.",
            "model_size": null,
            "test_battery_name": "Chinese National Counselor Level 3 Exam — skill operation assessment (skill choice questions)",
            "test_description": "1096 multiple-choice counseling skill questions (single- and multi-choice) originally from the Chinese National Counselor Level 3 Exam, categorized into Knowledge-based (192), Analytical-based (455) and Application-based (449) items; administered in Chinese and an English translation.",
            "llm_performance": "Chinese accuracy 46.1% (505/1096 subset as reported for Chinese questions); English accuracy 40.6% (0.406).",
            "human_baseline_performance": null,
            "performance_comparison": "Below professional passing threshold (exam pass defined as ≥60%); paper reports GPT-4 among the better-performing LLMs but still substantially below a professional pass standard and below unspecified human baselines.",
            "experimental_details": "Questions presented in two language versions (Chinese and English). Prompts instructed model to answer choice questions only (e.g., 'answer in form 1: B') without explanation. No additional fine-tuning applied for GPT-4 in the main comparison.",
            "limitations_or_caveats": "No direct human-subject baseline scores provided for this exam in the paper; translations may introduce bias; models were not domain-specialized for counseling which may reduce knowledge-based accuracy.",
            "uuid": "e9037.0",
            "source_info": {
                "paper_title": "Psychological Counseling Ability of Large Language Models",
                "publication_date_yy_mm": "2025-03"
            }
        },
        {
            "name_short": "GPT-3.5",
            "name_full": "GPT-3.5",
            "brief_description": "A mainstream LLM evaluated on the counselor exam dataset; performed worst of the tested models on Chinese items in this study.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5",
            "model_description": "Described generically as a mainstream LLM trained on English and/or Chinese data; no architecture, training-data, or parameter-size details are provided in this paper.",
            "model_size": null,
            "test_battery_name": "Chinese National Counselor Level 3 Exam — skill operation assessment (skill choice questions)",
            "test_description": "Same 1096 multiple-choice counseling skill questions in three categories (Knowledge / Analytical / Application) tested in Chinese and English translations.",
            "llm_performance": "Chinese accuracy 32.9%; English accuracy ~29.5% (0.295). For English, performance on Knowledge-based questions was significantly lower than on Analytical-based questions for GPT-3.5.",
            "human_baseline_performance": null,
            "performance_comparison": "Substantially below other tested LLMs on Chinese items and below professional pass threshold (60%); below implied human/professional competence though no human numbers provided.",
            "experimental_details": "Same prompt templates and bilingual presentation as other models; simple direct Q&A prompts without chain-of-thought or explanation allowed.",
            "limitations_or_caveats": "Paper notes GPT-3.5's poorer performance may reflect model/version differences and language-optimisation differences; no human baseline provided; results may be affected by translation quality to English.",
            "uuid": "e9037.1",
            "source_info": {
                "paper_title": "Psychological Counseling Ability of Large Language Models",
                "publication_date_yy_mm": "2025-03"
            }
        },
        {
            "name_short": "GLM-3",
            "name_full": "GLM-3",
            "brief_description": "A mainstream LLM included in this study's comparison on counseling exam items; among top performers on the Chinese version.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GLM-3",
            "model_description": "Reported as a mainstream LLM evaluated in both Chinese and English; no internal architecture or parameter-count specifics given in this paper.",
            "model_size": null,
            "test_battery_name": "Chinese National Counselor Level 3 Exam — skill operation assessment (skill choice questions)",
            "test_description": "1096 counseling skill multiple-choice items divided into Knowledge-based (192), Analytical-based (455), and Application-based (449); administered in Chinese and translated English versions.",
            "llm_performance": "Chinese accuracy 46.5%; English accuracy 29.9% (0.299).",
            "human_baseline_performance": null,
            "performance_comparison": "Among top performers on Chinese items (comparable to GPT-4 and ERNIE-3.5) but well below the 60% passing threshold and no human baseline reported.",
            "experimental_details": "Standardized prompt instructions in Chinese/English asking the model to output the choice only; no specialized fine-tuning applied for counseling domain.",
            "limitations_or_caveats": "Language differences (models optimized for Chinese vs English) likely affect cross-language performance; lack of human baseline and single-shot/simplified prompting constrain interpretability.",
            "uuid": "e9037.2",
            "source_info": {
                "paper_title": "Psychological Counseling Ability of Large Language Models",
                "publication_date_yy_mm": "2025-03"
            }
        },
        {
            "name_short": "Gemini",
            "name_full": "Gemini",
            "brief_description": "A mainstream LLM evaluated on the counseling exam dataset; performance intermediate among models for Chinese and English versions.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Gemini",
            "model_description": "Listed as one of the mainstream LLMs evaluated in this study; the paper does not provide architecture, training data, or size.",
            "model_size": null,
            "test_battery_name": "Chinese National Counselor Level 3 Exam — skill operation assessment (skill choice questions)",
            "test_description": "1096 multiple-choice counseling skill questions split into Knowledge-based, Analytical-based, and Application-based categories, tested in Chinese and English.",
            "llm_performance": "Chinese accuracy 45.0%; English accuracy 36.6% (0.366).",
            "human_baseline_performance": null,
            "performance_comparison": "Performance below the professional pass threshold and similar to other top LLMs on Chinese items, but below unspecified human baseline.",
            "experimental_details": "Administered with the same concise instruction prompts (answer choices only); no domain-specific retrieval or guidebook provided for Gemini in the main experiments.",
            "limitations_or_caveats": "As with other models, translation effects, lack of domain specialization, and simple prompting approach limit conclusions about real-world counseling competence.",
            "uuid": "e9037.3",
            "source_info": {
                "paper_title": "Psychological Counseling Ability of Large Language Models",
                "publication_date_yy_mm": "2025-03"
            }
        },
        {
            "name_short": "ERNIE-3.5",
            "name_full": "ERNIE-3.5",
            "brief_description": "A mainstream LLM evaluated on the counselor exam; additionally tested with Retrieval-Augmented Generation (RAG) using a Counseling Guidebook, which notably improved performance.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ERNIE-3.5",
            "model_description": "Reported as a mainstream LLM evaluated in Chinese and English; the paper notes it was provided with a domain reference document (Psychological Counselor's Guidebook) in an augmented condition.",
            "model_size": null,
            "test_battery_name": "Chinese National Counselor Level 3 Exam — skill operation assessment (skill choice questions)",
            "test_description": "1096 counseling skill multiple-choice questions (Knowledge/Analytical/Application) presented in Chinese and English translations.",
            "llm_performance": "Baseline Chinese accuracy 45.8%; baseline English accuracy 43.9% (0.439). With Retrieval-Augmented Generation (provided the Psychological Counselor's Guidebook), Chinese accuracy improved to 59.6% (an absolute increase of 13.8 percentage points). Per-type post-RAG accuracies: Knowledge-based 59.4%, Analytical-based 60.9%, Application-based 58.4%.",
            "human_baseline_performance": null,
            "performance_comparison": "Baseline ERNIE-3.5 was below the 60% pass threshold; after RAG it approached but did not consistently exceed the 60% pass threshold (overall 59.6%). No direct human baseline scores provided; authors suggest RAG substantially mitigates lack of domain knowledge.",
            "experimental_details": "Main experiment: concise 'answer choice only' prompts in Chinese/English. RAG experiment: Psychological Counselor's Guidebook (Ji, 2016) provided as a reference document for ERNIE-3.5 before answering Chinese questions; statistical comparisons used chi-square tests.",
            "limitations_or_caveats": "No human participant performance on this specific exam reported; improvement with RAG indicates domain knowledge gap rather than general reasoning failure but RAG used only for ERNIE-3.5; potential overfit to exam-style material and inability to engage in interactive counseling not assessed.",
            "uuid": "e9037.4",
            "source_info": {
                "paper_title": "Psychological Counseling Ability of Large Language Models",
                "publication_date_yy_mm": "2025-03"
            }
        },
        {
            "name_short": "ERNIE-3.5 (RAG)",
            "name_full": "ERNIE-3.5 with Retrieval-Augmented Generation (Psychological Counselor's Guidebook)",
            "brief_description": "ERNIE-3.5 augmented with an external counseling guidebook (RAG) showed a large, statistically significant accuracy improvement on the Chinese counseling exam questions.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "ERNIE-3.5 (RAG)",
            "model_description": "ERNIE-3.5 provided with the Psychological Counselor's Guidebook (Ji, 2016) as retrieval/reference material prior to answering; the paper frames this as RAG-style augmentation.",
            "model_size": null,
            "test_battery_name": "Chinese National Counselor Level 3 Exam — skill operation assessment (skill choice questions)",
            "test_description": "Same 1096 counseling skill multiple-choice items; RAG experiment applied to Chinese-version questions.",
            "llm_performance": "Chinese accuracy increased from 45.8% (pre-RAG) to 59.6% (post-RAG), an absolute improvement of 13.8 percentage points; per-type improvements were statistically significant.",
            "human_baseline_performance": null,
            "performance_comparison": "Post-RAG performance nearly reached the exam pass threshold (60%) but did not clearly exceed it; no human baseline scores reported for a formal comparison.",
            "experimental_details": "RAG implemented by providing the Psychological Counselor's Guidebook as a reference document to ERNIE-3.5 before answering Chinese questions; significance tested with chi-square tests comparing pre- and post-RAG correctness rates by question type.",
            "limitations_or_caveats": "RAG experiment only applied to ERNIE-3.5; while accuracy improved substantially, the study does not evaluate whether RAG-enabled outputs would translate to safe/effective real-world counseling; no human comparison scores provided; possible exam-format overfitting.",
            "uuid": "e9037.5",
            "source_info": {
                "paper_title": "Psychological Counseling Ability of Large Language Models",
                "publication_date_yy_mm": "2025-03"
            }
        },
        {
            "name_short": "Kosinski 2023 (Theory of Mind)",
            "name_full": "Theory of mind might have spontaneously emerged in large language models",
            "brief_description": "Cited work claiming that LLMs show emergent theory-of-mind-like abilities; cited here as background rather than evaluated directly in this paper.",
            "citation_title": "Theory of mind might have spontaneously emerged in large language models",
            "mention_or_use": "mention",
            "model_name": null,
            "model_description": null,
            "model_size": null,
            "test_battery_name": null,
            "test_description": "Mentioned as evidence that LLMs display properties similar to human cognitive abilities (theory of mind).",
            "llm_performance": null,
            "human_baseline_performance": null,
            "performance_comparison": null,
            "experimental_details": null,
            "limitations_or_caveats": "This paper only cites Kosinski (2023) in the introduction; no experimental details or results from that study are presented here.",
            "uuid": "e9037.6",
            "source_info": {
                "paper_title": "Psychological Counseling Ability of Large Language Models",
                "publication_date_yy_mm": "2025-03"
            }
        },
        {
            "name_short": "Wang et al. 2023 (Emotional intelligence)",
            "name_full": "Emotional intelligence of large language models",
            "brief_description": "Cited paper asserting that LLMs display properties of emotional intelligence; referenced as related work in the introduction.",
            "citation_title": "Emotional intelligence of large language models",
            "mention_or_use": "mention",
            "model_name": null,
            "model_description": null,
            "model_size": null,
            "test_battery_name": null,
            "test_description": "Referenced as evidence that LLMs can show emotional intelligence capabilities.",
            "llm_performance": null,
            "human_baseline_performance": null,
            "performance_comparison": null,
            "experimental_details": null,
            "limitations_or_caveats": "Only cited; no performance details extracted in this paper.",
            "uuid": "e9037.7",
            "source_info": {
                "paper_title": "Psychological Counseling Ability of Large Language Models",
                "publication_date_yy_mm": "2025-03"
            }
        },
        {
            "name_short": "Elyoseph et al. 2024 (Emotion recognition)",
            "name_full": "Capacity of generative AI to interpret human emotions from visual and textual data: pilot evaluation study",
            "brief_description": "Cited pilot evaluation that assessed LLM/AI capacity for emotion recognition from text and visuals; mentioned as background evidence.",
            "citation_title": "Capacity of generative AI to interpret human emotions from visual and textual data: pilot evaluation study",
            "mention_or_use": "mention",
            "model_name": null,
            "model_description": null,
            "model_size": null,
            "test_battery_name": null,
            "test_description": "Mentioned as an example of LLMs/AI being evaluated on emotion recognition tasks.",
            "llm_performance": null,
            "human_baseline_performance": null,
            "performance_comparison": null,
            "experimental_details": null,
            "limitations_or_caveats": "Only cited in the introduction; no results or metrics from that study are reproduced here.",
            "uuid": "e9037.8",
            "source_info": {
                "paper_title": "Psychological Counseling Ability of Large Language Models",
                "publication_date_yy_mm": "2025-03"
            }
        },
        {
            "name_short": "Suri et al. 2024 (Heuristic decision-making)",
            "name_full": "Do large language models show decision heuristics similar to humans? A case study using GPT-3.5",
            "brief_description": "Cited case study that examined whether LLMs exhibit human-like decision heuristics, explicitly naming GPT-3.5.",
            "citation_title": "Do large language models show decision heuristics similar to humans? A case study using GPT-3.5",
            "mention_or_use": "mention",
            "model_name": "GPT-3.5",
            "model_description": null,
            "model_size": null,
            "test_battery_name": null,
            "test_description": "Mentioned as an example of cognitive-psychology-style evaluation (heuristics/decision-making) applied to an LLM (GPT-3.5).",
            "llm_performance": null,
            "human_baseline_performance": null,
            "performance_comparison": null,
            "experimental_details": null,
            "limitations_or_caveats": "Cited as related work; this paper does not present Suri et al.'s experimental results.",
            "uuid": "e9037.9",
            "source_info": {
                "paper_title": "Psychological Counseling Ability of Large Language Models",
                "publication_date_yy_mm": "2025-03"
            }
        },
        {
            "name_short": "Hagendorff et al. 2023 (Cognitive biases)",
            "name_full": "Thinking fast and slow in large language models",
            "brief_description": "Cited work addressing cognitive biases and heuristic decision-making in LLMs; used in introduction to motivate evaluation of cognitive-like functions.",
            "citation_title": "Thinking fast and slow in large language models",
            "mention_or_use": "mention",
            "model_name": null,
            "model_description": null,
            "model_size": null,
            "test_battery_name": null,
            "test_description": "Referenced as evidence that LLMs show cognitive-bias-like behavior in decision-making tasks.",
            "llm_performance": null,
            "human_baseline_performance": null,
            "performance_comparison": null,
            "experimental_details": null,
            "limitations_or_caveats": "Only cited for context; no experimental detail from that study is included here.",
            "uuid": "e9037.10",
            "source_info": {
                "paper_title": "Psychological Counseling Ability of Large Language Models",
                "publication_date_yy_mm": "2025-03"
            }
        },
        {
            "name_short": "Peters & Matz 2024 (Trait inference)",
            "name_full": "Large language models can infer psychological dispositions of social media users",
            "brief_description": "Cited paper indicating LLMs can infer psychological dispositions from text; referenced as background evidence of LLM psychological inferences.",
            "citation_title": "Large language models can infer psychological dispositions of social media users",
            "mention_or_use": "mention",
            "model_name": null,
            "model_description": null,
            "model_size": null,
            "test_battery_name": null,
            "test_description": "Mentioned as an example of LLMs being evaluated on inferring psychological traits from text data.",
            "llm_performance": null,
            "human_baseline_performance": null,
            "performance_comparison": null,
            "experimental_details": null,
            "limitations_or_caveats": "Only cited as related work; no details reproduced in this paper.",
            "uuid": "e9037.11",
            "source_info": {
                "paper_title": "Psychological Counseling Ability of Large Language Models",
                "publication_date_yy_mm": "2025-03"
            }
        },
        {
            "name_short": "Hickman et al. 2024 (Quantitative & verbal ability)",
            "name_full": "The performance of large language models on quantitative and verbal ability tests: Initial evidence and implications for unproctored high-stakes testing",
            "brief_description": "Cited work that evaluated LLMs on quantitative and verbal ability tests, relevant to cognitive testing of LLMs; mentioned in the introduction.",
            "citation_title": "The performance of large language models on quantitative and verbal ability tests: Initial evidence and implications for unproctored high-stakes testing",
            "mention_or_use": "mention",
            "model_name": null,
            "model_description": null,
            "model_size": null,
            "test_battery_name": null,
            "test_description": "Referenced as evidence of LLM evaluation on quantitative and verbal cognitive ability tests.",
            "llm_performance": null,
            "human_baseline_performance": null,
            "performance_comparison": null,
            "experimental_details": null,
            "limitations_or_caveats": "Cited only; the present paper does not extract quantitative results from Hickman et al.",
            "uuid": "e9037.12",
            "source_info": {
                "paper_title": "Psychological Counseling Ability of Large Language Models",
                "publication_date_yy_mm": "2025-03"
            }
        },
        {
            "name_short": "Digutsch & Kosinski 2023 (Semantic priming)",
            "name_full": "Overlap in meaning is a stronger predictor of semantic activation in GPT-3 than in humans",
            "brief_description": "Cited study investigating semantic priming/activation in GPT-3 compared to humans; mentioned as background evidence of cognitive-like behavior in LLMs.",
            "citation_title": "Overlap in meaning is a stronger predictor of semantic activation in GPT-3 than in humans",
            "mention_or_use": "mention",
            "model_name": "GPT-3",
            "model_description": null,
            "model_size": null,
            "test_battery_name": null,
            "test_description": "Referenced as an example of LLM cognitive/semantic experiments (semantic priming) compared to humans.",
            "llm_performance": null,
            "human_baseline_performance": null,
            "performance_comparison": null,
            "experimental_details": null,
            "limitations_or_caveats": "Only cited for context; this paper does not reproduce the results.",
            "uuid": "e9037.13",
            "source_info": {
                "paper_title": "Psychological Counseling Ability of Large Language Models",
                "publication_date_yy_mm": "2025-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Theory of mind might have spontaneously emerged in large language models",
            "rating": 2,
            "sanitized_title": "theory_of_mind_might_have_spontaneously_emerged_in_large_language_models"
        },
        {
            "paper_title": "Do large language models show decision heuristics similar to humans? A case study using GPT-3.5",
            "rating": 2,
            "sanitized_title": "do_large_language_models_show_decision_heuristics_similar_to_humans_a_case_study_using_gpt35"
        },
        {
            "paper_title": "Thinking fast and slow in large language models",
            "rating": 2,
            "sanitized_title": "thinking_fast_and_slow_in_large_language_models"
        },
        {
            "paper_title": "Overlap in meaning is a stronger predictor of semantic activation in GPT-3 than in humans",
            "rating": 2,
            "sanitized_title": "overlap_in_meaning_is_a_stronger_predictor_of_semantic_activation_in_gpt3_than_in_humans"
        },
        {
            "paper_title": "The performance of large language models on quantitative and verbal ability tests: Initial evidence and implications for unproctored high-stakes testing",
            "rating": 2,
            "sanitized_title": "the_performance_of_large_language_models_on_quantitative_and_verbal_ability_tests_initial_evidence_and_implications_for_unproctored_highstakes_testing"
        },
        {
            "paper_title": "Capacity of generative AI to interpret human emotions from visual and textual data: pilot evaluation study",
            "rating": 2,
            "sanitized_title": "capacity_of_generative_ai_to_interpret_human_emotions_from_visual_and_textual_data_pilot_evaluation_study"
        },
        {
            "paper_title": "Emotional intelligence of large language models",
            "rating": 2,
            "sanitized_title": "emotional_intelligence_of_large_language_models"
        },
        {
            "paper_title": "Large language models can infer psychological dispositions of social media users",
            "rating": 2,
            "sanitized_title": "large_language_models_can_infer_psychological_dispositions_of_social_media_users"
        }
    ],
    "cost": 0.01695675,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Psychological Counseling Ability of Large Language Models</p>
<p>Fangyu Peng 
Ministry of Education Center for Studies of Psychological Application
Philosophy and Social Science Laboratory of Reading and Development in Children and Adolescents
South China Normal University)
South China Normal University
510631GuangzhouChina</p>
<p>Guangdong Key Laboratory of Mental Health and Cognitive Science
Normal University
510631GuangzhouSouth China, China</p>
<p>Jingxin Nie niejingxin@gmail.com 
Ministry of Education Center for Studies of Psychological Application
Philosophy and Social Science Laboratory of Reading and Development in Children and Adolescents
South China Normal University)
South China Normal University
510631GuangzhouChina</p>
<p>Guangdong Key Laboratory of Mental Health and Cognitive Science
Normal University
510631GuangzhouSouth China, China</p>
<p>Center for Studies of Psychological Application
South China Normal University
510631GuangzhouChina</p>
<p>Ministry of Education
Key Laboratory of Brain, Cognition and Education Sciences
South China Normal University)</p>
<p>School of Psychology
South China Normal University
510631GuangzhouChina</p>
<p>Psychological Counseling Ability of Large Language Models
1B023F320FC103C5467D84846C03E877psychological counselingLarge Language Modelsassessment
With the development of science and the continuous progress of artificial intelligence technology, Large Language Models (LLMs) have begun to be widely utilized across various fields.However, in the field of psychological counseling, the ability of LLMs have not been systematically assessed.In this study, we assessed the psychological counseling ability of mainstream LLMs using 1096 psychological counseling skill questions which were selected from the Chinese National Counselor Level 3 Examination, including Knowledge-based, Analytical-based, and Application-based question types.The analysis showed that the correctness rates of the LLMs for Chinese questions, in descending order, were GLM-3 (46.5%),GPT-4 (46.1%),Gemini (45.0%),ERNIE-3.5 (45.7%) and GPT-3.5 (32.9%).The correctness rates of the LLMs for English questions, in descending order, were ERNIE-3.5 (43.9%),GPT-4 (40.6%),Gemini (36.6%),GLM-3 (29.9%) and .A chi-square test indicated significant differences in the LLMs' performance on Chinese and English questions.Furthermore, we subsequently utilized the Counselor's Guidebook (Level 3) as a reference for ERNIE-3.5, resulting in a new correctness rate of 59.6%, a 13.8% improvement over its initial rate of 45.8%.In conclusion, the study assessed the psychological counseling ability of LLMs for the first time, which may provide insights for future enhancement and improvement of psychological counseling ability of LLMs.</p>
<p>Introduction</p>
<p>In recent years, Large Language Models (LLMs) have made significant progress in the field of natural language processing (Guu et al., 2020).Through pre-training and fine-tuning techniques (Chowdhery et al., 2023), LLMs are able to comprehend and follow human commands, thus demonstrating superior performance in a wide range of tasks (Wei et al., 2022).LLMs such as ChatGPT are rapidly changing human interaction with AI and raising questions about the nature of human intelligence and consciousness (Hintze, 2023).While LLMs were not designed to explicitly capture or mimic elements of human cognition and psychology, recent research suggests that LLMs may have spontaneously developed this ability due to the large pool of human-generated language content they have been trained with.For example, LLMs display properties similar to human cognitive and emotional abilities and processes, including theory of mind (Kosinski, 2023), emotional intelligence (Wang et al., 2023), emotion recognition (Elyoseph et al., 2024), heuristic decision making (Suri et al., 2024), cognitive biases in decision making (Hagendorff, Fabi &amp; Kosinski, 2023), mental trait inference (Peters &amp; Matz, 2024), quantitative and verbal ability (Hickman, Dunlop &amp; Wolf, 2024), and semantic priming (Digutsch &amp; Kosinski, 2023).</p>
<p>Psychological counseling refers to the use of psychological principles and methods by professionally trained counselors to help-seekers discover their own problems and their root causes, so as to tap the potential ability of the seekers themselves to change the original cognitive structure and behavioral patterns, in order to improve their adaptability to life and their ability to regulate the surrounding environment (Ma, 2014).In modern society, as more and more people are in a state of sub-optimal mental health (Huang &amp; Tang, 2021), the demand for psychological counselors is also increasing.However, the psychological counseling market lacks a comprehensive training mechanism and system, making it difficult to cultivate psychological counseling talents.Furthermore, the high costs may deter potential candidates from pursuing this field (Liu, 2023).Secondly, psychological counselors often have multiple careers, which leads to difficulties in shifting their identities when dealing with visitors, making it hard to maintain objectivity in counseling.Moreover, traditional counseling usually involves appointments, about 1 to 2 times a week, which may not ensure the timeliness of psychological counseling for visitors (Liu, 2023).On the other hand, the stigmatization of mental illnesses has caused some people with mental illnesses to be ashamed to admit that they suffer from mental illnesse.</p>
<p>The emergence of LLMs makes it possible for them to act as virtual counselors, avoiding the disadvantages of traditional counseling.LLMs can maintain the objectivity and neutrality of the subject in counseling, and their covert and anonymous nature can also reduce the psychological defenses of visitors.LLMs are more real-time and can provide timely psychological guidance and feedback to visitors anytime, anywhere.Research has shown that LLMs can help patients understand and cope with psychological difficulties, such as interventions for patients with depression (Chen &amp; Yan, 2024).LLMs can also be used to understand suicide by conducting a linguistic analysis of Internet users' discussions on suicide-related topics (Bauer et al., 2024), and they can obtain information about users' expressions, emotional states, and concerns from online texts and comments, generating a comprehensive and objective mental health assessment report (Chen &amp; Yan, 2024).</p>
<p>Thus, psychological counseling is a potential and promising application area for LLMs.</p>
<p>Though a few LLMs models for counseling, such as EmoGPT (Liu, 2023), SoulChat (Chen et al., 2023) and MentaLLaMA (Yang et al., 2024), have been conducted, there are no studies that have systematically and quantitatively assessed the counseling competencies of LLMs.LLMs are difficult to quantitatively assess in terms of efficacy, completion of counseling goals, and other metrics when acting as psychological counselors.Visitors may not consistently use LLMs for counseling, making it difficult to collect enough data to assess long-term efficacy.Furthermore, most of the training data used in the mental health large models are conversational data, psychological theories, and so on.There is a discrepancy between these training data and actual practice.In practice, it is a challenge for the model to be flexible in applying these theories to the specific situation of the visitor.</p>
<p>As shown in Figure 1, this study aims to assess the psychological counseling competence of LLMs and provide insights for future enhancement of LLMs' psychological counseling competence.First, an objective assessment dataset was established, which was original designed for human psychological counselors qualification test.Then, this dataset was used to assess the existing mainstream LLMs, including ERNIE-3.5, GLM-3, Gemini, GPT-3.5 and GPT-4.Since mainstream LLMs are not specifically trained for psychological counseling, they may lack the relevant professional knowledge in this field.Therefore, we considered using Retrieval-Augmented Generation (RAG) technology to provide the model with specialized domain knowledge to see if it could enhance its psychological counseling capabilities.</p>
<p>Figgure.1 Flow chart of assessing psychological counseling competence in the LLMs</p>
<p>Methods</p>
<p>Assessment Dataset</p>
<p>The assessment dataset includes 1096 psychological counseling skills questions that were selected from the Chinese National Counselor Level 3 Exam.The Ministry of Human Resources and Social Security of China officially certifies the exam, which is divided into a theoretical knowledge test and a skill operation assessment part.Both parts are written exams, graded on a hundred-mark system, where a score of 60 or above is considered passing.Passing the examination was a necessary condition for becoming a national professional qualification psychological counselor.The skill operation assessment part contains skill choice questions and case quiz questions, of which 80% of the points are allocated to skill choice questions and 20% to case quiz questions (Xu, 2011).The test questions selected for the assessment dataset are the skill choice questions of the skill operation assessment part, as this part not only contains theoretical knowledge, but is also closer to practical application, and it is easier to objectively judge the correctness of the choice questions.The skill choice question comprises cases and choice questions, each with four alternative options.For single choice questions, only one option is correct; for multiple choice questions, two or more options are correct, and selecting wrong, fewer, or more than one options is considered as incorrect.</p>
<p>These questions also can be categorized as three types: Knowledge-based, Analytical-based and Application-based (some examples are shown in Table 1), consisting of 192, 455 and 449 questions, respectively.The Knowledge-based questions mainly examine the degree of mastery of basic knowledge, including definitions, characteristics, classifications, theories, and so on.They typically necessitate direct responses grounded in existing knowledge, devoid of intricate analysis or application.The Analysis-based questions require an in-depth analysis and understanding of an issue or phenomenon based on a case or a conversation, involving an exploration of symptoms, subconsciousness, causes, relationships, and so forth.</p>
<p>The third type of questions, Application-based questions, integrates characteristics of both Knowledge-based and Analysis-based questions.It centers on examining the ability to apply existing knowledge to real cases.This not only requires a thorough understanding and mastery of pertinent knowledge by LLMs but also a keen insight and accurate analysis ability of psychological counseling cases.Analytical-based 455(41.5)</p>
<p>The help-seeker's current emotional symptoms include ( ).</p>
<p>Possible causes of the help-seeker's psychological problems include ( ).</p>
<p>The help-seeker's personality traits do not include ( ).</p>
<p>Application-based 449(41.0)</p>
<p>The most likely diagnosis for this help-seeker is ( ).Influential techniques used by the psychological counselor during the counseling process include ( ).</p>
<p>Assessment Procedure</p>
<p>A variety of mainstream LLMs, including GPT-4, GPT-3.5, GLM-3, Gemini, and ERNIE-3.5, were evaluated by the Counselling skills test.Given that these models were trained on English and/or Chinese datasets, two versions of the questions were used for testing, i.e., Chinese and English, to more accurately assess their performance and capabilities.The two versions of the prompts are presented in Table 2.
单选题要求只选择一个正确的选项，多选题要求选择两个或两个以上的正 确的选项。假如你是一名心理咨询师，请根据三个引号内案例或对话内容、 题号后单选或多选的要求，回答案例或对话后的单选或多选题，不用解释 或解析，回答形式为题号、选项，如 1、B。</p>
<p>English version</p>
<p>Only one correct choice is selected for single choice, and two or more correct choices are selected for multiple choice.If you are a psychological counselor, please answer the single or multiple choice questions after the case or conversation based on the content of the case or conversation, without explanation or analysis, in the form of question numbers and options, like 1: B.</p>
<p>Retrieval-Augmented Generation for Psychological Counseling</p>
<p>Since mainstream large language models are not specifically trained for psychological counseling, they may lack the relevant professional knowledge in this field.Therefore, we consider using Retrieval-Augmented Generation (RAG)</p>
<p>technology to provide the model with specialized domain knowledge to see if it can enhance its psychological counseling capabilities.Retrieval-Augmented Generation (RAG) was proposed by Meta AI in 2020, and its basic idea is to combine retrieval systems with generative models to integrate knowledge in a modular way (Lewis et al., 2020).In our experiment, the Psychological Counselor's Guidebook (Ji, 2016) was provided as reference to ERNIE-3.5 before it answers the questions.</p>
<p>Statistical analysis</p>
<p>The data analysis was conducted using SPSS 24.0.First, the correctness rate of different types of questions and different LLMs were calculated.Next, the chi-square test was conducted to test if there is any different of correctness between types of questions and LLMs.Subsequently, after using the RAG technique, the new rate of correctness rates were calculated and compared to original correctness by chi-square test.</p>
<p>Results</p>
<p>Accuracy Characteristics of LLMs in Question Answering Tasks</p>
<p>As shown in Table 3, for the three Chinese types of questions, the total correctness rates of all five LLMs (ERNIE-3.5,GLM-3, Gemini, GPT-3.5 and GPT-4) were 40.8%, 44.8% and 42.9%, respectively.In contrast, for the same types of English questions, the total correctness rates were 33.6%, 38.5% and 34.7%, respectively.</p>
<p>Three one-way chi-square tests were conducted to assess the differences in the accuracy of the answers among the three types of test questions in the Chinese and English versions (see Table 3).The results showed that the difference in the correctness rates between the two language versions was statistically significant in all three types of questions (χ²1 =10.61, df1 = 1, p1 = 0.001; χ²2 = 18.23, df2 = 1, p2 &lt; 0.001; (χ²3 = 31.42,df3 = 1, p3 &lt; 0.001).The chi-square test was further followed by multiple comparisons to assess the correctness of the answers on the two languages for each of the three question types.The results showed that there was a significant difference between the correctness rates of the questions for the knowledge-based, analytical-based and application-based questions respectively on the two language versions.Regardless of the question types, the Chinese version had significantly higher correctness rates than the English version.</p>
<p>A one-way two-level chi-square test was conducted to assess the correctness of LLMs in answering questions presented in two language versions (Chinese and English) (see Table 3).The results indicated that the difference in the percentage of correctness between the two language versions was statistically significant (χ² = 59.16, df = 1, p &lt; 0.001).The chi-square test was further followed by multiple comparisons to assess the correctness of the LLMs' answers in both language versions of the questions.The results showed a significant difference in correctness rates between the English and Chinese versions of the questions, with the Chinese version showing significantly higher correctness rates than the English version.A one-way five-level chi-square test chi-square test was conducted on the five LLMs (ERNIE-3.5,GLM-3, Gemini, GPT-3.5 and GPT-4) for doing Chinese questions correctly, and the results showed that the difference in the correctness rates of the five LLMs for doing Chinese questions was statistically significant (χ² = 59.91, df = 4, p &lt; 0.001).The chi-square test was further followed by multiple comparisons of the correctness of different LLMs in doing Chinese questions, and the results showed that ERNIE-3.5, GLM-3, Gemini and GPT-4 were significantly higher than the correctness of GPT-3.5 in doing Chinese questions.</p>
<p>A one-way five-level chi-square test was also conducted on the five LLMs (ERNIE-3.5,GLM-3, Gemini, GPT-3.5 and GPT-4) for correctly doing English questions, and it was found that the difference between the five LLMs in terms of correctly doing English questions was statistically significant (χ² = 77.54,df = 4, p &lt; 0.001).The chi-square test was further followed by multiple comparisons of the correctness of different LLMs in doing English questions, and ERNIE-3.5'scorrectness in doing English questions was significantly higher than that of GLM-3, Gemini and GPT-3.5.The correctness rate of Gemini doing English questions is significantly higher than the correctness rate of GLM-3 and GPT-3.5 in English version.GPT-4 445 a,b 0.406 ERNIE-3.5 &gt; Gemini, GLM-3, GPT-3.5;Gemini &gt; GLM-3, GPT-3.5 (p &lt; 0.05) Note: LLM = Large Language Model; χ2 test = chi-square test; Significance tests for multiple comparisons were performed using the letter labeling method, where the same labeled letter indicated that there was no difference between the corresponding two sets of data, and a different letter indicated that the difference was statistically significant.</p>
<p>Accuracy Characteristics of LLMs in Different Types of Questions</p>
<p>Five one-way three-level chi-square tests were conducted to evaluate the correctness of ERNIE-3.5, GLM-3, Gemini, GPT-3.5, and GPT-4 when answering three types of Chinese questions (Knowledge-based, Analytical-based and Application-based).The results in Table 5 indicate that the differences in accuracy rates among these five LLMs when answering three types of Chinese questions were not statistically significant.</p>
<p>Separate one-way three-level chi-square tests were performed for ERNIE-3.5, GLM-3, Gemini, and GPT-4 to assess their correctness in answering three types of English questions (Knowledge-based, Analytical-based and Application-based).The results showed that the differences in correctness among three LLMs when answering English questions were also not statistically significant.However, when a one-way three-level chi-square test was conducted on GPT-3.5'scorrectness in answering the three types of English questions, it was found that the difference in GPT-3.5'scorrectness was statistically significant (χ² = 6.60, df = 2, p = 0.037 &lt; 0.05).The chi-square test was further followed by multiple comparisons of GPT-3.5'scorrectness in doing the three types of English questions, and the results showed that GPT-3.5'scorrectness in doing Knowledge-based was significantly lower than the correctness in doing Analytical-based English questions.Note: LLM = Large Language Model; χ2 test = chi-square test; Significance tests for multiple comparisons were performed using the letter labeling method, where the same labeled letter indicated that there was no difference between the corresponding two sets of data, and a different letter indicated that the difference was statistically significant.</p>
<p>Assessment of LLMs with Psychological Counselor's Guidebook</p>
<p>To improve the accuracy of LLM's responses to questions, ERNIE-3.5 used the Psychological Counselor's Guidebook published by China Machine Press as a reference document (Ji, 2016).It re-examined the questions in Chinese and analyzed them statistically accordingly.The results of chi-square test showed that the correctness of ERNIE-3.5 questions was significantly different before and after the use of the counselor's guidebook (χ² = 41.73,df = 1, p &lt; 0.001).The correctness of the questions after referring the document was significantly higher than the correctness of the questions previously done.The percentage of questions done correctly without referencing the document was 45.8%, which increased to 59.6% after using the document, representing an improvement of 13.8%.</p>
<p>Three one-way two-level chi-square tests were conducted to assess ERNIE-3.5'scorrectness before and after using guidebook, categorized by question type.As shown in Table 6, the differences in correctness between ERNIE-3.5's responses before and after using guidebook for each of the three question types (Knowledge-based, Analytical-based and Application-based) were statistically significant (χ²1 = 9.38, df1</p>
<p>= 1, p1 = 0.002 &lt; 0.05; χ²2 = 19.25,df2 = 1, p2 &lt; 0.001; χ²3 = 13.50, df3 = 1, p3 &lt; 0.001).</p>
<p>The chi-square test was further followed by multiple comparisons of correctness of ERNIE-3.5 before and after prompting, showed that the correctness rate after using guidebook was significantly higher than that before prompting, regardless of the type of question.Note: LLM = Large Language Model; χ2 test = chi-square test; Significance tests for multiple comparisons were performed using the letter labeling method, where the same labeled letter indicated that there was no difference between the corresponding two sets of data, and a different letter indicated that the difference was statistically significant.</p>
<p>Discussion</p>
<p>In this study, we used 1096 counseling skills questions selected from the test questions of the Chinese National Counselor Level 3 Exam to assess the psychological counseling competence of mainstream LLMs through their question answering.Our findings indicate that the tested LLMs exhibited relatively low accuracy in the assessment, with an average of 43.26% for Chinese questions and 36.10% for English questions, suggesting their psychological counseling capabilities could be improved significantly.</p>
<p>Large language model (LLM) demonstrated varying performance across different languages, with the correct rate for Chinese questions generally being higher than that for English questions.This may be attributed to the fact that some LLMs were more heavily optimized for the Chinese model during their development and training phases, resulting in a higher accuracy for Chinese questions compared to English ones.</p>
<p>Meanwhile, it is possible that the questions, originally in Chinese, undergo some bias when translated into English, which could affect the LLM's understanding and subsequent performance on the English questions.The analysis concluded that, notable disparities in correctness rates were observed among different LLMs when tackling both Chinese and English questions, underscoring the varying linguistic comprehension and processing abilities among these models.The study concluded that LLMs performed relatively better on Analytical-based questions (44.8% in Chinese and 38.5% in English), but did not show an advantage on Knowledge-based questions (40.8% in Chinese and 33.6% in English).This may imply that LLMs are more adept at understanding and analyzing information in known situations and have limitations in theoretical knowledge of counseling psychology.In addition, the performance of Application-based questions (42.9% in Chinese and 34.7% in English) was in between, indicating that LLMs are competent in applying their knowledge to case situations, but there is still room for improvement.</p>
<p>In general, the differences between the types of questions were not significant, and LLMs did not get more than 50% correct on all types of questions, indicating that although LLMs have made significant progress in the field of natural language processing, there are still major limitations in comprehending and answering complex questions.</p>
<p>Since mainstream LLMs are not specifically trained for psychological counseling, they tend to yield lower accuracy rates when answering Knowledge-based questions pertinent to this domain.Therefore, we used Retrieval-Augmented Generation (RAG)</p>
<p>technology to see if it could enhance its psychological counseling capabilities.After ERNIE-3.5 was provided with the Psychological Counselor's Guidebook for reference, its correctness rate improved, rising from 45.8% to 59.6%.The correctness rate of questions done after the reference is significantly higher than that before the reference, demonstrating LLMs robust learning and adaptation capabilities within the realm of psychological counseling.This advancement predicted its potential to pass</p>
<p>There are three types of questions in this study, Knowledge-based, Analytical-based and Application-based.The corresponding types of errors can also be categorized into Knowledge-based, Analytical-based and Application-based errors.Knowledge-based errors refer to factual errors or conceptual confusion in the answers due to inaccurate understanding or incomplete mastery of relevant knowledge during the answering process.Analytical-based errors refer to deviations or errors in the analysis results due to improper logical reasoning, unclear analytical thinking or failure to accurately grasp the core of the problem in the process of analyzing the problem in combination with the case or dialogue.Application-based errors refer to the failure to get the correct answer to a question when applying relevant counseling knowledge or skills to solve a multiple-choice question following a case or a dialogue due to an incomplete grasp of the knowledge points or a failure to flexibly apply the relevant knowledge.</p>
<p>the Level 3
3
psychological counselor examination and underscores the capacity of LLMs to excel in standardized tests, potentially even qualifying them as professional psychological counselors.The improvement also pinpoints the lack of domain-specific knowledge as a crucial factor limiting their performance.With the continued advancement of technology and the accumulation of data, LLMs can be increasingly fine-tuned and optimized for specific domains such as mental health and psychological counseling.In summary, our research marks the first comprehensive measurement and evaluation of the psychological counseling ability of LLMs, potentially offering insights for future enhancements and refinements of their capability in this field.This study provides a new assessment of LLM counseling competence, but several limitations remain.First, we only examined some of the mainstream LLMs, namely GPT-4, GPT-3.5, GLM-3, Gemini, and ERNIE-3.5.Despite the popularity of these LLMs, many other LLMs exist, particularly the Mental Health Large Model.Future LLMs may perform better on counseling aptitude tests.Second, this study assessed LLMs' counseling competence through three types of questions: Knowledge-based, Analytical-based, and Application-based, which only provided a limited perspective, but the actual counseling process is more than that.Knowledge of counseling theory does not necessarily reflect the model's ability to practice in actual counseling, and since the theory and practice of counseling is constantly evolving, the model may not be able to update itself in real time with the latest research findings and therapeutic approaches.Although a number of real-life examples appeared in the case study questions, the model can only analyze based on predetermined information, and is not able to engage in real-life conversations and adjustments.Future research could benefit from larger and more diverse tests, and more scenarios could be designed to examine whether LLMs are able to counsel effectively.Finally, the prompts in this study used only simple direct questions and answers, which may affect the reliability and accuracy of the results generated by LLMs.</p>
<p>Table 1 .
1
Question Types for Assessment
Question Typesn (%)ExamplesKnowledge-based 192(17.5)Breathing relaxation method does not include ( ). Common methods of behavior modification include ( ).</p>
<p>Table 2 .
2
Assessment Prompts for LLMs
VersionsPromptsChineseversion</p>
<p>Table 3 .
3
Analysis of the Characteristics of Correctness of three types questions in different languages and Correctness of two language versions Significance tests for multiple comparisons were performed using the letter labeling method, where the same labeled letter indicated that there was no difference between the corresponding two sets of data, and a different letter indicated that the difference was statistically significant.
Question TypesTest versionχ²pChinese versionEnglish versionKnowledge-based0.408 a0.336 b10.610.001Analytical-based0.448 a0.385 b18.23&lt; 0.001Application-based0.429 a0.347 b31.42&lt; 0.001All types0.433 a0.361 b59.16&lt; 0.001Note: χ2 test = chi-square test; Gemini, GLM-3, GPT-3.5, with the correctness rate of 43.9%, 40.6%, 36.6%, 29.9%and 29.5%, respectively.
Correctness of different LLMs was reported in Table 4.The correctness rates of theLLMs for Chinese version were as follows: 46.5% for GLM-3, 46.1% for GPT-4, 45.8% for ERNIE-3.5, 45.0% for Gemini and 32.9% for GPT-3.5.The correctness rates of the LLMs for the English version were as follows: ERNIE-3.5,</p>
<p>Table 4 .
4
Analysis of the Characteristics of Correctness in Question Answering Tasks Performed by
Different LLMsTest versionLLMCorrectCorrectness rateχ²pERNIE-3.5502 b0.458GLM-3510 b0.465Chinese versionGemini GPT-3.5493 b 361 a0.450 0.32960.11&lt; 0.001GPT-4505 b0.461GLM-3, GPT-4, ERNIE-3.5, Gemini &gt; GPT-3.5 (p &lt; 0.05)ERNIE-3.5481 a0.439GLM-3328 c0.299English versionGemini GPT-3.5401 b 323 c0.366 0.29577.54&lt; 0.001</p>
<p>Table 5 .
5
Analysis of the Characteristics of Correctness of LLMs in Answering Different Types
Test versionLLMType of questionCorrectCorrectness rateχ²pKnowledge-based840.438ERNIE-3.5Analytical-based2110.4640.400.82Application-based2070.461Knowledge-based870.453GLM-3Analytical-based2250.4952.550.28Application-based1990.443Knowledge-based820.427GeminiAnalytical-based2140.4701.310.52ChineseApplication-based1980.441versionKnowledge-based530.276GPT-3.5Analytical-based1500.3303.500.17Application-based1580.352Knowledge-based860.448GPT-4Analytical-based2190.4811.330.52Application-based2000.445ERNIE-3.5 (RAG)Knowledge-based Analytical-based Application-based124 311 2980.646 0.684 0.6640.960.62Knowledge-based860.448ERNIE-3.5Analytical-based2090.4591.750.42Application-based1870.416Knowledge-based550.286GLM-3Analytical-based1470.3232.120.35Application-based1260.281English versionGeminiKnowledge-based Analytical-based Application-based64 183 1540.333 0.402 0.3434.480.11Knowledge-based42 b0.219GPT-3.5Analytical-based144 a0.3166.600.04Application-based137 a0.305Knowledge-based760.396GPT-4Analytical-based1940.4261.360.51Application-based1750.390</p>
<p>Table 6 .
6
Analysis of ERNIE-3.5'sCorrectness Characteristics Before and After Incorporating Counselors' Guide book
Type of questionRAGCorrectCorrectness rateχ²ppre-enhancement84 a0.438Knowledge-based9.380.002post-enhancement114 b0.594pre-enhancement211 a0.464Analytical-based19.25&lt; 0.001post-enhancement277 b0.609pre-enhancement207 a0.461Application-based13.50&lt; 0.001post-enhancement262 b0.584Chinese Questionspre-enhancement post-enhancement502 a 653 b0.458 0.59641.73&lt; 0.001
FundingThis work was supported by the Research Center for Brain Cognition and Human Development, Guangdong, China (No. 2024B0303390003); and the Striving for the First-Class, Improving Weak Links and Highlighting Features (SIH) Key Discipline for Psychology in South China Normal University.
Using Large Language Models to Understand Suicidality in a Social Media-Based Taxonomy of Mental Health Disorders: Linguistic Analysis of Reddit Posts. B Bauer, R Norel, A Leow, Z A Rached, B Wen, G Cecchi, JMIR mental health. 11e572342024</p>
<p>The application and challenges of large language models in college students' mental health intervention. S Chen, Q Yan, Proceedings of the Seminar on Sustainable Social and Economic Development in the Context of the New Era. the Seminar on Sustainable Social and Economic Development in the Context of the New EraFuzhou Institute of Technology2024</p>
<p>Soulchat: Improving llms' empathy, listening, and comfort abilities through fine-tuning with multi-turn empathy conversations. Y Chen, X Xing, J Lin, H Zheng, Z Wang, Q Liu, X Xu, Findings of the Association for Computational Linguistics: EMNLP 2023. 2023, December</p>
<p>Palm: Scaling language modeling with pathways. A Chowdhery, S Narang, J Devlin, M Bosma, G Mishra, A Roberts, . . Fiedel, N , Journal of Machine Learning Research. 242402023</p>
<p>Overlap in meaning is a stronger predictor of semantic activation in GPT-3 than in humans. J Digutsch, M Kosinski, Scientific Reports. 13150352023</p>
<p>Capacity of generative AI to interpret human emotions from visual and textual data: pilot evaluation study. Z Elyoseph, E Refoua, K Asraf, M Lvovsky, Y Shimoni, D Hadar-Shoval, JMIR Mental Health. 11e543692024</p>
<p>Retrieval augmented language model pre-training. K Guu, K Lee, Z Tung, P Pasupat, M Chang, International conference on machine learning. PMLR2020, November</p>
<p>Thinking fast and slow in large language models. T Hagendorff, S Fabi, M Kosinski, arXiv:2212.052062023arXiv preprint</p>
<p>The performance of large language models on quantitative and verbal ability tests: Initial evidence and implications for unproctored high-stakes testing. L Hickman, P D Dunlop, J L Wolf, arXiv:2304.12898ChatGPT believes it is conscious. Hintze, A2024. 2023arXiv preprint</p>
<p>Research on Subnormal State of Mentality of College Students from the Perspective of Ideological and Political Education. L Huang, H Tang, 7th International Conference on Social Science and Higher Education (ICSSHE 2021). Atlantis Press2021, November</p>
<p>Review Guide and Detailed Explanations of Psychological Counselor National Vocational Qualification Examination. Y Ji, 2016Level</p>
<p>M Kosinski, arXiv:2302.02083Theory of mind might have spontaneously emerged in large language models. 2023arXiv preprint</p>
<p>An exploration of the risks of artificial intelligence in psychological counseling to individual subjectivity and coping insights. M Y Liu, Psychologies. 052023</p>
<p>EmoGPT -Launching the first AI large-scale model vertical application in the field of mental health in China. Y Liu, 2023, July 1. August 15, 2024Shanghai Key Laboratory of Mental Health and Psychological Crisis Intervention</p>
<p>How to Conduct School Psychological Counseling. Z G Ma, 2014Educational Science PressBeijing</p>
<p>Large language models can infer psychological dispositions of social media users. H Peters, S Matz, PNAS Nexus. e2312024</p>
<p>Smile: Single-turn to multi-turn inclusive language expansion via chatgpt for mental health support. H Qiu, H He, S Zhang, A Li, Z Lan, arXiv:2305.004502023arXiv preprint</p>
<p>Do large language models show decision heuristics similar to humans? A case study using GPT-3.5. G Suri, L R Slater, A Ziaee, M Nguyen, Journal of Experimental Psychology: General. 2024</p>
<p>Emotional intelligence of large language models. X Wang, X Li, Z Yin, Y Wu, J Liu, Journal of Pacific Rim Psychology. 17183449092312139582023</p>
<p>J Wei, Y Tay, R Bommasani, C Raffel, B Zoph, S Borgeaud, . . Fedus, W , arXiv:2206.07682Emergent abilities of large language models. 2022arXiv preprint</p>
<p>Psychological counselor: A golden profession in the 21st century. W F Xu, China University Students Career Guide. 2011</p>
<p>MentaLLaMA: interpretable mental health analysis on social media with large language models. K Yang, T Zhang, Z Kuang, Q Xie, J Huang, S Ananiadou, Proceedings of the ACM on Web Conference 2024. the ACM on Web Conference 20242024. May</p>
<p>Psychological Counseling Chatbot Based on GPT-2 (Master's thesis). Z Zhuang, 2022Nanjing University of Posts and Telecommunications</p>            </div>
        </div>

    </div>
</body>
</html>