<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3850 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3850</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3850</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-91.html">extraction-schema-91</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or studies that use large language models (LLMs) to distill theories or synthesize knowledge from large collections of scholarly papers, including details about the method, input corpus, topic/query specification, output, evaluation, results, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-e26197fb0fa409866b287f4bf63abe7997223b51</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/e26197fb0fa409866b287f4bf63abe7997223b51" target="_blank">A general-purpose material property data extraction pipeline from large polymer corpora using natural language processing</a></p>
                <p><strong>Paper Venue:</strong> npj Computational Materials</p>
                <p><strong>Paper TL;DR:</strong> The feasibility of an automatic pipeline that starts from published literature and ends with extracted material property information is demonstrated, which outperforms other baseline models in three out of five named entity recognition datasets.</p>
                <p><strong>Paper Abstract:</strong> The ever-increasing number of materials science articles makes it hard to infer chemistry-structure-property relations from literature. We used natural language processing methods to automatically extract material property data from the abstracts of polymer literature. As a component of our pipeline, we trained MaterialsBERT, a language model, using 2.4 million materials science abstracts, which outperforms other baseline models in three out of five named entity recognition datasets. Using this pipeline, we obtained ~300,000 material property records from ~130,000 abstracts in 60 hours. The extracted data was analyzed for a diverse range of applications such as fuel cells, supercapacitors, and polymer solar cells to recover non-trivial insights. The data extracted through our pipeline is made available at polymerscholar.org which can be used to locate material property data recorded in abstracts. This work demonstrates the feasibility of an automatic pipeline that starts from published literature and ends with extracted material property information.</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3850.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3850.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or studies that use large language models (LLMs) to distill theories or synthesize knowledge from large collections of scholarly papers, including details about the method, input corpus, topic/query specification, output, evaluation, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MaterialsBERT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MaterialsBERT (domain-adapted BERT for materials science)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A BERT-based language model produced by further pretraining PubMedBERT on a 2.4 million-abstract materials science corpus to produce domain-specific contextual token embeddings that improve downstream NER for materials literature.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>MaterialsBERT</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_description</strong></td>
                            <td>A domain-adapted transformer encoder produced by initializing from PubMedBERT and continuing masked-language-model style pretraining on 2.4 million materials science abstracts; used as the token encoder in a sequence-labeling NER pipeline to extract material entities and property mentions from abstracts.</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>2.4 million materials science abstracts used for continued pretraining; downstream extraction applied to a filtered subset of abstracts (≈650,000 polymer-relevant abstracts, ≈130,000 abstracts containing numeric material property mentions). Language: English. Source: materials science literature corpus described in the paper (ref. describing the corpus cited as Ref. 12).</td>
                        </tr>
                        <tr>
                            <td><strong>topic_or_query_specification</strong></td>
                            <td>No natural-language prompting — the model is a pretrained encoder used within a supervised NER task. Corpus filtering for extraction used keyword/regex heuristics (e.g., filter abstracts containing substring 'poly' to find polymer-relevant documents; regular expressions to detect numeric information). For application-specific analyses the authors used keyword search on abstracts (e.g., 'polymer solar cell', 'fuel cell', 'supercapacitor').</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td>Not a generative LLM distillation workflow; instead, pretraining (masked language modeling) on the domain corpus to produce contextual embeddings, fine-tuning a supervised token-labeling head (linear layer + softmax) for NER on 750 annotated abstracts, then applying deterministic heuristic rules to combine extracted entities into structured material-property records; aggregate statistics and plots over the resulting structured database synthesize knowledge (correlations, trends, time series).</td>
                        </tr>
                        <tr>
                            <td><strong>output_type_and_format</strong></td>
                            <td>Trained transformer encoder weights (MaterialsBERT) plus token-level NER predictions; structured material-property records with entity fields (POLYMER, POLYMER_CLASS, PROPERTY_NAME, PROPERTY_VALUE, MONOMER, ORGANIC_MATERIAL, INORGANIC_MATERIAL, MATERIAL_AMOUNT); aggregated datasets and visualizations (scatter plots, Ragone plots, temporal trends).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_or_validation_method</strong></td>
                            <td>Standard NER metrics (precision, recall, F1) on held-out test split of 750 annotated polymer abstracts; inter-annotator agreement measured with Fleiss' Kappa (0.885) and pairwise Cohen's Kappa (0.906, 0.864, 0.887) on 10 shared abstracts; comparative evaluation on multiple public materials-science NER datasets; qualitative validation of aggregated outputs by reproducing known scientific trends and comparison to manually curated datasets (e.g., manually curated polymer solar cell data from referenced prior work and known literature maxima).</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>MaterialsBERT achieved the best F1 (66.4%) on the paper's polymer-abstract test set (Precision 62.5%, Recall 70.6%) and outperformed other BERT variants on three of five tested materials NER datasets. Using the full pipeline powered by this encoder the authors extracted ≈300,000 material-property records from ≈130,000 polymer-relevant abstracts in ~60 hours on a single Quadro 16 GB GPU. Aggregated analyses reproduced known physics and domain trends (e.g., strength–ductility trade-off, polymer solar cell metrics distributions, Ragone plot shifts), and produced datasets comparable in scale to manually curated resources (PoLyInfo).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>MaterialsBERT is an encoder (non-generative) and the pipeline is limited to abstracts (not full-text, figures, or tables), so multimodal and cross-sentence/table/figure co-referencing remains unaddressed. The ontology omits measurement methods/conditions, conversion of polymer names to chemical structures/SMILES is manual and a bottleneck, relation extraction across sentences is heuristic, and the approach can miss or misassociate entities (leading to false positives/negatives). No explicit mitigation of generative hallucination is needed (model is discriminative), but extraction errors and reliance on heuristics limit fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baselines_or_humans</strong></td>
                            <td>Compared to baseline encoders (PubMedBERT, MatBERT, BioBERT, ChemBERT, BERT-base) MaterialsBERT gave higher F1 on the authors' polymer test set and on three out of five public materials NER datasets. Aggregated NLP-derived trends matched those from manually curated datasets and known literature results (qualitative agreement). The extracted database size (~300k records) was comparable to/approached scale of human-curated PoLyInfo (~492k records) though automated records are currently limited to abstracts and require additional curation for downstream ML (e.g., structure mapping).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A general-purpose material property data extraction pipeline from large polymer corpora using natural language processing', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3850.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3850.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or studies that use large language models (LLMs) to distill theories or synthesize knowledge from large collections of scholarly papers, including details about the method, input corpus, topic/query specification, output, evaluation, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Polymer property extraction pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MaterialsBERT-powered general-purpose material property data extraction pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An end-to-end NLP pipeline that uses a MaterialsBERT encoder + supervised NER + rule-based postprocessing to extract structured material–property records from large collections of polymer abstracts and then aggregates those records to synthesize domain knowledge and recover scientific trends.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>MaterialsBERT-powered material property extraction pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_description</strong></td>
                            <td>Pipeline components: (1) corpus filtering for polymer relevance (keyword and regex), (2) token-level NER using a BERT-based encoder (MaterialsBERT) fine-tuned on 750 annotated abstracts with an 8-entity ontology, (3) heuristic rules and normalization to combine entities into material-property records, (4) aggregation and analysis of the extracted structured records to synthesize insights (correlations, temporal trends, device-specific performance spaces).</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Started from a 2.4 million materials-science-abstract corpus; filtered to ≈650,000 polymer-relevant abstracts and ≈130,000 abstracts containing numeric property mentions. The annotated training set for NER comprised 750 polymer abstracts (split 80/10/10 train/val/test). Extraction run over the 130k abstracts produced ≈300,000 property records. Language: English; domain: polymer/materials science; sources: scholarly abstracts in the authors' assembled materials corpus.</td>
                        </tr>
                        <tr>
                            <td><strong>topic_or_query_specification</strong></td>
                            <td>Document-level filtering and topic selection were specified via simple keyword matching and regular expressions (e.g., substring 'poly' to select polymer-relevant abstracts; numeric regex to find property mentions). For application-specific analyses authors selected abstracts via keywords such as 'polymer solar cell', 'fuel cell', 'supercapacitor'. No interactive natural-language prompt-driven querying or retrieval-augmented generation was used.</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td>Not a text-generation distillation approach; knowledge synthesis proceeds by: supervised NER to extract structured atomic facts (entities and values) from individual abstracts, deterministic heuristics to link entities into records, normalization of polymer names, then statistical aggregation (scatter plots, correlations, temporal binning) to synthesize domain-level observations and reproduce known scientific relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type_and_format</strong></td>
                            <td>Structured material property records (entity fields and numeric property values with units), an aggregated dataset (~300k records), summary visualizations (e.g., scatter plots for property pairs, Ragone plot, time-evolution plots), and downloadable data accessible via a web interface (https://polymerscholar.org).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_or_validation_method</strong></td>
                            <td>NER evaluation via precision, recall, F1 using strict entity-level correctness; inter-annotator agreement metrics (Fleiss' Kappa and Cohen's Kappa) for annotation quality; baseline comparisons across multiple pre-trained encoders; qualitative validation of synthesized knowledge by reproducing known trends and comparison to manually curated datasets and domain literature (e.g., manual polymer solar cell data from prior work; comparisons to PoLyInfo scale).</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Pipeline extracted ≈300,000 material-property records from ≈130,000 abstracts in ~60 hours on a single Quadro 16GB GPU. The extracted database enabled recovery of established scientific trends (strength–ductility trade-off; polymer class differences in Tg, conductivity, tensile strength; device-specific relationships for solar cells, fuel cells, and supercapacitors), and temporal shifts (e.g., rise of non-fullerene acceptors). For NER, MaterialsBERT-based encoder achieved F1=66.4% on the polymer test set, and outperformed other BERT variants on multiple materials NER datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Restricted to abstracts (no full-text, tables, or figures), so many data points in body/tables/images are missed; cross-sentence relation extraction and co-reference across figures/tables not solved; ontology omits measurement protocols/conditions which affect comparability; polymer-to-structure mapping (SMILES) not automated; rule-based record assembly can mis-associate entities; potential domain and platform biases inherent in corpus selection and keyword filtering.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baselines_or_humans</strong></td>
                            <td>Compared algorithmic encoders (PubMedBERT, MatBERT, BioBERT, ChemBERT, BERT-base): pipeline using MaterialsBERT yielded higher NER performance on several datasets. Aggregated outputs qualitatively matched human-curated datasets and known published trends (demonstrated by direct comparison plots to manually extracted polymer solar cell metrics). The automatically extracted dataset size approaches that of a long-standing human-curated database (PoLyInfo), but with different coverage (abstract-only) and without structural mappings that manual curation sometimes provides.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A general-purpose material property data extraction pipeline from large polymer corpora using natural language processing', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>ChemDataExtractor <em>(Rating: 2)</em></li>
                <li>ChemSpot <em>(Rating: 2)</em></li>
                <li>ChemicalTagger <em>(Rating: 2)</em></li>
                <li>PubMedBERT <em>(Rating: 2)</em></li>
                <li>MatBERT <em>(Rating: 2)</em></li>
                <li>BioBERT <em>(Rating: 2)</em></li>
                <li>ChemBERT <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3850",
    "paper_id": "paper-e26197fb0fa409866b287f4bf63abe7997223b51",
    "extraction_schema_id": "extraction-schema-91",
    "extracted_data": [
        {
            "name_short": "MaterialsBERT",
            "name_full": "MaterialsBERT (domain-adapted BERT for materials science)",
            "brief_description": "A BERT-based language model produced by further pretraining PubMedBERT on a 2.4 million-abstract materials science corpus to produce domain-specific contextual token embeddings that improve downstream NER for materials literature.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_or_method_name": "MaterialsBERT",
            "system_or_method_description": "A domain-adapted transformer encoder produced by initializing from PubMedBERT and continuing masked-language-model style pretraining on 2.4 million materials science abstracts; used as the token encoder in a sequence-labeling NER pipeline to extract material entities and property mentions from abstracts.",
            "input_corpus_description": "2.4 million materials science abstracts used for continued pretraining; downstream extraction applied to a filtered subset of abstracts (≈650,000 polymer-relevant abstracts, ≈130,000 abstracts containing numeric material property mentions). Language: English. Source: materials science literature corpus described in the paper (ref. describing the corpus cited as Ref. 12).",
            "topic_or_query_specification": "No natural-language prompting — the model is a pretrained encoder used within a supervised NER task. Corpus filtering for extraction used keyword/regex heuristics (e.g., filter abstracts containing substring 'poly' to find polymer-relevant documents; regular expressions to detect numeric information). For application-specific analyses the authors used keyword search on abstracts (e.g., 'polymer solar cell', 'fuel cell', 'supercapacitor').",
            "distillation_method": "Not a generative LLM distillation workflow; instead, pretraining (masked language modeling) on the domain corpus to produce contextual embeddings, fine-tuning a supervised token-labeling head (linear layer + softmax) for NER on 750 annotated abstracts, then applying deterministic heuristic rules to combine extracted entities into structured material-property records; aggregate statistics and plots over the resulting structured database synthesize knowledge (correlations, trends, time series).",
            "output_type_and_format": "Trained transformer encoder weights (MaterialsBERT) plus token-level NER predictions; structured material-property records with entity fields (POLYMER, POLYMER_CLASS, PROPERTY_NAME, PROPERTY_VALUE, MONOMER, ORGANIC_MATERIAL, INORGANIC_MATERIAL, MATERIAL_AMOUNT); aggregated datasets and visualizations (scatter plots, Ragone plots, temporal trends).",
            "evaluation_or_validation_method": "Standard NER metrics (precision, recall, F1) on held-out test split of 750 annotated polymer abstracts; inter-annotator agreement measured with Fleiss' Kappa (0.885) and pairwise Cohen's Kappa (0.906, 0.864, 0.887) on 10 shared abstracts; comparative evaluation on multiple public materials-science NER datasets; qualitative validation of aggregated outputs by reproducing known scientific trends and comparison to manually curated datasets (e.g., manually curated polymer solar cell data from referenced prior work and known literature maxima).",
            "results_summary": "MaterialsBERT achieved the best F1 (66.4%) on the paper's polymer-abstract test set (Precision 62.5%, Recall 70.6%) and outperformed other BERT variants on three of five tested materials NER datasets. Using the full pipeline powered by this encoder the authors extracted ≈300,000 material-property records from ≈130,000 polymer-relevant abstracts in ~60 hours on a single Quadro 16 GB GPU. Aggregated analyses reproduced known physics and domain trends (e.g., strength–ductility trade-off, polymer solar cell metrics distributions, Ragone plot shifts), and produced datasets comparable in scale to manually curated resources (PoLyInfo).",
            "limitations_or_challenges": "MaterialsBERT is an encoder (non-generative) and the pipeline is limited to abstracts (not full-text, figures, or tables), so multimodal and cross-sentence/table/figure co-referencing remains unaddressed. The ontology omits measurement methods/conditions, conversion of polymer names to chemical structures/SMILES is manual and a bottleneck, relation extraction across sentences is heuristic, and the approach can miss or misassociate entities (leading to false positives/negatives). No explicit mitigation of generative hallucination is needed (model is discriminative), but extraction errors and reliance on heuristics limit fidelity.",
            "comparison_to_baselines_or_humans": "Compared to baseline encoders (PubMedBERT, MatBERT, BioBERT, ChemBERT, BERT-base) MaterialsBERT gave higher F1 on the authors' polymer test set and on three out of five public materials NER datasets. Aggregated NLP-derived trends matched those from manually curated datasets and known literature results (qualitative agreement). The extracted database size (~300k records) was comparable to/approached scale of human-curated PoLyInfo (~492k records) though automated records are currently limited to abstracts and require additional curation for downstream ML (e.g., structure mapping).",
            "uuid": "e3850.0",
            "source_info": {
                "paper_title": "A general-purpose material property data extraction pipeline from large polymer corpora using natural language processing",
                "publication_date_yy_mm": "2022-09"
            }
        },
        {
            "name_short": "Polymer property extraction pipeline",
            "name_full": "MaterialsBERT-powered general-purpose material property data extraction pipeline",
            "brief_description": "An end-to-end NLP pipeline that uses a MaterialsBERT encoder + supervised NER + rule-based postprocessing to extract structured material–property records from large collections of polymer abstracts and then aggregates those records to synthesize domain knowledge and recover scientific trends.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_or_method_name": "MaterialsBERT-powered material property extraction pipeline",
            "system_or_method_description": "Pipeline components: (1) corpus filtering for polymer relevance (keyword and regex), (2) token-level NER using a BERT-based encoder (MaterialsBERT) fine-tuned on 750 annotated abstracts with an 8-entity ontology, (3) heuristic rules and normalization to combine entities into material-property records, (4) aggregation and analysis of the extracted structured records to synthesize insights (correlations, temporal trends, device-specific performance spaces).",
            "input_corpus_description": "Started from a 2.4 million materials-science-abstract corpus; filtered to ≈650,000 polymer-relevant abstracts and ≈130,000 abstracts containing numeric property mentions. The annotated training set for NER comprised 750 polymer abstracts (split 80/10/10 train/val/test). Extraction run over the 130k abstracts produced ≈300,000 property records. Language: English; domain: polymer/materials science; sources: scholarly abstracts in the authors' assembled materials corpus.",
            "topic_or_query_specification": "Document-level filtering and topic selection were specified via simple keyword matching and regular expressions (e.g., substring 'poly' to select polymer-relevant abstracts; numeric regex to find property mentions). For application-specific analyses authors selected abstracts via keywords such as 'polymer solar cell', 'fuel cell', 'supercapacitor'. No interactive natural-language prompt-driven querying or retrieval-augmented generation was used.",
            "distillation_method": "Not a text-generation distillation approach; knowledge synthesis proceeds by: supervised NER to extract structured atomic facts (entities and values) from individual abstracts, deterministic heuristics to link entities into records, normalization of polymer names, then statistical aggregation (scatter plots, correlations, temporal binning) to synthesize domain-level observations and reproduce known scientific relationships.",
            "output_type_and_format": "Structured material property records (entity fields and numeric property values with units), an aggregated dataset (~300k records), summary visualizations (e.g., scatter plots for property pairs, Ragone plot, time-evolution plots), and downloadable data accessible via a web interface (https://polymerscholar.org).",
            "evaluation_or_validation_method": "NER evaluation via precision, recall, F1 using strict entity-level correctness; inter-annotator agreement metrics (Fleiss' Kappa and Cohen's Kappa) for annotation quality; baseline comparisons across multiple pre-trained encoders; qualitative validation of synthesized knowledge by reproducing known trends and comparison to manually curated datasets and domain literature (e.g., manual polymer solar cell data from prior work; comparisons to PoLyInfo scale).",
            "results_summary": "Pipeline extracted ≈300,000 material-property records from ≈130,000 abstracts in ~60 hours on a single Quadro 16GB GPU. The extracted database enabled recovery of established scientific trends (strength–ductility trade-off; polymer class differences in Tg, conductivity, tensile strength; device-specific relationships for solar cells, fuel cells, and supercapacitors), and temporal shifts (e.g., rise of non-fullerene acceptors). For NER, MaterialsBERT-based encoder achieved F1=66.4% on the polymer test set, and outperformed other BERT variants on multiple materials NER datasets.",
            "limitations_or_challenges": "Restricted to abstracts (no full-text, tables, or figures), so many data points in body/tables/images are missed; cross-sentence relation extraction and co-reference across figures/tables not solved; ontology omits measurement protocols/conditions which affect comparability; polymer-to-structure mapping (SMILES) not automated; rule-based record assembly can mis-associate entities; potential domain and platform biases inherent in corpus selection and keyword filtering.",
            "comparison_to_baselines_or_humans": "Compared algorithmic encoders (PubMedBERT, MatBERT, BioBERT, ChemBERT, BERT-base): pipeline using MaterialsBERT yielded higher NER performance on several datasets. Aggregated outputs qualitatively matched human-curated datasets and known published trends (demonstrated by direct comparison plots to manually extracted polymer solar cell metrics). The automatically extracted dataset size approaches that of a long-standing human-curated database (PoLyInfo), but with different coverage (abstract-only) and without structural mappings that manual curation sometimes provides.",
            "uuid": "e3850.1",
            "source_info": {
                "paper_title": "A general-purpose material property data extraction pipeline from large polymer corpora using natural language processing",
                "publication_date_yy_mm": "2022-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "ChemDataExtractor",
            "rating": 2
        },
        {
            "paper_title": "ChemSpot",
            "rating": 2
        },
        {
            "paper_title": "ChemicalTagger",
            "rating": 2
        },
        {
            "paper_title": "PubMedBERT",
            "rating": 2
        },
        {
            "paper_title": "MatBERT",
            "rating": 2
        },
        {
            "paper_title": "BioBERT",
            "rating": 2
        },
        {
            "paper_title": "ChemBERT",
            "rating": 2
        }
    ],
    "cost": 0.01079,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>A general-purpose material property data</h1>
<h2>extraction pipeline from large polymer corpora using Natural Language Processing</h2>
<p>Pranav Shetty, ${ }^{\dagger}$ Arunkumar Chitteth Rajan, ${ }^{\ddagger}$ Christopher Kuenneth, ${ }^{\ddagger}$ Sonakshi Gupta, ${ }^{\text {II }}$ Lakshmi Prerana Panchumarti, ${ }^{\ddagger}$ Lauren Holm, ${ }^{\ddagger}$ Chao Zhang, ${ }^{\dagger}$ and Rampi Ramprasad ${ }^{* \cdot \ddagger}$<br>$\dagger$ School of Computational Science $\mathcal{E}$ Engineering<br>$\ddagger$ School of Materials Science and Engineering, Georgia Institute of Technology, 771 Ferst Drive NW, Atlanta, Georgia 30332, USA<br>I Department of Metallurgy Engineering and Materials Science, Indian Institute of Technology, Indore<br>E-mail: rampi.ramprasad@mse.gatech.edu</p>
<h4>Abstract</h4>
<p>The ever-increasing number of materials science articles makes it hard to infer chemistry-structure-property relations from published literature. We used natural language processing (NLP) methods to automatically extract material property data from the abstracts of polymer literature. As a component of our pipeline, we trained MaterialsBERT, a language model, using 2.4 million materials science abstracts, which outperforms other baseline models in three out of five named entity recognition datasets when used as the encoder for text. Using this pipeline, we obtained $\sim 300,000$ material property records from $\sim 130,000$ abstracts in 60 hours. The extracted data was analyzed for a diverse range of applications such as fuel cells, supercapacitors, and polymer</p>
<p>solar cells to recover non-trivial insights. The data extracted through our pipeline is made available through a web platform at https://polymerscholar.org which can be used to locate material property data recorded in abstracts conveniently. This work demonstrates the feasibility of an automatic pipeline that starts from published literature and ends with a complete set of extracted material property information.</p>
<h1>Introduction</h1>
<p>The number of materials science papers published annually grows at the rate of $6 \%$ compounded annually. Quantitative and qualitative materials property information is locked away in these publications written in natural language that is not directly machine-readable. The explosive growth in published literature makes it harder to see quantitative trends by just directly analyzing large amounts of literature. Searching the literature for material systems that have desirable properties also becomes more challenging. Moreover, material information published in a non-machine-readable form contributes to data scarcity in the field of materials informatics where the training of property predictors requires painstaking manual curation of the data of interest from literature. Here, we propose adapting techniques for information extraction from the natural language processing (NLP) literature to address these issues.</p>
<p>Information extraction from the written text is well studied within NLP and involves several key components such as named entity recognition (NER), i.e., identifying categories to which words in the text belong; relation extraction, i.e., classifying relationships between extracted entities; co-referencing, i.e., identifying clusters of named entities in the text referring to the same object such as a polymer and its abbreviation, and named entity normalization, i.e. identifying all the variations in the name for an entity across a large number of documents. The idea of "self-supervised learning" through transformer-based models such as BERT, ${ }^{1,2}$ pre-trained on massive corpora of unlabeled text to learn contextual embeddings, is the dominant paradigm of information extraction today. A common architecture for NER</p>
<p>and relation extraction is to feed a labeled input to BERT and use the output vector embedding for each word along with the corresponding labels (which could be entity labels or relation labels) as inputs to a downstream machine learning model (typically a neural network) that learns to predict those labels. The tasks mentioned above are label intensive. Extending these methods to new domains requires labeling new data sets with ontologies that are tailored to the specific domain of interest.</p>
<p>ChemDataExtractor, ${ }^{3}$ ChemSpot, ${ }^{4}$ and ChemicalTagger ${ }^{5}$ are tools that perform NER to tag material entities. For example, ChemDataExtractor has been used to create a database of Neel temperatures and Curie temperatures that were automatically mined from literature. ${ }^{6}$ It has also been used to generate a literature extracted database of magnetocaloric materials and train property prediction models for key figures of merit. ${ }^{7}$ In the space of polymers, the authors of Ref. 8 used a semi-automated approach that crawled papers automatically and used students to extract the Flory-Huggins parameter (a measure of the affinity between two materials, eg., a polymer and a solvent). Word embedding approaches were used in Ref. 9 to generate entity-rich documents for human experts to annotate which were then used to train a polymer named entity tagger. Most previous NLP-based efforts in materials science have focused on inorganic materials but limited work has been done to address information extraction challenges in polymers. Polymers in practice have several non-trivial variations in name for the same material entity which requires polymer names to be normalized. Moreover, unlike inorganic entities, polymer names cannot typically be converted to SMILES strings that are usable for downstream machine learning but the SMILES strings must instead be inferred from figures in the paper that contain the corresponding structure.</p>
<p>Past work to automatically extract material property information from literature has focused on specific properties typically using keyword search methods or regular expressions. ${ }^{10}$ However, there are few solutions in the literature that address building general-purpose capabilities for extracting material property information, i.e., for any material property. Moreover, property extraction and analysis of polymers from a large corpus of literature has also</p>
<p>not yet been addressed. Automatically analyzing large materials science corpora has enabled many novel discoveries in recent years such as Ref. 11, where a literature extracted data set of zeolites was used to analyze interzeolite relations. Using word embeddings trained on such corpora has also been used to predict novel materials for certain applications in inorganics as well as polymers. ${ }^{12,13}$</p>
<p>In this work, we built a general-purpose pipeline for extracting material property data. Starting with a corpus of 2.4 million materials science papers described in Ref. 12, we selected 750 abstracts from the polymer domain and annotated each of the abstracts using our own ontology that was designed for the purpose of extracting information from materials science literature. Using these 750 annotated abstracts we trained an NER model, using our MaterialsBERT language model to encode the input text into vector representations. MaterialsBERT in turn was trained by starting from PubMedBERT, another language model, and using 2.4 million materials science abstracts to continue training the model. ${ }^{14}$ The trained NER model was applied to polymer abstracts and heuristic rules were used to combine the predictions of the NER model and obtain material property records from all polymer relevant abstracts. This pipeline is illustrated in Figure 1. We restricted our focus to abstracts as associating property value pairs with their corresponding materials is a more tractable problem in abstracts. We analyzed the data obtained using this pipeline for applications as diverse as polymer solar cells, fuel cells, and supercapacitors and showed that several known trends and phenomena in materials science can be inferred using this data. Moreover, we trained a machine learning predictor for the glass transition temperature using automatically extracted data (Supplementary Information Section S5).</p>
<p>This is the first work to build a general-purpose material property data extraction pipeline, for any material property. MaterialsBERT, the language model that powers our information extraction pipeline is released in order to enable the information extraction efforts of other materials researchers. We show that MaterialsBERT outperforms other similar BERT-based language models such as BioBERT ${ }^{15}$ and ChemBERT ${ }^{16}$ on three out of five</p>
<p>materials science NER data sets. The data extracted using this pipeline can be explored using a convenient web-based interface (https://www.polymerscholar.org) which can aid polymer researchers in locating material property information of interest to them.
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Pipeline used for extracting material property records from a corpus of abstracts</p>
<h1>Results</h1>
<h2>Abstract annotation</h2>
<p>Our ontology for extracting material property information consists of 8 entity types namely POLYMER, POLYMER_CLASS, PROPERTY_VALUE, PROPERTY_NAME, MONOMER, ORGANIC_MATERIAL, INORGANIC_MATERIAL, and MATERIAL_AMOUNT. For a detailed description of these entity types, see Table 1. This ontology captures the key pieces of information commonly found in abstracts and the information we wish to utilize</p>
<p>for downstream purposes. Note that, unlike some other studies, our ontology scheme does not annotate entities using the BIO tagging scheme, i.e., Beginning-Inside-Outside of the labeled entity. Instead, we opt to keep the labels simple and annotate only tokens belonging to our ontology and label all other tokens as 'OTHER'. This is because, as reported in Ref. 14, for BERT-based sequence labeling models, the advantage offered by explicit BIO tags is negligible and IO tagging schemes suffice. More detailed annotation guidelines are provided in the Supplementary Information Section S1. A corpus of 2.4 million materials science papers was filtered to obtain a dataset of abstracts that were polymer relevant and likely to contain the entity types of interest to us. We did so by filtering abstracts containing the string 'poly' to find polymer-relevant abstracts and used regular expressions to find abstracts that contained numeric information.</p>
<p>Using the above-described ontology, we annotated 750 abstracts and split the abstracts into $80 \%$ for training, $10 \%$ for validation, and $10 \%$ for testing. Prior to manual annotation, we pre-annotated the dataset using dictionaries of entities for the entity types where one was available. ${ }^{17}$ This was intended to speed up the annotation process. This dataset was annotated by three domain experts using the tool Prodigy (https://prodi.gy). Annotation was done over three rounds using a small sample of abstracts in each round. With each round, the annotation guidelines were refined and the abstracts in the previous rounds were re-annotated using the refined guidelines.</p>
<p>In order to assess the inter-annotator agreement between the three annotators, we use 10 common abstracts to measure Cohen's Kappa and Fleiss Kappa ${ }^{18}$ metrics. The Fleiss Kappa metric was computed to be 0.885 and the pairwise Cohen's Kappa metric to be (0.906, $0.864,0.887$ ) for each of the three pairs of annotators. These metrics are comparable to interannotator agreements reported elsewhere in the literature ${ }^{19}$ and indicate good homogeneity in the annotations.</p>
<p>Table 1: Description of each entity type in the ontology used for annotating polymer abstracts</p>
<table>
<thead>
<tr>
<th>Entity type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>POLYMER</td>
<td>Material entities that are polymers</td>
</tr>
<tr>
<td>ORGANIC_MATERIAL</td>
<td>Material entities that are organic but not polymers. Typically used as plasticizers or cross-linking agents</td>
</tr>
<tr>
<td>MONOMER</td>
<td>Material entities which are explicitly indicated as being the repeat units for a POLYMER entity</td>
</tr>
<tr>
<td>POLYMER_CLASS</td>
<td>Material entities that don’t refer to a specific chemical substance but are broad terms used for a class of polymers</td>
</tr>
<tr>
<td>INORGANIC_MATERIAL</td>
<td>Material entities which are inorganic and are typically used as additives in a polymer formulation</td>
</tr>
<tr>
<td>MATERIAL_AMOUNT</td>
<td>Entity type indicating the amount of a particular material in a material formulation</td>
</tr>
<tr>
<td>PROPERTY_NAME</td>
<td>Entity type for a material property</td>
</tr>
<tr>
<td>PROPERTY_VALUE</td>
<td>Entity type including a numeric value and its unit for a material property</td>
</tr>
<tr>
<td>OTHER</td>
<td>Default entity type used for all tokens that do not lie in any of the above categories</td>
</tr>
</tbody>
</table>
<p>NER model</p>
<p>The architecture used for training our NER model is depicted in Figure 2. BERT and BERT-based models have become the de-facto solutions for a large number of NLP tasks. ${ }^{1}$ It embodies the transfer learning paradigm in which a model is trained on a large amount of unlabeled text using unsupervised objectives (not shown in the figure). The resulting BERT encoder can be used to generate token embeddings for the input text that are conditioned on all other input tokens and hence are context-aware. We used a BERT-based encoder to generate representations for tokens in the input text as shown in Figure 2. The generated representations were used as inputs to a linear layer connected to a softmax non-linearity that predicted the entity type of each token. We used a number of different encoders and compared the performance of the resulting models on our dataset of annotated polymer</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Model architecture used for named entity recognition: Each token in the input sequence is converted to a contextual embedding by a pre-trained transformer model which is then input to a single layer neural network. The output of the neural network is the entity type of the input token.</p>
<p>abstracts. We compared these models for a number of different publicly available materials science datasets as well.</p>
<p>We used early stopping while training the NER model, i.e., the number of epochs of training was determined by the peak performance of the model on the validation set as evaluated after every epoch of training. We also fine-tuned PubMedBERT on the abstracts of the 2.4 million papers, referred to as MaterialsBERT. During fine-tuning, we load the model and weights of PubMedBERT and continue training using the unsupervised objectives that PubMedBERT was originally trained on. The text of our corpus of abstracts forms the unlabeled input to the model. This is one of the BERT-based encoders that we test.</p>
<h1>Evaluation methods</h1>
<p>The performance of the NER model is evaluated using precision, recall and F1 score of the predicted entity tag compared to the ground truth labels. These are defined as below:</p>
<p>$$
\begin{aligned}
\text { Precision } &amp; =\frac{T P}{T P+F P} \
\text { Recall } &amp; =\frac{T P}{T P+F N} \
F 1 &amp; =\frac{2 \times \text { Precision } \times \text { Recall }}{\text { Precision }+ \text { Recall }}
\end{aligned}
$$</p>
<p>where TP are the true positives, FP are the false positives and FN are the false negatives. Each of the above metrics is reported as a \% value. We consider a predicted label to be a true positive only when the label of a complete entity is predicted correctly. For instance, for the polymer 'polyvinyl ethylene', both 'polyvinyl' and 'ethylene' must be correctly labeled, else the entity is deemed to be predicted incorrectly.</p>
<h2>NER model performance</h2>
<p>Table 2: Performance of various pre-trained BERT-based encoders on the test set of polymer abstracts. Values are reported in \%</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Model</th>
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Recall</th>
<th style="text-align: center;">F1</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">MaterialsBERT (ours)</td>
<td style="text-align: center;">62.5</td>
<td style="text-align: center;">70.6</td>
<td style="text-align: center;">$\mathbf{6 6 . 4}$</td>
</tr>
<tr>
<td style="text-align: center;">PubMedBERT</td>
<td style="text-align: center;">61.4</td>
<td style="text-align: center;">70.7</td>
<td style="text-align: center;">65.8</td>
</tr>
<tr>
<td style="text-align: center;">MatBERT</td>
<td style="text-align: center;">60.9</td>
<td style="text-align: center;">70.1</td>
<td style="text-align: center;">65.2</td>
</tr>
<tr>
<td style="text-align: center;">BioBERT</td>
<td style="text-align: center;">59.2</td>
<td style="text-align: center;">66.3</td>
<td style="text-align: center;">62.6</td>
</tr>
<tr>
<td style="text-align: center;">ChemBERT</td>
<td style="text-align: center;">52.2</td>
<td style="text-align: center;">62.6</td>
<td style="text-align: center;">57.0</td>
</tr>
<tr>
<td style="text-align: center;">BERT-base</td>
<td style="text-align: center;">52.1</td>
<td style="text-align: center;">61.0</td>
<td style="text-align: center;">56.2</td>
</tr>
</tbody>
</table>
<p>The performance of various pre-trained BERT-based language models tested for training an NER model using our annotated data set of polymer abstracts is shown in Table 2. We observe that MaterialsBERT, the model fine-tuned by us on 2.4 million materials science</p>
<p>abstracts using PubMedBERT as the starting point, outperforms PubMedBERT as well as other language models used. This is in agreement with results previously reported where the fine-tuning of a transformer-based language model on a domain-specific corpus results in improved downstream task performance. ${ }^{14}$ Similar trends are observed across two of the four materials science data sets as reported in Table 3 and thus MaterialsBERT outperforms other pre-trained language models in three out of five materials science data sets. These NER datasets were chosen to span a range of subdomains within materials science, i.e., across organic and inorganic materials. A more detailed description of these NER datasets is provided in Supplementary Information Section S2. Note that all pre-trained encoders tested in Table 2 use the BERT-base architecture, differing in their weights and hence are comparable. MaterialsBERT outperforms PubMedBERT on all datasets except ChemDNER, which demonstrates that fine-tuning on a domain specific corpus indeed produces a performance improvement on downstream classification tasks. ChemBERT is BERT-base fine-tuned on a corpus of $\sim 400,000$ organic chemistry papers and also out-performs BERTbase ${ }^{1}$ across the NER data sets tested. BioBERT ${ }^{15}$ was trained by fine-tuning BERT-base using the PubMed corpus and thus has the same vocabulary as BERT-base in contrast to PubMedBERT which has a vocabulary specific to the biomedical domain. Ref. 21 describes the model MatBERT which was pre-trained from scratch using a corpus of 2 million materials science articles. Despite MatBERT being a model that was pre-trained from scratch, MaterialsBERT outperforms MatBERT on three out of five datasets. While the vocabulary of MatBERT and MaterialsBERT are both relevant to the domain of materials science, this performance difference can likely be attributed to the fact that PubMedBERT, the initial model for MaterialsBERT was pre-trained on a much larger corpus of text ( 14 million abstracts and full text). All experiments shown in Table 2 and Table 3 were performed by us. Note that we do not test BiLSTM-based architectures ${ }^{22}$ as past work has shown that BERT-based architectures typically outperform BiLSTM-based ones. ${ }^{14,16,21}$ The performance on MaterialsBERT for each entity type in our ontology is described in Supplementary</p>
<p>Information Section S3.
Table 3: Performance of various BERT based encoders on the test sets of publicly available materials science NER datasets. Values are reported in \%</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Pre-trained en- <br> coder</th>
<th style="text-align: center;">ChemDNER ${ }^{23}$</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Inorganic <br> sis recipes ${ }^{24}$</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Inorganic <br> stracts ${ }^{17}$</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Ab-</th>
<th style="text-align: center;">ChemRxnExtractor ${ }^{16}$</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">P</td>
<td style="text-align: center;">R</td>
<td style="text-align: center;">F1</td>
<td style="text-align: center;">P</td>
<td style="text-align: center;">R</td>
<td style="text-align: center;">F1</td>
<td style="text-align: center;">P</td>
<td style="text-align: center;">R</td>
<td style="text-align: center;">F1</td>
<td style="text-align: center;">P</td>
<td style="text-align: center;">R</td>
<td style="text-align: center;">F1</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">MaterialsBERT <br> (ours)</td>
<td style="text-align: center;">70.1</td>
<td style="text-align: center;">68.2</td>
<td style="text-align: center;">69.2</td>
<td style="text-align: center;">69.1</td>
<td style="text-align: center;">68.3</td>
<td style="text-align: center;">$\mathbf{6 8 . 6}$</td>
<td style="text-align: center;">85.3</td>
<td style="text-align: center;">86.7</td>
<td style="text-align: center;">86.0</td>
<td style="text-align: center;">73.5</td>
<td style="text-align: center;">69.5</td>
<td style="text-align: center;">$\mathbf{7 1 . 4}$</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">PubMedBERT</td>
<td style="text-align: center;">71.5</td>
<td style="text-align: center;">69.0</td>
<td style="text-align: center;">$\mathbf{7 0 . 2}$</td>
<td style="text-align: center;">69.9</td>
<td style="text-align: center;">65.3</td>
<td style="text-align: center;">67.6</td>
<td style="text-align: center;">84.0</td>
<td style="text-align: center;">86.2</td>
<td style="text-align: center;">85.0</td>
<td style="text-align: center;">68.1</td>
<td style="text-align: center;">59.5</td>
<td style="text-align: center;">63.6</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">MatBERT</td>
<td style="text-align: center;">71.7</td>
<td style="text-align: center;">66.9</td>
<td style="text-align: center;">69.2</td>
<td style="text-align: center;">68.6</td>
<td style="text-align: center;">67.7</td>
<td style="text-align: center;">68.2</td>
<td style="text-align: center;">85.6</td>
<td style="text-align: center;">86.7</td>
<td style="text-align: center;">86.2</td>
<td style="text-align: center;">67.4</td>
<td style="text-align: center;">58.0</td>
<td style="text-align: center;">62.4</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">BioBERT</td>
<td style="text-align: center;">70.6</td>
<td style="text-align: center;">65.7</td>
<td style="text-align: center;">68.0</td>
<td style="text-align: center;">64.4</td>
<td style="text-align: center;">63.7</td>
<td style="text-align: center;">64.0</td>
<td style="text-align: center;">85.6</td>
<td style="text-align: center;">87.1</td>
<td style="text-align: center;">$\mathbf{8 6 . 4}$</td>
<td style="text-align: center;">74.8</td>
<td style="text-align: center;">65.4</td>
<td style="text-align: center;">69.8</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">ChemBERT</td>
<td style="text-align: center;">72.5</td>
<td style="text-align: center;">66.4</td>
<td style="text-align: center;">69.4</td>
<td style="text-align: center;">66.8</td>
<td style="text-align: center;">64.3</td>
<td style="text-align: center;">65.6</td>
<td style="text-align: center;">83.2</td>
<td style="text-align: center;">86.4</td>
<td style="text-align: center;">84.8</td>
<td style="text-align: center;">65.0</td>
<td style="text-align: center;">64.0</td>
<td style="text-align: center;">64.4</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">BERT-base</td>
<td style="text-align: center;">71.2</td>
<td style="text-align: center;">65.7</td>
<td style="text-align: center;">68.4</td>
<td style="text-align: center;">62.4</td>
<td style="text-align: center;">60.3</td>
<td style="text-align: center;">61.4</td>
<td style="text-align: center;">81.0</td>
<td style="text-align: center;">81.9</td>
<td style="text-align: center;">81.4</td>
<td style="text-align: center;">57.7</td>
<td style="text-align: center;">54.9</td>
<td style="text-align: center;">56.2</td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<h1>Quantifying the extracted data</h1>
<p>Using our pipeline, we extracted $\sim 300,000$ material property records from $\sim 130,000$ abstracts. Out of our corpus of 2.4 million articles, $\sim 650,000$ abstracts are polymer relevant and around $\sim 130,000$ out of those contain material property data. This extraction process took 60 hours using a single Quadro 16 GB GPU. To place this number in context, PoLyInfo a comparable database of polymer property records that is publicly available has 492,645 property records as of this writing. ${ }^{25}$ This database was manually curated by domain experts over many years while the material property records we have extracted using automated methods took 2.5 days using only abstracts and is yet of comparable size. The composition of these material property records is summarized in Table 4 for specific properties (grouped into a few property classes) that are utilized later on. For the general property class, we compute the number of neat polymers as the material property records corresponding to a single material of the POLYMER entity type. Blends correspond to material property records with multiple POLYMER entities while composites contain at least one material</p>
<p>entity that is not of the POLYMER or POLYMER_CLASS entity type. To compute the number of unique neat polymer records, we first counted all unique normalized polymer names from records that had a normalized polymer name. This accounts for the majority of polymers with multiple reported names as detailed in Ref. 26. Out of the remaining neat polymer records that did not have a normalized polymer name, we then counted all unique polymer names (accounting for case variations) and added them to the number of unique normalized polymer names to arrive at the estimated number of unique polymers. The number of extracted data points reported in Table 4 is higher than the figures shown later as additional constraints are imposed in each case in order to better study this data. For the general property class, we note that elongation at break data for an estimated 413 unique neat polymers was extracted. In contrast, Ref. 27 used 77 polymers to train a machine learning model. For tensile strength, an estimated 926 unique neat polymer data points are extracted while Ref. 28 used 672 data points to train a machine learning model. Thus the amount of data extracted in the aforementioned cases is already comparable to or greater than the amount of data being utilized to train property predictors in the literature. Note that Table 4 accounts for only 39207 points which is 13 % of the total extracted material property records. More details on the extracted material property records can be found in Supplementary Information Section S4. The reader is also encouraged to explore this data further through https://polymerscholar.org</p>
<h3>General property class</h3>
<p>We now analyze the properties extracted class-by-class in order to study their qualitative trend. Figure 3 shows property data extracted for the five most common polymer classes in our corpus (columns) and four most commonly reported properties (rows). Polymer classes are groups of polymers that share certain chemical attributes such as functional groups. These properties fall under the general property class as described in Table 4. The data is extracted when a polymer of that polymer class is part of the formulation for which</p>
<p>Table 4: Number of material property records extracted for several key polymer properties and figures of merit for certain applications</p>
<table>
<thead>
<tr>
<th>Property class</th>
<th>Property</th>
<th>Total number of datapoints</th>
<th>neat polymers/ blends/ composites</th>
<th>Estimated number of unique neat polymers</th>
</tr>
</thead>
<tbody>
<tr>
<td>General</td>
<td>Molecular Weight</td>
<td>9053</td>
<td>9053/-/-</td>
<td>2623</td>
</tr>
<tr>
<td></td>
<td>Glass Transition Temperature</td>
<td>6155</td>
<td>4612/1036/507</td>
<td>1732</td>
</tr>
<tr>
<td></td>
<td>Electrical conductivity</td>
<td>6030</td>
<td>3202/606/2222</td>
<td>1017</td>
</tr>
<tr>
<td></td>
<td>Tensile Strength</td>
<td>4382</td>
<td>2679/651/1052</td>
<td>926</td>
</tr>
<tr>
<td></td>
<td>Elongation at Break</td>
<td>1499</td>
<td>954/234/311</td>
<td>413</td>
</tr>
<tr>
<td>Polymer Solar Cells</td>
<td>Power Conversion Efficiency</td>
<td>3595</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td></td>
<td>Open Circuit Voltage</td>
<td>1386</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td></td>
<td>Short Circuit Current</td>
<td>1049</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td></td>
<td>Fill Factor</td>
<td>966</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>Fuel Cells</td>
<td>Proton conductivity</td>
<td>1359</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td></td>
<td>Areal Power Density</td>
<td>1235</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td></td>
<td>Areal Current Density</td>
<td>295</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td></td>
<td>Methanol permeability</td>
<td>174</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>Supercapacitors</td>
<td>Gravimetric Energy Density</td>
<td>1131</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td></td>
<td>Gravimetric Power Density</td>
<td>898</td>
<td>-</td>
<td>-</td>
</tr>
</tbody>
</table>
<p>a property is reported and does not necessarily correspond to homopolymers but instead could correspond to blends or composites. The polymer class is “inferred” through the POLYMER_CLASS entity type in our ontology and hence must be mentioned explicitly for the materials record to be part of this plot. Several key trends are captured in this plot. From the glass transition temperature ($T_{\mathrm{g}}$) row, we observe that polyamides and polyimides typically have higher $T_{\mathrm{g}}$ than other polymer classes. Molecular weights unlike the other properties reported are not intrinsic material properties but are determined by processing parameters. The reported molecular weights are far more frequent at lower molecular weights than at higher molecular weights; mimicking a power-law distribution rather than Gaussian distribution. This is consistent with longer chains being more difficult to synthesize than</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Material property data extracted from abstracts for material systems that contain a polymer from the polymer classes of polyurethane, polyimide, polyamide, polyester, and polysiloxane in each corresponding column. These are the most commonly reported polymer classes and the properties reported are the most commonly reported properties.</p>
<p>shorter chains. For electrical conductivity, we find that polyimides have much lower reported values which is consistent with them being widely used as electrical insulators. Also note that polyimides have higher tensile strengths as compared to other polymer classes, which is a well-known property of polyimides. 29</p>
<p>Figure 4 shows mechanical properties measured for films which demonstrates the tradeoff between elongation at break and tensile strength that is well known for material systems (often called the strength-ductility trade-off dilemma). Materials with high tensile strength tend to have a low elongation at break and conversely, materials with high elongation at break tend to have low tensile strength. 30 This known fact about the physics of material systems</p>
<p>emerges from an amalgamation of points independently gathered from different papers. In the next section we take a closer look at pairs of properties for various devices that reveal similarly interesting trends.
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Tensile Strength Vs Elongation at break for films demonstrating the strengthductility trade-off</p>
<h1>Knowledge extraction</h1>
<p>Next, we consider a few device applications and co-relations between the most important properties reported for these applications to demonstrate that non-trivial insights can be obtained by analyzing this data. We consider three device classes namely polymer solar cells, fuel cells, and supercapacitors and show that their known physics is being reproduced by NLP extracted data. We find documents specific to these applications by looking for relevant keywords in the abstract such as 'polymer solar cell' or 'fuel cell'. The total number of data points for key figures of merit for each of these applications is given in Table 4.</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: Co-relations between key properties extracted automatically from literature for polymer solar cells a) Power Conversion Efficiency against short circuit current b) Power Conversion Efficiency against fill factor c) Power Conversion Efficiency against open circuit voltage. Co-relations between key properties extracted manually from literature for polymer solar cells d) Power Conversion Efficiency against short circuit current e) Power Conversion Efficiency against fill factor f) Power Conversion Efficiency against open circuit voltage. Observe that the trends in this figure match well with NLP extracted data in Figure 5. Reproduced here with permission from Ref. 31</p>
<h1>Polymer solar cells</h1>
<p>Polymer solar cells, in contrast to conventional silicon-based solar cells, have the benefit of lower processing cost but suffer from lower power conversion efficiencies. Improving their power conversion efficiency by varying the materials used in the active layer of the cell is an active area of research. ${ }^{32}$ Figure 5a)-c) shows the power conversion efficiency for polymer solar cells plotted against the corresponding short circuit current, fill factor and open circuit voltage for NLP extracted data while Figure 5d)-f) shows the same pairs of properties for data extracted manually as reported in Ref. 31. Each data point in Figure 5a)-c) is taken from a particular paper and corresponds to a single material system. It is clear from Figure 5(c) that the peak power conversion efficiencies reported are around $16.71 \%$ which is close to the maximum known values reported in the literature ${ }^{33}$ as of this writing. The open-circuit voltages (OCV) appear to be Gaussian distributed at around 0.85 V . Figure 5(a) shows a linear trend between short circuit current and power conversion efficiency. It is clear that the trends observed in Figure 5a)-c) for NLP extracted data are quite similar to the trends observed from manually curated data in Figure 5d)-f).</p>
<h2>Fuel Cells</h2>
<p>Fuel cells are devices that convert a stream of fuel such as methanol or hydrogen and oxygen to electricity. Water is one of the primary by-products of this conversion making this a clean source of energy. A polymer membrane is typically used as a separating membrane between the anode and cathodes in fuel cells. ${ }^{34}$ Improving the proton conductivity and thermal stability of this membrane to produce fuel cells with higher power density is an active area of research. Figure 6(a) and 6(b) show plots for fuel cells comparing pairs of key performance metrics. The points on the power density versus current density plot (Figure 6(a)) lie along the line with a slope of 0.4 V which is the typical operating voltage of a fuel cell under maximum current densities. ${ }^{35}$ Each point in this plot corresponds to a fuel cell system extracted from the literature that typically reports variations in the polymer membrane.</p>
<p>Figure 6(b) illustrates yet another use-case of this capability, i.e., to find material systems lying in a desirable range of property values for the more specific case of direct methanol fuel cells. For such fuel cell membranes, low methanol permeability is desirable in order to prevent the methanol fuel from crossing the membrane and poisoning the cathode side. ${ }^{36}$ High proton conductivity is simultaneously desirable. The box shown in the figure illustrates the desirable region and can thus be used to easily locate promising materials systems.
<img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6: Co-relations between key properties extracted automatically from literature for three different applications a) Areal current Density Vs Areal Power Density for fuel cells. the slope of the best bit line has a slope of 0.4 V which is the typical operating voltage of a fuel cell b) Proton Conductivity Vs Methanol permeability for fuel cells. The red box shows the desirable region of the property space c) Up-to-date Ragone plot for supercapacitors showing energy density Vs power density. d) Power Conversion Efficiency against time for fullerene acceptors and e) Power Conversion Efficiency against time for non-fullerene acceptors f) Trend of number of datapoints extracted by our pipeline over time. The dashed lines represent the number of papers published for each of the three applications in the plot and correspond to the dashed Y-axis.</p>
<h1>Trends across time</h1>
<p>We show that known trends across time in polymer literature are also being reproduced in our extracted data. A Ragone plot illustrates the trade-off between energy and power density for devices and supercapacitors are a class of devices that have high power density but low energy density. Figure 6(c) illustrates the trade-off between gravimetric energy density and gravimetric power density for supercapacitors and is effectively an up-to-date version of the Ragone plot for supercapacitors. ${ }^{37}$ Historically, in most Ragone plots, the energy density of supercapacitors ranges from 1 to $10 \mathrm{~Wh} / \mathrm{kg} .{ }^{38}$ However, this is no longer true as several recent papers have demonstrated energy densities of up to $100 \mathrm{~Wh} / \mathrm{kg} .{ }^{39-41}$ As seen in Figure 6(c), the majority of points beyond an energy density of $10 \mathrm{~Wh} / \mathrm{kg}$ are from the previous two years, i.e., 2020 and 2021.</p>
<p>Figure 6(d) and Figure 6(e) shows the evolution of power conversion efficiency of polymer solar cells for fullerene acceptors and non-fullerene acceptors. These are the two major classes of acceptors which along with a polymer donor form the active layer of a bulk heterojunction polymer solar cell. Observe that more papers with fullerene acceptors are found in earlier years with the number dropping in recent years while non-fullerene acceptor based papers have become more numerous with time. They also exhibit higher power conversion efficiencies than their fullerene counterparts in recent years. This is a known trend within the domain of polymer solar cells reported in Ref. 42. It is worth noting that the authors realized this trend by studying the NLP extracted data and then looking for references to corroborate this observation.</p>
<p>Figure 6(f) shows the number of datapoints extracted by our pipeline over time for the various categories described in Table 4. Observe that the number of datapoints of the general category have grown exponentially at a rate of $6 \%$ per year. Out of the three applications considered in Figure 6(f), polymer solar cells have historically had the largest number of papers as well as datapoints although that appears to be declining over the past few years. Observe that there is a decline in the number of datapoints as well as the number of papers</p>
<p>in 2020 and 2021. This is likely attributable to the COVID-19 pandemic ${ }^{43}$ which appears to have lead to a drop in the number of experimental papers published that form the input to our pipeline. ${ }^{44}$</p>
<h1>Discussion</h1>
<p>A natural language processing pipeline that extracts material property records from abstracts has been built and demonstrated. This however has some limitations in practice that we describe below:</p>
<ol>
<li>Materials property information is multi-modal and can be found in the text, tables, and figures in the body of the paper. Co-referencing material entity mentions across large spans of text and across figures and tables is a challenging problem. In addition to this, relation extraction of material entities and property value pairs occurring across sentences, are challenges that need to be addressed when extending this work from abstracts to full-text.</li>
<li>The current ontology used consists of the most important entity types found in materials science literature. This makes it easier to combine material and property information using heuristic rules but misses other information about the material property record such as measurement methods or measurement conditions which in most cases would influence the property value.</li>
<li>Converting polymer names to a structure (typically a SMILES string ${ }^{45}$ ) is also a bottleneck to training downstream models as this must be done manually. Tools that can reliably and robustly convert images of chemical structures found in the literature to SMILES string are an area of future work for the community. The SMILES string so generated can be used to generate a structural fingerprint vector of the polymer which in turn can serve as the input to a machine learning model. Expanding the scope of</li>
</ol>
<p>this pipeline to images in the body of the paper would allow training downstream property models without any additional curation for converting images to SMILES strings. Training robust property predictors in this manner would in turn allow the continuous and semi-automatic design of new materials, thus addressing a missing link in materials informatics. An example of manually converting polymer names to SMILES strings followed by the training of a property prediction model for glass transition temperature is shown in Supplementary Information Section S5.</p>
<p>The automated extraction of material property records enables researchers to search through literature with greater granularity and find materials systems in the range of interest. It also enables insights to be inferred by analyzing large amounts of literature that would not otherwise be possible. As shown in the section "Knowledge extraction", a diverse range of applications were analyzed using this workflow to reveal non-trivial albeit known insights. This is the first work to build a general purpose capability to extract material property records from published literature. $\sim 300,000$ material property records were extracted from $\sim 130,000$ polymer abstracts using this capability. Through our web interface (https://polymerscholar.org) the community can conveniently locate material property data published in abstracts. As part of this work, we also train and release MaterialsBERT, a language model that is fine-tuned on 2.4 million materials science abstracts using PubMedBERT as the starting point and obtains the best F1 score across three of five materials science NER data sets tested.</p>
<p>Growing the extracted material property data set further would require extending this capability to the body of the paper. This would require more robust methods to associate the entities extracted using named entity recognition. A few steps also remain in order to utilize the extracted data to produce trained machine learning property prediction models. The biggest bottleneck in the case of organic materials is obtaining SMILES strings for material entities which can then be used to generate structural fingerprints for downstream machine learning models. There is also a wealth of additional information such as processing</p>            </div>
        </div>

    </div>
</body>
</html>