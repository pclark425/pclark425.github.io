<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8855 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8855</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8855</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-154.html">extraction-schema-154</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated on strict logical reasoning tasks, including details about the models, the logical reasoning tasks or benchmarks, the methods or approaches used to improve logical reasoning, the performance or results, comparisons to baselines or ablations, and any reported limitations or failure cases.</div>
                <p><strong>Paper ID:</strong> paper-c58325547156a70cb27c148e5b57738ca9ce79aa</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/c58325547156a70cb27c148e5b57738ca9ce79aa" target="_blank">Testing the General Deductive Reasoning Capacity of Large Language Models Using OOD Examples</a></p>
                <p><strong>Paper Venue:</strong> Neural Information Processing Systems</p>
                <p><strong>Paper TL;DR:</strong> A new synthetic and programmable reasoning dataset is constructed that enables control over deduction rules and proof complexity and shows that large language models have difficulty generalizing to longer proofs, but are able to generalize to compositional proofs.</p>
                <p><strong>Paper Abstract:</strong> Given the intractably large size of the space of proofs, any model that is capable of general deductive reasoning must generalize to proofs of greater complexity. Recent studies have shown that large language models (LLMs) possess some abstract deductive reasoning ability given chain-of-thought prompts. However, they have primarily been tested on proofs using modus ponens or of a specific size, and from the same distribution as the in-context examples. To measure the general deductive reasoning ability of LLMs, we test on a broad set of deduction rules and measure their ability to generalize to more complex proofs from simpler demonstrations from multiple angles: depth-, width-, and compositional generalization. To facilitate systematic exploration, we construct a new synthetic and programmable reasoning dataset that enables control over deduction rules and proof complexity. Our experiments on four LLMs of various sizes and training objectives show that they are able to generalize to compositional proofs. However, they have difficulty generalizing to longer proofs, and they require explicit demonstrations to produce hypothetical subproofs, specifically in proof by cases and proof by contradiction.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8855.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8855.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated on strict logical reasoning tasks, including details about the models, the logical reasoning tasks or benchmarks, the methods or approaches used to improve logical reasoning, the performance or results, comparisons to baselines or ablations, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-3.5 (text-davinci-003)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>OpenAI instruction-tuned large Transformer LM (RLHF variant) used with chain-of-thought few-shot prompting; evaluated for deductive proof generation on a synthetic natural-language proof dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5 (text-davinci-003)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Instruction-tuned large autoregressive Transformer model from OpenAI (text-davinci-003 family), trained with human feedback / instruction tuning (RLHF); accessed via OpenAI API for experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>175B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>PRONTOQA-OOD</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>A synthetic, programmable dataset of natural-language deductive reasoning problems (extension of PrOntoQA) that requires generating full chain-of-thought proofs using a full set of propositional natural-deduction rules (implication elimination/modus ponens, conjunction introduction/elimination, disjunction introduction/elimination, proof by contradiction), with controllable proof depth, width, and compositional structure; outputs are evaluated by semantic-parsing CoTs to FOL and checking rulewise validity.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>8-shot chain-of-thought (CoT) in-context learning prompting; demonstrations varied (in-distribution vs out-of-distribution), use of distractor sentences in questions, formal semantic parsing of outputs to first-order logic for automated proof verification.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Best overall among evaluated models: highest proof-accuracy across many deduction rules and strongest compositional generalization. Able to generalize to compositional proofs and in several cases to unseen rules (via analogous rules like modus tollens). However accuracy degrades as proof depth increases and some rule-specific OOD deficits remain (see limitations). (Quantitative plots provided in paper; experiments run with 8-shot CoT, 100 trials per condition, 95% CIs reported.)</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared ID (in-demonstration) vs OOD (test rule absent from in-context demos) in 8-shot CoT prompts; GPT-3.5 outperformed other evaluated models (PaLM 540B, LLaMA 65B, FLAN-T5 11B). Ablations included removing distractors, replacing with irrelevant sentences, and changing in-context distribution; GPT-3.5 exhibited copying of distractors in some settings (worse when distractors present in test but not in demos). Also contrasted ICL behavior with supervised/gradient-based learning observations (ICL generalizes differently).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Fails or degrades on disjunction elimination (proof-by-cases) and proof-by-contradiction when those rules are not shown in-context (requires explicit demonstrations). Performance decreases with increasing proof depth (longer proofs), and some width-generalization limits (only GPT-3.5 generalized to larger widths for conjunction introduction). Occasional heuristic errors (e.g., copying distractors into CoT) and invalid single-step inferences resulting in incorrect final proofs; token-limit constrains maximal tested proof complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>insights_or_conclusions</strong></td>
                            <td>Chain-of-thought elicitation with diverse but simple in-context examples helps; explicit demonstrations are necessary for some less-familiar rules (disjunction elimination, contradiction). ICL generalizes differently from supervised learning — sometimes better to present simple, single-rule examples rather than complex compositional ones. Distractors can help prevent shortcut heuristics, but may also induce copying heuristics in some models (notably GPT-3.5). Model size alone does not fully predict performance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Testing the General Deductive Reasoning Capacity of Large Language Models Using OOD Examples', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8855.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8855.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated on strict logical reasoning tasks, including details about the models, the logical reasoning tasks or benchmarks, the methods or approaches used to improve logical reasoning, the performance or results, comparisons to baselines or ablations, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PaLM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PaLM 540B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Google's large-scale pathway-based language model; evaluated with 8-shot CoT on PRONTOQA-OOD for deductive proof generation and OOD generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>PaLM</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Large Transformer language model (Pathways Language Model) developed by Google; trained at scale using Pathways; evaluated via authors' independent experiments reported in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>540B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>PRONTOQA-OOD</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Synthetic deductive reasoning benchmark requiring generation of full natural-language proofs across a complete set of propositional natural-deduction rules, with controllable depth/width and composition.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>8-shot chain-of-thought in-context prompting; experiments compared ID vs OOD demonstration distributions, tested with/without distractors, and varied proof depth/width and compositionality.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Performed comparably to LLaMA 65B in many conditions despite larger size. Able to generalize compositionally in most experiments, but struggled when number of different rule types in a proof reached 4, and performance decreased with proof depth.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared ID vs OOD demonstration distributions; sometimes performed better in OOD than ID (indicating ICL behavior not simply matching training distribution). Compared with smaller models (LLaMA, FLAN-T5) and GPT-3.5 (which outperformed PaLM overall). Ablations included distractor/no-distractor and fixed-order vs random sentence order.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Difficulty generalizing to longer proofs (depth generalization degrades), and failure modes appear when proofs include multiple (4) distinct rule types; required demonstrations for some rules (disjunction elimination and proof-by-contradiction) to reach good performance.</td>
                        </tr>
                        <tr>
                            <td><strong>insights_or_conclusions</strong></td>
                            <td>Larger scale helps but is not sufficient; instructive/simple in-context examples and coverage of rule types improve generalization. ICL sometimes benefits from simpler/single-rule demonstrations rather than compositional in-context examples.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Testing the General Deductive Reasoning Capacity of Large Language Models Using OOD Examples', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8855.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8855.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated on strict logical reasoning tasks, including details about the models, the logical reasoning tasks or benchmarks, the methods or approaches used to improve logical reasoning, the performance or results, comparisons to baselines or ablations, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLaMA-65B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLaMA 65B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Meta's LLaMA family 65B-parameter open foundation model; evaluated on PRONTOQA-OOD for formal deductive reasoning using CoT prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA 65B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Open and efficient Transformer-based foundation language model (LLaMA) with 65B parameters; tested for deductive proof generation with 8-shot chain-of-thought prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>65B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>PRONTOQA-OOD</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Synthetic benchmark for generating verifiable natural-language proofs in propositional natural deduction with control over proof depth/width/compositionality.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>8-shot CoT in-context learning; evaluated across deduction-rule types, ID vs OOD demonstration distributions, distractor/no-distractor ablations, and depth/width sweeps.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>LLaMA-65B performed comparably to PaLM-540B despite being much smaller; capable of compositional generalization in most settings. Not as strong as GPT-3.5 overall.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared with PaLM, GPT-3.5, and FLAN-T5; ablations similar to other models (distractors, varying in-context distributions). Demonstrated that model size alone is not strongly correlated with proof performance.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Degrades with proof depth; struggles on certain combinations of rules and with rule types it has not seen in demonstrations (notably disjunction elimination and proof-by-contradiction without demos).</td>
                        </tr>
                        <tr>
                            <td><strong>insights_or_conclusions</strong></td>
                            <td>Instruction-tuning and pretraining regime matter; smaller models with appropriate tuning/longer pretraining can match larger ones on these reasoning tasks when combined with CoT prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Testing the General Deductive Reasoning Capacity of Large Language Models Using OOD Examples', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8855.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8855.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated on strict logical reasoning tasks, including details about the models, the logical reasoning tasks or benchmarks, the methods or approaches used to improve logical reasoning, the performance or results, comparisons to baselines or ablations, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FLAN-T5-11B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>FLAN-T5 11B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Instruction-finetuned T5-family model (11B) evaluated with chain-of-thought prompting for natural-language proof generation on PRONTOQA-OOD.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>FLAN-T5 11B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>An instruction-tuned variant of the T5 Transformer (FLAN family) with 11B parameters; designed for improved instruction-following. Evaluated with 8-shot CoT prompts in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>11B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>PRONTOQA-OOD</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Synthetic dataset for strict deductive reasoning in natural language; requires outputting full chain-of-thought proofs that are semantically parsed and formally verified.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>8-shot chain-of-thought in-context prompting; same evaluation and ablation paradigms as other models (ID vs OOD, distractors, depth/width variation).</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Weaker than the larger models overall: performed reasonably on implication elimination (modus ponens) and conjunction elimination, but failed to learn/use some other deduction rules reliably under CoT prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared against larger models (GPT-3.5, PaLM, LLaMA). Performance demonstrates that smaller/instruction-tuned models can handle some rules but fail on others; ablations show sensitivity to demonstration distribution and distractors.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Unable to reliably use several deduction rules (e.g., disjunction elimination, proof-by-contradiction) under the evaluated prompting; generalization to larger depth and various widths limited.</td>
                        </tr>
                        <tr>
                            <td><strong>insights_or_conclusions</strong></td>
                            <td>Instruction tuning helps with some rule types, but scale and pretraining still influence the breadth of deduction rules the model can reliably execute under CoT prompting; explicit demonstrations remain important for less-familiar rules.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Testing the General Deductive Reasoning Capacity of Large Language Models Using OOD Examples', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8855.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e8855.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated on strict logical reasoning tasks, including details about the models, the logical reasoning tasks or benchmarks, the methods or approaches used to improve logical reasoning, the performance or results, comparisons to baselines or ablations, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PRONTOQA-OOD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PRONTOQA-OOD (PrOntoQA-OOD)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A new synthetic, programmable dataset introduced in this paper for testing general deductive reasoning (rule coverage, depth, width, compositional generalization) with automated, formal CoT evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>PRONTOQA-OOD (dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>N/A (dataset/entity rather than a model).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>N/A</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>PRONTOQA-OOD</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Generative synthetic benchmark that produces natural-language deductive reasoning problems with controlled deduction rules (complete set for propositional natural deduction except implication introduction), adjustable proof depth and width, compositional proofs (recursive generation), and distractors; gold CoTs available; evaluation by semantic-parsing CoTs to FOL and checking each step against allowed deduction rules.</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Dataset generation uses natural-deduction rules, recursive compositional proof generation pseudocode, addition of distractors to avoid heuristics; evaluation pipeline semantically parses CoT sentences to FOL and checks stepwise validity and premise-following, producing an automated correctness metric for generated proofs.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>N/A (dataset); used to reveal model behaviors: CoT elicits compositional generalization in multiple LLMs, but OOD deficits exist for certain rules and for depth generalization. The dataset enabled quantitative comparisons in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared in paper to prior datasets (ProofWriter, PRONTOQA original, FOLIO, CLUTRR, LogiQA) via a table: PRONTOQA-OOD uniquely supports automated proof evaluation, contains multiple deduction rules, and tests depth, width, and compositional generalization with generation code provided.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Does not include some natural-deduction rules (implication introduction, some negation rules) because of natural-language representational limits; token limits in using LLM APIs constrain maximal proof complexity in experiments; synthetic nature uses fictional predicates to avoid pretrained knowledge leakage (but still may not reflect all real-world reasoning complexities).</td>
                        </tr>
                        <tr>
                            <td><strong>insights_or_conclusions</strong></td>
                            <td>A programmable synthetic benchmark with formal CoT evaluation is effective for probing LLM deductive capacities, revealing that CoT + ICL can elicit compositional reasoning but that explicit demos are needed for certain hypothetical reasoning patterns (proof-by-cases, contradiction) and that depth generalization remains challenging.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Testing the General Deductive Reasoning Capacity of Large Language Models Using OOD Examples', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Language models are greedy reasoners: A systematic formal analysis of chain-of-thought <em>(Rating: 2)</em></li>
                <li>Proofwriter: Generating implications, proofs, and abductive statements over natural language <em>(Rating: 2)</em></li>
                <li>FOLIO: natural language reasoning with first-order logic <em>(Rating: 2)</em></li>
                <li>Chain of thought prompting elicits reasoning in large language models <em>(Rating: 2)</em></li>
                <li>PaLM: Scaling language modeling with pathways <em>(Rating: 2)</em></li>
                <li>Training language models to follow instructions with human feedback <em>(Rating: 2)</em></li>
                <li>On the compositional generalization gap of in-context learning <em>(Rating: 1)</em></li>
                <li>Diverse demonstrations improve in-context compositional generalization <em>(Rating: 1)</em></li>
                <li>Exploring length generalization in large language models <em>(Rating: 1)</em></li>
                <li>INT: an inequality benchmark for evaluating generalization in theorem proving <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8855",
    "paper_id": "paper-c58325547156a70cb27c148e5b57738ca9ce79aa",
    "extraction_schema_id": "extraction-schema-154",
    "extracted_data": [
        {
            "name_short": "GPT-3.5",
            "name_full": "GPT-3.5 (text-davinci-003)",
            "brief_description": "OpenAI instruction-tuned large Transformer LM (RLHF variant) used with chain-of-thought few-shot prompting; evaluated for deductive proof generation on a synthetic natural-language proof dataset.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-3.5 (text-davinci-003)",
            "model_description": "Instruction-tuned large autoregressive Transformer model from OpenAI (text-davinci-003 family), trained with human feedback / instruction tuning (RLHF); accessed via OpenAI API for experiments.",
            "model_size": "175B",
            "reasoning_task_name": "PRONTOQA-OOD",
            "reasoning_task_description": "A synthetic, programmable dataset of natural-language deductive reasoning problems (extension of PrOntoQA) that requires generating full chain-of-thought proofs using a full set of propositional natural-deduction rules (implication elimination/modus ponens, conjunction introduction/elimination, disjunction introduction/elimination, proof by contradiction), with controllable proof depth, width, and compositional structure; outputs are evaluated by semantic-parsing CoTs to FOL and checking rulewise validity.",
            "method_or_approach": "8-shot chain-of-thought (CoT) in-context learning prompting; demonstrations varied (in-distribution vs out-of-distribution), use of distractor sentences in questions, formal semantic parsing of outputs to first-order logic for automated proof verification.",
            "performance": "Best overall among evaluated models: highest proof-accuracy across many deduction rules and strongest compositional generalization. Able to generalize to compositional proofs and in several cases to unseen rules (via analogous rules like modus tollens). However accuracy degrades as proof depth increases and some rule-specific OOD deficits remain (see limitations). (Quantitative plots provided in paper; experiments run with 8-shot CoT, 100 trials per condition, 95% CIs reported.)",
            "baseline_comparison": "Compared ID (in-demonstration) vs OOD (test rule absent from in-context demos) in 8-shot CoT prompts; GPT-3.5 outperformed other evaluated models (PaLM 540B, LLaMA 65B, FLAN-T5 11B). Ablations included removing distractors, replacing with irrelevant sentences, and changing in-context distribution; GPT-3.5 exhibited copying of distractors in some settings (worse when distractors present in test but not in demos). Also contrasted ICL behavior with supervised/gradient-based learning observations (ICL generalizes differently).",
            "limitations_or_failures": "Fails or degrades on disjunction elimination (proof-by-cases) and proof-by-contradiction when those rules are not shown in-context (requires explicit demonstrations). Performance decreases with increasing proof depth (longer proofs), and some width-generalization limits (only GPT-3.5 generalized to larger widths for conjunction introduction). Occasional heuristic errors (e.g., copying distractors into CoT) and invalid single-step inferences resulting in incorrect final proofs; token-limit constrains maximal tested proof complexity.",
            "insights_or_conclusions": "Chain-of-thought elicitation with diverse but simple in-context examples helps; explicit demonstrations are necessary for some less-familiar rules (disjunction elimination, contradiction). ICL generalizes differently from supervised learning — sometimes better to present simple, single-rule examples rather than complex compositional ones. Distractors can help prevent shortcut heuristics, but may also induce copying heuristics in some models (notably GPT-3.5). Model size alone does not fully predict performance.",
            "uuid": "e8855.0",
            "source_info": {
                "paper_title": "Testing the General Deductive Reasoning Capacity of Large Language Models Using OOD Examples",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "PaLM",
            "name_full": "PaLM 540B",
            "brief_description": "Google's large-scale pathway-based language model; evaluated with 8-shot CoT on PRONTOQA-OOD for deductive proof generation and OOD generalization.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "PaLM",
            "model_description": "Large Transformer language model (Pathways Language Model) developed by Google; trained at scale using Pathways; evaluated via authors' independent experiments reported in the paper.",
            "model_size": "540B",
            "reasoning_task_name": "PRONTOQA-OOD",
            "reasoning_task_description": "Synthetic deductive reasoning benchmark requiring generation of full natural-language proofs across a complete set of propositional natural-deduction rules, with controllable depth/width and composition.",
            "method_or_approach": "8-shot chain-of-thought in-context prompting; experiments compared ID vs OOD demonstration distributions, tested with/without distractors, and varied proof depth/width and compositionality.",
            "performance": "Performed comparably to LLaMA 65B in many conditions despite larger size. Able to generalize compositionally in most experiments, but struggled when number of different rule types in a proof reached 4, and performance decreased with proof depth.",
            "baseline_comparison": "Compared ID vs OOD demonstration distributions; sometimes performed better in OOD than ID (indicating ICL behavior not simply matching training distribution). Compared with smaller models (LLaMA, FLAN-T5) and GPT-3.5 (which outperformed PaLM overall). Ablations included distractor/no-distractor and fixed-order vs random sentence order.",
            "limitations_or_failures": "Difficulty generalizing to longer proofs (depth generalization degrades), and failure modes appear when proofs include multiple (4) distinct rule types; required demonstrations for some rules (disjunction elimination and proof-by-contradiction) to reach good performance.",
            "insights_or_conclusions": "Larger scale helps but is not sufficient; instructive/simple in-context examples and coverage of rule types improve generalization. ICL sometimes benefits from simpler/single-rule demonstrations rather than compositional in-context examples.",
            "uuid": "e8855.1",
            "source_info": {
                "paper_title": "Testing the General Deductive Reasoning Capacity of Large Language Models Using OOD Examples",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "LLaMA-65B",
            "name_full": "LLaMA 65B",
            "brief_description": "Meta's LLaMA family 65B-parameter open foundation model; evaluated on PRONTOQA-OOD for formal deductive reasoning using CoT prompts.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "LLaMA 65B",
            "model_description": "Open and efficient Transformer-based foundation language model (LLaMA) with 65B parameters; tested for deductive proof generation with 8-shot chain-of-thought prompts.",
            "model_size": "65B",
            "reasoning_task_name": "PRONTOQA-OOD",
            "reasoning_task_description": "Synthetic benchmark for generating verifiable natural-language proofs in propositional natural deduction with control over proof depth/width/compositionality.",
            "method_or_approach": "8-shot CoT in-context learning; evaluated across deduction-rule types, ID vs OOD demonstration distributions, distractor/no-distractor ablations, and depth/width sweeps.",
            "performance": "LLaMA-65B performed comparably to PaLM-540B despite being much smaller; capable of compositional generalization in most settings. Not as strong as GPT-3.5 overall.",
            "baseline_comparison": "Compared with PaLM, GPT-3.5, and FLAN-T5; ablations similar to other models (distractors, varying in-context distributions). Demonstrated that model size alone is not strongly correlated with proof performance.",
            "limitations_or_failures": "Degrades with proof depth; struggles on certain combinations of rules and with rule types it has not seen in demonstrations (notably disjunction elimination and proof-by-contradiction without demos).",
            "insights_or_conclusions": "Instruction-tuning and pretraining regime matter; smaller models with appropriate tuning/longer pretraining can match larger ones on these reasoning tasks when combined with CoT prompting.",
            "uuid": "e8855.2",
            "source_info": {
                "paper_title": "Testing the General Deductive Reasoning Capacity of Large Language Models Using OOD Examples",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "FLAN-T5-11B",
            "name_full": "FLAN-T5 11B",
            "brief_description": "Instruction-finetuned T5-family model (11B) evaluated with chain-of-thought prompting for natural-language proof generation on PRONTOQA-OOD.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "FLAN-T5 11B",
            "model_description": "An instruction-tuned variant of the T5 Transformer (FLAN family) with 11B parameters; designed for improved instruction-following. Evaluated with 8-shot CoT prompts in experiments.",
            "model_size": "11B",
            "reasoning_task_name": "PRONTOQA-OOD",
            "reasoning_task_description": "Synthetic dataset for strict deductive reasoning in natural language; requires outputting full chain-of-thought proofs that are semantically parsed and formally verified.",
            "method_or_approach": "8-shot chain-of-thought in-context prompting; same evaluation and ablation paradigms as other models (ID vs OOD, distractors, depth/width variation).",
            "performance": "Weaker than the larger models overall: performed reasonably on implication elimination (modus ponens) and conjunction elimination, but failed to learn/use some other deduction rules reliably under CoT prompting.",
            "baseline_comparison": "Compared against larger models (GPT-3.5, PaLM, LLaMA). Performance demonstrates that smaller/instruction-tuned models can handle some rules but fail on others; ablations show sensitivity to demonstration distribution and distractors.",
            "limitations_or_failures": "Unable to reliably use several deduction rules (e.g., disjunction elimination, proof-by-contradiction) under the evaluated prompting; generalization to larger depth and various widths limited.",
            "insights_or_conclusions": "Instruction tuning helps with some rule types, but scale and pretraining still influence the breadth of deduction rules the model can reliably execute under CoT prompting; explicit demonstrations remain important for less-familiar rules.",
            "uuid": "e8855.3",
            "source_info": {
                "paper_title": "Testing the General Deductive Reasoning Capacity of Large Language Models Using OOD Examples",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "PRONTOQA-OOD",
            "name_full": "PRONTOQA-OOD (PrOntoQA-OOD)",
            "brief_description": "A new synthetic, programmable dataset introduced in this paper for testing general deductive reasoning (rule coverage, depth, width, compositional generalization) with automated, formal CoT evaluation.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "PRONTOQA-OOD (dataset)",
            "model_description": "N/A (dataset/entity rather than a model).",
            "model_size": "N/A",
            "reasoning_task_name": "PRONTOQA-OOD",
            "reasoning_task_description": "Generative synthetic benchmark that produces natural-language deductive reasoning problems with controlled deduction rules (complete set for propositional natural deduction except implication introduction), adjustable proof depth and width, compositional proofs (recursive generation), and distractors; gold CoTs available; evaluation by semantic-parsing CoTs to FOL and checking each step against allowed deduction rules.",
            "method_or_approach": "Dataset generation uses natural-deduction rules, recursive compositional proof generation pseudocode, addition of distractors to avoid heuristics; evaluation pipeline semantically parses CoT sentences to FOL and checks stepwise validity and premise-following, producing an automated correctness metric for generated proofs.",
            "performance": "N/A (dataset); used to reveal model behaviors: CoT elicits compositional generalization in multiple LLMs, but OOD deficits exist for certain rules and for depth generalization. The dataset enabled quantitative comparisons in the paper.",
            "baseline_comparison": "Compared in paper to prior datasets (ProofWriter, PRONTOQA original, FOLIO, CLUTRR, LogiQA) via a table: PRONTOQA-OOD uniquely supports automated proof evaluation, contains multiple deduction rules, and tests depth, width, and compositional generalization with generation code provided.",
            "limitations_or_failures": "Does not include some natural-deduction rules (implication introduction, some negation rules) because of natural-language representational limits; token limits in using LLM APIs constrain maximal proof complexity in experiments; synthetic nature uses fictional predicates to avoid pretrained knowledge leakage (but still may not reflect all real-world reasoning complexities).",
            "insights_or_conclusions": "A programmable synthetic benchmark with formal CoT evaluation is effective for probing LLM deductive capacities, revealing that CoT + ICL can elicit compositional reasoning but that explicit demos are needed for certain hypothetical reasoning patterns (proof-by-cases, contradiction) and that depth generalization remains challenging.",
            "uuid": "e8855.4",
            "source_info": {
                "paper_title": "Testing the General Deductive Reasoning Capacity of Large Language Models Using OOD Examples",
                "publication_date_yy_mm": "2023-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Language models are greedy reasoners: A systematic formal analysis of chain-of-thought",
            "rating": 2
        },
        {
            "paper_title": "Proofwriter: Generating implications, proofs, and abductive statements over natural language",
            "rating": 2
        },
        {
            "paper_title": "FOLIO: natural language reasoning with first-order logic",
            "rating": 2
        },
        {
            "paper_title": "Chain of thought prompting elicits reasoning in large language models",
            "rating": 2
        },
        {
            "paper_title": "PaLM: Scaling language modeling with pathways",
            "rating": 2
        },
        {
            "paper_title": "Training language models to follow instructions with human feedback",
            "rating": 2
        },
        {
            "paper_title": "On the compositional generalization gap of in-context learning",
            "rating": 1
        },
        {
            "paper_title": "Diverse demonstrations improve in-context compositional generalization",
            "rating": 1
        },
        {
            "paper_title": "Exploring length generalization in large language models",
            "rating": 1
        },
        {
            "paper_title": "INT: an inequality benchmark for evaluating generalization in theorem proving",
            "rating": 1
        }
    ],
    "cost": 0.01515425,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Testing the General Deductive Reasoning Capacity of Large Language Models Using OOD Examples</h1>
<p>Abulhair Saparov ${ }^{\dagger}$ Richard Yuanzhe Pang ${ }^{\dagger}$ Vishakh Padmakumar ${ }^{\dagger}$ Nitish Joshi ${ }^{\dagger}$<br>Seyed Mehran Kazemi ${ }^{\Delta}$ Najoung Kim ${ }^{\Delta, \beta, <em>}$ He He ${ }^{\dagger, </em>}$<br>${ }^{\dagger}$ New York University, ${ }^{\Delta}$ Google, ${ }^{\beta}$ Boston University<br>as17582@nyu.edu</p>
<h4>Abstract</h4>
<p>Given the intractably large size of the space of proofs, any model that is capable of general deductive reasoning must generalize to proofs of greater complexity. Recent studies have shown that large language models (LLMs) possess some abstract deductive reasoning ability given chain-of-thought prompts. However, they have primarily been tested on proofs using modus ponens or of a specific size, and from the same distribution as the in-context examples. To measure the general deductive reasoning ability of LLMs, we test on a broad set of deduction rules and measure their ability to generalize to more complex proofs from simpler demonstrations from multiple angles: depth-, width-, and compositional generalization. To facilitate systematic exploration, we construct a new synthetic and programmable reasoning dataset that enables control over deduction rules and proof complexity. Our experiments on four LLMs of various sizes and training objectives show that they are able to generalize to compositional proofs. However, they have difficulty generalizing to longer proofs, and they require explicit demonstrations to produce hypothetical subproofs, specifically in proof by cases and proof by contradiction.</p>
<h2>1 Introduction</h2>
<p>In many tasks that require deductive reasoning, such as theorem proving or medical diagnosis, the complexity of proofs can grow without bound via the use of multiple deduction rules and the composition of subproofs. Given the large space of proofs, it is infeasible to find data to cover proofs of all sizes. Therefore, a general reasoning model must extrapolate to complex proofs from simpler ones. Recent work has shown that LLMs, combined with in-context learning (ICL) and chain-of-thought (CoT) prompting, are capable of deductive reasoning to an extent [Huang and Chang, 2022, Han et al., 2022, Wei et al., 2022b, Kojima et al., 2022, Lewkowycz et al., 2022, Nye et al., 2021, Gontier et al., 2020]. However, much of the prior work focused on a limited set of deduction rules such as modus ponens [Zhang et al., 2022a, Saparov and He, 2023, Tafjord et al., 2021]. In addition, the evaluation is in-demonstration, where the test example comes from the same distribution as the in-context demonstrations. In this work, we evaluate whether LLMs are capable of general deductive reasoning by measuring how well they generalize to proofs that are more complex</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: An overview of the kinds of OOD generalization that we test in our experiments. Each training example is a sample CoT demonstration provided to the LLM in the few-shot prompt, whereas each test example is a sample proof that the model is expected to output.
than their demonstrations. ${ }^{1}$
We characterize the complexity of proofs from three angles: the deduction rules involved, the depth of the proof (i.e. length of a sequential chain of proof steps), and the width of the proof (i.e. the number of premises of each proof step). Each of the three dimensions contributes to the overall size of the proof. To measure the general deductive reasoning ability of LLMs, we extend prior studies in two key ways. First, we determine whether LLMs have learned a complete set of deduction rules, beyond modus ponens. Second, we evaluate whether they can reason over longer proofs than those given as in-context examples (depth- and width- generalization); and whether they are able to use multiple different deduction rules in a single proof (compositional generalization). Figure 1 shows an overview of our study.</p>
<p>Our findings suggest that in-context learning is best applied to reasoning tasks by including examples that cover a diverse set of deduction rules, and keeping the examples simple. The in-context examples should especially contain examples of deduction rules that are less familiar to the model (i.e. proof by cases and proof by contradiction), and distractors should be provided for such examples as the model is more prone to overfitting.</p>
<p>We test four different LLMs of different scales and training objectives: GPT-3.5 175B [Ouyang et al., 2022], PaLM 540B [Chowdhery et al., 2022], LLaMA 65B [Touvron et al., 2023], and FLAN-T5 11B [Chung et al., 2022], and we find:</p>
<ol>
<li>CoT is able to elicit out-of-demonstration (OOD) reasoning in LLMs generalizing to compositional proofs. This is somewhat surprising given the amount of previous work that claim that LLMs are not able to generalize compositionally [Hosseini et al., 2022, An et al., 2023]. See Section 4.2.2 and Figure 6.</li>
<li>ICL generalizes differently compared to supervised learning (i.e. gradient descent on in-context examples). We find numerous examples where it is strictly worse to provide in-context examples from the same distribution as the test example. For instance, in some cases, we observe better generalization to compositional proofs when the in-context examples each contain individual deduction rules. See Sections 4.2.2 and 4.3, and Figures 6 and 8.</li>
<li>However, the LLMs cannot generalize to some deduction rules without explicit demonstrations, specifically, proof by cases and proof by contradiction, suggesting that pretraining is not sufficient to teach the model to generate hypothetical subproofs. See Section 4.2.1 and Figure 4.</li>
<li>Model size does not strongly correlate with performance. Smaller (but not the smallest) models with instruction tuning and longer pretraining perform comparably to larger models.
<sup id="fnref6:0"><a class="footnote-ref" href="#fn:0">1</a></sup></li>
</ol>
<table>
<thead>
<tr>
<th>Dataset</th>
<th>Automated evaluation of proofs</th>
<th>Contains proofs with multiple deduction rules</th>
<th>Tests proof depth generalization</th>
<th>Tests proof width generalization</th>
<th>Tests compositional generalization</th>
<th>Data generation code available</th>
</tr>
</thead>
<tbody>
<tr>
<td>CLUTRR <br> Sinha et al. [2019]</td>
<td>$\boldsymbol{x}$</td>
<td>$\sim$</td>
<td>$\boldsymbol{x}$</td>
<td>$\checkmark$</td>
<td>$\sim$</td>
<td>$\checkmark$</td>
</tr>
<tr>
<td>LogiQA Liu et al. [2020]</td>
<td>$\boldsymbol{x}$</td>
<td>$\checkmark$</td>
<td>$\sim$</td>
<td>$\sim$</td>
<td>$\sim$</td>
<td>human- <br> annotated</td>
</tr>
<tr>
<td>ProofWriter <br> Tafjord et al. [2021]</td>
<td>$\checkmark$</td>
<td>$\sim$</td>
<td>$\checkmark$</td>
<td>$\sim$</td>
<td>$\sim$</td>
<td>$\boldsymbol{x}$</td>
</tr>
<tr>
<td>FOLIO <br> Han et al. [2022]</td>
<td>$\boldsymbol{x}$</td>
<td>$\checkmark$</td>
<td>$\sim$</td>
<td>$\sim$</td>
<td>$\sim$</td>
<td>human- <br> annotated</td>
</tr>
<tr>
<td>PRONTOQA <br> Saparov and He [2023]</td>
<td>$\checkmark$</td>
<td>$\boldsymbol{x}$</td>
<td>$\checkmark$</td>
<td>$\boldsymbol{x}$</td>
<td>$\boldsymbol{x}$</td>
<td>$\checkmark$</td>
</tr>
<tr>
<td>PRONTOQA-OOD (this dataset)</td>
<td>$\checkmark$</td>
<td>$\checkmark$</td>
<td>$\checkmark$</td>
<td>$\checkmark$</td>
<td>$\checkmark$</td>
<td>$\checkmark$</td>
</tr>
</tbody>
</table>
<p>Table 1: Comparison of existing datasets to evaluate reasoning ability. Datasets marked with $\sim$ contain examples of varying width, depth, and compositionality, but these are not programmable (i.e. we cannot generate new examples controlling for these variables), and splitting the existing examples would produce highly imbalanced splits.</p>
<h1>2 Related work</h1>
<p>OOD generalization of LLMs. Previous work has measured the generalization ability of LLMs on tasks such as bit parity and Boolean variable assignment [Anil et al., 2022], semantic parsing [Hosseini et al., 2022, Qiu et al., 2022], deductive reasoning [Zhang et al., 2022a, Sanyal et al., 2022, Kazemi et al., 2023], and arithmetic reasoning [Kudo et al., 2023], where the length/complexity of the test example is greater than that of the in-context examples. On the bit parity and variable assignment tasks, LLMs are able to generalize to longer inputs with scratchpad prompting [Nye et al., 2021], but this generalization is imperfect, and accuracy still degrades with increasing input length. Generally, larger models tend to be better at generalization than smaller ones. The studies on reasoning were limited to reasoning using modus ponens. Wu et al. [2021] tests the OOD generalization of transformers and graph neural networks on symbolic mathematical reasoning. Our study more systematically examines OOD generalization of LLMs to larger proofs as well as to other deduction rules.</p>
<p>Evaluating reasoning abilities of LLMs. A number of recent studies measured the reasoning ability of LLMs [Huang and Chang, 2022, Han et al., 2022]. Table 1 provides a comparison of our proposed dataset to datasets from these studies. Many of these datasets are not amenable to automated evaluation of proofs, relying instead on measuring label accuracy. The datasets also do not test for proof width generalization and compositional generalization. Some datasets focus on a limited set of deduction rules, namely modus ponens. Our work is closest to PRONTOQA [Saparov and He, 2023] but extends it to a complete set of deduction rules and to compositional proofs.</p>
<p>Understanding in-context learning. Recent work has shed some light on ICL, and the mechanism by which the model learns from in-context examples. Akyürek et al. [2023], Dai et al. [2023], von Oswald et al. [2022] showed that transformers can learn in-context by performing gradient descent on in-context examples internally. Xie et al. [2022], Wang et al. [2023] show that LLMs exhibit behavior similar to that of topic models where their output is dependent on a latent topic, and the in-context examples help to specify the topic. Ye et al. [2022] demonstrated that ICL is more effective when the in-context examples are both diverse and relevant to the test example. An et al. [2023] and Levy et al. [2022] explored the effect of in-context demonstrations on compositional generalization, showing that it benefits from diverse and individually simple demonstrations. Our results contribute to this growing literature by showing that the generalization behavior in ICL is different from that of supervised learning, and so algorithms such as gradient descent are not the only mechanisms underlying ICL.</p>
<h2>3 Approach</h2>
<p>A programmable dataset. Our main evaluation approach is to prompt the LLM with simpler proofs and test it on proofs with greater depth and width, or with those using additional deduction rules. Therefore, we require a programmable approach to data generation, where the deduction rules</p>
<table>
<thead>
<tr>
<th>Deduction rule</th>
<th>Formal definition</th>
<th>Natural language example</th>
</tr>
</thead>
<tbody>
<tr>
<td>Implication elimination (i.e. modus ponens)</td>
<td>$\frac{f(a) \forall x(f(x) \rightarrow g(x))}{g(a)}$</td>
<td>"Alex is a cat. All cats are carnivores. Alex is a carnivore."</td>
</tr>
<tr>
<td>Conjunction introduction</td>
<td>$\frac{A \quad B}{A \wedge B}$</td>
<td>"Alex is a cat. Alex is orange. Alex is a cat and orange."</td>
</tr>
<tr>
<td>Conjunction elimination</td>
<td>$\frac{A \wedge B}{A}$</td>
<td>"Alex is a cat and orange. Alex is orange."</td>
</tr>
<tr>
<td>Disjunction introduction</td>
<td>$\frac{A}{A \vee B}$</td>
<td>"Alex is a cat. Alex is a cat or orange."</td>
</tr>
<tr>
<td>Disjunction elimination (i.e. proof by cases)</td>
<td>$\frac{A \vee B \quad A \vdash C \quad B \vdash C}{C}$</td>
<td>"Alex is a cat or a dog. Suppose Alex is a cat ...then Alex is warm-blooded. Suppose Alex is a dog ...then Alex is warm-blooded. Alex is warm-blooded."</td>
</tr>
<tr>
<td>Proof by contradiction</td>
<td>$\frac{A \vdash B \quad \neg B}{\neg A}$</td>
<td>"Alex is cold-blooded. If Alex is a mammal, Alex is not cold-blooded. Suppose Alex is a mammal. Alex is not cold-blooded. This contradicts with Alex is coldblooded. Alex is not a mammal."</td>
</tr>
</tbody>
</table>
<p>Table 2: An overview of the deduction rules in PrOntoQA-OOD. The notation $A \vdash B$ denotes entailment: that $B$ is provable from $A$.</p>
<div class="codehilite"><pre><span></span><code>    &quot;Alex is a dog. All dogs are mammals. Alex is a mammal. Alex is
    blue. All mean things are not blue. Suppose Alex is mean. Alex is
    not blue. This contradicts with Alex is blue. Therefore, Alex is
    not mean. Alex is a mammal and not mean.&quot;
</code></pre></div>

<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: An example of a compositional proof containing modus ponens, proof by contradiction, and conjunction introduction, shown in both natural language and a formal tree representation.
used, as well as the depth and width of each proof, are controllable parameters. To this end, we propose PrOntoQA-OOD, a generative process for synthetic reasoning questions. Each example in PrOntoQA-OOD contains a handful of premises, a query (the target fact to be proved/disproved), and a gold CoT containing the proof of the query. See Figure 10 for an example from this dataset. Specifically, we extend the PrOntoQA dataset [Saparov and He, 2023] that contains proofs generated from synthetic world models using modus ponens. (1) To evaluate reasoning using different deduction rules, we generate proofs with deduction rules for all connectives in propositional logic: conjunction $\wedge$, disjunction $\vee$, implication $\rightarrow$, and negation $\neg$. (2) To study width/depth generalization, the proof depth and width are controllable parameters in proof generation, where they control the number of generated deduction rules, and the number of premises in each deduction rule, respectively. (3) To study compositional generalization, we generate compositional proofs using a simple recursive procedure, where each proof contains multiple subproofs with distinct deduction rules.</p>
<p>Generating proofs with a complete set of deduction rules. We follow the deduction rules of natural deduction [Gentzen, 1935, Pfenning, 2004], a well-studied proof calculus with desirable completeness properties. ${ }^{2}$ Examples of each deduction rule are shown in Table 2. For each type of deduction rule, we randomly generate a proof that applies that rule (see details in section A.4. An example of a compositional proof is shown in Figure 2. To prevent LLMs from exploiting knowledge from pretraining to solve the problems without reasoning, we use fictional names for all concepts (e.g. "wumpus" instead of "cat" etc.).</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Varying proof width and depth. To characterize the size or complexity of each proof, we represent each proof as a tree (Figure 2), where each proof step corresponds to a node, and its premises correspond to the parent nodes. Then the size of the proof can be naturally described by the width and depth of this tree. When generating proofs, we control the depth by continuing to append proof steps until a proof of the desired depth is generated. The number of premises of deduction rules is set to the desired proof width.</p>
<p>Generating compositional proofs. To generate proofs combining many different types of deduction rules, we use a simple recursive procedure: (1) select a deduction rule uniformly at random, (2) select the premises for the selected rule, (3) recursively generate a subproof for each premise. See section A. 5 for details and pseudocode.</p>
<p>Adding distractors. One key challenge to OOD generalization is shortcut solutions. For example, given the facts "Alex is a cat," "All cats are feline," since there is no other fact of the form "All cats are...," the model can deterministically follow the only valid deduction and conclude "Alex is feline." To make the heuristics uninformative, we add distractor sentences. In the above case, a distractor sentence would be "All cats are graceful." Then the model is forced to choose the correct premise from two options for the next deduction step. See Section A. 7 for details on distractors for all deduction rules.</p>
<p>Formal evaluation of chain-of-thought. Unlike previous datasets that evaluate on a binary true/false answer, PRONTOQA-OOD requires LLMs to generate full proofs. ${ }^{3}$ Therefore, we need a way to evaluate the correctness of the output proofs directly. The sentences in PRONTOQA-OOD are syntactically simple and amenable to semantic parsing, which allows us to formally analyze each step in the CoT. To determine whether a predicted CoT is correct, we: (1) semantically parse each CoT sentence into first-order logic, (2) determine whether each logical form follows from previous logical forms via a rule of deduction, and (3) compute whether there exists a path of correct steps from the premises to the goal. An example of this process is shown below:</p>
<table>
<thead>
<tr>
<th style="text-align: center;">"Alex is a dog.</th>
<th style="text-align: center;">$\operatorname{dog}(\text { alex })$,</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">All dogs are mammals.</td>
<td style="text-align: center;">$\rightarrow \forall x(\operatorname{dog}(x) \rightarrow$ mammal $(x))$,</td>
<td style="text-align: center;">$\rightarrow \forall x(\operatorname{dog}(x) \rightarrow$ mammal $(x))$</td>
<td style="text-align: center;">$\operatorname{dog}($ alex $)$</td>
</tr>
<tr>
<td style="text-align: center;">Alex is a mammal."</td>
<td style="text-align: center;">mammal (al ex)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>Each proof step is considered correct if it is valid and if it immediately follows one of its premises. ${ }^{4}$ For further details see section A.6.</p>
<h1>4 Results</h1>
<p>In this section, we test existing LLMs on PrONTOQA-OOD and analyze whether they can produce longer and compositional proofs given simpler demonstrations. We experiment with a variety of models, with different sizes and training objectives, as shown in Figure 3. In all experiments, we use 8 -shot chain-of-thought prompting. ${ }^{5}$
We compare performance in two settings: (1) an in-demonstration (ID) setting where the 8 in-context demonstrations come from the same distribution as the test example, and (2) an out-of-demonstration (OOD) setting where the in-context demonstrations come from a distribution that is different from that of the test example. $95 \%$ confidence intervals are provided for all results.</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 4: (top) Proof accuracy across examples with different deduction rules. The in-context examples and test examples come from the same distribution. (bottom) Change in proof accuracy, where the test example is out-of-demonstration with respect to the in-context examples. That is, the test example has the specified deduction rule, but the in-context examples are uniformly distributed over all other deduction rules. See Figure 11 in the Appendix for the equivalent plot with absolute proof accuracy on the $y$-axis. See Figure 5 for an incorrect example. Implication elimination examples have proof width of 1 and depth of 2 . Conjunction introduction, conjunction elimination, and disjunction introduction examples have proof width 3 and depth 2. Disjunction elimination examples have proof width 3 and depth 1 . Proof by contradiction examples have proof width 2 and depth 1 .</p>
<div class="codehilite"><pre><span></span><code><span class="n">Prove</span><span class="o">:</span><span class="w"> </span><span class="n">Max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">gorpus</span><span class="o">.</span>
<span class="n">Predicted</span><span class="w"> </span><span class="n">answer</span><span class="o">:</span><span class="w"> </span><span class="n">Max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">tumpus</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">rompus</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">lempus</span><span class="o">.</span><span class="w"> </span><span class="n">Max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">tumpus</span><span class="o">.</span>
<span class="n">Tumpuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">wumpuses</span><span class="o">.</span><span class="w"> </span><span class="n">Max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">wumpus</span><span class="o">.</span><span class="w"> </span><span class="n">Rompuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">gorpuses</span><span class="o">.</span><span class="w"> </span><span class="n">Max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">gorpus</span><span class="o">.</span>
<span class="n">Max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">gorpus</span><span class="o">.</span>
<span class="n">Expected</span><span class="w"> </span><span class="n">answer</span><span class="o">:</span><span class="w"> </span><span class="n">Assume</span><span class="w"> </span><span class="n">Max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">tumpus</span><span class="o">.</span><span class="w"> </span><span class="n">Tumpuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">gorpuses</span><span class="o">.</span><span class="w"> </span><span class="n">Max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">gorpus</span><span class="o">.</span>
<span class="n">Assume</span><span class="w"> </span><span class="n">Max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">rompus</span><span class="o">.</span><span class="w"> </span><span class="n">Rompuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">gorpuses</span><span class="o">.</span><span class="w"> </span><span class="n">Max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">gorpus</span><span class="o">.</span>
<span class="n">Assume</span><span class="w"> </span><span class="n">Max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">lempus</span><span class="o">.</span><span class="w"> </span><span class="n">Lempuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">gorpuses</span><span class="o">.</span><span class="w"> </span><span class="n">Max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">gorpus</span><span class="o">.</span>
<span class="n">Since</span><span class="w"> </span><span class="n">Max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">tumpus</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">rompus</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">lempus</span><span class="o">,</span><span class="w"> </span><span class="n">Max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">gorpus</span><span class="o">.</span>
</code></pre></div>

<p>Figure 5: Example of an incorrect proof generated by GPT-3.5 on an out-of-demonstration disjunction elimination example. The premises (axioms) are given in blue, and invalid steps are given in red. For the full example, see Figure 14 in the Appendix.</p>
<h1>4.1 Can LLMs use deduction rules other than modus ponens?</h1>
<p>We first evaluate whether LLMs "know" all deduction rules (Table 2) when provided with corresponding CoT prompts. For each deduction rule, we independently and identically generate 8 in-context examples and one test example, and prompt the model to answer the test example. We run each experiment for 100 trials and measure the accuracy of the output proofs. The accuracies are shown in the top chart of Figure 4. We emphasize that the $\Delta$ proof accuracies in the bottom row of the figure should be interpreted in comparison with the accuracies in the top row (e.g. for some rules, the zero $\Delta$ accuracy for FLAN-T5 is due to zero absolute accuracy). For clarity, we provide the same plots using absolute accuracy rather than $\Delta$ accuracy in Section A.2.</p>
<p>In general, most models are able to use each deduction rule reasonably well, with GPT-3.5 performing the best. Similar to prior studies [Liang et al., 2022], we do not observe a strong correlation between model size and performance. LLaMA performs comparably to PaLM, despite being smaller. FLANT5 is smaller and performs reasonably on implication and conjunction elimination, but is not able to learn the other deduction rules.</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Prove: Polly is not a lempus.
<img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Predicted answer: Polly is a wumpus, a jompus, and a tumpus. Everything that is a wumpus, a jompus, and a tumpus is not a lempus. Polly is not a lempus.</p>
<p>Expected answer: Polly is a tumpus. Polly is a jompus. Polly is a wumpus. Polly is a wumpus and a jompus and a tumpus. Everything that is a wumpus, a jompus, and a tumpus is not a lorpus. Polly is not a lorpus.
Assume Polly is a lempus. Each lempus is an impus and a lorpus and a rompus. Polly is an impus and a lorpus and a rompus. Polly is a lorpus. This contradicts with Polly is not a lorpus. Polly is not a lempus.</p>
<p>Figure 6: (top-left) Proof accuracy on compositional examples where the in-context examples are also compositional examples with the same min depth and number of rule types. (bottom-left) Change in proof accuracy where the test examples are compositional but the in-context examples are those of individual deduction rules. See Figure 12 in the Appendix for the equivalent plot with absolute proof accuracy on the y-axis. (right) Example of an incorrect proof generated by GPT-3.5 on an out-of-demonstration example with min depth 2 and 4 rule types. The premises (axioms) are given in blue, and invalid steps are given in red. For the full example, see Figure 15 in the Appendix.</p>
<h1>4.2 Out-of-demonstration generalization</h1>
<h3>4.2.1 Can LLMs generalize to unseen deduction rules?</h3>
<p>While the above results show that LLMs are able to reason with a variety of deduction rules, it is unclear whether the ability is learned from in-context examples or elicited from pretraining. We test the LLM with examples where the test proof requires a deduction rule that does not appear in the in-context examples (i.e. for each in-context example, we sample a deduction rule uniformly at random from the set of deduction rules excluding that of the test example). Our intuition was that LLMs would not be able to use deduction rules unless given explicit demonstrations thereof (aside from those like modus ponens which are well-represented in pretraining). The change in proof accuracy relative to the ID setting is shown in the bottom chart of Figure 4. Evidently, the models are able to use four deduction rules despite not being shown an in-context example with those rules: both conjunction rules, disjunction introduction, and (somewhat) implication elimination. GPT-3.5 was additionally able to use proof by contradiction by relying on an alternate deduction rule called modus tollens (i.e. given $\neg f(c)$ and $\forall x(g(c) \rightarrow f(c))$, conclude $\neg g(c)$ ). This is in contrast with McKenzie et al. [2022] which showed that reasoning with modus tollens exhibited inverse scaling behavior, and yet GPT-3.5 is able to use it correctly without any demonstrations. However, Wei et al. [2022a] has shown that when trained with additional compute, models are able to perform modus tollens. GPT-3.5 performed worse on disjunction elimination possibly due to the fact that there is no equivalent alternate rule (an example of an error is given in figure 5). However, no model is able to use disjunction elimination and proof by contradiction without demonstrations.</p>
<h3>4.2.2 Can LLMs generalize to compositional proofs?</h3>
<p>Next, we test whether the model is able to generalize to compositional proofs that contain multiple different deduction rules. In the ID setting, the in-context examples and test examples are both generated from the same distribution of compositional proofs. In the OOD setting, the in-context demonstrations contain non-compositional examples of each rule that appears in the test example. In Figure 6, in all but three experiments, we observe that the gap in proof accuracy between the ID and OOD settings is close to zero, indicating that the models are able to generalize compositionally</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 7: (top row) Proof accuracy vs proof depth of test examples, where in-context examples have fixed proof depth 2. (bottom row) Proof accuracy vs proof width of test examples, where in-context examples have fixed proof width 2. Dashed lines indicate in-distribution accuracy, where the depth and width of the in-context examples are the same as that of the text-examples. In these experiments, there are 4 rather than 8 in-context examples.
to an extent. This is surprising since past studies show that LLMs struggle with compositional generalization, but this could be due to the fact that much of the previous work focused on semantic parsing rather than on reasoning. But there is prior work showing that models can generalize compositionally in some settings, such as in Hosseini et al. [2022] (see Figure 4) and in Press et al. [2022] (see Figure 6). In addition, our study is limited by the token limit of the LLMs, as we are not able to further increase the complexity of the proofs without reducing the number of in-context examples, which would render the results difficult to compare. GPT-3.5 and PALM have difficulty when the number of rule types is 4 , with an example of an incorrect output given in the right side of Figure 6. Interestingly, PaLM, LLAMA, and FLAN-T5 sometimes perform better in the OOD setting than in the ID setting, showing that, in ICL, it is not always best to provide demonstrations from the same distribution as the test example.</p>
<h1>4.2.3 Can LLMs generalize to bigger proofs?</h1>
<p>To test whether LLMs can generalize to bigger proofs, we test the models on examples where the proof width or depth is larger than those of the in-context examples. As is evident from Figure 7, when shown demonstrations of proofs of depth 2, the models' performance decreases with increasing depth. But this is due to the increase in the inherent difficulty of the task, as both ID and OOD accuracies decrease with increasing depth. Though the notable exception is GPT-3.5 on conjunction elimination, where ID accuracy remains high as OOD accuracy decreases. Models are able to generalize better with increasing proof width on conjunction elimination, possibly because there are ample examples of long conjunctions in natural language, but only GPT-3.5 is able to generalize to greater proof widths on conjunction introduction.</p>
<h3>4.3 Do distractors help OOD generalization?</h3>
<p>In supervised learning, one challenge to OOD generalization is spurious correlations [Zhang et al., 2022b]. Intuitively, if ICL were to behave like supervised learning on in-context examples [Akyürek et al., 2023, Dai et al., 2023, von Oswald et al., 2022], we would expect that without distractors, the models would overfit to the in-context examples and perform poorly on OOD examples. An example where distractors hurt generalization is shown in Figure 9 where GPT-3.5 copies many of the distractor sentences into the output, likely due to the fact that it has learned to apply a copying heuristic from the in-context demonstrations. It seems only GPT-3.5 acquires these heuristics in implication and disjunction elimination. Surprisingly, this is not the case for all deduction rules, as is</p>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 8: (top) Proof accuracy on examples where both the in-context examples and test examples have distractors. Sentences in all questions are ordered randomly. (middle) Proof accuracy when distractors are removed from the in-context examples, but not from the test examples. The sentences of the in-context questions have a fixed order (corresponding to a postorder traversal of the ontology tree), whereas the sentences in the test question have random order. See Figure 13 in the Appendix for the equivalent plot with absolute proof accuracy on the y-axis. (bottom) The same setting as (middle) except the distractors in the in-context examples are instead replaced with irrelevant sentences. Implication elimination examples have proof width of 1 and depth of 2. Conjunction introduction, conjunction elimination, and disjunction introduction examples have proof width 2 and depth 2. Disjunction elimination examples have proof width 3 and depth 1. Proof by contradiction examples have proof width 2 and depth 1.</p>
<div class="codehilite"><pre><span></span><code><span class="n">Prove</span><span class="o">:</span><span class="w"> </span><span class="n">Sally</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">dull</span><span class="o">.</span>
<span class="n">Predicted</span><span class="w"> </span><span class="n">answer</span><span class="o">:</span><span class="w"> </span><span class="n">Sally</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="n">impus</span><span class="o">.</span><span class="w"> </span><span class="n">Impuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">sterpuses</span><span class="o">.</span><span class="w"> </span><span class="n">Every</span><span class="w"> </span><span class="n">grimpus</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span>
<span class="n">zumpus</span><span class="o">.</span><span class="w"> </span><span class="n">Every</span><span class="w"> </span><span class="n">brimpus</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">grimpus</span><span class="o">.</span><span class="w"> </span><span class="n">Lorpuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">dumpuses</span><span class="o">.</span><span class="w"> </span><span class="n">Brimpuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">vumpuses</span><span class="o">.</span>
<span class="n">Every</span><span class="w"> </span><span class="n">lorpus</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">brimpus</span><span class="o">.</span><span class="w"> </span><span class="n">Sally</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">brimpus</span><span class="o">.</span><span class="w"> </span><span class="n">Each</span><span class="w"> </span><span class="n">vumpus</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">opaque</span><span class="o">.</span><span class="w"> </span><span class="n">Each</span><span class="w"> </span><span class="n">dumpus</span>
<span class="k">is</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">brown</span><span class="o">.</span><span class="w"> </span><span class="n">Every</span><span class="w"> </span><span class="n">grimpus</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">dull</span><span class="o">.</span><span class="w"> </span><span class="n">Sally</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">grimpus</span><span class="o">.</span><span class="w"> </span><span class="n">Sally</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">dull</span><span class="o">.</span>
<span class="n">Expected</span><span class="w"> </span><span class="n">answer</span><span class="o">:</span><span class="w"> </span><span class="n">Sally</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">brimpus</span><span class="o">.</span><span class="w"> </span><span class="n">Every</span><span class="w"> </span><span class="n">brimpus</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">grimpus</span><span class="o">.</span><span class="w"> </span><span class="n">Sally</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span>
<span class="n">grimpus</span><span class="o">.</span><span class="w"> </span><span class="n">Each</span><span class="w"> </span><span class="n">grimpus</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">dull</span><span class="o">.</span><span class="w"> </span><span class="n">Sally</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">dull</span><span class="o">.</span>
</code></pre></div>

<p>Figure 9: Example of an incorrect proof generated by GPT-3.5 on an OOD implication elimination example where the in-context demonstrations have no distractors, but the test example does. The premises (axioms) are given in blue, and invalid steps are given in red. For the full example, see Figure 16 in the Appendix.
visible in Figure 8. The models' performance is largely unaffected, with the exception of a few rules for specific models. This is in stark contrast to supervised learning, where it is always best to train on examples from the same distribution as the test example.</p>
<h1>5 Conclusion and future work</h1>
<p>In this study, we provide a systematic test of the general deductive reasoning capabilities of LLMs, specifically measuring their rule-, depth-, width-, and compositional generalization abilities. We found that LLMs exhibit mixed generalization to unseen deduction rules, but they exhibit more robust generalization to compositional proofs than previously suggested.</p>
<p>One important future direction is to better understand the mechanism of ICL and CoT prompting. We found that in many cases, for a given test example, the best in-context examples were drawn from a distribution distinct from that of the test example. This is not explained by existing theories of Bayesian inference [Xie et al., 2022] or gradient descent [Akyürek et al., 2023, Dai et al., 2023, von Oswald et al., 2022]. Are simpler examples better even if the test example is fairly complex? Should we include examples with a diverse set of deduction rules [Levy et al., 2022]? Or should the in-context examples focus on rules for which the model's OOD generalization is poor? Further study is needed to better characterize generalization from in-context examples.</p>
<h1>Reproducibility statement</h1>
<p>For the sake of reproducibility of the analysis, model outputs (except those of PaLM), code for data generation, and analysis code are freely available with a permissive open-source license at github.com/asaparov/prontoqa. The generated data for all experiments in this paper is available in the file generated_ood_data.zip. The command python make_plots.py produces all figures used in this paper. GPT-3.5 experiments were run using the OpenAI API with the model text-davinci-003 on April $20^{\text {th }}-23^{\text {rd }}, 2023$. Experiments for Figure 7 and the bottom row of Figure 8 were run on August $3^{\text {rd }}-7^{\text {th }}, 2023$.</p>
<h2>Acknowledgements</h2>
<p>We thank Tania Bedrax-Weiss, Xin Xu, and Deepak Ramachandran for their valuable feedback. This work was supported by Open Philanthropy, AWS AI, Samsung Advanced Institute of Technology (under the project Next Generation Deep Learning: From Pattern Recognition to AI), and in part through the NYU IT High Performance Computing resources, services, and staff expertise. NJ is supported by an NSF Graduate Research Fellowship under grant number 1839302.</p>
<h2>References</h2>
<p>Ekin Akyürek, Dale Schuurmans, Jacob Andreas, Tengyu Ma, and Denny Zhou. What learning algorithm is in-context learning? Investigations with linear models. In The Eleventh International Conference on Learning Representations, 2023. URL https://openreview.net/forum?id= 0g0X4H8yN4I.</p>
<p>Shengnan An, Zeqi Lin, Qiang Fu, Bei Chen, Nanning Zheng, Jian-Guang Lou, and Dongmei Zhang. How do in-context examples affect compositional generalization? CoRR, abs/2305.04835, 2023. URL https://arxiv.org/abs/2305.04835.</p>
<p>Cem Anil, Yuhuai Wu, Anders Andreassen, Aitor Lewkowycz, Vedant Misra, Vinay V. Ramasesh, Ambrose Slone, Guy Gur-Ari, Ethan Dyer, and Behnam Neyshabur. Exploring length generalization in large language models. CoRR, abs/2207.04901, 2022. doi: 10.48550/arXiv.2207.04901. URL https://doi.org/10.48550/arXiv. 2207.04901.</p>
<p>Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. Palm: Scaling language modeling with pathways. CoRR, abs/2204.02311, 2022. doi: 10.48550/arXiv.2204.02311. URL https://doi.org/10.48550/arXiv.2204.02311.</p>
<p>Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Y. Zhao, Yanping Huang, Andrew M. Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and Jason Wei. Scaling instructionfinetuned language models. CoRR, abs/2210.11416, 2022. doi: 10.48550/arXiv.2210.11416. URL https://doi.org/10.48550/arXiv.2210.11416.</p>
<p>Damai Dai, Yutao Sun, Li Dong, Yaru Hao, Zhifang Sui, and Furu Wei. Why can gpt learn incontext? language models secretly perform gradient descent as meta optimizers. In Findings of the Association for Computational Linguistics: ACL 2023, Toronto, Canada, 2023. Association for Computational Linguistics.
G. Gentzen. Untersuchungen über das logische schließen i. Mathematische Zeitschrift, 39:176-210, 1935.</p>
<p>Nicolas Gontier, Koustuv Sinha, Siva Reddy, and Christopher Pal. Measuring systematic generalization in neural proof generation with transformers. In Hugo Larochelle, Marc'Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin, editors, Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, 2020. URL https://proceedings.neurips. cc/paper/2020/hash/fc84ad56f9f547eb89c72b9bac209312-Abstract.html.</p>
<p>Simeng Han, Hailey Schoelkopf, Yilun Zhao, Zhenting Qi, Martin Riddell, Luke Benson, Lucy Sun, Ekaterina Zubova, Yujie Qiao, Matthew Burtell, David Peng, Jonathan Fan, Yixin Liu, Brian Wong, Malcolm Sailor, Ansong Ni, Linyong Nan, Jungo Kasai, Tao Yu, Rui Zhang, Shafiq R. Joty, Alexander R. Fabbri, Wojciech Kryscinski, Xi Victoria Lin, Caiming Xiong, and Dragomir Radev. FOLIO: natural language reasoning with first-order logic. CoRR, abs/2209.00840, 2022. doi: 10.48550/arXiv.2209.00840. URL https://doi.org/10.48550/arXiv.2209.00840.</p>
<p>Arian Hosseini, Ankit Vani, Dzmitry Bahdanau, Alessandro Sordoni, and Aaron C. Courville. On the compositional generalization gap of in-context learning. In Jasmijn Bastings, Yonatan Belinkov, Yanai Elazar, Dieuwke Hupkes, Naomi Saphra, and Sarah Wiegreffe, editors, Proceedings of the Fifth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP, BlackboxNLP@EMNLP 2022, Abu Dhabi, United Arab Emirates (Hybrid), December 8, 2022, pages 272-280. Association for Computational Linguistics, 2022. URL https: //aclanthology.org/2022.blackboxnlp-1.22.</p>
<p>Jie Huang and Kevin Chen-Chuan Chang. Towards reasoning in large language models: A survey. CoRR, abs/2212.10403, 2022. doi: 10.48550/arXiv.2212.10403. URL https://doi.org/10. 48550/arXiv. 2212.10403.</p>
<p>Seyed Mehran Kazemi, Najoung Kim, Deepti Bhatia, Xin Xu, and Deepak Ramachandran. LAMBADA: backward chaining for automated reasoning in natural language. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics, Toronto, Canada, July 2023. Association for Computational Linguistics.</p>
<p>Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large language models are zero-shot reasoners. In Advances in Neural Information Processing Systems, 2022. URL http://papers.nips.cc/paper_files/paper/2022/hash/ 8bb0d291acd4acf06ef112099c16f326-Abstract-Conference.html.</p>
<p>Keito Kudo, Yoichi Aoki, Tatsuki Kuribayashi, Ana Brassard, Masashi Yoshikawa, Keisuke Sakaguchi, and Kentaro Inui. Do deep neural networks capture compositionality in arithmetic reasoning? In Andreas Vlachos and Isabelle Augenstein, editors, Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2023, Dubrovnik, Croatia, May 2-6, 2023, pages 1343-1354. Association for Computational Linguistics, 2023. URL https://aclanthology.org/2023.eacl-main. 98.</p>
<p>Itay Levy, Ben Bogin, and Jonathan Berant. Diverse demonstrations improve in-context compositional generalization. CoRR, abs/2212.06800, 2022. doi: 10.48550/arXiv.2212.06800. URL https: //doi.org/10.48550/arXiv.2212.06800.</p>
<p>Aitor Lewkowycz, Anders Johan Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay Venkatesh Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, Yuhuai Wu, Behnam Neyshabur, Guy Gur-Ari, and Vedant Misra. Solving quantitative reasoning problems with language models. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, Advances in Neural Information Processing Systems, 2022. URL https://openreview. net/forum?id=IFXTZERXdM7.</p>
<p>Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, Benjamin Newman, Binhang Yuan, Bobby Yan, Ce Zhang, Christian Cosgrove, Christopher D. Manning, Christopher Ré, Diana Acosta-Navas, Drew A. Hudson, Eric Zelikman, Esin Durmus, Faisal Ladhak, Frieda Rong, Hongyu Ren, Huaxiu Yao, Jue Wang, Keshav Santhanam, Laurel J. Orr, Lucia Zheng, Mert Yüksekgönül, Mirac Suzgun, Nathan Kim, Neel Guha, Niladri S. Chatterji, Omar Khattab, Peter Henderson, Qian Huang, Ryan Chi, Sang Michael Xie, Shibani Santurkar, Surya Ganguli, Tatsunori Hashimoto, Thomas Icard, Tianyi Zhang, Vishrav Chaudhary, William Wang, Xuechen Li, Yifan Mai, Yuhui Zhang, and Yuta Koreeda. Holistic evaluation of language models. CoRR, abs/2211.09110, 2022. doi: 10.48550/arXiv.2211.09110. URL https://doi.org/10.48550/arXiv.2211.09110.</p>
<p>Jian Liu, Leyang Cui, Hanmeng Liu, Dandan Huang, Yile Wang, and Yue Zhang. Logiqa: A challenge dataset for machine reading comprehension with logical reasoning. In Christian Bessiere, editor, Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI 2020, pages 3622-3628. ijcai.org, 2020. doi: 10.24963/ijcai.2020/501. URL https: //doi.org/10.24963/ijcai.2020/501.</p>
<p>Ian McKenzie, Alexander Lyzhov, Alicia Parrish, Ameya Prabhu, Aaron Mueller, Najoung Kim, Sam Bowman, and Ethan Perez. Inverse scaling prize: Second round winners, 2022. URL https://irmckenzie.co.uk/round2.</p>
<p>Maxwell I. Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, Charles Sutton, and Augustus Odena. Show your work: Scratchpads for intermediate computation with language models. CoRR, abs/2112.00114, 2021. URL https://arxiv.org/abs/2112.00114.</p>
<p>Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Gray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. Training language models to follow instructions with human feedback. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, Advances in Neural Information Processing Systems, 2022. URL https://openreview.net/forum?id=TGBKACxEON.</p>
<p>Frank Pfenning. Natural deduction. Lecture notes in 15-815 Automated Theorem Proving, 2004. URL https://www.cs.cmu.edu/ fp/courses/atp/handouts/ch2-natded.pdf.</p>
<p>Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A. Smith, and Mike Lewis. Measuring and narrowing the compositionality gap in language models. CoRR, abs/2210.03350, 2022. doi: 10.48550/arXiv.2210.03350. URL https://doi.org/10.48550/arXiv.2210.03350.</p>
<p>Linlu Qiu, Peter Shaw, Panupong Pasupat, Tianze Shi, Jonathan Herzig, Emily Pitler, Fei Sha, and Kristina Toutanova. Evaluating the impact of model scale for compositional generalization in semantic parsing. In Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang, editors, Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022, pages 9157-9179. Association for Computational Linguistics, 2022. URL https://aclanthology.org/2022.emnlp-main. 624.</p>
<p>Soumya Sanyal, Zeyi Liao, and Xiang Ren. Robustlr: A diagnostic benchmark for evaluating logical robustness of deductive reasoners. In Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang, editors, Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022, pages 9614-9631. Association for Computational Linguistics, 2022. doi: 10.18653/v1/2022.emnlp-main.653. URL https://doi.org/10.18653/v1/2022.emnlp-main.653.</p>
<p>Abulhair Saparov and He He. Language models are greedy reasoners: A systematic formal analysis of chain-of-thought. In The Eleventh International Conference on Learning Representations, 2023. URL https://openreview.net/forum?id=qFVVBzXxR2V.</p>
<p>Koustuv Sinha, Shagun Sodhani, Jin Dong, Joelle Pineau, and William L. Hamilton. CLUTRR: A diagnostic benchmark for inductive reasoning from text. In Kentaro Inui, Jing Jiang, Vincent Ng, and Xiaojun Wan, editors, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China, November 3-7, 2019, pages 4505-4514. Association for Computational Linguistics, 2019. doi: 10.18653/v1/D19-1458. URL https: //doi.org/10.18653/v1/D19-1458.</p>
<p>Oyvind Tafjord, Bhavana Dalvi, and Peter Clark. Proofwriter: Generating implications, proofs, and abductive statements over natural language. In Chengqing Zong, Fei Xia, Wenjie Li, and Roberto Navigli, editors, Findings of the Association for Computational Linguistics: ACL/IJCNLP 2021, Online Event, August 1-6, 2021, volume ACL/IJCNLP 2021 of Findings of ACL, pages 3621-3634. Association for Computational Linguistics, 2021. doi: 10.18653/v1/2021.findings-acl.317. URL https://doi.org/10.18653/v1/2021.findings-acl.317.</p>
<p>Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurélien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. LLaMA: Open and efficient foundation language models. CoRR, abs/2302.13971, 2023. doi: 10.48550/arXiv.2302.13971. URL https://doi. org/10.48550/arXiv.2302.13971.</p>
<p>Johannes von Oswald, Eyvind Niklasson, Ettore Randazzo, João Sacramento, Alexander Mordvintsev, Andrey Zhmoginov, and Max Vladymyrov. Transformers learn in-context by gradient descent. CoRR, abs/2212.07677, 2022. doi: 10.48550/arXiv.2212.07677. URL https://doi.org/10. 48550/arXiv. 2212.07677.</p>
<p>Xinyi Wang, Wanrong Zhu, and William Yang Wang. Large language models are implicitly topic models: Explaining and finding good demonstrations for in-context learning. CoRR, abs/2301.11916, 2023. doi: 10.48550/arXiv.2301.11916. URL https://doi.org/10.48550/arXiv. 2301. 11916 .</p>
<p>Jason Wei, Yi Tay, and Quoc V. Le. Inverse scaling can become u-shaped. CoRR, abs/2211.02011, 2022a. doi: 10.48550/arXiv.2211.02011. URL https://doi.org/10.48550/arXiv. 2211. 02011 .</p>
<p>Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed H. Chi, Quoc V Le, and Denny Zhou. Chain of thought prompting elicits reasoning in large language models. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, Advances in Neural Information Processing Systems, 2022b. URL https://openreview.net/forum?id= _VjQ1MeSB_J.</p>
<p>Yuhuai Wu, Albert Q. Jiang, Jimmy Ba, and Roger Baker Grosse. INT: an inequality benchmark for evaluating generalization in theorem proving. In 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net, 2021. URL https://openreview.net/forum?id=06LPudowNQm.</p>
<p>Sang Michael Xie, Aditi Raghunathan, Percy Liang, and Tengyu Ma. An explanation of in-context learning as implicit bayesian inference. In The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022. OpenReview.net, 2022. URL https://openreview.net/forum?id=RdJVFCHjUMI.</p>
<p>Xi Ye, Srinivasan Iyer, Asli Celikyilmaz, Ves Stoyanov, Greg Durrett, and Ramakanth Pasunuru. Complementary explanations for effective in-context learning. CoRR, abs/2211.13892, 2022. doi: 10.48550/arXiv.2211.13892. URL https://doi.org/10.48550/arXiv.2211.13892.</p>
<p>Hanlin Zhang, Yi-Fan Zhang, Li Erran Li, and Eric P. Xing. The impact of symbolic representations on in-context learning for few-shot reasoning. CoRR, abs/2212.08686, 2022a. doi: 10.48550/arXiv. 2212.08686. URL https://doi.org/10.48550/arXiv.2212.08686.</p>
<p>Honghua Zhang, Liunian Harold Li, Tao Meng, Kai-Wei Chang, and Guy Van den Broeck. On the paradox of learning to reason from data. CoRR, abs/2205.11502, 2022b. doi: 10.48550/arXiv. 2205.11502. URL https://doi.org/10.48550/arXiv.2205.11502.</p>
<h1>A Appendix</h1>
<h2>A. 1 Example from PrONTOQA-OOD</h2>
<p>Q: Everything that is a lorpus, a brimpus, or a jompus is a shumpus. Every wumpus is a vumpus and a sterpus and a brimpus. Everything that is a vumpus, a grimpus, or a brimpus is a lempus. Everything that is a lempus or a jompus or a lorpus is a dumpus. Vumpuses are rompuses. Every sterpus is a gorpus. Everything that is a vumpus, a grimpus, or a brimpus is a dumpus. Wumpuses are shumpuses. Polly is a rompus. Polly is a wumpus. Prove: Polly is a lempus or an impus or a yumpus.</p>
<p>A: Polly is a wumpus. Every wumpus is a vumpus and a sterpus and a brimpus. Polly is a vumpus and a sterpus and a brimpus. Polly is a brimpus. Polly is a vumpus, a grimpus, or a brimpus. Everything that is a vumpus, a grimpus, or a brimpus is a lempus. Polly is a lempus. Polly is a lempus, an impus, or a yumpus.</p>
<p>Figure 10: An example from PrONTOQA-OOD. This is a compositional example with a min depth of 4 and 3 rule types. The given answer is the expected chain-of-thought. The question is shown in blue, the query in red, and the chain-of-thought/answer in green.</p>
<h2>A. 2 Results with absolute accuracy</h2>
<p><img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 11: (top) Proof accuracy across examples with different deduction rules. The in-context examples and test examples come from the same distribution. (bottom) Proof accuracy where the test example is out-ofdemonstration with respect to the in-context examples (for comparison, the in-demonstration proof accuracy is shown as the dotted black bars). That is, the test example has the specified deduction rule, but the in-context examples are uniformly distributed over all other deduction rules. See Figure 5 for an incorrect example. Implication elimination examples have proof width of 1 and depth of 2 . Conjunction introduction, conjunction elimination, and disjunction introduction examples have proof width 3 and depth 2 . Disjunction elimination examples have proof width 3 and depth 1 . Proof by contradiction examples have proof width 2 and depth 1 .</p>
<p><img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<p>Figure 12: (top) Proof accuracy on compositional examples where the in-context examples are also compositional examples with the same min depth and number of rule types. (bottom) Proof accuracy where the test examples are compositional but the in-context examples are those of individual deduction rules (for comparison, the in-demonstration proof accuracy is shown as the dotted black bars).
<img alt="img-9.jpeg" src="img-9.jpeg" /></p>
<p>Figure 13: (top) Proof accuracy on examples where both the in-context examples and test examples have distractors. Sentences in all questions are ordered randomly. (middle) Proof accuracy when distractors are removed from the in-context examples, but not from the test examples (for comparison, the in-demonstration proof accuracy is shown as the dotted black bars). The sentences of the in-context questions have a fixed order (corresponding to a postorder traversal of the ontology tree), whereas the sentences in the test question have random order. (bottom) The same setting as (middle) except the distractors in the in-context examples are instead replaced with irrelevant sentences. Implication elimination examples have proof width of 1 and depth of 2. Conjunction introduction, conjunction elimination, and disjunction introduction examples have proof width 2 and depth 2. Disjunction elimination examples have proof width 3 and depth 1 . Proof by contradiction examples have proof width 2 and depth 1 .</p>
<h1>A. 3 Full examples of incorrect predicted proofs</h1>
<div class="codehilite"><pre><span></span><code><span class="n">Question</span><span class="o">:</span><span class="w"> </span><span class="n">Lempuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">gorpuses</span><span class="o">.</span><span class="w"> </span><span class="n">Rompuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">wumpuses</span><span class="o">.</span><span class="w"> </span><span class="n">Tumpuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">wumpuses</span><span class="o">.</span>
<span class="n">Dumpuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">gorpuses</span><span class="o">.</span><span class="w"> </span><span class="n">Every</span><span class="w"> </span><span class="n">zumpus</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">wumpus</span><span class="o">.</span><span class="w"> </span><span class="n">Every</span><span class="w"> </span><span class="n">brimpus</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">gorpus</span><span class="o">.</span>
<span class="n">Tumpuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">gorpuses</span><span class="o">.</span><span class="w"> </span><span class="n">Lempuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">wumpuses</span><span class="o">.</span><span class="w"> </span><span class="n">Rompuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">gorpuses</span><span class="o">.</span><span class="w"> </span><span class="n">Tumpuses</span>
<span class="n">are</span><span class="w"> </span><span class="n">gorpuses</span><span class="o">.</span><span class="w"> </span><span class="n">Max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">tumpus</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">rompus</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">lempus</span><span class="o">.</span><span class="w"> </span><span class="n">Max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">zumpus</span><span class="o">,</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">tumpus</span><span class="o">,</span><span class="w"> </span><span class="n">or</span>
<span class="n">a</span><span class="w"> </span><span class="n">rompus</span><span class="o">.</span>
<span class="n">Prove</span><span class="o">:</span><span class="w"> </span><span class="n">Max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">gorpus</span><span class="o">.</span>
<span class="n">Predicted</span><span class="w"> </span><span class="n">answer</span><span class="o">:</span><span class="w"> </span><span class="n">Max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">tumpus</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">rompus</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">lempus</span><span class="o">.</span><span class="w"> </span><span class="n">Max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">tumpus</span><span class="o">.</span>
<span class="n">Tumpuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">wumpuses</span><span class="o">.</span><span class="w"> </span><span class="n">Max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">wumpus</span><span class="o">.</span><span class="w"> </span><span class="n">Rompuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">gorpuses</span><span class="o">.</span><span class="w"> </span><span class="n">Max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">gorpus</span><span class="o">.</span>
<span class="n">Max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">gorpus</span><span class="o">.</span>
<span class="n">Expected</span><span class="w"> </span><span class="n">answer</span><span class="o">:</span><span class="w"> </span><span class="n">Assume</span><span class="w"> </span><span class="n">Max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">tumpus</span><span class="o">.</span><span class="w"> </span><span class="n">Tumpuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">gorpuses</span><span class="o">.</span><span class="w"> </span><span class="n">Max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">gorpus</span><span class="o">.</span>
<span class="n">Assume</span><span class="w"> </span><span class="n">Max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">rompus</span><span class="o">.</span><span class="w"> </span><span class="n">Rompuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">gorpuses</span><span class="o">.</span><span class="w"> </span><span class="n">Max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">gorpus</span><span class="o">.</span>
<span class="n">Assume</span><span class="w"> </span><span class="n">Max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">lempus</span><span class="o">.</span><span class="w"> </span><span class="n">Lempuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">gorpuses</span><span class="o">.</span><span class="w"> </span><span class="n">Max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">gorpus</span><span class="o">.</span>
<span class="n">Since</span><span class="w"> </span><span class="n">Max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">tumpus</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">rompus</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">lempus</span><span class="o">,</span><span class="w"> </span><span class="n">Max</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">gorpus</span><span class="o">.</span>
</code></pre></div>

<p>FIGURE 14: Example of an incorrect proof generated by GPT-3.5 on an out-of-demonstration disjunction elimination example. The premises (axioms) are given in blue, and invalid steps are given in red.</p>
<div class="codehilite"><pre><span></span><code><span class="n">Question</span><span class="o">:</span><span class="w"> </span><span class="n">Polly</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">wumpus</span><span class="o">.</span><span class="w"> </span><span class="n">Every</span><span class="w"> </span><span class="n">rompus</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">dumpus</span><span class="o">.</span><span class="w"> </span><span class="n">Lempuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">vumpuses</span><span class="o">.</span>
<span class="n">Everything</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">wumpus</span><span class="o">,</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">jompus</span><span class="o">,</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">tumpus</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">dumpus</span><span class="o">.</span><span class="w"> </span><span class="n">Polly</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">gorpus</span><span class="o">.</span>
<span class="n">Every</span><span class="w"> </span><span class="n">impus</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">brimpus</span><span class="o">.</span><span class="w"> </span><span class="n">Everything</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">wumpus</span><span class="o">,</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">gorpus</span><span class="o">,</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">shumpus</span><span class="w"> </span><span class="k">is</span>
<span class="n">a</span><span class="w"> </span><span class="n">vumpus</span><span class="o">.</span><span class="w"> </span><span class="n">Each</span><span class="w"> </span><span class="n">lempus</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="n">impus</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">lorpus</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">rompus</span><span class="o">.</span><span class="w"> </span><span class="n">Everything</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="k">is</span>
<span class="n">a</span><span class="w"> </span><span class="n">wumpus</span><span class="o">,</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">jompus</span><span class="o">,</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">tumpus</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">lorpus</span><span class="o">.</span><span class="w"> </span><span class="n">Zumpuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">lorpuses</span><span class="o">.</span><span class="w"> </span><span class="n">Polly</span><span class="w"> </span><span class="k">is</span>
<span class="n">a</span><span class="w"> </span><span class="n">shumpus</span><span class="o">.</span><span class="w"> </span><span class="n">Polly</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">zumpus</span><span class="o">.</span><span class="w"> </span><span class="n">Polly</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">zumpus</span><span class="o">.</span><span class="w"> </span><span class="n">Polly</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">wumpus</span><span class="o">.</span><span class="w"> </span><span class="n">Polly</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span>
<span class="n">jompus</span><span class="o">.</span><span class="w"> </span><span class="n">Polly</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">tumpus</span><span class="o">.</span>
<span class="n">Prove</span><span class="o">:</span><span class="w"> </span><span class="n">Polly</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">lempus</span><span class="o">.</span>
<span class="n">Predicted</span><span class="w"> </span><span class="n">answer</span><span class="o">:</span><span class="w"> </span><span class="n">Polly</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">wumpus</span><span class="o">,</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">jompus</span><span class="o">,</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">tumpus</span><span class="o">.</span><span class="w"> </span><span class="n">Everything</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span>
<span class="n">wumpus</span><span class="o">,</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">jompus</span><span class="o">,</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">tumpus</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">lempus</span><span class="o">.</span><span class="w"> </span><span class="n">Polly</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">lempus</span><span class="o">.</span>
<span class="n">Expected</span><span class="w"> </span><span class="n">answer</span><span class="o">:</span><span class="w"> </span><span class="n">Polly</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">tumpus</span><span class="o">.</span><span class="w"> </span><span class="n">Polly</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">jompus</span><span class="o">.</span><span class="w"> </span><span class="n">Polly</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">wumpus</span><span class="o">.</span><span class="w"> </span><span class="n">Polly</span>
<span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">wumpus</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">jompus</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">tumpus</span><span class="o">.</span><span class="w"> </span><span class="n">Everything</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">wumpus</span><span class="o">,</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">jompus</span><span class="o">,</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a</span>
<span class="n">tumpus</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">lorpus</span><span class="o">.</span><span class="w"> </span><span class="n">Polly</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">lorpus</span><span class="o">.</span>
<span class="n">Assume</span><span class="w"> </span><span class="n">Polly</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">lempus</span><span class="o">.</span><span class="w"> </span><span class="n">Each</span><span class="w"> </span><span class="n">lempus</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="n">impus</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">lorpus</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">rompus</span><span class="o">.</span><span class="w"> </span><span class="n">Polly</span>
<span class="k">is</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="n">impus</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">lorpus</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">rompus</span><span class="o">.</span><span class="w"> </span><span class="n">Polly</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">lorpus</span><span class="o">.</span><span class="w"> </span><span class="n">This</span><span class="w"> </span><span class="n">contradicts</span><span class="w"> </span><span class="k">with</span>
<span class="n">Polly</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">lorpus</span><span class="o">.</span><span class="w"> </span><span class="n">Polly</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">lempus</span><span class="o">.</span>
</code></pre></div>

<p>FIGURE 15: Example of an incorrect proof generated by GPT-3.5 on an out-of-demonstration example with min depth 2 and 4 rule types. The premises (axioms) are given in blue, and invalid steps are given in red.</p>
<div class="codehilite"><pre><span></span><code><span class="n">Question</span><span class="o">:</span><span class="w"> </span><span class="n">Every</span><span class="w"> </span><span class="n">grimpus</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">zumpus</span><span class="o">.</span><span class="w"> </span><span class="n">Each</span><span class="w"> </span><span class="n">vumpus</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">opaque</span><span class="o">.</span><span class="w"> </span><span class="n">Each</span><span class="w"> </span><span class="n">dumpus</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">not</span>
<span class="n">brown</span><span class="o">.</span><span class="w"> </span><span class="n">Each</span><span class="w"> </span><span class="n">grimpus</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">dull</span><span class="o">.</span><span class="w"> </span><span class="n">Lorpuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">moderate</span><span class="o">.</span><span class="w"> </span><span class="n">Every</span><span class="w"> </span><span class="n">brimpus</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">rainy</span><span class="o">.</span>
<span class="n">Impuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">temperate</span><span class="o">.</span><span class="w"> </span><span class="n">Lorpuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">dumpuses</span><span class="o">.</span><span class="w"> </span><span class="n">Brimpuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">vumpuses</span><span class="o">.</span><span class="w"> </span><span class="n">Every</span>
<span class="n">lorpus</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">brimpus</span><span class="o">.</span><span class="w"> </span><span class="n">Zumpuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">angry</span><span class="o">.</span><span class="w"> </span><span class="n">Grimpuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">yumpuses</span><span class="o">.</span><span class="w"> </span><span class="n">Every</span><span class="w"> </span><span class="n">brimpus</span>
<span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">grimpus</span><span class="o">.</span><span class="w"> </span><span class="n">Impuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">sterpuses</span><span class="o">.</span><span class="w"> </span><span class="n">Sally</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="n">impus</span><span class="o">.</span><span class="w"> </span><span class="n">Sally</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">brimpus</span><span class="o">.</span>
<span class="n">Prove</span><span class="o">:</span><span class="w"> </span><span class="n">Sally</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">dull</span><span class="o">.</span>
<span class="n">Predicted</span><span class="w"> </span><span class="n">answer</span><span class="o">:</span><span class="w"> </span><span class="n">Sally</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="n">impus</span><span class="o">.</span><span class="w"> </span><span class="n">Impuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">sterpuses</span><span class="o">.</span><span class="w"> </span><span class="n">Every</span><span class="w"> </span><span class="n">grimpus</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span>
<span class="n">zumpus</span><span class="o">.</span><span class="w"> </span><span class="n">Every</span><span class="w"> </span><span class="n">brimpus</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">grimpus</span><span class="o">.</span><span class="w"> </span><span class="n">Lorpuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">dumpuses</span><span class="o">.</span><span class="w"> </span><span class="n">Brimpuses</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">vumpuses</span><span class="o">.</span>
<span class="n">Every</span><span class="w"> </span><span class="n">lorpus</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">brimpus</span><span class="o">.</span><span class="w"> </span><span class="n">Sally</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">brimpus</span><span class="o">.</span><span class="w"> </span><span class="n">Each</span><span class="w"> </span><span class="n">vumpus</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">opaque</span><span class="o">.</span><span class="w"> </span><span class="n">Each</span><span class="w"> </span><span class="n">dumpus</span>
<span class="k">is</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">brown</span><span class="o">.</span><span class="w"> </span><span class="n">Every</span><span class="w"> </span><span class="n">grimpus</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">dull</span><span class="o">.</span><span class="w"> </span><span class="n">Sally</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">grimpus</span><span class="o">.</span><span class="w"> </span><span class="n">Sally</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">dull</span><span class="o">.</span>
<span class="n">Expected</span><span class="w"> </span><span class="n">answer</span><span class="o">:</span><span class="w"> </span><span class="n">Sally</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">brimpus</span><span class="o">.</span><span class="w"> </span><span class="n">Every</span><span class="w"> </span><span class="n">brimpus</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">grimpus</span><span class="o">.</span><span class="w"> </span><span class="n">Sally</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span>
<span class="n">grimpus</span><span class="o">.</span><span class="w"> </span><span class="n">Each</span><span class="w"> </span><span class="n">grimpus</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">dull</span><span class="o">.</span><span class="w"> </span><span class="n">Sally</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">dull</span><span class="o">.</span>
</code></pre></div>

<p>FIGURE 16: Example of an incorrect proof generated by GPT-3.5 on an OOD implication elimination example where the in-context demonstrations have no distractors, but the test example does. The premises (axioms) are given in blue, and invalid steps are given in red.</p>
<h1>A. 4 Generative process details</h1>
<p>In this section, we describe the process to generate examples of each deduction rule.
Implication elimination (i.e. modus ponens) Given $f(c)$ and $\forall x(f(x) \rightarrow g(x))$, prove $g(c)$. These are the examples in the original PrONTOQA. We follow the same process here:</p>
<ol>
<li>Generate an ontology. For simplicity, we generate linear ontologies, consisting of a collection of concepts, as well as subtype-supertype relations between those concepts (i.e. concept $f$ is a subtype of the supertype $g$ if every instance of $f$ is an instance of $g$ ). For simplicity, we limit each type to have at most one supertype.</li>
<li>Perform a random walk of length $k$ from a randomly selected start vertex, where $k$ is the desired proof depth.</li>
<li>Traverse the edges of the ontology and convert each into a sentence of the question.</li>
<li>Convert each step of the random walk into a sentence of the gold chain-of-thought.</li>
</ol>
<p>Note that this process allows us to generate proofs of any depth, but the width is fixed to 1.
Conjunction introduction Given $A$ and $B$, prove $A \wedge B$. The generative process is a modified version of that for implication elimination. Instead of generating rules of the form $\forall x(f(x) \rightarrow g(x))$, we generate rules of the form $\forall x\left(f_{1}(x) \wedge \ldots \wedge f_{n}(x) \rightarrow g(x)\right)$, where $n$ is the proof width. Given, $f_{1}(c), \ldots$, and $f_{n}(c)$, the model must first prove $f_{1}(c) \wedge \ldots \wedge f_{n}(c)$ before applying implication elimination to prove $g(c)$. To increase the depth of the proof, $g(c)$ itself can be part of a conjunct in the antecedent of another rule.</p>
<p>Conjunction elimination Given $A \wedge B$, prove $A$. These examples are identical to those in conjunction introduction, except the conjunction appears in the consequent of each rule, rather than in the antecedent: $\forall x\left(f(x) \rightarrow g_{1}(x) \wedge \ldots \wedge g_{n}(x)\right)$ where $n$ is the proof width.</p>
<p>Disjunction introduction Given $A$, prove $A \vee B$. These examples are identical to those in conjunction introduction, except the conjunction is replaced with disjunction: $\forall x\left(f_{1}(x) \vee \ldots \vee f_{n}(x) \rightarrow g(x)\right)$ where $n$ is the proof width. But note that grounded axioms are not necessary for every disjunct: To apply the rule $\forall x\left(f_{1}(x) \vee \ldots \vee f_{n}(x) \rightarrow g(x)\right)$, knowing $f_{n}(c)$ is sufficient, and we do not need to generate grounded axioms for the other disjuncts $f_{i}(c)$ for $i&lt;n$.</p>
<p>Disjunction elimination (i.e. proof by cases) Given $A_{1} \vee \ldots \vee A_{n}$, and $A_{i} \vdash C$ for all $i$, prove $C$. Here, $n$ is the proof width. While it is possible to construct proofs containing multiple nested applications of disjunction elimination, such proofs are quite complex, even for humans to understand, and so we fix the depth of these examples to 1 . To generate an example, we first generate the disjunction: $f_{1}(c) \vee \ldots \vee f_{n}(c)$. Next, generate the rules for each case: $\forall x\left(f_{i}(x) \rightarrow g(x)\right)$ for all $i$. The goal is to prove $g(c)$.</p>
<p>Proof by contradiction Given $A \vdash B$ and $\neg B$, prove $\neg A$. Note that this is a rule composed of two natural deduction rules: negation elimination and introduction. But since those individual rules do not lend themselves to a natural text representation, we choose to study their composition. Similar to disjunction elimination, it is possible to construct proofs containing multiple nested applications of proof by contradiction, but such proofs are unnaturally complex. So we fix the depth to 1 . To generate an example, we first generate an axiom $\neg g(c)$. Next, for each subproof, we generate a rule $\forall x\left(f_{1}(x) \vee \ldots \vee f_{n}(x) \rightarrow g(x)\right)$, where $n$ is the proof width. The goal is to prove $\neg f_{1}(c) \wedge \ldots \wedge \neg f_{n}(c)$. Note that in addition to proof by contradiction, this proof requires disjunction introduction, implication elimination, and conjunction introduction.</p>
<p>Note that the above list constitutes a complete set of deduction rules from propositional natural deduction, save for one rule: implication introduction. However, it is unclear how to construct an example with this deduction rule where its difficulty can be controlled by increasing the width or depth of the proof (e.g. how can a statement of the form $A_{1} \rightarrow A_{2} \rightarrow \ldots \rightarrow A_{n}$ be expressed in natural language?).</p>
<div class="codehilite"><pre><span></span><code><span class="n">Algorithm</span><span class="w"> </span><span class="mi">1</span><span class="p">:</span><span class="w"> </span><span class="n">Pseudocode</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">generating</span><span class="w"> </span><span class="n">examples</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">compositional</span><span class="w"> </span><span class="n">proofs</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">PrOnTOQA</span><span class="o">-</span><span class="n">OOD</span><span class="o">.</span><span class="w"> </span><span class="n">In</span>
<span class="n">this</span><span class="w"> </span><span class="n">algorithm</span><span class="p">,</span><span class="w"> </span>\<span class="p">(</span>\<span class="n">Omega</span>\<span class="p">)</span><span class="w"> </span><span class="n">denotes</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">set</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">all</span><span class="w"> </span><span class="n">logical</span><span class="w"> </span><span class="n">forms</span><span class="o">.</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">function</span><span class="w"> </span><span class="n">generate_compositional_proof</span><span class="w"> </span><span class="k">is</span>
<span class="n">initially</span><span class="w"> </span><span class="n">called</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">parameters</span><span class="w"> </span>\<span class="p">(</span>\<span class="n">Omega</span><span class="p">,</span><span class="w"> </span>\<span class="n">varnothing</span><span class="p">,</span><span class="w"> </span><span class="n">d</span><span class="p">,</span><span class="w"> </span><span class="n">e</span>\<span class="p">),</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="bp">false</span><span class="p">,</span><span class="w"> </span><span class="n">where</span><span class="w"> </span>\<span class="p">(</span><span class="n">d</span>\<span class="p">)</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">requested</span><span class="w"> </span><span class="n">depth</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span>\<span class="p">(</span><span class="n">e</span>\<span class="p">)</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">randomly</span>
<span class="n">selected</span><span class="w"> </span><span class="n">entity</span><span class="w"> </span><span class="n">name</span><span class="w"> </span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">g</span><span class="o">.</span><span class="w"> </span><span class="n">alex</span><span class="p">,</span><span class="w"> </span><span class="n">fae</span><span class="p">,</span><span class="w"> </span><span class="n">etc</span><span class="p">)</span><span class="o">.</span><span class="w"> </span><span class="n">sample</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">helper</span><span class="w"> </span><span class="n">function</span><span class="w"> </span><span class="n">that</span><span class="p">,</span><span class="w"> </span><span class="n">given</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="n">input</span><span class="w"> </span><span class="n">set</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">logical</span>
<span class="n">forms</span><span class="w"> </span>\<span class="p">(</span><span class="n">S</span>\<span class="p">)</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="n">entity</span><span class="w"> </span>\<span class="p">(</span><span class="n">e</span>\<span class="p">),</span><span class="w"> </span><span class="n">returns</span><span class="w"> </span><span class="n">sample_uniform</span><span class="p">(</span><span class="w"> </span>\<span class="p">(</span>\<span class="p">{</span>\<span class="n">operatorname</span><span class="p">{</span><span class="n">set</span><span class="p">}</span>\<span class="p">)</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">logical</span><span class="w"> </span><span class="n">forms</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span>\<span class="p">(</span><span class="n">S</span>\<span class="p">)</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">minimal</span><span class="w"> </span><span class="n">depth</span><span class="w"> </span><span class="n">where</span><span class="w"> </span><span class="n">all</span>
<span class="n">atoms</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">form</span><span class="w"> </span>\<span class="p">(</span><span class="n">t</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>\<span class="p">)</span><span class="w"> </span><span class="n">where</span><span class="w"> </span>\<span class="p">(</span><span class="n">t</span>\<span class="p">)</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">predicate</span><span class="w"> </span>\<span class="p">(</span>\<span class="p">}</span>\<span class="p">)</span><span class="w"> </span><span class="p">)</span><span class="o">.</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="k">function</span><span class="w"> </span><span class="nf">generate_compositional_proof (set of possible conclusions (logical forms) \</span><span class="p">(</span>C\<span class="p">),</span>
<span class="n">disallowed</span><span class="w"> </span><span class="s">deduction</span><span class="w"> </span><span class="s">rules</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">R</span><span class="o">\</span><span class="p">),</span>
<span class="n">requested</span><span class="w"> </span><span class="s">depth</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">d</span><span class="o">\</span><span class="p">),</span>
<span class="n">ground</span><span class="w"> </span><span class="s">entity</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">e</span><span class="o">\</span><span class="p">),</span>
<span class="n">is</span><span class="w"> </span><span class="s">proof</span><span class="w"> </span><span class="s">hypothetical</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">h</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="p">)</span>
<span class="w">    </span><span class="n">initialize</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">A</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">as</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="nb">set</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="nb">all</span><span class="w"> </span><span class="n">deduction</span><span class="w"> </span><span class="n">rules</span><span class="w"> </span><span class="n">excluding</span><span class="w"> </span><span class="n">those</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">R</span><span class="o">\</span><span class="p">)</span>
<span class="w">    </span><span class="o">/*</span><span class="w"> </span><span class="nb">filter</span><span class="w"> </span><span class="n">deduction</span><span class="w"> </span><span class="n">rules</span><span class="w"> </span><span class="n">such</span><span class="w"> </span><span class="n">that</span><span class="p">:</span><span class="w"> </span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="n">element</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">C</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">conclusion</span>
<span class="w">        </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">rule</span><span class="p">,</span><span class="w"> </span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="nb">which</span><span class="w"> </span><span class="n">we</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">sufficient</span><span class="w"> </span><span class="n">depth</span><span class="p">,</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="w"> </span><span class="n">we</span><span class="w"> </span><span class="n">don</span><span class="o">&#39;</span><span class="n">t</span><span class="w"> </span><span class="n">create</span>
<span class="w">        </span><span class="n">overly</span><span class="w"> </span><span class="nb">complex</span><span class="w"> </span><span class="nb">logical</span><span class="w"> </span><span class="n">forms</span><span class="w"> </span><span class="o">*/</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">C</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">does</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">contain</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">conjunction</span>
<span class="w">        </span><span class="nb">set</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">A</span><span class="p">=</span><span class="n">A</span><span class="w"> </span><span class="o">\</span><span class="n">backslash</span><span class="o">\</span><span class="p">{</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">conjunction_introduction</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="o">\</span><span class="p">}</span><span class="o">\</span><span class="p">)</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">C</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">does</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">contain</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">disjunction</span>
<span class="w">        </span><span class="nb">set</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">A</span><span class="p">=</span><span class="n">A</span><span class="w"> </span><span class="o">\</span><span class="n">backslash</span><span class="o">\</span><span class="p">{</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">disjunction_introduction</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="o">\</span><span class="p">}</span><span class="o">\</span><span class="p">)</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">h</span><span class="p">=</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">d</span><span class="p">=</span><span class="mi">1</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">C</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">does</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">contain</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">negation</span>
<span class="w">        </span><span class="nb">set</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">A</span><span class="p">=</span><span class="n">A</span><span class="w"> </span><span class="o">\</span><span class="n">backslash</span><span class="o">\</span><span class="p">{</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">proof_by_contradiction</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="o">\</span><span class="p">}</span><span class="o">\</span><span class="p">)</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">h</span><span class="p">=</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">d</span><span class="p">=</span><span class="mi">1</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">C</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="nb">contains</span><span class="w"> </span><span class="n">only</span><span class="w"> </span><span class="n">conjunctions</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">only</span><span class="w"> </span><span class="n">disjunctions</span>
<span class="w">        </span><span class="nb">set</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">A</span><span class="p">=</span><span class="n">A</span><span class="w"> </span><span class="o">\</span><span class="n">backslash</span><span class="o">\</span><span class="p">{</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">disjunction_elimination</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="o">\</span><span class="p">}</span><span class="o">\</span><span class="p">)</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">C</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="nb">contains</span><span class="w"> </span><span class="n">only</span><span class="w"> </span><span class="n">conjunctions</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">only</span><span class="w"> </span><span class="n">disjunctions</span>
<span class="w">        </span><span class="nb">set</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">A</span><span class="p">=</span><span class="n">A</span><span class="w"> </span><span class="o">\</span><span class="n">backslash</span><span class="o">\</span><span class="p">{</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">conjunction_elimination</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="o">\</span><span class="p">}</span><span class="o">\</span><span class="p">)</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">C</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="nb">contains</span><span class="w"> </span><span class="n">only</span><span class="w"> </span><span class="n">conjunctions</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">only</span><span class="w"> </span><span class="n">disjunctions</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="nb">any</span><span class="w"> </span><span class="n">operand</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">negated</span>
<span class="w">        </span><span class="nb">set</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">A</span><span class="p">=</span><span class="n">A</span><span class="w"> </span><span class="o">\</span><span class="n">backslash</span><span class="o">\</span><span class="p">{</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">implication_elimination</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="o">\</span><span class="p">}</span><span class="o">\</span><span class="p">)</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">d</span><span class="p">=</span><span class="mi">0</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">C</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="nb">contains</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">singleton</span><span class="w"> </span><span class="nb">logical</span><span class="w"> </span><span class="n">form</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">A</span><span class="p">=</span><span class="o">\</span><span class="n">varnothing</span><span class="o">\</span><span class="p">)</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">axiom</span><span class="w"> </span><span class="nb">step</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">conclusion</span><span class="w"> </span><span class="n">given</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="n">sample</span><span class="w"> </span><span class="o">\</span><span class="p">((</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="n">e</span><span class="p">)</span><span class="o">\</span><span class="p">)</span>
<span class="w">    </span><span class="o">\</span><span class="p">(</span><span class="n">r</span><span class="p">=</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">sample_uniform</span><span class="w"> </span><span class="o">\</span><span class="p">((</span><span class="n">A</span><span class="p">)</span><span class="o">\</span><span class="p">)</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">r</span><span class="p">=</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">implication_elimination</span>
<span class="w">        </span><span class="n">do</span>
<span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="nb">any</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">c</span><span class="w"> </span><span class="o">\</span><span class="n">in</span><span class="w"> </span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">c</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">share</span><span class="w"> </span><span class="nb">any</span><span class="w"> </span><span class="n">operands</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">negations</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">operands</span>
<span class="w">            </span><span class="k">while</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">a</span><span class="p">=</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">generate_compositional_proof</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="o">\</span><span class="n">left</span><span class="p">(</span><span class="o">\</span><span class="n">Omega</span><span class="p">,</span><span class="w"> </span><span class="o">\</span><span class="n">varnothing</span><span class="p">,</span><span class="w"> </span><span class="n">d</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">e</span><span class="p">,</span><span class="w"> </span><span class="n">h</span><span class="o">\</span><span class="n">right</span><span class="p">)</span><span class="o">\</span><span class="p">)</span>
<span class="w">            </span><span class="n">do</span>
<span class="w">            </span><span class="o">\</span><span class="p">(</span><span class="n">a</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">s</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">do</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">share</span><span class="w"> </span><span class="nb">any</span><span class="w"> </span><span class="n">operands</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">negations</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">operands</span>
<span class="w">            </span><span class="k">while</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">s</span><span class="p">=</span><span class="o">\</span><span class="n">operatorname</span><span class="p">{</span><span class="n">sample</span><span class="p">}(</span><span class="n">C</span><span class="p">,</span><span class="w"> </span><span class="n">e</span><span class="p">)</span><span class="o">\</span><span class="p">)</span>
<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">implication_elimination</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">premises</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">a</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="o">\</span><span class="n">forall</span><span class="w"> </span><span class="n">x</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="n">e</span><span class="w"> </span><span class="o">\</span><span class="n">rightarrow</span><span class="w"> </span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">\</span><span class="n">rightarrow</span><span class="w"> </span><span class="n">s</span><span class="p">[</span><span class="n">e</span><span class="w"> </span><span class="o">\</span><span class="n">rightarrow</span><span class="w"> </span><span class="n">x</span><span class="p">])</span><span class="o">\</span><span class="p">)</span>
<span class="w">            </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">r</span><span class="p">=</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">conjunction_introduction</span>
<span class="w">            </span><span class="n">initialize</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">P</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">as</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="nb">empty</span><span class="w"> </span><span class="n">list</span><span class="p">,</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="nb">i</span><span class="p">=</span><span class="mi">0</span><span class="o">\</span><span class="p">)</span>
<span class="w">            </span><span class="o">\</span><span class="p">(</span><span class="n">L</span><span class="p">=</span><span class="o">|</span><span class="n">C</span><span class="o">|\</span><span class="p">)</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">C</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="nb">contains</span><span class="w"> </span><span class="n">only</span><span class="w"> </span><span class="n">conjunctions</span><span class="p">,</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">L</span><span class="p">=</span><span class="mi">3</span><span class="o">\</span><span class="p">)</span>
<span class="w">            </span><span class="n">do</span>
<span class="w">            </span><span class="n">let</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">C_</span><span class="p">{</span><span class="nb">i</span><span class="p">}=</span><span class="nb">i</span><span class="o">^</span><span class="p">{</span><span class="n">t</span><span class="w"> </span><span class="n">h</span><span class="p">}</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">operand</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">C</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">C</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="nb">contains</span><span class="w"> </span><span class="n">only</span><span class="w"> </span><span class="n">conjunctions</span><span class="p">,</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">C_</span><span class="p">{</span><span class="nb">i</span><span class="p">}=</span><span class="o">\</span><span class="n">Omega</span><span class="o">\</span><span class="p">)</span>
<span class="w">            </span><span class="o">\</span><span class="p">(</span><span class="n">a</span><span class="p">=</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">generate_compositional_proof</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="o">\</span><span class="n">left</span><span class="p">(</span><span class="n">C_</span><span class="p">{</span><span class="nb">i</span><span class="p">},</span><span class="o">\</span><span class="p">{</span><span class="o">\</span><span class="n">right</span><span class="o">.\</span><span class="p">)</span><span class="w"> </span><span class="n">conjunction_elimination</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="o">\</span><span class="p">},</span><span class="w"> </span><span class="n">d</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">e</span><span class="p">,</span><span class="w"> </span><span class="n">h</span><span class="p">)</span><span class="o">\</span><span class="p">)</span>
<span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">a</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">atomic</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">a</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="nb">any</span><span class="w"> </span><span class="n">other</span><span class="w"> </span><span class="n">operand</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">C</span><span class="o">\</span><span class="p">)</span>
<span class="w">            </span><span class="nb">append</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">a</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">P</span><span class="o">\</span><span class="p">)</span>
<span class="w">            </span><span class="o">\</span><span class="p">(</span><span class="nb">i</span><span class="p">=</span><span class="nb">i</span><span class="o">+</span><span class="mi">1</span><span class="o">\</span><span class="p">)</span>
<span class="w">            </span><span class="k">while</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="nb">i</span><span class="o">&lt;</span><span class="n">L</span><span class="o">\</span><span class="p">)</span>
<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">conjunction_introduction</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">premises</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">P</span><span class="o">\</span><span class="p">)</span>
<span class="w">            </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">r</span><span class="p">=</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">conjunction_elimination</span>
<span class="w">            </span><span class="n">let</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">C</span><span class="o">^</span><span class="p">{</span><span class="o">\</span><span class="n">prime</span><span class="p">}</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="nb">set</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">conjunctions</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="nb">length</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="nb">i</span><span class="p">=</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">sample_uniform</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="o">\</span><span class="n">left</span><span class="p">(</span><span class="o">\</span><span class="p">{</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="o">\</span><span class="p">}</span><span class="o">\</span><span class="n">right</span><span class="p">)</span><span class="o">\</span><span class="p">)</span>
<span class="w">            </span><span class="o">\</span><span class="p">(</span><span class="n">C</span><span class="o">^</span><span class="p">{</span><span class="o">\</span><span class="n">prime</span><span class="p">}=</span><span class="o">\</span><span class="n">left</span><span class="o">\</span><span class="p">{</span><span class="n">c</span><span class="w"> </span><span class="o">\</span><span class="n">in</span><span class="w"> </span><span class="n">C</span><span class="o">^</span><span class="p">{</span><span class="o">\</span><span class="n">prime</span><span class="p">}:</span><span class="w"> </span><span class="o">\</span><span class="n">right</span><span class="o">.\</span><span class="p">)</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="nb">i</span><span class="o">^</span><span class="p">{</span><span class="n">t</span><span class="w"> </span><span class="n">h</span><span class="p">}</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">operand</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">c</span><span class="o">^</span><span class="p">{</span><span class="o">\</span><span class="n">prime</span><span class="p">}</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">C</span><span class="o">\</span><span class="p">}</span><span class="o">\</span><span class="p">)</span>
<span class="w">            </span><span class="n">do</span>
<span class="w">            </span><span class="o">\</span><span class="p">(</span><span class="n">a</span><span class="p">=</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">generate_compositional_proof</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="o">\</span><span class="n">left</span><span class="p">(</span><span class="n">C</span><span class="o">^</span><span class="p">{</span><span class="o">\</span><span class="n">prime</span><span class="p">},</span><span class="o">\</span><span class="p">{</span><span class="o">\</span><span class="n">right</span><span class="o">.\</span><span class="p">)</span><span class="w"> </span><span class="n">conjunction_introduction</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="o">\</span><span class="p">},</span><span class="w"> </span><span class="n">d</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">e</span><span class="p">,</span><span class="w"> </span><span class="n">h</span><span class="p">)</span><span class="o">\</span><span class="p">)</span>
<span class="w">            </span><span class="k">while</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">a</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="n">no</span><span class="w"> </span><span class="n">duplicate</span><span class="w"> </span><span class="n">operands</span><span class="p">,</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">each</span><span class="w"> </span><span class="n">operand</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">a</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">not</span><span class="w"> </span><span class="n">itself</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">conjunction</span><span class="w"> </span><span class="n">or</span><span class="w"> </span><span class="n">disjunction</span>
<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">conjunction_elimination</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">premise</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">a</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">conclusion</span><span class="w"> </span><span class="n">given</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="nb">i</span><span class="o">^</span><span class="p">{</span><span class="n">t</span><span class="w"> </span><span class="n">h</span><span class="p">}</span><span class="o">\</span><span class="p">)</span><span class="w"> </span><span class="n">operand</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="o">\</span><span class="p">(</span><span class="n">a</span><span class="o">\</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code>else if \(r=\) disjunction_introduction
    if \(C=\Omega\) let \(C\) be the set of disjunctions of length 3
    \(i=\) sample_uniform( number of disjuncts in \(C\) )
    do
        let \(C_{i}=i^{t h}\) operand of \(C\)
        \(a=\) generate_compositional_proof \(\left(C_{i},\{\right.\) disjunction_elimination \(\}, d-1, e, h\right)\)
    while \(a\) is atomic and \(a\) is not any other operand of \(C\)
    replace \(i^{t h}\) operand of \(C\) with \(a\)
    do
        \(x=\) sample \((C, e)\)
    while \(i^{t h}\) disjunct of \(x\) is distinct from all other disjuncts
    return disjunction_introduction with premise given by the \(i^{t h}\) operand of \(x\) and conclusion \(x\)
else if \(r=\) disjunction_elimination
    initialize \(P\) as an empty list
    while \(|P|&lt;2\) do
        \(p=\) generate_compositional_proof \((C,\{\operatorname{disjunction\_introduction}\}, d-1, e\), true \()\)
        if \(p\) is not a conjunction or disjunction and \(p\) has an axiom that is not an axiom of any \(q \in P\)
        append \(p\) to \(P\)
        let \(A_{i}\) be the set of axioms of \(P_{i}\) that are not axioms of \(P_{j}\) for \(i \neq j\)
        let \(a_{i}=\) sample_uniform \(\left(A_{i}\right)\) for all \(i\)
        let \(a^{\prime}\) be a disjunction with disjuncts \(a_{i}\)
        \(a=\) generate_compositional_proof \(\left(\left\{a^{\prime}\right\},\{\right.\) disjunction_introduction \(\}, d-1, e, h\right)\)
        return disjunction_introduction with premises \(a\) and \(P_{i}\)
    else if \(r=\) proof_by_contradiction
    let \(N\) be the set of all negated logical forms
    \(a=\) generate_compositional_proof \((N,\{\text { proof_by_contradiction }\}, d-1, h)\)
    do
        let \(a=\neg s\)
    \(b=\) generate_compositional_proof \(\left(\left\{s\right\},\{\right.\) proof_by_contradiction \(\}, d-1, e\), true \()\)
    while \(b\) has an atomic non-negated axiom that is not an axiom of \(a\)
    \(s^{\prime}=\) sample_uniform(\{atomic non-negated axioms of \(b\) that are not axioms of \(a\}\)
    return proof_by_contradiction with premises \(a\) and \(b\) and conclusion \(\neg s^{\prime}\)
</code></pre></div>

<h1>A. 5 Generating compositional proofs</h1>
<p>We use a simple recursive procedure to generate compositional proofs: (1) select a deduction rule uniformly at random, (2) select the premises for the selected rule, (3) recursively generate a subproof for each premise. A consistency checking step is required to make sure we avoid generating contradictory axioms. ${ }^{6}$ In addition, we avoid generating an elimination rule directly following an introduction rule (or vice versa). ${ }^{7}$ See Algorithm 1 in the appendix for pseudocode of this procedure. To test compositional proofs of various sizes, we implement a parameter that controls the minimum depth of the proof tree, and another parameter that controls the number of distinct rule types in each proof.</p>
<h2>A. 6 Further details on evaluation of CoT</h2>
<p>We aim to test whether LLMs are able to use deduction rules OOD, where the rules do not appear in the in-context examples, and we take care not to be overly strict. For example, we wish to avoid penalizing the model for formatting differences, so long as the reasoning is correct. To this end, in determining whether a logical form follows from previous logical forms, we consider any deduction rule listed in Table 2. We also allow for two additional rules: (1) given $\forall x(f(x) \rightarrow g(x))$ and</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>$\forall x(g(x) \rightarrow h(x))$ conclude $\forall x(f(x) \rightarrow h(x))$, and (2) given $\forall x(f(x) \rightarrow g(x))$ and $\neg g(c)$ conclude $\neg f(c)$ (i.e. modus tollens). ${ }^{8}$ Additionally, we are flexible with respect to the ordering of conjuncts and disjuncts. For example, given the previous steps $f(a) \wedge g(a)$ and $\forall x(g(x) \wedge f(x) \rightarrow u(x) \vee v(x))$, we consider $v(a) \vee u(a)$ to be valid.</p>
<h1>A. 7 Generating distractors</h1>
<p>Implication elimination For any rule $\forall x(f(x) \rightarrow g(x))$ in the gold proof, we generate a distractor rule $\forall x(f(x) \rightarrow h(x))$ where the concept $h$ is a distractor and is not helpful in completing the proof. In addition, for any ground logical form in the gold proof $f(c)$, we generate a distractor logical form $h(c)$ as well as a rule $\forall x\left(h(x) \rightarrow h^{\prime}(x)\right)$. Note that the original PRONTOQA only adds a single distractor, whereas we add multiple, one for each hop in the proof.
Conjunction introduction Similar to those in implication elimination. For any rule $\forall x\left(f_{1}(x) \wedge \ldots \wedge\right.$ $\left.f_{n}(x) \rightarrow g(x)\right)$, we generate a rule of the form $\forall x\left(h_{1}(x) \wedge \ldots \wedge h_{n-1}(x) \wedge f_{n}(x) \rightarrow g(x)\right)$ where $h_{i}$ are distractor concepts. Grounded distractor conjuncts are also generated as axioms $h_{i}(c)$, so that, given $f_{n}(c)$, both the gold rule and distractor rule are valid proof steps.
Conjunction elimination Distractors are generated similarly to the conjunction introduction case.
Disjunction introduction Distractors are generated similarly to the conjunction introduction case.
Disjunction elimination Since this deduction step has many premises, multiple distractors are necessary to ensure the model doesn't resort to heuristics. For every rule of the form $\forall x\left(f_{i}(x) \rightarrow g(x)\right)$, two distractor rules are generated: $\forall x\left(f_{i}(x) \rightarrow h^{\prime}(x)\right)$ and $\forall x\left(h_{i}(x) \rightarrow g(x)\right)$. A distractor disjunction is also generated: $h^{\prime \prime}(c) \vee h_{1}(c) \vee \ldots \vee h_{n-1}(c)$.
Proof by contradiction As with disjunction elimination, multiple distractors are necessary here. We generate two distractor rules $\forall x\left(f_{1}(x) \vee \ldots \vee f_{n}(x) \rightarrow h(x)\right)$ and $\forall x\left(h_{1}(x) \vee \ldots \vee h_{n}(x) \rightarrow g(x)\right)$. We also generate the distractor axiom $\neg h^{\prime}(c)$ so that the model is forced to choose between two axioms for the first step of the proof.
To avoid creating inconsistencies when generating a distractor rule, we avoid using existing predicates in the consequent of each rule.</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{8}$ Analogous to the broadly-valid steps in PRONTOQA.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref6:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>