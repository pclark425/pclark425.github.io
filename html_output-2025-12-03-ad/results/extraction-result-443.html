<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-443 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-443</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-443</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-17.html">extraction-schema-17</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <p><strong>Paper ID:</strong> paper-237532584</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2109.08006v3.pdf" target="_blank">Deep Algorithmic Question Answering: Towards a Compositionally Hybrid AI for Algorithmic Reasoning</a></p>
                <p><strong>Paper Abstract:</strong> An important aspect of artificial intelligence (AI) is the ability to reason in a step-by-step"algorithmic"manner that can be inspected and verified for its correctness. This is especially important in the domain of question answering (QA). We argue that the challenge of algorithmic reasoning in QA can be effectively tackled with a"systems"approach to AI which features a hybrid use of symbolic and sub-symbolic methods including deep neural networks. Additionally, we argue that while neural network models with end-to-end training pipelines perform well in narrow applications such as image classification and language modelling, they cannot, on their own, successfully perform algorithmic reasoning, especially if the task spans multiple domains. We discuss a few notable exceptions and point out how they are still limited when the QA problem is widened to include other intelligence-requiring tasks. However, deep learning, and machine learning in general, do play important roles as components in the reasoning process. We propose an approach to algorithm reasoning for QA, Deep Algorithmic Question Answering (DAQA), based on three desirable properties: interpretability, generalizability, and robustness which such an AI system should possess, and conclude that they are best achieved with a combination of hybrid and compositional AI.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e443.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e443.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DAQA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Deep Algorithmic Question Answering</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A proposed hybrid, compositional QA architecture that dynamically constructs deep inference graphs of functional nodes combining symbolic representations and vector embeddings to perform inspectable, multi-step algorithmic reasoning over heterogeneous knowledge bases.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Deep Algorithmic Question Answering (DAQA)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>DAQA is a systems-level hybrid AI for algorithmic reasoning in question answering. It constructs and expands an inference graph at query time by decomposing 'functional nodes' using learned decomposition (Δ) and aggregation (σ) functions. Functional nodes hold (1) symbolic attribute-value data (parsed question variables, KB results, inferred values), (2) the operation(s) to apply (which may be neural networks such as regressors/classifiers), and (3) a mapping model between symbolic and vector representations (embeddings). Edges represent rules/transition functions that drive decomposition and aggregation; transitions can be learned (e.g., by reinforcement learning) or provided. The architecture is modular and compositional: pre-trained neural modules, statistical/arithmetical operations, and symbolic deduction rules are composed dynamically to form algorithms (computational graphs) that are inspectable and updatable as knowledge or submodels change.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Symbolic representations of functional nodes: attribute-value pairs, rule-based decomposition/transition rules, deductive inference over symbolic structures, pre- and post-conditions on modules, and classical symbolic reasoning engines (implicitly rule-based/deductive components for decomposition and recursive reasoning).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Procedural/neural components include pre-trained deep neural networks for semantic parsing, prediction/regression modules, and other statistical or arithmetic inference operations. Reinforcement learning is suggested for learning transition/decomposition policies and search through operation space.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Modular hybrid integration: functional nodes maintain both symbolic and vector representations and include conversion functions (g and g') to map between them; symbolic decomposition rules (Δ) and aggregation selectors (σ) are learned or provided; components are composed dynamically into an inference graph (not end-to-end trained as a monolith). The paper proposes using weak supervision, module-wise training, and reinforcement learning (or similar) to learn transition functions; embeddings aggregate node elements to enable neural components to operate on symbolic state.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Emergent capabilities include: (1) interpretable, inspectable computational graphs representing algorithms (traceable deduction and numeric/inductive steps); (2) compositional generalization by composing existing modules into new algorithms; (3) robustness via alternative inference paths when KBs/data are missing (exploration of multiple deductions); (4) hybrid deductive-inductive reasoning enabling tasks that require both symbolic decomposition and statistical prediction (e.g., combining retrieval, regression prediction, and aggregation).</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Open-domain multi-step question answering requiring algorithmic reasoning across heterogeneous KBs and prediction tasks (no specific benchmark reported).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Designed for broader generalization than narrow end-to-end models by enabling compositional assembly of modules to handle diverse problems and by allowing module updates without retraining the whole system; paper claims improved adaptability to heterogeneous domains but provides no quantitative OOD results.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>High interpretability: inference graphs are inspectable, functional nodes store symbolic state and pre-/post-conditions, and the composed algorithm (sequence of operations) can be examined to verify correctness and conditions for module use.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Open challenges include: converting seamlessly between symbolic and vector representations across domains; the large space of decomposition and aggregation operations requiring search heuristics; difficulty of training the whole system end-to-end; lack of quantitative evaluation in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Principled by complementary strengths and division of labor between symbolic (deduction, explicit rules, pre/post-conditions, inspectability) and sub-symbolic components (statistical induction, perception, prediction). Emphasizes compositionality (dynamic program composition) and hybrid inference graphs as the organizing framework.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Deep Algorithmic Question Answering: Towards a Compositionally Hybrid AI for Algorithmic Reasoning', 'publication_date_yy_mm': '2021-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e443.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e443.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FRANK</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>FRANK QA system / Functional Inferences Over Heterogeneous Data</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid QA architecture that enables recursive deductive reasoning via rules and aggregation of data for prediction using pre-trained neural models; used as prior related work by the paper's author.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Functional inferences over heterogeneous data</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>FRANK QA system</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>FRANK adopts a hybrid inference architecture combining recursive deductive reasoning with the aggregation of heterogeneous data and use of pre-trained neural models for prediction and numeric inference. It dynamically composes modular inference operations beyond initial semantic parses.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Recursive deductive rules and rule-based reasoning over heterogeneous symbolic data (inference engine that constructs deductive proof/plans).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Pre-trained neural models used for prediction/aggregation and numeric/statistical inference operations.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Hybrid architecture where symbolic deduction composes and orchestrates pre-trained neural modules for inductive tasks; however, earlier FRANK lacked a neural representation for inference nodes and automated search over operations.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Supports recursive deduction combined with data aggregation for prediction, enabling answers that require both symbolic decomposition and inductive aggregation across heterogeneous sources.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Question answering over heterogeneous KBs and data requiring functional inferences.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Enables dynamic composition beyond parse-tree-generated programs; claims better flexibility than purely parse-based approaches but no quantitative evidence in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Provides explainable inference traces (cited work 'Explainable inference in the frank query answering system'), but lacks neural representations of nodes limiting some hybrid introspection.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Lacks (1) a neural representation of inference nodes and (2) intelligent search through the space of inference operations, making selection and efficiency suboptimal.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Division of labor: use deductive rules for decomposition/selection and neural modules for inductive aggregation/prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Deep Algorithmic Question Answering: Towards a Compositionally Hybrid AI for Algorithmic Reasoning', 'publication_date_yy_mm': '2021-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e443.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e443.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DeepProbLog</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DeepProbLog: Neural probabilistic logic programming</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neural-probabilistic logic programming framework that integrates neural components with probabilistic logic programming to combine perception and reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>DeepProbLog: Neural probabilistic logic programming</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>DeepProbLog</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>DeepProbLog augments probabilistic logic programming with neural predicates: perception components are implemented as neural networks whose outputs feed into a probabilistic logic program, enabling end-to-end reasoning with learned perception modules within a logic/probabilistic framework.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Probabilistic logic programming (ProbLog) providing symbolic/probabilistic rules and logical inference.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural networks acting as learned probabilistic predicates for perception or uncertain observations.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Tight coupling via neural predicates embedded in a probabilistic logic program; the neural outputs provide probability distributions used by the symbolic probabilistic inference engine (neural+probabilistic logic composition).</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Combines perceptual learning with principled probabilistic symbolic inference, enabling tasks requiring both perception and logical/probabilistic reasoning that neither alone handles well.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Tasks requiring perception + logical/probabilistic reasoning (paper reference only; no specific benchmarks reported here).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Claims improved capability to reason with uncertain perceptual inputs by leveraging symbolic probabilistic rules; no quantitative generalization data provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Symbolic logic program provides an interpretable reasoning trace; probabilistic semantics help quantify uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Not discussed in detail in this paper beyond being cited as a relevant neuro-symbolic approach; integration complexity and scalability are general concerns.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Combines probabilistic logic with neural perception under a unified neuro-symbolic probabilistic programming framework.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Deep Algorithmic Question Answering: Towards a Compositionally Hybrid AI for Algorithmic Reasoning', 'publication_date_yy_mm': '2021-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e443.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e443.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NEURAL TERPRET</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural TERPRET / Differentiable programs with neural libraries</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A differentiable program synthesis approach that learns to write interpretable algorithms while integrating neural perceptual components as library functions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Differentiable programs with neural libraries</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>NEURAL TERPRET</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>NEURAL TERPRET is an end-to-end trainable system that learns interpretable algorithms (programs) by composing differentiable program structures with neural library functions to handle perceptual sub-tasks. Programs remain interpretable while perceptual components are neural.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Interpretable program structure / differentiable program representations that correspond to algorithmic steps (symbolic program skeletons).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural library functions (deep neural networks) used as perceptual or subroutine components invoked by the differentiable program.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Differentiable integration: program execution is differentiable and composes neural subroutines; the combined system is trained end-to-end to learn both program structure and neural library parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Capability to learn interpretable algorithmic programs that incorporate learned perceptual modules, enabling compositional solutions to tasks requiring both symbolic control flow and neural perception.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Program induction and tasks requiring perceptual components combined with algorithmic structure (cited in paper; no specific benchmarks reported here).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Promotes compositional generalization by separating program structure from learned neural subroutines, potentially enabling transfer of learned libraries to new programs; no quantitative claims in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Programs learned are interpretable (symbolic program structure), enabling inspection of control flow and algorithmic steps.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Not discussed in depth here; general concerns include scalability and training complexity for large, open-domain tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Differentiable programming as a bridge between symbolic program structure and neural function approximation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Deep Algorithmic Question Answering: Towards a Compositionally Hybrid AI for Algorithmic Reasoning', 'publication_date_yy_mm': '2021-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e443.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e443.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Neural Algorithmic Reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural algorithmic reasoning (Veličković and Blundell 2021)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A line of work aiming to teach neural networks to imitate classical algorithms (e.g., sorting) and generalize algorithmic behavior; focuses on lower-level algorithmic primitives implemented in neural architectures.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Neural algorithmic reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Neural Algorithmic Reasoning approaches</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Approaches that train neural networks to learn the input/output behavior of classical algorithms and in some cases their internal steps (e.g., graph neural nets trained to replicate algorithmic procedures). The paper cites this as motivation but distinguishes DAQA by granularity and interpretability.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Implicit algorithmic specification derived from classical algorithms (not classical symbolic rules in some variants); treated as target behavior to be learned rather than explicit symbolic programs in many implementations.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural architectures (e.g., graph neural networks) trained end-to-end to emulate algorithmic procedures.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Primarily learning-based: neural networks are trained to reproduce algorithmic mappings; in some variants the algorithmic structure guides network design, but integration is often purely neural (emulation rather than tight neuro-symbolic coupling).</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Neural models can learn to imitate algorithmic behavior and sometimes generalize to larger instances; however, the paper notes limitations in scope (focus on lower-level algorithms) and interpretability (black-box estimation of outputs).</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Algorithmic tasks like sorting, lower-level data-structure algorithms; referenced in conceptual discussion rather than evaluated here.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Some reported ability to generalize to larger problem sizes in the referenced work, but the paper argues such approaches are limited for higher-level, heterogeneous algorithmic reasoning across domains.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Typically low — outputs are estimated by neural nets and internal steps may remain a black box, limiting inspectability.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Limited to lower-level algorithms; black-box nature undermines verification of correct execution for complex, higher-level algorithmic reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Learning-to-imitate algorithms; training neural networks to reproduce algorithmic mappings as a statistical learning problem.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Deep Algorithmic Question Answering: Towards a Compositionally Hybrid AI for Algorithmic Reasoning', 'publication_date_yy_mm': '2021-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e443.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e443.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Neural Symbolic Machines</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural symbolic machines: Learning semantic parsers on freebase with weak supervision</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neuro-symbolic approach that learns to map language to executable programs/queries over symbolic KBs via a neural controller trained with weak supervision.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Neural symbolic machines: Learning semantic parsers on freebase with weak supervision</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Neural Symbolic Machines</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Combines neural sequence models (semantic parsers) with a symbolic program executor over knowledge bases: the neural component generates programs/queries from language and the symbolic executor runs them against KBs; training can use weak supervision (question-answer pairs).</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Symbolic program/query executor over knowledge bases (e.g., logical query languages to access Freebase), providing exact symbolic execution semantics.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural semantic parser (sequence-to-program model) that generates candidate programs from natural language.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Neural generator (imperative) produces symbolic programs which are executed by a symbolic executor; learning couples the two via weak supervision signals (answer-level feedback) rather than end-to-end differentiable composition.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Enables mapping from language to symbolic queries and leverages symbolic execution for precise retrieval/logic while learning flexible parsing from data; supports compositional program generation from language.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Semantic parsing / question answering over Freebase (cited work; no new benchmarks in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Supports compositional generalization via programmatic representations; reliance on weak supervision can limit robustness and requires search/heuristics for program generation.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>High interpretability for the executed program (executable symbolic program is inspectable), while neural parser remains opaque.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Generating correct programs from language under weak supervision is challenging; initial parse may be insufficient and further deductive reasoning may be necessary as noted by the DAQA paper.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Division of labor: neural methods for mapping/induction, symbolic methods for exact execution and reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Deep Algorithmic Question Answering: Towards a Compositionally Hybrid AI for Algorithmic Reasoning', 'publication_date_yy_mm': '2021-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e443.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e443.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AlphaGo</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mastering the game of Go with deep neural networks and tree search</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A landmark system combining deep neural networks for policy/value estimation with Monte Carlo tree search (MCTS) for planning, exemplifying integration of learned models and procedural search.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Mastering the game of Go with deep neural networks and tree search</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AlphaGo (deep nets + MCTS)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>AlphaGo integrates deep policy and value networks (neural components) with Monte Carlo Tree Search (procedural planning/search component). The networks guide search and evaluate positions while MCTS performs deliberate planning over move sequences.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Procedural search/planning component (MCTS) that performs algorithmic exploration of game trees (not classical symbolic logic but procedural algorithmic search).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Deep convolutional neural networks trained for policy and value estimation.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Modular integration where neural networks provide heuristics (policy proposals and value evaluations) to a procedural search algorithm (MCTS); not end-to-end differentiable across the search component.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Combines statistical pattern recognition with deliberate search, producing strong strategic play (planning + learned heuristics) unattainable by either alone at the time.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Game playing: Go (professional-level play), cited as an example of hybrid integration.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Demonstrated ability to generalize learned heuristics within the game domain and to leverage planning for robust decision-making; paper cites as motivating example.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Partial: MCTS traces can be inspected but neural evaluations remain opaque; combined traces provide some insight into decision-making.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Not discussed in detail here; referenced as an example of hybrid success but not directly comparable to DAQA's goals.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Complementary strengths: learned evaluation/guidance + algorithmic planning/search.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Deep Algorithmic Question Answering: Towards a Compositionally Hybrid AI for Algorithmic Reasoning', 'publication_date_yy_mm': '2021-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e443.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e443.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Neural Turing Machine</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural Turing Machines</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neural architecture augmented with an external memory that can learn simple algorithmic tasks like copying and sorting by differentiable attention-based read/write to memory.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Neural turing machines</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Neural Turing Machine (NTM)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>NTMs extend neural networks with an external differentiable memory and attention-based read/write controllers, enabling the network to learn simple programs (copying, sorting) by learning to manipulate memory.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>External memory that can be used to store structured information (but is sub-symbolic and differentiable rather than classical symbolic logic).</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural controller networks (recurrent/attention-based) trained with gradient descent to learn read/write procedures.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Tight differentiable integration: memory operations are differentiable attentional procedures learned end-to-end with the neural controller.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Increased expressivity enabling learning of simple algorithmic behaviors (e.g., copying, sorting) that require step-by-step memory manipulation.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Algorithmic tasks such as copying and sorting (cited as examples).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Can generalize certain algorithmic patterns beyond training in controlled tasks, but scalability to complex, heterogeneous domains is limited according to the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Partial: learned memory access patterns can be inspected to some extent but remain primarily sub-symbolic.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Noted as a method to make neural networks more expressive but not a full solution for higher-level symbolic algorithmic reasoning across domains.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Differentiable memory augmentation as a bridge to algorithmic behavior in neural nets.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Deep Algorithmic Question Answering: Towards a Compositionally Hybrid AI for Algorithmic Reasoning', 'publication_date_yy_mm': '2021-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e443.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e443.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Neural-symbolic integration (compositional)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural-symbolic integration: A compositional perspective</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A survey/perspective describing compositional approaches that treat symbolic and neural modules as black boxes and integrate them by exposing functions to enable modular composition.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Neural-symbolic integration: A compositional perspective</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Compositional neural-symbolic integration (per Tsamoura et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Approaches that support compositionality by treating symbolic and neural modules as interoperable black boxes; composition is achieved by exposing module interfaces/functions and composing them based on semantic parses or learned planners.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Symbolic modules providing interpretable operations (e.g., logical operators, KB queries, symbolic executors) exposed as functions.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural modules providing perception, parsing, or prediction functionality, also exposed as callable functions.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Modular composition through exposed interfaces (function calls), mapping neural modules onto semantic parse trees or program skeletons; composition may be orchestrated by learned controllers or derived from parses.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Enables modular re-use of components, compositional generalization, and combining strengths of symbolic precision with neural flexibility to handle perception and noisy data.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>General neuro-symbolic tasks including VQA and QA via program synthesis; paper cites this perspective as relevant.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Promotes transfer and compositional generalization by assembling modules; actual generalization depends on module design and orchestration policies.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Higher interpretability at the orchestration/program level because symbolic modules and program skeletons are explicit, though neural modules remain opaque.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Shallow parse-tree-based composition can fail when intermediate reasoning steps (e.g., handling missing data) require deeper deductive/recursive exploration beyond the initial program skeleton.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Compositionality and modular interface-based integration of symbolic and neural components.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Deep Algorithmic Question Answering: Towards a Compositionally Hybrid AI for Algorithmic Reasoning', 'publication_date_yy_mm': '2021-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e443.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e443.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of hybrid reasoning systems that combine declarative (symbolic, logic-based, rule-based) and imperative (procedural, neural, step-by-step) approaches, including their architectures, integration methods, emergent properties, and performance characteristics.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Logical Neural Networks</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Logical neural networks</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An approach (cited) that aims to bring logical structure into neural network models by establishing structured correspondences between logical formulae and neural constructs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Logical neural networks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Logical Neural Networks (Riegel et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Frameworks that attempt to create one-to-one correspondences between neurons and elements of logical formulae, enabling networks to represent and manipulate logical structure more explicitly.</td>
                        </tr>
                        <tr>
                            <td><strong>declarative_component</strong></td>
                            <td>Formal logic structures (logical formulae) mapped into network constructs to enable symbolic-like manipulation.</td>
                        </tr>
                        <tr>
                            <td><strong>imperative_component</strong></td>
                            <td>Neural network architectures whose components correspond to logical elements and are trained with gradient methods.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_method</strong></td>
                            <td>Structural mapping/differentiable correspondences between logical formulae and neural units (neuron-to-formula mapping) to embed reasoning within neural computation.</td>
                        </tr>
                        <tr>
                            <td><strong>emergent_properties</strong></td>
                            <td>Potential to combine logical interpretability with neural generalization; claimed ability to incorporate logical constraints and structure inside neural computation.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Neural-symbolic reasoning tasks (cited as part of hybrid literature; no task-specific evaluation provided here).</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>declarative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>imperative_only_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparative_results</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_properties</strong></td>
                            <td>Aims to improve structured generalization by encoding logical relationships directly in network topology/activation semantics; no quantitative claims in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_properties</strong></td>
                            <td>Improves interpretability by aligning network elements with logical formulae, enabling some symbolic inspection of network behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Not detailed here; general challenges include scaling mappings to real-world complex logic and training stability.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_framework</strong></td>
                            <td>Structural correspondence between logic and neural elements as a bridge for neuro-symbolic reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Deep Algorithmic Question Answering: Towards a Compositionally Hybrid AI for Algorithmic Reasoning', 'publication_date_yy_mm': '2021-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Neural algorithmic reasoning <em>(Rating: 2)</em></li>
                <li>DeepProbLog: Neural probabilistic logic programming <em>(Rating: 2)</em></li>
                <li>Differentiable programs with neural libraries <em>(Rating: 2)</em></li>
                <li>Neural turing machines <em>(Rating: 2)</em></li>
                <li>Neural-symbolic integration: A compositional perspective <em>(Rating: 2)</em></li>
                <li>Functional inferences over heterogeneous data <em>(Rating: 2)</em></li>
                <li>Neural symbolic machines: Learning semantic parsers on freebase with weak supervision <em>(Rating: 2)</em></li>
                <li>Mastering the game of Go with deep neural networks and tree search <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-443",
    "paper_id": "paper-237532584",
    "extraction_schema_id": "extraction-schema-17",
    "extracted_data": [
        {
            "name_short": "DAQA",
            "name_full": "Deep Algorithmic Question Answering",
            "brief_description": "A proposed hybrid, compositional QA architecture that dynamically constructs deep inference graphs of functional nodes combining symbolic representations and vector embeddings to perform inspectable, multi-step algorithmic reasoning over heterogeneous knowledge bases.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Deep Algorithmic Question Answering (DAQA)",
            "system_description": "DAQA is a systems-level hybrid AI for algorithmic reasoning in question answering. It constructs and expands an inference graph at query time by decomposing 'functional nodes' using learned decomposition (Δ) and aggregation (σ) functions. Functional nodes hold (1) symbolic attribute-value data (parsed question variables, KB results, inferred values), (2) the operation(s) to apply (which may be neural networks such as regressors/classifiers), and (3) a mapping model between symbolic and vector representations (embeddings). Edges represent rules/transition functions that drive decomposition and aggregation; transitions can be learned (e.g., by reinforcement learning) or provided. The architecture is modular and compositional: pre-trained neural modules, statistical/arithmetical operations, and symbolic deduction rules are composed dynamically to form algorithms (computational graphs) that are inspectable and updatable as knowledge or submodels change.",
            "declarative_component": "Symbolic representations of functional nodes: attribute-value pairs, rule-based decomposition/transition rules, deductive inference over symbolic structures, pre- and post-conditions on modules, and classical symbolic reasoning engines (implicitly rule-based/deductive components for decomposition and recursive reasoning).",
            "imperative_component": "Procedural/neural components include pre-trained deep neural networks for semantic parsing, prediction/regression modules, and other statistical or arithmetic inference operations. Reinforcement learning is suggested for learning transition/decomposition policies and search through operation space.",
            "integration_method": "Modular hybrid integration: functional nodes maintain both symbolic and vector representations and include conversion functions (g and g') to map between them; symbolic decomposition rules (Δ) and aggregation selectors (σ) are learned or provided; components are composed dynamically into an inference graph (not end-to-end trained as a monolith). The paper proposes using weak supervision, module-wise training, and reinforcement learning (or similar) to learn transition functions; embeddings aggregate node elements to enable neural components to operate on symbolic state.",
            "emergent_properties": "Emergent capabilities include: (1) interpretable, inspectable computational graphs representing algorithms (traceable deduction and numeric/inductive steps); (2) compositional generalization by composing existing modules into new algorithms; (3) robustness via alternative inference paths when KBs/data are missing (exploration of multiple deductions); (4) hybrid deductive-inductive reasoning enabling tasks that require both symbolic decomposition and statistical prediction (e.g., combining retrieval, regression prediction, and aggregation).",
            "task_or_benchmark": "Open-domain multi-step question answering requiring algorithmic reasoning across heterogeneous KBs and prediction tasks (no specific benchmark reported).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Designed for broader generalization than narrow end-to-end models by enabling compositional assembly of modules to handle diverse problems and by allowing module updates without retraining the whole system; paper claims improved adaptability to heterogeneous domains but provides no quantitative OOD results.",
            "interpretability_properties": "High interpretability: inference graphs are inspectable, functional nodes store symbolic state and pre-/post-conditions, and the composed algorithm (sequence of operations) can be examined to verify correctness and conditions for module use.",
            "limitations_or_failures": "Open challenges include: converting seamlessly between symbolic and vector representations across domains; the large space of decomposition and aggregation operations requiring search heuristics; difficulty of training the whole system end-to-end; lack of quantitative evaluation in the paper.",
            "theoretical_framework": "Principled by complementary strengths and division of labor between symbolic (deduction, explicit rules, pre/post-conditions, inspectability) and sub-symbolic components (statistical induction, perception, prediction). Emphasizes compositionality (dynamic program composition) and hybrid inference graphs as the organizing framework.",
            "uuid": "e443.0",
            "source_info": {
                "paper_title": "Deep Algorithmic Question Answering: Towards a Compositionally Hybrid AI for Algorithmic Reasoning",
                "publication_date_yy_mm": "2021-09"
            }
        },
        {
            "name_short": "FRANK",
            "name_full": "FRANK QA system / Functional Inferences Over Heterogeneous Data",
            "brief_description": "A hybrid QA architecture that enables recursive deductive reasoning via rules and aggregation of data for prediction using pre-trained neural models; used as prior related work by the paper's author.",
            "citation_title": "Functional inferences over heterogeneous data",
            "mention_or_use": "mention",
            "system_name": "FRANK QA system",
            "system_description": "FRANK adopts a hybrid inference architecture combining recursive deductive reasoning with the aggregation of heterogeneous data and use of pre-trained neural models for prediction and numeric inference. It dynamically composes modular inference operations beyond initial semantic parses.",
            "declarative_component": "Recursive deductive rules and rule-based reasoning over heterogeneous symbolic data (inference engine that constructs deductive proof/plans).",
            "imperative_component": "Pre-trained neural models used for prediction/aggregation and numeric/statistical inference operations.",
            "integration_method": "Hybrid architecture where symbolic deduction composes and orchestrates pre-trained neural modules for inductive tasks; however, earlier FRANK lacked a neural representation for inference nodes and automated search over operations.",
            "emergent_properties": "Supports recursive deduction combined with data aggregation for prediction, enabling answers that require both symbolic decomposition and inductive aggregation across heterogeneous sources.",
            "task_or_benchmark": "Question answering over heterogeneous KBs and data requiring functional inferences.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Enables dynamic composition beyond parse-tree-generated programs; claims better flexibility than purely parse-based approaches but no quantitative evidence in this paper.",
            "interpretability_properties": "Provides explainable inference traces (cited work 'Explainable inference in the frank query answering system'), but lacks neural representations of nodes limiting some hybrid introspection.",
            "limitations_or_failures": "Lacks (1) a neural representation of inference nodes and (2) intelligent search through the space of inference operations, making selection and efficiency suboptimal.",
            "theoretical_framework": "Division of labor: use deductive rules for decomposition/selection and neural modules for inductive aggregation/prediction.",
            "uuid": "e443.1",
            "source_info": {
                "paper_title": "Deep Algorithmic Question Answering: Towards a Compositionally Hybrid AI for Algorithmic Reasoning",
                "publication_date_yy_mm": "2021-09"
            }
        },
        {
            "name_short": "DeepProbLog",
            "name_full": "DeepProbLog: Neural probabilistic logic programming",
            "brief_description": "A neural-probabilistic logic programming framework that integrates neural components with probabilistic logic programming to combine perception and reasoning.",
            "citation_title": "DeepProbLog: Neural probabilistic logic programming",
            "mention_or_use": "mention",
            "system_name": "DeepProbLog",
            "system_description": "DeepProbLog augments probabilistic logic programming with neural predicates: perception components are implemented as neural networks whose outputs feed into a probabilistic logic program, enabling end-to-end reasoning with learned perception modules within a logic/probabilistic framework.",
            "declarative_component": "Probabilistic logic programming (ProbLog) providing symbolic/probabilistic rules and logical inference.",
            "imperative_component": "Neural networks acting as learned probabilistic predicates for perception or uncertain observations.",
            "integration_method": "Tight coupling via neural predicates embedded in a probabilistic logic program; the neural outputs provide probability distributions used by the symbolic probabilistic inference engine (neural+probabilistic logic composition).",
            "emergent_properties": "Combines perceptual learning with principled probabilistic symbolic inference, enabling tasks requiring both perception and logical/probabilistic reasoning that neither alone handles well.",
            "task_or_benchmark": "Tasks requiring perception + logical/probabilistic reasoning (paper reference only; no specific benchmarks reported here).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Claims improved capability to reason with uncertain perceptual inputs by leveraging symbolic probabilistic rules; no quantitative generalization data provided in this paper.",
            "interpretability_properties": "Symbolic logic program provides an interpretable reasoning trace; probabilistic semantics help quantify uncertainty.",
            "limitations_or_failures": "Not discussed in detail in this paper beyond being cited as a relevant neuro-symbolic approach; integration complexity and scalability are general concerns.",
            "theoretical_framework": "Combines probabilistic logic with neural perception under a unified neuro-symbolic probabilistic programming framework.",
            "uuid": "e443.2",
            "source_info": {
                "paper_title": "Deep Algorithmic Question Answering: Towards a Compositionally Hybrid AI for Algorithmic Reasoning",
                "publication_date_yy_mm": "2021-09"
            }
        },
        {
            "name_short": "NEURAL TERPRET",
            "name_full": "Neural TERPRET / Differentiable programs with neural libraries",
            "brief_description": "A differentiable program synthesis approach that learns to write interpretable algorithms while integrating neural perceptual components as library functions.",
            "citation_title": "Differentiable programs with neural libraries",
            "mention_or_use": "mention",
            "system_name": "NEURAL TERPRET",
            "system_description": "NEURAL TERPRET is an end-to-end trainable system that learns interpretable algorithms (programs) by composing differentiable program structures with neural library functions to handle perceptual sub-tasks. Programs remain interpretable while perceptual components are neural.",
            "declarative_component": "Interpretable program structure / differentiable program representations that correspond to algorithmic steps (symbolic program skeletons).",
            "imperative_component": "Neural library functions (deep neural networks) used as perceptual or subroutine components invoked by the differentiable program.",
            "integration_method": "Differentiable integration: program execution is differentiable and composes neural subroutines; the combined system is trained end-to-end to learn both program structure and neural library parameters.",
            "emergent_properties": "Capability to learn interpretable algorithmic programs that incorporate learned perceptual modules, enabling compositional solutions to tasks requiring both symbolic control flow and neural perception.",
            "task_or_benchmark": "Program induction and tasks requiring perceptual components combined with algorithmic structure (cited in paper; no specific benchmarks reported here).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Promotes compositional generalization by separating program structure from learned neural subroutines, potentially enabling transfer of learned libraries to new programs; no quantitative claims in this paper.",
            "interpretability_properties": "Programs learned are interpretable (symbolic program structure), enabling inspection of control flow and algorithmic steps.",
            "limitations_or_failures": "Not discussed in depth here; general concerns include scalability and training complexity for large, open-domain tasks.",
            "theoretical_framework": "Differentiable programming as a bridge between symbolic program structure and neural function approximation.",
            "uuid": "e443.3",
            "source_info": {
                "paper_title": "Deep Algorithmic Question Answering: Towards a Compositionally Hybrid AI for Algorithmic Reasoning",
                "publication_date_yy_mm": "2021-09"
            }
        },
        {
            "name_short": "Neural Algorithmic Reasoning",
            "name_full": "Neural algorithmic reasoning (Veličković and Blundell 2021)",
            "brief_description": "A line of work aiming to teach neural networks to imitate classical algorithms (e.g., sorting) and generalize algorithmic behavior; focuses on lower-level algorithmic primitives implemented in neural architectures.",
            "citation_title": "Neural algorithmic reasoning",
            "mention_or_use": "mention",
            "system_name": "Neural Algorithmic Reasoning approaches",
            "system_description": "Approaches that train neural networks to learn the input/output behavior of classical algorithms and in some cases their internal steps (e.g., graph neural nets trained to replicate algorithmic procedures). The paper cites this as motivation but distinguishes DAQA by granularity and interpretability.",
            "declarative_component": "Implicit algorithmic specification derived from classical algorithms (not classical symbolic rules in some variants); treated as target behavior to be learned rather than explicit symbolic programs in many implementations.",
            "imperative_component": "Neural architectures (e.g., graph neural networks) trained end-to-end to emulate algorithmic procedures.",
            "integration_method": "Primarily learning-based: neural networks are trained to reproduce algorithmic mappings; in some variants the algorithmic structure guides network design, but integration is often purely neural (emulation rather than tight neuro-symbolic coupling).",
            "emergent_properties": "Neural models can learn to imitate algorithmic behavior and sometimes generalize to larger instances; however, the paper notes limitations in scope (focus on lower-level algorithms) and interpretability (black-box estimation of outputs).",
            "task_or_benchmark": "Algorithmic tasks like sorting, lower-level data-structure algorithms; referenced in conceptual discussion rather than evaluated here.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Some reported ability to generalize to larger problem sizes in the referenced work, but the paper argues such approaches are limited for higher-level, heterogeneous algorithmic reasoning across domains.",
            "interpretability_properties": "Typically low — outputs are estimated by neural nets and internal steps may remain a black box, limiting inspectability.",
            "limitations_or_failures": "Limited to lower-level algorithms; black-box nature undermines verification of correct execution for complex, higher-level algorithmic reasoning.",
            "theoretical_framework": "Learning-to-imitate algorithms; training neural networks to reproduce algorithmic mappings as a statistical learning problem.",
            "uuid": "e443.4",
            "source_info": {
                "paper_title": "Deep Algorithmic Question Answering: Towards a Compositionally Hybrid AI for Algorithmic Reasoning",
                "publication_date_yy_mm": "2021-09"
            }
        },
        {
            "name_short": "Neural Symbolic Machines",
            "name_full": "Neural symbolic machines: Learning semantic parsers on freebase with weak supervision",
            "brief_description": "A neuro-symbolic approach that learns to map language to executable programs/queries over symbolic KBs via a neural controller trained with weak supervision.",
            "citation_title": "Neural symbolic machines: Learning semantic parsers on freebase with weak supervision",
            "mention_or_use": "mention",
            "system_name": "Neural Symbolic Machines",
            "system_description": "Combines neural sequence models (semantic parsers) with a symbolic program executor over knowledge bases: the neural component generates programs/queries from language and the symbolic executor runs them against KBs; training can use weak supervision (question-answer pairs).",
            "declarative_component": "Symbolic program/query executor over knowledge bases (e.g., logical query languages to access Freebase), providing exact symbolic execution semantics.",
            "imperative_component": "Neural semantic parser (sequence-to-program model) that generates candidate programs from natural language.",
            "integration_method": "Neural generator (imperative) produces symbolic programs which are executed by a symbolic executor; learning couples the two via weak supervision signals (answer-level feedback) rather than end-to-end differentiable composition.",
            "emergent_properties": "Enables mapping from language to symbolic queries and leverages symbolic execution for precise retrieval/logic while learning flexible parsing from data; supports compositional program generation from language.",
            "task_or_benchmark": "Semantic parsing / question answering over Freebase (cited work; no new benchmarks in this paper).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Supports compositional generalization via programmatic representations; reliance on weak supervision can limit robustness and requires search/heuristics for program generation.",
            "interpretability_properties": "High interpretability for the executed program (executable symbolic program is inspectable), while neural parser remains opaque.",
            "limitations_or_failures": "Generating correct programs from language under weak supervision is challenging; initial parse may be insufficient and further deductive reasoning may be necessary as noted by the DAQA paper.",
            "theoretical_framework": "Division of labor: neural methods for mapping/induction, symbolic methods for exact execution and reasoning.",
            "uuid": "e443.5",
            "source_info": {
                "paper_title": "Deep Algorithmic Question Answering: Towards a Compositionally Hybrid AI for Algorithmic Reasoning",
                "publication_date_yy_mm": "2021-09"
            }
        },
        {
            "name_short": "AlphaGo",
            "name_full": "Mastering the game of Go with deep neural networks and tree search",
            "brief_description": "A landmark system combining deep neural networks for policy/value estimation with Monte Carlo tree search (MCTS) for planning, exemplifying integration of learned models and procedural search.",
            "citation_title": "Mastering the game of Go with deep neural networks and tree search",
            "mention_or_use": "mention",
            "system_name": "AlphaGo (deep nets + MCTS)",
            "system_description": "AlphaGo integrates deep policy and value networks (neural components) with Monte Carlo Tree Search (procedural planning/search component). The networks guide search and evaluate positions while MCTS performs deliberate planning over move sequences.",
            "declarative_component": "Procedural search/planning component (MCTS) that performs algorithmic exploration of game trees (not classical symbolic logic but procedural algorithmic search).",
            "imperative_component": "Deep convolutional neural networks trained for policy and value estimation.",
            "integration_method": "Modular integration where neural networks provide heuristics (policy proposals and value evaluations) to a procedural search algorithm (MCTS); not end-to-end differentiable across the search component.",
            "emergent_properties": "Combines statistical pattern recognition with deliberate search, producing strong strategic play (planning + learned heuristics) unattainable by either alone at the time.",
            "task_or_benchmark": "Game playing: Go (professional-level play), cited as an example of hybrid integration.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Demonstrated ability to generalize learned heuristics within the game domain and to leverage planning for robust decision-making; paper cites as motivating example.",
            "interpretability_properties": "Partial: MCTS traces can be inspected but neural evaluations remain opaque; combined traces provide some insight into decision-making.",
            "limitations_or_failures": "Not discussed in detail here; referenced as an example of hybrid success but not directly comparable to DAQA's goals.",
            "theoretical_framework": "Complementary strengths: learned evaluation/guidance + algorithmic planning/search.",
            "uuid": "e443.6",
            "source_info": {
                "paper_title": "Deep Algorithmic Question Answering: Towards a Compositionally Hybrid AI for Algorithmic Reasoning",
                "publication_date_yy_mm": "2021-09"
            }
        },
        {
            "name_short": "Neural Turing Machine",
            "name_full": "Neural Turing Machines",
            "brief_description": "A neural architecture augmented with an external memory that can learn simple algorithmic tasks like copying and sorting by differentiable attention-based read/write to memory.",
            "citation_title": "Neural turing machines",
            "mention_or_use": "mention",
            "system_name": "Neural Turing Machine (NTM)",
            "system_description": "NTMs extend neural networks with an external differentiable memory and attention-based read/write controllers, enabling the network to learn simple programs (copying, sorting) by learning to manipulate memory.",
            "declarative_component": "External memory that can be used to store structured information (but is sub-symbolic and differentiable rather than classical symbolic logic).",
            "imperative_component": "Neural controller networks (recurrent/attention-based) trained with gradient descent to learn read/write procedures.",
            "integration_method": "Tight differentiable integration: memory operations are differentiable attentional procedures learned end-to-end with the neural controller.",
            "emergent_properties": "Increased expressivity enabling learning of simple algorithmic behaviors (e.g., copying, sorting) that require step-by-step memory manipulation.",
            "task_or_benchmark": "Algorithmic tasks such as copying and sorting (cited as examples).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Can generalize certain algorithmic patterns beyond training in controlled tasks, but scalability to complex, heterogeneous domains is limited according to the paper.",
            "interpretability_properties": "Partial: learned memory access patterns can be inspected to some extent but remain primarily sub-symbolic.",
            "limitations_or_failures": "Noted as a method to make neural networks more expressive but not a full solution for higher-level symbolic algorithmic reasoning across domains.",
            "theoretical_framework": "Differentiable memory augmentation as a bridge to algorithmic behavior in neural nets.",
            "uuid": "e443.7",
            "source_info": {
                "paper_title": "Deep Algorithmic Question Answering: Towards a Compositionally Hybrid AI for Algorithmic Reasoning",
                "publication_date_yy_mm": "2021-09"
            }
        },
        {
            "name_short": "Neural-symbolic integration (compositional)",
            "name_full": "Neural-symbolic integration: A compositional perspective",
            "brief_description": "A survey/perspective describing compositional approaches that treat symbolic and neural modules as black boxes and integrate them by exposing functions to enable modular composition.",
            "citation_title": "Neural-symbolic integration: A compositional perspective",
            "mention_or_use": "mention",
            "system_name": "Compositional neural-symbolic integration (per Tsamoura et al.)",
            "system_description": "Approaches that support compositionality by treating symbolic and neural modules as interoperable black boxes; composition is achieved by exposing module interfaces/functions and composing them based on semantic parses or learned planners.",
            "declarative_component": "Symbolic modules providing interpretable operations (e.g., logical operators, KB queries, symbolic executors) exposed as functions.",
            "imperative_component": "Neural modules providing perception, parsing, or prediction functionality, also exposed as callable functions.",
            "integration_method": "Modular composition through exposed interfaces (function calls), mapping neural modules onto semantic parse trees or program skeletons; composition may be orchestrated by learned controllers or derived from parses.",
            "emergent_properties": "Enables modular re-use of components, compositional generalization, and combining strengths of symbolic precision with neural flexibility to handle perception and noisy data.",
            "task_or_benchmark": "General neuro-symbolic tasks including VQA and QA via program synthesis; paper cites this perspective as relevant.",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Promotes transfer and compositional generalization by assembling modules; actual generalization depends on module design and orchestration policies.",
            "interpretability_properties": "Higher interpretability at the orchestration/program level because symbolic modules and program skeletons are explicit, though neural modules remain opaque.",
            "limitations_or_failures": "Shallow parse-tree-based composition can fail when intermediate reasoning steps (e.g., handling missing data) require deeper deductive/recursive exploration beyond the initial program skeleton.",
            "theoretical_framework": "Compositionality and modular interface-based integration of symbolic and neural components.",
            "uuid": "e443.8",
            "source_info": {
                "paper_title": "Deep Algorithmic Question Answering: Towards a Compositionally Hybrid AI for Algorithmic Reasoning",
                "publication_date_yy_mm": "2021-09"
            }
        },
        {
            "name_short": "Logical Neural Networks",
            "name_full": "Logical neural networks",
            "brief_description": "An approach (cited) that aims to bring logical structure into neural network models by establishing structured correspondences between logical formulae and neural constructs.",
            "citation_title": "Logical neural networks",
            "mention_or_use": "mention",
            "system_name": "Logical Neural Networks (Riegel et al.)",
            "system_description": "Frameworks that attempt to create one-to-one correspondences between neurons and elements of logical formulae, enabling networks to represent and manipulate logical structure more explicitly.",
            "declarative_component": "Formal logic structures (logical formulae) mapped into network constructs to enable symbolic-like manipulation.",
            "imperative_component": "Neural network architectures whose components correspond to logical elements and are trained with gradient methods.",
            "integration_method": "Structural mapping/differentiable correspondences between logical formulae and neural units (neuron-to-formula mapping) to embed reasoning within neural computation.",
            "emergent_properties": "Potential to combine logical interpretability with neural generalization; claimed ability to incorporate logical constraints and structure inside neural computation.",
            "task_or_benchmark": "Neural-symbolic reasoning tasks (cited as part of hybrid literature; no task-specific evaluation provided here).",
            "hybrid_performance": null,
            "declarative_only_performance": null,
            "imperative_only_performance": null,
            "has_comparative_results": false,
            "generalization_properties": "Aims to improve structured generalization by encoding logical relationships directly in network topology/activation semantics; no quantitative claims in this paper.",
            "interpretability_properties": "Improves interpretability by aligning network elements with logical formulae, enabling some symbolic inspection of network behavior.",
            "limitations_or_failures": "Not detailed here; general challenges include scaling mappings to real-world complex logic and training stability.",
            "theoretical_framework": "Structural correspondence between logic and neural elements as a bridge for neuro-symbolic reasoning.",
            "uuid": "e443.9",
            "source_info": {
                "paper_title": "Deep Algorithmic Question Answering: Towards a Compositionally Hybrid AI for Algorithmic Reasoning",
                "publication_date_yy_mm": "2021-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Neural algorithmic reasoning",
            "rating": 2,
            "sanitized_title": "neural_algorithmic_reasoning"
        },
        {
            "paper_title": "DeepProbLog: Neural probabilistic logic programming",
            "rating": 2,
            "sanitized_title": "deepproblog_neural_probabilistic_logic_programming"
        },
        {
            "paper_title": "Differentiable programs with neural libraries",
            "rating": 2,
            "sanitized_title": "differentiable_programs_with_neural_libraries"
        },
        {
            "paper_title": "Neural turing machines",
            "rating": 2,
            "sanitized_title": "neural_turing_machines"
        },
        {
            "paper_title": "Neural-symbolic integration: A compositional perspective",
            "rating": 2,
            "sanitized_title": "neuralsymbolic_integration_a_compositional_perspective"
        },
        {
            "paper_title": "Functional inferences over heterogeneous data",
            "rating": 2,
            "sanitized_title": "functional_inferences_over_heterogeneous_data"
        },
        {
            "paper_title": "Neural symbolic machines: Learning semantic parsers on freebase with weak supervision",
            "rating": 2,
            "sanitized_title": "neural_symbolic_machines_learning_semantic_parsers_on_freebase_with_weak_supervision"
        },
        {
            "paper_title": "Mastering the game of Go with deep neural networks and tree search",
            "rating": 1,
            "sanitized_title": "mastering_the_game_of_go_with_deep_neural_networks_and_tree_search"
        }
    ],
    "cost": 0.018235,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Deep Algorithmic Question Answering: Towards a Compositionally Hybrid AI for Algorithmic Reasoning</p>
<p>Kwabena Nuamah k.nuamah@ed.ac.uk 
School of Informatics
University of Edinburgh</p>
<p>Deep Algorithmic Question Answering: Towards a Compositionally Hybrid AI for Algorithmic Reasoning</p>
<p>An important aspect of artificial intelligence (AI) is the ability to reason in a step-by-step "algorithmic" manner that can be inspected and verified for its correctness. This is especially important in the domain of question answering (QA). We argue that the challenge of algorithmic reasoning in QA can be effectively tackled with a "systems" approach to AI which features a hybrid use of symbolic and sub-symbolic methods including deep neural networks. Additionally, we argue that while neural network models with end-to-end training pipelines perform well in narrow applications such as image classification and language modelling, they cannot, on their own, successfully perform algorithmic reasoning, especially if the task spans multiple domains. We discuss a few notable exceptions and point out how they are still limited when the QA problem is widened to include other intelligence-requiring tasks. However, deep learning, and machine learning in general, do play important roles as components in the reasoning process. In this position paper, we propose an approach to algorithm reasoning for QA, Deep Algorithmic Question Answering (DAQA), based on three desirable properties: interpretability, generalizability, and robustness which such an AI system should posses, and conclude that they are best achieved with a combination of hybrid and compositional AI.</p>
<p>Introduction</p>
<p>Algorithms form the basis of problem solving and are, therefore, critical to any attempts to emulate human-like reasoning in AI. Algorithmic reasoning, as defined in (Veličković and Blundell 2021), allows us to automate and engineer systems that reason. An interesting domain in which to apply and evaluate such AI capabilities is that of question answering, and in particular, open domain QA. Some of the early techniques in QA, e.g. (Green et al. 1961), focused on reasoning about problems in a purely logical manner. However, recent techniques have been aimed more at the challenges of constructing the right queries to retrieve answers from knowledge bases (or sources) (KBs) ( (Usbeck et al. 2017), (Dubey et al. 2019)) as well as the construction of very large language models over a large number of documents from the web (Devlin et al. 2019).</p>
<p>Yet, many other tasks, such as the automatic selection of KBs and relevant knowledge, choice of inference algorithms, and how to combine them, are all important to fully automate the QA process. Several of these tasks are scoped out as engineering tasks which experts perform when deploying these AI systems (see Figure 1). We argue that these scoped out tasks should be part of the AI models which are built for QA tasks, as they are key ingredients in the full automation of the QA process. Deep Algorithmic Question Answering focuses on these tasks as well as the traditional QA problem with the added task of tackling questions that require multiple steps of reasoning to solve.</p>
<p>In this position paper we will focus on the QA problem, especially since QA is one of the longest standing applications of AI and since many other AI problems can be framed as QA problems. Why is it important to take such a high level perspective of QA and algorithmic reasoning, instead of one at the deeper level of knowledge/vector representation and semantics?</p>
<p>• It puts into sharper focus how narrow many popular AI techniques are: e.g, language modelling, image classification, etc. 'Narrow' in the sense that the models excel at perception tasks for which lots of training data is available, and in the sense that they are restricted to those specific tasks and cannot be applied to other tasks 'as-is' without major changes to the models or how they used. • It highlights how unreasonable many of the assumptions in AI models are when applied to real-world problems. For instance, (1) the assumptions that the answer to a question will be from the same distribution of data which was used to train the model; (2) the assumption that the model always has access to all the data that it needs to answer a question such that the decision of choosing which KBs to use to answer a question is never a problem. In many real-world applications, the data sources are diverse and heterogeneous, noisy and incomplete. • It shows how many AI techniques fail to address some of the challenging problems that have to be tackled. For example, dealing with uncertainty, noisy and incomplete information from KBs, especially in the context of QA. • It shows how huge aspects of what we currently claim to be AI are heavily dependent on designs and inputs from humans and how much work needs to be done to solve simple tasks without human intervention. For instance, pre-defining which DL models are used to tackle a classification or prediction task. Although tasks such as feature engineering, which was predominantly an expert's task have been replaced by better DL models, the human expertise has only shifted to tasks related to the choice of architecture of the neural network model, dataset selection and pre-processing for training, and the general engineering required to solve the specific task at hand.</p>
<p>• It shows why a compositional and hybrid approach is needed given that many of the tasks cannot simply be handled with an end-to-end training of deep neural network models. We believe that a systems approach to AI is needed to tackle algorithmic reasoning in QA and agree with the claim that there is the need to find new ways to synthesize AI from a hybrid of symbolic methods and deep neural networks (Marcus and Davis 2019).</p>
<p>We conclude that it is important to refine the scope of problems that AI for QA should solve by incorporating those tasks which, in the real-world applications, look messy and are often tackled by humans experts or data annotators. Further, tackling these problems highlights the need for AI approaches that can appropriately leverage both symbolic and sub-symbolic AI methods and also brings to the fore the need to have AI systems that are compositional in order to adapt seamlessly to different problem types.</p>
<p>In the sections that follow, we give some background to algorithmic reasoning, hybrid AI and compositionality, and then describe our proposed DAQA system.</p>
<p>Background</p>
<p>Algorithmic Reasoning</p>
<p>The task of algorithmic reasoning places emphasis on automating systems to reason about problems and programs following similar mechanisms to those which humans use when solving problems (Kröger 1977). However, our interpretation of this task goes beyond the classic logical reasoning context to one where learning and reasoning are combined to tackle more complex and diverse problems. This includes, for instance, choosing which algorithms to use, when and how to combine them (Veličković and Blundell 2021). Its application to question answering means having an automated system which is deliberate in the selection of inference steps needed to answer a question such that the inference process forms a computational graph which represents an algorithm for solving the problem.</p>
<p>We claim that achieving this with a purely symbolic or DL approach is not practical, given the known limitations of symbolic methods and sub-symbolic methods (Marcus and Davis 2019). There is a lot of work ongoing to reconcile these techniques (see section 2.2). However, many of these are either theory-focused, or at levels of abstraction that still makes it hard to tackle algorithmic reasoning in a practical problem domain such as QA.</p>
<p>This work is motivated in part by models proposed in (Veličković and Blundell 2021). However, we note that the authors make assumptions about the contexts in which algorithms are used, and limit the concept of algorithms to a narrow application of a single algorithm that is trained end-toend. This paper extends that notion to include the automatic,  (Fader, Zettlemoyer, and Etzioni 2014), (Liang, Jordan, and Klein 2013), (Nuamah, Bundy, and Lucas 2016), and  focus on the application of rules for decomposing problems in order to find answers, leading to inference processes or plans which are constructed dynamically. We extend some of these ideas in this work. Implicitly, the expectation of algorithmic reasoning is that the process and the inferred answer can be inspected to verify the steps involved in answering a question. This is very different from the expectations one has when using deep neural network models to train end-to-end models where the process of completing the task is not interpretable.</p>
<p>Hybrid AI</p>
<p>Hybrid AI is concerned with the integration of symbolic (logical) and sub-symbolic (DL-based) AI methodologies into neuro-symbolic architectures. This is a rapidly growing field with diverse approaches being explored. We refer you to papers that survey these works including (Besold et al. 2017) and (Belle 2020). Additionally, Henry Kautz's classification of the different types of neural-symbolic systems integrations are outlined in (Lamb et al. 2020). Our notion of hybrid AI is primarily inspired by DARPA's 'Third Wave of AI' research focus (DARPA 2018), "where systems are capable of acquiring new knowledge through generative contextual and explanatory models".</p>
<p>The strengths and shortcomings of both DL and symbolic AI paradigms are well documented. More recently in (Bengio, LeCun, and Hinton 2021), some of the pioneers and advocates of DL for AI highlighted the need to address the limitations of DL in order to tackle some of the human-like reasoning capabilities. In particular, they mention DL's current inability to perform deliberate systematic reasoning and planning as described by Kahneman's 'System 2' reasoning (Kahneman 2012).</p>
<p>Reconciling methodologies in distinct areas of learning and reasoning (e.g. statistics and logic) means combining the respective advantages while circumventing the shortcomings and limitations (Besold et al. 2017). Some of the approaches taken to reconcile symbolic and sub-symbolic reasoning include the following (not in any way exhaustive): creating a one-to-one correspondence between artificial neurons and elements of logical formulae (Riegel et al. 2020); using reinforcement learning with Monte-Carlo tree search to play Go in AlphaGo (Silver et al. 2016); differentiable architecture search by applying reinforcement learning over a discrete and non-differentiable search space (Liu, Simonyan, and Yang 2018); combining deductive and inductive reasoning methods for question answering   , (Nuamah and Bundy 2020); neural networks with external memory in the Neural Turing Machine (NTM) (Graves, Wayne, and Danihelka 2014) and reinforcement learning NTM variants (Zaremba and Sutskever 2016) to make them more expressive; memory networks ) ; probabilistic reasoning and program induction (Manhaeve et al. 2018). There is also a lot of interest in (Cozman and Munhoz 2021) for enhancing machine learning with knowledge representation and reasoning. In addition, relational reasoning using neural networks is showing a lot of promise in the visual QA context (Santoro et al. 2017) (Santoro et al. 2018). A review in (Aditya, Yang, and Baral 2019) also discusses different techniques for integrating knowledge and reasoning for image understanding.</p>
<p>A common theme in most of the work exploring hybrid AI is the need for symbol manipulation on models of the world, while being able to leverage other sub-symbolic machinery to learn these models from examples or to predict actions based on the models. These capabilities are also essential for performing algorithm reasoning.</p>
<p>Compositionality</p>
<p>The space of algorithms and algorithmic reasoning is far too large and varied to construct a single neural network model to solve it in practical way. It is not always possible to program or train one AI system to solve diverse kinds of problems. In many cases, even the ability of an expert to engineer a system to solve a range of problems, such as that of opendomain QA, is limited by the fact that one cannot anticipate all the possible kinds of questions to answer and how to combine existing AI modules achieve it. Compositionality provides a mechanism to compose solutions to problems by automating the combining of existing AI modules to solve new and varied problems. In this work, we use "compositionality" in a loose sense to include the entire spectrum from the high level integration of distinct AI components and systems, through to automatic program composition, all the way to the deeper level integration of knowledge representation, semantics and neural embedding. Different approaches can be used to build such compositional AI systems. We highlight a few below, but it is in no way an exhaustive list. (Gaunt et al. 2017) created an end-to-end trainable system, NEURAL TERPRET, that learns to write interpretable algorithms with perceptual components, while the Neural Turing Machine (Graves, Wayne, and Danihelka 2014) extend neural networks with an external memory such that the network can infer simple programs such as copying and sorting. Some neural-symbolic methods provide compositionality by treating the symbolic and neural network modules both as black boxes and integrating them by exposing appropriate functions (Tsamoura, Hospedales, and Loizos 2021). In a majority of cases, compositionality is achieved by mapping neural network modules onto the semantic parse tree of a natural language question or the generation of sequences of functions from the question text using a trained network (Andreas et al. 2016) (Yi et al. 2019) (Liang et al. 2017) (Kapanipathi et al. 2020) (Johnson et al. 2017a) (Johnson et al. 2017b). The generated program is then executed to answer the question.</p>
<p>However, generating a neural network architecture from a semantic parse tree of natural language text is not enough to achieve algorithmic reasoning. This is because intermediate reasoning steps such has handling failure due to the lack of relevant data cannot be recovered from in a shallow parse tree without any further reasoning or inference steps. Sometimes, the data retrieved at one step during inference determines how the rest of the algorithm is developed. For instance, in a question such as "Which country in Europe will have the highest GDP growth rate by 2032", the kind of data retrieved (or the lack thereof) will determine if retrieval is sufficient, or a more involving regression on past data for prediction will be needed. Hence, the automatic formulation of new algorithms using existing components requires one to look beyond the initial parse tree of the question and to work within the constraints of pre-and post-conditions of the underlying symbolic and sub-symbolic modules in order to combine them appropriately.</p>
<p>Achieving the task of algorithmic reasoning in the domain of question answering requires us to have some expectation of what such a system should look like and how it should behave. We list three of these below, all of which introduce new challenges that, if solved, will advance the development of AI architectures for QA.</p>
<p>• Interpretability: One of the basic requirements of a QA system with algorithmic reasoning capabilities is that its inner workings are interpretable and inspectable by a human user. Additionally, the intepretability allows a user to check if the pre-and post-conditions of the algorithms are satisfied. For instance, if heterogeneous modules are automatically composed to form novel algorithms which answer a question, one should be able to verify that the conditions associated with the appropriate use of the modules have been met. A key requirement for interpretability is a representation of the inference mechanism which supports both symbolic and sub-symbolic inference. For example, a dual (or hybrid) representation which supports both deductive inference through symbol manipulation and inductive inference over data observations using statistical methods will be needed. Better still, a representation which allows for a fluid translation between these representations will be useful.</p>
<p>• Generalizability: It is also important to think of QA problems at a much broader level beyond the narrow vertical perspectives, such as image recognition, prediction or classification tasks, in order to build the capabilities of the AI systems for algorithmic reasoning. One of the criticisms of narrow AI is the fact that they solve very specific problems well, but rarely capture most of the complexities which need to be dealt with in real-world applications. Most of these complexities are often handled by an expert. A desirable feature of AI systems in QA which performs algorithmic reasoning is that they are not restricted to neatly defined problems in benchmark datasets which sometimes lead to over-engineering of AI architectures that are built to exploit biases that are observable in the data set. Additionally, it is desirable for QA systems to be general in how they compose algorithms, both in the aspects of the QA processes that they use and the in kinds of problems that they can solve.</p>
<p>• Robustness: Finally, there is a need to build AI systems that are robust in the presence of noise, incomplete data and uncertainty. Robustness is also needed as knowledge changes or new knowledge is acquired. These are obvious problems that are faced when using AI in the real-world and so working only on problems or data sets that exclude these challenges results in AI systems which are brittle. In algorithmic reasoning in particular, it is necessary to build AI systems which are able to identify these uncertainties and incorporate them in the inference process and in the automatic generation of programs to solve problems. For instance, failures to access data or inconsistencies in data retrieved from KBs should not stop the QA system from finding answers to questions if alternative strategies for solving the question can be found using a different algorithm. However, how the AI system deals with such issues should be transparent to users.</p>
<p>In summary, many of the debates about symbolic versus sub-symbolic AI cease to exist when the scope of the problem being solved is viewed in its entirety; i.e. to include not only the specific task of prediction or classification, but other intermediate reasoning and decision steps (see Figure  1) which are often performed by the creators of the AI system and left out of the scope of what the system does.</p>
<p>Deep Algorithmic QA: Hybrid + Compositionality</p>
<p>Our proposed approach to algorithmic reasoning for question answering, DAQA, leverages both hybrid AI and compositionality. Specifically, we are interested not only in a narrow aspect of the question answering task, but in the often ignored aspects of the tasks usually hidden under the list of things which an engineer or expert user does. DAQA is deep in two senses: (1) the inference graphs constructed are deeper than the initial semantic parse trees of the question;</p>
<p>(2) it uses deep neural networks as part of the inference framework.</p>
<p>We use the following question example to shed light on the different aspects of our proposal: "What will be the population of the country in Europe which is predicted to have the highest GDP in 2032?".</p>
<p>Motivation</p>
<p>First, we make no assumptions about the presence of data needed to answer the question. We only assume that the AI system has a list of different KBs than it can access. These could be web documents sources that it has crawled, publicly available knowledge graphs with interfaces for querying data (e.g. SPARQL (World Wide Web Consortium, W3C 2013) or a web-based application programming interface (API)). This means that the choice of KBs to query and the integration of data from diverse sources is not trivial. Different modalities (text, images, videos) and formalisms (unstructured text, RDF, graph, probabilistic, etc.) make the task all the more difficult.</p>
<p>Second, we do not assume that the answer is pre-stored in any KB. In the question above, chances of having an exact answer stored some knowledge is very low to non-existent. As such, the only way to solve this question is to reason about it and dynamically construct an algorithm that can solve it.</p>
<p>Third, we claim that creating a deep neural network model which is trained in an end-to-end way to tackle open-domain QA including questions of the kind that we have above is not practical with the present state of the technology. However, simpler neural network models are available for solving aspects of the problem, such as the semantic parsing task and the prediction task. This brings to the fore a need for a compositional approach. That is, general purpose neural network models, statistical and arithmetic inference operations can be composed in a dynamic way to construct an appropriate algorithm that solves the question. Constraints Functional node, , with functions and ′ that transform the symbolic attribute-value pairs in to real-valued vectors in q Figure 3: (a) Shows the base inference graph with a question node and an answer node that is to be inferred. They are linked by an edge that can be split by applying decomposition operations on the question node. (b) An inference graph made up of functional nodes and edges labelled by operations for predicting decomposition and aggregation functions. Decomposition sub-graph (in red) is guided by a function ∆ that decomposes a functional node to create new continuations of the inference graph, and aggregation sub-graph (in green) which uses a model σ to select appropriate functions to combine nodes. Functional nodes provide both a symbolic and vector representation of the node's attribute-value internal representation, as well as function g and g for converting between the two representations.</p>
<p>on the individual inference modules such as pre-conditions and post-conditions ensure that they are composed in a computationally valid way.</p>
<p>Fourth, we do not assume that a correct semantic parse of the question is enough to compose a program which answers the question. In addition to semantic parsing, it is necessary to reason about the question to explore possible algorithms which could solve it (see Figure 2). In the above question, for example, there are tasks such as prediction that will not be explicit in the parse tree. As such, it is important to consider deductive methods to decompose the problem. Additionally, such decomposition needs to be recursive and be robust in the event of a failure to infer an answer by exploring different possible deductions simultaneously. Hybrid AI plays a significant role here as it provide a substrate on which to perform reasoning in the inference process while offering a more rigorous inductive mechanisms to draw inferences from data.</p>
<p>Proposed Model</p>
<p>A fundamental part of the above motivation is that of knowledge representation which supports both hybrid AI and compositionality. Although we leverage symbolic AI methods, we do not propose a classic expert system-styled mechanism. Instead, we propose the idea of hybrid inference graphs with functional nodes and illustrate these in Figure  3. An inference graph is constructed and expanded dynamically through the decompositions of its functional nodes using rules that are learned. Functional nodes represent three things:</p>
<ol>
<li>
<p>data: includes parsed information from the question, data to be inferred (represented by variables to be inferred) or data retrieved from KBs or inferred and propagated from other functional nodes.</p>
</li>
<li>
<p>the functional operations to be applied, e.g. regression.</p>
</li>
</ol>
<p>These operation could themselves be neural networks for prediction, classification, etc.</p>
<ol>
<li>a model to convert between the symbolic and vectorized representation of the functional node, possibly obtained through an aggregation of the embeddings of its elements.</li>
</ol>
<p>Functional nodes, therefore, provide support for both the symbolic manipulation of objects and the vector representation which can leverage the capabilities of DL. The edges linking functional nodes in the graph represent rules or transition functions from the state of the functional node to the next. This provides a mechanism for decomposing functional nodes, thereby expanding the frontier of the inference graph. The rules can be provided or learned from data, allowing the inference graph as a whole to be learned. Techniques developed in reinforcement learning can be used to learn these transitions functions in order to predict subsequent decompositions of nodes on the inference graph from a handful of rules and the pre-and post-conditions of the various inference operations.</p>
<p>Training this system as a whole to answer questions can be achieved in two ways. First, one may use some form of weak (or distant) supervision signal such as the question and the expected answer. However, constructing such as large dataset is an expensive and prohibitive process. An alternative is to leverage existing datasets to train the individual modules and learn a model that complements the deduction process by predicting candidate decompositions to be applied and the choice of appropriate operation for aggregating functional nodes.</p>
<p>As new knowledge becomes available, the different submodels needed to construct the inference graph, e.g. the functions ∆ and σ, can updated without having to re-train the entire system. Also, as prior knowledge changes, the representation in the functional nodes n can be updated. Similar to the method used in (Manhaeve et al. 2018), uncertainty values can be inferred and stored in one of the n s attribute-value pairs. This can be the basis of Bayesian updates as prior knowledge from KBs changes.</p>
<p>Discussion</p>
<p>Our proposed approach brings on board novel perspectives on AI for question answering. However, it also builds on some other related ideas and methodologies.</p>
<p>While there have been QA techniques that perform deductive reasoning during inference (e.g. (Fader, Zettlemoyer, and Etzioni 2014)) using operations such as query decomposition and rewriting, they lack the machinery to perform inductive reasoning using more detailed arithmetic and statistical operations. Recent methods such as the FRANK system (Nuamah, Bundy, and Lucas 2016), ) in the FRANK QA system adopt a hybrid inference architecture which allows for deductive reasoning using rules in a recursive manner and aggregation of data for prediction using a variety of inference operations including pre-trained neural network models. However, this approach lacks (1) a neural representation of inference nodes and (2) the ability to intelligently search through the space of inference operations for the appropriate ones to use in order to make inference more efficient. Recent work attempts to improve the automatic selection of kernels for Gaussian Process regression (Fletcher, Bundy, and Nuamah 2021). That said, the recursive approach used allows for the dynamic composition of modular inference operations beyond the one constructed from the syntactic or semantic parse of the question.</p>
<p>AutoML (see survey in (He, Zhao, and Chu 2021)) and AutoAI (Wang et al. 2020) aim to automate the pipeline of ML tasks. Although they address some pipeline tasks such as data cleaning, feature engineering, model selection, etc, current methods do not address some of the reasoning tasks involved in dynamically decomposition the problem to find appropriate answers when specific inference paths fail to yield results.</p>
<p>Many of the QA methods discussed in §2.2 and §2.3 generate programs based on the parse trees from the natural language question, and do not perform any further deductive reasoning or decompositions. As discussed in the respective sections, they are focused on other neuro-symbolic tasks such as integrating knowledge into neural networks and do tackle many of the tasks discussed in §4.</p>
<p>Although (Veličković and Blundell 2021) proposes ideas for achieving neural algorithmic reasoning, it differs from our proposal in two main ways. First, the notion of algorithms is at a different level of granularity. The focus in that paper is on 'lower' level algorithms such as sorting. More complex algorithms which involve higher level operations such as regression for prediction and many other arithmetic and statistical operations are not explored. Secondly, estimating the outputs of the algorithm using a purely neural network approach still suffers from a lack of interpretability given that it is still a black-box from the perspective of a user. This makes it very hard to verify that the neural network is executing the algorithms correctly.</p>
<p>It is worth noting the impact that large language models like GPT-3 (Brown et al. 2020) have had on QA and AI in general. Despite its limitations, as discussed in (Marcus and Davies 2020), its role as a pre-trained model in fine-tuning tasks in other models, for example in CLIP (Radford et al. 2021), is relevant to our proposed inference model. On its own, though, such large language models do not adequately address the desired properties we aim for.</p>
<p>Nevertheless, our proposed model also has some difficulties that need to be overcome. First, constructing a model which allows for the seamless conversion between symbolic and vector representations of the functional nodes across multiple domains is a hard problem and is still an active research area in neuro-symbolic AI. The space of decomposition and aggregation operations is also very large, so, appropriate search optimisations and heuristics will have to be developed to make it tractable. Promising work in architecture search using reinforcement learning (Liu, Simonyan, and Yang 2018) could offer a viable solution. Finally, training the model as a whole will be very hard, but reusing and fine-tuning pre-trained models in a plug-and-play manner within the inference architecture may be a possible solution.</p>
<p>Conclusion</p>
<p>The problem of algorithmic reasoning is one that fits well with the domain of QA since it helps to automate several aspects of the QA pipeline and leads to interpretable models for answering questions. We claim that a hybrid approach to AI with a strong element of compositionality is needed to tackle such a perspective on QA and other AI problems. We have proposed a systems approach to AI which leverages both symbolic and sub-symbolic methods in a framework that leads to solutions which are not possible by either one of these paradigms alone.</p>
<p>Figure 2 :
2Going beyond the semantic parse tree of the question by applying additional decompositions based on rules or pre-trained models for predicting continuations of the inference plan.
AcknowledgmentThe author would like to thank Vaishak Belle, Alan Bundy and Thomas Fletcher for feedback on an earlier draft and Huawei for supporting the research on which this paper was based under grant HO2017050001B8s. The author would also like to thank reviewers for valuable feedback.
Integrating knowledge and reasoning in image understanding. S Aditya, Y Yang, C Baral, arXiv:1906.09954arXiv preprintAditya, S.; Yang, Y.; and Baral, C. 2019. Integrating knowl- edge and reasoning in image understanding. arXiv preprint arXiv:1906.09954.</p>
<p>J Andreas, M Rohrbach, T Darrell, D Klein, arXiv:1601.01705Learning to compose neural networks for question answering. csAndreas, J.; Rohrbach, M.; Darrell, T.; and Klein, D. 2016. Learning to compose neural networks for question answer- ing. arXiv:1601.01705 [cs].</p>
<p>Symbolic Logic meets Machine Learning: A Brief Survey in Infinite Domains. V Belle, arXiv:2006.08480Belle, V. 2020. Symbolic Logic meets Machine Learning: A Brief Survey in Infinite Domains. arXiv:2006.08480 [cs].</p>
<p>Deep learning for AI. Y Bengio, Y Lecun, G Hinton, Communications of the ACM. 647Bengio, Y.; LeCun, Y.; and Hinton, G. 2021. Deep learning for AI. Communications of the ACM 64(7):58-65.</p>
<p>T R Besold, A Garcez, S Bader, H Bowman, P Domingos, P Hitzler, K.-U Kuehnberger, L C Lamb, D Lowd, P M V Lima, L De Penning, G Pinkas, H Poon, G Zaverucha, arXiv:1711.03902Neural-symbolic learning and reasoning: A survey and interpretation. csBesold, T. R.; d'Avila Garcez, A.; Bader, S.; Bowman, H.; Domingos, P.; Hitzler, P.; Kuehnberger, K.-U.; Lamb, L. C.; Lowd, D.; Lima, P. M. V.; de Penning, L.; Pinkas, G.; Poon, H.; and Zaverucha, G. 2017. Neural-symbolic learning and reasoning: A survey and interpretation. arXiv:1711.03902 [cs].</p>
<p>A Bordes, N Usunier, S Chopra, J Weston, arXiv:1506.02075Large-scale Simple Question Answering with Memory Networks. csBordes, A.; Usunier, N.; Chopra, S.; and Weston, J. 2015. Large-scale Simple Question Answering with Memory Net- works. arXiv:1506.02075 [cs].</p>
<p>. T B Brown, B Mann, N Ryder, M Subbiah, J Kaplan, P Dhariwal, A Neelakantan, P Shyam, G Sastry, A Askell, arXiv:2005.14165arXiv preprintet al. 2020. Language models are few-shot learnersBrown, T. B.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J.; Dhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell, A.; et al. 2020. Language models are few-shot learners. arXiv preprint arXiv:2005.14165.</p>
<p>Automated reasoning in the age of the internet. A Bundy, K Nuamah, C Lucas, International Conference on Artificial Intelligence and Symbolic Computation. SpringerBundy, A.; Nuamah, K.; and Lucas, C. 2018. Automated reasoning in the age of the internet. In International Confer- ence on Artificial Intelligence and Symbolic Computation, 3-18. Springer.</p>
<p>Some thoughts on knowledge-enhanced machine learning. F G Cozman, H N Munhoz, International Journal of Approximate Reasoning. 136AI Next CampaignDARPACozman, F. G., and Munhoz, H. N. 2021. Some thoughts on knowledge-enhanced machine learning. International Jour- nal of Approximate Reasoning 136:308-324. DARPA. 2018. AI Next Campaign.</p>
<p>J Devlin, M.-W Chang, K Lee, K Toutanova, arXiv:1810.04805BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. csDevlin, J.; Chang, M.-W.; Lee, K.; and Toutanova, K. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. arXiv:1810.04805 [cs].</p>
<p>. M Dubey, D Banerjee, A Abdelkawi, J Lehmann, Dubey, M.; Banerjee, D.; Abdelkawi, A.; and Lehmann, J.</p>
<p>C Ghidini, O Hartig, M Maleshkova, V Svátek, I Cruz, A Hogan, J Song, M Lefrançois, F Gandon, LC-QuAD 2.0: A Large Dataset for Complex Question Answering over Wikidata and DBpedia. Springer International Publishing11779The Semantic Web -ISWC 2019LC-QuAD 2.0: A Large Dataset for Complex Ques- tion Answering over Wikidata and DBpedia. In Ghidini, C.; Hartig, O.; Maleshkova, M.; Svátek, V.; Cruz, I.; Hogan, A.; Song, J.; Lefrançois, M.; and Gandon, F., eds., The Seman- tic Web -ISWC 2019, volume 11779. Springer International Publishing. 69-78.</p>
<p>Open question answering over curated and extracted knowledge bases. A Fader, L Zettlemoyer, O Etzioni, Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data MiningACMFader, A.; Zettlemoyer, L.; and Etzioni, O. 2014. Open question answering over curated and extracted knowledge bases. In Proceedings of the 20th ACM SIGKDD Interna- tional Conference on Knowledge Discovery and Data Min- ing, 1156-1165. ACM.</p>
<p>T Fletcher, A Bundy, K Nuamah, GPy-ABCD: A Configurable Automatic Bayesian Covariance Discovery Implementation. 8th ICML Workshop on Automated Machine Learning. In PressFletcher, T.; Bundy, A.; and Nuamah, K. 2021. GPy-ABCD: A Configurable Automatic Bayesian Covariance Discovery Implementation. 8th ICML Workshop on Automated Ma- chine Learning (In Press).</p>
<p>A L Gaunt, M Brockschmidt, N Kushman, D Tarlow, PMLR 10Differentiable programs with neural libraries. International Conference on Machine Learning. Gaunt, A. L.; Brockschmidt, M.; Kushman, N.; and Tarlow, D. 2017. Differentiable programs with neural libraries. In- ternational Conference on Machine Learning. PMLR 10.</p>
<p>A Graves, G Wayne, I Danihelka, arXiv:1410.5401Neural turing machines. Graves, A.; Wayne, G.; and Danihelka, I. 2014. Neural turing machines. arXiv:1410.5401 [cs].</p>
<p>Baseball: An automatic question-answerer. B F Green, A K Wolf, C Chomsky, K Laughery, Western Joint IRE-AIEE-ACM Computer Conference on -IRE-AIEE-ACM '61 (Western. ACM Press219Papers Presented at the May 9-11Green, B. F.; Wolf, A. K.; Chomsky, C.; and Laughery, K. 1961. Baseball: An automatic question-answerer. In Pa- pers Presented at the May 9-11, 1961, Western Joint IRE- AIEE-ACM Computer Conference on -IRE-AIEE-ACM '61 (Western), 219. ACM Press.</p>
<p>AutoML: A Survey of the State-of-the-Art. X He, K Zhao, X Chu, Knowledge-Based Systems. 212106622He, X.; Zhao, K.; and Chu, X. 2021. AutoML: A Survey of the State-of-the-Art. Knowledge-Based Systems 212:106622.</p>
<p>CLEVR: A diagnostic dataset for compositional language and elementary visual reasoning. J Johnson, B Hariharan, L Van Der Maaten, L Fei-Fei, C L Zitnick, R Girshick, 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEEJohnson, J.; Hariharan, B.; van der Maaten, L.; Fei-Fei, L.; Zitnick, C. L.; and Girshick, R. 2017a. CLEVR: A di- agnostic dataset for compositional language and elementary visual reasoning. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 1988-1997. IEEE.</p>
<p>Inferring and Executing Programs for Visual Reasoning. J Johnson, B Hariharan, L Van Der Maaten, J Hoffman, L Fei-Fei, C L Zitnick, R Girshick, 2017 IEEE International Conference on Computer Vision (ICCV). IEEEJohnson, J.; Hariharan, B.; Van Der Maaten, L.; Hoffman, J.; Fei-Fei, L.; Zitnick, C. L.; and Girshick, R. 2017b. Infer- ring and Executing Programs for Visual Reasoning. In 2017 IEEE International Conference on Computer Vision (ICCV), 3008-3017. IEEE.</p>
<p>Thinking, Fast and Slow. Penguin Psychology. D Kahneman, Penguin BooksKahneman, D. 2012. Thinking, Fast and Slow. Penguin Psychology. Penguin Books.</p>
<p>P Kapanipathi, I Abdelaziz, S Ravishankar, S Roukos, A Gray, R Astudillo, M Chang, C Cornelio, S Dana, A Fokoue, D Garg, A Gliozzo, S Gurajada, H Karanam, N Khan, D Khandelwal, Y.-S Lee, Y Li, F Luus, N Makondo, N Mihindukulasooriya, T Naseem, S Neelam, L Popa, R Reddy, R Riegel, G Rossiello, U Sharma, G P S Bhargav, M Yu, arXiv:2012.01707Question answering over knowledge bases by leveraging semantic parsing and neuro-symbolic reasoning. csKapanipathi, P.; Abdelaziz, I.; Ravishankar, S.; Roukos, S.; Gray, A.; Astudillo, R.; Chang, M.; Cornelio, C.; Dana, S.; Fokoue, A.; Garg, D.; Gliozzo, A.; Gurajada, S.; Karanam, H.; Khan, N.; Khandelwal, D.; Lee, Y.-S.; Li, Y.; Luus, F.; Makondo, N.; Mihindukulasooriya, N.; Naseem, T.; Nee- lam, S.; Popa, L.; Reddy, R.; Riegel, R.; Rossiello, G.; Sharma, U.; Bhargav, G. P. S.; and Yu, M. 2020. Question answering over knowledge bases by leveraging semantic parsing and neuro-symbolic reasoning. arXiv:2012.01707 [cs].</p>
<p>Lar: A logic of algorithmic reasoning. F Kröger, Acta Informatica. 83Kröger, F. 1977. Lar: A logic of algorithmic reasoning. Acta Informatica 8(3):243-266.</p>
<p>Graph neural networks meet neuralsymbolic computing: A survey and perspective. L Lamb, A Garcez, M Gori, M Prates, P Avelar, M Vardi, IJCAI-PRICAI 2020-29th International Joint Conference on Artificial Intelligence-Pacific Rim International Conference on Artificial Intelligence. Lamb, L.; Garcez, A.; Gori, M.; Prates, M.; Avelar, P.; and Vardi, M. 2020. Graph neural networks meet neural- symbolic computing: A survey and perspective. In IJCAI- PRICAI 2020-29th International Joint Conference on Arti- ficial Intelligence-Pacific Rim International Conference on Artificial Intelligence.</p>
<p>C Liang, J Berant, Q Le, K D Forbus, N Lao, arXiv:1611.00020Neural symbolic machines: Learning semantic parsers on freebase with weak supervision. csLiang, C.; Berant, J.; Le, Q.; Forbus, K. D.; and Lao, N. 2017. Neural symbolic machines: Learn- ing semantic parsers on freebase with weak supervision. arXiv:1611.00020 [cs].</p>
<p>Learning Dependency-Based Compositional Semantics. P Liang, M I Jordan, D Klein, Computational Linguistics. 392Liang, P.; Jordan, M. I.; and Klein, D. 2013. Learning Dependency-Based Compositional Semantics. Computa- tional Linguistics 39(2):389-446.</p>
<p>DeepProbLog: Neural probabilistic logic programming. H Liu, K Simonyan, Y Yang, R Manhaeve, S Dumancic, A Kimmig, T Demeester, L De Raedt, arXiv:1806.09055Darts: Differentiable architecture search. 31arXiv preprintLiu, H.; Simonyan, K.; and Yang, Y. 2018. Darts: Differen- tiable architecture search. arXiv preprint arXiv:1806.09055. Manhaeve, R.; Dumancic, S.; Kimmig, A.; Demeester, T.; and De Raedt, L. 2018. DeepProbLog: Neural probabilistic logic programming. Advances in Neural Information Pro- cessing Systems 31:3749-3759.</p>
<p>GPT-3, Bloviator: Ope-nAI's language generator has no idea what it's talking about. G Marcus, E Davies, Marcus, G., and Davies, E. 2020. GPT-3, Bloviator: Ope- nAI's language generator has no idea what it's talking about. https://www.technologyreview.com/2020/08/22/1007539/gpt3- openai-language-generator-artificial-intelligence-ai- opinion/.</p>
<p>Rebooting AI: Building Artificial Intelligence We Can Trust. G Marcus, Davis , E , Marcus, G., and Davis, E. 2019. Rebooting AI: Building Artificial Intelligence We Can Trust.</p>
<p>Explainable inference in the frank query answering system. K Nuamah, A Bundy, K Nuamah, A Bundy, C Lucas, Functional Inferences Over Heterogeneous Data. Ph.D. Dissertation, School of Informatics. SpringerUniversity of EdinburghInternational Conference on Web Reasoning and Rule SystemsNuamah, K., and Bundy, A. 2020. Explainable inference in the frank query answering system. In ECAI 2020. IOS Press. 2441-2448. Nuamah, K.; Bundy, A.; and Lucas, C. 2016. Func- tional inferences over heterogeneous data. In International Conference on Web Reasoning and Rule Systems, 159-166. Springer. Nuamah, K. 2018. Functional Inferences Over Heteroge- neous Data. Ph.D. Dissertation, School of Informatics, Uni- versity of Edinburgh.</p>
<p>Learning transferable visual models from natural language supervision. A Radford, J W Kim, C Hallacy, A Ramesh, G Goh, S Agarwal, G Sastry, A Askell, P Mishkin, J Clark, arXiv:2103.00020arXiv:2006.13155Logical neural networks. arXiv preprintcsRadford, A.; Kim, J. W.; Hallacy, C.; Ramesh, A.; Goh, G.; Agarwal, S.; Sastry, G.; Askell, A.; Mishkin, P.; Clark, J.; et al. 2021. Learning transferable visual models from natural language supervision. arXiv preprint arXiv:2103.00020. Riegel, R.; Gray, A.; Luus, F.; Khan, N.; Makondo, N.; Akhalwaya, I. Y.; Qian, H.; Fagin, R.; Barahona, F.; Sharma, U.; Ikbal, S.; Karanam, H.; Neelam, S.; Likhyani, A.; and Srivastava, S. 2020. Logical neural networks. arXiv:2006.13155 [cs].</p>
<p>A Santoro, D Raposo, D G Barrett, M Malinowski, R Pascanu, P Battaglia, T Lillicrap, arXiv:1706.01427A simple neural network module for relational reasoning. arXiv preprintSantoro, A.; Raposo, D.; Barrett, D. G.; Malinowski, M.; Pascanu, R.; Battaglia, P.; and Lillicrap, T. 2017. A sim- ple neural network module for relational reasoning. arXiv preprint arXiv:1706.01427.</p>
<p>A Santoro, R Faulkner, D Raposo, J Rae, M Chrzanowski, T Weber, D Wierstra, O Vinyals, R Pascanu, T Lillicrap, arXiv:1806.01822Relational recurrent neural networks. arXiv preprintSantoro, A.; Faulkner, R.; Raposo, D.; Rae, J.; Chrzanowski, M.; Weber, T.; Wierstra, D.; Vinyals, O.; Pascanu, R.; and Lillicrap, T. 2018. Relational recurrent neural networks. arXiv preprint arXiv:1806.01822.</p>
<p>Mastering the game of Go with deep neural networks and tree search. D Silver, A Huang, C J Maddison, A Guez, L Sifre, G Van Den Driessche, J Schrittwieser, I Antonoglou, V Panneershelvam, M Lanctot, S Dieleman, D Grewe, J Nham, N Kalchbrenner, I Sutskever, T Lillicrap, M Leach, K Kavukcuoglu, T Graepel, D Hassabis, Nature. 5297587Silver, D.; Huang, A.; Maddison, C. J.; Guez, A.; Sifre, L.; van den Driessche, G.; Schrittwieser, J.; Antonoglou, I.; Panneershelvam, V.; Lanctot, M.; Dieleman, S.; Grewe, D.; Nham, J.; Kalchbrenner, N.; Sutskever, I.; Lillicrap, T.; Leach, M.; Kavukcuoglu, K.; Graepel, T.; and Hassabis, D. 2016. Mastering the game of Go with deep neural networks and tree search. Nature 529(7587):484-489.</p>
<p>Neuralsymbolic integration: A compositional perspective. E Tsamoura, T Hospedales, M Loizos, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence35Tsamoura, E.; Hospedales, T.; and Loizos, M. 2021. Neural- symbolic integration: A compositional perspective. Pro- ceedings of the AAAI Conference on Artificial Intelligence 35(6).</p>
<p>R Usbeck, A.-C N Ngomo, B Haarmann, A Krithara, M Roder, G Napolitano, 7th Open Challenge on Question Answering over Linked Data. 11Usbeck, R.; Ngomo, A.-C. N.; Haarmann, B.; Krithara, A.; Roder, M.; and Napolitano, G. 2017. 7th Open Challenge on Question Answering over Linked Data (QALD-7). 11.</p>
<p>P Veličković, C Blundell, arXiv:2105.02761Neural algorithmic reasoning. cs, math, statVeličković, P., and Blundell, C. 2021. Neural algorithmic reasoning. arXiv:2105.02761 [cs, math, stat].</p>
<p>AutoAI: Automating the End-to-End AI Lifecycle with Humans-in-the-Loop. D Wang, P Ram, D K I Weidele, S Liu, M Muller, J D Weisz, A Valente, A Chaudhary, D Torres, H Samulowitz, L Amini, Proceedings of the 25th International Conference on Intelligent User Interfaces Companion. the 25th International Conference on Intelligent User Interfaces CompanionACMWang, D.; Ram, P.; Weidele, D. K. I.; Liu, S.; Muller, M.; Weisz, J. D.; Valente, A.; Chaudhary, A.; Torres, D.; Samu- lowitz, H.; and Amini, L. 2020. AutoAI: Automating the End-to-End AI Lifecycle with Humans-in-the-Loop. In Pro- ceedings of the 25th International Conference on Intelligent User Interfaces Companion, 77-78. ACM.</p>
<p>J Weston, S Chopra, A Bordes, arXiv:1410.3916Memory Networks. cs, statWeston, J.; Chopra, S.; and Bordes, A. 2015. Memory Networks. arXiv:1410.3916 [cs, stat].</p>
<p>World Wide Web Consortium, W3C. Sparql 1.1 overviewWorld Wide Web Consortium, W3C. 2013. Sparql 1.1 overview.</p>
<p>K Yi, J Wu, C Gan, A Torralba, P Kohli, J B Tenenbaum, arXiv:1810.02338Neural-symbolic VQA: Disentangling reasoning from vision and language understanding. csYi, K.; Wu, J.; Gan, C.; Torralba, A.; Kohli, P.; and Tenenbaum, J. B. 2019. Neural-symbolic VQA: Disen- tangling reasoning from vision and language understanding. arXiv:1810.02338 [cs].</p>
<p>Reinforcement learning neural turing machines -revised. W Zaremba, I Sutskever, arXiv:1505.00521Zaremba, W., and Sutskever, I. 2016. Reinforcement learn- ing neural turing machines -revised. arXiv:1505.00521 [cs].</p>            </div>
        </div>

    </div>
</body>
</html>