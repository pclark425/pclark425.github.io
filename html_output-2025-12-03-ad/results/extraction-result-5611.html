<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5611 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5611</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5611</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-115.html">extraction-schema-115</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <p><strong>Paper ID:</strong> paper-201666793</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/1908.09156v1.pdf" target="_blank">A framework for anomaly detection using language modeling, and its applications to finance</a></p>
                <p><strong>Paper Abstract:</strong> In the finance sector, studies focused on anomaly detection are often associated with time-series and transactional data analytics. In this paper, we lay out the opportunities for applying anomaly and deviation detection methods to text corpora and challenges associated with them. We argue that language models that use distributional semantics can play a significant role in advancing these studies in novel directions, with new applications in risk identification, predictive modeling, and trend analysis.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5611.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5611.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LSTM LM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Long Short-Term Memory based language model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A recurrent neural language model built with LSTM units that predicts next tokens in a sequence; proposed as an unsupervised mechanism to detect anomalies by examining input/output/hidden distributions and low-probability predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Long Short-Term Memory</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LSTM-based language model</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Recurrent neural network using LSTM units that consumes token input vectors and produces a probability distribution over next tokens via hidden state dynamics and output layers; described in conceptual form (inputs, hidden states, outputs, weights). No parameter counts or specific architecture depth provided in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Unsupervised next-token prediction: use the trained LM's output probability distribution to flag low-likelihood tokens as potential transcription/OCR/syntactic errors; analyze changes to input vectors, hidden vector distributions, and learned parameters over time/versions to detect semantic shifts or irregularities.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Text sequences (transcripts, OCR output, document text, sliding n-grams / sequences)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Transcription/OCR errors, syntactic anomalies, semantic irregularities, novelty (emerging vocabulary/patterns), distributional shifts in hidden representations</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Unseen domain-specific tokens (e.g., named entities or acquisitions) can be mistaken for anomalies; high variability (speaker style) can mimic anomalies; fine-tuned models may lack domain vocabulary; adversarially-crafted anomalous text may be made to appear normal.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A framework for anomaly detection using language modeling, and its applications to finance', 'publication_date_yy_mm': '2019-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5611.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5611.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Fine-tuned LM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Fine-tuned pre-trained language model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Pre-train a language model on large generic corpora, then fine-tune (typically only top layers) on domain-specific text; use shifts in hidden representations or newly learned parameters during fine-tuning as signals of anomaly or evolving trends.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Fine-tuned Language Models for Text Classification</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Pre-trained language model fine-tuned on target domain</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A language model pre-trained on large generic corpora (web/Wikipedia) whose top layers are then re-trained on a smaller domain-specific corpus while lower layers remain frozen; no specific architecture or parameter counts given in the paper (references generic transfer/fine-tuning approach).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Fine-tune on recent domain data and monitor distributional shifts in hidden layer representations; dramatic shifts in particular vectors or clusters compared to historical sector representations indicate possible anomalies (novel trends or semantic changes).</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Text sequences, domain corpora (e.g., sector filings, earnings calls)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Semantic novelty, evolving trends, sector-specific distributional shifts</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Fine-tuning can misinterpret rare legitimate domain tokens as anomalies; transfer selection issues (source vs target) can affect sensitivity; may overfit to idiosyncratic company signals if not carefully controlled.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A framework for anomaly detection using language modeling, and its applications to finance', 'publication_date_yy_mm': '2019-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5611.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5611.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Output-probability scoring</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Language model output probability scoring for error detection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Using the LM's next-token probability distribution as an anomaly score: low predicted probability for observed tokens flags potential transcription/OCR errors or unlikely constructions given domain context.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Probability-scoring language model (next-token scoring)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Any predictive LM (e.g., recurrent or transformer-style) that produces a probability distribution over the next token; the paper discusses using those probabilities to detect domain-specific errors (no specific LM architecture or size specified).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Score observed tokens using the model's predicted probability; tokens or sequences with abnormally low probability in a domain-trained LM are flagged as likely errors (transcription/OCR mistakes) or anomalies.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Transcripts, OCR text, token sequences</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Transcription errors, OCR mistakes, improbable token sequences (syntactic/semantic errors)</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Named entities and genuine rare events may receive low probability and be misclassified as errors; domain adaptation required to reduce false positives; does not provide quantitative performance in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A framework for anomaly detection using language modeling, and its applications to finance', 'publication_date_yy_mm': '2019-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5611.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e5611.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Word vectors / embeddings</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Distributed representations of words and phrases (word embeddings)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Vector-space word embeddings (e.g., word2vec) represent lexical items as continuous vectors; stability or shifts in nearest neighbors and vector distributions across corpora can be used to detect semantic anomalies or emergent vocabulary.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Distributed representations of words and phrases and their compositionality</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Pre-trained word embeddings / distributed representations</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Dense continuous vector representations learned from large corpora (skip-gram / CBOW-style methods); paper references both static embeddings and contextualized methods but does not specify sizes or training hyperparameters.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Compare embedding neighborhoods and distributional stability across time or subcorpora; identify vectors whose nearest neighbors change substantially or whose distributions diverge as semantic anomalies; detect unusual n-grams by comparing n-gram probabilities against prior filings/peers.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Words, n-grams, document text, corpora slices (temporal or sectoral)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Semantic anomalies, novelty, irregular semantic shifts, boilerplate vs abnormal clauses</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Instability of embeddings across runs and corpora can confound signals; infrequent words have unreliable vectors; distinguishing genuine semantic change from noise requires careful controls.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A framework for anomaly detection using language modeling, and its applications to finance', 'publication_date_yy_mm': '2019-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5611.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e5611.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Attention analysis</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Attention mechanism analysis for anomaly detection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use learned attention weights in attention-based models to surface which input tokens or spans the model focuses on; patterns of attention can indicate anomalous or suspicious content (e.g., attention concentrated on 'trigger words' for bot or propagandistic content).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Attention is All you Need</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Attention-based / Transformer models (attention mechanisms)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Neural architectures that compute weighted interactions between input positions (self-attention / multi-head attention) to produce context-aware representations; specific sizes or transformer variants are not given in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Inspect learned attention distributions to identify anomalous focus patterns (e.g., unusual attention to certain keywords or abnormal propagation signals); use attention as an interpretable signal to distinguish content types (engaging vs clickbait/bot).</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Text sequences (tweets, sentences, documents)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Propagandistic/promotional/clickbait content, unusual attention signatures indicating anomalous generation or engagement</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Attention weights are not guaranteed to be fully interpretable; adversarial actors may design content to shift attention patterns; attention alone may be insufficient for robust anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A framework for anomaly detection using language modeling, and its applications to finance', 'publication_date_yy_mm': '2019-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5611.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e5611.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Smoothed n-gram anomaly detection</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Smoothed n-gram representations for boilerplate and abnormal clause detection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Compare smoothed n-gram probabilities across a company's previous filings, sector peers, and similarly-sized companies to identify boilerplate language and flag abnormal clauses in long regulatory documents.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Smoothed n-gram language models</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Classical n-gram probabilistic models with smoothing to estimate sequence probabilities; used to compute likelihood of n-grams conditioned on different reference corpora for anomaly scoring.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Compute probability of each n-gram under multiple reference distributions (company history, sector, market-cap peers); n-grams with anomalously low/high relative probability are flagged as abnormal or boilerplate respectively.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Long documents (SEC filings, credit agreements), clause-level text</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Boilerplate detection, anomalous clauses, contextual relevance anomalies</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Requires appropriate reference corpora for meaningful comparisons; company-specific legitimate phrasing may be flagged incorrectly; not evaluated quantitatively in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A framework for anomaly detection using language modeling, and its applications to finance', 'publication_date_yy_mm': '2019-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Fine-tuned Language Models for Text Classification <em>(Rating: 2)</em></li>
                <li>Bert: Pre-training of deep bidirectional transformers for language understanding <em>(Rating: 2)</em></li>
                <li>Long Short-Term Memory <em>(Rating: 2)</em></li>
                <li>Distributed representations of words and phrases and their compositionality <em>(Rating: 2)</em></li>
                <li>Detecting Errors within a Corpus using Anomaly Detection <em>(Rating: 2)</em></li>
                <li>Linear) maps of the impossible: capturing semantic anomalies in distributional space <em>(Rating: 2)</em></li>
                <li>Real-Time Novel Event Detection from Social Media <em>(Rating: 2)</em></li>
                <li>Real-time Rumor Debunking on Twitter <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5611",
    "paper_id": "paper-201666793",
    "extraction_schema_id": "extraction-schema-115",
    "extracted_data": [
        {
            "name_short": "LSTM LM",
            "name_full": "Long Short-Term Memory based language model",
            "brief_description": "A recurrent neural language model built with LSTM units that predicts next tokens in a sequence; proposed as an unsupervised mechanism to detect anomalies by examining input/output/hidden distributions and low-probability predictions.",
            "citation_title": "Long Short-Term Memory",
            "mention_or_use": "mention",
            "model_name": "LSTM-based language model",
            "model_description": "Recurrent neural network using LSTM units that consumes token input vectors and produces a probability distribution over next tokens via hidden state dynamics and output layers; described in conceptual form (inputs, hidden states, outputs, weights). No parameter counts or specific architecture depth provided in the paper.",
            "model_size": null,
            "anomaly_detection_method": "Unsupervised next-token prediction: use the trained LM's output probability distribution to flag low-likelihood tokens as potential transcription/OCR/syntactic errors; analyze changes to input vectors, hidden vector distributions, and learned parameters over time/versions to detect semantic shifts or irregularities.",
            "data_type": "Text sequences (transcripts, OCR output, document text, sliding n-grams / sequences)",
            "anomaly_type": "Transcription/OCR errors, syntactic anomalies, semantic irregularities, novelty (emerging vocabulary/patterns), distributional shifts in hidden representations",
            "dataset_name": null,
            "performance_metrics": null,
            "baseline_comparison": null,
            "limitations_or_failure_cases": "Unseen domain-specific tokens (e.g., named entities or acquisitions) can be mistaken for anomalies; high variability (speaker style) can mimic anomalies; fine-tuned models may lack domain vocabulary; adversarially-crafted anomalous text may be made to appear normal.",
            "uuid": "e5611.0",
            "source_info": {
                "paper_title": "A framework for anomaly detection using language modeling, and its applications to finance",
                "publication_date_yy_mm": "2019-08"
            }
        },
        {
            "name_short": "Fine-tuned LM",
            "name_full": "Fine-tuned pre-trained language model",
            "brief_description": "Pre-train a language model on large generic corpora, then fine-tune (typically only top layers) on domain-specific text; use shifts in hidden representations or newly learned parameters during fine-tuning as signals of anomaly or evolving trends.",
            "citation_title": "Fine-tuned Language Models for Text Classification",
            "mention_or_use": "mention",
            "model_name": "Pre-trained language model fine-tuned on target domain",
            "model_description": "A language model pre-trained on large generic corpora (web/Wikipedia) whose top layers are then re-trained on a smaller domain-specific corpus while lower layers remain frozen; no specific architecture or parameter counts given in the paper (references generic transfer/fine-tuning approach).",
            "model_size": null,
            "anomaly_detection_method": "Fine-tune on recent domain data and monitor distributional shifts in hidden layer representations; dramatic shifts in particular vectors or clusters compared to historical sector representations indicate possible anomalies (novel trends or semantic changes).",
            "data_type": "Text sequences, domain corpora (e.g., sector filings, earnings calls)",
            "anomaly_type": "Semantic novelty, evolving trends, sector-specific distributional shifts",
            "dataset_name": null,
            "performance_metrics": null,
            "baseline_comparison": null,
            "limitations_or_failure_cases": "Fine-tuning can misinterpret rare legitimate domain tokens as anomalies; transfer selection issues (source vs target) can affect sensitivity; may overfit to idiosyncratic company signals if not carefully controlled.",
            "uuid": "e5611.1",
            "source_info": {
                "paper_title": "A framework for anomaly detection using language modeling, and its applications to finance",
                "publication_date_yy_mm": "2019-08"
            }
        },
        {
            "name_short": "Output-probability scoring",
            "name_full": "Language model output probability scoring for error detection",
            "brief_description": "Using the LM's next-token probability distribution as an anomaly score: low predicted probability for observed tokens flags potential transcription/OCR errors or unlikely constructions given domain context.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "Probability-scoring language model (next-token scoring)",
            "model_description": "Any predictive LM (e.g., recurrent or transformer-style) that produces a probability distribution over the next token; the paper discusses using those probabilities to detect domain-specific errors (no specific LM architecture or size specified).",
            "model_size": null,
            "anomaly_detection_method": "Score observed tokens using the model's predicted probability; tokens or sequences with abnormally low probability in a domain-trained LM are flagged as likely errors (transcription/OCR mistakes) or anomalies.",
            "data_type": "Transcripts, OCR text, token sequences",
            "anomaly_type": "Transcription errors, OCR mistakes, improbable token sequences (syntactic/semantic errors)",
            "dataset_name": null,
            "performance_metrics": null,
            "baseline_comparison": null,
            "limitations_or_failure_cases": "Named entities and genuine rare events may receive low probability and be misclassified as errors; domain adaptation required to reduce false positives; does not provide quantitative performance in the paper.",
            "uuid": "e5611.2",
            "source_info": {
                "paper_title": "A framework for anomaly detection using language modeling, and its applications to finance",
                "publication_date_yy_mm": "2019-08"
            }
        },
        {
            "name_short": "Word vectors / embeddings",
            "name_full": "Distributed representations of words and phrases (word embeddings)",
            "brief_description": "Vector-space word embeddings (e.g., word2vec) represent lexical items as continuous vectors; stability or shifts in nearest neighbors and vector distributions across corpora can be used to detect semantic anomalies or emergent vocabulary.",
            "citation_title": "Distributed representations of words and phrases and their compositionality",
            "mention_or_use": "mention",
            "model_name": "Pre-trained word embeddings / distributed representations",
            "model_description": "Dense continuous vector representations learned from large corpora (skip-gram / CBOW-style methods); paper references both static embeddings and contextualized methods but does not specify sizes or training hyperparameters.",
            "model_size": null,
            "anomaly_detection_method": "Compare embedding neighborhoods and distributional stability across time or subcorpora; identify vectors whose nearest neighbors change substantially or whose distributions diverge as semantic anomalies; detect unusual n-grams by comparing n-gram probabilities against prior filings/peers.",
            "data_type": "Words, n-grams, document text, corpora slices (temporal or sectoral)",
            "anomaly_type": "Semantic anomalies, novelty, irregular semantic shifts, boilerplate vs abnormal clauses",
            "dataset_name": null,
            "performance_metrics": null,
            "baseline_comparison": null,
            "limitations_or_failure_cases": "Instability of embeddings across runs and corpora can confound signals; infrequent words have unreliable vectors; distinguishing genuine semantic change from noise requires careful controls.",
            "uuid": "e5611.3",
            "source_info": {
                "paper_title": "A framework for anomaly detection using language modeling, and its applications to finance",
                "publication_date_yy_mm": "2019-08"
            }
        },
        {
            "name_short": "Attention analysis",
            "name_full": "Attention mechanism analysis for anomaly detection",
            "brief_description": "Use learned attention weights in attention-based models to surface which input tokens or spans the model focuses on; patterns of attention can indicate anomalous or suspicious content (e.g., attention concentrated on 'trigger words' for bot or propagandistic content).",
            "citation_title": "Attention is All you Need",
            "mention_or_use": "mention",
            "model_name": "Attention-based / Transformer models (attention mechanisms)",
            "model_description": "Neural architectures that compute weighted interactions between input positions (self-attention / multi-head attention) to produce context-aware representations; specific sizes or transformer variants are not given in the paper.",
            "model_size": null,
            "anomaly_detection_method": "Inspect learned attention distributions to identify anomalous focus patterns (e.g., unusual attention to certain keywords or abnormal propagation signals); use attention as an interpretable signal to distinguish content types (engaging vs clickbait/bot).",
            "data_type": "Text sequences (tweets, sentences, documents)",
            "anomaly_type": "Propagandistic/promotional/clickbait content, unusual attention signatures indicating anomalous generation or engagement",
            "dataset_name": null,
            "performance_metrics": null,
            "baseline_comparison": null,
            "limitations_or_failure_cases": "Attention weights are not guaranteed to be fully interpretable; adversarial actors may design content to shift attention patterns; attention alone may be insufficient for robust anomaly detection.",
            "uuid": "e5611.4",
            "source_info": {
                "paper_title": "A framework for anomaly detection using language modeling, and its applications to finance",
                "publication_date_yy_mm": "2019-08"
            }
        },
        {
            "name_short": "Smoothed n-gram anomaly detection",
            "name_full": "Smoothed n-gram representations for boilerplate and abnormal clause detection",
            "brief_description": "Compare smoothed n-gram probabilities across a company's previous filings, sector peers, and similarly-sized companies to identify boilerplate language and flag abnormal clauses in long regulatory documents.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "Smoothed n-gram language models",
            "model_description": "Classical n-gram probabilistic models with smoothing to estimate sequence probabilities; used to compute likelihood of n-grams conditioned on different reference corpora for anomaly scoring.",
            "model_size": null,
            "anomaly_detection_method": "Compute probability of each n-gram under multiple reference distributions (company history, sector, market-cap peers); n-grams with anomalously low/high relative probability are flagged as abnormal or boilerplate respectively.",
            "data_type": "Long documents (SEC filings, credit agreements), clause-level text",
            "anomaly_type": "Boilerplate detection, anomalous clauses, contextual relevance anomalies",
            "dataset_name": null,
            "performance_metrics": null,
            "baseline_comparison": null,
            "limitations_or_failure_cases": "Requires appropriate reference corpora for meaningful comparisons; company-specific legitimate phrasing may be flagged incorrectly; not evaluated quantitatively in the paper.",
            "uuid": "e5611.5",
            "source_info": {
                "paper_title": "A framework for anomaly detection using language modeling, and its applications to finance",
                "publication_date_yy_mm": "2019-08"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Fine-tuned Language Models for Text Classification",
            "rating": 2,
            "sanitized_title": "finetuned_language_models_for_text_classification"
        },
        {
            "paper_title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
            "rating": 2,
            "sanitized_title": "bert_pretraining_of_deep_bidirectional_transformers_for_language_understanding"
        },
        {
            "paper_title": "Long Short-Term Memory",
            "rating": 2,
            "sanitized_title": "long_shortterm_memory"
        },
        {
            "paper_title": "Distributed representations of words and phrases and their compositionality",
            "rating": 2,
            "sanitized_title": "distributed_representations_of_words_and_phrases_and_their_compositionality"
        },
        {
            "paper_title": "Detecting Errors within a Corpus using Anomaly Detection",
            "rating": 2,
            "sanitized_title": "detecting_errors_within_a_corpus_using_anomaly_detection"
        },
        {
            "paper_title": "Linear) maps of the impossible: capturing semantic anomalies in distributional space",
            "rating": 2,
            "sanitized_title": "linear_maps_of_the_impossible_capturing_semantic_anomalies_in_distributional_space"
        },
        {
            "paper_title": "Real-Time Novel Event Detection from Social Media",
            "rating": 2,
            "sanitized_title": "realtime_novel_event_detection_from_social_media"
        },
        {
            "paper_title": "Real-time Rumor Debunking on Twitter",
            "rating": 1,
            "sanitized_title": "realtime_rumor_debunking_on_twitter"
        }
    ],
    "cost": 0.01160175,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>A framework for anomaly detection using language modeling, and its applications to finance</p>
<p>Armineh Nourbakhsh armineh.nourbakhsh@spglobal.com 
Grace Bang grace.bang@spglobal.com 
A framework for anomaly detection using language modeling, and its applications to finance
S&amp;P Global Ratings New York, NY S&amp;P Global Ratings New York, NYanomaly detectiondeviation analysisoutlier detectionneural networkslanguage modelingnatural language processingfinance
In the finance sector, studies focused on anomaly detection are often associated with time-series and transactional data analytics. In this paper, we lay out the opportunities for applying anomaly and deviation detection methods to text corpora and challenges associated with them. We argue that language models that use distributional semantics can play a significant role in advancing these studies in novel directions, with new applications in risk identification, predictive modeling, and trend analysis.</p>
<p>INTRODUCTION</p>
<p>The detection of anomalous trends in the financial domain has focused largely on fraud detection [23], risk modeling [1], and predictive analysis [7]. The data used in the majority of such studies is of time-series, transactional, graph or generally quantitative or structured nature. This belies the critical importance of semistructured or unstructured text corpora that practitioners in the finance domain derive insights from-corpora such as financial reports, press releases, earnings call transcripts, credit agreements, news articles, customer interaction logs, and social data.</p>
<p>Previous research in anomaly detection from text has evolved largely independently from financial applications. Unsupervised clustering methods have been applied to documents in order to identify outliers and emerging topics [2]. Deviation analysis has been applied to text in order to identify errors in spelling [16] and tagging of documents [4]. Recent popularity of distributional semantics [18] has led to further advances in semantic deviation analysis [20]. However, current research remains largely divorced from specific applications within the domain of finance.</p>
<p>In the following sections, we enumerate major applications of anomaly detection from text in the financial domain, and contextualize them within current research topics in Natural Language Processing.</p>
<p>FIVE VIEWS ON ANOMALY</p>
<p>Anomaly detection is a strategy that is often employed in contexts where a deviation from a certain norm is sought to be captured, especially when extreme class imbalance impedes the use of a supervised approach. The implementation of such methods allows for the unveiling of previously hidden or obstructed insights.</p>
<p>In this section, we lay out five perspectives on how textual anomaly detection can be applied in the context of finance, and how each application opens up opportunities for NLP researchers to apply current research to the financial domain.</p>
<p>Anomaly as error</p>
<p>Previous studies have used anomaly detection to identify and correct errors in text [4,16]. These are often unintentional errors that occur as a result of some form of data transfer, e.g. from audio to text, from image to text, or from one language to another. Such studies have direct applicability to the error-prone process of earnings call or customer call transcription, where audio quality, accents, and domain-specific terms can lead to errors. Consider a scenario where the CEO of a company states in an audio conference, 'Now investments will be made in Asia. ' However, the system instead transcribes, 'No investments will be made in Asia. ' There is a meaningful difference in the implication of the two statements that could greatly influence the analysis and future direction of the company. Additionally, with regards to the second scenario, it is highly unlikely that the CEO would make such a strong and negative statement in a public setting thus supporting the use of anomaly detection for error correction.</p>
<p>Optical-character-recognition from images is another error-prone process with large applicability to finance. Many financial reports and presentations are circulated as image documents that need to undergo OCR in order to be machine-readable. OCR might also be applicable to satellite imagery and other forms of image data that might include important textual content such as a graphical representation of financial data. Errors that result from OCR'd documents can often be fixed using systems that have a robust semantic representation of the target domain. For instance, a model that is trained on financial reports might have encoded awareness that emojis are unlikely to appear in them or that it is unusual for the numeric value of profit to be higher than that of revenue.</p>
<p>Anomaly as irregularity</p>
<p>Anomaly in the semantic space might reflect irregularities that are intentional or emergent, signaling risky behavior or phenomena. A sudden change in the tone and vocabulary of a company's leadership in their earnings calls or financial reports can signal risk. News stories that have abnormal language, or irregular origination or propagation patterns might be unreliable or untrustworthy. [22] showed that when trained on similar domains or contexts, distributed representations of words are likely to be stable, where stability is measured as the similarity of their nearest neighbors in the distributed space. Such insight can be used to assess anomalies in this sense. As an example, [12] identified cliques of users on Twitter who consistently shared news from similar domains.</p>
<p>Characterizing these networks as "echo-chambers, " they then represented the content shared by these echo-chambers as distributed representations. When certain topics from one echo-chamber began to deviate from similar topics in other echo-chambers, the content was tagged as unreliable. [12] showed that this method can be used to improve the performance of standard methods for fake-news detection.</p>
<p>In another study [24], the researchers hypothesized that transparent language in earnings calls indicates high expectations for performance in the upcoming quarters, whereas semantic ambiguity can signal a lack of confidence and expected poor performance. By quantifying transparency as the frequent use of numbers, shorter words, and unsophisticated vocabulary, they showed that a change in transparency is associated with a change in future performance.</p>
<p>Anomaly as novelty</p>
<p>Anomaly can indicate a novel event or phenomenon that may or may not be risky. Breaking news stories often emerge as anomalous trends on social media. [9] experimented with this in their effort to detect novel events from Twitter conversations. By representing each event as a real-time cluster of tweets (where each tweet was encoded as a vector), they managed to assess the novelty of the event by comparing its centroid to the centroids of older events.</p>
<p>Novelty detection can also be used to detect emerging trends on social media, e.g. controversies that engulf various brands often start as small local events that are shared on social media and attract attention over a short period of time. How people respond to these events in early stages of development can be a measure of their veracity or controversiality [10,13].</p>
<p>An anomaly in an industry grouping of companies can also be indicative of a company that is disrupting the norm for that industry and the emergence of a new sector or sub-sector. Often known as trail-blazers, these companies innovate faster than their competitors to meet market demands sometimes even before the consumer is aware of their need. As these companies continually evolve their business lines, their core operations are novel outliers from others in the same industry classification that can serve as meaningful signals of transforming industry demands.</p>
<p>Anomaly as semantic richness</p>
<p>A large portion of text documents that analysts and researchers in the financial sectors consume have a regulatory nature. Annual financial reports, credit agreements, and filings with the U.S. Securities and Exchange Commission (SEC) are some of these types of documents. These documents can be tens or hundreds of pages long, and often include boilerplate language that the readers might need to skip or ignore in order to get to the "meat" of the content. Often, the abnormal clauses found in these documents are buried in standard text so as not to attract attention to the unique phrases.</p>
<p>[17] used smoothed representations of n-grams in SEC filings in order to identify boilerplate and abnormal language. They did so by comparing the probability of each n-gram against the company's previous filings, against other filings in the same sector, and against other filings from companies with similar market cap. The aim was to assist accounting analysts in skipping boilerplate language and focusing their attention on important snippets in these documents. Similar methods can be applied to credit agreements where covenants and clauses that are too common are often ignored by risk analysts and special attention is paid to clauses that "stand out" from similar agreements.</p>
<p>Anomaly as contextual relevance</p>
<p>Certain types of documents include universal as well as contextspecific signals. As an example, consider a given company's financial reports. The reports may include standard financial metrics such as total revenue, net sales, net income, etc. In addition to these universal metrics, businesses often report their performance in terms of the performance of their operating segments. These segments can be business divisions, products, services, or regional operations. The segments are often specific to the company or its peers. For example, Apple Inc. 's segments might include "iPhone, " "iMac, " "iPad, " and "services. " The same segments will not appear in reports by other businesses.</p>
<p>For many analysts and researchers, operating segments are a crucial part of exploratory or predictive analysis. They use performance metrics associated with these segments to compare the business to its competitors, to estimate its market share, and to project the overall performance of the business in upcoming quarters. Automating the identification and normalization of these metrics can facilitate more insightful analytical research. Since these segments are often specific to each business, supervised models that are trained on a diverse set of companies cannot capture them without overfitting to certain companies. Instead, these segments can be treated as company-specific anomalies.</p>
<p>ANOMALY DETECTION VIA LANGUAGE MODELING</p>
<p>Unlike numeric data, text data is not directly machine-readable, and requires some form of transformation as a pre-processing step. In "bag-of-words" methods, this transformation can take place by assigning an index number to each word, and representing any block of text as an unordered set of these words. A slightly more sophisticated approach might chain words into continuous "n-grams" and represent a block of text as an ordered series of "n-grams" that have been extracted on a sliding window of size n. These approaches are conventionally known as "language modeling. " Since the advent of high-powered processors enabled the widespread use of distributed representations, language modeling has rapidly evolved and adapted to these new capabilities. Recurrent neural networks can capture an arbitrarily long sequence of text and perform various tasks such as classification or text generation [21]. In this new context, language modeling often refers to training a recurrent network that predicts a word in a given sequence of text [6]. Language models are easy to train because even though they follow a predictive mechanism, they do not need any labeled data, and are thus unsupervised. Figure 1 is a simple illustration of how a neural network that is composed of recurrent units such as Long-Short Term Memory (LSTM) [5] can perform language modeling. The are four main components to the network:</p>
<p> The input vectors (x i ), which represent units (i.e. characters, words, phrases, sentences, paragraphs, etc.) in the input text. Occasionally, these are represented by one-hot vectors that assign a unique index to each particular input. More commonly, these vectors are adapted from a pre-trained corpus, where distributed representations have been inferred either by a simpler auto-encoding process [11] or by applying the same recurrent model to a baseline corpus such as Wikipedia [6].  The output vectors (y i ), which represent the model's prediction of the next word in the sequence. Naturally, they are represented in the same dimensionality as x i s.  The hidden vectors (h i ), which are often randomly initialized and learned through backpropagation. Often trained as dense representations, these vectors tend to display characteristics that indicate semantic richness [14] and compositionality [11]. While the language model can be used as a text-generation mechanism, the hidden vectors are a strong side product that are sometimes extracted and reused as augmented features in other machine learning systems [3].  The weights of the network (W i j ) (or other parameters in the network), which are tuned through backpropagation. These often indicate how each vectors in the input or hidden sequence is utilized to generate the output. These parameters play a big role in the way the output of neural networks are reverse-engineered or explained to the end user 1 .</p>
<p>The distributions of any of the above-mentioned components can be studied to mine signals for anomalous behavior in the context of irregularity, error, novelty, semantic richness, or contextual relevance.</p>
<p>Anomaly in input vectors</p>
<p>As previously mentioned, the input vectors to a text-based neural network are often adapted from publicly-available word vector corpora. In simpler architectures, the network is allowed to backpropagate its errors all the way to the input layer, which might cause the input vectors to be modified. This can serve as a signal for 1 As an example see https://tinyurl.com/y56drbnk anomaly in the semantic distributions between the original vectors and the modified vectors.</p>
<p>Analyzing the stability of word vectors when trained on different iterations can also signal anomalous trends [22].</p>
<p>Anomaly in output vectors</p>
<p>As previously mentioned, language models generate a probability distribution over a word (or character) in a sequence. These probabilities can be used to detect transcription or character-recognition errors in a domain-friendly manner. When the language model is trained on financial data, domain-specific trends (such as the use of commas and parentheses in financial metrics) can be captured and accounted for by the network, minimizing the rate of false positives.</p>
<p>Anomaly in hidden vectors</p>
<p>A recent advancement in text processing is the introduction of finetuning methods to neural networks trained on text [6]. Fine-tuning is an approach that facilitates the transfer of semantic knowledge from one domain (source) to another domain (target). The source domain is often large and generic, such as web data or the Wikipedia corpus, while the target domain is often specific (e.g. SEC filings). A network is pre-trained on the source corpus such that its hidden representations are enriched. Next, the pre-trained networks is retrained on the target domain, but this time only the final (or top few) layers are tuned and the parameters in the remaining layers remain "frozen. " The top-most layer of the network can be modified to perform a classification, prediction, or generation task in the target domain (see Figure 2).</p>
<p>Fine-tuning aims to change the distribution of hidden representations in such a way that important information about the source domain is preserved, while idiosyncrasies of the target domain are captured in an effective manner [15]. A similar process can be used to determine anomalies in documents. As an example, consider a model that is pre-trained on historical documents from a given sector. If fine-tuning the model on recent documents from the same sector dramatically shifts the representations for certain vectors, this can signal an evolving trend.</p>
<p>Anomaly in weight tensors and other parameters</p>
<p>Models that have interpretable parameters can be used to identify areas of deviation or anomalous content. Attention mechanisms [19] allow the network to account for certain input signals more than others. The learned attention mechanism can provide insight into potential anomalies in the input. Consider a language model that predicts the social media engagement for a given tweet. Such a model can be used to distinguish between engaging and information-rich content versus clickbait, bot-generated, propagandistic, or promotional content by exposing how, for these categories, engagement is associated with attention to certain distributions of "trigger words. " Table 1 lists four scenarios for using the various layers and parameters of a language model in order to perform anomaly detection from text.   </p>
<p>CHALLENGES AND FUTURE RESEARCH</p>
<p>Like many other domains, in the financial domain, the application of language models as a measurement for semantic regularity of text bears the challenge of dealing with unseen input. Unseen input can be mistaken for anomaly, especially in systems that are designed for error detection. As an example, a system that is trained to correct errors in an earnings call transcript might treat named entities such as the names of a company's executives, or a recent acquisition, as anomalies. This problem is particularly prominent in fine-tuned language models, which are pre-trained on generic corpora that might not include domain-specific terms.</p>
<p>When anomalies are of a malicious nature, such as in the case where abnormal clauses are included in credit agreements, the implementation of the anomalous content is adapted to appear normal. Thereby, the task of detecting normal language becomes more difficult.</p>
<p>Alternatively, in the case of language used by executives in company presentations such as earnings calls, there may be a lot of noise in the data due to the large degree of variability in the personalities and linguistic patterns of various leaders. The noise variability present in this content could be similar to actual anomalies, hence making it difficult to identify true anomalies.</p>
<p>Factors related to market interactions and competitive behavior can also impact the effectiveness of anomaly-detection models. In detecting the emergence of a new industry sector, it may be challenging for a system to detect novelty when a collection of companies, rather than a single company, behave in an anomalous way. The former may be the more common real-world scenario as companies closely monitor and mimic the innovations of their competitors. The exact notion of anomaly can also vary based on the sector and point in time. For example, in the technology sector, the norm in today's world is one of continuous innovation and technological advancements.</p>
<p>Additionally, certain types of anomaly can interact and make it difficult for systems to distinguish between them. As an example, a system that is trained to identify the operating segments of a company tends to distinguish between information that is specific to the company, and information that is common across different companies. As a result, it might identify the names of the company's board of directors or its office locations as its operating segments.</p>
<p>Traditional machine learning models have previously tackled the above challenges, and solutions are likely to emerge in the neural paradigms as well. Any future research in these directions will have to account for the impact of such solutions on the reliability and explainability of the resulting models and their robustness against adversarial data.</p>
<p>CONCLUSION</p>
<p>Anomaly detection from text can have numerous applications in finance, including risk detection, predictive analysis, error correction, and peer detection. We have outlined various perspectives on how anomaly can be interpreted in the context of finance, and corresponding views on how language modeling can be used to detect such aspects of anomalous content. We hope that this paper lays the groundwork for establishing a framework for understanding the opportunities and risks associated with these methods when applied in the financial domain.</p>
<p>Figure 1 :
1Illustration of a recurrent step in a language model. Excerpted from[8].</p>
<p>Figure 2 :
2A pre-trained model can be fine-tuned on a new domain, and applied to a classification or prediction task. Excerpted from[6].</p>
<p>Table 1 :
1Four scenarios for anomaly detection on text data using signals from various layers and parameters in a language model.</p>
<p>Credit risk analysis using machine and deep learning models. Peter Addo, Dominique Guegan, Bertrand Hassani, Risks. 638Peter Addo, Dominique Guegan, and Bertrand Hassani. 2018. Credit risk analysis using machine and deep learning models. Risks 6, 2 (2018), 38.</p>
<p>Unsupervised Topic Discovery by Anomaly Detection. Leon Cheng, Leon Cheng. 2013. Unsupervised Topic Discovery by Anomaly Detection.</p>
<p>Bert: Pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, arXiv:1810.04805arXiv preprintJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 (2018).</p>
<p>Detecting Errors within a Corpus using Anomaly Detection. Eleazar Eskin, 1st Meeting of the North American Chapter of the Association for Computational Linguistics. Eleazar Eskin. 2000. Detecting Errors within a Corpus using Anomaly Detection. In 1st Meeting of the North American Chapter of the Association for Computational Linguistics. https://www.aclweb.org/anthology/A00-2020</p>
<p>Long Short-Term Memory. Sepp Hochreiter, Jrgen Schmidhuber, Neural Computation. 9Sepp Hochreiter and Jrgen Schmidhuber. 1997. Long Short-Term Memory. Neural Computation 9, 8 (1997), 1735-1780.</p>
<p>Fine-tuned Language Models for Text Classification. Jeremy Howard, Sebastian Ruder, CoRR abs/1801.06146Jeremy Howard and Sebastian Ruder. 2018. Fine-tuned Language Models for Text Classification. CoRR abs/1801.06146 (2018).</p>
<p>Does trading volume contain information to predict stock returns? Evidence from China's stock markets. F Cheng, Lee, Oliver M Rui, Review of Quantitative Finance and Accounting. 14Cheng F Lee and Oliver M Rui. 2000. Does trading volume contain informa- tion to predict stock returns? Evidence from China's stock markets. Review of Quantitative Finance and Accounting 14, 4 (2000), 341-360.</p>
<p>Language modeling a billion words. Nicholas Leonard, Nicholas Leonard. 2016. Language modeling a billion words. http://torch.ch/ blog/2016/07/25/nce.html.</p>
<p>Real-Time Novel Event Detection from Social Media. Quanzhi Li, Armineh Nourbakhsh, Sameena Shah, Xiaomo Liu, 33rd IEEE International Conference on Data Engineering. San Diego, CA, USAQuanzhi Li, Armineh Nourbakhsh, Sameena Shah, and Xiaomo Liu. 2017. Real- Time Novel Event Detection from Social Media. In 33rd IEEE International Con- ference on Data Engineering, ICDE 2017, San Diego, CA, USA, April 19-22, 2017. 1129-1139.</p>
<p>Real-time Rumor Debunking on Twitter. Xiaomo Liu, Armineh Nourbakhsh, Quanzhi Li, Rui Fang, Sameena Shah, Proceedings of the 24th ACM International Conference on Information and Knowledge Management, CIKM 2015. the 24th ACM International Conference on Information and Knowledge Management, CIKM 2015Melbourne, VIC, AustraliaXiaomo Liu, Armineh Nourbakhsh, Quanzhi Li, Rui Fang, and Sameena Shah. 2015. Real-time Rumor Debunking on Twitter. In Proceedings of the 24th ACM International Conference on Information and Knowledge Management, CIKM 2015, Melbourne, VIC, Australia, October 19 -23, 2015. 1867-1870.</p>
<p>Distributed representations of words and phrases and their compositionality. Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, Jeff Dean, Advances in neural information processing systems. Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems. 3111-3119.</p>
<p>apping the echo-chamber: detecting and characterizing partisan networks on Twitter. Armineh Nourbakhsh, Xiaomo Liu, Quanzhi Li, Sameena Shah, Proceedings of the 2017 International Conference on Social Computing, Behavioral-Cultural Modeling, &amp; Prediction and Behavior Representation in Modeling and Simulation. the 2017 International Conference on Social Computing, Behavioral-Cultural Modeling, &amp; Prediction and Behavior Representation in Modeling and SimulationArmineh Nourbakhsh, Xiaomo Liu, Quanzhi Li, and Sameena Shah. 2017. "apping the echo-chamber: detecting and characterizing partisan networks on Twitter. In Proceedings of the 2017 International Conference on Social Computing, Behavioral- Cultural Modeling, &amp; Prediction and Behavior Representation in Modeling and Simulation.</p>
<p>Newsworthy Rumor Events: A Case Study of Twitter. Armineh Nourbakhsh, Xiaomo Liu, Sameena Shah, Rui Fang, Mohammad Mahdi Ghassemi, Quanzhi Li, IEEE International Conference on Data Mining Workshop, ICDMW 2015. Atlantic City, NJ, USAArmineh Nourbakhsh, Xiaomo Liu, Sameena Shah, Rui Fang, Mohammad Mahdi Ghassemi, and Quanzhi Li. 2015. Newsworthy Rumor Events: A Case Study of Twitter. In IEEE International Conference on Data Mining Workshop, ICDMW 2015, Atlantic City, NJ, USA, November 14-17, 2015. 27-32.</p>
<p>E Matthew, Mark Peters, Mohit Neumann, Matt Iyyer, Christopher Gardner, Kenton Clark, Luke Lee, Zettlemoyer, arXiv:1802.05365Deep contextualized word representations. arXiv preprintMatthew E Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. 2018. Deep contextualized word representations. arXiv preprint arXiv:1802.05365 (2018).</p>
<p>Learning to select data for transfer learning with Bayesian Optimization. Sebastian Ruder, Barbara Plank, 10.18653/v1/D17-1038Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics. the 2017 Conference on Empirical Methods in Natural Language Processing. Association for Computational LinguisticsCopenhagen, DenmarkSebastian Ruder and Barbara Plank. 2017. Learning to select data for transfer learn- ing with Bayesian Optimization. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguis- tics, Copenhagen, Denmark, 372-382. https://doi.org/10.18653/v1/D17-1038</p>
<p>A simple real-word error detection and correction using local word bigram and trigram. Pratip Samanta, B Bidyut, Chaudhuri, Proceedings of the 25th Conference on Computational Linguistics and Speech Processing. the 25th Conference on Computational Linguistics and Speech ProcessingROCLING 2013Pratip Samanta and Bidyut B. Chaudhuri. 2013. A simple real-word error detection and correction using local word bigram and trigram. In Proceedings of the 25th Conference on Computational Linguistics and Speech Processing (ROCLING 2013).</p>
<p>The Association for Computational Linguistics and Chinese Language Processing (ACLCLP). Kaohsiung, TaiwanThe Association for Computational Linguistics and Chinese Language Processing (ACLCLP), Kaohsiung, Taiwan, 211-220. https://www.aclweb.org/anthology/ O13-1022</p>
<p>Sameena Shah, Dietmar Dorr, Khalid Al-Kofahi, Jacob Sisk, Systems and methods for determining atypical language. n. d.Sameena Shah, Dietmar Dorr, Khalid Al-Kofahi, and Jacob Sisk. [n. d.]. Systems and methods for determining atypical language.</p>
<p>From Frequency to Meaning: Vector Space Models of Semantics. D Peter, Patrick Turney, Pantel, CoRR abs/1003.1141Peter D. Turney and Patrick Pantel. 2010. From Frequency to Meaning: Vector Space Models of Semantics. CoRR abs/1003.1141 (2010).</p>
<p>Attention is All you Need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Illia Kaiser, Polosukhin, Advances in Neural Information Processing Systems. I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. GarnettCurran Associates, Inc30Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,  ukasz Kaiser, and Illia Polosukhin. 2017. Attention is All you Need. In Advances in Neural Information Processing Systems 30, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Eds.). Curran Associates, Inc., 5998-6008.</p>
<p>Linear) maps of the impossible: capturing semantic anomalies in distributional space. Maria Eva, Marco Vecchi, Roberto Baroni, Zamparelli, Proceedings of the Workshop on Distributional Semantics and Compositionality. the Workshop on Distributional Semantics and CompositionalityAssociation for Computational LinguisticsEva Maria Vecchi, Marco Baroni, and Roberto Zamparelli. 2011. (Linear) maps of the impossible: capturing semantic anomalies in distributional space. In Proceed- ings of the Workshop on Distributional Semantics and Compositionality. Association for Computational Linguistics, 1-9.</p>
<p>Stochastic Language Generation in Dialogue using Recurrent Neural Networks with Convolutional Sentence Reranking. Milica Tsung Hsien Wen, Dongho Gasic, Nikola Kim, Pei-Hao Mrksic, David Su, Steve Vandyke, Young, Tsung Hsien Wen, Milica Gasic, Dongho Kim, Nikola Mrksic, Pei-Hao Su, David Vandyke, and Steve Young. 2015. Stochastic Language Generation in Dialogue using Recurrent Neural Networks with Convolutional Sentence Reranking. (08 2015).</p>
<p>Laura Wendlandt, Jonathan K Kummerfeld, Rada Mihalcea, arXiv:1804.09692Factors influencing the surprising instability of word embeddings. arXiv preprintLaura Wendlandt, Jonathan K Kummerfeld, and Rada Mihalcea. 2018. Fac- tors influencing the surprising instability of word embeddings. arXiv preprint arXiv:1804.09692 (2018).</p>
<p>Intelligent financial fraud detection: A comprehensive review. Jarrod West, Maumita Bhattacharya, 10.1016/j.cose.2015.09.005Computers &amp; Security. 57Jarrod West and Maumita Bhattacharya. 2016. Intelligent financial fraud detection: A comprehensive review. Computers &amp; Security 57 (2016), 47 -66. https: //doi.org/10.1016/j.cose.2015.09.005</p>
<p>Hanging on Every Word: Natural Language Processing Unlocks New Frontier in Corporate Earnings Sentiment Analysis. Frank Zhao, Frank Zhao. 2017. Hanging on Every Word: Natural Language Processing Unlocks New Frontier in Corporate Earnings Sentiment Analysis. https://www.valuewalk. com/2017/09/natural-language-processing-corporate-earnings-sentiment/.</p>            </div>
        </div>

    </div>
</body>
</html>