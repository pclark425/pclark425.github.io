<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7677 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7677</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7677</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-140.html">extraction-schema-140</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of a problem/prompt influences the performance of large language models, including details of the format, the task, the model, and reported performance differences.</div>
                <p><strong>Paper ID:</strong> paper-59641c10ed7431a3cf841f308367dc2dc0281b74</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/59641c10ed7431a3cf841f308367dc2dc0281b74" target="_blank">What Makes Good In-Context Examples for GPT-3?</a></p>
                <p><strong>Paper Venue:</strong> Workshop on Knowledge Extraction and Integration for Deep Learning Architectures; Deep Learning Inside Out</p>
                <p><strong>Paper TL;DR:</strong> This work proposes to retrieve examples that are semantically-similar to a test query sample to formulate its corresponding prompt, and evaluates the proposed approach on several natural language understanding and generation benchmarks, where the retrieval-based prompt selection approach consistently outperforms the random selection baseline.</p>
                <p><strong>Paper Abstract:</strong> GPT-3 has attracted lots of attention due to its superior performance across a wide range of NLP tasks, especially with its in-context learning abilities. Despite its success, we found that the empirical results of GPT-3 depend heavily on the choice of in-context examples. In this work, we investigate whether there are more effective strategies for judiciously selecting in-context examples (relative to random sampling) that better leverage GPT-3’s in-context learning capabilities.Inspired by the recent success of leveraging a retrieval module to augment neural networks, we propose to retrieve examples that are semantically-similar to a test query sample to formulate its corresponding prompt. Intuitively, the examples selected with such a strategy may serve as more informative inputs to unleash GPT-3’s power of text generation. We evaluate the proposed approach on several natural language understanding and generation benchmarks, where the retrieval-based prompt selection approach consistently outperforms the random selection baseline. Moreover, it is observed that the sentence encoders fine-tuned on task-related datasets yield even more helpful retrieval results. Notably, significant gains are observed on tasks such as table-to-text generation (44.3% on the ToTTo dataset) and open-domain question answering (45.5% on the NQ dataset).</p>
                <p><strong>Cost:</strong> 0.021</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7677.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7677.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of a problem/prompt influences the performance of large language models, including details of the format, the task, the model, and reported performance differences.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Context-sensitivity (random examples)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Sensitivity of GPT-3 performance to the choice of randomly sampled in-context examples</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper documents large variability in GPT-3's few-shot performance depending on which in‑context examples are provided, showing that different random example sets can change accuracy substantially on the same task.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Large autoregressive Transformer language model used in an in-context (few-shot) setting; no task-specific fine-tuning performed.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>175B</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>SST-2 sentiment analysis (as evaluated by GPT-3)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Binary sentiment classification of sentences (Stanford Sentiment Treebank benchmark).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Few-shot in-context classification: a small set of example (input, label) pairs concatenated into a single prompt then followed by a test sentence to label.</td>
                        </tr>
                        <tr>
                            <td><strong>format_category</strong></td>
                            <td>prompt style</td>
                        </tr>
                        <tr>
                            <td><strong>format_details</strong></td>
                            <td>Different randomly sampled sets of in-context examples (five different example-sets/trials reported). Examples concatenated with separators as in the paper's prompt template (e.g., 'Sentence: ... Label: ...').</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Five trials reported: 94.6%, 95.0%, 95.8%, 93.9%, 86.9% accuracy (Table 1)</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_change</strong></td>
                            <td>Range of 8.9 percentage points across trials (95.8% - 86.9%), indicating high sensitivity to which examples are used</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_setting</strong></td>
                            <td>GPT-3 in-context inference with different randomly selected example sets; exact number of examples per prompt as in the paper's few-shot template; temperature=0 for API runs (paper-wide setting).</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'What Makes Good In-Context Examples for GPT-3?', 'publication_date_yy_mm': '2021-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7677.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7677.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of a problem/prompt influences the performance of large language models, including details of the format, the task, the model, and reported performance differences.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>KATE (sentiment)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>KNN-Augmented In-Context Example Selection — Sentiment transfer evaluation (IMDB)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Using retrieval (kNN in sentence-embedding space) to pick semantically similar in-context examples (KATE) substantially improves GPT-3's few-shot accuracy versus randomly chosen examples on an out-of-dataset sentiment transfer evaluation (SST-2 examples → IMDB test).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Autoregressive Transformer used in few-shot (in-context) generation; the paper does not fine-tune GPT-3 itself and leverages it via API.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>175B</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>IMDB sentiment analysis (dataset-transfer; examples sampled from SST-2)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Binary sentiment classification on IMDB test set, using in-context examples selected from SST-2 training set.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Few-shot in-context classification; 3 in-context examples (paper states number of examples chosen to be 3 for this transfer setting); prompt template 'Sentence: ... Label:'.</td>
                        </tr>
                        <tr>
                            <td><strong>format_category</strong></td>
                            <td>prompt style / example selection</td>
                        </tr>
                        <tr>
                            <td><strong>format_details</strong></td>
                            <td>Examples selected either randomly or via KATE (kNN retrieval in RoBERTa-derived embedding space). Variants of sentence encoders used for retrieval: RoBERTa-large (KATE_roberta), RoBERTa fine-tuned on NLI (KATE_nli), NLI+STS-B (KATE_nli+sts-b), and RoBERTa fine-tuned on SST-2 (KATE_sst-2). Temperature set to 0.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>KATE_roberta: 91.99% accuracy; KATE_nli: 90.40%; KATE_nli+sts-b: 90.20%; KATE_sst-2: 93.43% (best)</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td>Random: 87.95% ± 2.74 accuracy; kNN_roberta (majority-vote of retrieved targets): 50.20% accuracy; Fine-tuned T5 (reference): 95.2% accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_change</strong></td>
                            <td>KATE_roberta vs Random: +4.04 percentage points absolute (91.99 - 87.95); KATE_sst-2 vs Random: +5.48 pp absolute; KATE_sst-2 approaches fine-tuned T5 but remains slightly lower (93.43 vs 95.2).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_setting</strong></td>
                            <td>In-context examples selected from SST-2 training set; 3 examples per prompt; retrieval uses RoBERTa-based encoders; negative Euclidean or cosine similarity depending on encoder; temperature=0; random baseline averaged over 5 runs (std reported).</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'What Makes Good In-Context Examples for GPT-3?', 'publication_date_yy_mm': '2021-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7677.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7677.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of a problem/prompt influences the performance of large language models, including details of the format, the task, the model, and reported performance differences.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>KATE (table-to-text)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>KNN-Augmented In-Context Example Selection — Table-to-text generation (ToTTo)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Selecting semantically similar table→text examples (KATE) as in-context demonstrations greatly improves GPT-3's table-to-text generation quality compared with random example selection, bringing GPT-3 close to a fine-tuned T5 model.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Autoregressive Transformer used to generate natural-language descriptions conditioned on a table and a few in-context table→sentence examples.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>175B</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>ToTTo (table-to-text generation)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Generate a human-readable sentence describing a given Wikipedia table and highlighted cells.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Few-shot in-context generation: concatenated (Table: ... Sentence: ...) example pairs; 2 in-context examples used (to fit GPT-3's token limit).</td>
                        </tr>
                        <tr>
                            <td><strong>format_category</strong></td>
                            <td>prompt style / input modality (tabular data)</td>
                        </tr>
                        <tr>
                            <td><strong>format_details</strong></td>
                            <td>Preprocessing to reduce token length (remove closing tags). In-context examples either randomly sampled or retrieved via KATE (RoBERTa variants). Number of examples set to 2. Evaluation uses BLEU and PARENT. Temperature=0.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>BLEU and PARENT</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>KATE_roberta: BLEU 41.0, PARENT 50.6</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td>Random: BLEU 28.4 ± 2.1, PARENT 39.3 ± 2.6; Fine-tuned T5 (3B reference): BLEU 41.2, PARENT 53.0</td>
                        </tr>
                        <tr>
                            <td><strong>performance_change</strong></td>
                            <td>KATE_roberta vs Random: +12.6 BLEU absolute (41.0 - 28.4) and +11.3 PARENT absolute (50.6 - 39.3); KATE_roberta reaches BLEU comparable to fine-tuned T5 (41.0 vs 41.2) though PARENT remains lower.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_setting</strong></td>
                            <td>2 in-context examples due to token limit; retrieval via RoBERTa or fine-tuned variants; evaluation on ToTTo dev set and on overlap / non-overlap subsets; temperature=0.</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'What Makes Good In-Context Examples for GPT-3?', 'publication_date_yy_mm': '2021-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7677.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e7677.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of a problem/prompt influences the performance of large language models, including details of the format, the task, the model, and reported performance differences.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>KATE (QA - NQ)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>KNN-Augmented In-Context Example Selection — Open-domain QA (Natural Questions)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Retrieving semantically similar question-answer pairs as in-context examples (KATE) substantially improves GPT-3 exact-match performance on Natural Questions vs random example selection, and fine-tuning the retrieval encoder on NLI/STS-B further helps.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Autoregressive Transformer used as a conditional generator to produce answers given a question and a set of in-context Q-A examples.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>175B</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Natural Questions (NQ) — open-domain QA</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Answer real-user queries (open-domain) with exact-match evaluation against ground-truth answers.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Few-shot in-context QA: concatenated Q: ... A: ... pairs used as examples; 64 in-context examples used in primary experiments for NQ (to the extent token limits allow).</td>
                        </tr>
                        <tr>
                            <td><strong>format_category</strong></td>
                            <td>prompt style / example selection</td>
                        </tr>
                        <tr>
                            <td><strong>format_details</strong></td>
                            <td>Retrieval via sentence encoders (RoBERTa-large and variants fine-tuned on NLI and STS-B); similarity measures negative Euclidean or cosine; majority voting also explored when retrieving many examples; temperature=0.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Exact Match (EM)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>KATE_roberta: 40.0% EM; KATE_nli: 40.8% EM; KATE_nli+sts-b: 41.6% EM</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td>Random (64 examples): 28.6% ± 0.3 EM; GPT-3 reported earlier (64 examples): 29.9% (paper cites); kNN_roberta (top-1 neighbor majority): 24.0% EM; Fine-tuned baselines (RAG/T5) reported for context: RAG 44.5% EM, T5+SSM 36.6%, T5 34.5%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_change</strong></td>
                            <td>KATE_roberta vs Random: +11.4 pp absolute (40.0 - 28.6); KATE_nli+sts-b vs Random: +13.0 pp absolute (41.6 - 28.6). KATE variants surpass closed-book T5 (34.5) and approach RAG (44.5) in this evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_setting</strong></td>
                            <td>64 retrieved in-context examples for NQ (when token-limit permits; paper also explores varying k); sentence encoders: RoBERTa-large (pretrained), RoBERTa fine-tuned on NLI, and additionally on STS-B; similarity used for ranking; temperature=0.</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'What Makes Good In-Context Examples for GPT-3?', 'publication_date_yy_mm': '2021-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7677.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e7677.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of a problem/prompt influences the performance of large language models, including details of the format, the task, the model, and reported performance differences.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>KATE (QA - WQ)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>KNN-Augmented In-Context Example Selection — Open-domain QA (WebQuestions)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>KATE retrieval improves GPT-3 exact-match performance on WebQuestions compared with random example selection, with NLI-fine-tuned retrieval encoders yielding the best gains.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Autoregressive Transformer used in few-shot QA generation.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>175B</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>WebQuestions (WQ) — open-domain QA</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Answer short factual questions from WebQuestions dataset, evaluated by exact-match.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Few-shot in-context QA with many retrieved Q-A exemplars (64 examples used in experiments where feasible).</td>
                        </tr>
                        <tr>
                            <td><strong>format_category</strong></td>
                            <td>prompt style / example selection</td>
                        </tr>
                        <tr>
                            <td><strong>format_details</strong></td>
                            <td>Retrieval using RoBERTa and NLI/STS-B fine-tuned variants; 64 examples; temperature=0.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Exact Match (EM)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>KATE_roberta: 47.7% EM; KATE_nli: 50.6% EM; KATE_nli+sts-b: 50.2% EM</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td>Random: 41.0% ± 0.5 EM; kNN_roberta: 23.9% EM; Fine-tuned baselines: RAG 45.5%, T5+SSM 44.7%, T5 37.4%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_change</strong></td>
                            <td>KATE_roberta vs Random: +6.7 pp absolute (47.7 - 41.0); KATE_nli vs Random: +9.6 pp absolute.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_setting</strong></td>
                            <td>64 retrieved in-context examples; sentence encoders varied; temperature=0.</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'What Makes Good In-Context Examples for GPT-3?', 'publication_date_yy_mm': '2021-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7677.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e7677.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of a problem/prompt influences the performance of large language models, including details of the format, the task, the model, and reported performance differences.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>KATE (QA - TriviaQA)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>KNN-Augmented In-Context Example Selection — Open-domain QA (TriviaQA)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>For TriviaQA the effect of KATE depends on the retrieval encoder: vanilla RoBERTa retrieval underperforms random selection, but retrieval encoders fine-tuned on NLI/STS-B outperform random selection, indicating encoder-task match matters for example selection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Autoregressive Transformer used in few-shot QA; generation evaluated by exact-match against TriviaQA references.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>175B</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>TriviaQA — open-domain QA</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Answer trivia questions; evaluated by exact-match.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Few-shot in-context QA; 10 in-context examples used for TriviaQA experiments (token-limit driven).</td>
                        </tr>
                        <tr>
                            <td><strong>format_category</strong></td>
                            <td>prompt style / example selection</td>
                        </tr>
                        <tr>
                            <td><strong>format_details</strong></td>
                            <td>10 retrieved in-context examples (due to token limits); retrieval encoders: RoBERTa-large baseline and NLI/STS-B fine-tuned variants; temperature=0.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Exact Match (EM)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>KATE_roberta: 57.5% EM; KATE_nli: 60.9% EM; KATE_nli+sts-b: 62.4% EM</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td>Random: 59.2% ± 0.4 EM; kNN_roberta: 26.2% EM; Fine-tuned baselines: RAG 68.0%, T5+SSM 60.5%, T5 50.1%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_change</strong></td>
                            <td>KATE_nli+sts-b vs Random: +3.2 pp absolute (62.4 - 59.2); KATE_roberta in this case underperforms Random by -1.7 pp (57.5 - 59.2), showing that choice of retrieval encoder matters.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_setting</strong></td>
                            <td>10 in-context examples for TriviaQA; retrieval encoder selection critical; temperature=0.</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'What Makes Good In-Context Examples for GPT-3?', 'publication_date_yy_mm': '2021-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7677.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e7677.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of a problem/prompt influences the performance of large language models, including details of the format, the task, the model, and reported performance differences.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Nearest vs Farthest example selection</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Effect of proximity (nearest vs farthest neighbors in embedding space) of in-context examples on GPT-3</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An experiment compared using the 10 closest training instances versus the 10 farthest (in a RoBERTa CLS embedding Euclidean space) as in-context examples for NQ and found nearest neighbors produce substantially better exact-match results than farthest ones.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Autoregressive Transformer used in few-shot QA generation.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>175B</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Natural Questions (NQ) — proximity selection experiment</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Answer open-domain questions; comparison isolates the effect of semantic proximity of in-context examples.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Few-shot in-context QA where the k examples are either the 10 most similar or 10 least similar training instances to the test question (based on RoBERTa CLS embeddings).</td>
                        </tr>
                        <tr>
                            <td><strong>format_category</strong></td>
                            <td>example selection strategy</td>
                        </tr>
                        <tr>
                            <td><strong>format_details</strong></td>
                            <td>Sentence representations: RoBERTa-large CLS embeddings; distance metric: Euclidean; k=10; evaluation on 100 randomly sampled test questions; EM reported (paper references Table 2).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Exact Match (EM)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_change</strong></td>
                            <td>Qualitative: nearest-neighbor example selection yields 'much better' EM than farthest-neighbor selection (numeric values not included in the main text excerpt).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_setting</strong></td>
                            <td>100 test questions randomly sampled; RoBERTa CLS embeddings used to measure proximity; 10 nearest vs 10 farthest neighbors compared; temperature=0.</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'What Makes Good In-Context Examples for GPT-3?', 'publication_date_yy_mm': '2021-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7677.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e7677.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of a problem/prompt influences the performance of large language models, including details of the format, the task, the model, and reported performance differences.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Number of in-context examples</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Effect of the number of in-context examples (k) on GPT-3 performance</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Across NQ experiments varying k ∈ {5,10,20,35,64}, both KATE and random selection baselines benefit from more examples, but KATE consistently outperforms random even with as few as 5 examples.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Autoregressive Transformer used with varying counts of in-context examples.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>175B</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Natural Questions (NQ) — ablation over number of in-context examples</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Open-domain QA; examine sensitivity to number of provided exemplars.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Few-shot in-context prompts with varying k (number of example pairs) concatenated before test input.</td>
                        </tr>
                        <tr>
                            <td><strong>format_category</strong></td>
                            <td>prompt style / scaling of examples</td>
                        </tr>
                        <tr>
                            <td><strong>format_details</strong></td>
                            <td>k values tested: 5, 10, 20, 35, 64 for NQ; compared KATE_nli+sts-b and KATE_roberta to random baseline; both methods improve with more examples but KATE retains advantage at all k tested; temperature=0.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Exact Match (EM) trend (plot shown in paper's Figure 2)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_change</strong></td>
                            <td>Qualitative: KATE consistently higher-than-random for all tested k, and both improve monotonically with increasing k; KATE shows clear advantage even at k=5.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_setting</strong></td>
                            <td>NQ dataset; multiple training-subset sizes used for retrieval analyses; temperature=0.</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'What Makes Good In-Context Examples for GPT-3?', 'publication_date_yy_mm': '2021-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7677.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e7677.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of a problem/prompt influences the performance of large language models, including details of the format, the task, the model, and reported performance differences.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Order of in-context examples</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Effect of ordering retrieved in-context examples within the prompt</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The ordering (most-similar-first vs reverse vs random permutations) of retrieved examples has small, dataset-dependent effects on performance; in NQ reverse ordering slightly outperformed default in the reported runs, but differences are minor relative to retrieval vs random selection effects.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Autoregressive Transformer used with ordered sequences of in-context exemplars.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>175B</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Natural Questions (NQ) — ordering ablation</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Open-domain QA; examine robustness to order of exemplars in the prompt.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Few-shot in-context prompt where retrieved examples are ordered by similarity score (most similar first), with experiments testing reverse order and random permutations.</td>
                        </tr>
                        <tr>
                            <td><strong>format_category</strong></td>
                            <td>prompt style / ordering</td>
                        </tr>
                        <tr>
                            <td><strong>format_details</strong></td>
                            <td>Default order: descending similarity (most similar first); reverse order: least similar first; 3 random permutations tested; reported EM scores for KATE_nli+sts-b: Trials: 42.0, 42.5, 42.0; Default: 41.6; Reverse: 42.8 (Table 8).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Exact Match (EM)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Default: 41.6% EM; Reverse order: 42.8% EM; sample trial values: 42.0%, 42.5%, 42.0%</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_change</strong></td>
                            <td>Reverse vs Default: +1.2 percentage points absolute (42.8 - 41.6); overall variations small compared to gains from retrieval vs random.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_setting</strong></td>
                            <td>KATE_nli+sts-b on NQ; multiple permutations and a reverse ordering evaluated; temperature=0.</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'What Makes Good In-Context Examples for GPT-3?', 'publication_date_yy_mm': '2021-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7677.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e7677.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of a problem/prompt influences the performance of large language models, including details of the format, the task, the model, and reported performance differences.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Prompt templates & delimiters</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Prompt template formats (Sentence: Label:, Table: ... Sentence:, Q: A:) and use of a special 'in' delimiter</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper documents specific prompt templates used across tasks (classification, table-to-text, QA) and a special delimiter token ('in') inserted between adjacent examples; this formatting controls generation behavior (e.g., termination) and standardizes how examples are presented to GPT-3.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Autoregressive Transformer conditioned on concatenated textual exemplars formatted with task-specific templates and separators.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>175B</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Multiple tasks (SST-2/IMDB sentiment, ToTTo table-to-text, QA)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Various NLU/NLG tasks using consistent prompt templates for in-context learning.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Few-shot in-context prompts with explicit template tokens and separators: 'Sentence: ... Label:' for sentiment, 'Table: ... Sentence:' for table-to-text, 'Q: ... A:' for QA; a special token/string 'in' inserted between examples to mark boundaries and generation termination.</td>
                        </tr>
                        <tr>
                            <td><strong>format_category</strong></td>
                            <td>prompt style / prompt engineering</td>
                        </tr>
                        <tr>
                            <td><strong>format_details</strong></td>
                            <td>Templates shown in Table 11; appendix Figure 3 shows that GPT-3 generates until the special 'in' token and treats example pairs as a single concatenated context; temperature=0 used across experiments; prompt preprocessing (e.g., removal of closing tags) applied for length control in ToTTo.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Not a single numeric metric — this is a format/design factor reported to influence generation behavior and comparability across methods</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_change</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_setting</strong></td>
                            <td>Templates applied consistently across tasks; delimiting examples with 'in' used to structure input; token-limit driven choices (number of examples) influenced by prompt length.</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'What Makes Good In-Context Examples for GPT-3?', 'publication_date_yy_mm': '2021-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Language models are few-shot learners <em>(Rating: 2)</em></li>
                <li>Sentence-bert: Sentence embeddings using siamese bert-networks <em>(Rating: 2)</em></li>
                <li>A retrieve-and-edit framework for predicting structured outputs <em>(Rating: 1)</em></li>
                <li>Dense passage retrieval for open-domain question answering <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7677",
    "paper_id": "paper-59641c10ed7431a3cf841f308367dc2dc0281b74",
    "extraction_schema_id": "extraction-schema-140",
    "extracted_data": [
        {
            "name_short": "Context-sensitivity (random examples)",
            "name_full": "Sensitivity of GPT-3 performance to the choice of randomly sampled in-context examples",
            "brief_description": "The paper documents large variability in GPT-3's few-shot performance depending on which in‑context examples are provided, showing that different random example sets can change accuracy substantially on the same task.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3",
            "model_description": "Large autoregressive Transformer language model used in an in-context (few-shot) setting; no task-specific fine-tuning performed.",
            "model_size": "175B",
            "task_name": "SST-2 sentiment analysis (as evaluated by GPT-3)",
            "task_description": "Binary sentiment classification of sentences (Stanford Sentiment Treebank benchmark).",
            "problem_format": "Few-shot in-context classification: a small set of example (input, label) pairs concatenated into a single prompt then followed by a test sentence to label.",
            "format_category": "prompt style",
            "format_details": "Different randomly sampled sets of in-context examples (five different example-sets/trials reported). Examples concatenated with separators as in the paper's prompt template (e.g., 'Sentence: ... Label: ...').",
            "performance_metric": "Accuracy",
            "performance_value": "Five trials reported: 94.6%, 95.0%, 95.8%, 93.9%, 86.9% accuracy (Table 1)",
            "baseline_performance": null,
            "performance_change": "Range of 8.9 percentage points across trials (95.8% - 86.9%), indicating high sensitivity to which examples are used",
            "experimental_setting": "GPT-3 in-context inference with different randomly selected example sets; exact number of examples per prompt as in the paper's few-shot template; temperature=0 for API runs (paper-wide setting).",
            "statistical_significance": null,
            "uuid": "e7677.0",
            "source_info": {
                "paper_title": "What Makes Good In-Context Examples for GPT-3?",
                "publication_date_yy_mm": "2021-01"
            }
        },
        {
            "name_short": "KATE (sentiment)",
            "name_full": "KNN-Augmented In-Context Example Selection — Sentiment transfer evaluation (IMDB)",
            "brief_description": "Using retrieval (kNN in sentence-embedding space) to pick semantically similar in-context examples (KATE) substantially improves GPT-3's few-shot accuracy versus randomly chosen examples on an out-of-dataset sentiment transfer evaluation (SST-2 examples → IMDB test).",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3",
            "model_description": "Autoregressive Transformer used in few-shot (in-context) generation; the paper does not fine-tune GPT-3 itself and leverages it via API.",
            "model_size": "175B",
            "task_name": "IMDB sentiment analysis (dataset-transfer; examples sampled from SST-2)",
            "task_description": "Binary sentiment classification on IMDB test set, using in-context examples selected from SST-2 training set.",
            "problem_format": "Few-shot in-context classification; 3 in-context examples (paper states number of examples chosen to be 3 for this transfer setting); prompt template 'Sentence: ... Label:'.",
            "format_category": "prompt style / example selection",
            "format_details": "Examples selected either randomly or via KATE (kNN retrieval in RoBERTa-derived embedding space). Variants of sentence encoders used for retrieval: RoBERTa-large (KATE_roberta), RoBERTa fine-tuned on NLI (KATE_nli), NLI+STS-B (KATE_nli+sts-b), and RoBERTa fine-tuned on SST-2 (KATE_sst-2). Temperature set to 0.",
            "performance_metric": "Accuracy",
            "performance_value": "KATE_roberta: 91.99% accuracy; KATE_nli: 90.40%; KATE_nli+sts-b: 90.20%; KATE_sst-2: 93.43% (best)",
            "baseline_performance": "Random: 87.95% ± 2.74 accuracy; kNN_roberta (majority-vote of retrieved targets): 50.20% accuracy; Fine-tuned T5 (reference): 95.2% accuracy",
            "performance_change": "KATE_roberta vs Random: +4.04 percentage points absolute (91.99 - 87.95); KATE_sst-2 vs Random: +5.48 pp absolute; KATE_sst-2 approaches fine-tuned T5 but remains slightly lower (93.43 vs 95.2).",
            "experimental_setting": "In-context examples selected from SST-2 training set; 3 examples per prompt; retrieval uses RoBERTa-based encoders; negative Euclidean or cosine similarity depending on encoder; temperature=0; random baseline averaged over 5 runs (std reported).",
            "statistical_significance": null,
            "uuid": "e7677.1",
            "source_info": {
                "paper_title": "What Makes Good In-Context Examples for GPT-3?",
                "publication_date_yy_mm": "2021-01"
            }
        },
        {
            "name_short": "KATE (table-to-text)",
            "name_full": "KNN-Augmented In-Context Example Selection — Table-to-text generation (ToTTo)",
            "brief_description": "Selecting semantically similar table→text examples (KATE) as in-context demonstrations greatly improves GPT-3's table-to-text generation quality compared with random example selection, bringing GPT-3 close to a fine-tuned T5 model.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3",
            "model_description": "Autoregressive Transformer used to generate natural-language descriptions conditioned on a table and a few in-context table→sentence examples.",
            "model_size": "175B",
            "task_name": "ToTTo (table-to-text generation)",
            "task_description": "Generate a human-readable sentence describing a given Wikipedia table and highlighted cells.",
            "problem_format": "Few-shot in-context generation: concatenated (Table: ... Sentence: ...) example pairs; 2 in-context examples used (to fit GPT-3's token limit).",
            "format_category": "prompt style / input modality (tabular data)",
            "format_details": "Preprocessing to reduce token length (remove closing tags). In-context examples either randomly sampled or retrieved via KATE (RoBERTa variants). Number of examples set to 2. Evaluation uses BLEU and PARENT. Temperature=0.",
            "performance_metric": "BLEU and PARENT",
            "performance_value": "KATE_roberta: BLEU 41.0, PARENT 50.6",
            "baseline_performance": "Random: BLEU 28.4 ± 2.1, PARENT 39.3 ± 2.6; Fine-tuned T5 (3B reference): BLEU 41.2, PARENT 53.0",
            "performance_change": "KATE_roberta vs Random: +12.6 BLEU absolute (41.0 - 28.4) and +11.3 PARENT absolute (50.6 - 39.3); KATE_roberta reaches BLEU comparable to fine-tuned T5 (41.0 vs 41.2) though PARENT remains lower.",
            "experimental_setting": "2 in-context examples due to token limit; retrieval via RoBERTa or fine-tuned variants; evaluation on ToTTo dev set and on overlap / non-overlap subsets; temperature=0.",
            "statistical_significance": null,
            "uuid": "e7677.2",
            "source_info": {
                "paper_title": "What Makes Good In-Context Examples for GPT-3?",
                "publication_date_yy_mm": "2021-01"
            }
        },
        {
            "name_short": "KATE (QA - NQ)",
            "name_full": "KNN-Augmented In-Context Example Selection — Open-domain QA (Natural Questions)",
            "brief_description": "Retrieving semantically similar question-answer pairs as in-context examples (KATE) substantially improves GPT-3 exact-match performance on Natural Questions vs random example selection, and fine-tuning the retrieval encoder on NLI/STS-B further helps.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3",
            "model_description": "Autoregressive Transformer used as a conditional generator to produce answers given a question and a set of in-context Q-A examples.",
            "model_size": "175B",
            "task_name": "Natural Questions (NQ) — open-domain QA",
            "task_description": "Answer real-user queries (open-domain) with exact-match evaluation against ground-truth answers.",
            "problem_format": "Few-shot in-context QA: concatenated Q: ... A: ... pairs used as examples; 64 in-context examples used in primary experiments for NQ (to the extent token limits allow).",
            "format_category": "prompt style / example selection",
            "format_details": "Retrieval via sentence encoders (RoBERTa-large and variants fine-tuned on NLI and STS-B); similarity measures negative Euclidean or cosine; majority voting also explored when retrieving many examples; temperature=0.",
            "performance_metric": "Exact Match (EM)",
            "performance_value": "KATE_roberta: 40.0% EM; KATE_nli: 40.8% EM; KATE_nli+sts-b: 41.6% EM",
            "baseline_performance": "Random (64 examples): 28.6% ± 0.3 EM; GPT-3 reported earlier (64 examples): 29.9% (paper cites); kNN_roberta (top-1 neighbor majority): 24.0% EM; Fine-tuned baselines (RAG/T5) reported for context: RAG 44.5% EM, T5+SSM 36.6%, T5 34.5%",
            "performance_change": "KATE_roberta vs Random: +11.4 pp absolute (40.0 - 28.6); KATE_nli+sts-b vs Random: +13.0 pp absolute (41.6 - 28.6). KATE variants surpass closed-book T5 (34.5) and approach RAG (44.5) in this evaluation.",
            "experimental_setting": "64 retrieved in-context examples for NQ (when token-limit permits; paper also explores varying k); sentence encoders: RoBERTa-large (pretrained), RoBERTa fine-tuned on NLI, and additionally on STS-B; similarity used for ranking; temperature=0.",
            "statistical_significance": null,
            "uuid": "e7677.3",
            "source_info": {
                "paper_title": "What Makes Good In-Context Examples for GPT-3?",
                "publication_date_yy_mm": "2021-01"
            }
        },
        {
            "name_short": "KATE (QA - WQ)",
            "name_full": "KNN-Augmented In-Context Example Selection — Open-domain QA (WebQuestions)",
            "brief_description": "KATE retrieval improves GPT-3 exact-match performance on WebQuestions compared with random example selection, with NLI-fine-tuned retrieval encoders yielding the best gains.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3",
            "model_description": "Autoregressive Transformer used in few-shot QA generation.",
            "model_size": "175B",
            "task_name": "WebQuestions (WQ) — open-domain QA",
            "task_description": "Answer short factual questions from WebQuestions dataset, evaluated by exact-match.",
            "problem_format": "Few-shot in-context QA with many retrieved Q-A exemplars (64 examples used in experiments where feasible).",
            "format_category": "prompt style / example selection",
            "format_details": "Retrieval using RoBERTa and NLI/STS-B fine-tuned variants; 64 examples; temperature=0.",
            "performance_metric": "Exact Match (EM)",
            "performance_value": "KATE_roberta: 47.7% EM; KATE_nli: 50.6% EM; KATE_nli+sts-b: 50.2% EM",
            "baseline_performance": "Random: 41.0% ± 0.5 EM; kNN_roberta: 23.9% EM; Fine-tuned baselines: RAG 45.5%, T5+SSM 44.7%, T5 37.4%",
            "performance_change": "KATE_roberta vs Random: +6.7 pp absolute (47.7 - 41.0); KATE_nli vs Random: +9.6 pp absolute.",
            "experimental_setting": "64 retrieved in-context examples; sentence encoders varied; temperature=0.",
            "statistical_significance": null,
            "uuid": "e7677.4",
            "source_info": {
                "paper_title": "What Makes Good In-Context Examples for GPT-3?",
                "publication_date_yy_mm": "2021-01"
            }
        },
        {
            "name_short": "KATE (QA - TriviaQA)",
            "name_full": "KNN-Augmented In-Context Example Selection — Open-domain QA (TriviaQA)",
            "brief_description": "For TriviaQA the effect of KATE depends on the retrieval encoder: vanilla RoBERTa retrieval underperforms random selection, but retrieval encoders fine-tuned on NLI/STS-B outperform random selection, indicating encoder-task match matters for example selection.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3",
            "model_description": "Autoregressive Transformer used in few-shot QA; generation evaluated by exact-match against TriviaQA references.",
            "model_size": "175B",
            "task_name": "TriviaQA — open-domain QA",
            "task_description": "Answer trivia questions; evaluated by exact-match.",
            "problem_format": "Few-shot in-context QA; 10 in-context examples used for TriviaQA experiments (token-limit driven).",
            "format_category": "prompt style / example selection",
            "format_details": "10 retrieved in-context examples (due to token limits); retrieval encoders: RoBERTa-large baseline and NLI/STS-B fine-tuned variants; temperature=0.",
            "performance_metric": "Exact Match (EM)",
            "performance_value": "KATE_roberta: 57.5% EM; KATE_nli: 60.9% EM; KATE_nli+sts-b: 62.4% EM",
            "baseline_performance": "Random: 59.2% ± 0.4 EM; kNN_roberta: 26.2% EM; Fine-tuned baselines: RAG 68.0%, T5+SSM 60.5%, T5 50.1%",
            "performance_change": "KATE_nli+sts-b vs Random: +3.2 pp absolute (62.4 - 59.2); KATE_roberta in this case underperforms Random by -1.7 pp (57.5 - 59.2), showing that choice of retrieval encoder matters.",
            "experimental_setting": "10 in-context examples for TriviaQA; retrieval encoder selection critical; temperature=0.",
            "statistical_significance": null,
            "uuid": "e7677.5",
            "source_info": {
                "paper_title": "What Makes Good In-Context Examples for GPT-3?",
                "publication_date_yy_mm": "2021-01"
            }
        },
        {
            "name_short": "Nearest vs Farthest example selection",
            "name_full": "Effect of proximity (nearest vs farthest neighbors in embedding space) of in-context examples on GPT-3",
            "brief_description": "An experiment compared using the 10 closest training instances versus the 10 farthest (in a RoBERTa CLS embedding Euclidean space) as in-context examples for NQ and found nearest neighbors produce substantially better exact-match results than farthest ones.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3",
            "model_description": "Autoregressive Transformer used in few-shot QA generation.",
            "model_size": "175B",
            "task_name": "Natural Questions (NQ) — proximity selection experiment",
            "task_description": "Answer open-domain questions; comparison isolates the effect of semantic proximity of in-context examples.",
            "problem_format": "Few-shot in-context QA where the k examples are either the 10 most similar or 10 least similar training instances to the test question (based on RoBERTa CLS embeddings).",
            "format_category": "example selection strategy",
            "format_details": "Sentence representations: RoBERTa-large CLS embeddings; distance metric: Euclidean; k=10; evaluation on 100 randomly sampled test questions; EM reported (paper references Table 2).",
            "performance_metric": "Exact Match (EM)",
            "performance_value": null,
            "baseline_performance": null,
            "performance_change": "Qualitative: nearest-neighbor example selection yields 'much better' EM than farthest-neighbor selection (numeric values not included in the main text excerpt).",
            "experimental_setting": "100 test questions randomly sampled; RoBERTa CLS embeddings used to measure proximity; 10 nearest vs 10 farthest neighbors compared; temperature=0.",
            "statistical_significance": null,
            "uuid": "e7677.6",
            "source_info": {
                "paper_title": "What Makes Good In-Context Examples for GPT-3?",
                "publication_date_yy_mm": "2021-01"
            }
        },
        {
            "name_short": "Number of in-context examples",
            "name_full": "Effect of the number of in-context examples (k) on GPT-3 performance",
            "brief_description": "Across NQ experiments varying k ∈ {5,10,20,35,64}, both KATE and random selection baselines benefit from more examples, but KATE consistently outperforms random even with as few as 5 examples.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3",
            "model_description": "Autoregressive Transformer used with varying counts of in-context examples.",
            "model_size": "175B",
            "task_name": "Natural Questions (NQ) — ablation over number of in-context examples",
            "task_description": "Open-domain QA; examine sensitivity to number of provided exemplars.",
            "problem_format": "Few-shot in-context prompts with varying k (number of example pairs) concatenated before test input.",
            "format_category": "prompt style / scaling of examples",
            "format_details": "k values tested: 5, 10, 20, 35, 64 for NQ; compared KATE_nli+sts-b and KATE_roberta to random baseline; both methods improve with more examples but KATE retains advantage at all k tested; temperature=0.",
            "performance_metric": "Exact Match (EM) trend (plot shown in paper's Figure 2)",
            "performance_value": null,
            "baseline_performance": null,
            "performance_change": "Qualitative: KATE consistently higher-than-random for all tested k, and both improve monotonically with increasing k; KATE shows clear advantage even at k=5.",
            "experimental_setting": "NQ dataset; multiple training-subset sizes used for retrieval analyses; temperature=0.",
            "statistical_significance": null,
            "uuid": "e7677.7",
            "source_info": {
                "paper_title": "What Makes Good In-Context Examples for GPT-3?",
                "publication_date_yy_mm": "2021-01"
            }
        },
        {
            "name_short": "Order of in-context examples",
            "name_full": "Effect of ordering retrieved in-context examples within the prompt",
            "brief_description": "The ordering (most-similar-first vs reverse vs random permutations) of retrieved examples has small, dataset-dependent effects on performance; in NQ reverse ordering slightly outperformed default in the reported runs, but differences are minor relative to retrieval vs random selection effects.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3",
            "model_description": "Autoregressive Transformer used with ordered sequences of in-context exemplars.",
            "model_size": "175B",
            "task_name": "Natural Questions (NQ) — ordering ablation",
            "task_description": "Open-domain QA; examine robustness to order of exemplars in the prompt.",
            "problem_format": "Few-shot in-context prompt where retrieved examples are ordered by similarity score (most similar first), with experiments testing reverse order and random permutations.",
            "format_category": "prompt style / ordering",
            "format_details": "Default order: descending similarity (most similar first); reverse order: least similar first; 3 random permutations tested; reported EM scores for KATE_nli+sts-b: Trials: 42.0, 42.5, 42.0; Default: 41.6; Reverse: 42.8 (Table 8).",
            "performance_metric": "Exact Match (EM)",
            "performance_value": "Default: 41.6% EM; Reverse order: 42.8% EM; sample trial values: 42.0%, 42.5%, 42.0%",
            "baseline_performance": null,
            "performance_change": "Reverse vs Default: +1.2 percentage points absolute (42.8 - 41.6); overall variations small compared to gains from retrieval vs random.",
            "experimental_setting": "KATE_nli+sts-b on NQ; multiple permutations and a reverse ordering evaluated; temperature=0.",
            "statistical_significance": null,
            "uuid": "e7677.8",
            "source_info": {
                "paper_title": "What Makes Good In-Context Examples for GPT-3?",
                "publication_date_yy_mm": "2021-01"
            }
        },
        {
            "name_short": "Prompt templates & delimiters",
            "name_full": "Prompt template formats (Sentence: Label:, Table: ... Sentence:, Q: A:) and use of a special 'in' delimiter",
            "brief_description": "The paper documents specific prompt templates used across tasks (classification, table-to-text, QA) and a special delimiter token ('in') inserted between adjacent examples; this formatting controls generation behavior (e.g., termination) and standardizes how examples are presented to GPT-3.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3",
            "model_description": "Autoregressive Transformer conditioned on concatenated textual exemplars formatted with task-specific templates and separators.",
            "model_size": "175B",
            "task_name": "Multiple tasks (SST-2/IMDB sentiment, ToTTo table-to-text, QA)",
            "task_description": "Various NLU/NLG tasks using consistent prompt templates for in-context learning.",
            "problem_format": "Few-shot in-context prompts with explicit template tokens and separators: 'Sentence: ... Label:' for sentiment, 'Table: ... Sentence:' for table-to-text, 'Q: ... A:' for QA; a special token/string 'in' inserted between examples to mark boundaries and generation termination.",
            "format_category": "prompt style / prompt engineering",
            "format_details": "Templates shown in Table 11; appendix Figure 3 shows that GPT-3 generates until the special 'in' token and treats example pairs as a single concatenated context; temperature=0 used across experiments; prompt preprocessing (e.g., removal of closing tags) applied for length control in ToTTo.",
            "performance_metric": "Not a single numeric metric — this is a format/design factor reported to influence generation behavior and comparability across methods",
            "performance_value": null,
            "baseline_performance": null,
            "performance_change": null,
            "experimental_setting": "Templates applied consistently across tasks; delimiting examples with 'in' used to structure input; token-limit driven choices (number of examples) influenced by prompt length.",
            "statistical_significance": null,
            "uuid": "e7677.9",
            "source_info": {
                "paper_title": "What Makes Good In-Context Examples for GPT-3?",
                "publication_date_yy_mm": "2021-01"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Language models are few-shot learners",
            "rating": 2
        },
        {
            "paper_title": "Sentence-bert: Sentence embeddings using siamese bert-networks",
            "rating": 2
        },
        {
            "paper_title": "A retrieve-and-edit framework for predicting structured outputs",
            "rating": 1
        },
        {
            "paper_title": "Dense passage retrieval for open-domain question answering",
            "rating": 1
        }
    ],
    "cost": 0.021397,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>What Makes Good In-Context Examples for GPT-3?</h1>
<p>Jiachang Liu ${ }^{1}$, Dinghan Shen ${ }^{2}$, Yizhe Zhang ${ }^{3}$, Bill Dolan ${ }^{4}$, Lawrence Carin ${ }^{1}$, Weizhu Chen ${ }^{2}$<br>${ }^{1}$ Duke University ${ }^{2}$ Microsoft Dynamics $365 \mathrm{AI} \quad{ }^{3}$ Meta AI ${ }^{4}$ Microsoft Research<br>${ }^{1}$ {jiachang.liu, lcarin}@duke.edu<br>${ }^{3}$ yizhe.zhang@hotmail.com<br>${ }^{2,4}$ {dishen, billdol, wzchen}@microsoft.com</p>
<h4>Abstract</h4>
<p>GPT-3 has attracted lots of attention due to its superior performance across a wide range of NLP tasks, especially with its in-context learning abilities. Despite its success, we found that the empirical results of GPT-3 depend heavily on the choice of in-context examples. In this work, we investigate whether there are more effective strategies for judiciously selecting incontext examples (relative to random sampling) that better leverage GPT-3's in-context learning capabilities. Inspired by the recent success of leveraging a retrieval module to augment neural networks, we propose to retrieve examples that are semantically-similar to a test query sample to formulate its corresponding prompt. Intuitively, the examples selected with such a strategy may serve as more informative inputs to unleash GPT-3's power of text generation. We evaluate the proposed approach on several natural language understanding and generation benchmarks, where the retrieval-based prompt selection approach consistently outperforms the random selection baseline. Moreover, it is observed that the sentence encoders finetuned on task-related datasets yield even more helpful retrieval results. Notably, significant gains are observed on tasks such as table-totext generation ( $44.3 \%$ on the ToTTo dataset) and open-domain question answering ( $45.5 \%$ on the NQ dataset).</p>
<h2>1 Introduction</h2>
<p>GPT-3 (Brown et al., 2020) is a new breakthrough in NLP research. Previously, NLP models are firstly pre-trained and then fine-tuned on a specific task. What sets GPT-3 apart from other models is its impressive "in-context" learning ability. Provided with a few in-context examples, GPT-3 can generalize to unseen cases without further finetuning. This opens up many new technological possibilities that are previously considered unique</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>${ }^{4}$ Work was done when Jiachang (intern) and Yizhe were at Microsoft.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Trial</th>
<th style="text-align: center;">1</th>
<th style="text-align: center;">2</th>
<th style="text-align: center;">3</th>
<th style="text-align: center;">4</th>
<th style="text-align: center;">5</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Accuracy</td>
<td style="text-align: center;">94.6</td>
<td style="text-align: center;">95.0</td>
<td style="text-align: center;">95.8</td>
<td style="text-align: center;">93.9</td>
<td style="text-align: center;">86.9</td>
</tr>
</tbody>
</table>
<p>Table 1: Results of GPT-3 on the SST-2 sentiment analysis dataset. Five different examples are randomly selected from the training set for each trial. Different contexts induce different accuracies on the test set.
to human. Future NLP systems can be developed to expand emails, extract entities from text, generate code based on natural language instructions with a few demonstration examples.</p>
<p>Despite its powerful and versatile in-context learning ability, GPT-3 has some practical challenges. The original paper utilizes task-relevant examples that are randomly sampled from the training set. However, we observe that the performance of GPT-3 tends to fluctuate with different choices of in-context examples. As shown in Table 1, the variance with distinct in-context examples can be significant. Our work aims to carefully examine this issue to gain a deeper understanding on how to better select in-context examples to improve GPT3 's performance without fine-tuning. Note that our approach requires a training set to select examples. With such a training dataset, it is possible to fine-tune GPT-3 to take full advantage of the model's strength. However, currently GPT-3 has not been released to public for fine-tuning. Even if it is available, fine-tuning GPT-3 requires hundreds of GPUs to load the 175B model, which is prohibitively expensive and time-consuming for ordinary research labs. Another issue is that storing large fine-tuned model checkpoints require huge storage space. Consequently, we resort to prompt/example engineering strategy. Nevertheless, the fine-tuning results using T5 are provided for reference.</p>
<p>A brute-force approach for selecting the optimal in-context instances would be to perform combinatorial search over the entire dataset. Unfortunately, this strategy is computationally impractical. To this</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: In-context example selection for GPT-3. White dots: unused training samples; grey dots: randomly sampled training samples; red dots: training samples selected by the k-nearest neighbors algorithm in the embedding space of a sentence encoder.
end, we empirically investigate the influences of employing different in-context examples. Interestingly, we find that the in-context examples that are closer to the test sample in the embedding space consistently give rise to stronger performance (relative to the farther ones). Inspired by this observation and the recent success of retrieval-augmented models Hashimoto et al., 2018), we propose to utilize nearest neighbors of a given test sample (among all the training instances available) as the in-context examples.</p>
<p>To verify the effectiveness of the proposed method, we evaluate it on several natural language understanding and generation tasks, including sentiment analysis, table-to-text generation and opendomain question answering. It is observed that the retrieval-based in-context examples unleash the in-context learning capabilities of GPT-3 much more effectively than the random sampling baseline, even when the number of examples is small. Moreover, we find that the specific sentence encoders employed for the retrieval procedure play a critical role. Thus, an extensive exploration is conducted and shows that encoders fine-tuned on natural language matching tasks serve as more effective in-context examples selector on the QA task. In summary, our contributions are as follows:
i) to the best of our knowledge, we take a first step towards understanding the sensitivity of GPT3's in-context learning ability with respect to the choice of in-context examples;
ii) to alleviate the sensitivity issue, an additional retrieval module is introduced to find semanticallysimilar in-context examples of a test instance, which greatly outperforms the baseline based on
randomly sampled in-context examples;
iii) empirically, the better selected examples lead GPT-3 to achieve comparable performance to a fine-tuned T5 model on the table-to-text task and outperforms the T5 model on the QA tasks;
iv) fine-tuning the retrieval model on task-related dataset(s) leads to stronger empirical results;
v) the performance of GPT-3 improves as the number of examples for retrieval increases.</p>
<h2>2 Method</h2>
<h3>2.1 GPT-3 for In-Context Learning</h3>
<p>The in-context learning scenario of GPT-3 can be regarded as a conditional text generation problem. Concretely, the probability of generating a target $y$ is conditioned on the context $C$, which includes $k$ examples, and the source $x$. Therefore, the probability can be expressed as:</p>
<p>$$
p_{\mathrm{LM}}(y \mid C, x)=\prod_{t=1}^{T} p\left(y_{t} \mid C, x, y_{&lt;t}\right)
$$</p>
<p>where LM denotes the parameters of the language model, and $C=\left{x_{1}, y_{1}, x_{2}, y_{2}, \ldots, x_{k}, y_{k}\right}$ is a context string concatenating $k$ training instances with the special character "in". A concrete illustration can be found in the Appendix.</p>
<p>For GPT-3, this generation process is implemented through a giant transformer-based architecture Vaswani et al., 2017). Due to the computational burden of fine-tuning, GPT-3 is leveraged in an in-context learning manner as described above. Unfortunately, as shown in Table 1, the results of GPT-3 tend to fluctuate significantly with different in-context examples. We aim to alleviate this issue via judicious in-context example selection.</p>
<h3>2.2 The Impact of In-Context Examples</h3>
<p>We start the investigation by looking at the role of in-context examples from an empirical perspective. Previous retrieve-and-edit literature usually retrieve prototypes that are close to the test source $x$ in some embedding space. These examples and the test source $x$ often share semantic or lexical similarities. This hints on how we may select incontext examples for GPT-3.</p>
<p>To this end, we examine the impact of the distance between the in-context example and the test sample on GPT-3's performance. Concretely, a comparison is made on the the Natural Questions (NQ) dataset between two selection strategies. Given a test example, the first method utilizes the 10 farthest training instances as the in-context examples, while the second employs the 10 closest neighbors. We use the CLS embeddings of a pre-trained RoBERTa-large model as sentence representations to measure the proximity of two sentences (using the Euclidean distance).</p>
<p>For evaluation, 100 test questions are randomly sampled and the average Exact Match (EM) scores with the two distinct strategies are reported in Table 2. It can be observed that the nearest neighbors, used as the in-context examples, give rise to much better results relative to the farthest ones. Moreover, the pre-trained RoBERTa model serves as effective sentence embeddings for the retrieval procedure.</p>
<h3>2.3 kNN-augmented Example Selection</h3>
<p>Based on the findings above, we propose KATE $^{1}$, a strategy to select good examples for in-context learning. The process is visualized in Figure 1. Specifically, we first use a sentence encoder to convert sources in both the training set and test set to vector representations. For online prediction, we can convert the training set first and encode each test source on the fly. Then, for each test source $x$, we retrieve its nearest $k$ neighbors $x_{1}, x_{2}, \ldots, x_{k}$ from the training set (according to the distances in the embedding space). Given some pre-defined similarity measure $s$ such as the negative Euclidean distance or the cosine similarity, the neighbors are ordered so that $s\left(x_{i}, x\right) \geq s\left(x_{j}, x\right)$ when $i&lt;j$.</p>
<p>The $k$ sources are concatenated with their targets to form the context $C=$ $\left{x_{1}, y_{1}, x_{2}, y_{2}, \ldots, x_{k}, y_{k}\right}$, which is sent to GPT-3 along with the test input. The algorithm is presented in Algorithm 1. Note that different</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup>Table 2: Comparison of the EM score on the closest 10 neighbors and farthest 10 neighbors on a subset of 100 test samples of the NQ dataset.</p>
<div class="codehilite"><pre><span></span><code><span class="nt">Algorithm</span><span class="w"> </span><span class="nt">1</span><span class="w"> </span><span class="nt">kNN</span><span class="w"> </span><span class="nt">In-context</span><span class="w"> </span><span class="nt">Example</span><span class="w"> </span><span class="nt">Selection</span>
<span class="nt">Given</span><span class="o">:</span><span class="w"> </span><span class="nt">test</span><span class="w"> </span><span class="nt">prompt</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">boldsymbol</span><span class="p">{</span><span class="err">x</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{test</span><span class="w"> </span><span class="p">}</span><span class="err">}\</span><span class="o">),</span><span class="w"> </span><span class="nt">training</span><span class="w"> </span><span class="nt">set</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">mathcal</span><span class="p">{</span><span class="err">D</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">T</span><span class="p">}</span><span class="o">=</span><span class="err">\</span><span class="o">)</span>
<span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">left</span><span class="err">\</span><span class="p">{</span><span class="err">\boldsymbol{x</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">i</span><span class="p">}</span><span class="o">,</span><span class="w"> </span><span class="err">\</span><span class="nt">boldsymbol</span><span class="p">{</span><span class="err">y</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">i</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="err">\}</span><span class="nt">_</span><span class="p">{</span><span class="err">i=1</span><span class="p">}</span><span class="o">^</span><span class="p">{</span><span class="err">N</span><span class="p">}</span><span class="err">\</span><span class="o">),</span><span class="w"> </span><span class="nt">sentence</span><span class="w"> </span><span class="nt">encoder</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">mu_</span><span class="p">{</span><span class="err">\theta</span><span class="p">}</span><span class="o">(</span><span class="err">\</span><span class="nt">cdot</span><span class="o">)</span><span class="err">\</span><span class="o">),</span><span class="w"> </span><span class="nt">and</span><span class="w"> </span><span class="nt">number</span>
<span class="nt">of</span><span class="w"> </span><span class="nt">in-context</span><span class="w"> </span><span class="nt">examples</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">k</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="o">(</span><span class="nt">hyperparameter</span><span class="o">).</span>
<span class="w">    </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">boldsymbol</span><span class="p">{</span><span class="err">v</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{test</span><span class="w"> </span><span class="p">}</span><span class="err">}</span><span class="o">=</span><span class="err">\</span><span class="nt">mu_</span><span class="p">{</span><span class="err">\theta</span><span class="p">}</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="err">\</span><span class="nt">boldsymbol</span><span class="p">{</span><span class="err">x</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{test</span><span class="w"> </span><span class="p">}</span><span class="err">}\</span><span class="nt">right</span><span class="o">)</span><span class="err">\</span><span class="o">)</span>
<span class="w">    </span><span class="nt">for</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">boldsymbol</span><span class="p">{</span><span class="err">x</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">i</span><span class="p">}</span><span class="w"> </span><span class="err">\</span><span class="nt">in</span><span class="w"> </span><span class="err">\</span><span class="nt">mathcal</span><span class="p">{</span><span class="err">D</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">T</span><span class="p">}</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">do</span>
<span class="w">        </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">boldsymbol</span><span class="p">{</span><span class="err">v</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">i</span><span class="p">}</span><span class="o">=</span><span class="err">\</span><span class="nt">mu_</span><span class="p">{</span><span class="err">\theta</span><span class="p">}</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="err">\</span><span class="nt">boldsymbol</span><span class="p">{</span><span class="err">x</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">i</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="o">)</span><span class="err">\</span><span class="o">)</span>
<span class="w">        </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">boldsymbol</span><span class="p">{</span><span class="err">s</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">i</span><span class="p">}</span><span class="o">=</span><span class="nt">-</span><span class="err">\</span><span class="nt">left</span><span class="err">\</span><span class="o">|</span><span class="err">\</span><span class="nt">boldsymbol</span><span class="p">{</span><span class="err">v</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{test</span><span class="w"> </span><span class="p">}</span><span class="err">}</span><span class="nt">-</span><span class="err">\</span><span class="nt">boldsymbol</span><span class="p">{</span><span class="err">v</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">i</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="err">\</span><span class="o">|</span><span class="nt">_</span><span class="p">{</span><span class="err">2</span><span class="p">}</span><span class="w"> </span><span class="err">\</span><span class="nt">quad</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="err">\</span><span class="nt">right</span><span class="o">.</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">or</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">left</span><span class="o">.</span><span class="err">\</span><span class="nt">frac</span><span class="p">{</span><span class="err">\boldsymbol{v</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{test</span><span class="w"> </span><span class="p">}</span><span class="err">}</span><span class="w"> </span><span class="err">\</span><span class="nt">cdot</span><span class="w"> </span><span class="err">\</span><span class="nt">boldsymbol</span><span class="p">{</span><span class="err">v</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">i</span><span class="p">}</span><span class="err">}</span><span class="p">{</span><span class="err">\left\|\boldsymbol{v</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{test</span><span class="w"> </span><span class="p">}</span><span class="err">}\</span><span class="nt">right</span><span class="err">\</span><span class="o">|</span><span class="nt">_</span><span class="p">{</span><span class="err">2</span><span class="p">}</span><span class="err">\</span><span class="nt">left</span><span class="err">\</span><span class="o">|</span><span class="err">\</span><span class="nt">boldsymbol</span><span class="p">{</span><span class="err">v</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">i</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="err">\</span><span class="o">|</span><span class="nt">_</span><span class="p">{</span><span class="err">2</span><span class="p">}</span><span class="err">}\</span><span class="nt">right</span><span class="o">)</span><span class="err">\</span><span class="o">)</span>
<span class="w">    </span><span class="nt">end</span><span class="w"> </span><span class="nt">for</span>
<span class="w">    </span><span class="nt">Select</span><span class="w"> </span><span class="nt">largest</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">k</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">similarities</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">boldsymbol</span><span class="p">{</span><span class="err">s</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">i</span><span class="p">}</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="err">&#39;</span><span class="nt">s</span><span class="w"> </span><span class="o">(</span><span class="nt">in</span><span class="w"> </span><span class="nt">descending</span>
<span class="w">    </span><span class="nt">order</span><span class="o">)</span><span class="w"> </span><span class="nt">with</span><span class="w"> </span><span class="nt">indices</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="p">{</span><span class="err">\sigma(1),</span><span class="w"> </span><span class="err">\ldots,</span><span class="w"> </span><span class="err">\sigma(k)\</span><span class="p">}</span><span class="err">\</span><span class="o">)</span>
<span class="w">    </span><span class="err">\</span><span class="o">(</span><span class="nt">C</span><span class="o">=</span><span class="err">\</span><span class="nt">left</span><span class="cp">[</span><span class="o">\</span><span class="nx">boldsymbol</span><span class="p">{</span><span class="nx">x</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="o">\</span><span class="nx">sigma</span><span class="p">(</span><span class="mi">1</span><span class="p">)}</span><span class="w"> </span><span class="p">;</span><span class="w"> </span><span class="o">\</span><span class="nx">boldsymbol</span><span class="p">{</span><span class="nx">y</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="o">\</span><span class="nx">sigma</span><span class="p">(</span><span class="mi">1</span><span class="p">)}</span><span class="w"> </span><span class="p">;</span><span class="w"> </span><span class="o">\</span><span class="nx">ldots</span><span class="w"> </span><span class="p">;</span><span class="w"> </span><span class="o">\</span><span class="nx">boldsymbol</span><span class="p">{</span><span class="nx">x</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="o">\</span><span class="nx">sigma</span><span class="p">(</span><span class="nx">k</span><span class="p">)}</span><span class="w"> </span><span class="p">;</span><span class="w"> </span><span class="o">\</span><span class="nx">boldsymbol</span><span class="p">{</span><span class="nx">y</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="o">\</span><span class="nx">sigma</span><span class="p">(</span><span class="nx">k</span><span class="p">)}</span><span class="o">\</span><span class="nx">right</span><span class="cp">]</span><span class="err">\</span><span class="o">)</span>
<span class="w">    </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">dot</span><span class="p">{</span><span class="err">\boldsymbol{y</span><span class="p">}</span><span class="err">}</span><span class="nt">_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{test</span><span class="w"> </span><span class="p">}</span><span class="err">}</span><span class="o">=</span><span class="err">\</span><span class="nt">operatorname</span><span class="p">{</span><span class="err">GPT</span><span class="p">}</span><span class="nt">-3</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="err">\</span><span class="nt">left</span><span class="cp">[</span><span class="nx">C</span><span class="w"> </span><span class="p">;</span><span class="w"> </span><span class="o">\</span><span class="nx">boldsymbol</span><span class="p">{</span><span class="nx">x</span><span class="p">}</span><span class="nx">_</span><span class="p">{</span><span class="o">\</span><span class="nx">text</span><span class="w"> </span><span class="p">{</span><span class="nx">test</span><span class="w"> </span><span class="p">}}</span><span class="o">\</span><span class="nx">right</span><span class="cp">]</span><span class="err">\</span><span class="nt">right</span><span class="o">)</span><span class="err">\</span><span class="o">)</span>
</code></pre></div>

<p>numbers of examples can be employed, and we conduct study on its impact in a later section.</p>
<p>Choices of Retrieval Module A core step for our context selection approach is mapping sentences into a latent semantic space, leaving a question as what sentence encoders we should choose. We compared among existing pre-trained text encoders and found them sufficient to retrieve semantically similar sentences. The sentence encoders can be divided into two categories.</p>
<p>The first category includes generally pre-trained sentence encoders such as the BERT, RoBERTa, and XLNet models. These models have been trained on large quantities of unsupervised tasks and achieved good performance on many natural language tasks. The corresponding embeddings contain rich semantic information from the original sentences.</p>
<p>The second category includes sentence encoders fine-tuned on specific tasks or datasets. For example, a sentence encoder trained on the STS dataset should be able to assess similarities among different questions better than a generally pre-trained sentence encoder. Sentence-BERT (Wolf et al., 2019; Reimers and Gurevych, 2019, 2020) shows that these fine-tuned encoders have achieved great performance on tasks such as sentence clustering, paraphrase mining, and information retrieval.</p>
<h2>3 Experimental Setup</h2>
<p>We apply our proposed method to the following three tasks: sentiment analysis, table-to-text generation, and question answering. Dataset split setups and prompt templates are shown in Table 9 and 11 in the Appendix. For the hyper-parameters in the GPT-3 API, we set the temperature to 0 .</p>
<h3>3.1 Sentence Embeddings for Retrieval</h3>
<p>To retrieve semantically-similar training instances, we consider two types of sentence embeddings.</p>
<ul>
<li>The original RoBERTa-large model (Liu et al., 2019), which is abbreviated as $\mathrm{KATE}_{\text {roberta }}$;</li>
<li>The RoBERTa-large models which are: $i$ ) finetuned on the SNLI and MultiNLI datasets ( $\mathrm{KATE}<em _nli_sts-b="{nli+sts-b" _text="\text">{\text {nli }}$ ) (Bowman et al., 2015; Williams et al., 2017); ii) first fine-tuned on the SNLI and MultiNLI dataset and then on the STS-B datasets ( $\mathrm{KATE}</em>$ ) (Cer et al., 2017).}</li>
</ul>
<p>All sentence encoders share the same architecture. The only differences are the specific datasets used for fine-tuning. The negative Euclidean distance is used for $\mathrm{KATE}<em _nli="{nli" _text="\text">{\text {roberta }}$, while the cosine similarity is employed for $\mathrm{KATE}</em>$.}}$ and $\mathrm{KATE}_{\text {nli+sts-b }</p>
<p>Sentiment Analysis For this task, we conduct experiments under the dataset-transfer setting. Incontext examples are selected from one dataset, and the evaluation is made on another dataset. This setting is designed to simulate a real-world scenario where we want to leverage an existing labeled dataset for a unlabeled one (of a similar task).</p>
<p>Specifically, we select examples from the SST2 training set (Socher et al., 2013; Wang et al., 2018) and ask GPT-3 to predict on the IMDB test set (Maas et al., 2011). To explore whether a sentence encoder fine-tuned on a similar task would benefit KATE, we also employ a pre-trained RoBERTa-large model fine-tuned on the SST-2 training set (dubbed as $\mathrm{KATE}_{\text {sst-2 }}$ ). The number of examples is chosen to be 3 since adding more examples does not further improve the performance.</p>
<p>Table-to-Text Generation Given a Wikipedia table and a set of highlighted cells, this task focuses on producing human-readable texts as descriptions. ToTTo (Parikh et al., 2020) ${ }^{2}$ is utilized for evaluation due to its popularity. We use BLEU (Papineni</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup>et al., 2002) and PARENT (Dhingra et al., 2019) metrics for evaluation. Because the token length limit of GPT-3 is 2048, we add a preprocessing step by deleting the closing angle brackets such as $&lt;/$ cell $&gt;$ and $&lt;/$ table $&gt;$ to save space. The number of in-context examples is set as 2 so that the input length is within the token limit.</p>
<p>Question Answering We conduct experiments on three QA benchmarks: Natural Questions (NQ) (Kwiatkowski et al., 2019), Web Questions (WQ) (Berant et al., 2013), and TriviaQA (Joshi et al., 2017). For evaluation, we use the Exact Match (EM) score, which is defined as the proportion of the number of predicted answers being exactly one of the ground-truth answers. The matching is performed after string normalization, which includes article and punctuation removal. The number of examples is set to be 64 for NQ and WQ and 10 for TriviaQA (The retrieved 64 examples exceed the token limit). We evaluate on the test sets of NQ and WQ and the dev set of TriviaQA.</p>
<h3>3.2 Baseline Methods</h3>
<p>Random Sampling For each test sentence, we randomly select in-context examples from the training set. We refer to this method as Random in the experimental results. On the test set, the random baseline is repeated for five times to obtain the average score and corresponding standard deviation.
$k$-Nearest Neighbor Additionally, to investigate whether the retrieval module is complementary to GPT-3's in-context learning ability, we further consider a $k$-nearest neighbor baseline. Specifically, the target $y_{1}$ associated with the first retrieved example is considered as the predicted target for the test sample. For the sentiment analysis and QA tasks, the top $k$ retrieved examples $\left{y_{1}, \ldots, y_{k}\right}$ are utilized, where the final prediction is determined by majority voting among the $k$ examples' targets. If there is a tie case, we use the target of the example most similar to the test sentence. To ensure fair comparison, we compare the baseline $k \mathrm{NN}$ and KATE under the same embedding space of a pre-trained RoBERTa-large model. This baseline is abbreviated as $k \mathrm{NN}_{\text {roberta }}$.
Fine-tuned T5 Although this work aims at improving the in-context learning abilities of GPT-3, we include a fine-tuned T5 (3B) model as a baseline. This comparison informs us where GPT-3 performs comparably or surpasses a fine-tuned model.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Method</th>
<th style="text-align: center;">Accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">T5 (fine-tuned)</td>
<td style="text-align: center;">95.2</td>
</tr>
<tr>
<td style="text-align: center;">Ours</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Random</td>
<td style="text-align: center;">$87.95 \pm 2.74$</td>
</tr>
<tr>
<td style="text-align: center;">$k \mathrm{NN}_{\text {roberta }}$</td>
<td style="text-align: center;">50.20</td>
</tr>
<tr>
<td style="text-align: center;">KATE roberta</td>
<td style="text-align: center;">91.99</td>
</tr>
<tr>
<td style="text-align: center;">KATE nli</td>
<td style="text-align: center;">90.40</td>
</tr>
<tr>
<td style="text-align: center;">KATE nli+sts-b</td>
<td style="text-align: center;">90.20</td>
</tr>
<tr>
<td style="text-align: center;">KATE ${ }_{\text {sst-2 }}$</td>
<td style="text-align: center;">$\mathbf{9 3 . 4 3}$</td>
</tr>
</tbody>
</table>
<p>Table 3: Results on the IMDB dataset. In-context examples are from the SST-2 dataset.</p>
<h2>4 Experimental Results</h2>
<h3>4.1 Sentiment Analysis</h3>
<p>We first evaluate KATE on the sentiment analysis task. The results are in Table 3. KATE consistently produces better performance relative to the random selection baseline. Notably, there is no variance with the obtained results since the fixed retrieved in-context examples are employed. For KATE, when the pre-trained sentence encoder is fine-tuned on NLI or NLI+STS-B datasets, the performance slightly decreases. Since the objectives of the IMDB and the NLI+STS-B datasets are different, this shows that fine-tuning on a dissimilar task hurts KATE's performance. In contrast, KATE $<em _roberta="{roberta" _text="\text">{\text {sst-2 }}$ obtains the best accuracy, showing that fine-tuning on a similar task improves KATE's performance. To verify that the gains are not merely from the retrieval step, we further compare $\mathrm{KATE}</em>}}$ with the $k \mathrm{NN<em _roberta="{roberta" _text="\text">{\text {roberta }}$. It turns out that the performance of $k \mathrm{NN}</em>}}$ is close to random guessing. This observation is consistent when one neighbor or three neighbors are retrieved. Notably, with the sentence encoder fine-tuned on the SST-2 dataset, the accuracy of $k \mathrm{NN<em _sst-2="{sst-2" _text="\text">{\text {sst-2 }}$ is 92.46 , which is lower than that of $\mathrm{KATE}</em>$. These results suggest that GPT-3 is critical to the final results, and the retrieval module is complementary to GPT-3.}</p>
<p>The fine-tuned T5 model works better since its parameters has been adapted to this specific task. However, fine-tuning requires access to model parameters, lots of memory storage, and time. The fine-tuning result here is just for reference. Through KATE, the performance of GPT-3 has increased significantly without fine-tuning.</p>
<h3>4.2 Table-to-text Generation</h3>
<p>We next evaluate KATE on the ToTTo dataset and present results in Table 4. KATE gives rise to considerable gains over the random baseline, according to both the BLEU and PARENT scores. Notably,</p>
<p>KATE enables GPT-3 to achieve performance comparable to a fine-tuned T5 model. On a finer scale, the evaluation can be done on the overlap subset and the nonoverlap subset. The overlap dev subset shares a significant number of header names with the training set, while the nonoverlap one does not. KATE improves results on both subsets, meaning that the retrieval module is helpful even when the dev set is out of distribution of the training set. Similar to sentiment analysis, there is a slight drop in performance from $\mathrm{KATE}<em _nli="{nli" _text="\text">{\text {roberta }}$ to $\mathrm{KATE}</em>}}$ and $\mathrm{KATE<em _nli="{nli" _text="\text">{\text {nli+sts-b }}$. This is due to the difference between the objectives of the ToTTo dataset and NLI+STSB datasets. The drop from $\mathrm{KATE}</em>$ baseline, it performs much worse than the random selection method and KATE, suggesting that the retrieval process and GPT-3 work collaboratively to achieve better results.}}$ to $\mathrm{KATE}_{\text {nli+sts-b }}$ further validates the idea that fine-tuning on a dissimilar task can hurt KATE's performance. For the $k \mathrm{NN</p>
<p>To understand how the retrieval mechanism helps GPT-3, we conduct a case study on the retrieved examples (see Table 5). By retrieving relevant examples from the training set, KATE provides useful detailed information within the table, e.g., the number of points, rebounds, and assists, to GPT-3 for more accurate description. On the other hand, the random selection method has the issue of hallucination, where the generated sequences contain information (i.e., "senior year" and "University of Texas") not present in the table.</p>
<h3>4.3 Questing Answering</h3>
<p>Lastly, we evaluate KATE on the open-domain QA tasks, as shown in Table 6. We compare with some state-of-the-art fine-tuned methods such as RAG (Lewis et al., 2020) and T5 (Raffel et al., 2019). The T5 results were reported in (Brown et al., 2020) using the 11B model, which needs specialized TPUs to do fine-tuning. KATE again improves GPT-3's performance substantially across various benchmarks. Moreover, KATE helps GPT3 to even outperform the fine-tuned T5 model. It is worth noting that this time both $\mathrm{KATE}<em _nli_sts-b="{nli+sts-b" _text="\text">{\text {nli }}$ and $\mathrm{KATE}</em>}}$ improve upon $\mathrm{KATE<em _roberta="{roberta" _text="\text">{\text {roberta }}$ because fine-tuning on NLI or STS-B datasets is helpful for retrieving semantically similar questions from the QA datasets. Moreover, on the NQ and TriviaQA datasets, further fine-tuning on the STS-B dataset improves KATE's results. We evaluate the baseline $k \mathrm{NN}</em>$ baseline results again suggest that}}$ by using the top-1 nearest neighbor. The $k \mathrm{NN</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Method</th>
<th style="text-align: center;">Overall</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Overlap Subset</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Nonoverlap Subset</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">BLEU</td>
<td style="text-align: center;">PARENT</td>
<td style="text-align: center;">BLEU</td>
<td style="text-align: center;">PARENT</td>
<td style="text-align: center;">BLEU</td>
<td style="text-align: center;">PARENT</td>
</tr>
<tr>
<td style="text-align: center;">T5 (fine-tuned)</td>
<td style="text-align: center;">41.2</td>
<td style="text-align: center;">53.0</td>
<td style="text-align: center;">46.7</td>
<td style="text-align: center;">56.1</td>
<td style="text-align: center;">35.8</td>
<td style="text-align: center;">50.0</td>
</tr>
<tr>
<td style="text-align: center;">Ours</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Random</td>
<td style="text-align: center;">$28.4 \pm 2.1$</td>
<td style="text-align: center;">$39.3 \pm 2.6$</td>
<td style="text-align: center;">$31.2 \pm 2.5$</td>
<td style="text-align: center;">$41.8 \pm 3.0$</td>
<td style="text-align: center;">$25.6 \pm 1.8$</td>
<td style="text-align: center;">$37.0 \pm 2.3$</td>
</tr>
<tr>
<td style="text-align: center;">$k \mathrm{NN}_{\text {roberta }}$</td>
<td style="text-align: center;">14.1</td>
<td style="text-align: center;">12.6</td>
<td style="text-align: center;">20.1</td>
<td style="text-align: center;">17.9</td>
<td style="text-align: center;">8.0</td>
<td style="text-align: center;">7.52</td>
</tr>
<tr>
<td style="text-align: center;">$\mathrm{KATE}_{\text {roberta }}$</td>
<td style="text-align: center;">41.0</td>
<td style="text-align: center;">50.6</td>
<td style="text-align: center;">48.4</td>
<td style="text-align: center;">55.9</td>
<td style="text-align: center;">33.6</td>
<td style="text-align: center;">45.5</td>
</tr>
<tr>
<td style="text-align: center;">$\mathrm{KATE}_{\text {nli }}$</td>
<td style="text-align: center;">39.9</td>
<td style="text-align: center;">49.5</td>
<td style="text-align: center;">47.4</td>
<td style="text-align: center;">54.6</td>
<td style="text-align: center;">32.5</td>
<td style="text-align: center;">44.5</td>
</tr>
<tr>
<td style="text-align: center;">$\mathrm{KATE}_{\text {nli+sts-b }}$</td>
<td style="text-align: center;">38.8</td>
<td style="text-align: center;">48.2</td>
<td style="text-align: center;">46.2</td>
<td style="text-align: center;">53.1</td>
<td style="text-align: center;">31.5</td>
<td style="text-align: center;">43.4</td>
</tr>
</tbody>
</table>
<p>Table 4: Table-to-text generation results on the ToTTo dev dataset.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Test Table</th>
<th style="text-align: left;">Table: <page_title $>$ Trey Johnson <section_title $>$ College <table $>&lt;$ cell $&gt;32&lt;$ col_header $&gt;$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">GP <cell $>4.8$ <col_header $>$ RPG $&lt;$ cell $&gt;2.3$ <col_header $>$ APG $&lt;$ cell $&gt;23.5$ <col_header $>$ PPG</td>
</tr>
<tr>
<td style="text-align: left;">Retrieved</td>
<td style="text-align: left;">Table: <page_title $>$ Dedric Lawson <section_title $>$ College <table $>&lt;$ cell $&gt;9.9$ <col_header $>$</td>
</tr>
<tr>
<td style="text-align: left;">Examples</td>
<td style="text-align: left;">RPG $&lt;$ cell $&gt;3.3$ <col_header $>$ APG $&lt;$ cell $&gt;19.2$ <col_header $>$ PPG</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Sentence: Dedric Lawson averaged 19.2 points, 9.9 rebounds and 3.3 assists per game.</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Table: <page_title $>$ Carsen Edwards <section_title $>$ College <table $>&lt;$ cell $&gt;3.8$ <col_header $>$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">RPG $&lt;$ cell $&gt;2.8$ <col_header $>$ APG $&lt;$ cell $&gt;18.5$ <col_header $>$ PPG</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Sentence: Edwards averaged 18.5 points, 3.8 rebounds and 2.8 assists per game.</td>
</tr>
<tr>
<td style="text-align: left;">Predictions</td>
<td style="text-align: left;">Ground-truth: Trey Johnson averaged 23.5 points, 4.8 rebounds, and 2.3 assists in 32 games.</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Random: Trey Johnson averaged 23.5 points per game in his senior year at the University of Texas.</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">KATE: Johnson averaged 23.5 points, 4.8 rebounds and 2.3 assists per game.</td>
</tr>
</tbody>
</table>
<p>Table 5: A sample of retrieved in-context examples from the ToTTo dataset. For the KATE method, GPT-3 pays more attention to detailed information such as the number of points, rebounds, and assists. In contrast, the random selection method leads GPT-3 to generate details which do not exist in the original table.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Method</th>
<th style="text-align: center;">NQ</th>
<th style="text-align: center;">WQ</th>
<th style="text-align: center;">TriviaQA</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">RAG (Open-Domain)</td>
<td style="text-align: center;">44.5</td>
<td style="text-align: center;">45.5</td>
<td style="text-align: center;">68.0</td>
</tr>
<tr>
<td style="text-align: center;">T5+SSM (Closed-Book)</td>
<td style="text-align: center;">36.6</td>
<td style="text-align: center;">44.7</td>
<td style="text-align: center;">60.5</td>
</tr>
<tr>
<td style="text-align: center;">T5 (Closed-Book)</td>
<td style="text-align: center;">34.5</td>
<td style="text-align: center;">37.4</td>
<td style="text-align: center;">50.1</td>
</tr>
<tr>
<td style="text-align: center;">GPT-3 (64 examples)</td>
<td style="text-align: center;">29.9</td>
<td style="text-align: center;">41.5</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">Ours</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Random</td>
<td style="text-align: center;">$28.6 \pm 0.3$</td>
<td style="text-align: center;">$41.0 \pm 0.5$</td>
<td style="text-align: center;">$59.2 \pm 0.4$</td>
</tr>
<tr>
<td style="text-align: center;">$k \mathrm{NN}_{\text {roberta }}$</td>
<td style="text-align: center;">24.0</td>
<td style="text-align: center;">23.9</td>
<td style="text-align: center;">26.2</td>
</tr>
<tr>
<td style="text-align: center;">$\mathrm{KATE}_{\text {roberta }}$</td>
<td style="text-align: center;">40.0</td>
<td style="text-align: center;">47.7</td>
<td style="text-align: center;">57.5</td>
</tr>
<tr>
<td style="text-align: center;">$\mathrm{KATE}_{\text {nli }}$</td>
<td style="text-align: center;">40.8</td>
<td style="text-align: center;">50.6</td>
<td style="text-align: center;">60.9</td>
</tr>
<tr>
<td style="text-align: center;">$\mathrm{KATE}_{\text {nli+sts-b }}$</td>
<td style="text-align: center;">41.6</td>
<td style="text-align: center;">50.2</td>
<td style="text-align: center;">62.4</td>
</tr>
</tbody>
</table>
<p>Table 6: Results on QA datasets. (*) We used 10 examples for TriviaQA and 64 examples for NQ and WQ.
the retrieval module and GPT-3 work together to achieve better performance. We also explore using 64 nearest neighbors ( 10 for TriviaQA) to determine the answer (by majority voting explained in Section 3.2). The EM score are similar to retrieving the top-1 nearest neighbor.</p>
<p>To investigate why the retrieved examples are helpful, we present a case study. Concretely, the retrieval examples from the NQ dataset are shown in Table 7. For the first and second cases, the random baseline provides wrong answers because GPT-3 is unable to recall the exact detail. However, the in-context examples selected by KATE contain the correct details, which facilitate GPT-3 to answer questions. For the third case, the random baseline
leads GPT-3 to misinterpret the question as asking for a specific location. In contrast, KATE selects similar types of questions asking for the origins of objects. Using these in-context examples, GPT-3 is able to interpret and answer the question correctly.</p>
<h2>5 Analysis of Different Factors</h2>
<h3>5.1 Number of In-context Examples</h3>
<p>We first investigate the impact of the number of examples on KATE's performance. Concretely, on the NQ dataset, we choose the number of examples to be $5,10,20,35$, and 64 , and $\mathrm{KATE}<em _roberta="{roberta" _text="\text">{\text {nli+sts-b }}$ is compared with the random baseline and $\mathrm{KATE}</em>$ across different settings. As shown in the left plot of Figure 2, both KATE and the random baseline benefit from utilizing more examples. However, KATE consistently outperforms the random selection method, even when the number of in-context examples is as few as 5 . This result is interesting because in practice, employing less examples leads to more efficient inference with GPT-3.}</p>
<h3>5.2 Size of Training Set for Retrieval</h3>
<p>We further examine how the size of the training set may influence the KATE method. On the NQ dataset, we create new subsets from the original training set, with sizes of $1 \mathrm{k}, 2 \mathrm{k}, 5 \mathrm{k}, 10 \mathrm{k}, 30 \mathrm{k}$, and</p>
<table>
<thead>
<tr>
<th style="text-align: center;">In-Context Examples</th>
<th style="text-align: center;">Predictions</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Question: The Mughal Gardens of Rashtrapati Bhavan is modelled on which garden?</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">The Mughal Garden of Rashtrapati Bhavan is modelled on? The Persian style of architecture</td>
<td style="text-align: center;">Ground-truth: Persian garden</td>
</tr>
<tr>
<td style="text-align: center;">Who built the first Mughal Garden in India? Babur</td>
<td style="text-align: center;">KATE: The Persian gardens</td>
</tr>
<tr>
<td style="text-align: center;">The landscape design of the Gardens of Versailles is known as which style? French garden</td>
<td style="text-align: center;">Random Baseline: Shalimar gardens</td>
</tr>
<tr>
<td style="text-align: center;">Question: What city was Zeus the patron god of?</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">What is the symbol of Zeus the Greek God? Bull</td>
<td style="text-align: center;">Ground-truth: Olympia</td>
</tr>
<tr>
<td style="text-align: center;">Where did Zeus spend most of his time? Mount Olympus</td>
<td style="text-align: center;">KATE: Olympia</td>
</tr>
<tr>
<td style="text-align: center;">Where was the statue of Zeus at Olympia located? In the Temple of Zeus</td>
<td style="text-align: center;">Random Baseline Athens</td>
</tr>
<tr>
<td style="text-align: center;">Question: Where did the Dewey decimal system come from?</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Where did the formula for area of a circle come from? Archimedes</td>
<td style="text-align: center;">Ground-truth: Melvil Dewey</td>
</tr>
<tr>
<td style="text-align: center;">Where did the name jack russell come from? Reverend John Russell</td>
<td style="text-align: center;">KATE: Melvil Dewey</td>
</tr>
<tr>
<td style="text-align: center;">Where did the letters of the alphabet come from? The Phoenician alphabet</td>
<td style="text-align: center;">Random Baseline: the library of Congress</td>
</tr>
</tbody>
</table>
<p>Table 7: Three samples of retrieved in-context examples from the NQ dataset. Three retrieved Q-A pairs are shown on the left. Predictions by the KATE method and useful details from in-context examples are shown in Green. Gold-standard references are shown in Blue. Predictions by the random baseline are shown in Red.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Left: Effect of number of in-context examples for different selection methods. Right: Effect of the size of training set for retrieval on KATE. Two representative sentence encoders are used in these studies.</p>
<p>70k, respectively. In-context examples are retrieved from these subsets instead of the original training set. The number of nearest neighbors is set to 64 . We compare $\mathrm{KATE}<em _roberta="{roberta" _text="\text">{\text {nli+sts-b }}$ with the random selection method and $\mathrm{KATE}</em>}}$, and the results are shown in the right plot of Figure 2. For $\mathrm{KATE<em _nli_sts-b="{nli+sts-b" _text="\text">{\text {roberta }}$ and $\mathrm{KATE}</em>$, as the size of the training set increases, the EM scores also increase. In contrast, the result of the random sampling baseline does not change much. Intuitively, as the training size gets larger, it is more likely for KATE to retrieve relevant in-context examples to help GPT-3 answer a question correctly. As we have shown previously in Table 7, the retrieved in-context examples could provide critical detailed information to GPT-3, thus helping GPT-3 to better answer the questions.}</p>
<h3>5.3 Order of In-context Examples</h3>
<p>Moreover, we explore how the order of in-context examples may affect KATE's results. As mentioned in Section 2.3, under the standard setting, the retrieved in-context examples are ordered such that $s\left(x_{i}, x\right) \geq s\left(x_{j}, x\right)$ whenever $i&lt;j$. Here, we ran-</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Trial</th>
<th style="text-align: center;">1</th>
<th style="text-align: center;">2</th>
<th style="text-align: center;">3</th>
<th style="text-align: center;">Default</th>
<th style="text-align: center;">Reverse</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">EM Score</td>
<td style="text-align: center;">42.0</td>
<td style="text-align: center;">42.5</td>
<td style="text-align: center;">42.0</td>
<td style="text-align: center;">41.6</td>
<td style="text-align: center;">42.8</td>
</tr>
</tbody>
</table>
<p>Table 8: Analysis on the effect of orders of in-context example on the NQ dataset using $\mathrm{KATE}<em _nli_sts-b="{nli+sts-b" _text="\text">{\text {nli+sts-b }}$. The default order puts the most similar example in the front, and the reverse order does the opposite.
domly permute the order of in-context examples in the NQ dataset for the proposed $\mathrm{KATE}</em>, x\right)$ whenever $i&lt;j$. The results are presented in Table 8. On this particular NQ dataset, the reverse order performs the best. However, we also did the experiments on the WQ and TriviaQA and find that the default order performs slightly better than the reverse order. Hence,}}$ method, and conduct the experiments for 3 different orders. Additionally, we explore the reverse order where $s\left(x_{i}, x\right) \leq s\left(x_{j</p>
<p>the choice of orders is data-dependent. Additionally, it can be observed that the variation among the NQ results tends to be quite small (compared with the difference between the random baseline and KATE), indicating that the example order does not have a significant impact on KATE's performance.</p>
<h2>6 Related Work</h2>
<p>Pre-trained Language Models NLP systems have made tremendous progress by pre-training models on unlabeled text (Devlin et al., 2018; Liu et al., 2019; Yang et al., 2019; Lewis et al., 2019; Raffel et al., 2019; Xue et al., 2020; Lample and Conneau, 2019; Radford et al., 2018, 2019). These models can be fine-tuned for a wide range of downstream tasks. GPT-3 (Brown et al., 2020), however, can perform in-context learning without fine-tuning. People have just started trying to understand GPT3 from different perspectives. (Hendrycks et al., 2020) studies which categories of questions GPT-3 is more capable of answering. (Zhao et al., 2021) proposes to improve the model by contextual calibration. However, their method is limited to predicting very few tokens because for long sequence generation, the contextual calibration step needs to be repeatedly performed after each newly generated token. In contrast, our work, KATE, only calls the API once and is suitable for both text classification and generation tasks. Another related work is LM-BFF (Gao et al., 2020), which uses a smaller language model (RoBERTa-large) to demonstrate that prompt-based fine-tuning can outperform standard fine-tuning on text classification tasks. Our work differs by showing that, without fine-tuning, relevant examples can still substantially improve the performance of GPT-3 for both text classification and generation tasks. Finally, AutoPrompt (Shin et al., 2020) explores adding some additional tokens to smaller language models to improve performance on classification tasks.</p>
<p>Retrieval-based Text Generation There is a long history of applying information retrieval to text generation (Sumita and Hitoshi, 1991). It is very related to the exemplar-based learning (Jäkel et al., 2008; Ziyadi et al., 2020). Some representative applications in the field of deep learning include machine translation (Gu et al., 2018), sentiment transfer (Li et al., 2018; Guu et al., 2018), QA (Karpukhin et al., 2020; Mao et al., 2020), dialogue generation (Yan et al., 2016; Cai et al., 2018; Song et al., 2016; Pandey et al., 2018; We-
ston et al., 2018; Wu et al., 2019), text summarization (Cao et al., 2017; Peng et al., 2019), data-to-text generation (Peng et al., 2019), and text-tocode generation (Hashimoto et al., 2018). All these retrieve-and-edit frameworks require their editors to be trained or fine-tuned on specific tasks. In contrast, our work uniquely examines how to better use GPT-3 as a universal editor without fine-tuning. We find that the more semantically similar context we provide to GPT-3, the better results the model can generate.</p>
<p>Improve NLP Systems with $k$ NN Some recent works try to incorporate non-parametric methods to improve a given model's performance. For example, the newly introduced $k$ NN-LM (Khandelwal et al., 2019), $k$ NN-MT (Khandelwal et al., 2020), and BERT- $k$ NN (Kassner and Schütze, 2020) generate the next token by retrieving the nearest $k$ neighbors from the datastore. Another related work $k$ NN classification model (Rajani et al., 2020) uses $k \mathrm{NN}$ as backoff when the confidence is low from the classification model. There are two key differences between our work and other approaches. First, we retrieve the nearest $k$ neighbors to modify the conditional context instead of the prediction. Second, we do not have access to the parameters of GPT-3. Instead, we rely on some independently pre-trained models to get the sentence embeddings to retrieve the nearest $k$ neighbors.</p>
<h2>7 Conclusion</h2>
<p>This work presented a first step towards investigating the sensitivity of GPT-3 to in-context examples. To this end, we proposed KATE, a non-parametric selection approach that retrieves in-context examples according to their semantic similarity to the test samples. On several natural language understanding and generation tasks, the proposed method improves GPT-3's performance, over the random sampling baseline, by a significant margin. Particularly, KATE enables GPT-3 to achieve performance comparable to a fine-tuned T5 model on the table-to-text generation task and outperforms T5 on the QA task. Moreover, we found that fine-tuning the sentence embeddings for retrieval on task-related datasets gave rise to further empirical gains. Detailed analysis was conducted to explore the robustness of KATE to different hyperprameters, such as the number of in-context examples, examples' order, etc. One limitation we notice is that despite the improved performance on sentiment analysis,</p>
<p>GPT-3 still lags behind the fine-tuned T5 model by a small margin. This suggests that our proposed method is more suitable and effective on long text generation tasks. We hope this work could provide insights for better understanding the behaviors of GPT-3 and represents a helpful step towards further improving its in-context learning capabilities.</p>
<h2>8 Ethical and Broader Impacts</h2>
<p>Risk Our proposed KATE method significantly improves the in-context learning ability of GPT-3 and makes long-text generation more easily without fine-tuning the pre-trained model. However, one risk implication is that our proposed method will benefit the research groups which are financially capable of using such huge models. For individual or small-group researchers, they cannot apply our proposed method to their specific applications since they don't have access to the model. Our work has suggested researchers should focus more on investigating the in-context learning of pretrained models. One potential future direction is for researchers to scale-down the sizes of pre-trained models to find a balance between model performance and model size. Once a smaller model is obtained with comparable performance (enhanced by KATE), our proposed method can become more widely accessible to individual researchers.</p>
<p>Potential Bias During the experiment on table-to-text generation, we have pointed out that large pre-trained language models could be susceptible to hallucination (case study in Table 5). This problem is more pronounced when we use randomly sampled examples. This happens because the language model is biased toward the training dataset. As shown in Table 5, when random examples are used, the sentence generated by GPT-3 is grammatically correct, but some details never exist in the given table. In contrast, our proposed method, KATE, can significantly alleviate this problem by guiding GPT-3 to look for and generate the correct information. For similar reasons, large pretrained models could be potentially susceptible to gender and racial bias. Since our KATE method shows that in-context examples are crucial for highquality long-text generations, one way to alleviate the racial and gender bias is to incorporate an additional module to filter out offensive in-context examples. Since racial and gender bias are not our main research focus, a full investigation goes beyond the scope of our work. However, we believe
this is an exciting opportunity for future work.</p>
<h2>Code Availability</h2>
<p>Implementations of the proposed KATE method discussed in this paper are available at https: //github.com/jiachangliu/KATEGPT3.</p>
<h2>References</h2>
<p>Jonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang. 2013. Semantic parsing on freebase from question-answer pairs. In Proceedings of the 2013 conference on empirical methods in natural language processing, pages 1533-1544.</p>
<p>Samuel R Bowman, Gabor Angeli, Christopher Potts, and Christopher D Manning. 2015. A large annotated corpus for learning natural language inference. arXiv preprint arXiv:1508.05326.</p>
<p>Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. arXiv preprint arXiv:2005.14165.</p>
<p>Deng Cai, Yan Wang, Wei Bi, Zhaopeng Tu, Xiaojiang Liu, Wai Lam, and Shuming Shi. 2018. Skeleton-to-response: Dialogue generation guided by retrieval memory. arXiv preprint arXiv:1809.05296.</p>
<p>Ziqiang Cao, Furu Wei, Wenjie Li, and Sujian Li. 2017. Faithful to the original: Fact aware neural abstractive summarization. arXiv preprint arXiv:1711.04434.</p>
<p>Daniel Cer, Mona Diab, Eneko Agirre, Inigo LopezGazpio, and Lucia Specia. 2017. Semeval-2017 task 1: Semantic textual similarity-multilingual and cross-lingual focused evaluation. arXiv preprint arXiv:1708.00055.</p>
<p>Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.</p>
<p>Bhuwan Dhingra, Manaal Faruqui, Ankur Parikh, MingWei Chang, Dipanjan Das, and William W Cohen. 2019. Handling divergent reference texts when evaluating table-to-text generation. arXiv preprint arXiv:1906.01081.</p>
<p>Tianyu Gao, Adam Fisch, and Danqi Chen. 2020. Making pre-trained language models better few-shot learners. arXiv preprint arXiv:2012.15723.</p>
<p>Jiatao Gu, Yong Wang, Kyunghyun Cho, and Victor OK Li. 2018. Search engine guided neural machine translation. In AAAI, pages 5133-5140.</p>
<p>Kelvin Guu, Tatsunori B Hashimoto, Yonatan Oren, and Percy Liang. 2018. Generating sentences by editing prototypes. Transactions of the Association for Computational Linguistics, 6:437-450.</p>
<p>Tatsunori B Hashimoto, Kelvin Guu, Yonatan Oren, and Percy S Liang. 2018. A retrieve-and-edit framework for predicting structured outputs. In Advances in Neural Information Processing Systems, pages $10052-10062$.</p>
<p>Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2020. Measuring massive multitask language understanding. arXiv preprint arXiv:2009.03300.</p>
<p>Frank Jäkel, Bernhard Schölkopf, and Felix A Wichmann. 2008. Generalization and similarity in exemplar models of categorization: Insights from machine learning. Psychonomic Bulletin \&amp; Review, 15(2):256271.</p>
<p>Mandar Joshi, Eunsol Choi, Daniel S Weld, and Luke Zettlemoyer. 2017. Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension. arXiv preprint arXiv:1705.03551.</p>
<p>Vladimir Karpukhin, Barlas Oğuz, Sewon Min, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020. Dense passage retrieval for open-domain question answering. arXiv preprint arXiv:2004.04906.</p>
<p>Nora Kassner and Hinrich Schütze. 2020. Bertknn: Adding a knn search component to pretrained language models for better qa. arXiv preprint arXiv:2005.00766.</p>
<p>Urvashi Khandelwal, Angela Fan, Dan Jurafsky, Luke Zettlemoyer, and Mike Lewis. 2020. Nearest neighbor machine translation. arXiv preprint arXiv:2010.00710.</p>
<p>Urvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke Zettlemoyer, and Mike Lewis. 2019. Generalization through memorization: Nearest neighbor language models. arXiv preprint arXiv:1911.00172.</p>
<p>Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, et al. 2019. Natural questions: a benchmark for question answering research. Transactions of the Association for Computational Linguistics, 7:453466.</p>
<p>Guillaume Lample and Alexis Conneau. 2019. Crosslingual language model pretraining. arXiv preprint arXiv:1901.07291.</p>
<p>Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, and Luke Zettlemoyer. 2019. Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. arXiv preprint arXiv:1910.13461.</p>
<p>Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al. 2020. Retrieval-augmented generation for knowledge-intensive nlp tasks. arXiv preprint arXiv:2005.11401.</p>
<p>Juncen Li, Robin Jia, He He, and Percy Liang. 2018. Delete, retrieve, generate: A simple approach to sentiment and style transfer. arXiv preprint arXiv:1804.06437.</p>
<p>Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692.</p>
<p>Andrew Maas, Raymond E Daly, Peter T Pham, Dan Huang, Andrew Y Ng, and Christopher Potts. 2011. Learning word vectors for sentiment analysis. In Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies, pages 142-150.</p>
<p>Yuning Mao, Pengcheng He, Xiaodong Liu, Yelong Shen, Jianfeng Gao, Jiawei Han, and Weizhu Chen. 2020. Generation-augmented retrieval for open-domain question answering. arXiv preprint arXiv:2009.08553.</p>
<p>Gaurav Pandey, Danish Contractor, Vineet Kumar, and Sachindra Joshi. 2018. Exemplar encoder-decoder for neural conversation generation. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1329-1338.</p>
<p>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting of the Association for Computational Linguistics, pages 311-318.</p>
<p>Ankur P Parikh, Xuezhi Wang, Sebastian Gehrmann, Manaal Faruqui, Bhuwan Dhingra, Diyi Yang, and Dipanjan Das. 2020. ToTTo: A controlled table-totext generation dataset. In Proceedings of EMNLP.</p>
<p>Hao Peng, Ankur P Parikh, Manaal Faruqui, Bhuwan Dhingra, and Dipanjan Das. 2019. Text generation with exemplar-based adaptive decoding. arXiv preprint arXiv:1904.04428.</p>
<p>Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. 2018. Improving language understanding by generative pre-training.</p>
<p>Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9.</p>
<p>Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2019. Exploring the limits of transfer learning with a unified text-to-text transformer. arXiv preprint arXiv:1910.10683.</p>
<p>Nazneen Fatema Rajani, Ben Krause, Wengpeng Yin, Tong Niu, Richard Socher, and Caiming Xiong. 2020. Explaining and improving model behavior with k nearest neighbor representations. arXiv preprint arXiv:2010.09030.</p>
<p>Nils Reimers and Iryna Gurevych. 2019. Sentence-bert: Sentence embeddings using siamese bert-networks. arXiv preprint arXiv:1908.10084.</p>
<p>Nils Reimers and Iryna Gurevych. 2020. Making monolingual sentence embeddings multilingual using knowledge distillation. arXiv preprint arXiv:2004.09813.</p>
<p>Taylor Shin, Yasaman Razeghi, Robert L Logan IV, Eric Wallace, and Sameer Singh. 2020. Autoprompt: Eliciting knowledge from language models with automatically generated prompts. arXiv preprint arXiv:2010.15980.</p>
<p>Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D Manning, Andrew Y Ng, and Christopher Potts. 2013. Recursive deep models for semantic compositionality over a sentiment treebank. In Proceedings of the 2013 conference on empirical methods in natural language processing, pages $1631-1642$.</p>
<p>Yiping Song, Rui Yan, Xiang Li, Dongyan Zhao, and Ming Zhang. 2016. Two are better than one: An ensemble of retrieval-and generation-based dialog systems. arXiv preprint arXiv:1610.07149.</p>
<p>Eiichiro Sumita and HDA Hitoshi. 1991. Experiments and prospects of example-based machine translation. In 29th Annual Meeting of the Association for Computational Linguistics, pages 185-192.</p>
<p>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. Advances in neural information processing systems, 30:5998-6008.</p>
<p>Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R Bowman. 2018. Glue: A multi-task benchmark and analysis platform for natural language understanding. arXiv preprint arXiv:1804.07461.</p>
<p>Jason Weston, Emily Dinan, and Alexander H Miller. 2018. Retrieve and refine: Improved sequence generation models for dialogue. arXiv preprint arXiv:1808.04776.</p>
<p>Adina Williams, Nikita Nangia, and Samuel R Bowman. 2017. A broad-coverage challenge corpus for sentence understanding through inference. arXiv preprint arXiv:1704.05426.</p>
<p>Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, et al. 2019. Huggingface's transformers: State-of-the-art natural language processing. arXiv preprint arXiv:1910.03771.</p>
<p>Yu Wu, Furu Wei, Shaohan Huang, Yunli Wang, Zhoujun Li, and Ming Zhou. 2019. Response generation by context-aware prototype editing. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 7281-7288.</p>
<p>Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, and Colin Raffel. 2020. mt5: A massively multilingual pre-trained text-to-text transformer. arXiv preprint arXiv:2010.11934.</p>
<p>Rui Yan, Yiping Song, and Hua Wu. 2016. Learning to respond with deep neural networks for retrieval-based human-computer conversation system. In Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval, pages 55-64.</p>
<p>Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ R Salakhutdinov, and Quoc V Le. 2019. Xlnet: Generalized autoregressive pretraining for language understanding. In Advances in neural information processing systems, pages 5753-5763.</p>
<p>Tony Z Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021. Calibrate before use: Improving few-shot performance of language models. arXiv preprint arXiv:2102.09690.</p>
<p>Morteza Ziyadi, Yuting Sun, Abhishek Goswami, Jade Huang, and Weizhu Chen. 2020. Examplebased named entity recognition. arXiv preprint arXiv:2008.10570.</p>
<h2>A An Example of In-context Learning</h2>
<p>As shown in the illustration of Figure 3, GPT-3 is asked to translate "mountain" to its German version based on the three examples given as part of the input.
<img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: The figure above shows how to perform in-context learning with a language model. Three incontext examples and the test prompt are concatenated as a single string input for GPT-3, with a special character "in" inserted between two adjacent examples. GPT-3 keeps generating tokens until there is a special character "in".</p>
<h2>B Data Split</h2>
<table>
<thead>
<tr>
<th style="text-align: center;">Dataset</th>
<th style="text-align: center;">Train</th>
<th style="text-align: center;">Dev</th>
<th style="text-align: center;">Test</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">SST-2</td>
<td style="text-align: center;">67 k</td>
<td style="text-align: center;">872</td>
<td style="text-align: center;">1.8 k</td>
</tr>
<tr>
<td style="text-align: center;">IMDB</td>
<td style="text-align: center;">25 k</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">25 k</td>
</tr>
<tr>
<td style="text-align: center;">ToTTo</td>
<td style="text-align: center;">120 k</td>
<td style="text-align: center;">7.7 k</td>
<td style="text-align: center;">7.7 k</td>
</tr>
<tr>
<td style="text-align: center;">NQ</td>
<td style="text-align: center;">79 k</td>
<td style="text-align: center;">8.8 k</td>
<td style="text-align: center;">3.6 k</td>
</tr>
<tr>
<td style="text-align: center;">WQ</td>
<td style="text-align: center;">3.4 k</td>
<td style="text-align: center;">361</td>
<td style="text-align: center;">2 k</td>
</tr>
<tr>
<td style="text-align: center;">TriviaQA</td>
<td style="text-align: center;">78.8 k</td>
<td style="text-align: center;">8.8 k</td>
<td style="text-align: center;">11.3 k</td>
</tr>
</tbody>
</table>
<p>Table 9: Data split for different datasets. In-context examples are selected from the training set. Because ToTTo and TriviaQA require submitting to their leaderboards, the evaluation is done on the dev sets. For all other datasets, the evaluation is done on the test sets.</p>
<h2>C Complete ToTTo Case Study</h2>
<p>Due to the length limit of the main paper, we present in the appendix the full ToTTo case study comparing the random sampling baseline and our proposed KATE method. We present the case study in Table 10.</p>
<p>As we have discussed in the main paper, the in-context examples retrieved by KATE facilitates GPT-3 to effectively extract key information from the given table. Detailed numbers such as the number of points, rebounds, and assists have all been included in the sentence.</p>
<p>In contrast, the sentence generated by GPT-3 using randomly sampled in-context examples only
extract partial information from the table. Only the number of points is included while the numbers of rebounds and assists are ignored. Moreover, the random sampling baseline could lead to the issue of hallucination. Both "senior year" and "University of Texas" are not present in the given table. One may wonder whether these wrong phrases were present in the randomly sampled in-context examples, which might have caused this issue. However, if we look at the randomly sampled in-context examples in the second block of the table, such information do not exist. This suggests such hallucinated phrases are generated by the language model itself.</p>
<p>This comparison provides some key insights on why KATE works better than the random sampling baseline. By retrieving semantically/syntactically similar in-context examples, KATE provides GPT3 with a much more accurate template/structure to do text generation. Without such structure, GPT-3 can generate sentences that are fluent but do not meet the goal of a particular task.</p>
<h2>D On Prompt Engineering vs. Fine-tuning</h2>
<p>As we mentioned in the main paper, given a training dataset, we could take the full advantage of the GPT-3's model strength through fine-tuning. However, there are several advantages of prompt engineering over fine-tuning. First, fine-tuning requires access to the model parameters and gradients. It is impossible to access this information via the current GPT-3's API. Second, fine-tuning large models are time-consuming and costly. Ordinary research labs and individual developers do not have resources to accomplish such tasks. Third, storing large fine-tuned model checkpoints requires large storage space. Even if GPT-3 is fine-tuned and stored for many specific tasks/datasets, many finetuned checkpoints may not be frequently called. This is not energy efficient. Our proposed KATE method does not require costly fine-tuning and improves the random baseline on both text classification and generation tasks, sometimes by a significant margin. This makes it more practical to deploy the same GPT-3 model across all tasks.</p>
<h2>E T5 Baseline</h2>
<p>Although our primary goal is to improve GPT-3's in-context learning ability, we also include the finetuned T5 results as a reference (3B T5 on SST-2 and</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Test Table</th>
<th style="text-align: center;">Table: <page_title $>$ Trey Johnson <section_title $>$ College <table $>&lt;$ cell $&gt;32&lt;$ col_header $&gt;$ <br> GP <cell $>4.8&lt;$ col_header $&gt;$ RPG $&lt;$ cell $&gt;2.3&lt;$ col_header $&gt;$ APG $&lt;$ cell $&gt;23.5&lt;$ col_header $&gt;$ PPG</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Randomly Sampled Examples</td>
<td style="text-align: center;">Table: <page_title $>$ List of RAGBRAI overnight stops <section_title $>$ By year <table $>&lt;$ cell $&gt;$ 1986 <col_header $>&lt;$ col_header $&gt;$ Year <cell $>$ Audubon (1) <col_header $>$ Route - start to finish (number indicates occurrence) <col_header $>$ Monday <cell $>2006$ <col_header $>&lt;$ col_header $&gt;$ Year <cell $>$ Audubon (2) <col_header $>$ Route - start to finish (number indicates occurrence) <br> <col_header $>$ Monday <br> Sentence: Audubon has been an RAGBRAI overnight stop in 1986 and 2006. <br> Table: <page_title $>$ List of Administrators of British Brunei <section_title $>$ British Brunei <br> administrators <table $>&lt;$ cell $&gt;$ Malcolm Stewart Hannibal McArthur <col_header $>$ Consul <br> Generals to Brunei <col_header $>$ British Consuls in Brunei <col_header $>$ British Residents in Brunei <br> Sentence: Malcolm Stewart Hannibal McArthur was the first British resident in Brunei.</td>
</tr>
<tr>
<td style="text-align: center;">KATE- <br> Retrieved <br> Examples</td>
<td style="text-align: center;">Table: <page_title $>$ Dedric Lawson <section_title $>$ College <table $>&lt;$ cell $&gt;9.9&lt;$ col_header $&gt;$ <br> RPG $&lt;$ cell $&gt;3.3&lt;$ col_header $&gt;$ APG $&lt;$ cell $&gt;19.2&lt;$ col_header $&gt;$ PPG <br> Sentence: Dedric Lawson averaged 19.2 points, 9.9 rebounds and 3.3 assists per game. <br> Table: <page_title $>$ Carsen Edwards <section_title $>$ College <table $>&lt;$ cell $&gt;3.8&lt;$ col_header $&gt;$ <br> RPG $&lt;$ cell $&gt;2.8&lt;$ col_header $&gt;$ APG $&lt;$ cell $&gt;18.5&lt;$ col_header $&gt;$ PPG <br> Sentence: Edwards averaged 18.5 points, 3.8 rebounds and 2.8 assists per game.</td>
</tr>
<tr>
<td style="text-align: center;">Predictions</td>
<td style="text-align: center;">Ground-truth: Trey Johnson averaged 23.5 points, 4.8 rebounds, and 2.3 assists in 32 games. <br> Random: Trey Johnson averaged 23.5 points per game in his senior year at the University of Texas. <br> KATE: Johnson averaged 23.5 points, 4.8 rebounds and 2.3 assists per game.</td>
</tr>
</tbody>
</table>
<p>Table 10: A sample of retrieved in-context examples from the ToTTo dataset. For the KATE method, GPT-3 pays more attention to detailed information such as the number of points, rebounds, and assists. In contrast, the random selection method leads GPT-3 to generate details which do not exist in the original table. Information such as "senior year" and "University of Texas" also do not exist in the randomly sampled in-context examples. This suggests that the wrong information was generated by the language model itself. Although the sentence by the random sampling baseline is fluent, it does meet the goal of the table-to-text task.</p>
<p>ToTTo datasets, and 11B T5 on the QA datasets). The reason for reporting the 3B T5 results on the SST-2 and ToTTo datasets is that this is the largest T5 model we can use. For the 3B T5 model, Google Colab ${ }^{3}$ provides a free V2-8 TPU to fine-tune the 3B model. We used the Colab tutorial notebook to fine-tune the 3B T5 model on the SST-2 and ToTTo training sets. We couldn't fine-tune the 11B T5 model because the model size is too large. Finetuning such a large model requires a V3-8 TPU, which is not free of charge. Fortunately, the original GPT-3 paper (Brown et al., 2020) has already reported the finet-tuned 11B T5 results on the three QA datasets, so we reuse these results in our main paper for the QA task. Our proposed KATE method significantly improves GPT-3, performing comparably to the fine-tuned T5 model on the table-to-text task and outperforming the fine-tuned T5 model on the QA task.</p>
<h2>F Details on Retrieval Modules</h2>
<p>As we mention in the main paper, we use the pretrained RoBERTa-large model (Liu et al., 2019)</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup>as the first retrieval module, which has 355M parameters and is pre-trained with the MLM (masked language modeling) objective. The result given by this module is denoted as $\mathrm{KATE}_{\text {roberta }}$. We directly download this model from the HuggingFace Model Zoo (MIT license) ${ }^{4}$. All other retrieval modules share the same architecture as the RoBERTa-large module but are fine-tuned on specific datasets.</p>
<p>For the fine-tuned retrieval modules, the first we use is the RoBERTa-large model fine-tuned on the SNLI and MultiNLI datasets ( $\mathrm{KATE}<em _mathrm_nli="\mathrm{nli">{\mathrm{nli}}$ ) (Bowman et al., 2015; Williams et al., 2017); the next we use is the RoBERTa-large model fine-tuned on the SNLI and MultiNLI dataset and then on the STS-B datasets $\left(\mathrm{KATE}</em>$.}+\mathrm{sts}-\mathrm{b}}\right)$ (Cer et al., 2017). These fine-tuned models have already been accomplished and included by the Sentence-BERT family and are publicly available, so we directly download from the Sentence-BERT Model Zoo ${ }^{5</p>
<p>Lastly, specifically for the sentiment analysis task, we include a RoBERTa-large model finetuned on the SST-2 dataset ( $\mathrm{KATE}_{\text {sst-2 }}$ ) (Socher et al., 2013; Wang et al., 2018). At the time of our</p>
<p><sup id="fnref:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<p>research, we didn't find a good publicly available fine-tuned model, so we fine-tune the pre-trained RoBERTa-large model on SST-2 by ourselves. The exact fine-tuning procedure, including the hyperparameters and learning rate, can be found at the HuggingFace website ${ }^{6}$. We fine-tune the RoBERTalarge model using a single V100 GPU.</p>
<h1>G Prompt Templates Used</h1>
<p>For reproducibility, we show the prompt templates used for all tasks in Tables 11 .</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<table>
<thead>
<tr>
<th style="text-align: left;">Task</th>
<th style="text-align: left;">Prompt Template</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">SST-2 \&amp; IMDB</td>
<td style="text-align: left;">Sentence: comes from the brave, uninhibited performances. Label: Positive <br> Sentence: This tearful movie about a sister and her battle to save as many souls as she can is very <br> moving. The film does well in picking up the characters and showing how Sister Helen deals with <br> each. A wonderful journey from life to death. Label:</td>
</tr>
<tr>
<td style="text-align: left;">ToTTo</td>
<td style="text-align: left;">Table: <page_title>Dedric Lawson <section_title>College <table><cell>9.9 <col_header>RPG <br> <cell>3.3 <col_header>APG <cell>19.2 <col_header>PPG <br> Sentence: Dedric Lawson averaged 19.2 points, 9.9 rebounds and 3.3 assists per game. <br> Table: <page_title>Trey Johnson <section_title>College <table><cell>32 <col_header>GP <br> <cell>4.8 <col_header>RPG <cell>2.3 <col_header>APG <cell>23.5 <col_header>PPG <br> Sentence:</td>
</tr>
<tr>
<td style="text-align: left;">QA</td>
<td style="text-align: left;">Q: The landscape design of the Gardens of Versailles is known as which style? <br> A: The Persian style of architecture. <br> Q: The Mughal Gardens of Rashtrapati Bhavan is modelled on which garden? <br> A:</td>
</tr>
</tbody>
</table>
<p>Table 11: The prompt templates used for all tasks discussed in the paper. We show only one in-context example per task for illustration purposes.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{6}$ The fine-tuning script we use can be found at https://huggingface.co/transformers/ v2.7.0/examples.html#glue.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:1">
<p>${ }^{4}$ The HuggingFace Model Zoo can be found at https: //huggingface.co/models.
${ }^{5}$ The Sentence-BERT Model Zoo can be found at https: //huggingface.co/sentence-transformers.&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>