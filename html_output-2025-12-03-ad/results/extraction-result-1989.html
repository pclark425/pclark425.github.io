<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1989 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1989</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1989</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-46.html">extraction-schema-46</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <p><strong>Paper ID:</strong> paper-282139042</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2510.14150v1.pdf" target="_blank">CodeEvolve: An open source evolutionary coding agent for algorithm discovery and optimization</a></p>
                <p><strong>Paper Abstract:</strong> In this work, we introduce CodeEvolve, an open-source evolutionary coding agent that unites Large Language Models (LLMs) with genetic algorithms to solve complex computational problems. Our framework adapts powerful evolutionary concepts to the LLM domain, building upon recent methods for generalized scientific discovery. CodeEvolve employs an island-based genetic algorithm to maintain population diversity and increase throughput, introduces a novel inspiration-based crossover mechanism that leverages the LLMs context window to combine features from successful solutions, and implements meta-prompting strategies for dynamic exploration of the solution space. We conduct a rigorous evaluation of CodeEvolve on a subset of the mathematical benchmarks used to evaluate Google DeepMind's closed-source AlphaEvolve. Our findings show that our method surpasses AlphaEvolve's performance on several challenging problems. To foster collaboration and accelerate progress, we release our complete framework as an open-source repository.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1989.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1989.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CODEEVOLVE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>CODEEVOLVE (this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source evolutionary coding agent that integrates a weighted LLM ensemble with an island-based genetic algorithm, introducing meta-prompting for exploration and an inspiration-based crossover that provides semantic context to LLMs instead of direct code splicing.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>CODEEVOLVE</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>hybrid (LLM-based operators + genetic algorithm)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Uses an LLM ensemble (GEMINI 2.5 FLASH and PRO models) as the generative/modification operator inside an island genetic algorithm. Operators include Depth Exploitation (LLM refines a selected high-ranking parent using ancestor chain), Meta-Prompting Exploration (an auxiliary LLM rewrites/enriches prompts before solution generation), and Inspiration-based Crossover (LLM is given several high-performing 'inspiration' solutions as semantic context to synthesize new solutions). Generation is instructed in a diff-based SEARCH/REPLACE format to encourage targeted edits.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Automated algorithm discovery on mathematical benchmarks from AlphaEvolve (P1: second autocorrelation inequality; P2.A/B: minimizing ratio of max/min distance; P3.A/B: circle packing in unit square; P4: circle packing in rectangle).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>AlphaEvolve (reported results), ablation baselines within CODEEVOLVE: mp+insp (full), mp (meta-prompting only), insp (inspiration only), no mp or insp (baseline evolutionary), no evolution (repeated prompting of trivial solution).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td>CODEEVOLVE (full system) outperforms the reported AlphaEvolve results on five of six benchmark instances; identical up to 6 decimal places on the remaining benchmark with a small improvement on the 7th decimal (qualitative summary; no single unified numeric metric reported across all benchmarks).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td>Classical GP is discussed as foundational but not empirically benchmarked in this paper; within ablations, the 'no mp or insp' evolutionary baseline (uses LLM ensemble but without meta-prompting or inspiration crossover) performs worse than mp+insp configuration on most problems — quantitative values per-epoch are shown in figures but specific numeric tables are not reported in text.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td>The full hybrid (mp+insp) shows the best convergence behavior on most benchmarks (fastest convergence and best final fitness for P2 and P3), while hybridization can be detrimental on specific tasks (e.g., P1 where mp alone outperforms mp+insp).</td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td>Diversity is encouraged via island GA, migration, meta-prompting, and inspiration selection; no explicit numeric diversity/novelty metric is reported.</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td>Not explicitly measured; paper notes that operator effectiveness is problem-dependent (e.g., meta-prompting works best for P1 while inspiration helps geometry problems), implying variable generalization across problem types.</td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td>No direct evidence about LLM training bias is reported; authors note closed-box LLM nondeterminism and potential reproducibility limits but do not quantify training-distribution biases.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td>CODEEVOLVE uses an ensemble weighting strategy (FLASH sampled 80% of calls, PRO 20%) to trade off throughput and breakthrough potential; authors state that using only the more powerful (PRO) model is 'prohibitive in terms of costs' but provide no numeric cost or time-per-inference comparisons. Experiments were run on 8 vCPU SageMaker instances with strict sandbox limits.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td>Ablation across mp+insp, mp, insp, no mp or insp, and no evolution: mp+insp converges fastest and best on many geometric packing problems (P3.A/B and P2), while mp alone is best for P1; insp alone often underperforms and can be detrimental on some tasks (P1). The ablation demonstrates strong synergy between meta-prompting and inspiration for complex packing problems, and problem-dependent operator utility.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td>Yes — prompt adaptation via the MetaPromptingLLM (it generates enriched prompts from parent prompt+solution) and the use of ancestor contexts and inspirations provide dynamic, online prompt/conditioning changes during evolution; ablations indicate prompt adaptation improves performance on several tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Direct code splicing can break syntax/semantics (motivating inspiration-based semantic crossover). Inspiration-based crossover can promote premature convergence or be detrimental (observed in P1). Stochastic LLM outputs and lack of fixed seeds in the GEMINI API limit exact reproducibility. No explicit failure rate (e.g., percentage of runtime errors) is reported, but failing solutions are given zero fitness.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>Learned LLM-based operators integrated into an evolutionary framework can outperform prior LLM-driven systems (AlphaEvolve) on many algorithm-discovery benchmarks; however, operator utility is problem-dependent — meta-prompting (broader exploration) excels on certain analytic tasks while inspiration-based semantic crossover (feature mixing) is crucial for geometric/packing problems. Ensemble weighting is an effective practical trade-off for computational cost, and prompt-adaptation (online modification of prompts) is a key mechanism by which learned operators adapt during evolution. The study highlights that learned operators provide semantically meaningful modifications that classical GP struggles to capture, but they also bring reproducibility, cost, and problem-specific robustness concerns.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1989.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1989.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AlphaEvolve</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AlphaEvolve (Google DeepMind)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A closed-source LLM-driven evolutionary system reported by DeepMind that generalizes LLM-guided program search from single mathematical functions to entire codebases and a broad range of algorithmic optimization tasks; used in this paper as the primary state-of-the-art baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>AlphaEvolve: A coding agent for scientific and algorithmic discovery</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AlphaEvolve</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>hybrid (LLM-guided evolution; closed-source implementation details not provided)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Described as combining LLMs with evolutionary algorithms to evolve code and algorithms at scale; specific operator mechanisms and training details are not disclosed in the whitepaper referenced by this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Same AlphaEvolve benchmark suite used in this paper (mathematical/algorithmic problems such as P1–P4 and others in Novikov et al. Appendix B).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>CODEEVOLVE compares its results to AlphaEvolve's reported best solutions on the same benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td>AlphaEvolve reported state-of-the-art results that CODEEVOLVE matches or surpasses on five of six benchmark instances; for P4 CODEEVOLVE matched up to sixth decimal and slightly improved the seventh decimal (qualitative comparison based on reported values).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td>AlphaEvolve is closed-source; CODEEVOLVE notes AlphaEvolve's computational resource usage in background but does not provide direct cost comparisons in numeric form.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>AlphaEvolve serves as the prior SOTA for LLM-driven evolutionary algorithm discovery; CODEEVOLVE's open-source, modular implementation demonstrates comparable or superior performance, indicating that LLM-guided evolution is reproducible in principle but closed-box LLMs and missing implementation details in AlphaEvolve impede community progress and reproducibility.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1989.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1989.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Classical GP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Classical Genetic Programming (Koza et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Traditional genetic programming methods that evolve populations of tree-structured programs using operators such as subtree crossover and mutation, noted for difficulties handling semantic complexity in modern programming languages.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Classical Genetic Programming</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>traditional GP (subtree crossover, mutation, fitness-based selection)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Evolutionary operators in GP include syntactic crossover (subtree exchanges), point/subtree mutations, and selection schemes; these operators operate directly on program syntactic representations and can break semantics when applied to modern, complex code.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>General program synthesis and symbolic program evolution; not benchmarked empirically in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Discussed conceptually as the historical baseline; CODEEVOLVE contrasts semantic, LLM-based modifications with syntax-level GP operators.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td>Paper qualitatively notes that classical GP struggles with semantic complexity and that direct syntactic crossover often breaks code, motivating inspiration-based semantic crossover mediated by LLM context.</td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Syntactic crossover/mutation can easily break syntax or semantics of modern code; scalability/semantic awareness limited compared to LLM-based operators.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>Classical GP provides the conceptual foundation for evolutionary search, but LLM-based operators that manipulate semantics via natural-language-conditioned generation can navigate modern program semantics more effectively; however, LLM-driven methods introduce new costs and reproducibility challenges.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1989.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1989.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FunSearch</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>FunSearch (Romera-Paredes et al., 2023)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An earlier demonstration of pairing an LLM with a programmatic evaluator to discover novel mathematical function solutions, establishing viability of LLM-guided program search for scientific discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Mathematical discoveries from program search with large language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>FunSearch (LLM + programmatic evaluator)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>LLM-based operator (paired with evaluator)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Used an LLM to generate mathematical program candidates which were evaluated and iteratively refined by an external evaluator; demonstrated that LLMs can be effective semantic operators in program search.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>Mathematical conjectures and function discovery (Nature 2023 experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Referenced as prior work motivating LLM-driven evolution; not directly compared empirically to classical GP in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>FunSearch established that LLMs can serve as semantically-aware program editors/generators in a search loop, motivating later systems (AlphaEvolve, CODEEVOLVE) to scale the idea to richer algorithmic code and to integrate more structured evolutionary mechanisms.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1989.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1989.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>OpenEvolve</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>OpenEvolve (Sharma, 2025)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source implementation of core LLM-driven evolutionary features intended to make LLM-evolution research accessible; cited as confirming the viability of LLM-driven evolution for broader research.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Openevolve: an open-source evolutionary coding agent</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>OpenEvolve</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>LLM-based evolutionary agent (open-source)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Provides accessible implementations of LLM-driven evolutionary features; specific operator internals are not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>General LLM-driven code evolution; not benchmarked in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>OpenEvolve is mentioned to show community interest and to provide an accessible baseline implementation, but the paper does not provide empirical comparisons between OpenEvolve and classical GP or other learned operators.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1989.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1989.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that compare learned operators (LLM-based, neural, or data-driven) with traditional genetic programming operators, including performance comparisons, training data effects, generalization, computational costs, and hybrid approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ShinkaEvolve</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ShinkaEvolve (Lange et al., 2025)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A recent open research project introducing refinements for sample efficiency in LLM-driven evolution using bandit-based LLM ensembles and novelty-based rejection filtering.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Shinkaevolve: Towards open-ended and sample-efficient program evolution</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>ShinkaEvolve</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>LLM-based with sample-efficiency mechanisms (bandit ensemble + novelty filtering)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Employs a bandit-based LLM ensemble to allocate calls adaptively and uses novelty-based rejection filtering to encourage effective exploration and sample efficiency; specific architectural or training details are not provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_or_benchmark</strong></td>
                            <td>LLM-driven program evolution and search; not directly evaluated in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_traditional_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_hybrid_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validity_or_executability_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_diversity_metric</strong></td>
                            <td>Novelty-based rejection filtering is described as used in ShinkaEvolve to increase exploration; no numeric metrics are reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>out_of_distribution_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_bias_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_comparison</strong></td>
                            <td>ShinkaEvolve is cited for sample-efficiency improvements; no numeric cost comparisons present in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_vs_general_pretraining</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_space_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>adaptation_during_evolution</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_for_theory</strong></td>
                            <td>ShinkaEvolve illustrates that ensemble scheduling and novelty filtering are promising directions to reduce LLM call budgets and improve exploration, aligning with CODEEVOLVE's ensemble-weighting and meta-prompting design choices.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>AlphaEvolve: A coding agent for scientific and algorithmic discovery <em>(Rating: 2)</em></li>
                <li>Mathematical discoveries from program search with large language models <em>(Rating: 2)</em></li>
                <li>Evolving code with a large language model <em>(Rating: 2)</em></li>
                <li>Shinkaevolve: Towards open-ended and sample-efficient program evolution <em>(Rating: 2)</em></li>
                <li>Openevolve: an open-source evolutionary coding agent <em>(Rating: 2)</em></li>
                <li>Evolution through large models <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1989",
    "paper_id": "paper-282139042",
    "extraction_schema_id": "extraction-schema-46",
    "extracted_data": [
        {
            "name_short": "CODEEVOLVE",
            "name_full": "CODEEVOLVE (this paper)",
            "brief_description": "An open-source evolutionary coding agent that integrates a weighted LLM ensemble with an island-based genetic algorithm, introducing meta-prompting for exploration and an inspiration-based crossover that provides semantic context to LLMs instead of direct code splicing.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "CODEEVOLVE",
            "operator_type": "hybrid (LLM-based operators + genetic algorithm)",
            "operator_description": "Uses an LLM ensemble (GEMINI 2.5 FLASH and PRO models) as the generative/modification operator inside an island genetic algorithm. Operators include Depth Exploitation (LLM refines a selected high-ranking parent using ancestor chain), Meta-Prompting Exploration (an auxiliary LLM rewrites/enriches prompts before solution generation), and Inspiration-based Crossover (LLM is given several high-performing 'inspiration' solutions as semantic context to synthesize new solutions). Generation is instructed in a diff-based SEARCH/REPLACE format to encourage targeted edits.",
            "training_data_description": null,
            "domain_or_benchmark": "Automated algorithm discovery on mathematical benchmarks from AlphaEvolve (P1: second autocorrelation inequality; P2.A/B: minimizing ratio of max/min distance; P3.A/B: circle packing in unit square; P4: circle packing in rectangle).",
            "comparison_baseline": "AlphaEvolve (reported results), ablation baselines within CODEEVOLVE: mp+insp (full), mp (meta-prompting only), insp (inspiration only), no mp or insp (baseline evolutionary), no evolution (repeated prompting of trivial solution).",
            "performance_learned_operator": "CODEEVOLVE (full system) outperforms the reported AlphaEvolve results on five of six benchmark instances; identical up to 6 decimal places on the remaining benchmark with a small improvement on the 7th decimal (qualitative summary; no single unified numeric metric reported across all benchmarks).",
            "performance_traditional_operator": "Classical GP is discussed as foundational but not empirically benchmarked in this paper; within ablations, the 'no mp or insp' evolutionary baseline (uses LLM ensemble but without meta-prompting or inspiration crossover) performs worse than mp+insp configuration on most problems — quantitative values per-epoch are shown in figures but specific numeric tables are not reported in text.",
            "performance_hybrid_operator": "The full hybrid (mp+insp) shows the best convergence behavior on most benchmarks (fastest convergence and best final fitness for P2 and P3), while hybridization can be detrimental on specific tasks (e.g., P1 where mp alone outperforms mp+insp).",
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": "Diversity is encouraged via island GA, migration, meta-prompting, and inspiration selection; no explicit numeric diversity/novelty metric is reported.",
            "out_of_distribution_performance": "Not explicitly measured; paper notes that operator effectiveness is problem-dependent (e.g., meta-prompting works best for P1 while inspiration helps geometry problems), implying variable generalization across problem types.",
            "training_bias_evidence": "No direct evidence about LLM training bias is reported; authors note closed-box LLM nondeterminism and potential reproducibility limits but do not quantify training-distribution biases.",
            "computational_cost_comparison": "CODEEVOLVE uses an ensemble weighting strategy (FLASH sampled 80% of calls, PRO 20%) to trade off throughput and breakthrough potential; authors state that using only the more powerful (PRO) model is 'prohibitive in terms of costs' but provide no numeric cost or time-per-inference comparisons. Experiments were run on 8 vCPU SageMaker instances with strict sandbox limits.",
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": null,
            "ablation_study_results": "Ablation across mp+insp, mp, insp, no mp or insp, and no evolution: mp+insp converges fastest and best on many geometric packing problems (P3.A/B and P2), while mp alone is best for P1; insp alone often underperforms and can be detrimental on some tasks (P1). The ablation demonstrates strong synergy between meta-prompting and inspiration for complex packing problems, and problem-dependent operator utility.",
            "hypothesis_space_characterization": null,
            "adaptation_during_evolution": "Yes — prompt adaptation via the MetaPromptingLLM (it generates enriched prompts from parent prompt+solution) and the use of ancestor contexts and inspirations provide dynamic, online prompt/conditioning changes during evolution; ablations indicate prompt adaptation improves performance on several tasks.",
            "failure_modes": "Direct code splicing can break syntax/semantics (motivating inspiration-based semantic crossover). Inspiration-based crossover can promote premature convergence or be detrimental (observed in P1). Stochastic LLM outputs and lack of fixed seeds in the GEMINI API limit exact reproducibility. No explicit failure rate (e.g., percentage of runtime errors) is reported, but failing solutions are given zero fitness.",
            "key_findings_for_theory": "Learned LLM-based operators integrated into an evolutionary framework can outperform prior LLM-driven systems (AlphaEvolve) on many algorithm-discovery benchmarks; however, operator utility is problem-dependent — meta-prompting (broader exploration) excels on certain analytic tasks while inspiration-based semantic crossover (feature mixing) is crucial for geometric/packing problems. Ensemble weighting is an effective practical trade-off for computational cost, and prompt-adaptation (online modification of prompts) is a key mechanism by which learned operators adapt during evolution. The study highlights that learned operators provide semantically meaningful modifications that classical GP struggles to capture, but they also bring reproducibility, cost, and problem-specific robustness concerns.",
            "uuid": "e1989.0"
        },
        {
            "name_short": "AlphaEvolve",
            "name_full": "AlphaEvolve (Google DeepMind)",
            "brief_description": "A closed-source LLM-driven evolutionary system reported by DeepMind that generalizes LLM-guided program search from single mathematical functions to entire codebases and a broad range of algorithmic optimization tasks; used in this paper as the primary state-of-the-art baseline.",
            "citation_title": "AlphaEvolve: A coding agent for scientific and algorithmic discovery",
            "mention_or_use": "use",
            "system_name": "AlphaEvolve",
            "operator_type": "hybrid (LLM-guided evolution; closed-source implementation details not provided)",
            "operator_description": "Described as combining LLMs with evolutionary algorithms to evolve code and algorithms at scale; specific operator mechanisms and training details are not disclosed in the whitepaper referenced by this paper.",
            "training_data_description": null,
            "domain_or_benchmark": "Same AlphaEvolve benchmark suite used in this paper (mathematical/algorithmic problems such as P1–P4 and others in Novikov et al. Appendix B).",
            "comparison_baseline": "CODEEVOLVE compares its results to AlphaEvolve's reported best solutions on the same benchmarks.",
            "performance_learned_operator": "AlphaEvolve reported state-of-the-art results that CODEEVOLVE matches or surpasses on five of six benchmark instances; for P4 CODEEVOLVE matched up to sixth decimal and slightly improved the seventh decimal (qualitative comparison based on reported values).",
            "performance_traditional_operator": null,
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": null,
            "out_of_distribution_performance": null,
            "training_bias_evidence": null,
            "computational_cost_comparison": "AlphaEvolve is closed-source; CODEEVOLVE notes AlphaEvolve's computational resource usage in background but does not provide direct cost comparisons in numeric form.",
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": null,
            "ablation_study_results": null,
            "hypothesis_space_characterization": null,
            "adaptation_during_evolution": null,
            "failure_modes": null,
            "key_findings_for_theory": "AlphaEvolve serves as the prior SOTA for LLM-driven evolutionary algorithm discovery; CODEEVOLVE's open-source, modular implementation demonstrates comparable or superior performance, indicating that LLM-guided evolution is reproducible in principle but closed-box LLMs and missing implementation details in AlphaEvolve impede community progress and reproducibility.",
            "uuid": "e1989.1"
        },
        {
            "name_short": "Classical GP",
            "name_full": "Classical Genetic Programming (Koza et al.)",
            "brief_description": "Traditional genetic programming methods that evolve populations of tree-structured programs using operators such as subtree crossover and mutation, noted for difficulties handling semantic complexity in modern programming languages.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Classical Genetic Programming",
            "operator_type": "traditional GP (subtree crossover, mutation, fitness-based selection)",
            "operator_description": "Evolutionary operators in GP include syntactic crossover (subtree exchanges), point/subtree mutations, and selection schemes; these operators operate directly on program syntactic representations and can break semantics when applied to modern, complex code.",
            "training_data_description": null,
            "domain_or_benchmark": "General program synthesis and symbolic program evolution; not benchmarked empirically in this paper.",
            "comparison_baseline": "Discussed conceptually as the historical baseline; CODEEVOLVE contrasts semantic, LLM-based modifications with syntax-level GP operators.",
            "performance_learned_operator": null,
            "performance_traditional_operator": null,
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": null,
            "out_of_distribution_performance": null,
            "training_bias_evidence": null,
            "computational_cost_comparison": null,
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": null,
            "ablation_study_results": null,
            "hypothesis_space_characterization": "Paper qualitatively notes that classical GP struggles with semantic complexity and that direct syntactic crossover often breaks code, motivating inspiration-based semantic crossover mediated by LLM context.",
            "adaptation_during_evolution": null,
            "failure_modes": "Syntactic crossover/mutation can easily break syntax or semantics of modern code; scalability/semantic awareness limited compared to LLM-based operators.",
            "key_findings_for_theory": "Classical GP provides the conceptual foundation for evolutionary search, but LLM-based operators that manipulate semantics via natural-language-conditioned generation can navigate modern program semantics more effectively; however, LLM-driven methods introduce new costs and reproducibility challenges.",
            "uuid": "e1989.2"
        },
        {
            "name_short": "FunSearch",
            "name_full": "FunSearch (Romera-Paredes et al., 2023)",
            "brief_description": "An earlier demonstration of pairing an LLM with a programmatic evaluator to discover novel mathematical function solutions, establishing viability of LLM-guided program search for scientific discovery.",
            "citation_title": "Mathematical discoveries from program search with large language models",
            "mention_or_use": "mention",
            "system_name": "FunSearch (LLM + programmatic evaluator)",
            "operator_type": "LLM-based operator (paired with evaluator)",
            "operator_description": "Used an LLM to generate mathematical program candidates which were evaluated and iteratively refined by an external evaluator; demonstrated that LLMs can be effective semantic operators in program search.",
            "training_data_description": null,
            "domain_or_benchmark": "Mathematical conjectures and function discovery (Nature 2023 experiments).",
            "comparison_baseline": "Referenced as prior work motivating LLM-driven evolution; not directly compared empirically to classical GP in this paper.",
            "performance_learned_operator": null,
            "performance_traditional_operator": null,
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": null,
            "out_of_distribution_performance": null,
            "training_bias_evidence": null,
            "computational_cost_comparison": null,
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": null,
            "ablation_study_results": null,
            "hypothesis_space_characterization": null,
            "adaptation_during_evolution": null,
            "failure_modes": null,
            "key_findings_for_theory": "FunSearch established that LLMs can serve as semantically-aware program editors/generators in a search loop, motivating later systems (AlphaEvolve, CODEEVOLVE) to scale the idea to richer algorithmic code and to integrate more structured evolutionary mechanisms.",
            "uuid": "e1989.3"
        },
        {
            "name_short": "OpenEvolve",
            "name_full": "OpenEvolve (Sharma, 2025)",
            "brief_description": "An open-source implementation of core LLM-driven evolutionary features intended to make LLM-evolution research accessible; cited as confirming the viability of LLM-driven evolution for broader research.",
            "citation_title": "Openevolve: an open-source evolutionary coding agent",
            "mention_or_use": "mention",
            "system_name": "OpenEvolve",
            "operator_type": "LLM-based evolutionary agent (open-source)",
            "operator_description": "Provides accessible implementations of LLM-driven evolutionary features; specific operator internals are not detailed in this paper.",
            "training_data_description": null,
            "domain_or_benchmark": "General LLM-driven code evolution; not benchmarked in this paper.",
            "comparison_baseline": null,
            "performance_learned_operator": null,
            "performance_traditional_operator": null,
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": null,
            "out_of_distribution_performance": null,
            "training_bias_evidence": null,
            "computational_cost_comparison": null,
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": null,
            "ablation_study_results": null,
            "hypothesis_space_characterization": null,
            "adaptation_during_evolution": null,
            "failure_modes": null,
            "key_findings_for_theory": "OpenEvolve is mentioned to show community interest and to provide an accessible baseline implementation, but the paper does not provide empirical comparisons between OpenEvolve and classical GP or other learned operators.",
            "uuid": "e1989.4"
        },
        {
            "name_short": "ShinkaEvolve",
            "name_full": "ShinkaEvolve (Lange et al., 2025)",
            "brief_description": "A recent open research project introducing refinements for sample efficiency in LLM-driven evolution using bandit-based LLM ensembles and novelty-based rejection filtering.",
            "citation_title": "Shinkaevolve: Towards open-ended and sample-efficient program evolution",
            "mention_or_use": "mention",
            "system_name": "ShinkaEvolve",
            "operator_type": "LLM-based with sample-efficiency mechanisms (bandit ensemble + novelty filtering)",
            "operator_description": "Employs a bandit-based LLM ensemble to allocate calls adaptively and uses novelty-based rejection filtering to encourage effective exploration and sample efficiency; specific architectural or training details are not provided in this paper.",
            "training_data_description": null,
            "domain_or_benchmark": "LLM-driven program evolution and search; not directly evaluated in this paper.",
            "comparison_baseline": null,
            "performance_learned_operator": null,
            "performance_traditional_operator": null,
            "performance_hybrid_operator": null,
            "validity_or_executability_rate": null,
            "novelty_or_diversity_metric": "Novelty-based rejection filtering is described as used in ShinkaEvolve to increase exploration; no numeric metrics are reported here.",
            "out_of_distribution_performance": null,
            "training_bias_evidence": null,
            "computational_cost_comparison": "ShinkaEvolve is cited for sample-efficiency improvements; no numeric cost comparisons present in this paper.",
            "transfer_learning_results": null,
            "domain_specific_vs_general_pretraining": null,
            "ablation_study_results": null,
            "hypothesis_space_characterization": null,
            "adaptation_during_evolution": null,
            "failure_modes": null,
            "key_findings_for_theory": "ShinkaEvolve illustrates that ensemble scheduling and novelty filtering are promising directions to reduce LLM call budgets and improve exploration, aligning with CODEEVOLVE's ensemble-weighting and meta-prompting design choices.",
            "uuid": "e1989.5"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "AlphaEvolve: A coding agent for scientific and algorithmic discovery",
            "rating": 2
        },
        {
            "paper_title": "Mathematical discoveries from program search with large language models",
            "rating": 2
        },
        {
            "paper_title": "Evolving code with a large language model",
            "rating": 2
        },
        {
            "paper_title": "Shinkaevolve: Towards open-ended and sample-efficient program evolution",
            "rating": 2
        },
        {
            "paper_title": "Openevolve: an open-source evolutionary coding agent",
            "rating": 2
        },
        {
            "paper_title": "Evolution through large models",
            "rating": 2
        }
    ],
    "cost": 0.0142715,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>CodeEvolve: An open source evolutionary coding agent for algorithm discovery and optimization
15 Oct 2025</p>
<p>Henrique Assumpção henrique.soares@inter.co 
Inter Science
Belo Horizonte
MGBrasil</p>
<p>Federal University of Minas Gerais
Belo Horizonte
MGBrasil</p>
<p>Diego Ferreira 
Inter Science
Belo Horizonte
MGBrasil</p>
<p>Federal University of Minas Gerais
Belo Horizonte
MGBrasil</p>
<p>Leandro Campos 
Inter Science
Belo Horizonte
MGBrasil</p>
<p>Federal University of Minas Gerais
Belo Horizonte
MGBrasil</p>
<p>Fabricio Murai 
Worcester Polytechnic Institute
WorcesterMAUSA</p>
<p>CodeEvolve: An open source evolutionary coding agent for algorithm discovery and optimization
15 Oct 20254795E3B2396A154951A501EA323F4112arXiv:2510.14150v1[cs.AI]
In this work, we introduce CODEEVOLVE, an open-source evolutionary coding agent that unites Large Language Models (LLMs) with genetic algorithms to solve complex computational problems.Our framework adapts powerful evolutionary concepts to the LLM domain, building upon recent methods for generalized scientific discovery.CODEEVOLVE employs an island-based genetic algorithm to maintain population diversity and increase throughput, introduces a novel inspiration-based crossover mechanism that leverages the LLMs context window to combine features from successful solutions, and implements meta-prompting strategies for dynamic exploration of the solution space.We conduct a rigorous evaluation of CODEEVOLVE on a subset of the mathematical benchmarks used to evaluate Google Deep-Mind's closed-source AlphaEvolve.Our findings show that our method surpasses AlphaEvolve's performance on several challenging problems.To foster collaboration and accelerate progress, we release our complete framework as an open-source repository 1 .</p>
<p>Introduction</p>
<p>The intersection of artificial intelligence (AI) and scientific discovery is entering a new era, marked by a paradigm shift from using AI as a tool for data analysis to using it as automated collaborative agents capable of generating, validating, and experimentally refining novel code solutions.At the forefront of this transformation are Large Language Models, which have demonstrated remarkable capabilities in the generation, understanding, and refinement of complex code (Chen et al., 2021).A framework that leverages the use of LLMs as code-optimization agents can tackle challenging algorithmic problems by exploring the solution space 1 https://github.com/inter-co/science-codeevolve in a way that closely resembles human creativity and iteration (Romera-Paredes et al., 2023).</p>
<p>Google DeepMind's AlphaEvolve (Novikov et al., 2025) has recently proven that combining LLMs with evolutionary algorithms can yield stateof-the-art solutions to many complex problems, from improving foundational matrix multiplication algorithms to optimizing large-scale data center infrastructure.AlphaEvolve, however, is described in a closed-source whitepaper that provides few technical implementation details.This opacity presents a significant barrier to progress and hinders collective innovation.</p>
<p>To address these challenges, we introduce CODEEVOLVE, an open-source evolutionary coding agent designed to incorporate the high-level principles of LLM-driven evolution into a concrete and reproducible framework.While inspired by the conceptual vision of AlphaEvolve, CODEEVOLVE proposes new approaches for its core components.Our method integrates an island-based genetic algorithm with a weighted LLM ensemble to iteratively evolve solutions.We design and implement several distinct modular mechanisms to drive this evolution: a depth exploitation operator for targeted refinement, an inspiration-based crossover mechanism to semantically combine features from successful solutions, and a meta-prompting exploration strategy that dynamically boosts the diversity of the prompt population.By incorporating continuous feedback from code execution and performance metrics, this system navigates the complex landscape of program synthesis to discover highperforming solutions.</p>
<p>We can summarize our contributions as follows:</p>
<p>• We propose a novel and transparent framework for automated algorithm discovery that combines both state-of-the-art LLMs and genetic algorithms.We further share both our source code and experimental results as an open-source repository.</p>
<p>• We perform an empirical evaluation of CODEEVOLVE on a suite of complex mathematical problems used to benchmark Google DeepMind's AlphaEvolve (Novikov et al., 2025), demonstrating that our method outperforms the latter on four distinct problems, yielding new state-of-the-art results.</p>
<p>• In order to understand the impact of the different components of CODEEVOLVE, we present an ablation that validates the contribution of our key architectural components to the overall quality of the solutions.</p>
<p>Related Work</p>
<p>Genetic programming and LLMs.Automated generation and optimization of computer programs has long been the domain of Genetic Programming (GP) (Koza, 1992(Koza, , 1994;;Langdon and Poli, 2013), where populations of programs are iteratively improved by operators such as crossoverwhere multiple programs are combined in order to generate a new one-, and mutation-where a program's content is altered according to some probabilistic process.Although foundational, classical GP methods often struggle with the semantic complexity of modern programming languages.</p>
<p>The recent advent of LLMs represents a paradigm shift.With their demonstrated success in generating high-quality solutions for competitive programming tasks (Li et al., 2022), LLMs have emerged as a powerful engine for program synthesis, capable of serving as sophisticated, semantically aware operators for code improvement.This synergy has given rise to a new class of techniques, formalized as "Evolution through Large Models" (Lehman et al., 2023;Hemberg et al., 2024).The breakthrough application of this concept was FunSearch (Romera-Paredes et al., 2023), which paired an LLM with a programmatic evaluator to discover novel solutions to open problems in mathematics, proving the viability of the approach for genuine scientific discovery.Building on this idea, Google DeepMind recently unveiled AlphaEvolve (Novikov et al., 2025), a closed-source model that generalizes the FunSearch framework from evolving single mathematical functions to entire codebases and a broader range of algorithmic optimization tasks.This system has been successfully in a wide range of different scenarios: from generating more efficient code for GPU kernels and optimizing the operations of warehouse-scale computers to strengthening results in complexity theory (Nagda et al., 2025).This broad applicability establishes LLM-guided evolution not as a niche technique but as a general-purpose engine for automated problem solving.</p>
<p>Evolutionary coding agents.Following the interest generated by AlphaEvolve, a few open source and independent research projects have focused on developing LLM-driven evolutionary agents.OpenEvolve (Sharma, 2025) provided an accessible implementation of the core features of LLM-driven evolution, confirming its viability for the wider research community.More recently, ShinkaEvolve (Lange et al., 2025) introduced refinements for sample efficiency, employing a bandit-based LLM ensemble and noveltybased rejection filtering to explore the solution space more effectively.CODEEVOLVE falls in this class of LLM-driven evolutionary models, and is designed to be broadly applicable to any algorithmic problem where one wishes to optimize one or more quantifiable metrics, while also aiming to foster collaborative and transparent research.</p>
<p>Meta-prompting.LLMs are notoriously sensitive to prompt variations (Anagnostidis and Bulian, 2024), and a considerable research effort has been directed towards creating systems to automatically design and improve prompts, known in the literature as "meta-prompting" (Suzgun and Kalai, 2024;Zhang et al., 2025).CODEEVOLVE builds upon evolutionary strategies for improving prompts (Fernando et al., 2023;Chen et al., 2023), mirroring the process being executed for the solutions to the underlying problem.By allowing the LLM to reflect on and rewrite its own instructions, it can unlock more diverse and effective evolutionary pathways.</p>
<p>Alternative algorithm discovery paradigms.LLM-driven evolution is part of a broader landscape of AI for scientific discovery, and many distinct approaches have seen major success in recent years.Deep Reinforcement Learning (RL), for instance, has achieved landmark results such as discovering faster matrix multiplication algorithms with AlphaTensor (Fawzi et al., 2022).While incredibly powerful, RL typically requires a more structured environment and a well-defined action space.Other approaches, such as agentic systems, leverage LLMs to reason over scientific hypothe-ses expressed in natural language (Gottweis et al., 2025).CODEEVOLVE attempts to find a balance between strictness of the former with the more highlevel approach of latter, by simultaneously using LLMs to reason about proposed solutions, while also employing a genetic algorithm for a rigorous exploration of the solution space.</p>
<p>Preliminaries</p>
<p>The task addressed here constitutes a meta-level optimization: we use an evolutionary algorithm to optimize programs, which themselves solve mathematical optimization problems.To clarify this distinction, this section formally defines the core concepts and notation used throughout the paper.</p>
<p>A solution is a program generated to solve a problem.When an existing solution S is used in a prompt to generate a new solution S ′ , we define S as the parent solution of S ′ .This parent-children relationship imposes a natural forest structure on the solution population, which is a collection of rooted, directed trees.For any solution S, we denote the set of its k nearest ancestors as A k (S).</p>
<p>A prompt is a textual input provided to a Large Language Model (LLM) to generate a solution.We denote the prompt used to generate solution S as its parent prompt, P (S).Since LLMs are inherently probabilistic, a single prompt can generate multiple distinct solutions.</p>
<p>The quality of a solution is quantified by an evaluation function, h : S → R d , which maps a solution S from the space of all possible solutions S to a real-valued vector of performance metrics, such as runtime, memory usage, or objective value.</p>
<p>We also define two fitness functions to measure the overall quality of prompts and solutions.The solution fitness, f sol : S → R ≥0 , maps a solution to a non-negative score and typically corresponds to the primary metric in h that we aim to optimize.The prompt fitness, f prompt , is derived from f sol and is defined as the maximum fitness achieved by any solution generated from that prompt:
f prompt (P ) = max S:P (S)=P {f sol (S)}.
(1)</p>
<p>This definition rewards prompts that have demonstrated the potential to generate high-quality solutions, making them valuable candidates for future evolution, even if some of their offspring may be suboptimal.</p>
<p>The primary optimization goal is to iteratively evolve an initial population of prompts and solu-tions, in order to maximize the solution fitness f sol over a maximum number of epochs N , while respecting constraints on other metrics from h, such as execution time and memory.</p>
<p>Methodology</p>
<p>Inspired by Google DeepMind's AlphaEvolve (Novikov et al., 2025), CODEEVOLVE integrates an evolutionary framework with Large Language Models (LLMs) to optimize programs.The architecture is based on the island genetic algorithm (Whitley and Starkweather, 1990).This model maintains multiple populations (islands), each evolving independently and periodically exchanging their best-performing individuals (migration).The migration step occurs according to a predefined graph (migration topology) whose nodes are islands and whose edges determine the migration paths.This approach enhances the amount of concurrent solutions being evaluated and the overall population diversity, while also allowing for successful solutions to propagate across the entire search effort, thus being a core component of our system.At each epoch t, every island i maintains a population of prompts P i t and solutions S i t .CODEEVOLVE operates through an iterative process designed to progressively enhance parallel populations of prompts/solutions.This process integrates three key components.The generation of new individuals is driven by a set of Evolutionary Operators (Section 4.2), which sample from the population to balance the exploration of novel strategies with the exploitation of promising ones.These operators leverage an LLM Ensemble for Solution Generation (Section 4.1) as the underlying engine for all code modifications.The entire evolutionary cycle is orchestrated by the Population Management module (Section 4.3), which handles solution evaluation, maintains population fitness, and manages the migration of topperforming individuals between islands.</p>
<p>LLM Ensemble for Solution Generation</p>
<p>We employ an ensemble of different state-of-the-art LLMs to generate and modify solutions, denoted by LLMEnsemble.Each model in the ensemble is assigned a weight, and for each generation task, a model is sampled according to these weights.Our experiments utilize an ensemble of Google's GEMINI 2.5 models (Comanici et al., 2025), with a higher sampling probability for the faster, more cost-effective model (FLASH) and a lower probability for the more powerful, but expensive (PRO).This strategy balances the high-throughput generation of FLASH with the capacity for significant breakthroughs of PRO (Novikov et al., 2025), while also being significantly cheaper, as only using the more expensive model is prohibitive in terms of costs.</p>
<p>Evolutionary Operators</p>
<p>New solutions are generated using a combination of exploitation and exploration strategies, which are executed in parallel across the islands.At each step, one of these two operators is chosen according to a hyperparameter p explr , which determines the probability of performing the exploration step.</p>
<ol>
<li>
<p>Depth exploitation.This operator aims to refine high-performing solutions.A parent solution S is selected from the current population S i t via rank-based selection, where the probability of selection is inversely proportional to its rank:
P (S) := rk(S) −1 S ′ ∈S i t rk(S ′ ) −1 ,(2)
where rk(S) is the position of S when sorting S i t by f sol in descending order.The LLM ensemble is then prompted with S, its parent prompt P (S), and its k closest ancestors, A k (S).Providing this truncated ancestral context encourages the LLM to perform targeted, incremental improvements rather than generating entirely new approaches as the depth of S in S i t increases.</p>
</li>
<li>
<p>Meta-prompting exploration.This operator is designed to foster solution diversity while also enriching the prompt population with feedback from previous solutions.A parent solution S is sampled uniformly from S i t .An auxiliary LLM denoted by MetaPromptingLLM generates a new, enriched prompt P ′ by analyzing the original parent prompt P (S) and the solution S itself.The LLMEnsemble then uses this new prompt P ′ and S to generate a new solution S ′ .Here, we intentionally exclude the ancestor chain to allow the model to explore novel strategies without being constrained by the solution's direct lineage, while also having access to a prompt P ′ with richer context.</p>
</li>
</ol>
<p>Inspiration-based Crossover.A key challenge in adapting evolutionary algorithms to LLMs is devising a meaningful crossover operator.Rather than directly splicing code, which often breaks syntax and semantics, we introduce an inspiration-based crossover mechanism.For both exploitation and exploration, we sample a set of high-performing "inspiration" solutions from the population using either the rank-based selection policy (if exploiting) or a random sample (if exploring).These complete solutions are provided as additional context to the LLMEnsemble.This encourages the LLM to synthesize new solutions that integrate successful patterns, logic, or functions from multiple parents, effectively performing a semantic crossover within the model's generative process.In order to prevent premature convergence, we only employ the inspiration-based crossover after the first wave of migrations occurs.</p>
<p>Algorithm 1 shows a pseudocode for the evolu-tionary operators.The LLMEnsemble (Section 4.1) receives as input a prompt, a set of ancestor solutions (which may be empty), the target solution itself and a set of inspirations, and it outputs a new solution.Similarly, the MetaPromptingLLM described in the exploration step receives as input a prompt and a solution, and outputs a new prompt.</p>
<p>Algorithm S ′ ← LLMEnsemble(P ′ , ∅, S, I) 13: end if 14: return S ′ , P ′ In practice, the process of generating new prompts/solutions mentioned above consists of instructing the LLM to modify the parent's code according to a diff-based SEARCH/REPLACE format, i.e., the LLM first searches for a specific section of code, and then replaces it with the proposed modifications.This ensures targeted and precise edits.</p>
<p>Population Management</p>
<p>CODEEVOLVE includes three mechanisms to manage the populations of solutions/prompts over time.</p>
<p>Initialization: The algorithm begins with a trivial initial solution (e.g., a function returning zero) and a basic prompt describing the problem.To create a diverse starting population at each island, the LLMEnsemble is prompted multiple times with this initial pair, generating a variety of independent approaches that become the roots of new solution trees.This initial diversification has proven crucial for discovering optimal solutions in our experiments.</p>
<p>Evaluation and Population Control: Each new solution is executed in a sandboxed environment with predefined runtime and memory limits.If a solution runs successfully, its fitness f sol (S) and other metrics h(S) are computed and it is added to the population.Solutions that fail or exceed resource limits are assigned a fitness of zero, and their execution logs are stored to provide instructive context for future LLM prompts.To maintain a maximum population size, a new individual is added only if its fitness is greater than that of the worst-performing individual currently in the population.The worst individual is then removed from the collection of live individuals.</p>
<p>Elitist Migration: The top-performing solutions from each island are copied and sent to all neighboring islands according to a predefined migration frequency.A migration rate dictates the proportion of solutions to be migrated.To prevent cycles and premature convergence, a solution is only permitted to migrate once from its island of origin.Upon arrival at a new island, a migrant solution is treated as a root of a new evolutionary tree, with its parent pointers set to NULL.</p>
<p>Experiments</p>
<p>In this section, we evaluate CODEEVOLVE on a set of mathematical problems from the benchmark suite used to validate AlphaEvolve (Novikov et al., 2025).Specifically, we are interested in answering the following questions:</p>
<ol>
<li>
<p>Can CODEEVOLVE advance the state of the art in automated algorithm discovery?</p>
</li>
<li>
<p>How do the different components of CODEE-VOLVE impact its performance on the proposed benchmarks?</p>
</li>
</ol>
<p>Benchmark Problems</p>
<p>We selected four benchmark problems that span different areas of mathematics and algorithm design.Problem P1 comes from real analysis, and problems P2, P3, and P4 are related to geometry.</p>
<p>P1: Second autocorrelation inequality.Let C be the smallest constant satisfying
∥f * f ∥ 2 2 ≤ C∥f * f ∥ 1 ∥f * f ∥ ∞ ,
for all nonnegative functions f : R → R, where ∥ • ∥ p denotes the p-norm of a given function, and f * f denotes the convolution operation.Hölder's inequality immediately yields C ≤ 1, and mathematicians have been trying to bound C from below by explicitly constructing step functions (Matolcsi and Vinuesa, 2009).We are thus interested in obtaining an algorithm to generate nonnegative step functions that maximizes the ratio between ∥f * f ∥ 2 2 and ∥f * f ∥ 1 ∥f * f ∥ ∞ (c.f.Novikov et al. (2025, Sec. B.2., Appendix B)).</p>
<p>P2: Minimizing the ratio of maximum to minimum distance.In this problem, we wish to find n d-dimensional points in order to minimize the ratio between their maximum to minimum distance.We consider two instances of this problem: n = 16, d = 2, and n = 14, d = 3, referred to as P2.A and P2.B, respectively (c.f.Novikov et al. (2025, Sec. B.8., Appendix B)).</p>
<p>P3: Packing circles inside a unit square to maximize sum of radii.In this problem, we wish to place n circles inside a unit square in order to maximize the sum of their radii.We consider two instances: n = 26 and n = 32, referred to as P3.A and P3.B, respectively (c.f.Novikov et al. (2025, Sec. B.12., Appendix B)).</p>
<p>P4: Packing circles inside a rectangle of perimeter 4 to maximize sum of radii.This problem is a relaxation of P3, where we still wish to place n circles in order to maximize the sum of their radii, but now we allow them to be placed in a rectangle of perimeter 4. We consider the case where n = 21 (c.f.Novikov et al. (2025, Sec. B.13., Appendix B)).</p>
<p>Experimental Setup</p>
<p>All experiments were conducted on the Amazon SageMaker platform for cloud-based computing, with each experimental run utilizing an environment with 8 vCPUs.To ensure fair and reproducible evaluations, we executed each candidate solution in a sandboxed environment with strict resource constraints.For the analysis problem (P1) and the distance minimization problems (P2), solutions were allocated a maximum of 5GB of memory and a runtime limit of 360 seconds.For the circle packing problems, experiments for P3 were allocated 1GB of memory and a 180-second runtime limit, while P4 was given 1GB of memory and a 360-second limit.</p>
<p>Our architecture employed 5 parallel islands for all experiments, each initialized with the same set of starting prompts and trivial solutions.For configurations utilizing the migration mechanism, the 10% top-performing solutions were exchanged be- tween islands every 40 epochs according to a ring topology, i.e., the underlying graph is the cycle graph C 5 on 5 nodes (islands).The evolutionary process was run for a different number of epochs depending on the problem's complexity: P1 and P3 ran for 100 epochs, P2 for 200 epochs, and P4 for 150 epochs.All experiments utilized a maximum population size of 40, initial population size of 6, p explr = 0.3.Experiments utilizing the inspirationbased crossover operator selected 3 inspirations from the solution population.All experiments also employed an unlimited maximum ancestor depth k, i.e., we allow all ancestor solutions of a given solution S to be collected in A k (S) (c.f.Algorithm 1).As mentioned in Section 4.1, we employ an ensemble of GEMINI 2.5 models.In our experiments, whenever the ensemble is called in CODEEVOLVE, there is an 80% probability of selecting FLASH, and 20% of selecting PRO.Both models are set with temperature parameters equal to 0.7, and top_p to 0.95.The meta-prompting LLM utilizes the same configuration for the FLASH model.Table 1 presents a direct comparison between the best results achieved by our CODEEVOLVE framework and the state-of-the-art solutions reported by Google DeepMind's AlphaEvolve.Our opensource agent not only matches the performance of its closed-source counterpart but surpasses it on five of the six benchmarks.Notably, CODEE-VOLVE discovered superior solutions for the second autocorrelation inequality (P1), for both instances of the distance minimization problem (P2.A and P2.B), and for both instances of the circle packing problem within a unit square (P3.A and P3.B).For the final problem of packing circles in a rectangle (P4), CODEEVOLVE achieved an objective value identical to AlphaEvolve's up to the sixth decimal place, with a minor improvement on the seventh.To provide a qualitative understanding of our results, we visualize the best-found solutions for the geometric problems.Figures 2 and 3 illustrate the optimal point placements discovered for minimizing the ratio of maximum to minimum distance.Similarly, Figures 4 and 5 display the discovered circle packing configurations within a unit square.The constructions for problems P1 and P4 are displayed in Figures 6 and 7, respectively.</p>
<p>Results</p>
<p>Ablations</p>
<p>In order to answer the second question posed in this section, we perform an ablation study of the many components of CODEEVOLVE.In particular, we are interested in evaluating the impact of the meta-prompting exploration and inspiration-based crossover operators discussed in Section 4.2.We perform this analysis on problems P1, P2.A and P3 (both instances), according to the different configurations described in Table 2.We choose these three problems in order to cover a diverse set of problems where CODEEVOLVE achieves state of the art performance.</p>
<p>Configuration Meta-prompting Inspirations Evolution and migration
mp+insp ✓ ✓ ✓ mp ✓ ✗ ✓ insp ✗ ✓ ✓ no mp or insp ✗ ✗ ✓ no evolution ✗ ✗ ✗
Table 2: Configurations for experiments conducted in the ablation study.The no evolution configuration serves as an important baseline, as it involves repeatedly prompting the LLM with only the initial trivial solution, without incorporating any feedback or previously generated code.This isolates the benefit of the iterative evolutionary loop itself.</p>
<p>Figure 8 shows the results of the ablations for problem P3.For problem P3.A, we can observe that all configurations surpass AlphaEvolve's solution, including the no evolve version without the evolutionary loop.Notably, the full method configuration mp+insp converges to the best-found solution fastest, suggesting a strong synergistic effect between the meta-prompting and inspiration mechanisms.A similar, more pronounced trend is visible in experiment P3.B.Here, the mp+insp configuration again demonstrates the fastest convergence to a superior solution.In contrast, the mp and insp configurations in isolation perform significantly worse, even underperforming the baseline evolutionary model (no mp or insp).This result strongly indicates that for complex packing problems, the combined effect of enriched exploration from meta-prompting and feature mixing from inspiration-based crossover is critical for effective search.</p>
<p>Figure 9 displays the results for problems P1 and P2.A.The results for P2.A align with our previous findings: the full mp+insp configuration outperforms all other instances, followed by insp and mp individually.It is noteworthy that only the configurations including the inspiration mechanism were able to surpass the AlphaEvolve benchmark, highlighting the importance of the crossover-like operator for this geometric problem.</p>
<p>Problem P1, however, presents an interesting exception to the general trend.In this case, the mp configuration achieved the best overall performance, followed by the full mp+insp model.Intriguingly, the addition of inspiration-based crossover appears to have a detrimental effect, as the insp configuration presented the overall worst performance.For this specific task, the broad, diverse exploration driven by meta-prompting may be more effective than the convergence-promoting effect of the inspiration mechanism.This underscores that while the full CODEEVOLVE architecture is robust, the optimal combination of evolutionary operators can be problem-dependent.</p>
<p>Discussion</p>
<p>Progress on other benchmarks.While we have demonstrated state-of-the-art performance on a subset of the AlphaEvolve our work is ongoing.We are actively applying CODEEVOLVE to the remaining mathematical problems outlined in the AlphaEvolve whitepaper (Novikov et al., 2025, Appendix B).For several problems, such as the Heilbronn problem for triangles and packing hexagons, our preliminary results are already approaching the known state-of-the-art bounds.However, other problems, like improving the lower bound for the Kissing Number problem, appear to be significantly harder and may require further methodological innovations.Our goal is to continue pushing the boundaries of what is achievable with a transparent methodology and a limited computational budget.We believe that future algorithmic enhancements to CODEEVOLVE will lead to to new breakthroughs.</p>
<p>Reproducibility.We are committed to transparency and reproducibility.Although the sampling operators used in our genetic algorithm are seedable, the main source of stochasticity in CODEEVOLVE lies within the LLM API calls themselves.We utilize an OpenAI-compatible SDK interface, which routes requests to the Google GEMINI models used in our work.As of our experiments, the API does not support fixed random seeds to guarantee deterministic outputs for identical prompts.Consequently, while some components of CODEEVOLVE are reproducible, the exact sequence of generated solutions and the final results cannot be replicated precisely.This is a current limitation of relying on closed-box commercial LLMs  , where M is the maximum fitness attained in all experiments, ϵ is a small constant that controls the spacing between curves, and y is the best fitness across all islands at a given epoch.for scientific research.</p>
<p>Open Source.A significant barrier to progress in LLM-driven algorithm discovery is the closed-source nature of systems like AlphaEvolve (Novikov et al., 2025).This opacity hinders replication, comparative analysis, and collective scientific innovation.Our primary contribution is to address this gap by releasing CODEEVOLVE as a fully open-source project.By providing the complete framework, experimental configurations, and results, we aim to democratize research in this area.</p>
<p>We are a small team with limited resources, and we believe that community collaboration is the most effective path toward accelerating progress.We invite researchers and practitioners to build upon our work, introduce new ideas, and collectively tackle challenging algorithmic problems.</p>
<p>Conclusion &amp; Future Work</p>
<p>In this paper, we introduced CODEEVOLVE, an open-source framework for algorithm discovery that integrates Large Language Models with an island-based genetic algorithm.By designing concrete implementations for high-level concepts such as meta-prompting and inspiration-based crossover, we developed a transparent and effective system for evolving codebases.Our empirical evaluation demonstrated that CODEEVOLVE not only replicates but surpasses the performance of the closedsource AlphaEvolve system on several complex mathematical benchmarks, establishing new stateof-the-art results.By releasing our complete framework and experimental results, we provide a valuable resource for the research community, aiming to democratize research in this promising domain.</p>
<p>For future work, we plan to expand upon the current features by incorporating more sophisticated evolutionary mechanisms, such as promoting increased solution diversity via the MAP-Elites algorithm (Mouret and Clune, 2015), and a more dynamic scheduling for the exploration-exploitation trade-off via RL methods.We also intend to conduct a large-scale analysis of hyperparameter sensitivity to further optimize performance across different problem domains.Finally, we will apply CODEEVOLVE to a broader range of scientific and engineering challenges to continue pushing the boundaries of automated algorithm discovery.</p>
<p>Figure 1 :
1
Figure 1: Overview of CODEEVOLVE.</p>
<p>Figure 2 :
2
Figure 2: Comparison of best placement of 16 2dimensional points for problem P2.A.</p>
<p>Figure 3 :
3
Figure 3: Comparison of best placement of 14 3dimensional points for problem P2.A.</p>
<p>sum of radii = 2.63597</p>
<p>Figure 4 :
4
Figure 4: Comparison of best placement of 26 circles inside a unit square for problem P3.A.</p>
<p>Figure 5 :
5
Figure 5: Comparison of best placement of 32 circles inside a unit square for problem P3.B.</p>
<p>Figure 6 :
6
Figure 6: Comparison of best nonnegative step functions found for problem P1.Legend indicates the number of steps in each function, and both functions were normalized so that their image is in [0, 1].</p>
<p>Figure 7 :
7
Figure 7: Comparison of best placement of 21 circles inside a rectangle of perimeter 4 for problem P4.</p>
<p>Figure 8 :
8
Figure8: Ablations for both instances of the circle packing problem P3.For easier visualization, the vertical axis shows − log(M + ϵ − y), where M is the maximum fitness attained in all experiments, ϵ is a small constant that controls the spacing between curves, and y is the best fitness across all islands at a given epoch.</p>
<p>Figure 9 :
9
Figure9: Ablations for problems P1 and P2.A. Vertical axis is defined as in Figure8.</p>
<p>1</p>
<p>Depth exploitation and Meta-prompt exploration steps of CODEEVOLVE at epoch t 1: Input: Populations P i t , S i t , exploration probability p explr , maximum ancestor depth k 2: Output: New solution S ′ , and new prompt P ′ if exploration is chosen 3: Sample p ∼ Uniform(0, 1) 4: Sample a solution S ∈ S i t (Eq.2) 5: Sample inspirations I ⊆ S i t \ {S} (Eq.2) 6: if p &lt; 1 − p explr then
7:Collect ancestor solutions A k (S) from S to8:its root in S i t S ′ ← LLMEnsemble(P (S), A k (S), S, I)9:P ′ ← NULL10: else11:
P ′ ← MetaPromptingLLM(P (S), S)12:</p>
<p>AcknowledgmentsThe authors thank Bruno Grossi for reviewing this paper and for the continuous support during the development of this project.We also thank Fernando Augusto and Tiago Machado for the useful conversations about possible applications of CODEE-VOLVE at Inter.Author contributionsH.A. started the project, designed and implemented the core features of CODEEVOLVE, and conducted experiments on all of the proposed benchmarks.D.F. implemented the benchmarks related to analysis and the code for the solution evaluator, and also conducted experiments for problem P1.L.C. and F.M. were involved in design discussions about the main components of CODEEVOLVE, as well as the analysis of the experimental results.H.A. and F.M. wrote the manuscript, and D.F. drafted preliminary versions of the two first sections.L.C. and F.M. were responsible for multiple rounds of revisions before the final submission.
Sotiris Anagnostidis, Jannis Bulian, arXiv:2408.11865susceptible are llms to influence in prompts? Preprint. 2024</p>
<p>EvoPrompting: Language models for codelevel neural architecture search. Angelica Chen, David M Dohan, David R So, Advances in Neural Information Processing Systems. 2023</p>
<p>Qiming Yuan, and others Penedones, Henrique and. Mark Chen, Jerry Tworek, Heewoo Jun, arXiv:2107.03374Evaluating large language models trained on code. 2021arXiv preprint</p>
<p>Gemini 2.5: Pushing the frontier with advanced reasoning, multimodality, long context, and next generation agentic capabilities. Gheorghe Comanici, Eric Bieber, Mike Schaekermann, Ice Pasupat, Noveen Sachdeva, Inderjit Dhillon ; Ori Ram, Dan Zhang, Evan Rosen, Luke Marris, Sam Petulla, Colin Gaffney, Asaf Aharoni, arXiv:2507.06261Marcel Blistein,. 2025Nathan Lintz, Tiago Cardal Pais, Henrik Jacobsson, Idan SzpektorPreprintNan-Jiang Jiang, and 3290 others</p>
<p>Discovering faster matrix multiplication algorithms with reinforcement learning. Alhussein Fawzi, Matej Balog, Alexander Huang, Thomas Hubert, Nature. 61079302022Bernardino Romera-Paredes, and 1 others</p>
<p>Promptbreeder: Self-referential self-improvement via prompt evolution. Chrisantha Fernando, Dylan Banarse, Henryk Michalewski, Simon Osindero, Tim Rocktäschel, arXiv:2309.167972023arXiv preprint</p>
<p>Jonas Gottweis, Wen-Hao Weng, Aleksandr Daryin, Tuan Tu, arXiv:2502.18864Anirudh Palepu, and 1 others. 2025. Towards an ai co-scientist. arXiv preprint</p>
<p>Evolving code with a large language model. Erik Hemberg, Stephen Moskal, Una-May O' Reilly, 10.1007/s10710-024-09494-2Genetic Programming and Evolvable Machines. 252212024</p>
<p>Genetic programming: on the programming of computers by means of natural selection. John R Koza, 1992MIT press1</p>
<p>Genetic programming as a means for programming computers by natural selection. John R Koza, 10.1007/BF00175355Statistics and Computing. 421994</p>
<p>Foundations of genetic programming. B William, Riccardo Langdon, Poli, 2013Springer Science &amp; Business Media</p>
<p>Robert Tjarko Lange, Yuki Imajuku, Edoardo Cetin, arXiv:2509.19349Shinkaevolve: Towards open-ended and sample-efficient program evolution. 2025arXiv preprint</p>
<p>Evolution through large models. Joel Lehman, Jonathan Gordon, Shreyas Jain, Kenz Ndousse, Christine Yeh, Kenneth O Stanley, Handbook of Evolutionary Machine Learning. Springer2023</p>
<p>Competition-level code generation with alphacode. Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Science. 37866241 others. 2022</p>
<p>Improved bounds on the supremum of autoconvolutions. Mate Matolcsi, Carlos Vinuesa, arXiv:0907.13792009Preprint</p>
<p>Illuminating search spaces by mapping elites. Jean-Baptiste Mouret, Jeff Clune, arXiv:1504.049092015Preprint</p>
<p>Reinforced generation of combinatorial structures: Applications to complexity theory. Ansh Nagda, Prabhakar Raghavan, Abhradeep Thakurta, arXiv:2509.180572025Preprint</p>
<p>Alphaevolve: A coding agent for scientific and algorithmic discovery. Alexander Novikov, Ngân Vũ, Marvin Eisenberger, Emilien Dupont, Po-Sen Huang, Adam Zsolt Wagner, Sergey Shirobokov, Borislav Kozlovskii, J R Francisco, Ruiz, M Pawan Abbas Mehrabian, Abigail Kumar, Swarat See, George Chaudhuri, Alex Holland, Sebastian Davies, Pushmeet Nowozin, Matej Kohli, Balog, arXiv:2506.131312025Preprint</p>
<p>Mathematical discoveries from program search with large language models. Bernardino Romera-Paredes, Mohammad Barekatain, Alexander Novikov, Matej Balog, M Pawan Kumar, Emilien Dupont, J R Francisco, Jordan S Ruiz, Pengming Ellenberg, Wang, 10.1038/s41586-023-06924-6Omar Fawzi, and 1 others. 2023624</p>
<p>Openevolve: an open-source evolutionary coding agent. Asankhaya Sharma, 2025</p>
<p>Metaprompting: Enhancing language models with taskagnostic scaffolding. Mirac Suzgun, Adam Tauman, Kalai , arXiv:2401.129542024Preprint</p>
<p>Genitor ii.: a distributed genetic algorithm. Darrell Whitley, Timothy Starkweather, 10.1080/09528139008953723J. Exp. Theor. Artif. Intell. 231990</p>
<p>Meta prompting for ai systems. Yifan Zhang, Yang Yuan, Andrew Chi-Chih Yao, arXiv:2311.114822025Preprint</p>            </div>
        </div>

    </div>
</body>
</html>