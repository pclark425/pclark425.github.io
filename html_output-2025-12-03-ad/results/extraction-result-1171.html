<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1171 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1171</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1171</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-26.html">extraction-schema-26</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <p><strong>Paper ID:</strong> paper-253236849</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2210.15327v2.pdf" target="_blank">Towards Language-driven Scientific AI</a></p>
                <p><strong>Paper Abstract:</strong> Inspired by recent and revolutionary developments in AI, particularly in language understanding and generation, we set about designing AI systems that are able to address complex scientific tasks that challenge human capabilities to make new discoveries. Central to our approach is the notion of natural language as core representation, reasoning, and exchange format between scientific AI and human scientists. In this paper, we identify and discuss some of the main research challenges to accomplish such vision.</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1171.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1171.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Scientific AI (vision)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Language-driven Scientific AI (this paper's vision)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A proposed class of AI systems that use natural language as the core representation, reasoning, and exchange format to collaborate with human scientists, autonomously propose research goals, hypotheses, and evaluate claims against evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Language-driven Scientific AI</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A conceptual, modular AI architecture centered on large pre-trained language models (transformer-based), augmented with retrieval, multi-modal (vision + text) grounding, chain-of-thought style decomposition, and evidence-based credibility review components (e.g., claim verification, retrieval-augmented generation, and explainable argumentation). Emphasizes continuous belief updating, domain adaptation, and the use of natural language prompts and dialogues to formulate research goals and methods.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>No concrete automated scientific discoveries are reported in this paper; the paper articulates a research agenda and envisions systems that could autonomously generate and evaluate research goals, hypotheses, and claims across scientific domains but provides no实例 of actual discoveries produced by such systems.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Proposed evaluation methods discussed at a conceptual level: (1) factuality/entailment checks to ensure generated claims are coherent with source literature, (2) claim verification against the literature (e.g., SciFact-style supported/refuted/insufficient labels), (3) evidence-based, explainable credibility review inspired by acred framework, (4) retrieval-augmented evaluation to bring in up-to-date state-of-the-art, and (5) measuring statistical significance of problems with respect to the model's internal representations to decide how much external knowledge to fetch. No concrete experimental evaluation protocols or numerical metrics for discoveries are provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Conceptual proposals only: validate generated hypotheses/claims by (a) automatic claim verification against scientific literature (SciFact-like systems), (b) evidence linking and explainable credibility reviews (acred-inspired), and (c) human-in-the-loop expert review and debate. The paper emphasizes the need for real experimental validation pipelines but does not present implemented validation experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>No operational novelty-assessment procedure is implemented; the paper suggests novelty would be assessed by (1) checking whether a claim is supported/contradicted by prior literature, (2) measuring how statistically significant or under-represented a problem is in the model's training data, and (3) human peer review and debate, but gives no concrete scoring or thresholds.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>No numerical metrics or quantifiable impact measures are provided. The paper suggests measuring model 'proficiency' per topic and statistical significance of problems in training data, but does not define concrete metrics or numerical thresholds.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Key challenges listed: generative models hallucinate and can produce nonsensical claims; lack of datasets to evaluate hypothesis generation and high-level scientific tasks; brittleness and poor generalization of rule-like problem-solving methods; domain-adaptation can cause loss of generality; scientific visual information is complex and under-datasets; need for continuous, real-time updating and validation of model beliefs; absence of concrete evaluation/validation pipelines for actual discoveries; difficulty in assessing incremental vs transformational discoveries since no operational criteria are provided.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1171.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1171.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative Pre-trained Transformer 3</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large transformer-based generative language model trained with self-supervised objectives over massive text corpora, able to produce realistic human-like text and perform few-shot learning via prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Language models are few-shot learners</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>GPT-3</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Transformer-based, autoregressive language model pre-trained to predict next token on large-scale corpora; used as an exemplar of generative language models that can produce natural-language formulations of tasks when prompted (pre-train, prompt, predict paradigm). The paper references GPT-3 as a component class to build language-driven scientific AI.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>The paper does not attribute any scientific discoveries to GPT-3; it is cited as an enabling language technology that could be used to formulate hypotheses or scientific text, but no actual discoveries made by GPT-3 are reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Within this paper GPT-3 is discussed in the context of standard NLP evaluations (few-shot learning, text generation quality). For the scientific context, the paper suggests complementing generative outputs with entailment checks and claim verification (e.g., SciFact) and retrieval to improve factuality, but gives no experimental metrics for discovery tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>No discovery validation for GPT-3 is reported in this paper. The paper highlights the need for external retrieval, entailment-based checks, and evidence-based credibility reviews to validate claims generated by such models.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>No discovery-impact metrics are provided; GPT-3 is referenced in relation to capabilities on language benchmarks but no numerical discovery-impact measures are given in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Paper notes GPT-3-like models commonly hallucinate, can produce nonsensical or ungrounded scientific claims, lack explicit mechanisms to link claims to evidence, and require retrieval/validation and control to be useful for scientific discovery. Also notes absence of datasets and benchmarks for higher-level scientific tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1171.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1171.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SciFact</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SciFact (claim verification for scientific claims)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A dataset and system for automatic verification of scientific claims against the literature, labeling claims as Supported, Refuted, or NotEnoughInfo and retrieving evidence sentences that justify the label.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Fact or fiction: Verifying scientific claims</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>SciFact</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An evidence-based claim verification framework/dataset that pairs scientific claims with abstracts and gold evidence sentences and a label (SUPPORTED/REFUTED/NOTENOUGHINFO); used as a reference point for validating scientific claims generated by models.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>scientific literature (cross-domain)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>SciFact itself is not a discovery-making system; it is used to evaluate whether a claim (potentially generated by an automated system) is supported or refuted by existing literature. The paper cites SciFact as prior work on validation rather than as a system that produces discoveries.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Standard claim-verification metrics: classification accuracy for supported/refuted/NEI labels, retrieval/evidence selection performance (precision/recall/F1 for evidence sentences). The paper does not report numeric values here but references SciFact as an approach for validation.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Automatic comparison of model-predicted labels and evidence sentences to gold annotations derived from literature; used to validate factual support for generated claims.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty in SciFact is assessed by whether a claim is covered or contradicted in existing literature (i.e., it's not novel if fully supported by prior papers), but the paper only cites SciFact as an example and does not operationalize novelty detection for generated discoveries.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Limitations cited in the paper's discussion of validation tools like SciFact: existing claim-verification datasets are limited in scope/size, may not generalize across scientific modalities (e.g., figures/diagrams), and do not by themselves establish the originality or experimental validity of a purported discovery; they only assess literature support.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Artificial intelligence to win the nobel prize and beyond: Creating the engine for scientific discovery <em>(Rating: 2)</em></li>
                <li>Fact or fiction: Verifying scientific claims <em>(Rating: 2)</em></li>
                <li>Thoughtful artificial intelligence: Forging a new partnership for data science and scientific discovery <em>(Rating: 1)</em></li>
                <li>Chain of thought prompting elicits reasoning in large language models <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1171",
    "paper_id": "paper-253236849",
    "extraction_schema_id": "extraction-schema-26",
    "extracted_data": [
        {
            "name_short": "Scientific AI (vision)",
            "name_full": "Language-driven Scientific AI (this paper's vision)",
            "brief_description": "A proposed class of AI systems that use natural language as the core representation, reasoning, and exchange format to collaborate with human scientists, autonomously propose research goals, hypotheses, and evaluate claims against evidence.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Language-driven Scientific AI",
            "system_description": "A conceptual, modular AI architecture centered on large pre-trained language models (transformer-based), augmented with retrieval, multi-modal (vision + text) grounding, chain-of-thought style decomposition, and evidence-based credibility review components (e.g., claim verification, retrieval-augmented generation, and explainable argumentation). Emphasizes continuous belief updating, domain adaptation, and the use of natural language prompts and dialogues to formulate research goals and methods.",
            "discovery_domain": null,
            "discovery_description": "No concrete automated scientific discoveries are reported in this paper; the paper articulates a research agenda and envisions systems that could autonomously generate and evaluate research goals, hypotheses, and claims across scientific domains but provides no实例 of actual discoveries produced by such systems.",
            "discovery_type": null,
            "discovery_type_justification": null,
            "evaluation_methods": "Proposed evaluation methods discussed at a conceptual level: (1) factuality/entailment checks to ensure generated claims are coherent with source literature, (2) claim verification against the literature (e.g., SciFact-style supported/refuted/insufficient labels), (3) evidence-based, explainable credibility review inspired by acred framework, (4) retrieval-augmented evaluation to bring in up-to-date state-of-the-art, and (5) measuring statistical significance of problems with respect to the model's internal representations to decide how much external knowledge to fetch. No concrete experimental evaluation protocols or numerical metrics for discoveries are provided in this paper.",
            "validation_approaches": "Conceptual proposals only: validate generated hypotheses/claims by (a) automatic claim verification against scientific literature (SciFact-like systems), (b) evidence linking and explainable credibility reviews (acred-inspired), and (c) human-in-the-loop expert review and debate. The paper emphasizes the need for real experimental validation pipelines but does not present implemented validation experiments.",
            "novelty_assessment": "No operational novelty-assessment procedure is implemented; the paper suggests novelty would be assessed by (1) checking whether a claim is supported/contradicted by prior literature, (2) measuring how statistically significant or under-represented a problem is in the model's training data, and (3) human peer review and debate, but gives no concrete scoring or thresholds.",
            "impact_metrics": "No numerical metrics or quantifiable impact measures are provided. The paper suggests measuring model 'proficiency' per topic and statistical significance of problems in training data, but does not define concrete metrics or numerical thresholds.",
            "comparison_to_human_discoveries": false,
            "comparison_details": null,
            "success_rate": null,
            "challenges_limitations": "Key challenges listed: generative models hallucinate and can produce nonsensical claims; lack of datasets to evaluate hypothesis generation and high-level scientific tasks; brittleness and poor generalization of rule-like problem-solving methods; domain-adaptation can cause loss of generality; scientific visual information is complex and under-datasets; need for continuous, real-time updating and validation of model beliefs; absence of concrete evaluation/validation pipelines for actual discoveries; difficulty in assessing incremental vs transformational discoveries since no operational criteria are provided.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1171.0"
        },
        {
            "name_short": "GPT-3",
            "name_full": "Generative Pre-trained Transformer 3",
            "brief_description": "A large transformer-based generative language model trained with self-supervised objectives over massive text corpora, able to produce realistic human-like text and perform few-shot learning via prompting.",
            "citation_title": "Language models are few-shot learners",
            "mention_or_use": "mention",
            "system_name": "GPT-3",
            "system_description": "Transformer-based, autoregressive language model pre-trained to predict next token on large-scale corpora; used as an exemplar of generative language models that can produce natural-language formulations of tasks when prompted (pre-train, prompt, predict paradigm). The paper references GPT-3 as a component class to build language-driven scientific AI.",
            "discovery_domain": null,
            "discovery_description": "The paper does not attribute any scientific discoveries to GPT-3; it is cited as an enabling language technology that could be used to formulate hypotheses or scientific text, but no actual discoveries made by GPT-3 are reported here.",
            "discovery_type": null,
            "discovery_type_justification": null,
            "evaluation_methods": "Within this paper GPT-3 is discussed in the context of standard NLP evaluations (few-shot learning, text generation quality). For the scientific context, the paper suggests complementing generative outputs with entailment checks and claim verification (e.g., SciFact) and retrieval to improve factuality, but gives no experimental metrics for discovery tasks.",
            "validation_approaches": "No discovery validation for GPT-3 is reported in this paper. The paper highlights the need for external retrieval, entailment-based checks, and evidence-based credibility reviews to validate claims generated by such models.",
            "novelty_assessment": null,
            "impact_metrics": "No discovery-impact metrics are provided; GPT-3 is referenced in relation to capabilities on language benchmarks but no numerical discovery-impact measures are given in this paper.",
            "comparison_to_human_discoveries": false,
            "comparison_details": null,
            "success_rate": null,
            "challenges_limitations": "Paper notes GPT-3-like models commonly hallucinate, can produce nonsensical or ungrounded scientific claims, lack explicit mechanisms to link claims to evidence, and require retrieval/validation and control to be useful for scientific discovery. Also notes absence of datasets and benchmarks for higher-level scientific tasks.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1171.1"
        },
        {
            "name_short": "SciFact",
            "name_full": "SciFact (claim verification for scientific claims)",
            "brief_description": "A dataset and system for automatic verification of scientific claims against the literature, labeling claims as Supported, Refuted, or NotEnoughInfo and retrieving evidence sentences that justify the label.",
            "citation_title": "Fact or fiction: Verifying scientific claims",
            "mention_or_use": "mention",
            "system_name": "SciFact",
            "system_description": "An evidence-based claim verification framework/dataset that pairs scientific claims with abstracts and gold evidence sentences and a label (SUPPORTED/REFUTED/NOTENOUGHINFO); used as a reference point for validating scientific claims generated by models.",
            "discovery_domain": "scientific literature (cross-domain)",
            "discovery_description": "SciFact itself is not a discovery-making system; it is used to evaluate whether a claim (potentially generated by an automated system) is supported or refuted by existing literature. The paper cites SciFact as prior work on validation rather than as a system that produces discoveries.",
            "discovery_type": null,
            "discovery_type_justification": null,
            "evaluation_methods": "Standard claim-verification metrics: classification accuracy for supported/refuted/NEI labels, retrieval/evidence selection performance (precision/recall/F1 for evidence sentences). The paper does not report numeric values here but references SciFact as an approach for validation.",
            "validation_approaches": "Automatic comparison of model-predicted labels and evidence sentences to gold annotations derived from literature; used to validate factual support for generated claims.",
            "novelty_assessment": "Novelty in SciFact is assessed by whether a claim is covered or contradicted in existing literature (i.e., it's not novel if fully supported by prior papers), but the paper only cites SciFact as an example and does not operationalize novelty detection for generated discoveries.",
            "impact_metrics": null,
            "comparison_to_human_discoveries": false,
            "comparison_details": null,
            "success_rate": null,
            "challenges_limitations": "Limitations cited in the paper's discussion of validation tools like SciFact: existing claim-verification datasets are limited in scope/size, may not generalize across scientific modalities (e.g., figures/diagrams), and do not by themselves establish the originality or experimental validity of a purported discovery; they only assess literature support.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1171.2"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Artificial intelligence to win the nobel prize and beyond: Creating the engine for scientific discovery",
            "rating": 2,
            "sanitized_title": "artificial_intelligence_to_win_the_nobel_prize_and_beyond_creating_the_engine_for_scientific_discovery"
        },
        {
            "paper_title": "Fact or fiction: Verifying scientific claims",
            "rating": 2,
            "sanitized_title": "fact_or_fiction_verifying_scientific_claims"
        },
        {
            "paper_title": "Thoughtful artificial intelligence: Forging a new partnership for data science and scientific discovery",
            "rating": 1,
            "sanitized_title": "thoughtful_artificial_intelligence_forging_a_new_partnership_for_data_science_and_scientific_discovery"
        },
        {
            "paper_title": "Chain of thought prompting elicits reasoning in large language models",
            "rating": 1,
            "sanitized_title": "chain_of_thought_prompting_elicits_reasoning_in_large_language_models"
        }
    ],
    "cost": 0.0110525,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Towards Language-driven Scientific AI
31 Oct 2022</p>
<p>José Manuel Gómez-Pérez 
Language Technology Research Lab
Expert.ai</p>
<p>Poeta Joan Maragall
28020MadridSpain</p>
<p>Towards Language-driven Scientific AI
31 Oct 2022ScienceArtificial IntelligenceLanguage Understanding
Inspired by recent and revolutionary developments in AI, particularly in language understanding and generation, we set about designing AI systems that are able to address complex scientific tasks that challenge human capabilities to make new discoveries. Central to our approach is the notion of natural language as core representation, reasoning, and exchange format between scientific AI and human scientists. In this paper, we identify and discuss some of the main research challenges to accomplish such vision.</p>
<p>Introduction</p>
<p>During her presidential address at the AAAI Conference, Gil (2022) pondered whether artificial intelligence (AI) will write scientific papers in the future. She believed that we can be hopeful that the answer is yes and that it may happen sooner than we might expect. As scientific questions become significantly more complex, our capabilities to do scientific breakthroughs need to be augmented. Compare for instance the challenges of formulating Kepler's laws of planetary motion or the discovery of a cure for Polio with demonstrating the existence of binary stellar-mass black hole systems (Abbott et al., 2016) or the treatment of glioblastoma, a type of brain cancer. While the former were achieved by a single scientist, the latter require large and interdisciplinary teams involving the collaboration of hundreds of scientists from different fields to work together during years to produce results.</p>
<p>In this paper, we present a personal perspective inspired by recent breakthroughs in AI and particularly language technologies to enable a next generation of AI systems that may become an effective part of the scientific ecosystem, collaborate, contribute, and eventually produce significant findings (Kitano, 2016). In recent years, the incorporation of intelligent techniques for data mining and machine learning has provided scientists with powerful data-driven analytics and discovery capabilities. However, such techniques have been focused on solving well-defined narrow tasks. Confining intelligent machines to such tasks can severely limit our ability to truly harness the potential of AI to enable us to tackle larger scientific problems.</p>
<p>It is time to take a quantum leap. Future scientific endeavors will require partnerships of scientists and AI, where machines may independently pursue substantial aspects of the research and contribute their own discoveries. Such thoughtful AI systems (Gil, 2017) should be capable of formulating their own research goals, proposing and evaluating hypotheses, designing theories, debating alternative options, and generating new knowledge. They should be able to explain their reasoning, compare their rationales to others, and situate their findings in the existing literature. AI systems should be able to communicate with scientists with different levels of expertise in a topic. To form a true partnership, they should be able to take guidance from scientists as well as to provide guidance to them. Today, this vision is still impossible to the point that new research is required to make it happen.</p>
<p>The following sections delve into the challenges this vision entails and how it could be accomplished from a language-driven research perspective.</p>
<p>Scientific AI will be language-driven</p>
<p>As part of the scientific task forces of the future, AI systems will need to exchange feedback with human scientists and learn from their interaction. Rather than fixed, structured formalisms to represent scientific knowledge, which can be brittle and constrained to our ability to represent things explicitly, we propose a natural language-driven approach where language is the main formalism to represent and exchange scientific information between the different agents in the scientific ecosystem, be they humans or machines.</p>
<p>Generative language models like GPT-3 (Brown et al., 2020) or T5 (Raffel et al., 2020) produce realistic human text based on a statistical bias acquired through self-supervised training over an extremely large document corpus, learning to guess the word that is most likely to come next given a prompt, with applications in many language tasks like information extraction, reading comprehension and question answering, conversation, summarization or machine translation. Such models promote a change of paradigm in NLP, from "pretrain, fine-tune, predict" to "pre-train, prompt, predict", where a prompt is a piece of text inserted in the input examples so that the task that needs to be solved can be formulated as a language modeling problem. Subsequently, prompt-based prediction (Gao et al., 2021;Schick and Schütze, 2021) seeks to specify such prompts as effectively as possible.</p>
<p>We posit that the task of formulating research goals, hypotheses, and claims by machines in natural language, as well as the evaluation of those produced by other scientists, can be recast into a series of instructions and prompts in natural language that inform the model. However, there is no research that has explored this path yet. Generative language models and prompt-based prediction are promising but still in their infancy, scientific tasks like the formulation of hypotheses, goals and claims require a level of knowledge, abstract thinking and reasoning only humans have been capable of yet, and there are no datasets that enable the evaluation and testing of systems that aim to solve such tasks at human level.</p>
<p>...but also multi-modal</p>
<p>Although we propose language as the main representation and exchange formalism for scientific AI systems, scientific knowledge is heterogeneous and can present itself in many forms. As originally put by Reddy (1988), "Reading a chapter in a college freshman text and answering the questions at the end of the chapter is a hard problem that requires advances in vision, language, problem-solving, and learning theory.". As of today, this is still one of the grand challenges to be tackled in AI.</p>
<p>Like many other manifestations of human thought, scientific discourse usually adopts the form of a narrative, a scientific publication or technical report, where related information is presented in mutually supportive ways over different modalities, including text, diagrams, figures, mathematical equations or tables, which need to be accounted for, represented, and understood across the different modalities. Visually grounded language and visual reasoning is frequent in Science. However, dealing with scientific visual information entails additional complexity compared to natural images.</p>
<p>For example, scientific diagrams are more abstract and symbolic than natural images, hindering the application of conventional language and vision understanding methods. Some approaches like (Kembhavi et al., 2016) propose to parse diagram components and connectors as a graph that can be subsequently interpreted. However, this approach does not seem to generalize beyond a few types of predefined diagrams (water cycle, food chain, etc.). Others (Gomez-Perez and Ortega, 2019) leverage the free supervision provided by the correspondence between scientific figures and the text in their captions to generate a unified language-vision representation space that enables language-vision understanding. Experimental results showed the emergence of visual representations capturing certain features, such as line plots, whisker plots or immunoblots, and their combination in more complex figures. Follow up work by Gomez-Perez and Ortega (2020) tap on language models and cross-modal attention to identify regions of interest corresponding to diagram components and their relationships to improve the selection of relevant visual information in order to answer different types of questions.</p>
<p>Unlike natural image datasets for visual question answering or image captioning like COCO (Lin et al., 2014) and Visual Genome (Krishna et al., 2017), there are barely any datasets that are rich with annotated scientific diagrams or such dataset are too small to train large models (AI2D 1 ). So far, this has been a strong limitation for any significant progress in this area that our work aims to address.</p>
<p>Generating problem-solving strategies</p>
<p>Tackling scientific problems of such complexity that may challenge human scientists will require AI systems to learn strategies (methods) that allow decomposing the scientific task at hand into simpler, more attainable steps, following a divide-and-conquer approach. The notion of problem-solving methods (Mcdermott, 1988) was originally proposed in the context of expert system research and then applied to answer scientific questions in disciplines like chemistry, physics, and biology (Gómez-Pérez et al., 2010). However, while the resulting systems were able to provide effective strategies to answer certain types of scientific questions, such "recipes" tend to be rigid, brittle, and hard to generalize. This problem can be seen as an instance of the knowledge acquisition bottleneck (Feigenbaum, 1984), where the resulting model suffers from the cognitive limitations that humans may experience to identify, formulate, and explicitly represent the potentially vast number of possible cases to be covered. Therefore, rather than exclusively modeled by experts, scientific problemsolving methods should also be learnt from the data. Language models have shown good results in tasks like multi-hop question answering (Mavi et al., 2022), where answering a question requires several steps. Recent work (Wei et al., 2022) explores the ability of language models to generate a coherent chain of thought as a series of short sentences that mimic the reasoning process a person might follow when responding to a question. Indeed, inducing a chain of thought via prompting has shown to enable sufficiently large language models to better perform reasoning tasks. Even more recently, other approaches (Khot et al., 2022) advocate for solving complex tasks by directly decomposing such tasks into simpler sub-tasks via prompting, optimizing each prompt for its specific task, further decomposing and, if necessary, replacing the prompt with more effective ones, trained models, or symbolic functions.</p>
<p>Factual, argumentative, and ethical scientific AI</p>
<p>It is common for generative language models like GPT-3 to produce text that is realistic but also hallucinatory or nonsensical. 2 In science we need models that do not just look thoughtful and able to reason with scientific information, but models that as a matter of fact are scientific. Tasks like entailment have been used with good results (Pasunuru and Bansal, 2018) in support of generative tasks like abstractive text summarization to ensure coherence between the summary and the original text, increasing factuality. However, science also requires the ability to link the scientific hypotheses, goals, and claims generated by the model with actual evidence that supports such statements. Just like human scientists produce new research based on previous work and cite such work to sustain their research, scientific AI will need to contrast their research goals, hypotheses, and claims with evidence.</p>
<p>Previous work in this direction, like SciFact (Wadden et al., 2020), explores the validation of claims against the literature to determine whether they are supported or refuted by previous work. We plan to take a step further, creating an evidence-based framework for credibility review inspired by recent breakthroughs in fact-checking and misinformation detection, like the acred credibility review framework (Denaux and Gomez-Perez, 2020), both evidence-based, explainable and differentiable.</p>
<p>On the other hand, future scientific AIs will also require the ability to be argumentative and justify their own reasoning in natural language, driven by a notion of reward that stems from winning a scientific discussion and positively reinforces such behavior. Furthermore, scientific AI will need to act in ways that are compliant with human best practices and principles. This requires the AI to be self-aware, including a quantifiable notion of proficiency in each particular topic, as well as explainable, faithful and truthful. In this regard, approaches like (Dalvi et al., 2022) generate chains of reasoning that show how the answers to questions are implied by the model's own internal beliefs, allowing users to interact with the explanations to identify erroneous beliefs and provide corrections.</p>
<p>Modularity, adaptation and autonomous learning</p>
<p>We need large models that contain representations of vast amounts of knowledge in core and progressively capilar scientific disciplines, with a grounding in world knowledge and commonsense understanding, as well as the ability to continuously acquire and update the model's beliefs as the state of the art evolves. Until now, scientific language models like SciBert (Beltagy et al., 2019), BioBert (Lee et al., 2019) or SpaceRoBERTa (Berquand et al., 2021) have tried to address the challenge of domain-specifty through additional pre-training on large amounts of scientific documents that leverage largescale open access scientific resources like OpenAire 3 , arXiv 4 , Web of Science 5 or Semantic Scholar. 6 However, only such knowledge which is statistically significant in the training data is effectively captured, limiting the usefulness of pre-trained language models as knowledge bases or reasoning engines. Domain adaptation based on additional pre-training may also entail generality loss, impacting on downstream tasks (Garcia-Silva et al., 2022).</p>
<p>Large language models have recently been shown to generate more factual responses by employing modularity in combination with retrieval (Adolphs et al., 2021;Zhou et al., 2022), starting to include internet search as a way to fill in gaps in their internal representations. Science is a moving target, with an exponential annual production of scientific publications 7 that reflects a constant progress of the state of the art. Thus, it is imperative for scientific AI to reach out for knowledge outside of their current beliefs proactively, as a researcher would, in order to have an up-to-date view of the field of interest. Acquiring a quantifiable understanding of how statistically significant the problem to be addressed can be for the internal representations of a scientific language model is needed in order to estimate the type and amount of external knowledge to be brought on board. Defining methods to effectively query and retrieve such knowledge would come next. Finally, more research is required that goes beyond current methods (Peters et al., 2019;Wang et al., 2021) to validate the acquired scientific knowledge, inject such knowledge into the model, and update the model's beliefs on demand and possibly in real-time.</p>
<p>Conclusions</p>
<p>In the future, scientific AI systems should be able to deal with questions like "What if liver cancer patients are treated with ifosfamide after treatment with trabectedin? and the other way around?", "What if the COVID-19 virus becomes 9% more infectious?", "What will be the consequences of noise associated with human activities in the Venice lagoon ecosystem?". Inspired by recent and revolutionary developments in AI, particularly in language understanding and generation, we set about designing AI systems that are able to propose their own strategies to address complex scientific tasks, including answering such questions and justifying their answers, as well as generating and evaluating research goals, hypotheses, and claims. Central to our approach is the notion of natural language as core representation, reasoning, and exchange format between AI systems and human scientists. Rather than providing an exhaustive list, in this paper we focus on some of the key research challenges that need to be addressed to accomplish such vision. 7 Science and Engineering publication output continues to grow on average at nearly 4% per year; from 2008 to 2018, output grew from 1.8 million to 2.6 million articles. In 2018, China (with a share of 21%) and the United States (with a share of 17%) were the largest producers. As a group, the EU countries (with a share of 24%) produced more articles than China or the United States. https://ncses.nsf.gov/pubs/nsb20206/ </p>
<p>SemanticWeb -ISWC 2020, Springer International Publishing, Cham. pp.  147-163.   Feigenbaum, E.A., 1984. Knowledge engineering: The applied side of artificial intelligence, in: Proc. of a Symposium on Computer Culture: The Scientific, Intellectual, and Social Impact of the Computer, New York Academy of Sciences, USA. p. 91-107. Gao, T., Fisch, A., Chen, D., 2021. Making pre-trained language models better few-shot learners, in: Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), Association for Computational Linguistics, Online. pp. 3816-3830. URL: https://aclanthology.org/2021.acl-long.295, doi:10.18653/v1/2021.acl-long.295. Garcia-Silva, A., Berrio, C., Gomez-Perez, J.M., Martínez-Heras, J.A., Donati, A., Roma, I., 2022. Spaceqa: Answering questions about the design of space missions and space craft concepts, in: Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval, Association for Computing Machinery, New York, NY, USA. p. 3306-3311. URL: https://doi.org/10.1145/3477495.3531697, doi:10.1145/3477495.3531697. Gil, Y., 2017. Thoughtful artificial intelligence: Forging a new partnership for data science and scientific discovery. Data Science 1. URL: http://www.isi.edu/~gil/papers/gil-ds17.pdf, doi:10.3233/DS-170011. https://ojs.aaai.org/index.php/aimagazine/article/view/18149, doi:10.1609/aimag.v42i4.18149. Gomez-Perez, J.M., Ortega, R., 2019. Look, read and enrich -learning from scientific figures and their captions, in: Proceedings of the 10th International Conference on Knowledge Capture, Association for Computing Machinery, New York, NY, USA. p. 101-108. URL: https://doi.org/10.1145/3360901.3364420, doi:10.1145/3360901.3364420.Gil, 
Y., 
2022. 
Will 
ai 
write 
scientific 
papers 
in 
the future? 
AI Magazine 42, 
3-15. 
URL: </p>
<p>https://allenai.org/data/diagrams
GPT-3, Bloviator: OpenAI's language generator has no idea what it's talking about https://www.technologyreview.com/2020/08/22/1007539/gpt3-openai-language-generator-artificial-in
https://www.openaire.eu 4 https://arxiv.org 5 https://clarivate.com/webofsciencegroup/solutions/web-of-science 6 https://www.semanticscholar.org</p>
<p>Observation of gravitational waves from a binary black hole merger. B P Abbott, LIGO Scientific Collaboration10.1103/PhysRevLett.116.061102doi:10.1103/PhysRevLett.116.061102and Virgo Collaboration). 11661102Abbott, B.P., et al. (LIGO Scientific Collaboration and Virgo Col- laboration), 2016. Observation of gravitational waves from a bi- nary black hole merger. Phys. Rev. Lett. 116, 061102. URL: https://link.aps.org/doi/10.1103/PhysRevLett.116.061102, doi:10.1103/PhysRevLett.116.061102.</p>
<p>Reason first, then respond: Modular generation for knowledge-infused dialogue. L Adolphs, K Shuster, J Urbanek, A D Szlam, J Weston, ArXiv abs/2111.05204Adolphs, L., Shuster, K., Urbanek, J., Szlam, A.D., Weston, J., 2021. Reason first, then respond: Modular generation for knowledge-infused dialogue. ArXiv abs/2111.05204.</p>
<p>SciBERT: A pretrained language model for scientific text. I Beltagy, K Lo, A Cohan, 10.18653/v1/D19-1371Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)Hong Kong, ChinaAssociation for Computational LinguisticsBeltagy, I., Lo, K., Cohan, A., 2019. SciBERT: A pretrained language model for scientific text, in: Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th Inter- national Joint Conference on Natural Language Processing (EMNLP- IJCNLP), Association for Computational Linguistics, Hong Kong, China. pp. 3615-3620. URL: https://aclanthology.org/D19-1371, doi:10.18653/v1/D19-1371.</p>
<p>Spacetransformers: Language modeling for space systems. A Berquand, P Darm, A Riccardi, 10.1109/ACCESS.2021.3115659IEEE Access. 9Berquand, A., Darm, P., Riccardi, A., 2021. Spacetransformers: Lan- guage modeling for space systems. IEEE Access 9, 133111-133122. doi:10.1109/ACCESS.2021.3115659.</p>
<p>Language models are few-shot learners. T Brown, B Mann, N Ryder, M Subbiah, J D Kaplan, P Dhariwal, A Neelakantan, P Shyam, G Sastry, A Askell, S Agarwal, A Herbert-Voss, G Krueger, T Henighan, R Child, A Ramesh, D Ziegler, J Wu, C Winter, C Hesse, M Chen, E Sigler, M Litwin, S Gray, B Chess, J Clark, C Berner, S Mccandlish, A Radford, I Sutskever, D Amodei, H Larochelle, M Ranzato, R Hadsell, M F Balcan, Advances in Neural Information Processing Systems. Lin, H.Curran Associates, IncBrown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert- Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., Amodei, D., 2020. Language models are few-shot learners, in: Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M.F., Lin, H. (Eds.), Advances in Neural Information Processing Systems, Curran Associates, Inc.. pp. 1877-1901.</p>
<p>Towards teachable reasoning systems. B Dalvi, O Tafjord, P Clark, ArXiv abs/2204.13074Dalvi, B., Tafjord, O., Clark, P., 2022. Towards teachable reasoning systems. ArXiv abs/2204.13074.</p>
<p>ISAAQ -mastering textbook questions with pre-trained transformers and bottom-up and top-down attention. R Denaux, J M Gomez-Perez, J Z Pan, V Tamma, C Amato, K Janowicz, B Fu, A Polleres, O Seneviratne, J M Perez, R Ortega, 10.18653/v1/2020.emnlp-main.441Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). Kagal, L.the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)OnlineAssociation for Computational LinguisticsLinked credibility reviews for explainable misinformation detectionDenaux, R., Gomez-Perez, J.M., 2020. Linked credibility reviews for explain- able misinformation detection, in: Pan, J.Z., Tamma, V., d'Amato, C., Janowicz, K., Fu, B., Polleres, A., Seneviratne, O., Kagal, L. (Eds.), The Gomez-Perez, J.M., Ortega, R., 2020. ISAAQ -mastering text- book questions with pre-trained transformers and bottom-up and top-down attention, in: Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Association for Computational Linguistics, Online. pp. 5469- 5479. URL: https://aclanthology.org/2020.emnlp-main.441, doi:10.18653/v1/2020.emnlp-main.441.</p>
<p>A framework and computer system for knowledge-level acquisition, representation, and reasoning with process knowledge. J M Gómez-Pérez, M Erdmann, M Greaves, O Corcho, R Benjamins, 10.1016/j.ijhcs.2010.05.004International Journal of Human-Computer Studies. 68Gómez-Pérez, J.M., Erdmann, M., Greaves, M., Corcho, O., Benjamins, R., 2010. A framework and computer system for knowledge-level acquisition, representation, and reasoning with process knowledge. International Journal of Human-Computer Studies 68, 641-668. URL: https://www.sciencedirect.com/science/article/pii/S1071581910000662, doi:https://doi.org/10.1016/j.ijhcs.2010.05.004.</p>
<p>A diagram is worth a dozen images. A Kembhavi, M Salvato, E Kolve, M Seo, H Hajishirzi, A Farhadi, Computer Vision -ECCV. Leibe, B., Matas, J., Sebe, N., Welling, M.ChamSpringer International PublishingKembhavi, A., Salvato, M., Kolve, E., Seo, M., Hajishirzi, H., Farhadi, A., 2016. A diagram is worth a dozen images, in: Leibe, B., Matas, J., Sebe, N., Welling, M. (Eds.), Computer Vision -ECCV 2016, Springer International Publishing, Cham. pp. 235-251.</p>
<p>Decomposed prompting: A modular approach for solving complex tasks. T Khot, H Trivedi, M Finlayson, Y Fu, K Richardson, P Clark, A Sabharwal, ArXiv abs/2210.02406Khot, T., Trivedi, H., Finlayson, M., Fu, Y., Richardson, K., Clark, P., Sabharwal, A., 2022. Decomposed prompting: A modular approach for solving complex tasks. ArXiv abs/2210.02406.</p>
<p>Artificial intelligence to win the nobel prize and beyond: Creating the engine for scientific discovery. H Kitano, 10.1609/aimag.v37i1.2642AI Magazine. 37Kitano, H., 2016. Artificial intelligence to win the nobel prize and beyond: Creating the engine for scientific discovery. AI Magazine 37, 39-49. URL: https://ojs.aaai.org/index.php/aimagazine/article/view/2642, doi:10.1609/aimag.v37i1.2642.</p>
<p>Visual genome: Connecting language and vision using crowdsourced dense image annotations. R Krishna, Y Zhu, O Groth, J Johnson, K Hata, J Kravitz, S Chen, Y Kalantidis, L J Li, D A Shamma, M S Bernstein, L Fei-Fei, 10.1007/s11263-016-0981-7doi:10.1007/s11263-016-0981-7Int. J. Comput. Vision. 123Krishna, R., Zhu, Y., Groth, O., Johnson, J., Hata, K., Kravitz, J., Chen, S., Kalantidis, Y., Li, L.J., Shamma, D.A., Bernstein, M.S., Fei-Fei, L., 2017. Visual genome: Connecting language and vision using crowdsourced dense image annotations. Int. J. Comput. Vi- sion 123, 32-73. URL: https://doi.org/10.1007/s11263-016-0981-7, doi:10.1007/s11263-016-0981-7.</p>
<p>BioBERT: a pre-trained biomedical language representation model for biomedical text mining. J Lee, W Yoon, S Kim, D Kim, S Kim, C H So, J Kang, 10.1093/bioinformatics/btz682doi:10.1093/bioinformatics/btz682Bioinformatics. 36Lee, J., Yoon, W., Kim, S., Kim, D., Kim, S., So, C.H., Kang, J., 2019. BioBERT: a pre-trained biomedical language repre- sentation model for biomedical text mining. Bioinformatics 36, 1234-1240. URL: https://doi.org/10.1093/bioinformatics/btz682, doi:10.1093/bioinformatics/btz682.</p>
<p>Microsoft COCO: common objects in context. T Lin, M Maire, S J Belongie, L D Bourdev, R B Girshick, J Hays, P Perona, D Ramanan, P Doll&apos;a R, C L Zitnick, arXiv:1405.0312Lin, T., Maire, M., Belongie, S.J., Bourdev, L.D., Girshick, R.B., Hays, J., Perona, P., Ramanan, D., Doll'a r, P., Zitnick, C.L., 2014. Mi- crosoft COCO: common objects in context. CoRR abs/1405.0312. URL: http://arxiv.org/abs/1405.0312, arXiv:1405.0312.</p>
<p>A survey on multi-hop question answering and generation. V Mavi, A Jangra, A Jatowt, ArXiv abs/2204.09140Mavi, V., Jangra, A., Jatowt, A., 2022. A survey on multi-hop question answering and generation. ArXiv abs/2204.09140.</p>
<p>Preliminary Steps Toward a Taxonomy of Problem-Solving Methods. J Mcdermott, 10.1007/978-1-4684-7122-9_8doi:10.1007/978-1-4684-7122-9_8Springer USBoston, MAMcdermott, J., 1988. Preliminary Steps Toward a Taxonomy of Problem-Solving Methods. Springer US, Boston, MA. pp. 225-256. URL: https://doi.org/10.1007/978-1-4684-7122-9_8, doi:10.1007/978-1-4684-7122-9_8.</p>
<p>Multi-reward reinforced summarization with saliency and entailment. R Pasunuru, M Bansal, 10.18653/v1/N18-2102Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesNew Orleans, LouisianaAssociation for Computational Linguistics2Short PapersPasunuru, R., Bansal, M., 2018. Multi-reward reinforced summarization with saliency and entailment, in: Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers), Association for Computational Linguistics, New Orleans, Louisiana. pp. 646-653. URL: https://aclanthology.org/N18-2102, doi:10.18653/v1/N18-2102.</p>
<p>Knowledge enhanced contextual word representations. M E Peters, M Neumann, R Logan, R Schwartz, V Joshi, S Singh, N A Smith, 10.18653/v1/D19-1005Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)Hong Kong, ChinaAssociation for Computational LinguisticsPeters, M.E., Neumann, M., Logan, R., Schwartz, R., Joshi, V., Singh, S., Smith, N.A., 2019. Knowledge enhanced contextual word represen- tations, in: Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Con- ference on Natural Language Processing (EMNLP-IJCNLP), Association for Computational Linguistics, Hong Kong, China. pp. 43-54. URL: https://aclanthology.org/D19-1005, doi:10.18653/v1/D19-1005.</p>
<p>Exploring the limits of transfer learning with a unified text-to-text transformer. C Raffel, N Shazeer, A Roberts, K Lee, S Narang, M Matena, Y Zhou, W Li, P J Liu, Journal of Machine Learning Research. 21Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., Liu, P.J., 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of Machine Learning Research 21, 1-67. URL: http://jmlr.org/papers/v21/20-074.html.</p>
<p>Foundations and grand challenges of artificial intelligence: Aaai presidential address. R Reddy, 10.1609/aimag.v9i4.950AI Magazine. 9Reddy, R., 1988. Foundations and grand challenges of artificial in- telligence: Aaai presidential address. AI Magazine 9, 9. URL: https://www.aaai.org/ojs/index.php/aimagazine/article/view/950, doi:10.1609/aimag.v9i4.950.</p>
<p>Exploiting cloze-questions for fewshot text classification and natural language inference. T Schick, H Schütze, 10.18653/v1/2021.eacl-main.20Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main VolumeAssociation for Computational LinguisticsSchick, T., Schütze, H., 2021. Exploiting cloze-questions for few- shot text classification and natural language inference, in: Pro- ceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, Association for Computational Linguistics, Online. pp. 255- 269. URL: https://aclanthology.org/2021.eacl-main.20, doi:10.18653/v1/2021.eacl-main.20.</p>
<p>Fact or fiction: Verifying scientific claims. D Wadden, S Lin, K Lo, L L Wang, M Van Zuylen, A Cohan, H Hajishirzi, 10.18653/v1/2020.emnlp-main.609Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)OnlineAssociation for Computational LinguisticsWadden, D., Lin, S., Lo, K., Wang, L.L., van Zuylen, M., Co- han, A., Hajishirzi, H., 2020. Fact or fiction: Verifying sci- entific claims, in: Proceedings of the 2020 Conference on Em- pirical Methods in Natural Language Processing (EMNLP), Association for Computational Linguistics, Online. pp. 7534- 7550. URL: https://aclanthology.org/2020.emnlp-main.609, doi:10.18653/v1/2020.emnlp-main.609.</p>
<p>R Wang, D Tang, N Duan, Z Wei, X Huang, J Ji, G Cao, D Jiang, M Zhou, 2021. K-Adapter, 10.18653/v1/2021.findings-acl.121Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. OnlineAssociation for Computational LinguisticsWang, R., Tang, D., Duan, N., Wei, Z., Huang, X., Ji, J., Cao, G., Jiang, D., Zhou, M., 2021. K-Adapter: Infus- ing Knowledge into Pre-Trained Models with Adapters, in: Find- ings of the Association for Computational Linguistics: ACL-IJCNLP 2021, Association for Computational Linguistics, Online. pp. 1405- 1418. URL: https://aclanthology.org/2021.findings-acl.121, doi:10.18653/v1/2021.findings-acl.121.</p>
<p>Chain of thought prompting elicits reasoning in large language models. J Wei, X Wang, D Schuurmans, M Bosma, E Chi, Q Le, D Zhou, ArXiv abs/2201.11903Wei, J., Wang, X., Schuurmans, D., Bosma, M., Chi, E., Le, Q., Zhou, D., 2022. Chain of thought prompting elicits reasoning in large language models. ArXiv abs/2201.11903.</p>
<p>Think before you speak: Explicitly generating implicit commonsense knowledge for response generation. P Zhou, K Gopalakrishnan, B Hedayatnia, S Kim, J Pujara, X Ren, Y Liu, D Hakkani-Tur, 10.18653/v1/2022.acl-long.88Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. the 60th Annual Meeting of the Association for Computational LinguisticsDublin, IrelandAssociation for Computational Linguistics1Long Papers)Zhou, P., Gopalakrishnan, K., Hedayatnia, B., Kim, S., Pujara, J., Ren, X., Liu, Y., Hakkani-Tur, D., 2022. Think before you speak: Explicitly generating implicit commonsense knowledge for re- sponse generation, in: Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Pa- pers), Association for Computational Linguistics, Dublin, Ireland. pp. 1237-1252. URL: https://aclanthology.org/2022.acl-long.88, doi:10.18653/v1/2022.acl-long.88.</p>            </div>
        </div>

    </div>
</body>
</html>