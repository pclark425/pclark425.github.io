<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3665 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3665</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3665</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-91.html">extraction-schema-91</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or studies that use large language models (LLMs) to distill theories or synthesize knowledge from large collections of scholarly papers, including details about the method, input corpus, topic/query specification, output, evaluation, results, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-615c34193a26b8a5dc04407d777ea0ff81114fb5</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/615c34193a26b8a5dc04407d777ea0ff81114fb5" target="_blank">An Analysis on Large Language Models in Healthcare: A Case Study of BioBERT</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> This research explores the path that led to the incorporation of BioBERT into healthcare applications, highlighting its suitability for addressing the specific requirements of tasks related to biomedical text mining and explores techniques to improve the model's interpretability and validates its performance compared to existing healthcare-focused language models.</p>
                <p><strong>Paper Abstract:</strong> This paper conducts a comprehensive investigation into applying large language models, particularly on BioBERT, in healthcare. It begins with thoroughly examining previous natural language processing (NLP) approaches in healthcare, shedding light on the limitations and challenges these methods face. Following that, this research explores the path that led to the incorporation of BioBERT into healthcare applications, highlighting its suitability for addressing the specific requirements of tasks related to biomedical text mining. The analysis outlines a systematic methodology for fine-tuning BioBERT to meet the unique needs of the healthcare domain. This approach includes various components, including the gathering of data from a wide range of healthcare sources, data annotation for tasks like identifying medical entities and categorizing them, and the application of specialized preprocessing techniques tailored to handle the complexities found in biomedical texts. Additionally, the paper covers aspects related to model evaluation, with a focus on healthcare benchmarks and functions like processing of natural language in biomedical, question-answering, clinical document classification, and medical entity recognition. It explores techniques to improve the model's interpretability and validates its performance compared to existing healthcare-focused language models. The paper thoroughly examines ethical considerations, particularly patient privacy and data security. It highlights the benefits of incorporating BioBERT into healthcare contexts, including enhanced clinical decision support and more efficient information retrieval. Nevertheless, it acknowledges the impediments and complexities of this integration, encompassing concerns regarding data privacy, transparency, resource-intensive requirements, and the necessity for model customization to align with diverse healthcare domains.</p>
                <p><strong>Cost:</strong> 0.008</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3665.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3665.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, systems, or studies that use large language models (LLMs) to distill theories or synthesize knowledge from large collections of scholarly papers, including details about the method, input corpus, topic/query specification, output, evaluation, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Transformer-Highlights</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Transformer-based highlights extraction from scientific papers</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A transformer-based approach for extracting concise highlights or summaries from scientific papers, intended to synthesize key points from scholarly documents.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Transformer-based highlights extraction from scientific papers</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>Transformer-based highlights extraction</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_description</strong></td>
                            <td>A transformer model applied to scientific papers to extract 'highlights' (concise salient sentences or summary elements) from scholarly documents; described in the cited work as a transformers-based summarization/highlight extraction method for scientific literature.</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>topic_or_query_specification</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td>Transformer-based summarization / highlight extraction (as implied by the title); exact algorithmic details (e.g., supervised extraction, abstractive summarization, or training data) are not provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type_and_format</strong></td>
                            <td>Extracted highlights or concise summaries of scientific papers (textual highlights), as indicated by the method's purpose.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_or_validation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baselines_or_humans</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'An Analysis on Large Language Models in Healthcare: A Case Study of BioBERT', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Transformer-based highlights extraction from scientific papers <em>(Rating: 2)</em></li>
                <li>Biobert: a pre-trained biomedical language representation model for biomedical text mining <em>(Rating: 1)</em></li>
                <li>Large language models encode clinical knowledge <em>(Rating: 2)</em></li>
                <li>Huatuogpt, towards taming language model to be a doctor <em>(Rating: 1)</em></li>
                <li>Towards expert-level medical question answering with large language models <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3665",
    "paper_id": "paper-615c34193a26b8a5dc04407d777ea0ff81114fb5",
    "extraction_schema_id": "extraction-schema-91",
    "extracted_data": [
        {
            "name_short": "Transformer-Highlights",
            "name_full": "Transformer-based highlights extraction from scientific papers",
            "brief_description": "A transformer-based approach for extracting concise highlights or summaries from scientific papers, intended to synthesize key points from scholarly documents.",
            "citation_title": "Transformer-based highlights extraction from scientific papers",
            "mention_or_use": "mention",
            "system_or_method_name": "Transformer-based highlights extraction",
            "system_or_method_description": "A transformer model applied to scientific papers to extract 'highlights' (concise salient sentences or summary elements) from scholarly documents; described in the cited work as a transformers-based summarization/highlight extraction method for scientific literature.",
            "input_corpus_description": null,
            "topic_or_query_specification": null,
            "distillation_method": "Transformer-based summarization / highlight extraction (as implied by the title); exact algorithmic details (e.g., supervised extraction, abstractive summarization, or training data) are not provided in this paper.",
            "output_type_and_format": "Extracted highlights or concise summaries of scientific papers (textual highlights), as indicated by the method's purpose.",
            "evaluation_or_validation_method": null,
            "results_summary": null,
            "limitations_or_challenges": null,
            "comparison_to_baselines_or_humans": null,
            "uuid": "e3665.0",
            "source_info": {
                "paper_title": "An Analysis on Large Language Models in Healthcare: A Case Study of BioBERT",
                "publication_date_yy_mm": "2023-10"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Transformer-based highlights extraction from scientific papers",
            "rating": 2,
            "sanitized_title": "transformerbased_highlights_extraction_from_scientific_papers"
        },
        {
            "paper_title": "Biobert: a pre-trained biomedical language representation model for biomedical text mining",
            "rating": 1,
            "sanitized_title": "biobert_a_pretrained_biomedical_language_representation_model_for_biomedical_text_mining"
        },
        {
            "paper_title": "Large language models encode clinical knowledge",
            "rating": 2,
            "sanitized_title": "large_language_models_encode_clinical_knowledge"
        },
        {
            "paper_title": "Huatuogpt, towards taming language model to be a doctor",
            "rating": 1,
            "sanitized_title": "huatuogpt_towards_taming_language_model_to_be_a_doctor"
        },
        {
            "paper_title": "Towards expert-level medical question answering with large language models",
            "rating": 1,
            "sanitized_title": "towards_expertlevel_medical_question_answering_with_large_language_models"
        }
    ],
    "cost": 0.008123499999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>An Analysis on Large Language Models in Healthcare: A Case Study of BioBERT</h1>
<p>A Preprint</p>
<p>Shyni Sharaf<br>School of Computer Science and Engineering<br>Kerala University of Digital Sciences-<br>Innovation and Technology<br>Thiruvananthapuram, India<br>shyni.cs22@duk.ac.in</p>
<p>V. S. Anoop<br>Applied NLP Research Lab<br>School of Digital Sciences<br>Kerala University of Digital Sciences-<br>Innovation and Technology<br>Thiruvananthapuram, India<br>anoop.vs@duk.ac.in</p>
<h4>Abstract</h4>
<p>This paper conducts a comprehensive investigation into applying large language models, particularly on BioBERT, in healthcare. It begins with thoroughly examining previous natural language processing (NLP) approaches in healthcare, shedding light on the limitations and challenges these methods face. Following that, this research explores the path that led to the incorporation of BioBERT into healthcare applications, highlighting its suitability for addressing the specific requirements of tasks related to biomedical text mining. The analysis outlines a systematic methodology for fine-tuning BioBERT to meet the unique needs of the healthcare domain. This approach includes various components, including the gathering of data from a wide range of healthcare sources, data annotation for tasks like identifying medical entities and categorizing them, and the application of specialized preprocessing techniques tailored to handle the complexities found in biomedical texts. Additionally, the paper covers aspects related to model evaluation, with a focus on healthcare benchmarks and functions like processing of natural language in biomedical, question-answering, clinical document classification, and medical entity recognition. It explores techniques to improve the model's interpretability and validates its performance compared to existing healthcare-focused language models. The paper thoroughly examines ethical considerations, particularly patient privacy and data security. It highlights the benefits of incorporating BioBERT into healthcare contexts, including enhanced clinical decision support and more efficient information retrieval. Nevertheless, it acknowledges the impediments and complexities of this integration, encompassing concerns regarding data privacy, integrity, bias mitigation, transparency, resource-intensive requirements, and the necessity for model customization to align with diverse healthcare domains.</p>
<p>Keywords Large language models $\cdot$ Healthcare $\cdot$ BioBERT $\cdot$ Health informatics $\cdot$ Natural Language Processing</p>
<h2>1 Introduction</h2>
<p>NLP processing has evolved to become LLM (Large Language Model). In the 1940s, after World War II, people realized the importance of translation between languages and wanted to create a machine that could perform automatic translation. Early NLP systems were rule-based systems that humans manually programmed with rules for processing language. These systems often had many limitations in handling complex language and could be easily deceived by unexpected inputs. In the early 2000s, statistical NLP models began to emerge. These models were trained on large text datasets and learned to predict the next word in a sequence based on preceding words. Statistical NLP models exhibited greater robustness compared to rule-based systemsWang et al. [2023a] and could handle a wider range of language tasks. By the mid-2010s, deep learning models started to revolutionize NLP. These models, based on artificial neural networks, had the capability to learn intricate patterns from data. Deep learning models Lavanya and Sasikala [2021]quickly outperformed statistical NLP models such as machine translation, summarization of texts, and question answering. In 2017, the Transformer La Quatra and Cagliero [2022]a deep learning model designed for processing</p>
<p>sequential data, such as text, marked a significant milestone. It achieved state-of-the-art results across numerous NLP tasks and soon became the standard architecture for training LLMs. This shift led to the emergence of natural language processing (NLP) as we know it today. NLP has radically transformed into the era of large language models (LLMs).</p>
<p>LLMs are trained on massive text datasets, sometimes containing hundreds of billions or even trillions of words. This extensive training enables LLMs to understand the intricate patterns and relationships inherent in language. As a result, LLMs have fundamentally altered how we interact with and harness the power of language. Popular LLMs like GPT-3.5, GPT-4, PaLM, Cohere, LaMDA, Llama, and others have revolutionized our interaction with data by redefining the boundaries of language understanding and generation. Natural Language Processing (NLP) is a branch of artificial intelligence (AI) and computational linguistics that facilitates interaction between computers and humans through natural language. LLMsReddy [2023]process vast amounts of textual data, learn the underlying patterns, and generate contextually relevant human-like text. This technology has not only catalyzed but has become a driving force in transforming healthcare and biomedical applications. In this article, we conduct a comparative analysis of the diverse applications of LLMs in the healthcare and biomedical domains. We explore how LLMs are reshaping the landscape by offering innovative solutions to long-standing challenges. Current healthcare and biomedical systems often operate inefficiently, have limited access to relevant information, and involve cumbersome documentation processes. LLMs can address these challenges by providing rapid, context-aware responses to medical queries, extracting valuable insights from unstructured data, and automating clinical documentation. The major contributions of this article are as follows:</p>
<ul>
<li>Conducts a detailed evaluation of the existing prominent state-of-the-art large language models introduced in the healthcare domain.</li>
<li>Taking BioBERT as a reference pre-trained language model, we check the applications of the same in healthcare.</li>
<li>Discusses the prominence of BioBERT in downstream clinical natural language processing tasks and discusses them in detail.</li>
<li>Outlines the challenges with LLM in healthcare and presents the future research directions.</li>
</ul>
<h1>1.1 An overview of LLM components</h1>
<ul>
<li>Input Text: Initially, the LLM receives raw text as input. This text can be in sentences, paragraphs, or documents.</li>
<li>Tokenization: The text we give is divided into individual tokens. Tokens can be words, subwords, or characters, depending on LLMs tokenization scheme. This step breaks down the text into manageable units for processing.</li>
<li>Word Embeddings: Each token is transformed into a high-dimensional vector through word embeddings. These vectors capture the token's meaning and context. Word embeddings are learned during the model's training using a vast amount of text data.</li>
<li>Transformer Layers: The embedded vectors are passed through multiple transformer layers. Each transformer layer consists of two main components:</li>
<li>Multi-Head Self-Attention: This component weighs the importance of each token in relation to others, capturing dependencies and context.</li>
<li>Feedforward Neural Networks: Complex transformations are applied to the vectors, enhancing the model's understanding of patterns and relationships.</li>
<li>Output Layer: After processing through the transformer layers, the output is fed into a linear layer. This linear layer generates a probability distribution that spans the model's vocabulary. It estimates the probability of different words or word sequences following the input text.</li>
<li>Probability Estimation: The probability distribution generated in the previous step is used for various tasks such as language generation, text completion, and question answering.</li>
<li>Training and Fine-Tuning: LLMs are initially trained on a large text corpus to learn embeddings and model parameters. Fine-tuning can follow, where the model is further trained on task-specific data to adapt its language understanding to the specific task or domain.</li>
</ul>
<h2>2 NLP for Healthcare Applications</h2>
<p>LLMs have emerged as a transformative technology in healthcare, enabling an extensive range of applications, from clinical decision support to medical data analysis. LLMs allow healthcare professionals to harness the power of language data for improved patient care, research, and administrative tasks.</p>
<ul>
<li>Medical Question Answering: LLMs can answer medical questions, providing quick and accurate responses. This application aids healthcare professionals in accessing medical knowledge and information rapidly.</li>
<li>Electronic Health Record (EHR) Analysis: LLMs can analyze unstructured text in electronic health records, extracting valuable insights about patient histories, diagnoses, treatments, and clinical notes. This supports clinical decision-making and research.</li>
<li>Clinical Documentation: LLMs can assist healthcare providers in generating clinical notes, reports, and documentation. This streamlines the documentation process, allowing clinicians to focus more on patient care.</li>
<li>Medical Imaging: LLMs can assist in medical image interpretation by generating natural language descriptions of images. This can improve communication between radiologists and referring physiciansWang et al. [2023b]Rao et al. [2023].</li>
<li>Clinical Decision Support: LLMs can provide context-aware information to support clinical decisions. They can recommend treatment options, predict patient outcomes, and identify potential risks Rao et al. [2023].</li>
<li>Healthcare Communication: LLMs can improve doctor-patient communication by offering language translation services, ensuring effective communication in multilingual healthcare settings Yunxiang et al. [2023]</li>
<li>Patient Engagement: LLMs can be used in chatbots and virtual assistants Ray [2023] to engage with patients, answer their healthcare queries, and provide health-related information and guidance. Healthcare professionals can use NLP to extract relevant information from patient records, such as medical history, medication allergies, and previous diagnoses, enabling the creation of personalized treatment plans and early identification of high-risk patients for disease prevention.</li>
<li>Enhancing Medical Research: NLP can also analyze large amounts of medical data to identify patterns and trendsHao et al. [2018]. It helps researchers to develop new treatments and therapies.</li>
<li>Improving Clinical Trials: NLP algorithms can sift through much data and extract information relevant to the clinical trial. NLP helps clinical trials Chen et al. [2020]by finding the right participants faster and cheaper through patient data analysis and improves efficiency. It reduces the time and cost.</li>
<li>Improving Digital Health Records: NLP can make digital patient records more correct and complete. These records hold information about a person's health history and treatments. NLP helps doctors to get the right details from these health records Costea [2020]so they can make better decisions for patient care.</li>
<li>Supports Medical Practitioners: NLP makes many everyday tasks of health professionals easierDemnerFushman et al. [2009]. For instance, it finds possible issues with medicines, helps doctors adjust treatment plans, and helps doctors write notes faster by saving time and reducing errors, so they can spend more time caring for patients. Also, NLP aids in extracting Information from medical literature, helping healthcare professionals to learn Henwood and Lister [2007]stay current with the latest research and best practices.</li>
</ul>
<h1>3 Language Models and Healthcare</h1>
<p>Large Language Models (LLMs) are one of the most exciting areas in Artificial Intelligence (AI) research that have the ability to process and generate human-like text for various healthcare applications. The more data we train, the more predictions will be more accurate. Mainly used LLM are GPT-3, BERT, and RoBERTa Liu et al. [2019], which are trained on billions of words and patterns. so these models can understand the structure easily and generate text. Once the model is generated it can be fine-tuned for a specific Task. The applications of LLM Hao et al. [2018] healthcare have many different aspects and have the power to bring about significant positive changes in various fields. These technologies offer real-time assistance to healthcare professionals by helping them diagnose diseases and give the right treatments without Errors. Predictive Analytics in healthcare can use data to predict disease outbreaks and enhance healthcare delivery efficiency. The significance of studying LLM applications in healthcare is that it is versatile. LLMs should be used in healthcare in a collaborative and verified way to ensure responsible and effective use, ultimately improving patient care. This means the use of LLMs should be carefully monitored and evaluated, and thereby identifying potential problems or risks. LLMs are a powerful tool that has the potential to revolutionize healthcare.</p>
<h3>3.1 Benefits of LLMs in Healthcare:</h3>
<ul>
<li>
<p>Improved Support for Clinical Decisions: LLMs assist healthcare providers in decision-making by providing access to a vast amount of medical knowledge and up-to-date research. They can suggest potential diagnoses, treatment options, or relevant research articles quickly. LLMs can make the diagnosis and data more accurate than humans; thereby, the quality of outcomes and care of patients can be improved.</p>
</li>
<li>
<p>Efficient Information Retrieval: LLMs can be used to clarification medical tests by analyzing the results providing valuable information and helping to find out the abnormalities. By this, we can reduce the time and cost of interpreting the results and improve accuracy and reliability.</p>
</li>
<li>Clarification of Medical Tests: LLMs can identify clinical trials by analyzing the current conditions of the patient, medical history, and treatment plans. This will improve the efficiency and effectiveness and provide potential lifesaving treatments.</li>
<li>Searching for Potential Clinical Trials: LLMs can identify clinical trials by analyzing the current conditions of the patient, medical history, and treatment plans. This will improve the efficiency and effectiveness and provide potential lifesaving treatments</li>
</ul>
<h1>3.2 Limitations and Challenges of Using LLMs in Healthcare</h1>
<ul>
<li>Data Privacy and Security: Integrating LLMs into healthcare must proceed cautiously to safeguard highly sensitive healthcare data. Ensuring data privacy and security, along with compliance with regulations such as HIPAA, is paramount to prevent the potentially severe consequences of data breaches.</li>
<li>Bias and Fairness: LLMs trained on biased data may produce biased or unfair results in healthcare applications. This can lead to disparities in care, misdiagnoses, or unfair allocation of resources.</li>
<li>Lack of Transparency: LLMs often operate as "black boxes," making it challenging to understand their decision-making processes. This lack of transparency can hinder trust among healthcare professionals and patients.</li>
<li>Quality Control: Ensuring the quality and accuracy of information generated or retrieved by LLMs is crucial. Erroneous information or recommendations could harm patients or mislead healthcare providers.</li>
<li>Concern of Ethical issues: Using LLMs in healthcare raises ethical concerns, such as the potential for technology to replace human interaction in patient care, leading to depersonalized medicine.</li>
<li>Resource Intensiveness: Developing, fine-tuning, and maintaining LLMs for healthcare can be resourceintensive regarding computational power, data annotation, and expert oversight.</li>
<li>Generalization Challenges: LLMs may struggle with generalizing to specific healthcare domains, specialties, or rare conditions if not adequately fine-tuned. Customization may be necessary.</li>
</ul>
<h2>4 Related Studies</h2>
<p>In this section, we review relevant articles that have explored the integration of LLMs in healthcare applications. The articles showcase the significant impact of large language models in various healthcare-related tasks, such as biomedical text mining, medical image interpretation, medical question answering, and processing electronic health records. They also highlight the need for careful evaluation and consideration of limitations when applying these models in clinical settings. The strengths include improved task performance and potential benefits for healthcare However, the resource-intensive nature of such models and potential challenges in fine-tuning for specific healthcare applications should be considered. N. Kang et al. Kang et al. [2013]primarily focus on evaluating the performance of MetaMap and Peregrine tools used for biomedical concept normalization. The study investigates the usefulness of rule-based NLP modules that are used to enhance the performance of MetaMap and Peregrine, an adjunct to dictionary-based concept normalization in the biomedical field, to evaluate the Corpus for Arizona Disease.
S. A. Hasan et al. Hasan and Farri [2019] discuss the application of deep learning(DL) techniques in clinical natural language processing (CNLP). The model emphasizes the use of DL models for various clinical applications. Deep learning-driven clinical NLP applications include diagnostic inferencing, biomedical article retrieval, clinical paraphrase generation, adverse drug event detection, and medical image caption generation. J. Lee et al. lee2020biobertLee et al. [2020]introduced BioBERT, a pre-trained biomedical language representation model tailored for biomedical text mining. BioBERT's training involved a substantial biomedical text corpus. This model excelled in various tasks such as named entity recognition, relation extraction, and question answering, achieving state-of-the-art performance across the board.</p>
<p>Shin et al.Shin et al. [2020]contributed to the field with BioMegatron, a larger pre-trained biomedical language model aimed at biomedical text mining analogous to BioBERT. Differing in scale, BioMegatron was trained on an even more extensive corpus of biomedical text and exhibited state-of-the-art performance in tasks such as entity recognition, relation extraction, and question-answering. Additionally, X. Yang et al.Yang et al. [2022a] presented GatorTron, a substantial clinical language model created for processing and interpreting electronic health records (EHRs). With extensive scaling in model parameters and training data, GatorTron significantly improved performance across clinical NLP tasks, offering potential enhancements in healthcare-related natural language processing by evaluating it on 5 clinical NLP tasks like clinical concept extraction, medical relation extraction, semantic textual similarity, natural</p>
<p>Table 1: Some state-of-the-art approaches in using LLM and related techniques in the healthcare NLP</p>
<table>
<thead>
<tr>
<th>Author</th>
<th>Model</th>
<th>Methodology</th>
</tr>
</thead>
<tbody>
<tr>
<td>N. Kang et al. Kang et al. [2013]</td>
<td>Rule-based NLP</td>
<td>A rule-based NLP module used to enhance the performance of MetaMap and Peregrine.</td>
</tr>
<tr>
<td>S. A. Hasan et al. Hasan and Farri [2019]</td>
<td>Deep Learning</td>
<td>Addresses the challenges posed by clinical documents, including acronyms, nonstandard clinical jargon, inconsistent document structure, and privacy concerns.</td>
</tr>
<tr>
<td>J. Lee et al. Lee et al. [2020]</td>
<td>BioBERT</td>
<td>Pre-training on large-scale biomedical corpora outperforms BERT and other models in biomedical textmining tasks.</td>
</tr>
<tr>
<td>HC Shin et al. Shin et al. [2020]</td>
<td>BioMegatron</td>
<td>Empirical study on factors affecting domain-specific language models, pre-training on larger domain corpus.</td>
</tr>
<tr>
<td>X. Yang et al. Yang et al. [2022b]</td>
<td>GatorTron</td>
<td>Developing a large clinical language model, scaling up the number of parameters and training data.</td>
</tr>
<tr>
<td>K. Singhal et al.Singhal et al. [2022]</td>
<td>MultiMedQA, PaLM, Flan-PaLM, Med-PaLM</td>
<td>MultiMedQA benchmark, human evaluation of model answers, instruction prompt tuning.</td>
</tr>
<tr>
<td>Wang et al.Wang et al. [2023b] [5]</td>
<td>ChatGPT, CAD networks</td>
<td>Integrating LLMs with CAD networks, enhancing output with natural language text.</td>
</tr>
<tr>
<td>S. Reddy et al.Reddy [2023]</td>
<td>$-$</td>
<td>Discusses the potential use of Large Language Models (LLMs) in healthcare. Highlights concerns related to misinformation and data falsification. Proposes a framework for evaluation, including human assessments.</td>
</tr>
<tr>
<td>H. Zhang et al. Zhang et al. [2023]</td>
<td>HuatuoGPT</td>
<td>Leveraging distilled data from ChatGPT and real-world data from doctors for medical consultation, reward model training.</td>
</tr>
<tr>
<td>K. Singhal et al.Singhal et al. [2023]</td>
<td>Med-PaLM - 2</td>
<td>Improving upon Med-PaLM with base LLM improvements, medical domain fine-tuning, and prompting strategies.</td>
</tr>
</tbody>
</table>
<p>language inference (NLI), and medical question answering (MQA).
J.Singhal et al.Singhal et al. [2022]explored the encoding of clinical knowledge using Large Language Models. They demonstrated that training LLMs on extensive clinical text enabled them to accurately answer questions related to clinical concepts, showcasing their potential in encoding clinical knowledge. They proposed a robust framework for human evaluation of model responses, incorporating factors such as factuality, precision, potential harm, and bias into the assessment process. PaLM, and its instruction-tuned variant, Flan-PaLM, were evaluated using MultiMedQA. Wang et al.Wang et al. [2023b]presented Chatcad, a large language model designed for interactive computer-aided diagnosis (CAD) in medical image analysis. Trained on a dataset featuring medical images and their accompanying text descriptions, Chatcad demonstrated the ability to accurately diagnose diseases from images, aiding radiologists in their diagnoses.
S. Reddy et al.Kang et al. [2013]reddy2023evaluatingintroduced a framework for evaluating the translational value of Large Language Models (LLMs) in healthcare. This framework was a comprehensive tool for assessing LLMs' performance in healthcare applications. It was subsequently employed to assess the NLP performance of LLM's on the grounds of not assessing the models' functional, utility, and ethical aspects as they apply to healthcare, and recommended governance aspects of LLMs in healthcare are required. Zhang et al.Zhang et al. [2023]unveiled HuatuoGPT, a specialized LLM tailored for medical consultation. By leveraging data from ChatGPT and realworld doctors, HuatuoGPT was fine-tuned to provide clinical advice and support to patients. This unique approach improved its performance, achieving state-of-the-art results in medical consultation tasks. K. Singhal et al.Singhal et al. [2023]introduced Med-PaLM 2, an LLM designed for expert-level medical question answering. This model achieved remarkable scores in medical question-answering tasks with a score of $67.2 \%$ on the MedQA dataset, highlighting its potential for delivering high-precision performance to medical question answering.</p>
<h1>5 An Analysis of LLMs in Healthcare - A Case Study of BioBERT</h1>
<p>In this section, we delve into the methodologies and outcomes of the aforementioned articles. We assess how LLMs are employed to address healthcare challenges and explore their impact on various aspects of the healthcare industry.</p>
<p>The paper "BioBERT: a pre-trained biomedical language representation model for biomedical text mining" by J Lee et al. Lee et al. [2020] investigates how the recently introduced pre-trained language model BERT can be adapted for biomedical corpora. In this article, we explore the possibility of Fine-tuning BioBERT for the healthcare domain, which can be a valuable endeavor given its success in biomedical text-mining tasks. To adapt BioBERT for healthcare applications, methodology outlines the steps and considerations for fine-tuning BioBERT for healthcare-specific tasks. It emphasizes the importance of domain expertise, data quality, and ethical considerations in developing robust and reliable healthcare language models. To adapt BioBERT for healthcare applications, the following methodology can be considered:</p>
<ul>
<li>Data Collection: Gather a comprehensive and diverse dataset from healthcare and biomedical sources. This dataset should include electronic health records (EHRs) Yang et al. [2022a]medical literature, clinical notes, medical imaging reports, and other relevant sources. And annotate the data for various healthcare-related tasks, such as medical entity recognition (e.g., disease names, medications, procedures), medical text classification (e.g., diagnosis prediction, disease classification), and medical question-answeringSinghal et al. [2023].</li>
<li>Pre-processing: Prepare the data by cleaning and formatting it for training. This may involve standardizing medical terms, removing duplicates, removing any errors or inconsistencies in the data, and handling missing values. Then Customize tokenization to accommodate the unique vocabulary and structure of biomedical and clinical texts. Clinical text data often contains specialized vocabulary and structure, so it is important to use a customized tokenizer for this type of data. Hence specialized tokenizers may be needed to handle medical terminology, abbreviations, and symbols. Some common tokenizers for biomedical and clinical text data include:</li>
<li>The BioBERT tokenizer. This tokenizer is based on the BERT tokenizer but has been customized to handle medical terminology and abbreviations.</li>
<li>The MedTokenizer. This tokenizer is specifically designed for biomedical text data.</li>
<li>The SciBERT tokenizer. This tokenizer is designed for scientific text data, which includes biomedical text.
<img alt="img-0.jpeg" src="img-0.jpeg" /></li>
</ul>
<p>Figure 1: Overall architecture for BioBERT Pre-training</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Overall architecture for BioBERT Finetuning</p>
<p>BioBERT is a pre-trained language model trained on a massive dataset of biomedical text. The pre-trained weights represent the model's understanding of the general structure and semantics of biomedical text. Design a set of downstream tasks specific to healthcare. Many different downstream tasks can be performed using BioBERT. Some common tasks include:</p>
<ul>
<li>Medical Entity Recognition: This task involves identifying and extracting medical entities from text. These entities can include diseases, medications, and medical procedures.</li>
<li>Medical Text Classification: In this task, the text is categorized into different healthcare-related categories. Examples of categories include diagnosis, prognosis, and treatment.</li>
<li>Disease Prediction: This task involves predicting the likelihood of a patient having a particular disease.</li>
<li>Medical Question-Answering: This task involves answering questions about medical topics based on text.</li>
</ul>
<p>Fine-tune BioBERT on these tasks using the annotated healthcare dataset. Fine-tuning is adjusting the model's weights to improve performance on a specific task. This is done by feeding the model the annotated healthcare dataset and letting it learn from it. Apply appropriate loss functions. A loss function measures the model's performance on the task. The loss function is used to update the model's weights during fine-tuning. Incorporate transfer learning techniques: Transfer learning involves using a model trained on one task to enhance the performance of a model on a distinct task. This can be achieved by initializing the new model with the pre-trained model's weights. Conduct experiments on hyperparameters. Hyperparameters represent the configurations of the machine learning algorithm and significantly influence the model's performance. Common hyperparameters to explore encompass:</p>
<ul>
<li>Adjust the learning rate, which dictates the magnitude of weight updates in each training iteration.</li>
<li>Vary the batch size, determining the quantity of samples utilized for weight updates in each training iteration.</li>
<li>Modify the number of epochs, specifying how often the model undergoes training on the data.</li>
</ul>
<h1>5.1 Evaluation Metrics:</h1>
<p>Assess the fine-tuned BioBERT model across a range of healthcare-related benchmarks and tasks. These include biomedical NLP tasks, medical question-answering, clinical document classification, medical entity recognition, generating discharge summaries, interpreting medical records, and providing medical advice.</p>
<ul>
<li>F1 score: It is calculated by taking the harmonic mean of precision and recall. it is the measure of the accuracy and completeness of the model's predictions. The F1 score is a good metric for tasks such as medical entity recognition and text classification.</li>
<li>Accuracy: Accuracy is the percentage of predictions that the model gets correct.</li>
<li>Precision: Precision is the percentage of positive predictions that are actually positive.</li>
<li>Recall: Recall is the percentage of actual positives that are predicted as positive.</li>
<li>AUC: AUC is the area under the receiver operating characteristic curve. It measures the model's ability to distinguish between positive and negative examples. AUC is a good metric for tasks such as medical question-answering and disease prediction.</li>
<li>C-index: The C-index measures the model's ability to predict the survival of patients.</li>
</ul>
<h1>5.2 Model Interpretability:</h1>
<p>To enhance the interpretability of a fine-tuned BioBERT model, employ the following techniques:</p>
<ul>
<li>Analyze the model's predictions : Examine the model's predictions and comprehend their rationale. This involves inspecting the model's features for making predictions and scrutinizing the attention weights assigned to various parts of the text.</li>
<li>Utilize visualization techniques : Make the model's predictions more comprehensible through graphical representations. Employ heat maps to visualize attention weights or other visualization methods to elucidate how the model generates predictions.</li>
<li>Leverage explainability tools : Utilize various explainability tools designed to elucidate how a machine learning model arrives at its predictions. These tools reveal the features employed by the model for prediction and provide insight into the significance of each feature.</li>
</ul>
<h3>5.3 Validation and Testing</h3>
<p>To validate the performance of a fine-tuned BioBERT model for healthcare tasks, consider the following actions.</p>
<ul>
<li>Compare model's performance with that of other existing biomedical models like BioMegatronShin et al. [2020] GatorTron Yang et al. [2022b]and clinical language modelsSinghal et al. [2022]. Use the same evaluation metrics and datasets to determine the best-performing model based on these metrics.</li>
<li>Experiment with hyperparameters, recognizing that these settings can significantly influence the model's performance. Conduct experiments with different hyperparameters to identify the optimal configuration for the specific task.</li>
<li>Validate the model on external healthcare datasets or benchmarks to assess its generalizability and robustness. The model should demonstrate strong performance on previously unseen datasets.</li>
</ul>
<p>When validating the performance of a fine-tuned BioBERT model for healthcare tasks, also consider the following factors:</p>
<ul>
<li>The size and quality of the training dataset.</li>
<li>The specific task for which the model is being evaluated.</li>
<li>The choice of evaluation metrics.</li>
<li>The clinical requirements that the model aims to address.</li>
</ul>
<h3>5.4 Deployment and Integration:</h3>
<p>To deploy and integrate a fine-tuned BioBERT Lee et al. [2020]model into healthcare applications and systems, take the following actions:</p>
<ul>
<li>
<p>Apply regularization techniques to prevent overfitting, a potential issue when training the model on a limited dataset. Overfitting occurs when the model captures noise in the data rather than the underlying patterns. Regularization discourages the model from learning non-generalizable patterns.</p>
</li>
<li>
<p>Augment dataset by artificially increasing its size. Employ techniques such as image translation, text generation, and synthetic data creation to enhance the dataset. Data augmentation bolsters the model's performance by increasing its resilience to data noise and variations.</p>
</li>
<li>Integrate the model into the application or system, making it accessible for making predictions or recommendations. Embed the model within the application or system or provide an API for seamless access.</li>
<li>Ensure compliance with relevant healthcare regulations and privacy standards during the model's deployment. This is crucial for safeguarding patient privacy and promoting responsible model usage. Be aware that healthcare regulations and privacy standards can vary between regions.</li>
</ul>
<p>While deploying and integrating a fine-tuned BioBERT model into healthcare applications, consider the following:</p>
<ul>
<li>Evaluate the model's performance on a held-out dataset to ensure its effectiveness with new data.</li>
<li>Continuously monitor the model's performance to confirm it meets expectations.</li>
<li>Regularly update the model to account for changes in the data.</li>
</ul>
<h1>5.5 Continuous Improvement:</h1>
<p>Continuously update and fine-tune the model in response to new healthcare data availability or evolving clinical requirements.</p>
<ul>
<li>Seek feedback from healthcare professionals, leveraging their expertise in the field for model improvement. Use their insights to identify areas where the model underperforms or to uncover new potential applications.</li>
<li>Fine-tune the model using newly acquired healthcare data, applying the same training process employed in the model's initial training phase.</li>
<li>Experiment with various hyperparameters to optimize the model's performance for the specific task.</li>
<li>Apply regularization techniques to prevent overfitting, a concern that may arise when training the model on a limited dataset.</li>
<li>Enhance the model's robustness by employing data augmentation techniques, making it more resilient to noise and data variations.</li>
<li>Continually monitor the model's performance to ensure it meets expectations. If performance deteriorates, consider fine-tuning or updating it with fresh data.</li>
</ul>
<h3>5.6 Documentation and Accessibility:</h3>
<p>Comprehensively document the fine-tuned BioBERT model, including pre-trained weights and code, and make it accessible to the healthcare and research community. Provide comprehensive documentation, code, and model checkpoints in various formats like a technical paper, a blog post, and a GitHub repository. This approach will expand accessibility to a broader audience.</p>
<h3>5.7 Ethical Considerations:</h3>
<p>To ensure that the fine-tuned model addresses ethical concerns related to patient privacy and data security and that it avoids inadvertently revealing sensitive patient information in compliance with healthcare regulations like HIPAA, the following specific ethical considerations should be incorporated when using a fine-tuned BioBERT model:</p>
<ul>
<li>Respecting Patient Privacy:Users must refrain from utilizing the model to access or disclose sensitive patient information, including patient names, medical records, and insurance details.</li>
<li>Enhancing Data Security: The model should be safeguarded against unauthorized access and use. This entails implementing measures like encryption and access control.</li>
<li>Mitigating Bias: Efforts should be made to prevent bias against any particular group of people. This can be achieved by employing a balanced dataset and avoiding discriminatory features.</li>
<li>Ensuring Transparency: The model must be transparent and interpretable. Users should have the capacity to comprehend how the model operates and how it generates its predictions.</li>
<li>Establishing Accountability: Developers and users of the model bear responsibility for its actions. They are obligated to ensure the model's safe and responsible use.</li>
</ul>
<h1>6 Discussion</h1>
<p>Based on analyzing the selected works, we realized that LLMs have the potential to revolutionize healthcare. They can introduce novel approaches to enhance clinical decision-making, facilitate information retrieval, and enable more natural language interaction. We have explored the potential benefits and limitations of integrating these language models into healthcare applications. BioBERT's primary strength resides in its capacity to comprehend and process intricate biomedical and clinical texts. Its pre-training on an extensive corpus of biomedical literature provides it with a robust foundation to accurately interpret medical terminologies, abbreviations, and concepts. Such capability proves indispensable in the healthcare context, where specialized language prevails. Moreover, BioBERT can undergo fine-tuning for specific applications, encompassing medical entity recognition, text classification, disease prediction, and question-answering. This adaptability empowers healthcare professionals to harness the model's capabilities across a broad spectrum of clinical and administrative functions.</p>
<h3>6.1 Advantages of using BioBERT for healthcare applications</h3>
<p>BioBERT offers improved clinical decision support, representing one of its most promising applications. Healthcare providers can utilize the model to swiftly access current medical knowledge, research articles, and patient records. This empowers them to render more informed decisions regarding diagnosis, treatment, and patient care, enhancing patient outcomes. BioBERT significantly enhances information retrieval efficiency from electronic health records (EHRs) and other clinical documents. Its ability to process and analyze extensive text data aids healthcare professionals in promptly accessing patient-specific information, thereby reducing the risk of overlooking critical data. The model's natural language processing capabilities make it accessible to healthcare professionals, even those without technical backgrounds. This promotes more effective communication between healthcare providers and technology, enhancing user experience and adoption. However, we must recognize and tackle the challenges linked to deploying BioBERT in healthcare:</p>
<ol>
<li>Data Privacy and Security: Healthcare data is highly sensitive and falls under stringent privacy regulations. To ensure BioBERT's compliance with these regulations, such as HIPAA in the United States, it is crucial to prevent data breaches and safeguard patient information.</li>
<li>Bias and Fairness: BioBERT, like other language models, can inherit biases present in the training data. This bias can lead to disparities in healthcare if not carefully mitigated. Developing techniques to identify and rectify bias in healthcare-specific contexts is essential.</li>
<li>Lack of Transparency: Interpreting BioBERT's decisions can be challenging due to its complex architecture. Efforts to make the model more transparent and explainable are necessary to build trust among healthcare professionals.</li>
<li>Quality Control: Ensuring the quality and accuracy of information generated or retrieved by BioBERT is paramount. Erroneous information or recommendations could have serious consequences in clinical settings.</li>
<li>Resource Intensiveness: Developing, fine-tuning, and maintaining BioBERT for healthcare can be resourceintensive, requiring substantial computational power, data annotation, and expert oversight.</li>
<li>Generalization Challenges: BioBERT may struggle with generalizing to specific healthcare domains, specialties, or rare conditions if not adequately fine-tuned. Customization may be necessary to achieve optimal performance.</li>
</ol>
<p>BioBERT holds immense potential for revolutionizing healthcare applications by improving information retrieval, clinical decision support, and natural language interaction. However, its deployment in the healthcare sector must be accompanied by stringent measures to address privacy concerns, mitigate bias, ensure transparency, maintain data quality, allocate resources effectively, and fine-tune for specific healthcare contexts. With careful consideration and responsible implementation, BioBERT can become a valuable tool for healthcare professionals, enhancing patient care and medical research.</p>
<h2>7 Conclusion and Future Work</h2>
<p>In conclusion, this study offers valuable insights into how the Large Language Models can impact the healthcare sector. It highlights the potential of enhancing various aspects of healthcare, applications such as improving patient care and streamlining healthcare processes. However, challenges such as model performance and ethical considerations remain. Future research shall focus on addressing the existing challenges and further harnessing the capabilities of LLMs by extending to the following dimensions.</p>
<ul>
<li>Improving model performance</li>
<li>Extending NLP for downstream tasks.</li>
<li>Harnessing the capabilities of multimodal LLMs to provide a more comprehensive understanding of patient health.</li>
<li>Developing cost-effective methods for developing and deploying LLMs.</li>
</ul>
<h1>References</h1>
<p>Jiaqi Wang, Enze Shi, Sigang Yu, Zihao Wu, Chong Ma, Haixing Dai, Qiushi Yang, Yanqing Kang, Jinru Wu, Huawen Hu, et al. Prompt engineering for healthcare: Methodologies and applications. arXiv preprint arXiv:2304.14670, 2023a.</p>
<p>PM Lavanya and E Sasikala. Deep learning techniques on text classification using natural language processing (nlp) in social healthcare network: A comprehensive survey. In 2021 3rd international conference on signal processing and communication (ICPSC), pages 603-609. IEEE, 2021.
Moreno La Quatra and Luca Cagliero. Transformer-based highlights extraction from scientific papers. Knowledge-Based Systems, 252:109382, 2022.
Sandeep Reddy. Evaluating large language models for use in healthcare: A framework for translational value assessment. Informatics in Medicine Unlocked, page 101304, 2023.
Sheng Wang, Zihao Zhao, Xi Ouyang, Qian Wang, and Dinggang Shen. Chatcad: Interactive computer-aided diagnosis on medical image using large language models. arXiv preprint arXiv:2302.07257, 2023b.
Arya Rao, John Kim, Meghana Kamineni, Michael Pang, Winston Lie, and Marc D Succi. Evaluating chatgpt as an adjunct for radiologic decision-making. medRxiv, pages 2023-02, 2023.
Li Yunxiang, Li Zihan, Zhang Kai, Dan Ruilong, and Zhang You. Chatdoctor: A medical chat model fine-tuned on llama model using medical domain knowledge. arXiv preprint arXiv:2303.14070, 2023.
Partha Pratim Ray. Chatgpt: A comprehensive review on background, applications, key challenges, bias, ethics, limitations and future scope. Internet of Things and Cyber-Physical Systems, 2023.
Tianyong Hao, Xieling Chen, Guozheng Li, and Jun Yan. A bibliometric analysis of text mining in medical research. Soft Computing, 22:7875-7892, 2018.
Xieling Chen, Haoran Xie, Gary Cheng, Leonard KM Poon, Mingming Leng, and Fu Lee Wang. Trends and features of the applications of natural language processing techniques for clinical trials text analysis. Applied Sciences, 10(6): 2157, 2020.
Elena-Alexandra Costea. Machine learning-based natural language processing algorithms and electronic health records data. Linguistic and Philosophical Investigations, (19):93-99, 2020.
Dina Demner-Fushman, Wendy W Chapman, and Clement J McDonald. What can natural language processing do for clinical decision support? Journal of biomedical informatics, 42(5):760-772, 2009.
Suzanne Henwood and Jim Lister. NLP and coaching for health care professionals: Developing expert practice. John Wiley \&amp; Sons, 2007.
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692, 2019.</p>
<p>Ning Kang, Bharat Singh, Zubair Afzal, Erik M van Mulligen, and Jan A Kors. Using rule-based natural language processing to improve disease normalization in biomedical text. Journal of the American Medical Informatics Association, 20(5):876-881, 2013.
Sadid A Hasan and Oladimeji Farri. Clinical natural language processing with deep learning. Data Science for Healthcare: Methodologies and Applications, pages 147-171, 2019.
Jinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu Kim, Chan Ho So, and Jaewoo Kang. Biobert: a pre-trained biomedical language representation model for biomedical text mining. Bioinformatics, 36(4):1234-1240, 2020.</p>
<p>Hoo-Chang Shin, Yang Zhang, Evelina Bakhturina, Raul Puri, Mostofa Patwary, Mohammad Shoeybi, and Raghav Mani. Biomegatron: Larger biomedical domain language model. arXiv preprint arXiv:2010.06060, 2020.</p>
<p>Xi Yang, Aokun Chen, Nima PourNejatian, Hoo Chang Shin, Kaleb E Smith, Christopher Parisien, Colin Compas, Cheryl Martin, Anthony B Costa, Mona G Flores, et al. A large language model for electronic health records. NPJ Digital Medicine, 5(1):194, 2022a.
Karan Singhal, Shekoofeh Azizi, Tao Tu, S Sara Mahdavi, Jason Wei, Hyung Won Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen Pfohl, et al. Large language models encode clinical knowledge. arXiv preprint arXiv:2212.13138, 2022.
Hongbo Zhang, Junying Chen, Feng Jiang, Fei Yu, Zhihong Chen, Jianquan Li, Guiming Chen, Xiangbo Wu, Zhiyi Zhang, Qingying Xiao, et al. Huatuogpt, towards taming language model to be a doctor. arXiv preprint arXiv:2305.15075, 2023.
Karan Singhal, Tao Tu, Juraj Gottweis, Rory Sayres, Ellery Wulczyn, Le Hou, Kevin Clark, Stephen Pfohl, Heather Cole-Lewis, Darlene Neal, et al. Towards expert-level medical question answering with large language models. arXiv preprint arXiv:2305.09617, 2023.
Xi Yang, Aokun Chen, Nima PourNejatian, Hoo Chang Shin, Kaleb E Smith, Christopher Parisien, Colin Compas, Cheryl Martin, Mona G Flores, Ying Zhang, et al. Gatortron: A large clinical language model to unlock patient information from unstructured electronic health records. arXiv preprint arXiv:2203.03540, 2022b.</p>            </div>
        </div>

    </div>
</body>
</html>