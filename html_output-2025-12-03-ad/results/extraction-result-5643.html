<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5643 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5643</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5643</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-115.html">extraction-schema-115</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <p><strong>Paper ID:</strong> paper-270702371</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2406.16308v1.pdf" target="_blank">Anomaly Detection of Tabular Data Using LLMs</a></p>
                <p><strong>Paper Abstract:</strong> Large language models (LLMs) have shown their potential in long-context understanding and mathematical reasoning. In this paper, we study the problem of using LLMs to detect tabular anomalies and show that pre-trained LLMs are zero-shot batch-level anomaly detectors. That is, without extra distribution-specific model fitting, they can discover hidden outliers in a batch of data, demonstrating their ability to identify low-density data regions. For LLMs that are not well aligned with anomaly detection and frequently output factual errors, we apply simple yet effective data-generating processes to simulate synthetic batch-level anomaly detection datasets and propose an end-to-end fine-tuning strategy to bring out the potential of LLMs in detecting real anomalies. Experiments on a large anomaly detection benchmark (ODDS) showcase i) GPT-4 has on-par performance with the state-of-the-art transductive learning-based anomaly detection methods and ii) the efficacy of our synthetic dataset and fine-tuning strategy in aligning LLMs to this task.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5643.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5643.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative Pre-trained Transformer 4</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large proprietary transformer-based language model from OpenAI used in this paper as a zero-shot batch-level anomaly detector by prompting serialized tabular data; shown to detect low-density (outlier) regions in batches without task-specific fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4 (gpt-4-1106preview via API)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Proprietary large transformer language model (autoregressive/decoder-based API usage reported); used via OpenAI API with default generation hyperparameters.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Zero-shot, prompt-based detection on serialized one-dimensional feature lists: data serialized to text ("Data i is x_i."), a brief task prompt ("Abnormal data differ from the majority. Which data are abnormal?"), and a system instruction to output indices only; aggregate per-feature outputs to form per-row anomaly scores.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Tabular data (batch-level detection; features treated independently and serialized as lists of scalars), i.e., structured/tabular data represented as lists.</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Point outliers / low-density anomalies (contamination outliers in continuous and discrete features).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>ODDS benchmark (Rayana, 2016) for real-world evaluation; synthetic Gaussian/Categorical mixtures for fine-tuning and density-experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUROC on ODDS benchmark (AUROC reported in Table 1). Paper reports GPT-4 achieves on-par AUROC performance with a state-of-the-art transductive method (ECOD) on ODDS; additionally used kernel-density aggregation of predicted anomalies to show capture of low-density regions in synthetic experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>GPT-4 (zero-shot) is reported to be comparable to state-of-the-art transductive learning-based anomaly detectors (ECOD, KNN listed) on ODDS without extra fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>No fine-grained numeric failure rates reported for GPT-4; general limitations apply (context window limits -> subsampling to 150 rows and 10 columns), dependence on serialization/prompt design, and possible instruction-following variability across models though GPT-4 followed the 'only answer indices' instruction reliably in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Anomaly Detection of Tabular Data Using LLMs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5643.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5643.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-3.5 Turbo (gpt-3.5-turbo-1106)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A widely used OpenAI conversational transformer model evaluated in zero-shot prompt-based batch-level anomaly detection on serialized tabular features.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5 (gpt-3.5-turbo-1106 via API)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Proprietary transformer conversational model from OpenAI used via API with default generation settings in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Zero-shot prompt-based detection using the same serialization and prompts as for GPT-4; per-feature outputs aggregated into per-row anomaly scores.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Tabular data (serialized per-feature lists of scalars).</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Point outliers / low-density anomalies (contamination outliers).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>ODDS benchmark; synthetic datasets for demonstration.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUROC on ODDS reported (Table 1) and compared qualitatively to other methods; specific numeric values not reproduced in paper text excerpt.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>GPT-3.5 is outperformed by GPT-4 and by some fine-tuned LLMs (e.g., Mistral-AD), per the paper's reported comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Same practical limitations as GPT-4 (input length limits, need for serialization/prompting), and lower performance than GPT-4 and some fine-tuned models on ODDS per reported results.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Anomaly Detection of Tabular Data Using LLMs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5643.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5643.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Llama-2 (pre-finetune)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Llama-2 (Meta)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Open-source family of transformer LLMs evaluated here; the 70B-parameter variant (and a 7B variant) are tested in prompt-based anomaly detection but unaligned variants make factual errors on index/value mapping.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama-2</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Open-source transformer-based LLM family; experiments used both a 70B-parameter version and a 7B-parameter version (70B reported making errors prior to fine-tuning).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>70B / 7B</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Zero-shot prompt-based detection on serialized per-feature scalar lists using the same prompt; also used as base model for fine-tuning experiments (see Llama2-AD).</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Tabular data (serialized per-feature lists of scalars).</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Point outliers / low-density anomalies; both continuous and discrete contamination anomalies.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>ODDS benchmark for quantitative evaluation; synthetic datasets for fine-tuning/data generation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUROC on ODDS (pre-fine-tuning results reported in Table 1); qualitative failure cases illustrated (missed anomalies, false positives).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Pre-fine-tuned Llama-2 performed worse than GPT variants and exhibited misalignment; after fine-tuning performance improved substantially (see Llama2-AD).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Observed failure modes: factual errors (missing anomalies, false positives), incorrect pairing of indices and values, outputting indices outside the batch, or listing all rows as abnormal; demonstrates misalignment to this AD task without fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Anomaly Detection of Tabular Data Using LLMs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5643.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e5643.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Llama2-AD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Llama-2 fine-tuned for Anomaly Detection (Llama2-AD)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Llama-2-based model fine-tuned using an end-to-end supervised strategy on a synthetically generated anomaly detection dataset using LoRA; shown to correct pre-finetuning factual/formatting errors and substantially improve AUROC.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama2-AD (Llama-2 7B fine-tuned with LoRA)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Fine-tuned variant of Llama-2 (7B parameter base) using parameter-efficient LoRA adapters trained on 5,000 synthetic batches (2,500 continuous and 2,500 discrete) and validated on held-out synthetic batches; original LLM weights frozen while low-rank adapter weights updated.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>End-to-end supervised fine-tuning: synthetic batch-level question/answer pairs are serialized and used to teach the model to output index-based anomaly answers (train objective maximizes conditional token log-likelihood), then deployed with same serialization + prompt pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Tabular data (serialized per-feature scalar lists), both continuous and discrete simulated batches plus ODDS for evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Point outliers / contamination anomalies (continuous Gaussian mixture and discrete categorical mixture).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Synthetic training dataset (5,000 batches: 2,500 continuous + 2,500 discrete) generated by the authors; evaluated on ODDS benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUROC on ODDS; paper reports on-average AUROC improvement of ~8.9 points for Llama2 after fine-tuning compared to pre-fine-tuning; qualitative example in Fig.2 shows corrected detection of all anomalies in a toy batch.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Fine-tuned Llama2-AD significantly outperforms its un-fine-tuned counterpart (Llama-2), and the fine-tuning closed or reduced the gap compared to stronger zero-shot LLMs; specific numeric comparisons to KNN/ECOD/GPT-4 appear in Table 1.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Fine-tuning requires synthetic labeled batches and LoRA training; dependence on quality and representativeness of synthetic data; potential generalization limits to data distributions not covered by synthetic generation choices; still limited by context window, per-feature independence assumption, and serialization decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Anomaly Detection of Tabular Data Using LLMs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5643.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e5643.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mistral (pre-finetune)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mistral (open LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Open-source transformer model (used in a 7B variant) evaluated in zero-shot prompt-based tabular anomaly detection and later fine-tuned; pre-fine-tuned Mistral shows weaker performance compared to GPT-4 but improves after task-specific fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Mistral</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Open-source transformer LLM family; experiments used a 7B-parameter base model with generation hyperparameters temperature=0.75, top_p=0.9.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Zero-shot prompt-based detection on serialized per-feature lists; also used as base for LoRA fine-tuning (Mistral-AD).</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Tabular data serialized as scalar lists (per-feature).</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Point outliers / contamination anomalies (continuous and discrete).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>ODDS benchmark for evaluation; synthetic datasets for fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUROC on ODDS reported in Table 1; pre-fine-tuning performance improved after LoRA fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Mistral pre-fine-tuning underperforms compared to GPT-4; after fine-tuning Mistral-AD shows significant AUROC improvements (paper reports ~6.7 AUROC increase on average).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Pre-fine-tuning misalignment and instruction-following variability; requires LoRA fine-tuning with synthetic data to reach competitive performance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Anomaly Detection of Tabular Data Using LLMs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5643.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e5643.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mistral-AD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mistral fine-tuned for Anomaly Detection (Mistral-AD)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Mistral 7B model fine-tuned with LoRA on the synthetic supervised batch-level anomaly dataset; used to detect low-density regions in synthetic continuous mixtures and achieves notable AUROC improvements versus the base model.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Mistral-AD (Mistral 7B fine-tuned with LoRA)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Mistral 7B base model with LoRA adapters trained on 5,000 synthetic batches (2,500 continuous + 2,500 discrete) and validated on held-out synthetic data; training used learning rate 1e-3 with 2 epochs for Mistral in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>End-to-end supervised fine-tuning (LoRA) on serialized text question/answer pairs; deployment uses the same serialization + prompt zero-shot inference pipeline after fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Tabular data (serialized per-feature lists), applied to both synthetic mixtures and ODDS benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Point outliers / low-density contamination anomalies (both continuous Gaussian mixture + wide uniform contamination and discrete categorical contamination).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Synthetic training dataset created by authors; evaluated on ODDS and on a synthetic contaminated mixture p(x) for density capture experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUROC on ODDS; paper reports Mistral-AD shows average AUROC increase of ~6.7 points relative to pre-finetuned Mistral; additionally used kernel density estimation of predicted anomalies from 500 batches to show capture of low-density modes.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Mistral-AD significantly outperforms the base Mistral model and outperforms GPT-3.5 in reported comparisons; it approaches competitive performance though GPT-4 remains a strong zero-shot baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Generalization depends on representativeness of synthetic data; requires LoRA fine-tuning resources; sensitive to serialization choices and per-feature independence assumption; context-window based subsampling applied (150 rows, 10 columns) due to token limits.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Anomaly Detection of Tabular Data Using LLMs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5643.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e5643.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Serialization+Prompt</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Text Serialization and Prompting for Batch-level AD</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method that converts numerical tabular batch-level anomaly detection into a text-to-text task by serializing each scalar feature value into short sentences, prompting the LLM to list abnormal row indices, and aggregating per-feature outputs into per-row anomaly scores.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>method (used with multiple LLMs)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Not a model—serialization template: each scalar x_{i,k} serialized as "Data i is x_{i,k}." (rounded to two decimals); prompt C = "Abnormal data differ from the majority. Which data are abnormal?" plus a system message "Only answer data indices." Iterated per feature and aggregated by counting occurrences of an index across features.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Prompt-based, zero-shot or fine-tuned text-to-text anomaly detection: per-feature serialization + task prompt; output constrained to indices only; anomaly score = count of features for which an index was output as abnormal.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Tabular / structured data serialized as lists of scalar values (one-dimensional per-feature inputs).</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Point outliers / low-density/corruption anomalies in individual features; supports continuous and discrete features (categorical).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Applied to ODDS benchmark and synthetic datasets generated by authors.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Evaluated with AUROC on ODDS; success qualitatively demonstrated by density-capture experiments using kernel density estimation of predicted anomalies.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Using this serialization + prompting with GPT-4 yields performance comparable to ECOD/KNN (transductive baselines) on ODDS without tuning; fine-tuned LLMs using the same pipeline (with LoRA) substantially improve over their base versions.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Assumes feature independence (authors explicitly detect anomalies per feature and aggregate); authors note that inputting full vectors instead of per-feature lists degraded performance (LLMs may not treat vectors as unordered sets); token/context length constraints required subsampling; parsing model outputs can be non-trivial for some LLMs that produce verbose outputs (authors used system messages and regex-guided generation constraints).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Anomaly Detection of Tabular Data Using LLMs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5643.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e5643.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>End-to-end LoRA Fine-tune (Synthetic)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>End-to-end supervised LoRA fine-tuning on synthetic batch anomaly datasets</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method to align LLMs to batch-level tabular anomaly detection by training LoRA adapters on supervised Q/A pairs where synthetic batches (continuous Gaussian mixtures and discrete categorical mixtures) provide ground-truth anomaly indices; the model is trained to output the final index-based answer directly.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>training method (LoRA fine-tuning on synthetic data)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Parameter-efficient LoRA adapters appended to LLM weight matrices; original LLM weights frozen while low-rank adapters are trained by maximizing token-level conditional log-likelihood of ground-truth serialized responses. Training set: 5,000 synthetic batches (2,500 continuous, 2,500 discrete); validation: 400 batches.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Supervised end-to-end fine-tuning (no chain-of-thought): present serialized batch X and ground-truth answer Y (index lists or "All rows are normal."), optimize LoRA parameters to directly produce correct index outputs at inference.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Tabular (synthetic batches), both continuous (Gaussian mixture with narrow normal & wide anomalous components) and discrete (mixture of categorical distributions).</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Contamination outliers: continuous wide-Gaussian/uniform anomalies and discrete anomalous categorical distributions; contamination ratio π randomly chosen <0.2.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Synthetic dataset produced by authors (5000 training batches, 400 validation batches) and ODDS used for downstream evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUROC improvements reported on ODDS for models fine-tuned with this strategy; authors report average AUROC increases of ~8.9 for Llama2 and ~6.7 for Mistral after fine-tuning; also qualitative density-capture evaluation using kernel density estimation on predicted anomalies.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Fine-tuning using this synthetic end-to-end LoRA approach substantially improved open-source LLMs' AD performance versus their pre-fine-tuned counterparts and enabled them to approach or beat some baseline LLMs (e.g., Mistral-AD outperforms GPT-3.5 in reported comparisons).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Relies on quality and coverage of synthetic data; does not teach explicit intermediate numerical algorithms (authors avoided chain-of-thought arithmetic); potential mismatch between synthetic and real-world distributions; requires computational resources for LoRA fine-tuning and curated synthetic generation parameters; still limited by token/context window and per-feature independence assumption.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Anomaly Detection of Tabular Data Using LLMs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Anomalygpt: Detecting industrial anomalies using large visionlanguage models <em>(Rating: 2)</em></li>
                <li>Large language models for forecasting and anomaly detection: A systematic literature review <em>(Rating: 2)</em></li>
                <li>ODDS library <em>(Rating: 2)</em></li>
                <li>A unifying review of deep and shallow anomaly detection <em>(Rating: 1)</em></li>
                <li>Training language models to follow instructions with human feedback <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5643",
    "paper_id": "paper-270702371",
    "extraction_schema_id": "extraction-schema-115",
    "extracted_data": [
        {
            "name_short": "GPT-4",
            "name_full": "Generative Pre-trained Transformer 4",
            "brief_description": "A large proprietary transformer-based language model from OpenAI used in this paper as a zero-shot batch-level anomaly detector by prompting serialized tabular data; shown to detect low-density (outlier) regions in batches without task-specific fine-tuning.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-4 (gpt-4-1106preview via API)",
            "model_description": "Proprietary large transformer language model (autoregressive/decoder-based API usage reported); used via OpenAI API with default generation hyperparameters.",
            "model_size": null,
            "anomaly_detection_method": "Zero-shot, prompt-based detection on serialized one-dimensional feature lists: data serialized to text (\"Data i is x_i.\"), a brief task prompt (\"Abnormal data differ from the majority. Which data are abnormal?\"), and a system instruction to output indices only; aggregate per-feature outputs to form per-row anomaly scores.",
            "data_type": "Tabular data (batch-level detection; features treated independently and serialized as lists of scalars), i.e., structured/tabular data represented as lists.",
            "anomaly_type": "Point outliers / low-density anomalies (contamination outliers in continuous and discrete features).",
            "dataset_name": "ODDS benchmark (Rayana, 2016) for real-world evaluation; synthetic Gaussian/Categorical mixtures for fine-tuning and density-experiments.",
            "performance_metrics": "AUROC on ODDS benchmark (AUROC reported in Table 1). Paper reports GPT-4 achieves on-par AUROC performance with a state-of-the-art transductive method (ECOD) on ODDS; additionally used kernel-density aggregation of predicted anomalies to show capture of low-density regions in synthetic experiments.",
            "baseline_comparison": "GPT-4 (zero-shot) is reported to be comparable to state-of-the-art transductive learning-based anomaly detectors (ECOD, KNN listed) on ODDS without extra fine-tuning.",
            "limitations_or_failure_cases": "No fine-grained numeric failure rates reported for GPT-4; general limitations apply (context window limits -&gt; subsampling to 150 rows and 10 columns), dependence on serialization/prompt design, and possible instruction-following variability across models though GPT-4 followed the 'only answer indices' instruction reliably in experiments.",
            "uuid": "e5643.0",
            "source_info": {
                "paper_title": "Anomaly Detection of Tabular Data Using LLMs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "GPT-3.5",
            "name_full": "GPT-3.5 Turbo (gpt-3.5-turbo-1106)",
            "brief_description": "A widely used OpenAI conversational transformer model evaluated in zero-shot prompt-based batch-level anomaly detection on serialized tabular features.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-3.5 (gpt-3.5-turbo-1106 via API)",
            "model_description": "Proprietary transformer conversational model from OpenAI used via API with default generation settings in experiments.",
            "model_size": null,
            "anomaly_detection_method": "Zero-shot prompt-based detection using the same serialization and prompts as for GPT-4; per-feature outputs aggregated into per-row anomaly scores.",
            "data_type": "Tabular data (serialized per-feature lists of scalars).",
            "anomaly_type": "Point outliers / low-density anomalies (contamination outliers).",
            "dataset_name": "ODDS benchmark; synthetic datasets for demonstration.",
            "performance_metrics": "AUROC on ODDS reported (Table 1) and compared qualitatively to other methods; specific numeric values not reproduced in paper text excerpt.",
            "baseline_comparison": "GPT-3.5 is outperformed by GPT-4 and by some fine-tuned LLMs (e.g., Mistral-AD), per the paper's reported comparisons.",
            "limitations_or_failure_cases": "Same practical limitations as GPT-4 (input length limits, need for serialization/prompting), and lower performance than GPT-4 and some fine-tuned models on ODDS per reported results.",
            "uuid": "e5643.1",
            "source_info": {
                "paper_title": "Anomaly Detection of Tabular Data Using LLMs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Llama-2 (pre-finetune)",
            "name_full": "Llama-2 (Meta)",
            "brief_description": "Open-source family of transformer LLMs evaluated here; the 70B-parameter variant (and a 7B variant) are tested in prompt-based anomaly detection but unaligned variants make factual errors on index/value mapping.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Llama-2",
            "model_description": "Open-source transformer-based LLM family; experiments used both a 70B-parameter version and a 7B-parameter version (70B reported making errors prior to fine-tuning).",
            "model_size": "70B / 7B",
            "anomaly_detection_method": "Zero-shot prompt-based detection on serialized per-feature scalar lists using the same prompt; also used as base model for fine-tuning experiments (see Llama2-AD).",
            "data_type": "Tabular data (serialized per-feature lists of scalars).",
            "anomaly_type": "Point outliers / low-density anomalies; both continuous and discrete contamination anomalies.",
            "dataset_name": "ODDS benchmark for quantitative evaluation; synthetic datasets for fine-tuning/data generation.",
            "performance_metrics": "AUROC on ODDS (pre-fine-tuning results reported in Table 1); qualitative failure cases illustrated (missed anomalies, false positives).",
            "baseline_comparison": "Pre-fine-tuned Llama-2 performed worse than GPT variants and exhibited misalignment; after fine-tuning performance improved substantially (see Llama2-AD).",
            "limitations_or_failure_cases": "Observed failure modes: factual errors (missing anomalies, false positives), incorrect pairing of indices and values, outputting indices outside the batch, or listing all rows as abnormal; demonstrates misalignment to this AD task without fine-tuning.",
            "uuid": "e5643.2",
            "source_info": {
                "paper_title": "Anomaly Detection of Tabular Data Using LLMs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Llama2-AD",
            "name_full": "Llama-2 fine-tuned for Anomaly Detection (Llama2-AD)",
            "brief_description": "A Llama-2-based model fine-tuned using an end-to-end supervised strategy on a synthetically generated anomaly detection dataset using LoRA; shown to correct pre-finetuning factual/formatting errors and substantially improve AUROC.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Llama2-AD (Llama-2 7B fine-tuned with LoRA)",
            "model_description": "Fine-tuned variant of Llama-2 (7B parameter base) using parameter-efficient LoRA adapters trained on 5,000 synthetic batches (2,500 continuous and 2,500 discrete) and validated on held-out synthetic batches; original LLM weights frozen while low-rank adapter weights updated.",
            "model_size": "7B",
            "anomaly_detection_method": "End-to-end supervised fine-tuning: synthetic batch-level question/answer pairs are serialized and used to teach the model to output index-based anomaly answers (train objective maximizes conditional token log-likelihood), then deployed with same serialization + prompt pipeline.",
            "data_type": "Tabular data (serialized per-feature scalar lists), both continuous and discrete simulated batches plus ODDS for evaluation.",
            "anomaly_type": "Point outliers / contamination anomalies (continuous Gaussian mixture and discrete categorical mixture).",
            "dataset_name": "Synthetic training dataset (5,000 batches: 2,500 continuous + 2,500 discrete) generated by the authors; evaluated on ODDS benchmark.",
            "performance_metrics": "AUROC on ODDS; paper reports on-average AUROC improvement of ~8.9 points for Llama2 after fine-tuning compared to pre-fine-tuning; qualitative example in Fig.2 shows corrected detection of all anomalies in a toy batch.",
            "baseline_comparison": "Fine-tuned Llama2-AD significantly outperforms its un-fine-tuned counterpart (Llama-2), and the fine-tuning closed or reduced the gap compared to stronger zero-shot LLMs; specific numeric comparisons to KNN/ECOD/GPT-4 appear in Table 1.",
            "limitations_or_failure_cases": "Fine-tuning requires synthetic labeled batches and LoRA training; dependence on quality and representativeness of synthetic data; potential generalization limits to data distributions not covered by synthetic generation choices; still limited by context window, per-feature independence assumption, and serialization decisions.",
            "uuid": "e5643.3",
            "source_info": {
                "paper_title": "Anomaly Detection of Tabular Data Using LLMs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Mistral (pre-finetune)",
            "name_full": "Mistral (open LLM)",
            "brief_description": "Open-source transformer model (used in a 7B variant) evaluated in zero-shot prompt-based tabular anomaly detection and later fine-tuned; pre-fine-tuned Mistral shows weaker performance compared to GPT-4 but improves after task-specific fine-tuning.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Mistral",
            "model_description": "Open-source transformer LLM family; experiments used a 7B-parameter base model with generation hyperparameters temperature=0.75, top_p=0.9.",
            "model_size": "7B",
            "anomaly_detection_method": "Zero-shot prompt-based detection on serialized per-feature lists; also used as base for LoRA fine-tuning (Mistral-AD).",
            "data_type": "Tabular data serialized as scalar lists (per-feature).",
            "anomaly_type": "Point outliers / contamination anomalies (continuous and discrete).",
            "dataset_name": "ODDS benchmark for evaluation; synthetic datasets for fine-tuning.",
            "performance_metrics": "AUROC on ODDS reported in Table 1; pre-fine-tuning performance improved after LoRA fine-tuning.",
            "baseline_comparison": "Mistral pre-fine-tuning underperforms compared to GPT-4; after fine-tuning Mistral-AD shows significant AUROC improvements (paper reports ~6.7 AUROC increase on average).",
            "limitations_or_failure_cases": "Pre-fine-tuning misalignment and instruction-following variability; requires LoRA fine-tuning with synthetic data to reach competitive performance.",
            "uuid": "e5643.4",
            "source_info": {
                "paper_title": "Anomaly Detection of Tabular Data Using LLMs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Mistral-AD",
            "name_full": "Mistral fine-tuned for Anomaly Detection (Mistral-AD)",
            "brief_description": "Mistral 7B model fine-tuned with LoRA on the synthetic supervised batch-level anomaly dataset; used to detect low-density regions in synthetic continuous mixtures and achieves notable AUROC improvements versus the base model.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Mistral-AD (Mistral 7B fine-tuned with LoRA)",
            "model_description": "Mistral 7B base model with LoRA adapters trained on 5,000 synthetic batches (2,500 continuous + 2,500 discrete) and validated on held-out synthetic data; training used learning rate 1e-3 with 2 epochs for Mistral in experiments.",
            "model_size": "7B",
            "anomaly_detection_method": "End-to-end supervised fine-tuning (LoRA) on serialized text question/answer pairs; deployment uses the same serialization + prompt zero-shot inference pipeline after fine-tuning.",
            "data_type": "Tabular data (serialized per-feature lists), applied to both synthetic mixtures and ODDS benchmark.",
            "anomaly_type": "Point outliers / low-density contamination anomalies (both continuous Gaussian mixture + wide uniform contamination and discrete categorical contamination).",
            "dataset_name": "Synthetic training dataset created by authors; evaluated on ODDS and on a synthetic contaminated mixture p(x) for density capture experiments.",
            "performance_metrics": "AUROC on ODDS; paper reports Mistral-AD shows average AUROC increase of ~6.7 points relative to pre-finetuned Mistral; additionally used kernel density estimation of predicted anomalies from 500 batches to show capture of low-density modes.",
            "baseline_comparison": "Mistral-AD significantly outperforms the base Mistral model and outperforms GPT-3.5 in reported comparisons; it approaches competitive performance though GPT-4 remains a strong zero-shot baseline.",
            "limitations_or_failure_cases": "Generalization depends on representativeness of synthetic data; requires LoRA fine-tuning resources; sensitive to serialization choices and per-feature independence assumption; context-window based subsampling applied (150 rows, 10 columns) due to token limits.",
            "uuid": "e5643.5",
            "source_info": {
                "paper_title": "Anomaly Detection of Tabular Data Using LLMs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Serialization+Prompt",
            "name_full": "Text Serialization and Prompting for Batch-level AD",
            "brief_description": "A method that converts numerical tabular batch-level anomaly detection into a text-to-text task by serializing each scalar feature value into short sentences, prompting the LLM to list abnormal row indices, and aggregating per-feature outputs into per-row anomaly scores.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "method (used with multiple LLMs)",
            "model_description": "Not a model—serialization template: each scalar x_{i,k} serialized as \"Data i is x_{i,k}.\" (rounded to two decimals); prompt C = \"Abnormal data differ from the majority. Which data are abnormal?\" plus a system message \"Only answer data indices.\" Iterated per feature and aggregated by counting occurrences of an index across features.",
            "model_size": null,
            "anomaly_detection_method": "Prompt-based, zero-shot or fine-tuned text-to-text anomaly detection: per-feature serialization + task prompt; output constrained to indices only; anomaly score = count of features for which an index was output as abnormal.",
            "data_type": "Tabular / structured data serialized as lists of scalar values (one-dimensional per-feature inputs).",
            "anomaly_type": "Point outliers / low-density/corruption anomalies in individual features; supports continuous and discrete features (categorical).",
            "dataset_name": "Applied to ODDS benchmark and synthetic datasets generated by authors.",
            "performance_metrics": "Evaluated with AUROC on ODDS; success qualitatively demonstrated by density-capture experiments using kernel density estimation of predicted anomalies.",
            "baseline_comparison": "Using this serialization + prompting with GPT-4 yields performance comparable to ECOD/KNN (transductive baselines) on ODDS without tuning; fine-tuned LLMs using the same pipeline (with LoRA) substantially improve over their base versions.",
            "limitations_or_failure_cases": "Assumes feature independence (authors explicitly detect anomalies per feature and aggregate); authors note that inputting full vectors instead of per-feature lists degraded performance (LLMs may not treat vectors as unordered sets); token/context length constraints required subsampling; parsing model outputs can be non-trivial for some LLMs that produce verbose outputs (authors used system messages and regex-guided generation constraints).",
            "uuid": "e5643.6",
            "source_info": {
                "paper_title": "Anomaly Detection of Tabular Data Using LLMs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "End-to-end LoRA Fine-tune (Synthetic)",
            "name_full": "End-to-end supervised LoRA fine-tuning on synthetic batch anomaly datasets",
            "brief_description": "A method to align LLMs to batch-level tabular anomaly detection by training LoRA adapters on supervised Q/A pairs where synthetic batches (continuous Gaussian mixtures and discrete categorical mixtures) provide ground-truth anomaly indices; the model is trained to output the final index-based answer directly.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "training method (LoRA fine-tuning on synthetic data)",
            "model_description": "Parameter-efficient LoRA adapters appended to LLM weight matrices; original LLM weights frozen while low-rank adapters are trained by maximizing token-level conditional log-likelihood of ground-truth serialized responses. Training set: 5,000 synthetic batches (2,500 continuous, 2,500 discrete); validation: 400 batches.",
            "model_size": null,
            "anomaly_detection_method": "Supervised end-to-end fine-tuning (no chain-of-thought): present serialized batch X and ground-truth answer Y (index lists or \"All rows are normal.\"), optimize LoRA parameters to directly produce correct index outputs at inference.",
            "data_type": "Tabular (synthetic batches), both continuous (Gaussian mixture with narrow normal & wide anomalous components) and discrete (mixture of categorical distributions).",
            "anomaly_type": "Contamination outliers: continuous wide-Gaussian/uniform anomalies and discrete anomalous categorical distributions; contamination ratio π randomly chosen &lt;0.2.",
            "dataset_name": "Synthetic dataset produced by authors (5000 training batches, 400 validation batches) and ODDS used for downstream evaluation.",
            "performance_metrics": "AUROC improvements reported on ODDS for models fine-tuned with this strategy; authors report average AUROC increases of ~8.9 for Llama2 and ~6.7 for Mistral after fine-tuning; also qualitative density-capture evaluation using kernel density estimation on predicted anomalies.",
            "baseline_comparison": "Fine-tuning using this synthetic end-to-end LoRA approach substantially improved open-source LLMs' AD performance versus their pre-fine-tuned counterparts and enabled them to approach or beat some baseline LLMs (e.g., Mistral-AD outperforms GPT-3.5 in reported comparisons).",
            "limitations_or_failure_cases": "Relies on quality and coverage of synthetic data; does not teach explicit intermediate numerical algorithms (authors avoided chain-of-thought arithmetic); potential mismatch between synthetic and real-world distributions; requires computational resources for LoRA fine-tuning and curated synthetic generation parameters; still limited by token/context window and per-feature independence assumption.",
            "uuid": "e5643.7",
            "source_info": {
                "paper_title": "Anomaly Detection of Tabular Data Using LLMs",
                "publication_date_yy_mm": "2024-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Anomalygpt: Detecting industrial anomalies using large visionlanguage models",
            "rating": 2,
            "sanitized_title": "anomalygpt_detecting_industrial_anomalies_using_large_visionlanguage_models"
        },
        {
            "paper_title": "Large language models for forecasting and anomaly detection: A systematic literature review",
            "rating": 2,
            "sanitized_title": "large_language_models_for_forecasting_and_anomaly_detection_a_systematic_literature_review"
        },
        {
            "paper_title": "ODDS library",
            "rating": 2,
            "sanitized_title": "odds_library"
        },
        {
            "paper_title": "A unifying review of deep and shallow anomaly detection",
            "rating": 1,
            "sanitized_title": "a_unifying_review_of_deep_and_shallow_anomaly_detection"
        },
        {
            "paper_title": "Training language models to follow instructions with human feedback",
            "rating": 1,
            "sanitized_title": "training_language_models_to_follow_instructions_with_human_feedback"
        }
    ],
    "cost": 0.014208499999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Anomaly Detection of Tabular Data Using LLMs</p>
<p>Aodong Li aodongl1@uci.edu 
Yunhan Zhao 
Chen Qiu 
Marius Kloft 
Padhraic Smyth 
Maja Rudolph 
Stephan Mandt 
U C Irvine 
Bosch Center 
Rptu Kaiserslautern-Landau 
Anomaly Detection of Tabular Data Using LLMs
4DA8310044E110A62A7DA286FBC264EE
Large language models (LLMs) have shown their potential in long-context understanding and mathematical reasoning.In this paper, we study the problem of using LLMs to detect tabular anomalies and show that pre-trained LLMs are zeroshot batch-level anomaly detectors.That is, without extra distribution-specific model fitting, they can discover hidden outliers in a batch of data, demonstrating their ability to identify low-density data regions.For LLMs that are not well aligned with anomaly detection and frequently output factual errors, we apply simple yet effective datagenerating processes to simulate synthetic batchlevel anomaly detection datasets and propose an end-to-end fine-tuning strategy to bring out the potential of LLMs in detecting real anomalies.Experiments on a large anomaly detection benchmark (ODDS) showcase i) GPT-4 has on-par performance with the state-of-the-art transductive learning-based anomaly detection methods and ii) the efficacy of our synthetic dataset and fine-tuning strategy in aligning LLMs to this task.</p>
<p>Introduction</p>
<p>Large language models (LLMs), which employ transformerbased architectures and billions of learnable parameters, can process and generate text that exhibits human-level realism.LLMs have enabled groundbreaking real-world applications that were hardly possible a few years ago, such as chatbots e.g.,(ChatGPT) and code generation e.g., GitHub Copilot [Roziere et al., 2023].</p>
<p>This paper studies the application of LLMs to anomaly detection (AD)-one of the fundamental problems in machine learning occurring in many applications [Ruff et al., 2021].AD concerns the detection of irregular instances-so-called anomalies-in data.There exist several settings of AD [Qiu et al., 2022;Li et al., 2023;Li et al., 2024]; we consider the setting of zero-shot batch-level AD [Li et al., 2024], illustrated in Fig. 1, where we want to find an anomalous instance x i ∈ R K in a batch of data X = {x 1 , . . ., x N } ⊂ R K .This setting finds applications in many domains, from fraud detection and intrusion detection to medical anomaly detection and industrial damage detection.</p>
<p>Zero-shot batch-level AD utilizes batch information to adapt to distribution shifts and can exploit modern hardware like GPUs for parallel computation [Li et al., 2024].Numerous shallow methods have been developed for this setting under the name of unsupervised anomaly discovery1 [Ramaswamy et al., 2000;Breunig et al., 2000;Liu et al., 2008;Li et al., 2022].On the other hand, LLMs have high promise for this setting.Their input and output format-natural language text-leads to simpler usage for practitioners.LLMs require no expertise in selecting anomaly detection models and setting hyperparameters.Moreover, they have the potential to understand task background information and customize task needs.For example, when we know some pattern is rare but normal, we can inform LLMs to exclude that pattern from detected anomalies.</p>
<p>Another motivation for studying zero-shot batch-level AD arises from the data-wrangling task.[Narayan et al., 2022] demonstrated employing LLMs to detect and correct errors in attribute-value pairs for tabular data, assuming that LLMs understand the attribute meanings and values as humans do.Unfortunately, in many real-world applications, especially in specialized domains where i) LLMs have relatively less information and ii) data are preprocessed into numerical values, LLMs cannot reliably detect errors.Therefore, we study the problem of using LLMs to detect errors in a given data batch where errors are present as outliers.</p>
<p>Using LLMs for zero-shot batch-level AD is challenging.First, the data consists of numerical tables, while LLMs expect text as input.Second, detecting anomalies in tables requires sophisticated computation with numerical data, such as estimating and thresholding densities.It remains unclear 1) whether LLMs can perform these tasks and 2) how to effectively prompt LLMs for AD.Third, LLMs have varying capabilities in mathematical reasoning and text understanding.How to align LLMs unprepared for this AD problem must be addressed.</p>
<p>The contributions of this paper are as follows, addressing the aforementioned challenges:</p>
<p>• We propose a serialization method (illustrated in Fig. 1)</p>
<p>that converts batch-level anomaly detection from a numerical task to a text-based task.The method comes along without hyperparameter tuning.• We empirically evaluate our approach on both synthetic and real-world data using GPT, Llama2, and Mistral.The experiments demonstrate that GPT-3.5 and GPT-4 can effectively detect anomalies in batches.• We develop a strategy for fine-tuning anomaly detectors by synthesizing normal and anomalous data, thereby training the LLM to detect anomalies accurately.• Experiments on the ODDS benchmark [Rayana, 2016] demonstrate that our simple method using the original GPT-4 performs on par with the state-of-the-art transductive learning-based methods.The fine-tuned Mistral-based detector outperforms GPT-3.5, highlighting the effectiveness of our fine-tuning strategy.</p>
<p>As follows, we discuss related works in Sec. 2, then present our method of applying and fine-tuning LLMs to detect anomalies in Sec. 3. We conduct experiments in Sec. 4 and conclude with Sec. 5.</p>
<p>Related Work</p>
<p>Anomaly detection with LLMs.[Gu et al., 2024] uses indistribution paired images and texts to jointly train a language model and a vision encoder to describe in natural language text the found anomalies in an image.[Elhafsi et al., 2023] relies on LLMs' environment understanding and reasoning ability to monitor semantic anomalies in autonomous driving systems.[Park, 2024] employs LLMs as agents to validate and interpret financial anomalies.[Su et al., 2024] surveyed the work in time series anomaly detection.Unlike the above work, we tackle zero-shot batch-level anomaly detection for tabular data.Zero-shot batch-level anomaly detection.Batch-level anomaly detection or unsupervised anomaly discovery has been studied for a long time [Chandola et al., 2009].While numerous transductive learning-based methods have been proposed, they are shallow methods and require hyperparameter settings for each data batch [Tax and Duin, 2004;Xu et al., 2010;Zhou and Paffenroth, 2017;Ramaswamy et al., 2000;Li et al., 2022].In deep anomaly detection, zero-shot batch-level anomaly detection utilizes batch normalization layers to automatically adapt to each data batch [Li et al., 2024].In this work, we apply LLMs as zero-shot batch-level anomaly detectors to accomplish this task across datasets solely based on their gained knowledge through pretraining.</p>
<p>Zero-shot learning in LLMs.LLMs have shown unprecedented zero-shot ability in many downstream NLP tasks [Chang et al., 2023].Many recent works start to leverage such zero-shot ability of LLMs to other tasks, such as arithmetic reasoning [Lewkowycz et al., 2022;Imani et al., 2023] and time series forecasting [Gruver et al., 2024].LLMs have also been applied to data wrangling for error detection [Narayan et al., 2022;Vos et al., 2022].To our knowledge, we are the first to explore and benchmark LLMs on tabular anomaly detection tasks and propose effective approaches that enhance the ability of LLMs on this task.</p>
<p>Method</p>
<p>This section will first present the problem setup, then introduce our text-based method for batch-level anomaly detection using large language models (LLMs), and finally propose an end-to-end fine-tuning strategy for LLMs to be better aligned to anomaly detection.</p>
<p>Problem Setup</p>
<p>We consider a batch of possibly contaminated data D := {x i ∈ R K } N i=1 (a numerical table) in the presence of unlabeled anomalies.We assume the number of anomalies is far less than normal data, i.e., the normal data takes the majority in the batch.We stress that the data batch can contain no anomalies.LLMs can tell when the batch is contaminated or not.The aim is to identify which data points in the batch are abnormal.</p>
<p>Text Formulation of Batch-level Anomaly Detection</p>
<p>We assume each feature dimension is independent, and we detect anomalies for each feature separately2 .The detection results of each feature dimension will then be aggregated to form the final results.</p>
<p>Data Serialization.We designed a template to serialize data into text because LLMs only accept text input.Assuming independent features, we can detect anomalies on one feature dimension at a time.Then, the data to be serialized will be one-dimensional float scalars.Denote the single-feature data by {x i ∈ R} N i=1 .We use the template serialize the ith data point. 3The data index i is necessary to disambiguate repetitive data values.We approximate the data value up to two decimal places in the serialization.Each serialized data point is then concatenated as input to the LLMs.We use T in := +{T in I } N i=1 to denote the concatenation operation where + represents concatenating each element in a set.Prompt Engineering.Besides the data input, we need to inform the LLMs of the anomaly detection task.We use a description text C :="Abnormal data are different from the majority.Which data are abnormal?"to characterize anomalies and ask questions.The serialized data input and task description together formulate the input to the LLMs, i.e., X := +{T in , C}. Fig. 1 presents a serialization example with five synthetic data.
T in i :="Data i is x i ." to
With the input X, LLMs can respond to the anomaly detection request.The response will include anomalous data indices (the numeric data indices) by design.In most cases, LLMs tend to generate diverse responses with long reasoning.We further regularize the output format by delivering another system message-"Only answer data indices."-tothe LLMs to have easy-to-parse responses. 4lgorithm 1 LLM for batch-level anomaly detection
Require: LLM, D := {x i ∈ R K } N i=1
Initialize anomaly score for each row
s i = 0, i = 1, . . . , N for each column k in D do Set serialization T in = "Data 1 is x 1,k . Data 2 is x 2,k . ... Data N is x N,k ."
Set prompt C = "Abnormal data differ from the majority.Which data are abnormal?"</p>
<p>Get response Ŷk = LLM(T in + C) Update anomaly scores for all data points
s i = s i + 1[i ∈ Ŷk ].
end for return anomaly scores s i , i = 1, . . ., N</p>
<p>Anomaly detection as a text-to-text task.One can get anomaly predictions for each feature dimension with the pro-posed data serialization methods and the prompts.We now introduce a simple method for aggregating the responses of all feature dimensions and constructing anomaly scores for each data point.</p>
<p>We propose to set the anomaly score of the ith data to be the number of occurrences of data index i in all responses.That is, suppose the response to the kth feature dimension is Ŷk , then
s i = K k=1 1[i ∈ Ŷk ].
The anomaly scores are useful for performance evaluation and characterizing the degree of abnormality.The full procedure is presented in Alg. 1.</p>
<p>Prediction extraction from output.Automatically parsing the LLM output and extracting the predicted anomalies facilitate model evaluations and improve the response-to-detection speed.To get the predictions, we instruct the model to output only anomalous data indices by sending a system message-"Only answer data indices" However, research shows that the capability of following instructions by LLMs differs to some extent [Ouyang et al., 2022;Zhou et al., 2023].In our experiments, we observed that the fine-tuned LLMs (e.g., Mistral-AD and Llama-AD used in the experiments) can faithfully follow the same output format used during the fine-tuning stage.GPT-3.5 and GPT-4 also follow the instructions well and output succinct answers containing predicted data identifiers.So, we can extract the predictions automatically for these models.See Supp.B.1 for script details.</p>
<p>The other models in our experiments, Llama-2 and Mistral, oftentimes output redundant information besides predictions even though they are instructed to only output predictions.Redundant information makes it hard to pinpoint the predictions without human involvement, complicating the parsing process.To completely suppress redundant information, we manually modify the output token probabilities at each generation step and require the generation to follow a specific pattern.We use regular expressions to specify the desired model output patterns with the Outlines library [Willard and Louf, 2023]5 .We found that grammar-correct formats with complete sentences are essential for generating high-quality predictions.So the regular expression in use is ((Data [0-9]+(, [0-9]+) * are abnormal.)|(Alldata are normal.))which allows the model to predict abnormal data or to abstain from predictions if all data seemingly comes from the same datagenerating process.Extracting integers from the formatted output can be accomplished by the same automatic procedure</p>
<p>End-to-end Finetune Strategy</p>
<p>Unfortunately, not all LLMs are prepared to detect anomalies.Fig. 2 shows a failing case with an open-sourced LLM-Llama-2 (70 billion-parameter version).Llama-2 makes factual errors: it only discovers two outliers and misses another two; it wrongly labels one normal data as abnormal.Our experiments also observed that Llama-2 may pair incorrect indices and values, generate indices beyond the batch length, or list every data as abnormal.These phenomena signify the misalignment of Llama-2 or other LLMs in detecting anomalies.</p>
<p>Synthetic dataset.To align LLMs in batch-level anomaly detection, we simulate a synthetic dataset with ground truth labels for LLMs to learn.The dataset contains continuous and discrete data types, covering real-world data types.Discrete data is a mixture of normal and abnormal Categorical distributions.Continuous data is a Gaussian mixture where normal data is a narrow Gaussian while anomalies are from a wide Gaussian.All the model parameters are randomly selected from a pre-defined interval.The contamination ratio π for both data types is also random but ensured to be smaller than 0.2.The data generating processes are listed in Algs. 2 and 3 in Supp. A. The corresponding graphical models are shown in Fig. 3.We simulate 2,500 batches for each data type.When a data batch is normal, its ground-truth response is "All rows are normal."6For other batches that contain anomalies, we use the ground truth answers Y ="Data a 1 , a 2 ,... and a A are abnormal."where {a i : y ai = 1} A i=1 are the anomaly indices.Simulated synthetic data is serialized in our proposed text formulation.Synthetic data examples are in Supp. A.</p>
<p>End-to-end fine-tune.We align LLMs to the anomaly detection task through fine-tuning.The most common finetuning strategy is Chain-of-Thought [Wei et al., 2022].However, applying Chain-of-Thoughts to reason about anomalies is hard.Challenges arise from the complications of the AD task.For example, suppose we construct the chain of thoughts using the two-standard deviation range method7 .This method is a rough criterion and cannot cover all discrete and multimodal continuous data cases.In addition, asking LLMs to calculate the sample mean and sample standard deviation is another arithmetic challenge for LLMs.</p>
<p>Instead, we propose to teach LLMs in an end-to-end fashion-not focusing on "how to solve" but on "what to expect."We directly present the answer to the model and ask LLMs to learn to predict that given answer without caring about the intermediate steps.Therefore, we fine-tune LLMs on the synthetic dataset {(X b , Y b )} B b=1 in a supervised manner.Fig. 2 shows the efficacy of our fine-tuning method on a toy data batch.After aligning Llama2 (7 billion-parameter version) -Llama2-AD -detects all anomalies.</p>
<p>We apply low-rank adaptation (LoRA [Hu et al., 2022]), a parameter-efficient fine-tuning method to align LLMs.LoRA appends an additional low-rank weight matrix to each original weight matrix.The low-rank matrix can be parameterized efficiently through matrix factorization.The original weights are kept fixed during fine-tuning, and newly added low-rank matrices are updated.After fine-tuning, the low-rank weight matrices can be absorbed into the original weight matrix to fix the model size.</p>
<p>We fine-tune the LLMs by maximizing the conditional loglikelihood
B b=1 log p(Y b |X b ; θ LoRA , θ LLM ) of our simulated synthetic dataset {(X b , Y b )} B
b=1 with respect to the learnable θ LoRA while keeping LLM's original parameter θ LLM fixed.The conditional log-likelihood can be further factorized over the tokens
{y b i } L b i=1 of each response Y b in an auto-regressive fashion: B b=1 L b i=1 log p(y b i |y b &lt;i , X b ; θ LoRA , θ LLM ).
After optimization, θ LoRA can be integrated into θ LLM by an element-wise addition, which keeps the model size constant.More details are in [Hu et al., 2022].</p>
<p>Experiments</p>
<p>This section shows experimental results on the ODDS anomaly detection benchmark.One surprising result is that our simple prompt engineering method with the original GPT-4 performs similarly to the state-of-the-art anomaly detection method.Our alignment method using synthetic data on Llama2 and Mistral demonstrates significant improvements over their primitive counterparts.</p>
<p>We first introduce the global experimental setups and then the implementation details of our proposed methods.Finally, we present the results.</p>
<p>Experiment Setup</p>
<p>We follow the widely adopted ODDS tabular data benchmark [Rayana, 2016] to evaluate LLMs batch-level anomaly detection performance.Some LLMs have input token limits due to the context window size and GPU memory constraint.Therefore, we randomly sub-sample 150 rows and use the first 10 columns for each dataset to perform the evaluation.We extensively study various LLMs to support our findings.</p>
<p>Table 1: AUROC results of batch-level anomaly detection on the ODDS benchmark.Different LLMs are evaluated.Specifically, we show the performance of two LLMs (Llama2, Mistral) before and after finetuning.Proprietary LLMs (GPT-3.5 and GPT-4) are also compared.Additional state-of-the-art transductive learning-based approaches, i.e., KNN and ECOD, are listed for comparisons.Note that KNN and ECOD are not zero-shot batch-level methods.</p>
<p>Proposed Methods</p>
<p>Baselines GPT-3.5 GPT-</p>
<p>Implementation Details</p>
<p>We run all experiments three times with different random seeds.All our experiments except GPT-3.5 and GPT-4 are performed using an A6000 GPU with PyTorch.Llama-2 and Mistral can fit into the GPU memory.The temperature and where the contamination ratio is 0.1, resulting in p(x) in blue.We sample 500 independent batches from p(x) and ask the LLM to predict anomalies using our proposed method for each batch.We collect all the predicted anomalies and estimate the density by a kernel density estimator, shown by pa(x) in orange.pa(x) successfully captures three low-density regions of p(x), demonstrating the LLM's ability to detect anomalies.More details are in Supp.B. illustrate LLM's low-density region detection ability, we simulate a synthetic data distribution contaminated by anomalies.We use a two-component Gaussian mixture as the normal data distribution.We contaminate this normal data distribution with a wide uniform distribution representing abnormal data distribution.The final distribution is shown by p(x) in blue in Fig. 4. We sample data batches from this contaminated data distribution and apply our fine-tuned Mistral-AD (see below) to predict anomalies.We collect the predicted anomalies from all batches and use the kernel density estimator to fit a density pa (x) on them.Llama2-AD, Mistral vs. Mistral-AD), both models show significant improvements: on average, 8.9 and 6.7 AUROC increases, respectively, showing the efficacy of our fine-tuning strategy.</p>
<p>Conclusion</p>
<p>We consider using large language models (LLMs) to detect anomalies for numerical data wrangling.We address this problem through batch-level anomaly detection.We developed a text formulation for LLMs to accomplish this task.</p>
<p>We found LLMs are capable to identify low-density regions in a batch of data.Surprisingly, GPT-4 is a strong zeroshot batch-level anomaly detectors that have comparable performance with state-of-the-art transductive learning methods.For LLMs that are not well aligned to this task, we designed and simulated a synthetic dataset to fine-tune the LLMs in an "end-to-end" fashion.Experiments demonstrate the significance of our findings and the efficacy of our proposed finetune strategy.</p>
<p>Figure 1 :
1
Figure 1: The illustration of batch-level anomaly detection with LLMs.We serialize the data batch into text and apply our proposed prompts as the input to LLMs.LLMs then respond by answering the indices of abnormal data based on LLMs' knowledge.The system message "Only answer data indices" regularizes LLM responses and ensures responses are easy to parse.</p>
<p>Figure 2 :
2
Figure 2: Illustration of Llama2 for batch-level anomaly detection before and after our fine-tuning strategy.With the same input prompt, Llama2-70b (70-billion parameter version) makes factual mistakes-two false negatives (missing 5 and 10) and one false positive (incorrect 14).These results are obtained from https://www.llama2.ai.On the contrary, our fine-tuned 7-billion parameter (10x smaller than Llama2-70b) Llama2-AD succeeds in discovering all anomalies.</p>
<p>Figure 3 :
3
Figure 3: Graphical models of the synthetic data generating processes.(Left) We use a binary Gaussian mixture (i.e., K = 2) to generate a batch of continuous data of size N .One Gaussian corresponds to normal data, and another corresponds to abnormal data.(Right) A multinomial mixture model (K = 2) for discrete data where one multinomial is for normal and one for abnormal data.π controls the anomaly ratio.Specifics of the random variables in the models are in Supp.A</p>
<p>Figure 4 :
4
Figure4: LLMs can detect low-density regions in a contaminated data distribution.We use our Mistral-AD fine-tuned based on Mistral as the demonstrating LLM.Normal data distribution is represented by two Gaussian distributions located at -25 and 25 respectively.The contaminated data distribution is formed by combining the normal distributions and a wide uniform distribution spanned over interval[−100, 100], where the contamination ratio is 0.1, resulting in p(x) in blue.We sample 500 independent batches from p(x) and ask the LLM to predict anomalies using our proposed method for each batch.We collect all the predicted anomalies and estimate the density by a kernel density estimator, shown by pa(x) in orange.pa(x) successfully captures three low-density regions of p(x), demonstrating the LLM's ability to detect anomalies.More details are in Supp.B.</p>
<p>Fig. 4
4
shows pa (x) captures the three low-density regions in p(x), separated by two peak Gaussian distributions, demonstrating LLM's low-density region detection ability.Quantitative results.The results of OODS benchmark are shown in Tab. 1.The results summarize two salient conclusions: (i) Sophisticated LLMs are state-of-the-art zero-shot batch-level anomaly detectors.Comparing GPT-4 against ECOD, state-of-the-art method on ODDS benchmark, GPT-4 shows on-par performance without extra fine-tuning, indicating the huge potential of LLMs in the anomaly detection task.(ii) Proposed end-to-end fine-tuning strategy significantly boost the performance.Checking the performance of the same LLM before and after fine-tuning (Llama2 vs.</p>
<p>Using "zero-shot batch-level" stresses that our proposed method is a deep learning-based method rather than a shallow method.
We also tried to relax this independence assumption and input the data as a vector. However, the performance degrades. The reason could be that LLMs cannot distinguish a vector from a set of scalars. For the latter, the order between elements is unimportant.
Experimental performance is not sensitive to data names. We also named data by "Row" instead of "Data" as if in a table where columns correspond to features or data dimensions and rows index data points. The experimental performance is similar.
Use "Only answer row numbers" when data are named "Row."
https://outlines-dev.github.io/outlines/
We facilitate optimization convergence by designing highprobability response formats and using complete, grammarconsistent sentences.
The two-standard deviation range refers to the interval[−2σ, 2σ]  where σ is the standard deviation. Any data points located outside this range are considered abnormal.
Specifically, we use api of gpt-3.5-turbo-1106 and gpt-4-1106preview.
A Synthetic DatasetA.1 Data Generating Processes Data generating processes of synthetic discrete and continuous data are presented in Alg. 2 and Alg. 3, respectively.Discrete data is a mixture of normal and abnormal Categorical distributions.Continuous data is the clutter setup where normal data is sampled from a narrow Gaussian distribution while anomalies are from another wide Gaussian distribution.In practice, we generate the discrete data by setting the hyperparameters N l = 20, N h = 100, π l = 0.01, π h = 0.2, M l = 1, M h = 4, α = 20.For continuous data generation, we choose N l = 20, N h = 100, π l = 0.01, π h = 0.2, µ l = −100, µ h = 100, σ l n = 0.5, σ h n = 5.For both data types, the contamination ratio π is smaller than 0.2.Algorithm 2 Generate discrete datap n ∼ Dir({α} Mn ) 5: p a ∼ Dir({α} Ma ) 6: for i = 1, . . ., N do 7:x i ∼ {(1 − π)p n , πp a } 8: end for 9: return {x i }, i = 1, . . ., N Algorithm 3 Generate continuous data5: σ a = 10σ n 6: for i = 1, . . ., N do 7:xA.2 Data ExamplesB Implementation DetailsB.1 Prediction Extraction ProcedureThe automatic procedure for extracting model predictions in all experiments is the following code snippet in Python.def parse_generation_results(ans, max_num=149): response_ret = [] if ans.endswith("."):ans = ans.rstrip(".")ans = ans.rsplit(":-&gt;",1)[-1] if ":" in and: ans = ans.replace(":"," ") ans = ans.replace(",","") ans = ans.split()if "no" in ans or "No" in ans or "None" in and:return [] for r in and: if r.isnumeric() and "." not in r and int(r)&lt;= max_num: response_ret.append(int(r))return response_retB.2 Qualitative StudyIn Fig.4, we use p(x) = 0.45N (−25, 2.5 2 ) + 0.45N (25, 2.5 2 ) + 0.1Unif(−100, 100).pa (x) is estimated by a kernel density estimator with 5.0-bandwidth Gaussian kernels.The predicted anomalies are collected from 500 independent batch predictions, where each batch contains 50 data points sampled from p(x).B.3 Quantitative StudyImplementation details.The output from LLMs are naturally diverse and less controllable.A system prompt: "Only answer row numbers." is passed to all LLMs to easier parse the responses for evaluation.We manually filter unreasonable predictions of LLMs.Specifically, (i) we ignore predictions that beyond provided data samples; (ii) we choose the semantic consistent one if the output contains multiple answers.We repeat all experiments 3 times with different random seeds.All our experiments are implemented with Py-Torch using A6000 GPU.For Llama-2 and Mistral, the temperature and top p generation hyperparameters are set as 0.75 and 0.9, respectively.For GPT-3.5 and GPT-4, we use the default hypereparameter settings.We fine-tune all models using LoRA parameter-efficient fine-tuning strategy[Hu et al., 2022].We finetune Llama-2 for five epochs and Mistral for two epochs with the same learning rate 1e-3.All optimizations are convergent.
On the other hand, for GPT-3.5 and GPT-4, we use their default hyperparameter settings and perform the experiments through their API. We fine-tune Llama-2-7B and Mistral-7B using LoRA parameter-efficient fine-tuning strategy [Hu et al., 2022] on our synthetic datasets. We generate training and validation sets separately. The training set involves 5000 data batches (2500 continuous data batches and 2500 discrete data batches), while the validation set contains 400 data batches (200 for continuous and 200 for discrete data). top p generation hyperparameters are set as 0.75 and 0.9 for Llama-2 and Mistral, respectively. The resulting models are named Llama2-AD and Mistral-AD</p>
<p>Semantic anomaly detection with large language models. Breunig, Proceedings of the 2000 ACM SIGMOD international conference on Management of data. the 2000 ACM SIGMOD international conference on Management of dataEdward Schmerling, Issa AD Nesnas, and Marco Pavone2000. 2000. 2009. 2009. 2023. 2023. 202341Autonomous Robots</p>
<p>Anomalygpt: Detecting industrial anomalies using large visionlanguage models. Gruver, mathprompter:The 61st Annual Meeting Of The Association For Computational Linguistics. ICLR2024. 2024. 2024. 1932-1940, 2024. 2022. 2022. 202336Proceedings of the AAAI Conference on Artificial Intelligence</p>
<p>Ecod: Unsupervised outlier detection using empirical cumulative distribution functions. Jiang, arXiv:2310.068252008 eighth ieee international conference on data mining. Avanika Narayan, Ines Chami, Laurel Orr, Christopher Ré, Alex RayIEEE2023. 2023. 2022. 2022. 2022. 2022. 2023. 19882-19910. PMLR, 2023. 2024. 2024. 2008. 2008. 2022. 2022. 202235arXiv preprintProceedings of the VLDB Endowment. Ouyang et al., 2022. et al. Training language models to follow instructions with human feedback. Advances in neural information processing systems</p>
<p>Enhancing anomaly detection in financial markets with an llm-based multi-agent framework. Taejin Park, ; Park, Qiu, arXiv:2403.19735Proceedings of the 2000 ACM SIGMOD international conference on Management of data. Sridhar Ramaswamy, Rajeev Rastogi, Kyuseok Shim, the 2000 ACM SIGMOD international conference on Management of dataPMLR2024. 2024. 2022. 2022. 2000arXiv preprintInternational conference on machine learning</p>
<p>A unifying review of deep and shallow anomaly detection. Rayana ; Roziere, arXiv:2308.12950Shebuti Rayana. ODDS library. 2016. 2016. 2023. 2023. 2021109arXiv preprintCode llama: Open foundation models for code</p>
<p>Large language models for forecasting and anomaly detection: A systematic literature review. Su, arXiv:2402.10350arXiv:2307.09702Advances in Neural Information Processing Systems. Wei, 2024. 2024. 2004. 2004. 2023. 2023. 2022. 2022. 202354arXiv preprintNeurIPS 2022 First Table Representation Workshop. Willard and Louf, 2023] Brandon T Willard and Rémi Louf. Efficient guided generation for llms</p>
<p>Chong Zhou and Randy C Paffenroth. Anomaly detection with robust deep autoencoders. Xu, Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. the 23rd ACM SIGKDD international conference on knowledge discovery and data mining2010. 2010. 2017. 201723Advances in neural information processing systems</p>
<p>Instruction-following evaluation for large language models. Zhou, arXiv:2311.079112023. 2023arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>