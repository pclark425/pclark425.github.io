<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8935 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8935</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8935</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-155.html">extraction-schema-155</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models (LLMs) are used to generate or design novel chemicals for specific applications, including details of the models, methods, applications, results, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-ddc1899e59a8e4fda60f5a175fef710a63abcef9</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/ddc1899e59a8e4fda60f5a175fef710a63abcef9" target="_blank">DrugAssist: a large language model for molecule optimization</a></p>
                <p><strong>Paper Venue:</strong> Briefings Bioinform.</p>
                <p><strong>Paper TL;DR:</strong> The proposed DrugAssist is an interactive molecule optimization model which performs optimization through human–machine dialogue by leveraging LLM’s strong interactivity and generalizability, simultaneously showcasing immense potential in transferability and iterative optimization.</p>
                <p><strong>Paper Abstract:</strong> Abstract Recently, the impressive performance of large language models (LLMs) on a wide range of tasks has attracted an increasing number of attempts to apply LLMs in drug discovery. However, molecule optimization, a critical task in the drug discovery pipeline, is currently an area that has seen little involvement from LLMs. Most of existing approaches focus solely on capturing the underlying patterns in chemical structures provided by the data, without taking advantage of expert feedback. These non-interactive approaches overlook the fact that the drug discovery process is actually one that requires the integration of expert experience and iterative refinement. To address this gap, we propose DrugAssist, an interactive molecule optimization model which performs optimization through human–machine dialogue by leveraging LLM’s strong interactivity and generalizability. DrugAssist has achieved leading results in both single and multiple property optimization, simultaneously showcasing immense potential in transferability and iterative optimization. In addition, we publicly release a large instruction-based dataset called ‘MolOpt-Instructions’ for fine-tuning language models on molecule optimization tasks. We have made our code and data publicly available at https://github.com/blazerye/DrugAssist, which we hope to pave the way for future research in LLMs’ application for drug discovery.</p>
                <p><strong>Cost:</strong> 0.02</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8935.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8935.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models (LLMs) are used to generate or design novel chemicals for specific applications, including details of the models, methods, applications, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DrugAssist</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DrugAssist (interactive molecule optimization LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An instruction-tuned, interactive molecule-optimization model built by fine-tuning Llama2-7B-Chat on a >1M instruction-style dataset (MolOpt-Instructions); it generates optimized SMILES via natural-language dialogue and supports multi-turn iterative refinement and multi-property/range-constrained objectives.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>DrugAssist (fine-tuned Llama2-7B-Chat)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer-based causal LLM (instruction-tuned chat model)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B parameters</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Fine-tuned on MolOpt-Instructions (~1.03M matched molecular pairs derived from ZINC via mmpdb, properties computed by iDrug) mixed with Stanford Alpaca instruction data (52k examples replicated to balance); instruction-tuned with multi-task learning.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Drug discovery — molecule/property optimization (Solubility, BBBP, hERG, QED, H-bond donors/acceptors) with single- and multi-property objectives and range constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Direct SMILES generation guided by natural-language prompts; supports multi-turn interactive optimization where human feedback or retrieved similar molecules act as hints (retrieval-assisted iterative refinement).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_of_chemicals</strong></td>
                            <td>Produces molecules structurally similar to inputs (dataset pairs were selected with similarity >0.65; dataset mean similarity ~0.69 ± 0.06) focusing on property improvement rather than generating wholly novel scaffolds; explicit fraction of novel (out-of-training) molecules not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>application_specificity</strong></td>
                            <td>Models are driven by explicit, property-focused instructions (increase/decrease, thresholds, or target ranges) and evaluated on property-specific objectives; supports combining properties (zero-shot multi-property requests) and few-shot adaptation to unseen properties.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Valid SMILES ratio, success/correct rate under 'loose' and 'strict' definitions (property increase/decrease or threshold; range tasks for solubility), average similarity between source and optimized molecules; property-specific thresholds (e.g., QED +0.1, BBBP +0.1).</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Outperformed baselines in single- and multi-property optimization. Representative numbers: Solubility success 0.74, BBBP success 0.80, simultaneous multi-property 'All' success 0.62, valid rate 0.98, average similarity 0.69 (Table 4). Across 16 tasks DrugAssist achieved high valid ratios (~0.95–0.99) and substantially higher correct ratios than other LLM baselines (e.g., QED+ correct ratio: 0.76 loose / 0.63 strict). Demonstrated zero-shot multi-property combination and few-shot adaptation to properties not seen during training (e.g., logP). Iterative, retrieval-assisted refinement enabled recovery from initial failures.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Compared to sequence-based models (Mol-Seq2Seq, Mol-Transformer) and LLM baselines (Llama2-7B-Chat baseline, GPT-3.5-turbo via ChatDrug, BioMedGPT-LM-7B), DrugAssist achieved higher success and validity rates. Mol-Transformer outperformed Mol-Seq2Seq but underperformed DrugAssist; GPT-3.5 often returned identical molecules while BioMedGPT-LM-7B frequently produced non-molecule outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_and_challenges</strong></td>
                            <td>Lower success on stricter/range-constrained tasks (notably the 'esol+ strict' range task). Evaluation relies on in silico property predictors (iDrug, RDKit) rather than experimental validation. The paper notes potential hallucination and multimodal limitations as future work. The model still benefits from human/retrieval hints for difficult cases. Synthesizability and experimental feasibility of generated molecules were not assessed in the study.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DrugAssist: a large language model for molecule optimization', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8935.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8935.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models (LLMs) are used to generate or design novel chemicals for specific applications, including details of the models, methods, applications, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Llama2-7B-Chat</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Llama 2 7B Chat</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Meta's open chat-capable LLM (7B) used both as the base model for fine-tuning (to produce DrugAssist) and as a comparative baseline for prompt-based molecule optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Llama 2: Open foundation and fine-tuned chat models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama2-7B-Chat</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer-based chat LLM</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B parameters</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Pretrained by Meta (pretraining data not detailed in this paper); used here either as baseline with prompting or as the fine-tuning starting point for DrugAssist.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>General-purpose LLM; evaluated for molecule optimization via prompt engineering in this work.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Prompt-based direct SMILES generation and multi-turn dialogue without specialized molecule instruction fine-tuning (unless further tuned).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_of_chemicals</strong></td>
                            <td>Not quantified in this paper; baseline outputs had lower success rates in property optimization and lower validity/correctness than DrugAssist.</td>
                        </tr>
                        <tr>
                            <td><strong>application_specificity</strong></td>
                            <td>Applied via crafted prompts to effect property changes; lacks the domain instruction fine-tuning present in DrugAssist.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Valid ratio and correct/success ratio under the same experimental tasks (Table 5 comparisons).</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Produced valid SMILES at moderate rates but low correctness on optimization objectives (e.g., QED+ correct ratio 0.17 loose), and was outperformed by DrugAssist across tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Serves as baseline chat LLM; DrugAssist (instruction-tuned) shows substantial gains over Llama2-7B-Chat prompted directly.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_and_challenges</strong></td>
                            <td>Without task-specific instruction tuning, performance on molecule optimization tasks is limited; lower ability to follow strict property-range instructions and multi-property combinations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DrugAssist: a large language model for molecule optimization', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8935.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8935.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models (LLMs) are used to generate or design novel chemicals for specific applications, including details of the models, methods, applications, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3.5-turbo</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatGPT (GPT-3.5-turbo)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A GPT-family chat model (used via the ChatDrug workflow) applied to molecular editing tasks using carefully crafted prompts; in experiments it produced high valid-SMILES rates but low optimization success and often returned identical molecules.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-turbo (ChatGPT)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>GPT-style transformer LLM</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Prompt-driven molecule editing and conversational drug editing (evaluated here via the ChatDrug workflow).</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Prompt-based direct generation and multi-turn dialogue; used ChatDrug prompts and retrieval-assisted iterative process in comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_of_chemicals</strong></td>
                            <td>Often low in practice here — the paper reports many cases where GPT-3.5-turbo returned the input molecule unchanged, indicating low novelty of edits in this experimental setup.</td>
                        </tr>
                        <tr>
                            <td><strong>application_specificity</strong></td>
                            <td>Relies on crafted prompts (from ChatDrug) to target property changes; not instruction-tuned specifically for MolOpt-Instructions in this study.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Valid ratio and correct/success ratio across 16 tasks (see Table 5).</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>High valid ratio (e.g., 0.94–0.98 across several tasks) but generally low correct/success ratios (e.g., QED+ correct ratio 0.15), frequently failing to produce substantive optimizations.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Although its valid rate is competitive, GPT-3.5-turbo was outperformed by DrugAssist on correctness; often generated identical molecules whereas DrugAssist produced targeted property-improving edits.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_and_challenges</strong></td>
                            <td>Tendency to return identical molecules or fail to provide meaningful edits under the prompts used; benefits from domain-specific fine-tuning for better optimization performance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DrugAssist: a large language model for molecule optimization', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8935.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8935.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models (LLMs) are used to generate or design novel chemicals for specific applications, including details of the models, methods, applications, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BioMedGPT-LM-7B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BioMedGPT-LM-7B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Llama2-based biomedical generative LLM evaluated as a baseline for molecule optimization tasks; in these experiments it often failed to produce valid molecule outputs or misunderstood task instructions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Biomedgpt: Open multimodal generative pre-trained transformer for biomedicine</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BioMedGPT-LM-7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Llama2-based biomedical generative LLM</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B parameters</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Not specified in this paper (developed for biomedical domain in its own work).</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Biomedical generation and QA; evaluated here for molecule optimization prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Prompt-based generation and multi-turn dialogue.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_of_chemicals</strong></td>
                            <td>Not reported; frequently produced non-molecule or guidance outputs instead of SMILES, yielding low valid-SMILES rates.</td>
                        </tr>
                        <tr>
                            <td><strong>application_specificity</strong></td>
                            <td>Designed for biomedical tasks but not specialized/tuned for molecule-optimization instruction formats used in this evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Valid ratio and correct/success ratio across tasks (Table 5).</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Low valid ratios (e.g., often ~0.20–0.35) and low correct ratios; frequently misunderstood optimization prompts and generated text guidance rather than SMILES.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Underperformed compared to DrugAssist and GPT-3.5-turbo in these molecule-optimization tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_and_challenges</strong></td>
                            <td>Difficulty following molecule-optimization instructions in this setup; produced many non-SMILES outputs; indicates a gap between biomedical pretraining and instruction-following for molecule design.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DrugAssist: a large language model for molecule optimization', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8935.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e8935.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models (LLMs) are used to generate or design novel chemicals for specific applications, including details of the models, methods, applications, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MolOpt-Instructions</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MolOpt-Instructions dataset</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An instruction-style dataset released with this work containing over one million matched molecular pairs (derived from ZINC via mmpdb) annotated with computed properties and paired with natural-language optimization instructions for fine-tuning LLMs on molecule optimization tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Constructed from ~1,000,000 randomly sampled ZINC molecules; similar pairs generated with mmpdb MMPA; filtered for similarity >0.65 and logP difference >2.5; properties (Solubility, BBBP, hERG, QED, H-bond donors/acceptors) computed with iDrug and RDKit; ChatGPT helped generate candidate instruction templates which were manually refined.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Fine-tuning/instruction-tuning LLMs for molecule optimization in drug discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Used to create instruction-response pairs for supervised fine-tuning (instruction tuning) of LLMs; supports tasks: loose increase/decrease, strict thresholded changes, and range-constrained optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_of_chemicals</strong></td>
                            <td>Dataset focuses on matched pairs with moderate structural similarity (mean similarity ~0.69 ± 0.06) and substantial property differences (logP difference ~2.82 ± 0.31). Explicit out-of-sample novelty metrics for generated molecules are not provided.</td>
                        </tr>
                        <tr>
                            <td><strong>application_specificity</strong></td>
                            <td>Designed to train models to follow natural-language optimization directives for several ADMET and structural properties and to support multi-property and range-constrained tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Dataset statistics (unique pairs, molecules, similarity, logP difference), scaffold diversity (average molecules per scaffold ~2.95; >93.7% of scaffolds had ≤5 molecules), and distributions of structural/ADMET properties.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Enabled successful instruction-tuning of Llama2-7B-Chat to produce DrugAssist with strong performance on a suite of molecule-optimization tasks; addresses the lack of instruction-format molecule-optimization data.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Differs from traditional molecule-pair datasets by providing natural-language instructions and range-based tasks better aligned with real-world optimization objectives.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_and_challenges</strong></td>
                            <td>Property labels are computed in silico (iDrug/RDKit) rather than experimentally measured; dataset covers six properties only; selection criteria (similarity/logP thresholds) bias training toward matched-pair-style edits and may limit exposure to radical de novo generation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DrugAssist: a large language model for molecule optimization', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8935.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e8935.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models (LLMs) are used to generate or design novel chemicals for specific applications, including details of the models, methods, applications, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatDrug</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatDrug (conversational drug editing framework)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prior framework that uses prompt engineering and retrieval to enable conversational drug editing with general LLMs; cited/used as a baseline workflow here (GPT-3.5 results were obtained using ChatDrug prompts/workflow).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Chatgpt-powered conversational drug editing using retrieval and domain feedback</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Framework / prompt-and-retrieval workflow</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Conversational molecular design and drug editing via general LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Prompt engineering + retrieval of similar molecules + multi-turn human/LLM dialogue to iteratively edit molecules.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_of_chemicals</strong></td>
                            <td>Depends on the underlying LLM used; not quantified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>application_specificity</strong></td>
                            <td>Provides a retrieval-augmented workflow to guide LLMs in molecule editing tasks; used experimentally to compare general-LM prompt-based performance.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>When used in this paper's comparisons, metrics were valid-SMILES ratio and correctness/success across the same tasks used to evaluate DrugAssist.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Using ChatDrug prompts with GPT-3.5-turbo yielded high valid rates but low correctness; required retrieval and domain feedback to improve outputs but still underperformed specialized instruction-tuned models.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Represents prompt-and-retrieval baseline approaches relying on general LLMs; DrugAssist (instruction-tuned) outperformed this workflow in producing property-optimized molecules.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_and_challenges</strong></td>
                            <td>Relies strongly on the capabilities of the underlying LLM; without instruction tuning, outputs can be identical to inputs or fail to meet property objectives; retrieval and human feedback are needed to reach correct results in many cases.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DrugAssist: a large language model for molecule optimization', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Chatgpt-powered conversational drug editing using retrieval and domain feedback <em>(Rating: 2)</em></li>
                <li>Interactive molecular discovery with natural language <em>(Rating: 2)</em></li>
                <li>Biomedgpt: Open multimodal generative pre-trained transformer for biomedicine <em>(Rating: 2)</em></li>
                <li>Molecular optimization by capturing chemist's intuition using deep neural networks <em>(Rating: 1)</em></li>
                <li>Junction tree variational autoencoder for molecular graph generation <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8935",
    "paper_id": "paper-ddc1899e59a8e4fda60f5a175fef710a63abcef9",
    "extraction_schema_id": "extraction-schema-155",
    "extracted_data": [
        {
            "name_short": "DrugAssist",
            "name_full": "DrugAssist (interactive molecule optimization LLM)",
            "brief_description": "An instruction-tuned, interactive molecule-optimization model built by fine-tuning Llama2-7B-Chat on a &gt;1M instruction-style dataset (MolOpt-Instructions); it generates optimized SMILES via natural-language dialogue and supports multi-turn iterative refinement and multi-property/range-constrained objectives.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "DrugAssist (fine-tuned Llama2-7B-Chat)",
            "model_type": "Transformer-based causal LLM (instruction-tuned chat model)",
            "model_size": "7B parameters",
            "training_data": "Fine-tuned on MolOpt-Instructions (~1.03M matched molecular pairs derived from ZINC via mmpdb, properties computed by iDrug) mixed with Stanford Alpaca instruction data (52k examples replicated to balance); instruction-tuned with multi-task learning.",
            "application_domain": "Drug discovery — molecule/property optimization (Solubility, BBBP, hERG, QED, H-bond donors/acceptors) with single- and multi-property objectives and range constraints.",
            "generation_method": "Direct SMILES generation guided by natural-language prompts; supports multi-turn interactive optimization where human feedback or retrieved similar molecules act as hints (retrieval-assisted iterative refinement).",
            "novelty_of_chemicals": "Produces molecules structurally similar to inputs (dataset pairs were selected with similarity &gt;0.65; dataset mean similarity ~0.69 ± 0.06) focusing on property improvement rather than generating wholly novel scaffolds; explicit fraction of novel (out-of-training) molecules not reported.",
            "application_specificity": "Models are driven by explicit, property-focused instructions (increase/decrease, thresholds, or target ranges) and evaluated on property-specific objectives; supports combining properties (zero-shot multi-property requests) and few-shot adaptation to unseen properties.",
            "evaluation_metrics": "Valid SMILES ratio, success/correct rate under 'loose' and 'strict' definitions (property increase/decrease or threshold; range tasks for solubility), average similarity between source and optimized molecules; property-specific thresholds (e.g., QED +0.1, BBBP +0.1).",
            "results_summary": "Outperformed baselines in single- and multi-property optimization. Representative numbers: Solubility success 0.74, BBBP success 0.80, simultaneous multi-property 'All' success 0.62, valid rate 0.98, average similarity 0.69 (Table 4). Across 16 tasks DrugAssist achieved high valid ratios (~0.95–0.99) and substantially higher correct ratios than other LLM baselines (e.g., QED+ correct ratio: 0.76 loose / 0.63 strict). Demonstrated zero-shot multi-property combination and few-shot adaptation to properties not seen during training (e.g., logP). Iterative, retrieval-assisted refinement enabled recovery from initial failures.",
            "comparison_to_other_methods": "Compared to sequence-based models (Mol-Seq2Seq, Mol-Transformer) and LLM baselines (Llama2-7B-Chat baseline, GPT-3.5-turbo via ChatDrug, BioMedGPT-LM-7B), DrugAssist achieved higher success and validity rates. Mol-Transformer outperformed Mol-Seq2Seq but underperformed DrugAssist; GPT-3.5 often returned identical molecules while BioMedGPT-LM-7B frequently produced non-molecule outputs.",
            "limitations_and_challenges": "Lower success on stricter/range-constrained tasks (notably the 'esol+ strict' range task). Evaluation relies on in silico property predictors (iDrug, RDKit) rather than experimental validation. The paper notes potential hallucination and multimodal limitations as future work. The model still benefits from human/retrieval hints for difficult cases. Synthesizability and experimental feasibility of generated molecules were not assessed in the study.",
            "uuid": "e8935.0",
            "source_info": {
                "paper_title": "DrugAssist: a large language model for molecule optimization",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Llama2-7B-Chat",
            "name_full": "Llama 2 7B Chat",
            "brief_description": "Meta's open chat-capable LLM (7B) used both as the base model for fine-tuning (to produce DrugAssist) and as a comparative baseline for prompt-based molecule optimization.",
            "citation_title": "Llama 2: Open foundation and fine-tuned chat models",
            "mention_or_use": "use",
            "model_name": "Llama2-7B-Chat",
            "model_type": "Transformer-based chat LLM",
            "model_size": "7B parameters",
            "training_data": "Pretrained by Meta (pretraining data not detailed in this paper); used here either as baseline with prompting or as the fine-tuning starting point for DrugAssist.",
            "application_domain": "General-purpose LLM; evaluated for molecule optimization via prompt engineering in this work.",
            "generation_method": "Prompt-based direct SMILES generation and multi-turn dialogue without specialized molecule instruction fine-tuning (unless further tuned).",
            "novelty_of_chemicals": "Not quantified in this paper; baseline outputs had lower success rates in property optimization and lower validity/correctness than DrugAssist.",
            "application_specificity": "Applied via crafted prompts to effect property changes; lacks the domain instruction fine-tuning present in DrugAssist.",
            "evaluation_metrics": "Valid ratio and correct/success ratio under the same experimental tasks (Table 5 comparisons).",
            "results_summary": "Produced valid SMILES at moderate rates but low correctness on optimization objectives (e.g., QED+ correct ratio 0.17 loose), and was outperformed by DrugAssist across tasks.",
            "comparison_to_other_methods": "Serves as baseline chat LLM; DrugAssist (instruction-tuned) shows substantial gains over Llama2-7B-Chat prompted directly.",
            "limitations_and_challenges": "Without task-specific instruction tuning, performance on molecule optimization tasks is limited; lower ability to follow strict property-range instructions and multi-property combinations.",
            "uuid": "e8935.1",
            "source_info": {
                "paper_title": "DrugAssist: a large language model for molecule optimization",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "GPT-3.5-turbo",
            "name_full": "ChatGPT (GPT-3.5-turbo)",
            "brief_description": "A GPT-family chat model (used via the ChatDrug workflow) applied to molecular editing tasks using carefully crafted prompts; in experiments it produced high valid-SMILES rates but low optimization success and often returned identical molecules.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-turbo (ChatGPT)",
            "model_type": "GPT-style transformer LLM",
            "model_size": null,
            "training_data": null,
            "application_domain": "Prompt-driven molecule editing and conversational drug editing (evaluated here via the ChatDrug workflow).",
            "generation_method": "Prompt-based direct generation and multi-turn dialogue; used ChatDrug prompts and retrieval-assisted iterative process in comparisons.",
            "novelty_of_chemicals": "Often low in practice here — the paper reports many cases where GPT-3.5-turbo returned the input molecule unchanged, indicating low novelty of edits in this experimental setup.",
            "application_specificity": "Relies on crafted prompts (from ChatDrug) to target property changes; not instruction-tuned specifically for MolOpt-Instructions in this study.",
            "evaluation_metrics": "Valid ratio and correct/success ratio across 16 tasks (see Table 5).",
            "results_summary": "High valid ratio (e.g., 0.94–0.98 across several tasks) but generally low correct/success ratios (e.g., QED+ correct ratio 0.15), frequently failing to produce substantive optimizations.",
            "comparison_to_other_methods": "Although its valid rate is competitive, GPT-3.5-turbo was outperformed by DrugAssist on correctness; often generated identical molecules whereas DrugAssist produced targeted property-improving edits.",
            "limitations_and_challenges": "Tendency to return identical molecules or fail to provide meaningful edits under the prompts used; benefits from domain-specific fine-tuning for better optimization performance.",
            "uuid": "e8935.2",
            "source_info": {
                "paper_title": "DrugAssist: a large language model for molecule optimization",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "BioMedGPT-LM-7B",
            "name_full": "BioMedGPT-LM-7B",
            "brief_description": "A Llama2-based biomedical generative LLM evaluated as a baseline for molecule optimization tasks; in these experiments it often failed to produce valid molecule outputs or misunderstood task instructions.",
            "citation_title": "Biomedgpt: Open multimodal generative pre-trained transformer for biomedicine",
            "mention_or_use": "use",
            "model_name": "BioMedGPT-LM-7B",
            "model_type": "Llama2-based biomedical generative LLM",
            "model_size": "7B parameters",
            "training_data": "Not specified in this paper (developed for biomedical domain in its own work).",
            "application_domain": "Biomedical generation and QA; evaluated here for molecule optimization prompts.",
            "generation_method": "Prompt-based generation and multi-turn dialogue.",
            "novelty_of_chemicals": "Not reported; frequently produced non-molecule or guidance outputs instead of SMILES, yielding low valid-SMILES rates.",
            "application_specificity": "Designed for biomedical tasks but not specialized/tuned for molecule-optimization instruction formats used in this evaluation.",
            "evaluation_metrics": "Valid ratio and correct/success ratio across tasks (Table 5).",
            "results_summary": "Low valid ratios (e.g., often ~0.20–0.35) and low correct ratios; frequently misunderstood optimization prompts and generated text guidance rather than SMILES.",
            "comparison_to_other_methods": "Underperformed compared to DrugAssist and GPT-3.5-turbo in these molecule-optimization tasks.",
            "limitations_and_challenges": "Difficulty following molecule-optimization instructions in this setup; produced many non-SMILES outputs; indicates a gap between biomedical pretraining and instruction-following for molecule design.",
            "uuid": "e8935.3",
            "source_info": {
                "paper_title": "DrugAssist: a large language model for molecule optimization",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "MolOpt-Instructions",
            "name_full": "MolOpt-Instructions dataset",
            "brief_description": "An instruction-style dataset released with this work containing over one million matched molecular pairs (derived from ZINC via mmpdb) annotated with computed properties and paired with natural-language optimization instructions for fine-tuning LLMs on molecule optimization tasks.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": null,
            "model_type": null,
            "model_size": null,
            "training_data": "Constructed from ~1,000,000 randomly sampled ZINC molecules; similar pairs generated with mmpdb MMPA; filtered for similarity &gt;0.65 and logP difference &gt;2.5; properties (Solubility, BBBP, hERG, QED, H-bond donors/acceptors) computed with iDrug and RDKit; ChatGPT helped generate candidate instruction templates which were manually refined.",
            "application_domain": "Fine-tuning/instruction-tuning LLMs for molecule optimization in drug discovery.",
            "generation_method": "Used to create instruction-response pairs for supervised fine-tuning (instruction tuning) of LLMs; supports tasks: loose increase/decrease, strict thresholded changes, and range-constrained optimization.",
            "novelty_of_chemicals": "Dataset focuses on matched pairs with moderate structural similarity (mean similarity ~0.69 ± 0.06) and substantial property differences (logP difference ~2.82 ± 0.31). Explicit out-of-sample novelty metrics for generated molecules are not provided.",
            "application_specificity": "Designed to train models to follow natural-language optimization directives for several ADMET and structural properties and to support multi-property and range-constrained tasks.",
            "evaluation_metrics": "Dataset statistics (unique pairs, molecules, similarity, logP difference), scaffold diversity (average molecules per scaffold ~2.95; &gt;93.7% of scaffolds had ≤5 molecules), and distributions of structural/ADMET properties.",
            "results_summary": "Enabled successful instruction-tuning of Llama2-7B-Chat to produce DrugAssist with strong performance on a suite of molecule-optimization tasks; addresses the lack of instruction-format molecule-optimization data.",
            "comparison_to_other_methods": "Differs from traditional molecule-pair datasets by providing natural-language instructions and range-based tasks better aligned with real-world optimization objectives.",
            "limitations_and_challenges": "Property labels are computed in silico (iDrug/RDKit) rather than experimentally measured; dataset covers six properties only; selection criteria (similarity/logP thresholds) bias training toward matched-pair-style edits and may limit exposure to radical de novo generation.",
            "uuid": "e8935.4",
            "source_info": {
                "paper_title": "DrugAssist: a large language model for molecule optimization",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "ChatDrug",
            "name_full": "ChatDrug (conversational drug editing framework)",
            "brief_description": "A prior framework that uses prompt engineering and retrieval to enable conversational drug editing with general LLMs; cited/used as a baseline workflow here (GPT-3.5 results were obtained using ChatDrug prompts/workflow).",
            "citation_title": "Chatgpt-powered conversational drug editing using retrieval and domain feedback",
            "mention_or_use": "mention",
            "model_name": null,
            "model_type": "Framework / prompt-and-retrieval workflow",
            "model_size": null,
            "training_data": null,
            "application_domain": "Conversational molecular design and drug editing via general LLMs.",
            "generation_method": "Prompt engineering + retrieval of similar molecules + multi-turn human/LLM dialogue to iteratively edit molecules.",
            "novelty_of_chemicals": "Depends on the underlying LLM used; not quantified in this paper.",
            "application_specificity": "Provides a retrieval-augmented workflow to guide LLMs in molecule editing tasks; used experimentally to compare general-LM prompt-based performance.",
            "evaluation_metrics": "When used in this paper's comparisons, metrics were valid-SMILES ratio and correctness/success across the same tasks used to evaluate DrugAssist.",
            "results_summary": "Using ChatDrug prompts with GPT-3.5-turbo yielded high valid rates but low correctness; required retrieval and domain feedback to improve outputs but still underperformed specialized instruction-tuned models.",
            "comparison_to_other_methods": "Represents prompt-and-retrieval baseline approaches relying on general LLMs; DrugAssist (instruction-tuned) outperformed this workflow in producing property-optimized molecules.",
            "limitations_and_challenges": "Relies strongly on the capabilities of the underlying LLM; without instruction tuning, outputs can be identical to inputs or fail to meet property objectives; retrieval and human feedback are needed to reach correct results in many cases.",
            "uuid": "e8935.5",
            "source_info": {
                "paper_title": "DrugAssist: a large language model for molecule optimization",
                "publication_date_yy_mm": "2023-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Chatgpt-powered conversational drug editing using retrieval and domain feedback",
            "rating": 2
        },
        {
            "paper_title": "Interactive molecular discovery with natural language",
            "rating": 2
        },
        {
            "paper_title": "Biomedgpt: Open multimodal generative pre-trained transformer for biomedicine",
            "rating": 2
        },
        {
            "paper_title": "Molecular optimization by capturing chemist's intuition using deep neural networks",
            "rating": 1
        },
        {
            "paper_title": "Junction tree variational autoencoder for molecular graph generation",
            "rating": 1
        }
    ],
    "cost": 0.0204645,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>DrugAssist: A Large Language Model for MOLECULE OPTIMIZATION</h1>
<p>Geyan Ye, ${ }^{1 \dagger}$ Xibao Cai, ${ }^{2 \dagger}$ Houtim Lai, ${ }^{1}$ Xing Wang, ${ }^{1}$ Junhong Huang, ${ }^{1}$<br>Longyue Wang, ${ }^{1 *}$ Wei Liu ${ }^{1}$ \&amp; Xiangxiang Zeng ${ }^{2}$<br>${ }^{1}$ Tencent AI Lab ${ }^{2}$ Department of Computer Science, Hunan University<br>{blazerye, vinnylywang, topliu}@tencent.com<br>{dalecai, xzeng}@hnu.edu.cn</p>
<h4>Abstract</h4>
<p>Recently, the impressive performance of large language models (LLMs) on a wide range of tasks has attracted an increasing number of attempts to apply LLMs in drug discovery. However, molecule optimization, a critical task in the drug discovery pipeline, is currently an area that has seen little involvement from LLMs. Most of existing approaches focus solely on capturing the underlying patterns in chemical structures provided by the data, without taking advantage of expert feedback. These non-interactive approaches overlook the fact that the drug discovery process is actually one that requires the integration of expert experience and iterative refinement. To address this gap, we propose DrugAssist, an interactive molecule optimization model which performs optimization through humanmachine dialogue by leveraging LLM's strong interactivity and generalizability. DrugAssist has achieved leading results in both single and multiple property optimization, simultaneously showcasing immense potential in transferability and iterative optimization. In addition, we publicly release a large instructionbased dataset called "MolOpt-Instructions" for fine-tuning language models on molecule optimization tasks. We have made our code and data publicly available at https://github.com/blazerye/DrugAssist, which we hope to pave the way for future research in LLMs' application for drug discovery.</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: The illustration of our proposed DrugAssist model framework, which focus on optimizing molecules through human-machine dialogue.</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>1 INTRODUCTION</h1>
<p>Recently, generative artificial intelligence has made remarkable strides in the field of natural language processing (NLP), particularly with the advent of Large Language Models (LLMs) such as GPT (Generative Pre-trained Transformer) (Radford et al., 2019). These models have demonstrated impressive capabilities in a wide range of tasks, extending far beyond everyday communication and question-answering scenarios. Researchers have increasingly recognized the potential of these models in addressing complex and diverse problems across various domains, prompting interests in their applications within professional fields.</p>
<p>In recent years, there has been an increasing number of attempts to apply conversational LLMs in the field of drug discovery (Yunxiang et al., 2023; Han et al., 2023; Wu et al., 2023; Luo et al., 2023; Zeng et al., 2023; Liu et al., 2023b). However, molecule optimization, a critical task in the drug discovery pipeline, is currently an area that has seen little involvement from LLMs. Existing approaches can be broadly categorized into two main types. The first type represents molecules as sequences (commonly SMILES strings) and generates an optimized molecular sequence by learning from the input data. The second type of approach represents molecules as graphs and formulates molecule optimization as a graph-to-graph translation problem (He et al., 2022). One of the major issues with these approaches is the lack of interactivity. They focus solely on capturing the underlying patterns in chemical structures provided by the data, without taking advantage of the invaluable expert experience and feedback. In contrast, the drug discovery pipeline involves iterative refining processes that entail conversations with domain experts to incorporate their feedback, ultimately achieving the desired outcome (Liu et al., 2023b).</p>
<p>In light of the advancements in powerful LLMs, our work aims to leverage their strong interactivity and generalizability for molecule optimization. To the best of our knowledge, there are currently no molecule optimization models that focus on human-machine interaction. We summarize main contributions of this work as follows:</p>
<ul>
<li>To facilitate future research, we publicly release a large instruction-based dataset called "MolOptInstructions" for fine-tuning language models on molecule optimization tasks. The dataset contains an adequate amount of data, ensuring both similarity constraints and a substantial difference in properties between molecules.</li>
<li>We propose DrugAssist, an interactive molecule optimization model fine-tuned on Llama2-7BChat, which performs optimization through human-machine dialogue. By enabling multi-turn conversations, domain experts can guide the model in further optimizing initially generated molecules with imperfections.</li>
<li>Compared to traditional molecular optimization approaches (He et al., 2021; Jin et al., 2020) and LLM-based implementations (Liu et al., 2023b; Luo et al., 2023), DrugAssist has consistently achieved leading results in multi-property optimization, which is a less frequently addressed and more challenging task in molecule optimization. Moreover, our optimization objectives include maintaining optimized molecular property values within a given range. DrugAssist continues to demonstrate impressive performance in this category of tasks, which are more aligned with real-world requirements compared to most studies that solely focus on increasing or decreasing property values.</li>
</ul>
<h2>2 Related Work</h2>
<h3>2.1 TRADITIONAL APPROACHES IN MOLECULE OPTIMIZATION</h3>
<p>Based on the different representations of molecules, we can divide these models into two categories: sequence-based and graph-based.</p>
<p>Sequence-based Most of these methods utilize SMILES (Simplified Molecular-Input Line-Entry System) string as the molecular representation. They view molecule optimization as machine translation problem in natural language processing (NLP), where a text is translated from one language to another (He et al., 2021). Similar to translation tasks in NLP, the conversion between molecules encoded in SMILES in molecular optimization tasks can also be seen as a transformation between "languages". The main architectures for this category of models include recurrent neural networks</p>
<p>(RNNs) (Gupta et al., 2018; Bjerrum \&amp; Threlfall, 2017; Segler et al., 2018), variational autoencoders (VAEs) (Jin et al., 2018a;b; Dai et al., 2018; Liu et al., 2018; Simonovsky \&amp; Komodakis, 2018), and Transformer (He et al., 2021; 2022). Meanwhile, reinforcement learning (Olivecrona et al., 2017; Putin et al., 2018), adversarial training (Kadurin et al., 2017), and transfer learning (Segler et al., 2018) serve as typical optimization techniques. Considering the significant progress has made in the field of LLMs in recent years, we believe that these sequence-based molecule optimization methods have great potential for further exploration.</p>
<p>Graph-based These methods typically use graph to represent molecules and directly generate molecule graphs. VAEs are also very popular in molecular graph generation. Jin et al. (2018a) decomposed a molecular graph into a junction tree of chemical substructures. Then, they employed a junction tree VAE (JT-VAE) to generate molecules with improved properties by applying gradient ascent over the learned latent space. Subsequent works have derived many variants based on JTVAE, such as VJTNN (Jin et al., 2018b), HierG2G (Jin et al., 2020), etc. In comparison to sequencebased methods, a notable distinction is that most graph-based approaches, such as JT-VAE, can consistently generate valid molecules due to the validation checks performed at each step of the generation process.</p>
<p>Despite the achievements of the aforementioned methods in the field of molecule optimization, we believe that they still have some shortcomings that need to be addressed:</p>
<ul>
<li>Most of the existing works focus on optimizing a single property of molecules, while there are few that simultaneously optimize multiple properties, which is a more common requirement in real life. Moreover, in most works, the optimization goal is to maximize the difference in properties between the optimized and original molecules while satisfying a certain similarity constraint. Alongside this, it's worth noting that in real-life situations, there is often a need for the property value of the optimized molecule to fall within a specific range, an aspect that has received little attention in existing research.</li>
<li>Most methods suffer from catastrophic forgetting when the optimization task is changed. For example, a model that performs well in optimizing QED values of molecules needs to be retrained on a dataset containing $\log \mathrm{P}$ property before being used to optimize $\log \mathrm{P}$ values. This approach not only incurs additional costs but also suffers from a lack of sufficient experimental data to facilitate training for some molecular properties, such as ADMET.</li>
<li>To the best of our knowledge, no existing studies have focused on the interactivity of these molecular optimization models. Interactive models facilitate effective communication between domain experts and artificial intelligence models. Experts can conveniently provide feedback and suggestions to the model in the form of natural language, and the model can also obtain real-time access to expert experience related to specific problems. However, existing approaches struggle to efficiently utilize these valuable expert experiences and feedback.</li>
</ul>
<h1>2.2 LLMS IN BIOMEDICAL DOMAIN</h1>
<p>In recent years, there has been an increasing number of attempts to apply LLMs in the field of biomedicine. The majority of research efforts are centered around QA (question-answering) tasks, such as Chatdoctor (Yunxiang et al., 2023), Med-Alpaca (Han et al., 2023), PMC-LLaMA (Wu et al., 2023) that focus on medical QA, and BioMedGPT (Luo et al., 2023) on molecule/protein QA. There is relatively much less work focused on addressing practical tasks within the drug discovery domain. ChatMol (Zeng et al., 2023) is employed for conversational molecular design, specifically, it can accomplish two tasks: molecule understanding and molecule generation, which involve bidirectional conversion between molecular descriptions and SMILES strings of molecules. ChatDrug (Liu et al., 2023b) is a framework to facilitate drug editing using LLMs. Specifically, following the ChatDrug workflow, users can obtain carefully crafted prompts that assist in obtaining suggestions on drug editing tasks from general LLMs, such as ChatGPT.</p>
<h2>3 MEthods</h2>
<p>Our methodology incorporates two primary components: the construction of our MolOptInstructions dataset and the subsequent instruction tuning of Llama2-7B-chat model.</p>
<h1>3.1 Construction of MolOpt-Instructions Dataset</h1>
<p>Most of datasets currently used for molecule optimization are in the form of "molecule-molecule pairs", which cannot be directly used to train language models like Llama. Although Fang et al. (2023) introduce a comprehensive instruction dataset specifically designed for training Large Language Models in the biomedical domain, it does not cover tasks associated with molecule optimization. Additionally, in some popular benchmark dataset (Jin et al., 2018b), the molecule pairs which are relatively few in number, only satisfy similarity constraints, and the difference in properties between the molecules within the same pair is not sufficiently significant. To tackle these issues, we construct instruction-based datasets called "MolOpt-Instructions" for fine-tuning language models on molecule optimization tasks. It contains an adequate amount of data, ensuring both similarity constraints and a substantial difference in properties between molecules.</p>
<p>Overview and Statistics MolOpt-Instructions consists over one million molecule pairs. Currently, it includes six types of molecular properties, namely Solubility, BBBP (Blood-Brain Barrier Penetration), hERG (Human Ether-a-go-go-Related Gene) inhibition, QED (Quantitative Estimate of Drug-likeness) and the number of hydrogen bond donor and acceptor, with detailed information provided in Table 1.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Unique pairs</th>
<th style="text-align: center;">Unique molecules</th>
<th style="text-align: center;">Similarity</th>
<th style="text-align: center;">LogP difference</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">$1,029,949$</td>
<td style="text-align: center;">$1,595,839$</td>
<td style="text-align: center;">$0.69 \pm 0.06$</td>
<td style="text-align: center;">$2.82 \pm 0.31$</td>
</tr>
</tbody>
</table>
<p>Table 1: Statistics of our proposed MolOpt-Instructions dataset. It contains an adequate amount of data, ensuring both similarity constraints and a substantial difference in properties between molecules.</p>
<p>Data Construction The workflow of the data construction is shown in Figure 2. To begin with, we randomly selected one million molecules from ZINC database (Irwin \&amp; Shoichet, 2005). Then, we used mmpdb (Dalke et al., 2018) to construct a database from these molecules and generate similar pairs. Mmpdb, an open-source Matched Molecular Pair (MMP) platform, generates MMPs through Matched Molecular Pair Analysis (MMPA). In essence, a MMP consists of two molecules that differ by a defined structural transformation, resulting in highly similar molecular structures within the pairs generated by mmpdb. Following this, we selected the molecular pairs that met our requirements from these candidates. Our selection criteria are as follows: the similarity between each pair of molecules should be greater than 0.65 , and the difference in $\log P$ should be greater than 2.5. Once we identified the suitable molecular pairs, we proceeded to calculate their property values using iDrug, an AI-driven drug discovery platform developed by Tencent (iDrug, 2020). To make the data more balanced, we maintain a roughly 1:1 ratio of increased to decreased property values for target molecules relative to source molecules by swapping the source and target molecules of some pairs. The rationale behind choosing the difference in $\log \mathrm{P}$ as a screening criterion lies in its close relation to various aspects of a molecule's biological activity and pharmacokinetics. After obtaining these pairs and their corresponding property values, we asked ChatGPT to suggest a variety of instructions and manually refine them for the molecule optimization tasks.</p>
<p>We designed three types of optimization tasks: the first category requires only an increase or decrease in the given property value; the second category adds a threshold requirement for the increase or decrease; and the third category requires the optimized property value to be within a given range. In Table 2, we show an example of an instruction for each of these three categories. All instructions in the dataset can be found in https://github.com/blazerye/DrugAssist.</p>
<p>Different from several widely used molecule optimization datasets, our optimization tasks are not just vaguely asking to "optimize the given molecule", but also have range requirements, making them more closely aligned with real-world scenarios.</p>
<p>Analysis and Discussion To ensure the diversity of molecules in our dataset, we employ Murcko scaffold analysis to evaluate the chemical diversity of the source molecules randomly selected from ZINC database. The average molecules per scaffold is 2.95 , and more than $93.7 \%$ of the scaffolds contained no more than five molecules. The scaffold analysis indicates a high degree of structural</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: The workflow of data construction of MolOpt-Instructions. First, we randomly picked one million molecules from the ZINC dataset. Then, we used mmpb (Dalke et al., 2018) to generate similar pairs based on these molecules and selected the molecular pairs that met our requirements from these candidates. Once we identified the suitable molecular pairs, we proceeded to calculate their property values using iDrug (iDrug, 2020). After obtaining these pairs and their corresponding property values, we asked ChatGPT to suggest a variety of instructions and manually refine them for the molecule optimization tasks.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Task category</th>
<th style="text-align: left;">Example prompt</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">loose</td>
<td style="text-align: left;">I have a molecule with the SMILES string [SMILES]. Suggest modifications <br> to increase its [property] value while maintaining its core structure.</td>
</tr>
<tr>
<td style="text-align: center;">strict</td>
<td style="text-align: left;">I have a molecule with the SMILES string [SMILES]. Suggest modifications <br> to increase its [property] value by at least [threshold] compared to the pre- <br> optimized value while maintaining its core structure.</td>
</tr>
<tr>
<td style="text-align: center;">range</td>
<td style="text-align: left;">Here is a molecule represented by the SMILES string [SMILES]. Provide <br> me with an optimized version that has a [property] value between [lower <br> bound] and [upper bound]. The output molecule should be similar to the input <br> molecule.</td>
</tr>
</tbody>
</table>
<p>Table 2: Examples of prompts for optimization tasks with three different goals - loose, strict and range. "[SMILES]" represents the SMILES string for the molecule.
diversity among the source molecules. Therefore, models developed using this dataset are expected to demonstrate robust prediction coverage for a broad spectrum of structurally diverse compounds.</p>
<p>Furthermore, we also plot distribution graphs for molecular structural and ADMET-related properties, as shown in Figure 3 and Figure 4, respectively. For molecular structural properties, we focus on Bertz complexity, molecular weight, atom count and ring count. Bertz Complexity is a key parameter for assessing the structural complexity of a molecule, providing insights into its potential reactivity and stability. Molecular weight, a measure of a molecule's size, influences various physical and chemical properties, including solubility, volatility, and reaction kinetics. Atom count, indicative of the molecule's size and complexity, impacts its stability and potential intermolecular interactions. Ring count, a measure of cyclic structures within a molecule, informs about its structural rigidity, conformational flexibility, and possible biological activity. These graphs provide a more intuitive visualization of the diversity in the physical structure and biochemical properties of molecules in MolOpt-Instructions.</p>
<h1>3.2 InStruction Tuning</h1>
<p>For LLMs to follow natural language instructions and complete real-world tasks, instruction tuning has been widely used for alignment (Ouyang et al., 2022). In this process, the LLM is fine-tuned on a collection of tasks, which are defined through a set of instructions.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Distribution of structural properties of molecules within MolOpt-Instructions, illustrating the structural diversity of the molecules.
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Distribution of ADMET-related properties of molecules within MolOpt-Instructions. Currently, MolOpt-Instructions covers six properties, namely Solubility, BBBP (Blood-Brain Barrier Penetration), hERG (Human Ether-a-go-go-Related Gene) inhibition, QED (Quantitative Estimate of Drug-likeness) and the number of hydrogen bond donor and acceptor. The distribution graph demonstrates the diversity of biochemical properties of molecules in our dataset.</p>
<p>Our work follow the similar approach performing instruction tuning on Llama2-7B-Chat using our MolOpt-Instructions dataset. Formally, we define the text input as a sequence of tokens, $U=$ $\left{u_{1}, u_{2}, \ldots, u_{N}\right}$, where each $u_{i}$ is a text token and $N$ is the total sequence length. At the stage of instruction fine-tuning, the sequence $U$ is further split into two parts, instruction $I$ and response $R$. The training objective is to minimize the negative log-likelihood over the response $R$ with respect to trainable parameters $\theta$ as follows: $L(R ; \theta)=-\sum_{u_{i} \in R} \log \Phi\left(u_{i} \mid u_{&lt;i}, I\right)$.
Multi-task learning In instruction tuning, the occurrence of catastrophic forgetting is a common phenomenon in pre-trained language models (De Lange et al., 2021; Dong et al., 2023). Ensuring that the model maintains high interactivity while optimizing molecules is one of our important objectives. To achieve this, we employ multi-task learning as our instruction tuning strategy. Specifically, the composition of our text input consists of two parts: (1) General knowledge: such as everyday conversational question-answering data; (2) Domain-specific knowledge: for our model, it pertains to molecule optimization. We mix these two types of data at a certain ratio. To achieve this ratio, we replicate the data from the less abundant category. Figure 5 illustrates our instruction tuning strategy.</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: The illustration of multi-task learning strategy. We apply instruction tuning by directly combining different data sources (general knowledge and molecule optimization), effectively mitigating catastrophic forgetting during the fine-tuning stage.</p>
<h1>4 EXPERIMENTS</h1>
<p>We provide a comprehensive view of DrugAssist's performance on traditional molecule optimization tasks, as well as its capabilities in dialogue and interaction.</p>
<h3>4.1 EXPERIMENTAL SETUP</h3>
<p>Models DrugAssist is a model fine-tuned from the Meta's Llama-2-7B-Chat model on over one million instruction-response demonstrations. We conduct a systematic comparison with the following sequence-based models:</p>
<ul>
<li>He et al. (2021) utilized the SOTA machine translation models, the Seq2Seq with attention and the Transformer for molecule optimization tasks.</li>
<li>ChatDrug (Liu et al., 2018) is a framework to facilitate the systematic investigation of drug editing using LLMs. For the molecule optimization tasks, they obtained results from ChatGPT (GPT-3.5turbo) using carefully crafted prompts.</li>
<li>Llama2-7B-Chat (Touvron et al., 2023) is a fine-tuned generative text model with 7 billion parameters, developed and publicly released by Meta. It outperforms open-source chat models on most benchmarks, and is on par with some popular closed-source models like ChatGPT and PaLM (Narang \&amp; Chowdhery, 2022).</li>
<li>BioMedGPT-LM-7B (Luo et al., 2023) is the first large generative language model based on Llama2 in the biomedical domain.</li>
</ul>
<p>Training Details At instruction tuning stage, we train the model for 10 epochs with a batch size of 512. We use the AdamW optimizer, with $\beta=(0.9,0.999)$ and a learning rate of $1 \mathrm{e}-4$, without weight decay. Warm-up is executed over $3 \%$ of the total training steps, followed by a cosine schedule for learning rate decay. Linear layers within the LLM utilize a LoRA rank of 64 and a LoRA alpha of 128. The model is trained on 8 NVIDIA Tesla A100-SXM4-40GB GPUs.</p>
<p>Dataset for Instruction Tuning To ensure our model maintains high interactivity while optimizing moluecules, we employ multi-task learning strategy introduced in Section 3.2 to construct training data. We utilize instruction data from two sources:</p>
<ul>
<li>MolOpt-Instructions We have provided a detailed introduction to this dataset in Section 3.</li>
<li>Stanford Alpaca In order to preserve the model's natural language dialogue capabilities and counteract the forgetting effect during the supervised fine-tuning phase, we utilized the dataset employed for fine-tuning a 7B Llama model, which comprises 52 k instruction-following data provided by Stanford.</li>
</ul>
<p>Considering that the MolOpt-Instructions dataset contains significantly more data than the Stanford Alpaca dataset, we created the final dataset by replicating the Stanford Alpaca dataset five times and then mixing it with the Molopt-Instructions dataset. We divide the mixed data into training, validation, and test sets at a ratio of $0.9: 0.05: 0.05$, respectively.</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6: Multi-round optimization process proposed by Liu et al. (2023b). The model is initially provided with a source molecule and specific optimization criteria. Upon generating the optimized molecule, its property values are assessed. If it meets the requirements, the process terminates. If not, a molecule most similar to the source molecule and fulfilling the criteria is retrieved from the database to guide further optimization. The process continues until the requirements is met or the predefined maximum number of iterations is reached.</p>
<h1>4.2 Evaluation Methods</h1>
<p>Comparisons with Traditional Approaches We compared DrugAssist with two molecule optimization models proposed by He et al. (2021). One of them employs a Seq2Seq with attention architecture (which we refer to as Mol-Seq2Seq), and the other uses a Transformer architecture (which we refer to as Mol-Transformer). Specifically, we compared the performance of these models in optimizing two properties: BBBP and Solubility. We calculated the success rates, validity, and average similarity between molecules before and after optimization, with the detailed definition of "success" summarized as follows:</p>
<ul>
<li>Solubility: We consider the optimization to be successful if the Solubility of the generated molecule falls within the given range. Specifically, we have divided the Solubility values into 10 intervals, each with a size of 1 .</li>
<li>BBBP: We consider the optimization to be successful if the generated molecule's BBBP property type is correct. Specifically, we have categorized BBBP values into three groups: low, medium, and high, corresponding to the value ranges of $0-0.3,0.3-0.7$, and $0.7-1$, respectively.</li>
</ul>
<p>The prompt we used is "Here is a molecule represented by the SMILES string [SMILES]. Provide me with an optimized version that has a molecular solubility value between [lower bound] and [upper bound] (unit: logarithm of mol/L), and change the blood-brain barrier penetration (BBBP) from [source category] to [target category]". We use this prompt to obtain results from DrugAssist in a single-turn dialogue manner.</p>
<p>Comparisons with LLMs We compared DrugAssist with ChatDrug, Llama2-7B-Chat, and BioMedGPT-LM-7B. We randomly selected an additional 500 molecules from the ZINC dataset to serve as the testset for this experiment. Specifically, we compared the performance of these models on 16 tasks. Following the approach of Liu et al. (2023b), we employ multi-turn dialogues to enable LLMs to optimize molecules. We first propose optimization requirements, and if the model's output does not meet our requirements, we search the database for a molecule that meets the requirements and is most similar to the model's output, using it as a hint for the model to make modifications, until the requirements are met or the pre-set number of iterations is reached. Figure 6 illustrates the optimization process.</p>
<p>We computed the success rate and validity for each task. We have adopted two sets of criteria for defining "successful optimization" - loose and strict. For the loose criteria, if the optimized molecular property is higher or lower than the pre-optimization property as required, we consider the optimization to be successful. For the strict criteria, except for the "Solubility", if the optimized molecular property is higher or lower than the pre-optimization property by a specified threshold, we consider the optimization to be successful. For the "Solubility", if the optimized molecular property value falls within the required range, we consider the optimization to be successful. Our range requirements are set as follows: Given a test molecule with Solubility value x , in the task of increasing the Solubility value, the optimized range requirement is $[\mathrm{x}+0.5, \mathrm{x}+1.5]$; in the task of</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Property</th>
<th style="text-align: center;">Threshold</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">QED</td>
<td style="text-align: center;">0.1</td>
</tr>
<tr>
<td style="text-align: left;">hydrogen bond acceptor</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: left;">hydrogen bond donor</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: left;">BBBP</td>
<td style="text-align: center;">0.1</td>
</tr>
<tr>
<td style="text-align: left;">hERG inhibition</td>
<td style="text-align: center;">0.1</td>
</tr>
</tbody>
</table>
<p>Table 3: The threshold settings for different properties. For the strict criteria, except for the "Solubility", we consider the optimization to be successful only if the optimized molecular property is higher or lower than the pre-optimization property by the threshold shown in table.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Model</th>
<th style="text-align: center;">Solubility</th>
<th style="text-align: center;">BBBP</th>
<th style="text-align: center;">All</th>
<th style="text-align: center;">Valid rate</th>
<th style="text-align: center;">Similarity</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Mol-Seq2Seq</td>
<td style="text-align: center;">0.46</td>
<td style="text-align: center;">0.55</td>
<td style="text-align: center;">0.35</td>
<td style="text-align: center;">0.76</td>
<td style="text-align: center;">0.61</td>
</tr>
<tr>
<td style="text-align: left;">Mol-Transformer</td>
<td style="text-align: center;">0.70</td>
<td style="text-align: center;">0.78</td>
<td style="text-align: center;">0.59</td>
<td style="text-align: center;">0.96</td>
<td style="text-align: center;">$\mathbf{0 . 7 0}$</td>
</tr>
<tr>
<td style="text-align: left;">Ours</td>
<td style="text-align: center;">$\mathbf{0 . 7 4}$</td>
<td style="text-align: center;">$\mathbf{0 . 8 0}$</td>
<td style="text-align: center;">$\mathbf{0 . 6 2}$</td>
<td style="text-align: center;">$\mathbf{0 . 9 8}$</td>
<td style="text-align: center;">0.69</td>
</tr>
</tbody>
</table>
<p>Table 4: Comparisons with traditional approaches on optimizing molecules' Solubility and BBBP value. We choose success rate, valid rate and similarity as evaluation metrics. The Solubility and BBBP columns display the success rates of the model optimizing these two individual properties respectively, while the "All" column shows the success rate of the model simultaneously optimizing both properties. Our model has achieved the highest success rates in both single-property and multiproperty optimization while maintaining high validity and high similarity to the molecules to be optimized. Furthermore, we can also observe that the Transformer architecture performs much better than the Seq2Seq with attention architecture on this task.
decreasing the Solubility value, the optimized range requirement is [x-1.5, x-0.5]. The threshold settings for different properties in our experiments are shown in Table 3. Detailed prompt settings for each task can be found in Table 6 in Appendix. BBBP, Solubility, and hERG inhibition are predicted from iDrug, while the rest can be calculated deterministically using RDKit.</p>
<h1>4.3 MAIN RESULTS</h1>
<p>In this section, we conduct a comprehensive and systematic comparison with aforementioned models.</p>
<p>Comparisons with traditional approaches Here we compared our model with He et al. (2021). The results are shown in Table 4. Our model has achieved the highest success rates in both singleproperty and multi-property optimization while maintaining high validity and high similarity to the molecules to be optimized.</p>
<p>Comparisons with LLMs The results are shown in Table 5. Our model significantly outperforms other LLMs in terms of both success rate and valid rate across all tasks.</p>
<p>From the perspective of the valid ratio of generating valid molecules, BioMedGPT-LM performs poorly. The main reason is that it has difficulty understanding the optimization requirements, often generating content such as guiding users to websites for molecule optimization, rather than outputting the optimized molecule. Although GPT-3.5-turbo appears to have high valid ratio, it often generates molecules that are identical to the given molecule to be optimized, thus failing to serve the purpose of molecule optimization. Our model, on the other hand, demonstrates a significant advantage in generating valid molecules, with virtually no instances of misunderstanding requirements or generating identical molecules to the ones to be optimized.</p>
<p>From the perspective of accuracy, even when we use multi-turn dialogues to prompt the baseline LLMs for comparison, they still struggle to complete the optimization tasks, with low success rates even on relatively simple tasks that only require increasing a single property value.</p>
<p>Our model exhibits good molecule optimization capabilities and strong adaptability to different properties and optimization objectives. Even though our model has only been exposed to data with</p>
<p>individual properties during training, it achieves competitive results in multi-property optimization tasks. However, we also note that our model has a relatively lower success rate in tasks specifying the range of post-optimization property values ("esol+ strict" task). How to better achieve these more challenging optimization objectives is worth further exploration in the future.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Task</th>
<th style="text-align: center;">Model</th>
<th style="text-align: center;">Valid ratio (loose/strict)</th>
<th style="text-align: center;">Correct ratio (loose/strict)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">$q e d+$</td>
<td style="text-align: center;">Llama2-7B-Chat</td>
<td style="text-align: center;">$0.69 / 0.55$</td>
<td style="text-align: center;">$0.17 / 0.16$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">GPT-3.5-turbo</td>
<td style="text-align: center;">$0.97 / 0.96$</td>
<td style="text-align: center;">$0.15 / 0.15$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">BioMedGPT-LM</td>
<td style="text-align: center;">$0.34 / 0.32$</td>
<td style="text-align: center;">$0.15 / 0.09$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Ours</td>
<td style="text-align: center;">$0.99 / 0.97$</td>
<td style="text-align: center;">$0.76 / 0.63$</td>
</tr>
<tr>
<td style="text-align: center;">acceptor+</td>
<td style="text-align: center;">Llama2-7B-Chat</td>
<td style="text-align: center;">$0.45 / 0.43$</td>
<td style="text-align: center;">$0.08 / 0.08$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">GPT-3.5-turbo</td>
<td style="text-align: center;">$0.98 / 0.96$</td>
<td style="text-align: center;">$0.04 / 0.06$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">BioMedGPT-LM</td>
<td style="text-align: center;">$0.45 / 0.39$</td>
<td style="text-align: center;">$0.18 / 0.13$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Ours</td>
<td style="text-align: center;">$0.97 / 0.96$</td>
<td style="text-align: center;">$0.71 / 0.67$</td>
</tr>
<tr>
<td style="text-align: center;">donor+</td>
<td style="text-align: center;">Llama2-7B-Chat</td>
<td style="text-align: center;">$0.45 / 0.48$</td>
<td style="text-align: center;">$0.15 / 0.08$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">GPT-3.5-turbo</td>
<td style="text-align: center;">$0.98 / 0.95$</td>
<td style="text-align: center;">$0.10 / 0.04$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">BioMedGPT-LM</td>
<td style="text-align: center;">$0.46 / 0.46$</td>
<td style="text-align: center;">$0.17 / 0.09$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Ours</td>
<td style="text-align: center;">$0.98 / 0.95$</td>
<td style="text-align: center;">$0.72 / 0.76$</td>
</tr>
<tr>
<td style="text-align: center;">solubility+</td>
<td style="text-align: center;">Llama2-7B-Chat</td>
<td style="text-align: center;">$0.56 / 0.56$</td>
<td style="text-align: center;">$0.36 / 0.20$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">GPT-3.5-turbo</td>
<td style="text-align: center;">$0.94 / 0.95$</td>
<td style="text-align: center;">$0.16 / 0.05$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">BioMedGPT-LM</td>
<td style="text-align: center;">$0.27 / 0.35$</td>
<td style="text-align: center;">$0.18 / 0.09$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Ours</td>
<td style="text-align: center;">$0.98 / 0.98$</td>
<td style="text-align: center;">$0.80 / 0.41$</td>
</tr>
<tr>
<td style="text-align: center;">$b b b p+$</td>
<td style="text-align: center;">Llama2-7B-Chat</td>
<td style="text-align: center;">$0.56 / 0.57$</td>
<td style="text-align: center;">$0.19 / 0.14$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">GPT-3.5-turbo</td>
<td style="text-align: center;">$0.97 / 0.95$</td>
<td style="text-align: center;">$0.10 / 0.10$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">BioMedGPT-LM</td>
<td style="text-align: center;">$0.26 / 0.22$</td>
<td style="text-align: center;">$0.16 / 0.07$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Ours</td>
<td style="text-align: center;">$0.99 / 0.98$</td>
<td style="text-align: center;">$0.82 / 0.61$</td>
</tr>
<tr>
<td style="text-align: center;">herg-</td>
<td style="text-align: center;">Llama2-7B-Chat</td>
<td style="text-align: center;">$0.59 / 0.55$</td>
<td style="text-align: center;">$0.39 / 0.31$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">GPT-3.5-turbo</td>
<td style="text-align: center;">$0.98 / 0.97$</td>
<td style="text-align: center;">$0.13 / 0.15$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">BioMedGPT-LM</td>
<td style="text-align: center;">$0.20 / 0.18$</td>
<td style="text-align: center;">$0.13 / 0.12$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Ours</td>
<td style="text-align: center;">$0.99 / 0.98$</td>
<td style="text-align: center;">$0.71 / 0.67$</td>
</tr>
<tr>
<td style="text-align: center;">sol $+\&amp; a c c+$</td>
<td style="text-align: center;">Llama2-7B-Chat</td>
<td style="text-align: center;">$0.55 / 0.52$</td>
<td style="text-align: center;">$0.15 / 0.04$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">GPT-3.5-turbo</td>
<td style="text-align: center;">$0.92 / 0.91$</td>
<td style="text-align: center;">$0.09 / 0.02$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">BioMedGPT-LM</td>
<td style="text-align: center;">$0.29 / 0.32$</td>
<td style="text-align: center;">$0.10 / 0.07$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Ours</td>
<td style="text-align: center;">$0.95 / 0.95$</td>
<td style="text-align: center;">$0.50 / 0.27$</td>
</tr>
<tr>
<td style="text-align: center;">qed $+\&amp; b b b p+$</td>
<td style="text-align: center;">Llama2-7B-Chat</td>
<td style="text-align: center;">$0.52 / 0.56$</td>
<td style="text-align: center;">$0.14 / 0.09$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">GPT-3.5-turbo</td>
<td style="text-align: center;">$0.96 / 0.95$</td>
<td style="text-align: center;">$0.09 / 0.06$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">BioMedGPT-LM</td>
<td style="text-align: center;">$0.35 / 0.36$</td>
<td style="text-align: center;">$0.16 / 0.11$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Ours</td>
<td style="text-align: center;">$0.99 / 0.98$</td>
<td style="text-align: center;">$0.65 / 0.41$</td>
</tr>
</tbody>
</table>
<p>Table 5: Comparisons with LLMs. We evaluated the performance of LLMs on 16 tasks, covering all three optimization objectives introduced in Section 3.1 - loose, strict, and range. We calculated the valid ratio (number of valid SMILES generated/total number in the test set) and success rate (number of molecules meeting optimization objectives/total number in the test set) of the generated molecules. In the task naming, " + " represents the goal of increasing the property value, while "-" represents property the attribute value. The " $\&amp;$ " symbol represents the simultaneous optimization of two given properties. "sol" stands for "Solubility", and "acc" stands for "the number of hydrogen bond acceptor". "loose" and "strict" are the two criteria for defining successful optimization, as detailed in Section 4.1.</p>
<h1>4.4 CASE Study</h1>
<p>In this section, we showcase the exceptional capabilities of our model in molecule optimization tasks through several specific examples, beyond its high success rate.</p>
<p>Transferability Figure 7 demonstrates the good transferability of our model under the zero-shot setting. We randomly selected two properties, BBBP and QED, and asked DrugAssist to increase their values by at least 0.1 simultaneously. Our model achieved this and the resulting molecule is structurally similar to the original one. Although the model has only been exposed to data with individual properties during training, users can still freely combine these properties when using the model to optimize them simultaneously. Traditional models, however, often require retraining on new datasets with multiple properties in order to achieve this.
<img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 7: Good transferability of DrugAssist under the zero-shot setting. Users can freely combine individual properties in training data to request DrugAssist to optimize them simultaneously.</p>
<p>Figure 8 demonstrates the good transferability of DrugAssist under the few-shot setting. We asked DrugAssist to increase the logP value of a given molecule by at least 0.1 , even though this property is not included in the training data. By providing a few examples of similar molecules with successfully increased $\log \mathrm{P}$ values by at least 0.1 in the prompt, our model was able to achieve this. Our model can optimize properties not encountered during training through few-shot, which is difficult to achieve for traditional models (e.g., JT-VAE).
<img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 8: Good transferability of DrugAssist under the few-shot setting. By providing examples of successful optimizations for molecules similar to the one to be optimized, DrugAssist can optimize properties not encountered during training.</p>
<p>Iterative optimization Figure 9 illustrates the iterative optimization capability of our model. We asked DrugAssist to increase the QED value of a given molecule by at least 0.1 , but it failed. Then, we found a molecule from the database that was similar to the failed molecule it provided and met the optimization requirements as a hint for it to generate a new one. This time, it chose to optimize different functional groups than the first time and succeeded, and the final molecule generated is structurally similar to the original given molecule. We can conclude that when the model provides a molecule that does not fully meet the requirements, it can correct the error and generate a new, compliant molecule based on a human-provided example that meets the criteria. This ability highlights</p>
<p>the potential for DrugAssist to assist researchers in continually adjusting and optimizing molecules in real-world scenarios.
<img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<p>Figure 9: Iterative optimization capability of DrugAssist. when the model provides a molecule that does not fully meet the requirements, it can correct the error and generate a new, compliant molecule based on a human-provided example.</p>
<h1>5 CONCLUSION AND Future WORK</h1>
<p>In this paper, we present DrugAssist, an interactive molecule optimization model. Unlike previous methods, DrugAssist can interact with humans in real-time using natural language. It can provide optimized results based on the instructions given by users and continue to adjust according to their feedback. It demonstrates excellent performance in both single-property and multi-property optimization, including more challenging tasks, such as optimizing within specified property value ranges. Additionally, it shows great potential in transferability and iterative optimization capabilities during the interaction process. Furthermore, we publicly release MolOpt-Instructions, an instruction-based dataset to facilitate future work on fine-tuning LLMs in the molecule optimization domain.</p>
<p>In the future, we aim to improve the model's ability to handle multimodal data and tasks (Lyu et al., 2023; Li et al., 2023a) to reduce hallucination problems (Zhang et al., 2023; Liu et al., 2023a; Li et al., 2023b; Cai et al., 2023). Additionally, we are endeavoring to further enhance DrugAssist's interactive capabilities to better understand users' needs and feedback.</p>
<h2>REFERENCES</h2>
<p>Esben Jannik Bjerrum and Richard Threlfall. Molecular generation with recurrent neural networks (rnns). arXiv preprint arXiv:1705.04612, 2017.</p>
<p>Xibao Cai, Houtim Lai, Xing Wang, Longyue Wang, Wei Liu, Yijun Wang, Zixu Wang, Dongsheng Cao, and Xiangxiang Zeng. Comprehensive evaluation of molecule property prediction with chatgpt. Methods, 2023.</p>
<p>Hanjun Dai, Yingtao Tian, Bo Dai, Steven Skiena, and Le Song. Syntax-directed variational autoencoder for molecule generation. In Proceedings of the international conference on learning representations, 2018.</p>
<p>Andrew Dalke, Jerome Hert, and Christian Kramer. mmpdb: An open-source matched molecular pair platform for large multiproperty data sets. Journal of chemical information and modeling, 58 (5):902-910, 2018.</p>
<p>Matthias De Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Aleš Leonardis, Gregory Slabaugh, and Tinne Tuytelaars. A continual learning survey: Defying forgetting in classification tasks. IEEE transactions on pattern analysis and machine intelligence, 44(7):3366-3385, 2021.</p>
<p>Guanting Dong, Hongyi Yuan, Keming Lu, Chengpeng Li, Mingfeng Xue, Dayiheng Liu, Wei Wang, Zheng Yuan, Chang Zhou, and Jingren Zhou. How abilities in large language models are affected by supervised fine-tuning data composition. arXiv preprint arXiv:2310.05492, 2023.</p>
<p>Yin Fang, Xiaozhuan Liang, Ningyu Zhang, Kangwei Liu, Rui Huang, Zhuo Chen, Xiaohui Fan, and Huajun Chen. Mol-instructions: A large-scale biomolecular instruction dataset for large language models. arXiv preprint arXiv:2306.08018, 2023.</p>
<p>Anvita Gupta, Alex T Müller, Berend JH Huisman, Jens A Fuchs, Petra Schneider, and Gisbert Schneider. Generative recurrent networks for de novo drug design. Molecular informatics, 37 (1-2):1700111, 2018.</p>
<p>Tianyu Han, Lisa C Adams, Jens-Michalis Papaioannou, Paul Grundmann, Tom Oberhauser, Alexander Löser, Daniel Truhn, and Keno K Bressem. Medalpaca-an open-source collection of medical conversational ai models and training data. arXiv preprint arXiv:2304.08247, 2023.</p>
<p>Jiazhen He, Huifang You, Emil Sandström, Eva Nittinger, Esben Jannik Bjerrum, Christian Tyrchan, Werngard Czechtizky, and Ola Engkvist. Molecular optimization by capturing chemist's intuition using deep neural networks. Journal of cheminformatics, 13(1):1-17, 2021.</p>
<p>Jiazhen He, Eva Nittinger, Christian Tyrchan, Werngard Czechtizky, Atanas Patronov, Esben Jannik Bjerrum, and Ola Engkvist. Transformer-based molecular optimization beyond matched molecular pairs. Journal of cheminformatics, 14(1):18, 2022.
iDrug, 2020. URL https://drug.ai.tencent.com.
John J Irwin and Brian K Shoichet. Zinc- a free database of commercially available compounds for virtual screening. Journal of chemical information and modeling, 45(1):177-182, 2005.</p>
<p>Wengong Jin, Regina Barzilay, and Tommi Jaakkola. Junction tree variational autoencoder for molecular graph generation. In International conference on machine learning, pp. 2323-2332. PMLR, 2018a.</p>
<p>Wengong Jin, Kevin Yang, Regina Barzilay, and Tommi Jaakkola. Learning multimodal graph-tograph translation for molecular optimization. arXiv preprint arXiv:1812.01070, 2018b.</p>
<p>Wengong Jin, Regina Barzilay, and Tommi Jaakkola. Hierarchical generation of molecular graphs using structural motifs. In International conference on machine learning, pp. 4839-4848. PMLR, 2020 .</p>
<p>Artur Kadurin, Sergey Nikolenko, Kuzma Khrabrov, Alex Aliper, and Alex Zhavoronkov. drugan: an advanced generative adversarial autoencoder model for de novo generation of new molecules with desired molecular properties in silico. Molecular pharmaceutics, 14(9):3098-3104, 2017.</p>
<p>Yingshu Li, Yunyi Liu, Zhanyu Wang, Xinyu Liang, Lingqiao Liu, Lei Wang, Leyang Cui, Zhaopeng Tu, Longyue Wang, and Luping Zhou. A comprehensive study of gpt-4v's multimodal capabilities in medical imaging. medRxiv, pp. 2023-11, 2023a.</p>
<p>Yunxin Li, Longyue Wang, Baotian Hu, Xinyu Chen, Wanqi Zhong, Chenyang Lyu, and Min Zhang. A comprehensive evaluation of gpt-4v on knowledge-intensive visual question answering. arXiv preprint arXiv:2311.07536, 2023b.</p>
<p>Bingshuai Liu, Chenyang Lyu, Zijun Min, Zhanyu Wang, Jinsong Su, and Longyue Wang. Retrievalaugmented multi-modal chain-of-thoughts reasoning for large language models. arXiv preprint arXiv:2312.01714, 2023a.</p>
<p>Qi Liu, Miltiadis Allamanis, Marc Brockschmidt, and Alexander Gaunt. Constrained graph variational autoencoders for molecule design. Advances in neural information processing systems, 31, 2018.</p>
<p>Shengchao Liu, Jiongxiao Wang, Yijin Yang, Chengpeng Wang, Ling Liu, Hongyu Guo, and Chaowei Xiao. Chatgpt-powered conversational drug editing using retrieval and domain feedback. arXiv preprint arXiv:2305.18090, 2023b.</p>
<p>Yizhen Luo, Jiahuan Zhang, Siqi Fan, Kai Yang, Yushuai Wu, Mu Qiao, and Zaiqing Nie. Biomedgpt: Open multimodal generative pre-trained transformer for biomedicine. arXiv preprint arXiv:2308.09442, 2023.</p>
<p>Chenyang Lyu, Minghao Wu, Longyue Wang, Xinting Huang, Bingshuai Liu, Zefeng Du, Shuming Shi, and Zhaopeng Tu. Macaw-llm: Multi-modal language modeling with image, audio, video, and text integration. arXiv preprint arXiv:2306.09093, 2023.</p>
<p>Sharan Narang and Aakanksha Chowdhery. Pathways language model (palm): Scaling to 540 billion parameters for breakthrough performance. Google AI Blog, 2022.</p>
<p>Marcus Olivecrona, Thomas Blaschke, Ola Engkvist, and Hongming Chen. Molecular de-novo design through deep reinforcement learning. Journal of cheminformatics, 9(1):1-14, 2017.</p>
<p>Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems, 35: $27730-27744,2022$.</p>
<p>Evgeny Putin, Arip Asadulaev, Yan Ivanenkov, Vladimir Aladinskiy, Benjamin Sanchez-Lengeling, Alán Aspuru-Guzik, and Alex Zhavoronkov. Reinforced adversarial neural computer for de novo molecular design. Journal of chemical information and modeling, 58(6):1194-1204, 2018.</p>
<p>Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.</p>
<p>Marwin HS Segler, Thierry Kogej, Christian Tyrchan, and Mark P Waller. Generating focused molecule libraries for drug discovery with recurrent neural networks. ACS central science, 4(1): $120-131,2018$.</p>
<p>Martin Simonovsky and Nikos Komodakis. Graphvae: Towards generation of small graphs using variational autoencoders. In Artificial Neural Networks and Machine Learning-ICANN 2018: 27th International Conference on Artificial Neural Networks, Rhodes, Greece, October 4-7, 2018, Proceedings, Part I 27, pp. 412-422. Springer, 2018.</p>
<p>Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023.</p>
<p>Chaoyi Wu, Weixiong Lin, Xiaoman Zhang, Ya Zhang, Yanfeng Wang, and Weidi Xie. Pmc-llama: Towards building open-source language models for medicine. arXiv preprint arXiv:2305.10415, 2023.</p>
<p>Li Yunxiang, Li Zihan, Zhang Kai, Dan Ruilong, and Zhang You. Chatdoctor: A medical chat model fine-tuned on llama model using medical domain knowledge. arXiv preprint arXiv:2303.14070, 2023.</p>
<p>Zheni Zeng, Bangchen Yin, Shipeng Wang, Jiarui Liu, Cheng Yang, Haishen Yao, Xingzhi Sun, Maosong Sun, Guotong Xie, and Zhiyuan Liu. Interactive molecular discovery with natural language. arXiv preprint arXiv:2306.11976, 2023.</p>
<p>Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhang, Yulong Chen, et al. Siren's song in the ai ocean: A survey on hallucination in large language models. arXiv preprint arXiv:2309.01219, 2023.</p>
<h1>A Prompt Settings for the comparisons with LLMs</h1>
<table>
<thead>
<tr>
<th style="text-align: center;">Task</th>
<th style="text-align: center;">Prompt</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">qed+ loose</td>
<td style="text-align: center;">Help me make molecule [SMILES] more like a drug. The output molecule should be similar to the input molecule.</td>
</tr>
<tr>
<td style="text-align: center;">qed+ strict</td>
<td style="text-align: center;">How can we modify the molecule [SMILES] to increase its QED value by at least 0.1 compared to the pre-optimized value to make it more drug-like while keeping it similar to the input molecule?</td>
</tr>
<tr>
<td style="text-align: center;">acceptor+ loose</td>
<td style="text-align: center;">Can you make molecule [SMILES] with more hydrogen bond acceptors? The output molecule should be similar to the input molecule.</td>
</tr>
<tr>
<td style="text-align: center;">acceptor+ strict</td>
<td style="text-align: center;">Help me increase the number of hydrogen bond acceptors in the molecule [SMILES] by at least 2 compared to the pre-optimized value. The output molecule should be similar to the input molecule.</td>
</tr>
<tr>
<td style="text-align: center;">donor+ loose</td>
<td style="text-align: center;">Can you make molecule [SMILES] with more hydrogen bond donors? The output molecule should be similar to the input molecule.</td>
</tr>
<tr>
<td style="text-align: center;">donor+ strict</td>
<td style="text-align: center;">Help me increase the number of hydrogen bond donors in the molecule [SMILES] by at least 2 compared to the pre-optimized value. The output molecule should be similar to the input molecule.</td>
</tr>
<tr>
<td style="text-align: center;">solubility+ loose</td>
<td style="text-align: center;">How can we modify the molecule [SMILES] to increase its water solubility value while keeping it similar to the input molecule?</td>
</tr>
<tr>
<td style="text-align: center;">solubility+ strict</td>
<td style="text-align: center;">Can you give me an optimized version of the molecule [SMILES] with a water solubility value ranging from lower bound to higher bound (logarithm of $\mathrm{mol} / \mathrm{L}$ ) while maintaining similarity to the original molecule?</td>
</tr>
<tr>
<td style="text-align: center;">bbbp+ loose</td>
<td style="text-align: center;">How can we modify the molecule [SMILES] to increase its blood-brain barrier penetration (BBBP) value while keeping it similar to the input molecule?</td>
</tr>
<tr>
<td style="text-align: center;">bbbp+ strict</td>
<td style="text-align: center;">How can we modify the molecule [SMILES] to increase its blood-brain barrier penetration (BBBP) value by at least 0.1 compared to the pre-optimized value while keeping it similar to the input molecule?</td>
</tr>
<tr>
<td style="text-align: center;">herg- loose</td>
<td style="text-align: center;">How can we modify the molecule [SMILES] to decrease its hERG inhibition value while keeping it similar to the input molecule?</td>
</tr>
<tr>
<td style="text-align: center;">herg- strict</td>
<td style="text-align: center;">How can we modify the molecule [SMILES] to decrease its hERG inhibition value by at least 0.1 compared to the pre-optimized value while keeping it similar to the input molecule?</td>
</tr>
<tr>
<td style="text-align: center;">sol $+\&amp;$ acc+ loose</td>
<td style="text-align: center;">How can we modify the molecule [SMILES] to increase its water solubility value and to have more hydrogen bond acceptors? The output molecule should be similar to the input molecule.</td>
</tr>
<tr>
<td style="text-align: center;">sol $+\&amp;$ acc+ strict</td>
<td style="text-align: center;">Can you give me an optimized version of the molecule [SMILES] with a water solubility value ranging from lower bound to higher bound (logarithm of $\mathrm{mol} / \mathrm{L}$ ), and with at least 2 more hydrogen bond acceptors while maintaining similarity to the original molecule?</td>
</tr>
<tr>
<td style="text-align: center;">qed $+\&amp;$ bbbp+ loose</td>
<td style="text-align: center;">How can we modify the molecule [SMILES] to increase its blood-brain barrier penetration (BBBP) value and make it more like a drug? The output molecule should be similar to the input molecule.</td>
</tr>
<tr>
<td style="text-align: center;">qed $+\&amp;$ bbbp+ strict</td>
<td style="text-align: center;">How can we modify the molecule [SMILES] to increase its blood-brain barrier penetration (BBBP) value by at least 0.1 and increase its QED value by at least 0.1 compared to the pre-optimized value to make it more drug-like? The output molecule should be similar to the input molecule.</td>
</tr>
</tbody>
</table>
<p>Table 6: Prompts for different tasks. "[SMILES]" represents the SMILES string for the molecule.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<ul>
<li>Corresponding Author, ${ }^{\dagger}$ Equal Contribution.</li>
</ul>
<p><a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>