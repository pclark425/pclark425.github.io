<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7713 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7713</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7713</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-144.html">extraction-schema-144</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods that use large language models to synthesize, distill, or generate scientific theories, hypotheses, or structured knowledge from collections of scholarly papers.</div>
                <p><strong>Paper ID:</strong> paper-278024019</p>
                <p><strong>Paper Title:</strong> Knowledge Graphs and Their Reciprocal Relationship with Large Language Models</p>
                <p><strong>Paper Abstract:</strong> : The reciprocal relationship between Large Language Models (LLMs) and Knowledge Graphs (KGs) highlights their synergistic potential in enhancing artificial intelligence (AI) applications. LLMs, with their natural language understanding and generative capabilities, support the automation of KG construction through entity recognition, relation extraction, and schema generation. Conversely, KGs serve as structured and interpretable data sources that improve the transparency, factual consistency and reliability of LLM-based applications, mitigating challenges such as hallucinations and lack of explainability. This study conducts a systematic literature review of 77 studies to examine AI methodologies supporting LLM–KG integration, including symbolic AI, machine learning, and hybrid approaches. The research explores diverse applications spanning healthcare, finance, justice, and industrial automation, revealing the transformative potential of this synergy. Through in-depth analysis, this study identifies key limitations in current approaches, including challenges in scalability with maintaining dynamic and real-time Knowledge Graphs, difficulty in adapting general-purpose LLMs to specialized domains, limited explainability in tracing model outputs to interpretable reasoning, and ethical concerns surrounding bias, fairness, and transparency. In response, the study highlights potential strategies to optimize LLM–KG synergy. The findings from this study provide actionable insights for researchers and practitioners aiming for robust, transparent, and adaptive AI systems to enhance knowledge-driven AI applications through LLM–KG integration, further advancing generative AI and explainable AI (XAI) applications.</p>
                <p><strong>Cost:</strong> 0.017</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7713.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7713.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods that use large language models to synthesize, distill, or generate scientific theories, hypotheses, or structured knowledge from collections of scholarly papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RAG</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Retrieval-Augmented Generation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A class of methods that augment LLMs at inference with retrieved external knowledge (documents or KG subgraphs) to ground generation, reduce hallucinations, and enable multi-hop reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>Retrieval-Augmented Generation</td>
                        </tr>
                        <tr>
                            <td><strong>authors</strong></td>
                            <td>multiple (reviewed literature)</td>
                        </tr>
                        <tr>
                            <td><strong>year</strong></td>
                            <td>2025</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Retrieval-Augmented Generation (RAG)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>At inference, retrieve relevant documents or KG subgraphs and provide them as context to an LLM so the model conditions generation on grounded, verifiable facts rather than only parametric knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>text documents and/or KG subgraphs (retrieved passages, subgraphs)</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>textual answers grounded by retrieved facts; optionally updated KG subgraphs or structured answers</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_technique</strong></td>
                            <td>retrieval-augmented prompting (RAG); contextual prompting with retrieved evidence</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>datasets_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>varied across cited works (factuality/accuracy, human evaluation, downstream QA performance); review cites a 37% reduction in factual errors for enterprise chatbots when using KG-RAG</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Reported in the reviewed literature to substantially reduce hallucinations and improve factuality; the survey cites a 37% reduction in factual errors in an enterprise chatbot evaluation when KG subgraphs were dynamically retrieved.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Does not by itself ensure traceability to KG provenance or full explainability; computational cost for real-time retrieval and KG subgraph selection; gaps remain in integrating RAG with formal XAI audits.</td>
                        </tr>
                        <tr>
                            <td><strong>counterpoint</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Knowledge Graphs and Their Reciprocal Relationship with Large Language Models', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7713.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7713.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods that use large language models to synthesize, distill, or generate scientific theories, hypotheses, or structured knowledge from collections of scholarly papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Auto-KG Agent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Auto-KG Agent</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An LLM-driven framework that automates the extraction of semantic triples from unstructured text to populate and update Knowledge Graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Auto-KG Agent</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>Auto-KG Agent</td>
                        </tr>
                        <tr>
                            <td><strong>authors</strong></td>
                            <td>cited as [11] in review (authors not listed in review text)</td>
                        </tr>
                        <tr>
                            <td><strong>year</strong></td>
                            <td>2024</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Auto-KG Agent</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Uses LLMs as autonomous agents to perform semantic triple extraction (entity and relation extraction) from unstructured corpora and populate KGs with minimal manual curation.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>unstructured text (papers, reports, web pages)</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>knowledge graph triples / populated KG</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_technique</strong></td>
                            <td>LLM agent prompting and structured extraction prompts; likely few-shot or instruction prompts</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>datasets_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>not specified in review (typical metrics: precision/recall of triples, human validation)</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Described as automating semantic triple extraction and reducing manual curation effort; review does not report numeric results.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Potential for extraction errors / hallucinated triples, need for entity normalization and ontology alignment, scalability and validation overhead.</td>
                        </tr>
                        <tr>
                            <td><strong>counterpoint</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Knowledge Graphs and Their Reciprocal Relationship with Large Language Models', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7713.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7713.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods that use large language models to synthesize, distill, or generate scientific theories, hypotheses, or structured knowledge from collections of scholarly papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>VieMedKG</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>VieMedKG</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A domain-specific Knowledge Graph and benchmark for traditional Vietnamese medicine constructed using LLM-assisted extraction from textual sources.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>VieMedKG: Knowledge Graph and Benchmark for Traditional Vietnamese Medicine</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>VieMedKG: Knowledge Graph and Benchmark for Traditional Vietnamese Medicine</td>
                        </tr>
                        <tr>
                            <td><strong>authors</strong></td>
                            <td>T Trinh, A Dao, H T H Nhung, H T Son</td>
                        </tr>
                        <tr>
                            <td><strong>year</strong></td>
                            <td>2024</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>VieMedKG construction (LLM-assisted KG building)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Applies LLMs to extract medical entities and relations from domain texts to construct a specialized KG and associated benchmark for evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>domain-specific textual corpora (traditional medicine texts, articles)</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>domain Knowledge Graph and benchmark</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_technique</strong></td>
                            <td>semantic parsing / prompt-based entity-relation extraction (zero/few-shot prompting implied)</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>datasets_used</strong></td>
                            <td>traditional Vietnamese medicine textual sources (as dataset for KG construction)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>benchmarking of KG quality and downstream tasks (not numerically specified in review)</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Presented as a domain KG and benchmark; review notes it as an example of LLMs constructing domain-specific KGs but does not provide metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Domain adaptation challenges, need for expert validation in sensitive medical domain, potential hallucinations in extraction.</td>
                        </tr>
                        <tr>
                            <td><strong>counterpoint</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Knowledge Graphs and Their Reciprocal Relationship with Large Language Models', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7713.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e7713.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods that use large language models to synthesize, distill, or generate scientific theories, hypotheses, or structured knowledge from collections of scholarly papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>KARGEN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>KARGEN (Knowledge-enhanced Automated Radiology Report Generation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A system that leverages domain-specific embeddings from radiology datasets and LLMs to generate radiology reports and assist medical KG creation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Knowledge-enhanced Automated Radiology Report Generation Using Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>Knowledge-enhanced Automated Radiology Report Generation Using Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>authors</strong></td>
                            <td>Y Li, Z Wang, Y Liu, L Wang, L Liu, L Zhou, Kargen (et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>year</strong></td>
                            <td>2024</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>KARGEN</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Combines domain embeddings from radiology data with LLM generation to produce medically-grounded radiology reports and to populate/align KGs for clinical use.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>radiology datasets (text reports), potentially images (radiology images) though review emphasizes text</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>automated radiology reports and KG triples/structured clinical knowledge</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_technique</strong></td>
                            <td>knowledge-injection into prompts; embedding-enhanced conditioning; likely RAG-like grounding</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>datasets_used</strong></td>
                            <td>radiology datasets (unspecified in review)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>not detailed in review (typical: clinical correctness, factuality, human expert evaluation)</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Reported as improving report generation fidelity via knowledge enhancement; specific quantitative outcomes not provided in review.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Risk of clinical hallucinations, need for strict validation and explainability (attention maps used for traceability), domain adaptation constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>counterpoint</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Knowledge Graphs and Their Reciprocal Relationship with Large Language Models', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7713.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e7713.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods that use large language models to synthesize, distill, or generate scientific theories, hypotheses, or structured knowledge from collections of scholarly papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SG-RAG</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SG-RAG (Subgraph Retrieval-Augmented Generation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-hop QA model integrating Knowledge Graph subgraph retrieval with LLMs to answer complex queries that require chaining multiple facts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>SG-RAG: Multi-Hop Question Answering with Large Language Models Through Knowledge Graphs</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>SG-RAG: Multi-Hop Question Answering with Large Language Models Through Knowledge Graphs</td>
                        </tr>
                        <tr>
                            <td><strong>authors</strong></td>
                            <td>A O M Saleh, G Tur, Y Saygin</td>
                        </tr>
                        <tr>
                            <td><strong>year</strong></td>
                            <td>2024</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>SG-RAG</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Retrieves relevant KG subgraphs as context for an LLM to perform multi-hop reasoning across connected facts, improving performance on structured querying tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>questions plus KG (structured graph) data</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>textual QA answers grounded in multi-hop KG evidence</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_technique</strong></td>
                            <td>retrieval of KG subgraphs + contextual prompting to the LLM</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>datasets_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>task accuracy on multi-hop QA; review states it outperforms traditional SQL-based approaches for structured queries</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Reported to outperform SQL-based approaches in structured data querying for multi-hop QA in the cited work.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Complexity of subgraph selection, traceability to specific KG facts, scalability to large KGs.</td>
                        </tr>
                        <tr>
                            <td><strong>counterpoint</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Knowledge Graphs and Their Reciprocal Relationship with Large Language Models', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7713.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e7713.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods that use large language models to synthesize, distill, or generate scientific theories, hypotheses, or structured knowledge from collections of scholarly papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>zrLLM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>zrLLM (Zero-Shot Relational Learning with LLMs)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An approach applying zero-shot LLM capabilities to temporal knowledge graphs for predicting time-sensitive relations without task-specific supervision.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>zrLLM: Zero-Shot Relational Learning on Temporal Knowledge Graphs with Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>zrLLM: Zero-Shot Relational Learning on Temporal Knowledge Graphs with Large Language Models</td>
                        </tr>
                        <tr>
                            <td><strong>authors</strong></td>
                            <td>Tresp, V. (cited in review)</td>
                        </tr>
                        <tr>
                            <td><strong>year</strong></td>
                            <td>2024</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>zrLLM</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Uses LLMs in a zero-shot manner to infer temporal relations and predict time-sensitive facts for Temporal Knowledge Graph completion.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>temporal KG facts and textual descriptions</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>predicted temporal triples / KG updates</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_technique</strong></td>
                            <td>zero-shot prompting</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>datasets_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>not specified in review (likely link prediction metrics for TKGs)</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Described as applying zero-shot relational learning to temporal KGs; specific numeric results not provided in review.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Zero-shot predictions may lack reliability for fine-grained temporal reasoning; needs validation and alignment with ontologies.</td>
                        </tr>
                        <tr>
                            <td><strong>counterpoint</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Knowledge Graphs and Their Reciprocal Relationship with Large Language Models', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7713.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e7713.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods that use large language models to synthesize, distill, or generate scientific theories, hypotheses, or structured knowledge from collections of scholarly papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RD-P</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Retrieve-and-Discriminate Prompter (RD-P)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A retrieval-augmented prompting framework that integrates knowledge graphs to improve trustworthy, knowledge-intensive question answering with LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>RD-P: A Trustworthy Retrieval-Augmented Prompter with Knowledge Graphs for LLMs</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>RD-P: A Trustworthy Retrieval-Augmented Prompter with Knowledge Graphs for LLMs</td>
                        </tr>
                        <tr>
                            <td><strong>authors</strong></td>
                            <td>Y Huang, G Zeng</td>
                        </tr>
                        <tr>
                            <td><strong>year</strong></td>
                            <td>2024</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>RD-P</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Retrieves KG-backed evidence and discriminates/filters retrieved items before constructing prompts for the LLM to ensure trustworthy, knowledge-grounded responses.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>queries and KG-backed evidence / retrieved passages</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>knowledge-grounded answers; reduced hallucinations</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_technique</strong></td>
                            <td>retrieval + discrimination + prompt construction (RAG-family)</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>datasets_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>not specified in review (expected: factuality, faithfulness, QA accuracy)</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Presented as improving reliability in knowledge-intensive QA; no numeric metrics given in review summary.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Doesn't fully solve traceability/XAI; relies on quality of KG retrieval and discrimination heuristics.</td>
                        </tr>
                        <tr>
                            <td><strong>counterpoint</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Knowledge Graphs and Their Reciprocal Relationship with Large Language Models', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7713.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e7713.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods that use large language models to synthesize, distill, or generate scientific theories, hypotheses, or structured knowledge from collections of scholarly papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ORKG</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Open Research Knowledge Graph (ORKG)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A scholarly KG resource designed to represent bibliographic and research contributions, which can be used to ground LLM outputs and improve scholarly QA.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Leveraging LLMs in Scholarly Knowledge Graph Question Answering</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>Leveraging LLMs in Scholarly Knowledge Graph Question Answering</td>
                        </tr>
                        <tr>
                            <td><strong>authors</strong></td>
                            <td>T A Taffa, R Usbeck</td>
                        </tr>
                        <tr>
                            <td><strong>year</strong></td>
                            <td>2023</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>ORKG-backed Scholarly QA (using ORKG as grounding source)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Uses ORKG structured bibliographic/contextual data as retrieval context for LLMs to improve answers to research-related queries and bibliographic QA.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>bibliographic metadata, structured scholarly KG records (ORKG)</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>scholarly QA answers grounded in ORKG triples; improved bibliographic responses</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_technique</strong></td>
                            <td>structured prompt + retrieved KG context; possibly few-shot prompting</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>datasets_used</strong></td>
                            <td>ORKG (Open Research Knowledge Graph)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>improvements in output accuracy for research-related questions (not numerically specified in review)</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Described as significantly improving LLM responses to research questions by providing bibliographic context; no precise metrics in review.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Quality depends on ORKG coverage and update frequency; traceability and interpretability partially addressed but require XAI pipelines.</td>
                        </tr>
                        <tr>
                            <td><strong>counterpoint</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Knowledge Graphs and Their Reciprocal Relationship with Large Language Models', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7713.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e7713.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods that use large language models to synthesize, distill, or generate scientific theories, hypotheses, or structured knowledge from collections of scholarly papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Zero-Shot Chinese MedKG</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Zero-Shot Construction of Chinese Medical Knowledge Graph with GPT-3.5-turbo and GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A demonstration that ChatGPT-family models (GPT-3.5-turbo, GPT-4) can be prompted in zero-shot to construct a medical KG from Chinese medical texts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Zero-Shot Construction of Chinese Medical Knowledge Graph with GPT-3.5-turbo and GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>Zero-Shot Construction of Chinese Medical Knowledge Graph with GPT-3.5-turbo and GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>authors</strong></td>
                            <td>L I Wu, Y Su, G Li</td>
                        </tr>
                        <tr>
                            <td><strong>year</strong></td>
                            <td>2023</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Zero-shot LLM-based KG construction (Chinese medical)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Applies zero-shot prompting to ChatGPT-family LLMs to extract entities and relations from Chinese medical texts and build a KG without labeled supervision.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>full-text Chinese medical documents</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>medical KG triples / constructed KG</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_technique</strong></td>
                            <td>zero-shot prompting with structured output constraints</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-turbo, GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>datasets_used</strong></td>
                            <td>Chinese medical corpora (unspecified)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>not specified in review (likely extraction precision/recall and human validation)</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Demonstrated feasibility of zero-shot KG construction with ChatGPT variants; detailed metrics not reported in the review summary.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Potential extraction errors, need for entity normalization and expert validation; issues with hallucinated relations.</td>
                        </tr>
                        <tr>
                            <td><strong>counterpoint</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Knowledge Graphs and Their Reciprocal Relationship with Large Language Models', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7713.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e7713.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods that use large language models to synthesize, distill, or generate scientific theories, hypotheses, or structured knowledge from collections of scholarly papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PRLLM / PPNet</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Patent Response Large Language Model (PRLLM) and Patent Precedents Knowledge Graph (PPNet)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A specialized pipeline combining an LLM for patent response generation with a domain-specific patent KG to improve factuality in patent-domain NLP tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Patent Response Large Language Model (PRLLM) and Patent Precedents Knowledge Graph (PPNet)</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>Patent Response Large Language Model (PRLLM) and Patent Precedents Knowledge Graph (PPNet)</td>
                        </tr>
                        <tr>
                            <td><strong>authors</strong></td>
                            <td>cited in review as [58]</td>
                        </tr>
                        <tr>
                            <td><strong>year</strong></td>
                            <td>2024</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>PRLLM + PPNet</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Injects patent KG content as structured context during LLM prompting or retrieval to produce faithful patent responses and leverage precedent knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>patent texts and patent-knowledge graph (PPNet)</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>patent-domain textual responses and KG-grounded outputs</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_technique</strong></td>
                            <td>knowledge-injection / RAG with domain KG</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>datasets_used</strong></td>
                            <td>patent corpora and PPNet (patent KG)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>not specified in review (expected: factuality, precision of legal/patent claims)</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Presented as a specialized NLP system for patent understanding and response generation; quantitative results not provided in review summary.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Domain complexity requires careful validation; legal/patent correctness is high-stakes and needs expert oversight.</td>
                        </tr>
                        <tr>
                            <td><strong>counterpoint</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Knowledge Graphs and Their Reciprocal Relationship with Large Language Models', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>LLMs for Knowledge Graph construction and reasoning: Recent capabilities and future opportunities <em>(Rating: 2)</em></li>
                <li>Graph Retrieval-Augmented Generation for Large Language Models: A Survey <em>(Rating: 2)</em></li>
                <li>Leveraging LLMs in Scholarly Knowledge Graph Question Answering <em>(Rating: 2)</em></li>
                <li>Auto-KG Agent <em>(Rating: 1)</em></li>
                <li>RD-P: A Trustworthy Retrieval-Augmented Prompter with Knowledge Graphs for LLMs <em>(Rating: 2)</em></li>
                <li>Zero-Shot Construction of Chinese Medical Knowledge Graph with GPT-3.5-turbo and GPT-4 <em>(Rating: 2)</em></li>
                <li>KARGEN: Knowledge-enhanced Automated Radiology Report Generation Using Large Language Models <em>(Rating: 2)</em></li>
                <li>SG-RAG: Multi-Hop Question Answering with Large Language Models Through Knowledge Graphs <em>(Rating: 2)</em></li>
                <li>zrLLM: Zero-Shot Relational Learning on Temporal Knowledge Graphs with Large Language Models <em>(Rating: 1)</em></li>
                <li>Patent Response System Optimised for Faithfulness: Procedural Knowledge Embodiment with Knowledge Graph and Retrieval Augmented Generation <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7713",
    "paper_id": "paper-278024019",
    "extraction_schema_id": "extraction-schema-144",
    "extracted_data": [
        {
            "name_short": "RAG",
            "name_full": "Retrieval-Augmented Generation",
            "brief_description": "A class of methods that augment LLMs at inference with retrieved external knowledge (documents or KG subgraphs) to ground generation, reduce hallucinations, and enable multi-hop reasoning.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "paper_title": "Retrieval-Augmented Generation",
            "authors": "multiple (reviewed literature)",
            "year": 2025,
            "method_name": "Retrieval-Augmented Generation (RAG)",
            "method_description": "At inference, retrieve relevant documents or KG subgraphs and provide them as context to an LLM so the model conditions generation on grounded, verifiable facts rather than only parametric knowledge.",
            "input_type": "text documents and/or KG subgraphs (retrieved passages, subgraphs)",
            "output_type": "textual answers grounded by retrieved facts; optionally updated KG subgraphs or structured answers",
            "prompting_technique": "retrieval-augmented prompting (RAG); contextual prompting with retrieved evidence",
            "model_name": null,
            "model_size": null,
            "datasets_used": null,
            "evaluation_metric": "varied across cited works (factuality/accuracy, human evaluation, downstream QA performance); review cites a 37% reduction in factual errors for enterprise chatbots when using KG-RAG",
            "reported_results": "Reported in the reviewed literature to substantially reduce hallucinations and improve factuality; the survey cites a 37% reduction in factual errors in an enterprise chatbot evaluation when KG subgraphs were dynamically retrieved.",
            "limitations": "Does not by itself ensure traceability to KG provenance or full explainability; computational cost for real-time retrieval and KG subgraph selection; gaps remain in integrating RAG with formal XAI audits.",
            "counterpoint": true,
            "uuid": "e7713.0",
            "source_info": {
                "paper_title": "Knowledge Graphs and Their Reciprocal Relationship with Large Language Models",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "Auto-KG Agent",
            "name_full": "Auto-KG Agent",
            "brief_description": "An LLM-driven framework that automates the extraction of semantic triples from unstructured text to populate and update Knowledge Graphs.",
            "citation_title": "Auto-KG Agent",
            "mention_or_use": "mention",
            "paper_title": "Auto-KG Agent",
            "authors": "cited as [11] in review (authors not listed in review text)",
            "year": 2024,
            "method_name": "Auto-KG Agent",
            "method_description": "Uses LLMs as autonomous agents to perform semantic triple extraction (entity and relation extraction) from unstructured corpora and populate KGs with minimal manual curation.",
            "input_type": "unstructured text (papers, reports, web pages)",
            "output_type": "knowledge graph triples / populated KG",
            "prompting_technique": "LLM agent prompting and structured extraction prompts; likely few-shot or instruction prompts",
            "model_name": null,
            "model_size": null,
            "datasets_used": null,
            "evaluation_metric": "not specified in review (typical metrics: precision/recall of triples, human validation)",
            "reported_results": "Described as automating semantic triple extraction and reducing manual curation effort; review does not report numeric results.",
            "limitations": "Potential for extraction errors / hallucinated triples, need for entity normalization and ontology alignment, scalability and validation overhead.",
            "counterpoint": true,
            "uuid": "e7713.1",
            "source_info": {
                "paper_title": "Knowledge Graphs and Their Reciprocal Relationship with Large Language Models",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "VieMedKG",
            "name_full": "VieMedKG",
            "brief_description": "A domain-specific Knowledge Graph and benchmark for traditional Vietnamese medicine constructed using LLM-assisted extraction from textual sources.",
            "citation_title": "VieMedKG: Knowledge Graph and Benchmark for Traditional Vietnamese Medicine",
            "mention_or_use": "mention",
            "paper_title": "VieMedKG: Knowledge Graph and Benchmark for Traditional Vietnamese Medicine",
            "authors": "T Trinh, A Dao, H T H Nhung, H T Son",
            "year": 2024,
            "method_name": "VieMedKG construction (LLM-assisted KG building)",
            "method_description": "Applies LLMs to extract medical entities and relations from domain texts to construct a specialized KG and associated benchmark for evaluation.",
            "input_type": "domain-specific textual corpora (traditional medicine texts, articles)",
            "output_type": "domain Knowledge Graph and benchmark",
            "prompting_technique": "semantic parsing / prompt-based entity-relation extraction (zero/few-shot prompting implied)",
            "model_name": null,
            "model_size": null,
            "datasets_used": "traditional Vietnamese medicine textual sources (as dataset for KG construction)",
            "evaluation_metric": "benchmarking of KG quality and downstream tasks (not numerically specified in review)",
            "reported_results": "Presented as a domain KG and benchmark; review notes it as an example of LLMs constructing domain-specific KGs but does not provide metrics.",
            "limitations": "Domain adaptation challenges, need for expert validation in sensitive medical domain, potential hallucinations in extraction.",
            "counterpoint": true,
            "uuid": "e7713.2",
            "source_info": {
                "paper_title": "Knowledge Graphs and Their Reciprocal Relationship with Large Language Models",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "KARGEN",
            "name_full": "KARGEN (Knowledge-enhanced Automated Radiology Report Generation)",
            "brief_description": "A system that leverages domain-specific embeddings from radiology datasets and LLMs to generate radiology reports and assist medical KG creation.",
            "citation_title": "Knowledge-enhanced Automated Radiology Report Generation Using Large Language Models",
            "mention_or_use": "mention",
            "paper_title": "Knowledge-enhanced Automated Radiology Report Generation Using Large Language Models",
            "authors": "Y Li, Z Wang, Y Liu, L Wang, L Liu, L Zhou, Kargen (et al.)",
            "year": 2024,
            "method_name": "KARGEN",
            "method_description": "Combines domain embeddings from radiology data with LLM generation to produce medically-grounded radiology reports and to populate/align KGs for clinical use.",
            "input_type": "radiology datasets (text reports), potentially images (radiology images) though review emphasizes text",
            "output_type": "automated radiology reports and KG triples/structured clinical knowledge",
            "prompting_technique": "knowledge-injection into prompts; embedding-enhanced conditioning; likely RAG-like grounding",
            "model_name": null,
            "model_size": null,
            "datasets_used": "radiology datasets (unspecified in review)",
            "evaluation_metric": "not detailed in review (typical: clinical correctness, factuality, human expert evaluation)",
            "reported_results": "Reported as improving report generation fidelity via knowledge enhancement; specific quantitative outcomes not provided in review.",
            "limitations": "Risk of clinical hallucinations, need for strict validation and explainability (attention maps used for traceability), domain adaptation constraints.",
            "counterpoint": true,
            "uuid": "e7713.3",
            "source_info": {
                "paper_title": "Knowledge Graphs and Their Reciprocal Relationship with Large Language Models",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "SG-RAG",
            "name_full": "SG-RAG (Subgraph Retrieval-Augmented Generation)",
            "brief_description": "A multi-hop QA model integrating Knowledge Graph subgraph retrieval with LLMs to answer complex queries that require chaining multiple facts.",
            "citation_title": "SG-RAG: Multi-Hop Question Answering with Large Language Models Through Knowledge Graphs",
            "mention_or_use": "mention",
            "paper_title": "SG-RAG: Multi-Hop Question Answering with Large Language Models Through Knowledge Graphs",
            "authors": "A O M Saleh, G Tur, Y Saygin",
            "year": 2024,
            "method_name": "SG-RAG",
            "method_description": "Retrieves relevant KG subgraphs as context for an LLM to perform multi-hop reasoning across connected facts, improving performance on structured querying tasks.",
            "input_type": "questions plus KG (structured graph) data",
            "output_type": "textual QA answers grounded in multi-hop KG evidence",
            "prompting_technique": "retrieval of KG subgraphs + contextual prompting to the LLM",
            "model_name": null,
            "model_size": null,
            "datasets_used": null,
            "evaluation_metric": "task accuracy on multi-hop QA; review states it outperforms traditional SQL-based approaches for structured queries",
            "reported_results": "Reported to outperform SQL-based approaches in structured data querying for multi-hop QA in the cited work.",
            "limitations": "Complexity of subgraph selection, traceability to specific KG facts, scalability to large KGs.",
            "counterpoint": false,
            "uuid": "e7713.4",
            "source_info": {
                "paper_title": "Knowledge Graphs and Their Reciprocal Relationship with Large Language Models",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "zrLLM",
            "name_full": "zrLLM (Zero-Shot Relational Learning with LLMs)",
            "brief_description": "An approach applying zero-shot LLM capabilities to temporal knowledge graphs for predicting time-sensitive relations without task-specific supervision.",
            "citation_title": "zrLLM: Zero-Shot Relational Learning on Temporal Knowledge Graphs with Large Language Models",
            "mention_or_use": "mention",
            "paper_title": "zrLLM: Zero-Shot Relational Learning on Temporal Knowledge Graphs with Large Language Models",
            "authors": "Tresp, V. (cited in review)",
            "year": 2024,
            "method_name": "zrLLM",
            "method_description": "Uses LLMs in a zero-shot manner to infer temporal relations and predict time-sensitive facts for Temporal Knowledge Graph completion.",
            "input_type": "temporal KG facts and textual descriptions",
            "output_type": "predicted temporal triples / KG updates",
            "prompting_technique": "zero-shot prompting",
            "model_name": null,
            "model_size": null,
            "datasets_used": null,
            "evaluation_metric": "not specified in review (likely link prediction metrics for TKGs)",
            "reported_results": "Described as applying zero-shot relational learning to temporal KGs; specific numeric results not provided in review.",
            "limitations": "Zero-shot predictions may lack reliability for fine-grained temporal reasoning; needs validation and alignment with ontologies.",
            "counterpoint": true,
            "uuid": "e7713.5",
            "source_info": {
                "paper_title": "Knowledge Graphs and Their Reciprocal Relationship with Large Language Models",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "RD-P",
            "name_full": "Retrieve-and-Discriminate Prompter (RD-P)",
            "brief_description": "A retrieval-augmented prompting framework that integrates knowledge graphs to improve trustworthy, knowledge-intensive question answering with LLMs.",
            "citation_title": "RD-P: A Trustworthy Retrieval-Augmented Prompter with Knowledge Graphs for LLMs",
            "mention_or_use": "mention",
            "paper_title": "RD-P: A Trustworthy Retrieval-Augmented Prompter with Knowledge Graphs for LLMs",
            "authors": "Y Huang, G Zeng",
            "year": 2024,
            "method_name": "RD-P",
            "method_description": "Retrieves KG-backed evidence and discriminates/filters retrieved items before constructing prompts for the LLM to ensure trustworthy, knowledge-grounded responses.",
            "input_type": "queries and KG-backed evidence / retrieved passages",
            "output_type": "knowledge-grounded answers; reduced hallucinations",
            "prompting_technique": "retrieval + discrimination + prompt construction (RAG-family)",
            "model_name": null,
            "model_size": null,
            "datasets_used": null,
            "evaluation_metric": "not specified in review (expected: factuality, faithfulness, QA accuracy)",
            "reported_results": "Presented as improving reliability in knowledge-intensive QA; no numeric metrics given in review summary.",
            "limitations": "Doesn't fully solve traceability/XAI; relies on quality of KG retrieval and discrimination heuristics.",
            "counterpoint": false,
            "uuid": "e7713.6",
            "source_info": {
                "paper_title": "Knowledge Graphs and Their Reciprocal Relationship with Large Language Models",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "ORKG",
            "name_full": "Open Research Knowledge Graph (ORKG)",
            "brief_description": "A scholarly KG resource designed to represent bibliographic and research contributions, which can be used to ground LLM outputs and improve scholarly QA.",
            "citation_title": "Leveraging LLMs in Scholarly Knowledge Graph Question Answering",
            "mention_or_use": "mention",
            "paper_title": "Leveraging LLMs in Scholarly Knowledge Graph Question Answering",
            "authors": "T A Taffa, R Usbeck",
            "year": 2023,
            "method_name": "ORKG-backed Scholarly QA (using ORKG as grounding source)",
            "method_description": "Uses ORKG structured bibliographic/contextual data as retrieval context for LLMs to improve answers to research-related queries and bibliographic QA.",
            "input_type": "bibliographic metadata, structured scholarly KG records (ORKG)",
            "output_type": "scholarly QA answers grounded in ORKG triples; improved bibliographic responses",
            "prompting_technique": "structured prompt + retrieved KG context; possibly few-shot prompting",
            "model_name": null,
            "model_size": null,
            "datasets_used": "ORKG (Open Research Knowledge Graph)",
            "evaluation_metric": "improvements in output accuracy for research-related questions (not numerically specified in review)",
            "reported_results": "Described as significantly improving LLM responses to research questions by providing bibliographic context; no precise metrics in review.",
            "limitations": "Quality depends on ORKG coverage and update frequency; traceability and interpretability partially addressed but require XAI pipelines.",
            "counterpoint": false,
            "uuid": "e7713.7",
            "source_info": {
                "paper_title": "Knowledge Graphs and Their Reciprocal Relationship with Large Language Models",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "Zero-Shot Chinese MedKG",
            "name_full": "Zero-Shot Construction of Chinese Medical Knowledge Graph with GPT-3.5-turbo and GPT-4",
            "brief_description": "A demonstration that ChatGPT-family models (GPT-3.5-turbo, GPT-4) can be prompted in zero-shot to construct a medical KG from Chinese medical texts.",
            "citation_title": "Zero-Shot Construction of Chinese Medical Knowledge Graph with GPT-3.5-turbo and GPT-4",
            "mention_or_use": "mention",
            "paper_title": "Zero-Shot Construction of Chinese Medical Knowledge Graph with GPT-3.5-turbo and GPT-4",
            "authors": "L I Wu, Y Su, G Li",
            "year": 2023,
            "method_name": "Zero-shot LLM-based KG construction (Chinese medical)",
            "method_description": "Applies zero-shot prompting to ChatGPT-family LLMs to extract entities and relations from Chinese medical texts and build a KG without labeled supervision.",
            "input_type": "full-text Chinese medical documents",
            "output_type": "medical KG triples / constructed KG",
            "prompting_technique": "zero-shot prompting with structured output constraints",
            "model_name": "GPT-3.5-turbo, GPT-4",
            "model_size": null,
            "datasets_used": "Chinese medical corpora (unspecified)",
            "evaluation_metric": "not specified in review (likely extraction precision/recall and human validation)",
            "reported_results": "Demonstrated feasibility of zero-shot KG construction with ChatGPT variants; detailed metrics not reported in the review summary.",
            "limitations": "Potential extraction errors, need for entity normalization and expert validation; issues with hallucinated relations.",
            "counterpoint": true,
            "uuid": "e7713.8",
            "source_info": {
                "paper_title": "Knowledge Graphs and Their Reciprocal Relationship with Large Language Models",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "PRLLM / PPNet",
            "name_full": "Patent Response Large Language Model (PRLLM) and Patent Precedents Knowledge Graph (PPNet)",
            "brief_description": "A specialized pipeline combining an LLM for patent response generation with a domain-specific patent KG to improve factuality in patent-domain NLP tasks.",
            "citation_title": "Patent Response Large Language Model (PRLLM) and Patent Precedents Knowledge Graph (PPNet)",
            "mention_or_use": "mention",
            "paper_title": "Patent Response Large Language Model (PRLLM) and Patent Precedents Knowledge Graph (PPNet)",
            "authors": "cited in review as [58]",
            "year": 2024,
            "method_name": "PRLLM + PPNet",
            "method_description": "Injects patent KG content as structured context during LLM prompting or retrieval to produce faithful patent responses and leverage precedent knowledge.",
            "input_type": "patent texts and patent-knowledge graph (PPNet)",
            "output_type": "patent-domain textual responses and KG-grounded outputs",
            "prompting_technique": "knowledge-injection / RAG with domain KG",
            "model_name": null,
            "model_size": null,
            "datasets_used": "patent corpora and PPNet (patent KG)",
            "evaluation_metric": "not specified in review (expected: factuality, precision of legal/patent claims)",
            "reported_results": "Presented as a specialized NLP system for patent understanding and response generation; quantitative results not provided in review summary.",
            "limitations": "Domain complexity requires careful validation; legal/patent correctness is high-stakes and needs expert oversight.",
            "counterpoint": true,
            "uuid": "e7713.9",
            "source_info": {
                "paper_title": "Knowledge Graphs and Their Reciprocal Relationship with Large Language Models",
                "publication_date_yy_mm": "2025-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "LLMs for Knowledge Graph construction and reasoning: Recent capabilities and future opportunities",
            "rating": 2,
            "sanitized_title": "llms_for_knowledge_graph_construction_and_reasoning_recent_capabilities_and_future_opportunities"
        },
        {
            "paper_title": "Graph Retrieval-Augmented Generation for Large Language Models: A Survey",
            "rating": 2,
            "sanitized_title": "graph_retrievalaugmented_generation_for_large_language_models_a_survey"
        },
        {
            "paper_title": "Leveraging LLMs in Scholarly Knowledge Graph Question Answering",
            "rating": 2,
            "sanitized_title": "leveraging_llms_in_scholarly_knowledge_graph_question_answering"
        },
        {
            "paper_title": "Auto-KG Agent",
            "rating": 1,
            "sanitized_title": "autokg_agent"
        },
        {
            "paper_title": "RD-P: A Trustworthy Retrieval-Augmented Prompter with Knowledge Graphs for LLMs",
            "rating": 2,
            "sanitized_title": "rdp_a_trustworthy_retrievalaugmented_prompter_with_knowledge_graphs_for_llms"
        },
        {
            "paper_title": "Zero-Shot Construction of Chinese Medical Knowledge Graph with GPT-3.5-turbo and GPT-4",
            "rating": 2,
            "sanitized_title": "zeroshot_construction_of_chinese_medical_knowledge_graph_with_gpt35turbo_and_gpt4"
        },
        {
            "paper_title": "KARGEN: Knowledge-enhanced Automated Radiology Report Generation Using Large Language Models",
            "rating": 2,
            "sanitized_title": "kargen_knowledgeenhanced_automated_radiology_report_generation_using_large_language_models"
        },
        {
            "paper_title": "SG-RAG: Multi-Hop Question Answering with Large Language Models Through Knowledge Graphs",
            "rating": 2,
            "sanitized_title": "sgrag_multihop_question_answering_with_large_language_models_through_knowledge_graphs"
        },
        {
            "paper_title": "zrLLM: Zero-Shot Relational Learning on Temporal Knowledge Graphs with Large Language Models",
            "rating": 1,
            "sanitized_title": "zrllm_zeroshot_relational_learning_on_temporal_knowledge_graphs_with_large_language_models"
        },
        {
            "paper_title": "Patent Response System Optimised for Faithfulness: Procedural Knowledge Embodiment with Knowledge Graph and Retrieval Augmented Generation",
            "rating": 1,
            "sanitized_title": "patent_response_system_optimised_for_faithfulness_procedural_knowledge_embodiment_with_knowledge_graph_and_retrieval_augmented_generation"
        }
    ],
    "cost": 0.017013499999999997,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Knowledge Graphs and Their Reciprocal Relationship with Large Language Models
21 April 2025</p>
<p>Ramandeep Singh Dehal 0009-0004-1515-0914
Management Science Department
Cape Breton University
B1M 1A2SydneyNSCanada</p>
<p>Mehak Sharma 0009-0009-2198-5973
Management Science Department
Cape Breton University
B1M 1A2SydneyNSCanada</p>
<p>Enayat Rajabi enayat_rajabi@cbu.ca 0000-0002-9557-0043
Management Science Department
Cape Breton University
B1M 1A2SydneyNSCanada</p>
<p>Knowledge Graphs and Their Reciprocal Relationship with Large Language Models
21 April 202590D5FFAA27FA46A8365516476CEBA5A410.3390/make7020038Received: 6 March 2025 Revised: 7 April 2025 Accepted: 12 April 2025Knowledge GraphsLarge Language Modelsmachine learningartificial intelligence
The reciprocal relationship between Large Language Models (LLMs) and Knowledge Graphs (KGs) highlights their synergistic potential in enhancing artificial intelligence (AI) applications.LLMs, with their natural language understanding and generative capabilities, support the automation of KG construction through entity recognition, relation extraction, and schema generation.Conversely, KGs serve as structured and interpretable data sources that improve the transparency, factual consistency and reliability of LLM-based applications, mitigating challenges such as hallucinations and lack of explainability.This study conducts a systematic literature review of 77 studies to examine AI methodologies supporting LLM-KG integration, including symbolic AI, machine learning, and hybrid approaches.The research explores diverse applications spanning healthcare, finance, justice, and industrial automation, revealing the transformative potential of this synergy.Through in-depth analysis, this study identifies key limitations in current approaches, including challenges in scalability with maintaining dynamic and real-time Knowledge Graphs, difficulty in adapting general-purpose LLMs to specialized domains, limited explainability in tracing model outputs to interpretable reasoning, and ethical concerns surrounding bias, fairness, and transparency.In response, the study highlights potential strategies to optimize LLM-KG synergy.The findings from this study provide actionable insights for researchers and practitioners aiming for robust, transparent, and adaptive AI systems to enhance knowledge-driven AI applications through LLM-KG integration, further advancing generative AI and explainable AI (XAI) applications.</p>
<p>Introduction</p>
<p>In today's artificial intelligence (AI)-driven world, understanding and utilizing structured and unstructured data effectively has become critical for decision-making in various domains.Recently, Large Language Models (LLMs) have gained popularity due to their use cases in well-received generative AI applications such as ChatGPT, DeepSeek, Gemini, and Copilot and in domain-specific model's highlighting its importance in decision-making systems [1].Despite the success of LLMs in AI applications, there have been a few known challenges with LLMs due to their lack of factual knowledge.There have been instances of LLMs not being able to recall their training corpus and experiencing hallucinations.For instance, LLMs might answer "Facebook bought YouTube in 2006" when asked "When was YouTube bought by Facebook?", which contradicts the fact that Google bought YouTube in 2006.This challenge creates trust issues with LLMs.LLMs have also been criticized for their lack of interpretability as black box models.They store knowledge implicitly in their parameters, making it hard to understand or confirm the information they provide.Moreover, some LLMs make decisions based on probabilities, which can lead to uncertain or unclear reasoning.Even when LLMs try to explain their reasoning using methods like a chain of thought, these explanations can sometimes include false or misleading information, which depicts LLMs as suffering from the hallucination issue.This makes them unreliable in critical domains like medical diagnosis or legal decisions, where mistakes can have serious consequences [2].For example, in medicine, an LLM might give the wrong diagnosis and back it up with reasoning that does not match common medical knowledge.Another challenge is that LLMs trained on general information often struggle with domain adaptation due to the lack of domain-specific knowledge or new training data [3].This limits their ability to adapt to unique or evolving domains.The challenges show that the specific patterns and functions of LLMs that are used to predict outcomes or decisions are not directly accessible or explainable to humans.The complexity of LLMs often leaves users questioning how outputs are generated and whether the decisions made by algorithms are fair and accurate.Addressing these challenges requires a deeper understanding of their reciprocal relationship and how LLMs can be explainable while effectively integrated.On the other hand, a Knowledge Graph (KG) as a semantic network for structured data representation model facilitates reasoning, information retrieval, and contextual insights.KG technologies such as entity recognition, relationship extraction, and schema generation make AI models more explainable [4].KGs with their structured and factual nature offer a way to mitigate the explainability concerns of LLMs and improve their output and contextual accuracy [5].The derivative of KG-LLM integration is to ensure understandability and transparency through 'Explainable AI' also known as XAI, which bridges the interpretability gap between complex models and human users and plays a pivotal role in building trust in these integrated systems [6].Conversely, LLMs augment KG construction by automating processes like entity extraction and relationship identification from unstructured data [7].This is crucial for applications like medical KGs, where inaccuracies can have critical implications [8].LLMs use vectors and neural networks to predict natural language, which is capable of generating human-like text and processing complex information [9].As a result, when LLMs and KGs are coupled together, they can improve machine learning reasoning and data-centric decision-making and provide Findable, Accessible, Interoperable and Reusable (FAIR) unbiased explainable systems [10].To understand the reciprocal relationship between these two technologies, we went through the existing literature to create more robust systems through a systematic review and outlined the following research questions: The main contributions of this paper are addressed through the investigation of the three research questions.By answering these questions, this study contributes to systematically exploring the LLM-KG relationship, categorizing AI methodologies, addressing explainability challenges through XAI, and providing insights into domain-specific applications like healthcare and finance.Through this study, we aimed to contribute to the field of LLM-KG integration.First, we offer a systematic and structured review of 77 research papers, thereby highlighting key advancements in AI methodologies for constructing and utilizing KGs.Second, we provide a comprehensive classification framework that categorizes existing techniques into three primary groups-symbolic AI, machine learning, and evolutionary computation-while providing a comparative analysis of the strengths and limitations inherent in each approach.Third, this study identifies critical challenges such as (1) scalability, where real-time updates and integration of large-scale KGs into LLM workflows remain computationally intensive; (2) domain adaptation, as general-purpose LLMs often struggle to align with domain-specific knowledge embedded in KGs effectively; (3) explainability, due to the difficulty of tracing outputs to human-understandable reasoning; and (4) ethical considerations, including fairness, bias mitigation, and data governance challenges.It also proposes how emerging methods-including XAI frameworks, retrieval-augmented generation, and hybrid neuro-symbolic models-can address these issues.Finally, we outline the gaps and limitations paving the path for future research, emphasizing the need for dynamic updates to Knowledge Graphs, multimodal integration, and bias mitigation strategies to further the practical application of LLM-driven Knowledge Graphs, ultimately moving toward a better understanding of the integration and utilizing their collaborative strengths to create systems that are robust, versatile and trustworthy.</p>
<p>Literature Review</p>
<p>Neoteric advancements in integrating LLMs and KGs have laid the groundwork for improving AI systems' reasoning and decision-making.In particular, recent studies and frameworks such as Auto-KG Agent [11], RAG-based pipelines [12] and domain-specific models like VieMedKG [13] and KARGEN [14] exemplify current progress in real-world applications of LLM-KG integration.Pan et al., 2024, andRen et al., 2024, emphasize the capabilities of LLMs in automating KG construction from unstructured data.These studies demonstrate technical advancements in automating KG creation and improving scalability, particularly in domains with large unstructured datasets [3,15].However, the focus has largely been on the technical aspects of LLM-driven KG construction, with indirect and limited attention paid to the critical role of this integration, i.e., explainability in ensuring the interpretability and trustworthiness of these systems.</p>
<p>Other studies such as Zhu et al., 2024, highlight how KGs serve as inputs to LLM applications by providing structured, factual knowledge that mitigates hallucinations and improves contextual accuracy.Frameworks like Retrieval Augmented Generation (RAG) illustrate the synergy of this integration but often fall short in addressing how XAI can trace outputs to verifiable KG data [8].While these existing studies focus on the value of explainability, they lack a systematic exploration of XAI's role in building user trust and meeting regulatory requirements in sensitive domains such as healthcare and finance.</p>
<p>Despite advancements and progress in LLM-KG integration, critical gaps persist in understanding their bidirectional relationship.Existing literature often treats LLMs and KGs in isolation, fragmenting insights into how LLMs enhance KG construction (e.g., via entity extraction) or how domain-specific KGs (e.g., medical ontologies) improve LLM reliability.While Zhu et al. pioneered a unified framework exploring KGs as both inputs and outputs for LLMs, their work overlooks systematic methodologies for ensuring traceability and accountability through XAI [8].For instance, though they identify XAI's potential to bridge interpretability gaps, they fail to operationalize how fairness or auditability can be achieved in practice [5,7].Hence, the AI techniques to support LLM-KG workflows and how XAI principles can be tailored to domain-specific needs remain unanswered.Our work addresses these gaps by rigorously mapping methodologies for LLM-KG integration (e.g., fine-tuning, Retrieval Augmented Generation, and hybrid architectures) and proposing an XAI-driven framework to enhance transparency in high-stakes domains like healthcare and finance.By extending the research beyond the current literature, we present a focused approach toward understanding LLM-KG systems and prioritizing adaptability, ensuring systems evolve with emerging knowledge while maintaining explainability-a critical step toward unlocking LLM-KG potential in real-world applications.</p>
<p>Methods</p>
<p>Our study adopts a PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses-Scoping Review) [16] methodology to examine how LLMs integrate with KGs in the context of generative AI applications.PRISMA-ScR provides a structured framework that allows us to conduct a structured, comprehensive assessment of the existing literature, capturing patterns, identifying research gaps, and understanding the trend of this integration over recent years.Drawing on PRISMA-ScR guidelines, we structured this review to achieve robust results by following a defined protocol for study selection and analysis.</p>
<p>Specific Research Questions</p>
<p>As our primary goal is to provide an overview of the integration of LLM-KG through the studies published across various domains, we formulated three specific research questions that guided our collection, extraction, analysis, and synthesis of evidence.These three research questions (RQ1-RQ3) were selected based on the emerging challenges and opportunities identified in the literature on LLM-KG integration.RQ1: How are LLMs being used to construct KGs? RQ1 explores how LLMs are utilized to construct KGs, addressing the growing interest in automating KG creation from unstructured data sources, i.e., critically required in domains such as healthcare, law, and education.RQ2: How are KGs being used to improve the outputs of LLMs?RQ2 examines how KGs can be used to enhance LLM outputs in mitigating issues like hallucinations and contextual accuracy, which are concerns in real-world applications.RQ3: What AI methodologies are used for LLM-based KG systems and KG-based LLMs?Our review is guided by these research questions to provide a comprehensive lens through which the bidirectional relationship between LLMs and KGs can be analyzed, categorized, and advanced, identify methodological gaps, and investigate the challenges faced in this integration.</p>
<p>Data Sources and Search Strategy</p>
<p>To prepare a cumulative dataset for the systematic review, we conducted an automated search process by applying a search string across four academic search engines and libraries, and then, we manually selected studies that are focused on the topic of interest.We used targeted terms such as "Large Language Model" and "Knowledge Graph" to capture a wide range of studies on LLM and KG integration.In this research, we referred to the major scientific databases such as ACM Digital, IEEE Xplore, Google Scholar and Elsevier Scopus.</p>
<p>We opted for a partially automated approach because search engines differ on how they structure search strings.To overcome this for the search strategy, we developed a targeted search query using Boolean operators to capture relevant publications: ("Large Language Model" OR "LLM") AND ("Knowledge Graph" OR "KG").Furthermore, the large number of papers that were first retrieved did not align with the scope of our research.</p>
<p>Inclusion and Exclusion Criteria</p>
<p>We applied four exclusion and inclusion criteria to evaluate the studies retrieved from 2019 to 2024 through our search.Papers were excluded from the research if they met any of the following exclusion criteria, and the papers adhering to the eligibility criteria were included in the research process.The Table 1 below states the criteria.</p>
<p>Selection Process</p>
<p>To ensure comprehensive literature coverage, papers were initially identified using the search string on major scientific databases, followed by manually narrowing down the list of the retrieved papers in our dataset by selecting the studies that aligned with the scope of our research based on the analysis of the metadata like title, abstract, and keywords.These papers' titles, years, and DOIs were extracted from the databases by executing a Python script utilizing the Selenium library to automate the steps and store the relevant information in an Excel file.We additionally used Pandas for data cleaning operations, such as removing duplicates and filtering entries with missing metadata (e.g., DOIs or publication years).Ambiguous cases were resolved through full-text reviews and collaborative review sessions among authors to ensure consistency and accuracy in inclusion.The process is further elaborated in Figure 1 below.We retrieved 3658 papers that were potentially relevant to our analysis.Once the titles were extracted, we first proceeded to remove duplicate results.This left us with 3317 results.Next, we removed those papers that were published in arXiv, leaving us with 2701 results.Afterward, we also removed those results which were published in books, blogs and forums.In total, we were ultimately left with 2639 results.Furthermore, we filtered the articles out with blank or missing attributes such as years and DOI.Thereafter, after applying exclusion and inclusion criteria, we reduced the total number of papers to 2374, which was further processed.Then to systematically filter studies, we performed a filtration function on the titles of the shortlisted papers, where we scanned for the query keywords "Large Language Model/LLM" and "Knowledge Graph/KG" and made sure the papers were relevant to the research topic, and we followed the defined inclusion and exclusion criteria, ensuring the selection of papers that align within our research focus.After this step, we were left with 1006 articles.Then, we proceeded with the initial screening of scanning titles and abstract skimming.Titles of all collected papers were skim-read and screened to determine relevance.Papers that clearly did not meet the inclusion criteria were marked for exclusion and documented in an exclusion log (see Appendix Table A1 for an example of paper screening).</p>
<p>We individually inspected the titles and decided to remove 250 articles, and 756 results were shortlisted for the next step of reviewing abstracts.During the secondary screening, papers that passed the initial screening were reviewed in greater depth by examining the abstract, introduction, and conclusion sections to assess the authors' objectives and contributions.In this step, we carefully analyzed the abstract and title of each paper to determine its alignment with our research questions.After manually reviewing each paper and evaluating its domain and research focus, initially, 181 papers were identified and shortlisted based on our established inclusion and exclusion criteria.We re-examined and re-evaluated the dataset to determine the significance of each study after refining our research questions.Ultimately, 77 papers were deemed directly aligned with the updated research questions and were incorporated into the final analysis, and the remaining papers were excluded due to their limited relevance to the revised scope of our study.Figure 2 below depicts the flow of the systematic review.During the process, whenever there was a conflict, we performed an in-depth review, where the papers whose relevance remained ambiguous after secondary screening underwent a full-text review.This allowed for a thorough assessment, particularly for papers that addressed complex methodologies or had overlapping themes.We reviewed the full text of the paper and decided based on the primary domain of the paper whether to include it for meta-analysis or not.This stage provided further clarification on the relevance of the papers to our research questions.</p>
<p>Dimensions</p>
<p>To understand the complete horizon of the LLM and KG integration, we collected information across several key dimensions, including the title of the paper for easy reference, the year of publication to analyze trends over time, and the source to identify the most relevant libraries contributing to the research.</p>
<p>1.</p>
<p>Domain: In the context of this research, this dimension largely refers to the domain or area of knowledge where the integration of LLMs and KGs is utilized to address challenges, solve problems, or drive innovations.While going through the dataset, we identified five major domains.These include computer science, education, finance, healthcare, and justice.The domain dimension is crucial for businesses as it helps identify industry-specific opportunities where LLM-KG can drive innovation, optimize operations, and enhance decision-making.By categorizing applications into areas like finance, healthcare, education, and justice, businesses can develop AI-driven solutions tailored to their sector, improving efficiency, customer experience, and competitive advantage.Understanding domain-specific applications allows companies to utilize AI not just for automation but as a strategic tool for growth, differentiation, and market leadership.</p>
<p>2.</p>
<p>Model Implemented: This dimension refers to the specific AI or computational model used to integrate LLM-KG.These models usually automate tasks essential for constructing and maintaining KGs, such as entity recognition, relationship extraction, and schema generation.Based on the studies, we were able to narrow down to five major models implemented, which are as follows:</p>
<p>• Autoregressive Transformers (Decoder-Only Models): These models, such as GPT-2, GPT-</p>
<p>3.</p>
<p>Applications: This dimension provides insights into how these solutions are used to solve real-world problems across various domains, including but not limited to building recommendation systems for providing personalized suggestions, developing classification systems for categorizing unstructured data into predefined groups, question answering systems and general NLP solutions for sentiment analysis and its applications.</p>
<p>4.</p>
<p>Input Type: This dimension investigates various types of input data used by the AI models in the studies finalized.Major types included in the finalized studies include text, images, and videos.It brings the focus to the ability of these models to incorporate unstructured and multimodal data to structured actionable insights.</p>
<p>Data Extraction, Data Analysis, and Synthesis</p>
<p>We implemented a structured form for the process of data extraction and employed a systematic approach to gather the relevant information from the shortlisted papers.During this process, we accessed the complete paper text and recorded specific relevant information while focusing on answering our research questions.Two researchers worked together during this process to ensure the accuracy of the data, resolving any disagreements through the discussions and involving a third researcher when needed.</p>
<p>Upon completing the form with the dataset populated from the information gathered from the papers, we analyzed it using two research methodologies, thematic analysis and descriptive statistics, to synthesize the collected data and present our findings.First, for the quantitative research approach, we used descriptive statistics to identify patterns, such as the number of papers published each year, their domain, and the multimodal dimensions.Second, for the qualitative research approach, we performed a thematic analysis to explore the content in more detail, identifying model implementation, applications, and implications, particularly in the context of XAI.Together, these approaches offered both high-level trends via quantitative insights and deep insights via qualitative synthesis, allowing us to synthesize the findings and draw meaningful conclusions comprehensively.</p>
<p>Results</p>
<p>We identified 77 studies focusing on our research area published between 2019 and 2024.During this timeframe, there has been a noticeable growth in interest in the topic, starting with the popularity of the launch of the generative AI application ChatGPT.Based on the studies, we could map the type of models implemented in each of the studies.The most frequently implemented models were Hybrid/Retrieval-Augmented Models, which combine LLMs with symbolic reasoning, external retrieval mechanisms, or structured knowledge sources to enhance factuality, transparency, and contextual grounding.These models were prevalent across diverse applications such as question answering, semantic search, and Knowledge Graph construction, followed by Seq2Seq Models, which are Encoder-Decoder Transformers like T5 and BART and were widely used for tasks such as summarization, translation, and KG-to-text generation.Autoregressive Transformers, particularly GPT-based models, appeared commonly in generative pipelines, especially for open-ended question answering.Bidirectional Transformers such as BERT were often applied in classification and entity extraction tasks.In contrast, fewer studies used Symbolic-Neural Hybrids/Others, including LSTMs and rule-based systems, primarily in specialized or low-resource scenarios.This distribution reflects a growing emphasis on hybrid and retrieval-augmented strategies for improving explainability and grounding in LLM-KG pipelines.Table 2 summarizes our mapping for model implementation.Our dataset is available at https://doi.org/10.6084/m9.figshare.28468637.v1accessed on 1 March 2025 [17].</p>
<p>Model Implemented Theme Papers</p>
<p>Hybrid/Retrieval-Augmented Models Combines LLMs with external retrieval, symbolic reasoning, or structured knowledge to enhance factual accuracy and context.</p>
<p>[11-14,18-64]</p>
<p>Model Implemented Theme Papers</p>
<p>Encoder-Decoder Transformers (Seq2Seq Models)</p>
<p>Transforms input sequences into structured or translated outputs, ideal for summarization, translation, and KG-to-text tasks.</p>
<p>[ [65][66][67][68][69][70][71][72][73][74][75][76][77][78][79][80][81] Autoregressive Transformers (Decoder-Only)</p>
<p>A family of autoregressive language models, designed to generate coherent and contextually relevant text.</p>
<p>[ [82][83][84][85][86] Bidirectional Transformers (Encoder-Only)</p>
<p>A transformer-based model pre-trained for understanding the context of words in both directions.[87,88] Symbolic-Neural Hybrids/Others</p>
<p>Integrates neural networks with rule-based or symbolic components, often used in domain-specific or low-resource applications.[89,90] We were also able to identify various applications of these studies.Notable applications include recommendation systems generation [91].Another key application is language model generation, such as the Retrieve-and-Discriminate Prompter (RD-P) framework, which is formed to enhance the performance and overall ability and reliability in performing knowledge-intensive question-answering tasks [20].Additionally, these studies contribute to general NLP applications such as the Patent Response Large Language Model (PRLLM) and Patent Precedents Knowledge Graph (PPNet), which is developed as a specialized NLP system for understanding and generating responses in the patent domain [58].Most of the input types of the models were text-based.While video and image inputs appear rarely, their inclusions signify a growing potential for multimodal integration.Figure 3 shows the frequency of each LLM architecture across the reviewed papers, with Hybrid/Retrieval-Augmented Models being the most prevalent, followed by Seq2Seq and decoder-only models.</p>
<p>RQ1: How Are LLMs Being Used to Construct KGs?</p>
<p>LLMs have transformed the construction of KGs by automating tasks such as entity recognition, relation extraction, schema design, and ontology development from unstructured or semi-structured data.This capability is particularly valuable in domains like healthcare, where LLMs are used to transform research papers, clinical records, and other textual sources into structured KGs.For example, GPT-4 and similar models have been employed to construct domain-specific KGs [8], such as VieMedKG for traditional Vietnamese medicine by extracting entities and relationships from textual data [13].New frameworks like Auto-KG Agent further automate semantic triple extraction for KG population, reducing reliance on manual curation [11].In healthcare, LLMs process research papers and clinical records to generate structured KGs that capture relationships between diseases, treatments, and symptoms [43,75].Similarly, KARGEN leverages domain-specific embeddings from radiology datasets to streamline medical KG creation and report generation [14].Beyond healthcare, LLMs extract cybersecurity KGs from threat intelligence data [86] and educational KGs from textbooks by integrating semantic relations [74].LLMs also excel in constructing multimodal KGs, which integrate textual, visual and symbolic data for applications like robotics and embodied AI.For instance, frameworks like Scene-MMKG and ManipMob-MMKG combine perceptual (visual) and symbolic data to build KGs that support fine-grained scene understanding, robotic navigation, and object manipulation [76].Recent surveys highlight LLM-driven multimodal KG construction, where models fuse text, images, and structured data for applications ranging from tourism recommendation systems [88] to socio-culturally adapted chatbots [44,61].These advancements highlight the versatility of LLMs in handling diverse data types and domains.A key strength of LLMs lies in their ability to support zero-shot and few-shot learning, enabling efficient KG construction with minimal labeled data.This is particularly useful in rapidly evolving domains like job-skills mapping [60] and cultural heritage [50,55,92].For example, few-shot prompting has been used to generate accurate SPARQL queries for populating scholarly KGs with bibliographic data [29] and, when coupled with Chain of Thought (CoT) reasoning, helps detect missing relationships in incomplete KGs [32], while zeroshot learning enables entity and relationship extraction in contexts where labeled data are scarce [36].Prompt engineering techniques further refine structured entity-relation extraction, allowing LLMs to generate high-quality triples without manual annotation [46].Challenges persist in SPARQL query generation for KG population, as seen in benchmarks like Spider4SPARQL [28], but advances in zero-shot ontology alignment improve crossdataset knowledge integration [87].LLMs also play a critical role in refining and updating existing KGs.They enable dynamic updates to ensure KGs remain relevant over time, particularly in fast-evolving fields like healthcare, finance, and law.Advanced techniques such as neural embeddings, prompt engineering, and RAG systems are employed to achieve high-precision and real-time knowledge extraction [23,42,93].For instance, zrLLM applies zero-shot learning to Temporal Knowledge Graphs (TKGs), predicting time-sensitive facts [30], while RAG systems build conference-specific KGs from event websites [59].TKGs leverage LLMs to embed evolving data, such as software development KGs that track hidden entities in GitHub repositories [56] and also to predict and represent timesensitive information, embedding temporal facts and relationships to build KGs that evolve alongside changing data [94].Hybrid approaches combining retrieval-based learning and structured pretraining further enhance dynamic KG updates [5,22].Additionally, LLMs facilitate entity normalization and synonym detection, which are crucial for resolving ambiguities in KG construction.Techniques like clustering LLM-generated embeddings help link semantically related entities within scientific KGs, ensuring that different surface forms of entities are correctly aggregated [41].In academic KGs, LLM-assisted graph reasoning improves ontology alignment and schema construction [95], while zero-shot prompting aligns ontology elements across datasets [87].This approach is particularly beneficial in academic KGs, where entity variants can hinder effective graph construction [38].By combining prompting mechanisms with relation extraction, LLMs enable scalable and automated KG construction across domains.Contextual prompts guide models to focus on domain-specific knowledge, as seen in frameworks that build financial and medical KGs using structured schema-based extractions [43,54].LLMs also act as graph encoders, enhancing node classification with textual embeddings [22], and integrate data from APIs and databases for education-focused KGs [69].These advancements significantly reduce the effort and expertise required for KG construction, accelerating the development of AI-driven applications.The reciprocal relationship between LLMs and KGs is discussed further in Section 5.</p>
<p>RQ2: How Are KGs Being Used to Improve the Output of LLMs?</p>
<p>When KGs are used as input into LLM applications, KGs act as a grounding mechanism for their responses in structured, verified information, reducing hallucinations and improving contextual accuracy.This is particularly critical in sensitive domains like medicine, where incorrect outputs can have significant consequences.For example, in medical question-answering systems, KGs allow the construction of domain-specific LLMs whose responses align with established knowledge [50,75].Legal KGs further ensure compliance in generated contracts by injecting structured metadata, improving fact-checking for legislative texts [21,62].Yang, in his paper, demonstrates how medical KGs improve the reliability and precision of LLM-generated responses by validating answers through entityrelation triples representing diseases, symptoms, and treatments [43].Similarly, KARGEN leverages domain-specific embeddings from radiology datasets to enhance medical report generation and decision-making [14].Cybersecurity KGs similarly reduce false positives in threat detection by grounding LLM outputs in structured threat intelligence [26].KGs also support multi-hop reasoning, enabling LLMs to derive insights from interconnected nodes.This capability is valuable in applications like recommendation systems, industrial management, and complex question-answering (QA) systems.For instance, Venkatakrishnan et al. and Wei et al. highlight how KGs enable LLMs to navigate through interconnected nodes, retrieving facts that span multiple relationships [19,23].The SG-RAG model integrates multi-hop reasoning KGs with LLMs to tackle complex QA tasks, outperforming traditional SQL-based approaches in structured data querying [12,83].Son et al., 2024, further describe Virtual Knowledge Graphs (VKGs) that encode facts and queries into dense vector spaces, allowing LLMs to efficiently retrieve relevant knowledge across multiple hops.This is particularly useful in databases and QA systems, where answers often require chaining multiple facts.KGs, being versatile, have several types that can be integrated with LLMs to not only improve their capabilities but also to enhance their performance: Cultural KGs: These KGs capture culturally and traditionally accurate regional languages, mitigating hallucinations in folklore-related LLM tasks.Traditional Folklore Knowledge Graphs (TFKGs), for instance, ensure that LLM outputs are based on verified facts [13,50].</p>
<p>3.</p>
<p>Industrial KGs: Used in wirearchy management and immigration law, industrial KGs model organizational hierarchies and legal processes, improving the accuracy of LLM outputs in these domains [19,50].Environmental sustainability KGs extend this by grounding ESG (Environmental, Social, Governance) queries in fact-based responses [47].</p>
<p>4.</p>
<p>Hybrid KGs: Combining multimodal data (textual, visual, audio, and numeric), hybrid KGs enhance LLM performance in domains like recommendation systems and robotics [23,42].For example, frameworks like ManipMob-MMKG integrate scene-driven multimodal KGs to jointly process visual and textual inputs, supporting tasks like object identification and environment navigation [76].In knowledge-based visual question answering (VQA), KGs improve multimodal reasoning by linking visual inputs to structured knowledge [85].</p>
<p>KGs also improve disambiguation and context resolution by linking ambiguous entities in LLM outputs to specific KG nodes.Techniques like synonym detection and clustering ensure semantic coherence, resolving multiple representations of the same entity.This is enhanced in multilingual contexts, where KGs optimize semantic communication to improve LLM comprehension of cross-lingual queries [89].Such methods are critical in academic and scientific contexts, where ambiguous terminology can lead to inconsistencies [38,41].RAG systems further enhance LLM output by integrating relevant KG subgraphs during inference.These subgraphs act as contextually rich knowledge sources, guiding LLMs to produce accurate responses [96].In scholarly applications, structured prompts derived from KGs significantly improve LLM responses to research questions, as demonstrated by [70] in their study [70].For instance, Taffa and Usbeck highlight in their paper how the Open Research Knowledge Graph (ORKG) provides bibliographic context for answering research-related questions, significantly improving output accuracy [29].Finally, contextual prompts derived from KGs enhance LLM reasoning by infusing domain-specific knowledge directly into LLMs during fine-tuning.This approach bypasses the need for comprehensive pre-training and is particularly useful for entities not covered by existing knowledge bases, such as niche products and emerging concepts [36].Semantic verification techniques grounded in KGs further mitigate hallucination risks by fact-checking LLMgenerated content [57,77].By combining these capabilities, KGs enable LLMs to perform complex reasoning tasks, reduce errors, and improve contextual understanding, making them indispensable for AI-driven applications.</p>
<p>RQ3: What AI Methodologies Are Used for LLM-Based KG Systems and KG-Based LLMs?</p>
<p>Understanding the AI methodologies that drive LLM-KG construction and interaction has become imperative.There are multiple AI methodologies being used in LLM based KGs construction which are classified into three categories, symbolic AI, machine learning and evolutionary computation.</p>
<p>1.</p>
<p>Symbolic AI-Symbolic AI is heavily implemented in LLM-based KG construction for the tasks requiring explicit rule-based reasoning and validation [55].See some examples below:</p>
<p>• SPARQL Query Generation: LLMs generate SPARQL queries to validate KGs against predefined ontologies, ensuring compliance with knowledge representation standards [19].Recent benchmarks like Spider4SPARQL is used to rigorously evaluate LLMs' ability to handle complex query structures, while the subgraph extraction algorithms refine SPARQL generation by isolating contextually relevant graph segments [35] [44].</p>
<p>In contrast to both symbolic AI and machine learning, evolutionary computation focuses on optimizing and dynamically updating KGs to accommodate new information and maintain relevance over time.</p>
<p>3.</p>
<p>Evolutionary Computation-The uncommon and less prevalent than machine learning and symbolic AI, evolutionary computation is being used occasionally to optimize tasks.For example,</p>
<p>• Dynamic KG Updates: Algorithms inspired by biological evolution optimize graph structures dynamically to accommodate new knowledge, ensuring relevance over time [23,97].</p>
<p>In recent years, hybrid approaches that combine symbolic and neural methodologies have also gained traction.Scene-Driven KGs integrate symbolic rules with perceptual data from vision-language models, enabling robots to interpret dynamic environments in real time, for example, spatial hierarchies [76].This is further strengthened by rule-based fact verification by Momii et al. to depict LLM-generated text that aligns with structured domain knowledge [39].Embedding-rule fusion frameworks combine logic-based constraints with LLM-generated embeddings, allowing KGs to adapt to ambiguous inputs while maintaining ontological consistency.For instance, medical diagnosis systems use symbolic disease taxonomies to ground neural symptom predictions, reducing hallucination risks [3].Temporal reasoning methodologies are essential for applications involving time-sensitive data.TKGs use temporal embeddings to represent dynamic relationships and enable LLMs to answer time-specific questions accurately [94].Similarly, VKGs facilitate multi-hop reasoning by embedding facts and queries into vectorized representations, improving retrieval performance across large-scale datasets [49].While the preceding section describes how symbolic AI, machine learning, and evolutionary computation support LLM-based KG systems, despite their discrete strengths, a distinct defiance emerges in practice when trying to ensure transparency and trust of both the constructed KGs and the LLMs that utilize these KGs.To address this challenge, XAI methods bridge the gap that connects symbolic AI, ML and evolutionary computation.XAI serves as a unifying framework that ensures transparency, interpretability and trust and addresses concerns related to fairness and error detection across diverse AI methodologies.These methods improve confidence in the generated knowledge by making the reasoning processes behind entity recognition and relationship extraction more interpretable and accessible.In symbolic AI methodologies, rule-based methods like DRaM provide explicit logic for inferring relationships [98], while SPARQL queries validate knowledge consistency [55,97].In machine learning, interpretable embeddings and fine-tuned prompt engineering improve the transparency of knowledge extraction and reasoning [42].This allows us to improve the interpretability of LLM outputs.A major issue with LLM is hallucination, which occurs when a Large Language Model starts to generate a response that is factually incorrect or illogical or has no relation to the input prompt.Explainability also aims to facilitate error analysis, enabling the identification and correction of hallucinations and inaccuracies commonly associated with LLMs, especially in the sensitive domains where inaccuracies can have serious consequences [19,75].XAI transcends individual methodologies to ensure transparency and accountability.Attention maps in models like KARGEN correlate LLM decisions with specific KG subgraphs, answering questions like "Why was this drug contraindicated?" in clinical settings [7,14].Multi-stage validation pipelines combine SPARQL-based ontological checks [37] with gradient-based attribution [99] to audit knowledge provenance.For instance, financial KGs cross-validate LLM-generated market predictions against historical transaction patterns.Moreover, XAI promotes better data governance by ensuring compliance with regulatory and ethical standards.Validation techniques such as SPARQL query generation allow the systematic verification of KG consistency against the predefined ontologies, allowing both transparency and reliability [19,55].These approaches also improve usability by making LLM-driven KG systems more accessible to non-technical users, permitting them to understand and utilize the outputs effectively.Overall, the integration of XAI in LLM-based KG construction bridges the gap between advanced AI technologies and user trust, enabling more robust, accurate, and ethical applications across various domains, which mitigates the algorithmic discrimination [4,100].In the reverse relationship, once constructed and validated using AI methodologies, KGs do not simply act as static knowledge repositories.Instead, they enhance LLMs' capabilities by serving as dynamic, structured inputs that refine the model's outputs by addressing limitations like hallucination and contextual ambiguity.This integration relies on several AI methodologies across retrieval-based techniques, neural architectures, and explainability frameworks.For instance, RAG dynamically retrieves relevant subgraphs from KGs [101] to ground LLM outputs in verified knowledge during inference, ensuring factual accuracy [3].Neural architectures, such as hybrid models like GRAPHCODE [102], incorporate KGs as external memory to guide text generation and reasoning tasks, enabling improved contextual consistency and domain-specific adaptation [15].Additionally, KGs are integrated into training pipelines, as seen in frameworks like ERNIE and KEPLER, which inject domain-specific facts into LLMs, improving reasoning accuracy and factual consistency [3].Validated KGs dynamically augment LLMs through RAG by retrieving contextually relevant KG subgraphs during inference to ground outputs, reducing factual errors by 37% in enterprise chatbots [101].Embedding injection architectures like ERNIE embed domain-specific KG triples into LLM training pipelines, improving rare entity recognition in scholarly datasets [3], and Iterative Refinement Loops such as GRAPHCODE's external memory module allow LLMs to query and update KGs mid-reasoning, enabling adaptive troubleshooting in IoT systems [15,102].Simultaneously, KG-enhanced LLMs reinforce transparency and trust using XAI methods.Finally, attention mechanisms are used to map LLM decisions to specific KG nodes, answering critical questions like "Why did the model prioritize this entity?"Meanwhile, rule-based validation ensures that KG-retrieved evidence aligns with LLM-generated outputs [103].For example, Khorashadizadeh et al. combine KG embeddings with gradient-based attribution to trace LLM predictions back to subgraph structures, improving transparency and interpretability and ensuring that outputs are well-grounded in the KG [99].This synergy not only mitigates hallucination but also fosters trust in applications like clinical diagnosis, where KG-anchored explanations justify model decisions to end users [103].By tightly coupling KGs with XAI, researchers achieve dual objectives: enhancing LLM reliability through structured knowledge while making the interplay between LLMs and KGs interpretable and accountable.These findings provide a foundation for understanding the interplay between LLMs and KGs, which we further analyze in the discussion below.</p>
<p>Discussion</p>
<p>The Reciprocal Relationship</p>
<p>In exploring the reciprocal interplay between LLMs and KGs, it is vital to acknowledge their two main modes of interaction: LLMs as tools to build KGs and KGs as inputs into LLM applications.While this topic is discussed in RQ1 and RQ2, this section extends the discussion by understanding the interdependencies, broader implications and implementation of advanced methodologies.Table 3 below helps us understand their duality concerning purpose, input and output.</p>
<p>Facets Knowledge Graph → LLM LLM → Knowledge Graph</p>
<p>Purpose</p>
<p>To enrich LLM's output accuracy and data governance, providing factual grounding and regulatory compliance.</p>
<p>To automate or augment KG construction, expanding or updating the KG.</p>
<p>Input Format</p>
<p>KGs as Input into LLMs</p>
<p>KGs act as structured and reliable inputs to strengthen the performance of LLMs.By preparing LLMs through semantic layers, we can ground their outputs by facts that are verifiable knowledge, KGs address challenges like hallucinations, data sparsity, and domain-specific inaccuracies.This is particularly beneficial in applications like RAG, where KGs supplement LLM prompts with relevant structured information to improve response quality and compliance with regulations.</p>
<p>Moreover, KGs are indispensable for data governance and access control.By ensuring that only authorized data are included in LLM workflows, KGs enable organizations to maintain regulatory compliance and prevent the misuse of sensitive information.For example, in industrial settings, KGs can filter out irrelevant or unauthorized data during LLM processing, thereby avoiding "context poisoning", where irrelevant data skew the generated outputs.Additionally, multi-hop reasoning facilitated by KGs allows LLMs to traverse interconnected nodes, uncovering deeper insights critical for complex applications like industrial knowledge management and personalized recommendation systems [42,55].</p>
<p>KG as input has applications in LLMs, such as in the medical question-answering systems, where KGs provide structured insights about diseases, treatments and clinical trials, ensuring that LLMs generate accurate and relevant responses [75,92].Cultural applications, such as traditional folklore KGs, allow LLMs to generate folklore-related answers by anchoring them to verified sources [50].Similarly, legal and industrial KGs enable LLMs to navigate complex relationships and retrieve pertinent data, such as in loan suggestion, immigration processes and recommendation systems [19,23].</p>
<p>LLMs to Build KGs</p>
<p>LLMs are instrumental in constructing KGs by automating entity recognition, relation extraction and schema creation, reducing the manual effort traditionally required in building KGs.In addition, LLMs also enable the rapid transformation of unstructured data (e.g., textual reports, academic papers) into structured knowledge.This capability is particularly evident in healthcare, where LLMs extract actionable insights from research papers to populate KGs with accurate medical information.</p>
<p>LLMs also dynamically update KGs, maintaining their continued relevance in fastevolving domains.Techniques such as prompt engineering, semantic parsing and neural embeddings further refine LLM-driven KG construction [37,42].This dynamic interaction is supported by advanced techniques such as vector-based embeddings, prompt-to-query retrieval, and fine-tuning LLMs with KG data.These methodologies not only enhance the precision and scalability of KG construction but also enable organizations to adapt their knowledge bases to emerging trends and challenges.For example, organizations employing hybrid RAG solutions combine LLM-powered vector searches with KG-based filters, achieving both speed and accuracy in data retrieval.This reciprocal relationship between LLMs and KGs accelerates innovation in applications that consist of complex question-answering systems like ChatGPT [1,50,55].</p>
<p>LLMs have various applications when building KGs, such as LLMs like GPT-4 and BERT, which are used to create domain-specific KGs, like the VieMedKG for traditional Vietnamese medicine, by identifying and linking entities and relationships in unstructured data [13,97].In the healthcare domain, LLMs extract insights from textual sources to populate KGs with accurate and comprehensive representations of diseases, treatments and biomarkers [55,75].In legal and industrial domains, LLMs transform fragmented data, such as paper-based immigration records into structured KGs, facilitating efficient data handling and retrieval [19,36].</p>
<p>Limitations</p>
<p>Despite their transformative potential, the integration of LLMs and KGs presents several challenges:</p>
<p>1.</p>
<p>Domain-Specific Challenges: LLMs often struggle with subtleties in specialized areas such as healthcare, finance and justice, leading to inaccuracies in entity recognition and relation extraction.This can compromise the quality of the resulting KGs and the outputs of LLM applications.</p>
<p>2.</p>
<p>Computational Intensity: The dynamic integration of KGs into LLM workflows demand significant computational resources, especially in real-time applications.This includes the cost of fine-tuning LLMs with domain-specific KG data or employing hybrid retrieval-augmented generation techniques.</p>
<p>3.</p>
<p>Explainability Concerns: While KGs enhance the interpretability of LLM outputs, the inherent opacity of LLMs' reasoning processes remains a barrier.Even with advancements in XAI, ensuring trust and validation in sensitive domains like healthcare and governance is challenging, and this poses the risk of algorithmic discrimination.</p>
<p>4.</p>
<p>Data Governance and Compliance: Ensuring data governance, regulatory compliance and access control during KG and LLM integration is complex, especially in highly regulated industries.Failure to manage this concern can lead to data misuse or ethical concerns.</p>
<p>Addressing these limitations requires a varied, complicated approach, including advances in domain-specific optimization, computational efficiency and XAI techniques.As the research progresses, the integration of KGs and LLMs is poised to unlock new possibilities in AI, bridging the gap between structured and unstructured data to deliver reliable and innovative solutions.</p>
<p>Gap Analysis</p>
<p>This section aims towards finding critical gaps in the integration of LLMs and KGs, systematically examining disparities across four analytical dimensions-the disciplinary focus, model architectures, application domains, and input modalities-and three research questions (RQ1-RQ3).Supported by a quantitative synthesis of 77 research studies, this analysis identifies underexplored opportunities and methodological limitations hindering the advancement of LLM-KG systems.</p>
<p>Research Question Gap Description</p>
<p>RQ1 (LLMs in KG Construction)</p>
<p>Static Construction Paradigms</p>
<p>Current focus is on static KGs, neglecting real-time dynamic updates.</p>
<p>Automation Deficits</p>
<p>Need to address automated schema generation or entity linking.</p>
<p>Sparse Multi-Hop Reasoning</p>
<p>Leveraging KGs for complex reasoning (e.g., causal inference).</p>
<p>RQ3 (Methodological Diversity) Ethical Oversights</p>
<p>Few studies address fairness, bias mitigation, or ethical governance.</p>
<p>Future Work and Strategic Recommendations</p>
<p>In light of the identified gaps, this section outlines future research directions and strategic recommendations to advance LLM-KG systems' development and practical application.We have formulated strategic recommendations to address the evolving challenges and opportunities in developing context-aware LLM and KG systems.Building on the findings of our study, we aim to strategically bridge disciplinary imbalances, incorporate diverse data sources, refine specialized architectures, enhance explainability mechanisms, integrate symbolic and machine learning approaches, and embed ethical governance throughout the pipeline.By following these guidelines, future work on LLM-based KG systems can achieve greater accuracy, transparency, and societal value while ensuring ethical and practical applicability across diverse domains.Table 5 below outlines these strategic recommendations; their focus areas, such as prioritizing cross-disciplinary research, advanced multimodal integration, optimized domain-specific architectures, embedded explainability mechanisms, hybrid methodologies and institutionalizing ethical practices; and how they align with identified research gaps in the field.</p>
<p>Focus Area Recommendation Alignment with Gaps</p>
<p>Cross-Disciplinary Research</p>
<p>Prioritize underrepresented domains (e.g., finance, cultural heritage).</p>
<p>Addresses disciplinary imbalance and interdisciplinary gaps.</p>
<p>Multimodal Integration</p>
<p>Develop frameworks for combining KGs with visual, auditory, or sensor data.</p>
<p>Mitigates text-centric and multimodal input gaps.</p>
<p>Domain-Specific Models</p>
<p>Fine-tune LLMs and build specialized KGs for healthcare, finance, etc.</p>
<p>Reduces reliance on general-purpose models.</p>
<p>Explainability</p>
<p>Embed XAI frameworks to map LLM outputs to KG nodes.</p>
<p>Resolves explainability and traceability deficits.</p>
<p>Hybrid Methodologies</p>
<p>Integrate symbolic AI with machine learning for dynamic KG construction.</p>
<p>Addresses automation and methodological silos.</p>
<p>Ethical Governance</p>
<p>Institutionalize fairness audits and bias mitigation in methodologies.</p>
<p>Mitigates ethical oversights in sensitive domains.</p>
<p>This systematic gap analysis, grounded in empirical data from 181 studies, elucidates critical barriers to progress in LLM-KG integration.By addressing disciplinary imbalances, methodological silos, and ethical lacunae, researchers can unlock transformative applications across scientific and societal domains.Future work must prioritize interdisciplinary collaboration, multimodal innovation, and ethical governance to realize the full potential of LLM-KG systems.</p>
<p>Conclusions</p>
<p>The interplay between LLMs and KGs represents a transformative synergy in AI.LLMs offer advanced capabilities for processing and interpreting unstructured data, enabling the automation of KG construction through entity recognition, relation extraction, schema generation and zero/few-shot learning methods.Conversely, KGs serve as robust, interpretable and structured inputs that improve LLM-based applications' factual consistency, reasoning ability and transparency, particularly in high-impact domains such as healthcare, finance, and law.</p>
<p>This study systematically reviewed 77 peer-reviewed publications to explore this reciprocal relationship, guided by three core research questions.First, we examined how LLMs contribute to KG development and found widespread use of automated techniques for knowledge extraction and schema design.Second, we analyzed how KGs enhance LLM performance by supporting multi-hop reasoning, reducing hallucinations, and enabling domain-specific adaptations.Third, we categorized the AI methodologies supporting these systems, observing a shift toward hybrid architectures that blend symbolic AI, machine learning, and neuro-symbolic models.XAI also enables trust, transparency, and traceability in LLM-KG workflows.</p>
<p>Despite these advances, limitations remain.Scalability challenges persist in maintaining dynamic, real-time KGs; domain adaptation remains difficult when applying generalpurpose LLMs to specialized fields; explainability remains an open challenge; and ethical considerations, including algorithmic discrimination, bias, fairness and governance, demand further attention.Many reviewed studies also showed limitations in methodological diversity and multimodal integration.</p>
<p>We identified these issues through a structured gap analysis and proposed strategic recommendations to guide future research.This includes the development of domainspecific, adaptable, and multimodal frameworks that align with the contemporary needs.To conclude, the synergy between LLMs and KGs offers a promising path toward building AI systems that are not only powerful and efficient but also transparent, reliable and ethically grounded.</p>
<p>•:</p>
<p>RQ1How are LLMs being used to construct KGs? • RQ2: How are KGs being used to improve the output of LLMs? • RQ3: What AI methodologies are used for LLM-based KG systems and KG-based LLMs?</p>
<p>Figure 1 .
1
Figure 1.Systematic review selection process.</p>
<p>Figure 2 .
2
Figure 2. Systematic review visualization.</p>
<p>Figure 3 .
3
Figure 3. Distribution by model implemented.</p>
<p>Table 1 .
1
Inclusion and exclusion criteria for paper selection.</p>
<p>Include Papers That Are Exclude Papers That Are
Published on blogs, forums, pages,IC-1 Written in EnglishEC-1or unofficial sites (e.g., not in con-ferences or journals)IC-2Published in an official conference or journal (peer-reviewed)EC-2Published in books or in ArXiv (not peer-reviewed in a conference or journal yet)IC-3Discusses KGs, LLMs, or Semantic graphs and explore their workingsEC-3Primarily focused on AI/ML (de-termined by reviewing the title, in-troduction, and conclusion)IC-4 Published between 2019-2024EC-4Mentions Knowledge Graphs but is not focused on them</p>
<p>Table 2 .
2
Models implemented in each study.</p>
<p>Table 2 .
2
Cont.</p>
<p>While symbolic AI excels at rule-based reasoning and formal validation, machine learning methodologies take a more data-driven approach towards automating the discovery and extraction of knowledge from large unstructured datasets.2. Customized prompts guide the LLM in extracting domainspecific entities and relationships.By fine-tuning LLMs with custom prompts, machine learning facilitates domain-specific knowledge extraction [42,92].Comparative studies by Schneider et al. demonstrate how prompt engineering aligns LLM outputs with KG structures, ensuring factual text generation [80].
Machine Learning (ML)-ML supports the most LLM based methodologies to pro-vide data driven approaches to extract and refine knowledge. See some examples be-low:•Neural Network Techniques: Embedding-based models and GNN architectureslike HybridGCN are used for link prediction and subgraph extraction fromtextual and relational data to build and refine KGs which further enables theautomated discovery of relationships in KGs [23,42,90]. HybridGCN furtherscales KG reasoning by integrating graph neural networks with LLMs [90], whileneural-symbolic frameworks like those by Liu et al. combine LLM embeddingswith structured query generation for multi-hop reasoning [67].•Semantic Parsing: LLMs transform unstructured text such as natural languageinto structured data helping the generation of triples, graphs and relationshipsthat populate KGs [13,55].•Prompt Engineering:
. • Logic-Based Inference: Frameworks like DRaM use symbolic reasoning to derive and validate relationships in KGs, improving interpretability and accuracy [97].• Ontology Matching: Algorithms align LLM-generated entities with predefined taxonomies, ensuring semantic consistency in domains like scholarly KGs [87].• Multi-Level Knowledge Generation: Techniques like few-shot KG completion fill missing relationships with minimal labeled data, they enable LLMs to generate triples and attributes for KG completion reducing reliance on labelled datasets, as demonstrated by Li et al. in generating hierarchical attributes for sparse KGs</p>
<p>Table 3 .
3
Reciprocal relationship between KGs and LLMs.</p>
<p>Most studies focus on static KG construction, with limited exploration of dynamic systems that update in real time.As knowledge is being created at such an immense rate and now recent advancements in computational AI are able to process big data real time, there are certain dataflow and workflows such as streaming data integration that could be explored to implement dynamic KGs
6.1.3. Applications•Bias Toward Language-Centric Tasks: Language modeling applications account for63.6% (49 papers) of the studies, whereas recommendation systems (7.8%, 6 papers)and question answering (1.29%, 1 paper) receive minimal attention.•Under deployment of Generative AI: Despite its versatility, ChatGPT is utilized inonly 5.2% of studies (four papers), indicating its untapped potential in real-worldapplications where such Gen AI could assist adaptive education or customer service.6.1.4. Input Modalities•Text-Centric Paradigms: All the studies rely exclusively on textual inputs, neglectingother methods such as image or video data.•Absence of Multimodal Integration: Fewer than 4% (three papers) of studies exploremultimodal systems combining KGs with images and videos as multimodal inputs.•Monolingual Limitations: No studies investigate multilingual KG-LLM systems,constraining their utility in linguistically diverse regions.6.2. Gaps Aligned with the Research Questions6.2.1. RQ1: LLMs in KG Construction•Static Construction Paradigms: with LLMs.6.1. Gaps Across Analytical Dimensions • Automation Deficits: Advanced techniques like automated schema generation or6.1.1. Domains granular entity linking are addressed in few papers.• 6.2.2. RQ2: KGs in Enhancing LLM Outputs Distribution of domains: A striking 76.6% (59 papers) of studies originate from the core domain of computer science, overshadowing other domains representing research•in the field of AI and machine learning. The rest had applications in education (15.6%, Explainability Challenges: While KGs mitigate LLM hallucinations, only a few studies12 papers), healthcare (5.19%, 4 papers), finance (1.29%, 1 paper) and justice (1.29%, formalize explainability frameworks to trace outputs to KG nodes.•1 paper). Domain-Specific KG Underutilization: Critical sectors like healthcare employ domain-•Lack of Interdisciplinary Synergy: Fewer than ten studies bridge insights from comple-specific KGs in only some of the cases, despite their potential for precision.•mentary domains, for instance, healthcare and education or environmental policy and Sparse Multi-Hop Reasoning: Very few of the studies exploit KGs' relational structureseconomics, limiting the cross-domain applicability of LLM-KG frameworks. Studies for complex reasoning tasks (e.g., causal inference).originating from domains such as finance and justice are underrepresented. This 6.2.3. RQ3: Methodological Diversity shows that the application of LLM-KG frameworks can be investigated and then • Isolated Methodological Approaches: Symbolic AI, machine learning, and evolution-implemented in various domains. ary computation are rarely integrated, stifling innovation in hybrid problem-solving.6.1.2. Model Implementation • Ethical Oversights: Methodologies addressing fairness, bias mitigation, or ethical•Predominance of Hybrid/Retrieval-Augmented Models: Hybrid/Retrieval-Augmented governance are critically absent, particularly in high-stakes domains like healthcare.Models (66.2%, 51 papers) dominate research, while specialized architectures like Bidirec-This is summarized in Table 4 below.tional Transformers or Symbolic-Neural Hybrids (2.6%, 2 papers each) are underutilized.•Scarce Decoder-based Autoregressive Transformer Adaptation: Only 6.4% (five papers)of studies employ fine-tuned LLMs (e.g., GPT variants) tailored to domain-specificchallenges in healthcare or finance.•Limited Hybrid Methodologies: Fewer than 5% of papers investigate synergies be-tween disparate architectures, for example, integrating neural networks with symbolicreasoning systems.</p>
<p>Table 4 .
4
Identified gaps aligned with research questions.</p>
<p>Table 4 .
4
Cont.
Research QuestionGapDescriptionRQ2 (KGs in Enhancing LLMs)Explainability ChallengesTraceability between LLM outputs and KG nodes.</p>
<p>Table 5 .
5
Strategic Recommendations.</p>
<p>Data Availability Statement:The data presented in this study are available on Figshare at https:// figshare.com/articles/dataset/Dataset_-_Reciprocal_Relationship_Of_KGs_And_LLMs/28468637/1?file= 52560449 (accessed on 1 March 2025) with the following DOI: https://doi.org/10.6084/m9.figshare.28468637.v1 (accessed on 1 March 2025).Conflicts of Interest:The authors declare no conflicts of interest.AbbreviationsThe following abbreviations are used in this manuscript:Appendix AThis table is included in the appendix as it provides supplementary details on the selected research and study screening, serving as additional reference material for readers interested in further specifics that support the main findings.-The title does not clearly focus on the integration of LLMs and Knowledge Graphs for the research aim.-While it mentions "Large Language Models" and "Knowledge Graphs," it seems more aligned with general AI/ML methods rather than the specific research questions outlined.No
C Qin, A Zhang, Z Zhang, J Chen, M Yasunaga, D Yang, arXiv:2302.06476Is ChatGPT a General-Purpose Natural Language Processing Task Solver? arXiv 2023. </p>
<p>M Danilevsky, K Qian, R Aharonov, Y Katsis, B Kawas, Sen, arXiv:2010.00711Survey of the State of Explainable AI for Natural Language Processing. 2020</p>
<p>J Z Pan, S Razniewski, J C Kalo, S Singhania, J Chen, S Dietze, H Jabeen, J Omeliyanenko, W Zhang, M Lissandrini, arXiv:2308.06374Large Language Models and Knowledge Graphs: Opportunities and Challenges. arXiv 2023. </p>
<p>Knowledge-graph-based explainable AI: A systematic review. E Rajabi, K Etminani, J. Inf. Sci. 502024</p>
<p>A survey on augmenting Knowledge Graphs (KGs) with large language models (LLMs): Models, evaluation metrics, benchmarks, and challenges. N Ibrahim, S Aboulela, A Ibrahim, R Kashef, 10.1007/s44163-024-00175-8Discov. Artif. Intell. 2024, 4, 76. [CrossRef</p>
<p>R Bommasani, D A Hudson, E Adeli, R Altman, S Arora, S V Arx, M S Bernstein, J Bohg, A Bosselut, E Brunskill, arXiv:2108.07258On the Opportunities and Risks of Foundation Models. 2022</p>
<p>Synergizing Knowledge Graphs with Large Language Models: A Comprehensive Review and Future Prospects. D Li, F Xu, arXiv:2407.184702024</p>
<p>LLMs for Knowledge Graph construction and reasoning: Recent capabilities and future opportunities. Y Zhu, X Wang, J Chen, S Qiao, Y Ou, Y Yao, S Deng, H Chen, N Zhang, 10.1007/s11280-024-01297-wWorld Wide Web 2024, 27, 58. [CrossRef</p>
<p>Language Models are Few-Shot Learners. T Brown, B Mann, N Ryder, M Subbiah, J D Kaplan, P Dhariwal, A Neelakantan, P Shyam, G Sastry, A Askell, Adv. Neural Inf. Process. Syst. 332020</p>
<p>Towards FAIR Explainable AI: A standardized ontology for mapping XAI solutions to use cases, explanations, and AI systems. A Adhikari, E Wenink, J Van Der Waa, C Bouter, I Tolios, S Raaijmakers, Proceedings of the 15th International Conference on PErvasive Technologies Related to Assistive Environments. the 15th International Conference on PErvasive Technologies Related to Assistive EnvironmentsNew York, NY, USA29 June-1 July 2022</p>
<p>Towards Harnessing Large Language Models as Autonomous Agents for Semantic Triple Extraction from Unstructured Text. A Ananya, S Tiwari, N Mihindukulasooriya, T Soru, Z Xu, D Moussallem, 2024. 1 March 2025</p>
<p>SG-RAG: Multi-Hop Question Answering with Large Language Models Through Knowledge Graphs. A O M Saleh, G Tur, Y Saygin, Proceedings of the 7th International Conference on Natural Language and Speech Processing (ICNLSP). the 7th International Conference on Natural Language and Speech Processing (ICNLSP)Trento, NJ, USA19-20 October 2024</p>
<p>VieMedKG: Knowledge Graph and Benchmark for Traditional Vietnamese Medicine. T Trinh, A Dao, H T H Nhung, H T Son, 2024</p>
<p>Y Li, Z Wang, Y Liu, L Wang, L Liu, L Zhou, Kargen, arXiv:2409.05370Knowledge-enhanced Automated Radiology Report Generation Using Large Language Models. 2024</p>
<p>A Survey of Large Language Models for Graphs. X Ren, J Tang, D Yin, N Chawla, C Huang, Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. the 30th ACM SIGKDD Conference on Knowledge Discovery and Data MiningBarcelona, SpainAugust 2024</p>
<p>Systematic Mapping Studies in Software Engineering. K Petersen, R Feldt, S Mujtaba, M Mattsson, 10.14236/ewic/EASE2008.82008BCS Learning &amp; DevelopmentNicosia, Cyprus</p>
<p>. R S Dehal, Dataset, -Reciprocal_Relationship_Of_KGs_And_LLMs. 2024. 1 March 2025</p>
<p>Are Large Language Models a Good Replacement of Taxonomies?. Y Sun, H Xin, K Sun, Y E Xu, X Yang, X L Dong, N Tang, L Chen, 10.14778/3681954.3681973Proc. VLDB Endow. VLDB Endow202417</p>
<p>Semantic interlinking of Immigration Data using LLMs for Knowledge Graph Construction. R Venkatakrishnan, E Tanyildizi, M A Canbaz, 10.1145/3589335.3651557Proceedings of the Companion Proceedings of the ACM Web Conference 2024. the Companion the ACM Web Conference 2024SingaporeMay 2024</p>
<p>RD-P: A Trustworthy Retrieval-Augmented Prompter with Knowledge Graphs for LLMs. Y Huang, G Zeng, 10.1145/3627673.3679659Proceedings of the 33rd ACM International Conference on Information and Knowledge Management. the 33rd ACM International Conference on Information and Knowledge ManagementNew York, NY, USA21-25 October 2024</p>
<p>Leveraging Knowledge Graphs and LLMs to Support and Monitor Legislative Systems. A Colombo, Proceedings of the 33rd ACM International Conference on Information and Knowledge Management. the 33rd ACM International Conference on Information and Knowledge ManagementBoise, ID, USA21-25 October 2024</p>
<p>Exploring the Potential of Large Language Models (LLMs)in Learning on Graphs. Z Chen, H Mao, H Li, W Jin, H Wen, X Wei, S Wang, D Yin, W Fan, H Liu, 10.1145/3655103.3655110ACM SIGKDD Explor. Newsl. 252024</p>
<p>LLMRec: Large Language Models with Graph Augmentation for Recommendation. W Wei, X Ren, J Tang, Q Wang, L Su, S Cheng, J Wang, D Yin, C Huang, 10.1145/3616855.3635853Proceedings of the 17th ACM International Conference on Web Search and Data Mining. the 17th ACM International Conference on Web Search and Data MiningMerida, MexicoMarch 2024</p>
<p>Generations of Knowledge Graphs: The Crazy Ideas and the Business Impact. X L Dong, Proc. VLDB Endow. VLDB Endow202316</p>
<p>Research on Intelligent Question-Answering Systems Based on Large Language Models and Knowledge Graphs. Q Wu, Y Wang, Proceedings of the 2023 16th International Symposium on Computational Intelligence and Design (ISCID). the 2023 16th International Symposium on Computational Intelligence and Design (ISCID)Hangzhou, ChinaDecember 2023</p>
<p>Actionable Cyber Threat Intelligence Using Knowledge Graphs and Large Language Models. R Fieblinger, M T Alam, N Rastogi, Proceedings of the 2024 IEEE European Symposium on Security and Privacy Workshops (EuroS&amp;PW). the 2024 IEEE European Symposium on Security and Privacy Workshops (EuroS&amp;PW)Vienna, Austria8-12 July 2024</p>
<p>Representing the Interaction between Users and Products via LLM-assisted Knowledge Graph Construction. J Vizcarra, S Haruta, M Kurokawa, Proceedings of the 2024 IEEE 18th International Conference on Semantic Computing (ICSC). the 2024 IEEE 18th International Conference on Semantic Computing (ICSC)Laguna Hills, CA, USAFebruary 2024</p>
<p>Spider4SPARQL: A Complex Benchmark for Evaluating Knowledge Graph Question Answering Systems. C Kosten, P Cudré-Mauroux, K Stockinger, 10.1109/BigData59044.2023.10386182Proceedings of the 2023 IEEE International Conference on Big Data (BigData). the 2023 IEEE International Conference on Big Data (BigData)Sorrento, Italy18 December 2023</p>
<p>T A Taffa, R Usbeck, arXiv:2311.09841Leveraging LLMs in Scholarly Knowledge Graph Question Answering. arXiv 2023. </p>
<p>Z Ding, H Cai, J Wu, Y Ma, R Liao, B Xiong, arXiv:2311.10112Tresp, V. zrLLM: Zero-Shot Relational Learning on Temporal Knowledge Graphs with Large Language Models. 2024</p>
<p>Information Extraction of Aviation Accident Causation Knowledge Graph: An LLM-Based Approach. L Chen, J Xu, T Wu, J Liu, 10.3390/electronics13193936202413</p>
<p>Framing Few-Shot Knowledge Graph Completion with Large Language Models. A M P Braşoveanu, L J B Nixon, A Weichselbraun, A Scharl, 2024133936</p>
<p>A Structure and Content Prompt-Based Method for Knowledge Graph Question Answering over Scholarly Data. L Jiang, X Yan, R Usbeck, 2023. 1 March 2025</p>
<p>EduEmbedd-A Knowledge Graph Embedding for Education. A Mohanty, 2023. 1 March 20253532</p>
<p>Improving Subgraph Extraction Algorithms for One-Shot SPARQL Query Generation with Large Language Models. D Pliukhin, D Radyush, L Kovriguina, D Mouromtsev, 2024. 1 March 2025</p>
<p>Infusing Knowledge into Large Language Models with Contextual Prompts. K Vasisht, B Ganesan, V Kumar, V Bhatnagar, Proceedings of the 20th International Conference on Natural Language Processing (ICON). the 20th International Conference on Natural Language Processing (ICON)Goa, IndiaDecember 2023</p>
<p>. J D Pawar, Devi Lalitha, 2023GoaGoa University; India</p>
<p>Scaling Scientific Knowledge Discovery with Neuro-Symbolic AI and Large Language Models. W J Schmidt, D Rincon-Yanez, E Kharlamov, A Paschke, 2024. 1 March 2025</p>
<p>Use Large Language Models for Named Entity Disambiguation in Academic Knowledge Graphs. S Liu, Y Fang, 2023Atlantis PressAmsterdam, The Netherlands</p>
<p>Rule-based Fact Verification Utilizing Knowledge Graphs. Y Momii, T Takiguchi, Y Ariki, 2023. 1 March 2025</p>
<p>Extracting Mathematical Concepts with Large Language Models. V De Paiva, Q Gao, P Kovalev, L S Moss, 2023. 1 March 2025</p>
<p>Probing Large Language Models for Scientific Synonyms. F Thießen, J D'souza, M Stocker, 2023. 1 March 2025</p>
<p>Large Language Model-Augmented Multi-Hop Question-Answering System Based on Knowledge Graph in Medical Field. F Wang, D Shi, J Aguilar, X Cui, J Jiang, L Shen, M Li, Llm-Kgmqa, 10.21203/rs.3.rs-4721418/v12024. 1 March 2025CrossRef</p>
<p>Integrated Application of LLM Model and Knowledge Graph in Medical Text Mining and Knowledge Extraction. J Yang, Soc. Med. Health Manag. 52024</p>
<p>LLM-based Multi-Level Knowledge Generation for Few-shot Knowledge Graph Completion. Q Li, Z Chen, C Ji, S Jiang, J Li, 10.24963/ijcai.2024/236Proceedings of the Thirty-ThirdInternational Joint Conference on Artificial Intelligence. the Thirty-ThirdInternational Joint Conference on Artificial IntelligenceJeju, Republic of KoreaAugust 2024</p>
<p>An LLM-Aided Enterprise Knowledge Graph (EKG) Engineering Process. E Laurenzi, A Mathys, A Martin, 10.1609/aaaiss.v3i1.31194Proc. AAAI Symp. Ser. 2024. AAAI Symp. Ser. 20243</p>
<p>Knowledge Graph Extraction from Textual Data Using LLM. K Gillani, E Novak, K Kenda, D Mladenić, 2024. 1 March 2025</p>
<p>Knowledge Graph Aided LLM Based ESG Question-Answering from News. T K Gupta, T Goel, I Verma, L Dey, S Bhardwaj, 2024. 1 March 2025</p>
<p>Prompting: Evaluating the Knowledge Graph Construction with LLMs. H Ghanem, C Cruz, 2024. 1 March 2025Fine-Tuning vs</p>
<p>Multi-hop Database Reasoning with Virtual Knowledge Graph. J Son, Y Seonwoo, S Yoon, J Thorne, A Oh, R Biswas, L A Kaffee, O Agarwal, P Minervini, S Singh, De Melo, 10.18653/v1/2024.kallm-1.1Proceedings of the 1st Workshop on Knowledge Graphs and Large Language Models. the 1st Workshop on Knowledge Graphs and Large Language ModelsBangkok, Thailand; Bangkok, ThailandAssociation for Computational LinguisticsKaLLM 2024. 15 August 2024. 2024</p>
<p>Application of LLM-Augmented Knowledge Graphs for Wirearchy Management. X Ventura De Los Ojos, 2024Barcelona, SpainUniversitat Oberta de Catalunya (UOC</p>
<p>Fine-Tuning Large Language Models for Domain Knowledge Graph Alignment via Neighborhood Partitioning and Generative Subgraph Encoding. S Dernbach, K Agarwal, A Zuniga, M Henry, S Choudhury, Glam, 10.1609/aaaiss.v3i1.31186Proc. AAAI Symp. Ser. 2024. AAAI Symp. Ser. 20243</p>
<p>Leveraging LLMs in Semantic Mapping for Knowledge Graph-Based Automated Enterprise Model Generation; Gesellschaft für Informatik e. B Reitemeyer, H G Fill, 10.18420/modellierung20242024Berlin, Germany</p>
<p>Knowledge Graph Builder-Constructing a Graph from Arbitrary Text Using an LLM. A B Kollegger, A Erdl, M Hunger, Proceedings of the 32nd International Symposium on Graph Drawing and Network Visualization (GD 2024). S Felsner, K Klein, the 32nd International Symposium on Graph Drawing and Network Visualization (GD 2024)Vienna, Austria; Germany18-20 September 2024. 2024320Schloss Dagstuhl-Leibniz-Zentrum für Informatik: Dagstuhl</p>
<p>Dynamic Knowledge Graph Asset Pricing. V X Li, Y Tan, 10.2139/ssrn.48419212024. 1 March 2025CrossRef</p>
<p>Validating Semantic Artifacts with Large Language Models. N Tufek, A Saissre, V P Just, F J Ekaputra, M Sabou, A Hanbury, 10.1007/978-3-031-78952-6_9European Semantic Web Conference. Nature; Cham, SwitzerlandSpringer2024</p>
<p>L Gan, M Blum, D Dessí, B Mathiak, R Schenkel, S Dietze, arXiv:2501.04455Hidden Entity Detection from GitHub Leveraging Large Language Models. 2024</p>
<p>Semantic Verification in Large Language Model-based Retrieval Augmented Generation. A Martin, H F Witschel, M Mandl, M Stockhecke, 10.1609/aaaiss.v3i1.31199Proc. AAAI Symp. Ser. 2024. AAAI Symp. Ser. 20243</p>
<p>Patent Response System Optimised for Faithfulness: Procedural Knowledge Embodiment with Knowledge Graph and Retrieval Augmented Generation. J M Chu, H C Lo, J Hsiang, C C Cho, S Li, M Li, M J Zhang, E Choi, M Geva, P Hase, H Ji, 10.18653/v1/2024.knowllm-1.12Proceedings of the 1st Workshop on Towards Knowledgeable Language Models. the 1st Workshop on Towards Knowledgeable Language ModelsBangkok, Thailand; Bangkok, ThailandAssociation for Computational LinguisticsKnowLLM 2024. 16 August 2024. 2024</p>
<p>Employing RAG to Create a Conference Knowledge Graph from Text. D Dobriy, 2024. 1 March 2025</p>
<p>A Dynamic Jobs-Skills Knowledge Graph. A Seif, S Toh, H K Lee, 2024. 1 March 2025</p>
<p>Socio-cultural adapted chatbots: Harnessing Knowledge Graphs and Large Language Models for enhanced context awarenes. J Camboim De Sá, D Anastasiou, M Da Silveira, C Pruski, Proceedings of the 1st Worskhop on Towards Ethical and Inclusive Conversational AI: Language Attitudes, Linguistic Diversity, and Language Rights (TEICAI 2024). the 1st Worskhop on Towards Ethical and Inclusive Conversational AI: Language Attitudes, Linguistic Diversity, and Language Rights (TEICAI 2024)St. Julian's, Malta22 March 2024</p>
<p>. N Hosseini-Kivanani, S Höhn, D Anastasiou, B Migge, A Soltan, D Dippold, E Kamlovskaya, F Philippy, 2024Malta</p>
<p>Extracting Licence Information from Web Resources with a Large Language Model. E Daga, J Carvalho, A Morales Tirado, 2024. 1 March 2025Heraklion, Greece</p>
<p>The State of the Art Large Language Models for Knowledge Graph Construction from Text: Techniques, Tools, and Challenges. D' Souza, J Mihindukulasooriya, N , 2024. 1 March 2025</p>
<p>LLMs for Knowledge-Graphs Enhanced Task-Oriented Dialogue Systems: Challenges and Opportunities. V I R Iga, G C Silaghi, Proceedings of the Advanced Information Systems Engineering Workshops. the Advanced Information Systems Engineering WorkshopsLimassol, CyprusJune 2024</p>
<p>. J P A Almeida, C Di Ciccio, C Kalloniatis, 10.1007/978-3-031-61003-5_152024SpringerCham, Switzerland</p>
<p>Breaking the Barrier: Utilizing Large Language Models for Industrial Recommendation Systems through an Inferential Knowledge Graph. Q Zhao, H Qian, Z Liu, G D Zhang, L Gu, 10.1145/3627673.3680022Proceedings of the 33rd ACM International Conference on Information and Knowledge Management. the 33rd ACM International Conference on Information and Knowledge ManagementBoise, ID, USAOctober 2024</p>
<p>Making Large Language Models Perform Better in Knowledge Graph Completion. Y Zhang, Z Chen, L Guo, Y Xu, W Zhang, H Chen, 10.1145/3664647.3681327Proceedings of the 32nd ACM International Conference on Multimedia. the 32nd ACM International Conference on MultimediaMelbourne, VIC, Australia28 October-1 November 2024</p>
<p>New Frontiers of Knowledge Graph Reasoning: Recent Advances and Future Trends. L Liu, Z Wang, J Bai, Y Song, H Tong, Proceedings of the Companion Proceedings of the ACM Web Conference 2024. the Companion the ACM Web Conference 2024SingaporeMay 2024</p>
<p>Zero-Shot Construction of Chinese Medical Knowledge Graph with GPT-3.5-turbo and GPT-4. L I Wu, Y Su, G Li, 10.1145/3657305ACM Trans. Manag. Inf. Syst. 1636573052024</p>
<p>Cross-Data Knowledge Graph Construction for LLM-enabled Educational Question-Answering System: A Case Study at HCMUT. T Bui, O Tran, P Nguyen, B Ho, L Nguyen, T Bui, T Quan, 10.1145/3643479.3662055Proceedings of the 1st ACM Workshop on AI-Powered Q&amp;A Systems for Multimedia. the 1st ACM Workshop on AI-Powered Q&amp;A Systems for MultimediaPhuket, Thailand14 June 2024</p>
<p>Research on Engineering Management Question-answering System in the Communication Industry Based on Large Language Models and Knowledge Graphs. Y Jiang, J Yao, F Li, Y Zhang, 10.1145/3653946.3653961Proceedings of the 2024 7th International Conference on Machine Vision and Applications. the 2024 7th International Conference on Machine Vision and ApplicationsSingaporeMarch 2024</p>
<p>GraphLingo: Domain Knowledge Exploration by Synchronizing Knowledge Graphs and Large Language Models. D Le, K Zhao, M Wang, Y Wu, Proceedings of the 2024 IEEE 40th International Conference on Data Engineering (ICDE). the 2024 IEEE 40th International Conference on Data Engineering (ICDE)Utrecht, The NetherlandsMay 2024</p>
<p>Unifying Large Language Models and Knowledge Graphs: A Roadmap. S Pan, L Luo, Y Wang, C Chen, J Wang, X Wu, IEEE Trans. Knowl. Data Eng. 362024</p>
<p>The Deep Integration of Knowledge Graphs and Large Language Models: Advancements, Challenges, and Future Directions. D Li, F Xu, 10.1109/ICSECE61636.2024.10729340Proceedings of the 2024 IEEE 2nd International Conference on Sensors, Electronics and Computer Engineering (ICSECE). the 2024 IEEE 2nd International Conference on Sensors, Electronics and Computer Engineering (ICSECE)Jinzhou, ChinaAugust 2024</p>
<p>Knowledge Graphs as Context Sources for LLM-Based Explanations of Learning Recommendations. H Abu-Rasheed, C Weber, M Fathi, Proceedings of the 2024 IEEE Global Engineering Education Conference (EDUCON). the 2024 IEEE Global Engineering Education Conference (EDUCON)Kos, Greece8-11 May 2024</p>
<p>ChatTf: A Knowledge Graph-Enhanced Intelligent Q&amp;A System for Mitigating Factuality Hallucinations in Traditional Folklore. J Xu, H Zhang, H Zhang, J Lu, G Xiao, IEEE Access. 122024</p>
<p>Scene-Driven Multimodal Knowledge Graph Construction for Embodied AI. Y Song, P Sun, H Liu, Z Li, W Song, Y Xiao, X Zhou, IEEE Trans. Knowl. Data Eng. 362024</p>
<p>Connecting AI: Merging Large Language Models and Knowledge Graph. M Jovanović, M Campbell, Computer. 562023</p>
<p>Towards Using Automatically Enhanced Knowledge Graphs to Aid Temporal Relation Extraction. T Knez, S Žitnik, Proceedings of the First Workshop on Patient-Oriented Language Processing (CL4Health) @ LREC-COLING 2024; Demner-Fushman. D Ananiadou, S Thompson, P Ondov, B , the First Workshop on Patient-Oriented Language Processing (CL4Health) @ LREC-COLING 2024; Demner-FushmanTorino, Italy2024ELRA and ICCL</p>
<p>Research on Large Language Model for Coal Mine Equipment Maintenance Based on Multi-Source Text. X Cao, W Xu, J Zhao, Y Duan, X Yang, 10.3390/app14072946Appl. Sci. 142024. 2946</p>
<p>A Comparative Analysis of Conversational Large Language Models in Knowledge-Based Text Generation. P Schneider, M Klettner, E Simperl, F Matthes, arXiv:2402.014952024</p>
<p>Enhancing Retrieval-Augmented Generation Models with Knowledge Graphs: Innovative Practices Through a Dual-Pathway Approach. S Xu, M Chen, S Chen, Proceedings of the Advanced Intelligent Computing Technology and Applications. the Advanced Intelligent Computing Technology and ApplicationsTianjin, ChinaAugust 2024</p>
<p>. D S Huang, Z Si, W Chen, 10.1007/978-981-97-5678-0_342024Singapore</p>
<p>Let's Chat to Find the APIs: Connecting Human, LLM and Knowledge Graph through AI Chain. Q Huang, Z Wan, Z Xing, C Wang, J Chen, X Xu, Q Lu, 10.1109/ASE56229.2023.00075Proceedings of the 2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE). the 2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)LuxembourgSeptember 2023</p>
<p>A Benchmark to Understand the Role of Knowledge Graphs on Large Language Model's Accuracy for Question Answering on Enterprise SQL Databases. J Sequeda, D Allemang, B Jacob, Proceedings of the 7th Joint Workshop on Graph Data Management Experiences &amp; Systems (GRADES) and Network Data Analytics (NDA). the 7th Joint Workshop on Graph Data Management Experiences &amp; Systems (GRADES) and Network Data Analytics (NDA)Santiago, Chile14 June 2024</p>
<p>SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model. L Fu, H Guan, K Du, J Lin, W Xia, W Zhang, R Tang, Y Wang, Y Yu, 10.1145/3627673.3679760Proceedings of the 33rd ACM International Conference on Information and Knowledge Management. the 33rd ACM International Conference on Information and Knowledge ManagementBoise, ID, USAOctober 2024</p>
<p>Prompting Large Language Models with Knowledge-Injection for Knowledge-Based Visual Question Answering. Z Hu, P Yang, F Liu, Y Meng, X Liu, Big Data Min. Anal. 72024</p>
<p>CyberQ: Generating Questions and Answers for Cybersecurity Education Using Knowledge Graph-Augmented LLMs. G Agrawal, K Pal, Y Deng, H Liu, Y C Chen, 10.1609/aaai.v38i21.30362Proc. AAAI Conf. AAAI Conf202438</p>
<p>Ontology Matching with Large Language Models. S Hertling, H Paulheim, Olala, 10.1145/3587259.3627571Proceedings of the 12th Knowledge Capture Conference 2023. the 12th Knowledge Capture Conference 2023Pensacola, FL, USADecember 2023</p>
<p>Optimizing Tourism Accommodation Offers by Integrating Language Models and Knowledge Graph Technologies. Information. A Cadeddu, A Chessa, V De Leo, G Fenu, E Motta, F Osborne, D Reforgiato Recupero, A Salatino, L Secchi, 2024398</p>
<p>Semantic Communication Enhanced by Knowledge Graph Representation Learning. N Hello, P Di Lorenzo, E C Strinati, Proceedings of the 2024 IEEE 25th International Workshop on Signal Processing Advances in Wireless Communications (SPAWC). the 2024 IEEE 25th International Workshop on Signal Processing Advances in Wireless Communications (SPAWC)Lucca, ItalySeptember 2024</p>
<p>An Integrative Model for Scalable Recommender Systems with Knowledge Graph and Graph Neural Networks. D A K Nguyen, S Kha, T V Le, Hybridgcn, Int. J. Adv. Comput. Sci. Appl. 13272024</p>
<p>Self-consistency, Extract and Rectify: Knowledge Graph Enhance Large Language Model for Electric Power Question Answering. J Zhao, Z Ma, H Zhao, X Zhang, Q Liu, C Zhang, Proceedings of the Advanced Intelligent Computing Technology and Applications. the Advanced Intelligent Computing Technology and ApplicationsTianjin, ChinaAugust 2024</p>
<p>. D S Huang, Y Pan, J Guo, 2024Singapore</p>
<p>Zero-Shot Construction of Chinese Medical Knowledge Graph with ChatGPT. L I Wu, G Li, Proceedings of the 2023 IEEE International Conference on Medical Artificial Intelligence (MedAI). the 2023 IEEE International Conference on Medical Artificial Intelligence (MedAI)Beijing, China18-19 November 2023</p>
<p>Graph Retrieval-Augmented Generation for Large Language Models: A Survey. T T Procko, O Ochoa, 10.1109/AIxSET62544.2024.00030Proceedings of the 2024 Conference on AI, Science, Engineering, and Technology (AIxSET). the 2024 Conference on AI, Science, Engineering, and Technology (AIxSET)Laguna Hills, CA, USA30 September-2 October 2024</p>
<p>Enhancing Exploratory Testing by Large Language Model and Knowledge Graph. Y Su, D Liao, Z Xing, Q Huang, M Xie, Q Lu, X Xu, 10.1145/3597503.3639157Proceedings of the IEEE/ACM 46th International Conference on Software Engineering. the IEEE/ACM 46th International Conference on Software EngineeringLisbon, Portugal14-20 April 2024</p>
<p>Large Language Models on Graphs: A Comprehensive Survey. B Jin, G Liu, C Han, M Jiang, H Ji, J Han, IEEE Trans. Knowl. Data Eng. 362024</p>
<p>GPT-4: A Stochastic Parrot or Ontological Craftsman? Discovering Implicit Knowledge Structures in Large Language Models. T T Procko, T Elvira, O Ochoa, 10.1109/TransAI60598.2023.00043Proceedings of the 2023 Fifth International Conference on Transdisciplinary AI (TransAI). the 2023 Fifth International Conference on Transdisciplinary AI (TransAI)Laguna Hills, CA, USASeptember 2023</p>
<p>The Application of Constructing Knowledge Graph of Oral Historical Archives Resources Based on LLM-RAG. Y Sun, W Yang, Y Liu, 10.1145/3686397.3686420Proceedings of the 2024 8th International Conference on Information System and Data Mining. the 2024 8th International Conference on Information System and Data MiningNew York, NY, USAJune 2024</p>
<p>Improving Adaptive Knowledge Graph Construction via Large Language Models with Multiple Views. Y Chen, S Cui, K Huang, S Wang, C Tang, T Liu, B Fang, H Wang, X Han, M Liu, G Cheng, Y Liu, 10.1007/978-981-99-7224-1_21In Proceedings of the Knowledge Graph and Semantic Computing: Knowledge Graph Empowers Artificial General Intelligence. Zhang, N.August 2023. 2023Singapore</p>
<p>Research Trends for the Interplay between Large Language Models and Knowledge Graphs. H Khorashadizadeh, F Z Amara, M Ezzabady, F Ieng, S Tiwari, N Mihindukulasooriya, J Groppe, S Sahri, F Benamara, S Groppe, arXiv:2406.082232024</p>
<p>Exposing Algorithmic Discrimination and Its Consequences in Modern Society: Insights from a Scoping Study. R S Dehal, M Sharma, R De Souza Santos, 10.1145/3639475.3640098Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Society. the 46th International Conference on Software Engineering: Software Engineering in SocietyNew York, NY, USA14-20 April 2024</p>
<p>B Peng, Y Zhu, Y Liu, X Bo, H Shi, C Hong, Y Zhang, S Tang, arXiv:2408.08921Graph Retrieval-Augmented Generation: A Survey. 2024</p>
<p>D Guo, S Ren, S Lu, Z Feng, D Tang, S Liu, L Zhou, N Duan, A Svyatkovskiy, S Fu, arXiv:2009.08366Pre-training Code Representations with Data Flow. arXiv 2021. </p>
<p>Enhanced Story Comprehension for Large Language Models through Dynamic Document-Based Knowledge Graphs. B R Andrus, Y Nasiri, S Cui, B Cullen, N Fulda, 10.1609/aaai.v36i10.21286Proc. Aaai Conf. Aaai Conf202236</p>
<p>Disclaimer/Publisher's Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods. instructions or products referred to in the content</p>            </div>
        </div>

    </div>
</body>
</html>