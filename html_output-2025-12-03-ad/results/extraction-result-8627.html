<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8627 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8627</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8627</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-155.html">extraction-schema-155</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models (LLMs) are used to generate or design novel chemicals for specific applications, including details of the models, methods, applications, results, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-266999179</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2401.06775v2.pdf" target="_blank">Large language models in healthcare and medical domain: A review</a></p>
                <p><strong>Paper Abstract:</strong> The deployment of large language models (LLMs) within the healthcare sector has sparked both enthusiasm and apprehension. These models exhibit the remarkable capability to provide proficient responses to free-text queries, demonstrating a nuanced understanding of professional medical knowledge. This comprehensive survey delves into the functionalities of existing LLMs designed for healthcare applications, elucidating the trajectory of their development, starting from traditional Pretrained Language Models (PLMs) to the present state of LLMs in healthcare sector. First, we explore the potential of LLMs to amplify the efficiency and effectiveness of diverse healthcare applications, particularly focusing on clinical language understanding tasks. These tasks encompass a wide spectrum, ranging from named entity recognition and relation extraction to natural language inference, multi-modal medical applications, document classification, and question-answering. Additionally, we conduct an extensive comparison of the most recent state-of-the-art LLMs in the healthcare domain, while also assessing the utilization of various open-source LLMs and highlighting their significance in healthcare applications. Furthermore, we present the essential performance metrics employed to evaluate LLMs in the biomedical domain, shedding light on their effectiveness and limitations. Finally, we summarize the prominent challenges and constraints faced by large language models in the healthcare sector, offering a holistic perspective on their potential benefits and shortcomings. This review provides a comprehensive exploration of the current landscape of LLMs in healthcare, addressing their role in transforming medical applications and the areas that warrant further research and development.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8627.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8627.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models (LLMs) are used to generate or design novel chemicals for specific applications, including details of the models, methods, applications, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Chemical language models (de novo)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chemical language models for de novo drug design</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Review-level mention of generative chemical language models applied to de novo drug design, summarizing that these models have shown notable achievements while facing specific challenges and opportunities in chemistry applications.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Chemical language models for de novo drug design: Challenges and opportunities</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>chemical language model / generative language model (transformer-based)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>drug discovery / de novo drug design</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>general generative chemical language modeling (de novo molecule generation from learned chemical sequence representations)</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_of_chemicals</strong></td>
                            <td>Not quantified in this review; described qualitatively as 'notable achievements' for de novo design but no percentages or similarity metrics are reported in the survey text.</td>
                        </tr>
                        <tr>
                            <td><strong>application_specificity</strong></td>
                            <td>Discussed at a conceptual level (models aim to generate drug-like molecules), but no concrete per-target tailoring details or protocols are given in this review excerpt.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Not specified here in detail; the review points to docking evaluations and standard benchmark metrics used in primary studies (see cited works).</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>This survey cites that chemical language models have shown success in de novo design tasks but emphasizes that challenges remain; the review does not present original experimental results.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>The review frames chemical language models as promising relative to earlier approaches but discusses challenges and opportunities rather than giving numerical head-to-head comparisons in this text.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_and_challenges</strong></td>
                            <td>Survey notes high-level challenges (evaluation, generalization, synthesizability and practical deployment) and frames several open problems; no specific failure-case data provided in the reviewed paragraphs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large language models in healthcare and medical domain: A review', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8627.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8627.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models (LLMs) are used to generate or design novel chemicals for specific applications, including details of the models, methods, applications, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Warm-started biochemical LM generation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Exploiting pretrained biochemical language models for targeted drug design</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Mention of a specific empirical study that uses pretrained biochemical language models to initialize molecule-generation models, comparing one-stage vs two-stage warm-start strategies and generation via beam search or sampling, evaluated by docking and benchmark metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Exploiting pretrained biochemical language models for targeted drug design</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>pretrained biochemical language model used to initialize molecule generation models (transformer-based biochemical LM)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>targeted drug design / molecule generation for docking-based evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>warm-start initialization of generative molecule models (one-stage and two-stage warm-start strategies); candidate generation using beam search or sampling</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_of_chemicals</strong></td>
                            <td>Reported qualitatively: warm-started models produce molecules that outperform baseline generative models on docking evaluation and benchmark metrics; exact novelty statistics (e.g., fraction outside training set or similarity scores) are not provided in the review text.</td>
                        </tr>
                        <tr>
                            <td><strong>application_specificity</strong></td>
                            <td>Evaluated for target-directed design via docking scores and benchmark metrics, indicating molecules were assessed for target-relevant properties rather than generic generation.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Docking evaluation and unspecified benchmark metrics (as reported by the review summarizing the primary study).</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Warm-started models outperform baseline models; the one-stage warm-start strategy shows superior generalization on docking evaluation and benchmark metrics; beam search is reported as more effective than sampling for assessing compound quality (no raw numbers provided in review).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Compared to baseline molecule-generation models (unnamed here), warm-started initializations perform better; within-generation methods, beam search produced higher-quality compounds than sampling according to docking/benchmark evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_and_challenges</strong></td>
                            <td>Review notes generalization trade-offs between one- and two-stage strategies and dependence on generation method (beam search vs sampling); the review does not report details on synthesizability, medicinal chemistry validation, or model sizes—those details must be obtained from the primary paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large language models in healthcare and medical domain: A review', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8627.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8627.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models (LLMs) are used to generate or design novel chemicals for specific applications, including details of the models, methods, applications, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>elEmBERT-V1 (Tox21)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>elEmBERT-V1 (chemical property / toxicity predictor)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Mention of a model (elEmBERT-V1) that achieved strong performance (AUC 0.961) on the Tox21 dataset for predicting chemical properties/toxicity, illustrating LLM-style models applied to chemical property prediction relevant to design decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>elEmBERT-V1</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>BERT-style transformer fine-tuned for chemical/property prediction</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Tox21 dataset (as evaluation target); training corpus not specified in the review text</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>chemical property prediction / toxicity prediction (drug safety)</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_of_chemicals</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>application_specificity</strong></td>
                            <td>Used to predict toxicity properties (thus supporting selection/filtering of candidate molecules rather than direct generation).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Area under ROC curve (AUC) — reported AUC = 0.961 on Tox21 in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Reported state-of-the-art predictive performance on Tox21 (AUC 0.961), indicating effectiveness at property prediction that can inform molecule design pipelines.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_and_challenges</strong></td>
                            <td>This model is predictive (not generative); the review does not provide details on how predictions were integrated into generative design workflows or on limitations such as domain shift or synthesizability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large language models in healthcare and medical domain: A review', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Exploiting pretrained biochemical language models for targeted drug design <em>(Rating: 2)</em></li>
                <li>Chemical language models for de novo drug design: Challenges and opportunities <em>(Rating: 2)</em></li>
                <li>Large language model for molecular chemistry <em>(Rating: 2)</em></li>
                <li>The drug-like molecule pre-training strategy for drug discovery <em>(Rating: 1)</em></li>
                <li>AI-based language models powering drug discovery and development <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8627",
    "paper_id": "paper-266999179",
    "extraction_schema_id": "extraction-schema-155",
    "extracted_data": [
        {
            "name_short": "Chemical language models (de novo)",
            "name_full": "Chemical language models for de novo drug design",
            "brief_description": "Review-level mention of generative chemical language models applied to de novo drug design, summarizing that these models have shown notable achievements while facing specific challenges and opportunities in chemistry applications.",
            "citation_title": "Chemical language models for de novo drug design: Challenges and opportunities",
            "mention_or_use": "mention",
            "model_name": null,
            "model_type": "chemical language model / generative language model (transformer-based)",
            "model_size": null,
            "training_data": null,
            "application_domain": "drug discovery / de novo drug design",
            "generation_method": "general generative chemical language modeling (de novo molecule generation from learned chemical sequence representations)",
            "novelty_of_chemicals": "Not quantified in this review; described qualitatively as 'notable achievements' for de novo design but no percentages or similarity metrics are reported in the survey text.",
            "application_specificity": "Discussed at a conceptual level (models aim to generate drug-like molecules), but no concrete per-target tailoring details or protocols are given in this review excerpt.",
            "evaluation_metrics": "Not specified here in detail; the review points to docking evaluations and standard benchmark metrics used in primary studies (see cited works).",
            "results_summary": "This survey cites that chemical language models have shown success in de novo design tasks but emphasizes that challenges remain; the review does not present original experimental results.",
            "comparison_to_other_methods": "The review frames chemical language models as promising relative to earlier approaches but discusses challenges and opportunities rather than giving numerical head-to-head comparisons in this text.",
            "limitations_and_challenges": "Survey notes high-level challenges (evaluation, generalization, synthesizability and practical deployment) and frames several open problems; no specific failure-case data provided in the reviewed paragraphs.",
            "uuid": "e8627.0",
            "source_info": {
                "paper_title": "Large language models in healthcare and medical domain: A review",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Warm-started biochemical LM generation",
            "name_full": "Exploiting pretrained biochemical language models for targeted drug design",
            "brief_description": "Mention of a specific empirical study that uses pretrained biochemical language models to initialize molecule-generation models, comparing one-stage vs two-stage warm-start strategies and generation via beam search or sampling, evaluated by docking and benchmark metrics.",
            "citation_title": "Exploiting pretrained biochemical language models for targeted drug design",
            "mention_or_use": "mention",
            "model_name": null,
            "model_type": "pretrained biochemical language model used to initialize molecule generation models (transformer-based biochemical LM)",
            "model_size": null,
            "training_data": null,
            "application_domain": "targeted drug design / molecule generation for docking-based evaluation",
            "generation_method": "warm-start initialization of generative molecule models (one-stage and two-stage warm-start strategies); candidate generation using beam search or sampling",
            "novelty_of_chemicals": "Reported qualitatively: warm-started models produce molecules that outperform baseline generative models on docking evaluation and benchmark metrics; exact novelty statistics (e.g., fraction outside training set or similarity scores) are not provided in the review text.",
            "application_specificity": "Evaluated for target-directed design via docking scores and benchmark metrics, indicating molecules were assessed for target-relevant properties rather than generic generation.",
            "evaluation_metrics": "Docking evaluation and unspecified benchmark metrics (as reported by the review summarizing the primary study).",
            "results_summary": "Warm-started models outperform baseline models; the one-stage warm-start strategy shows superior generalization on docking evaluation and benchmark metrics; beam search is reported as more effective than sampling for assessing compound quality (no raw numbers provided in review).",
            "comparison_to_other_methods": "Compared to baseline molecule-generation models (unnamed here), warm-started initializations perform better; within-generation methods, beam search produced higher-quality compounds than sampling according to docking/benchmark evaluation.",
            "limitations_and_challenges": "Review notes generalization trade-offs between one- and two-stage strategies and dependence on generation method (beam search vs sampling); the review does not report details on synthesizability, medicinal chemistry validation, or model sizes—those details must be obtained from the primary paper.",
            "uuid": "e8627.1",
            "source_info": {
                "paper_title": "Large language models in healthcare and medical domain: A review",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "elEmBERT-V1 (Tox21)",
            "name_full": "elEmBERT-V1 (chemical property / toxicity predictor)",
            "brief_description": "Mention of a model (elEmBERT-V1) that achieved strong performance (AUC 0.961) on the Tox21 dataset for predicting chemical properties/toxicity, illustrating LLM-style models applied to chemical property prediction relevant to design decisions.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "elEmBERT-V1",
            "model_type": "BERT-style transformer fine-tuned for chemical/property prediction",
            "model_size": null,
            "training_data": "Tox21 dataset (as evaluation target); training corpus not specified in the review text",
            "application_domain": "chemical property prediction / toxicity prediction (drug safety)",
            "generation_method": null,
            "novelty_of_chemicals": null,
            "application_specificity": "Used to predict toxicity properties (thus supporting selection/filtering of candidate molecules rather than direct generation).",
            "evaluation_metrics": "Area under ROC curve (AUC) — reported AUC = 0.961 on Tox21 in the review.",
            "results_summary": "Reported state-of-the-art predictive performance on Tox21 (AUC 0.961), indicating effectiveness at property prediction that can inform molecule design pipelines.",
            "comparison_to_other_methods": null,
            "limitations_and_challenges": "This model is predictive (not generative); the review does not provide details on how predictions were integrated into generative design workflows or on limitations such as domain shift or synthesizability.",
            "uuid": "e8627.2",
            "source_info": {
                "paper_title": "Large language models in healthcare and medical domain: A review",
                "publication_date_yy_mm": "2023-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Exploiting pretrained biochemical language models for targeted drug design",
            "rating": 2,
            "sanitized_title": "exploiting_pretrained_biochemical_language_models_for_targeted_drug_design"
        },
        {
            "paper_title": "Chemical language models for de novo drug design: Challenges and opportunities",
            "rating": 2,
            "sanitized_title": "chemical_language_models_for_de_novo_drug_design_challenges_and_opportunities"
        },
        {
            "paper_title": "Large language model for molecular chemistry",
            "rating": 2,
            "sanitized_title": "large_language_model_for_molecular_chemistry"
        },
        {
            "paper_title": "The drug-like molecule pre-training strategy for drug discovery",
            "rating": 1,
            "sanitized_title": "the_druglike_molecule_pretraining_strategy_for_drug_discovery"
        },
        {
            "paper_title": "AI-based language models powering drug discovery and development",
            "rating": 1,
            "sanitized_title": "aibased_language_models_powering_drug_discovery_and_development"
        }
    ],
    "cost": 0.01241425,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>LARGE LANGUAGE MODELS IN HEALTHCARE AND MEDICAL DOMAIN: A REVIEW
8 Jul 2024</p>
<p>Zabir Al Nazi 
University of California
Riverside RiversideCA</p>
<p>Wei Peng wepeng@stanford.edu 
Stanford University
Palo AltoCA</p>
<p>LARGE LANGUAGE MODELS IN HEALTHCARE AND MEDICAL DOMAIN: A REVIEW
8 Jul 202406675461266215C956556D8868FBEBEDarXiv:2401.06775v2[cs.CL]
The deployment of large language models (LLMs) within the healthcare sector has sparked both enthusiasm and apprehension.These models exhibit the remarkable capability to provide proficient responses to free-text queries, demonstrating a nuanced understanding of professional medical knowledge.This comprehensive survey delves into the functionalities of existing LLMs designed for healthcare applications, elucidating the trajectory of their development, starting from traditional Pretrained Language Models (PLMs) to the present state of LLMs in healthcare sector.First, we explore the potential of LLMs to amplify the efficiency and effectiveness of diverse healthcare applications, particularly focusing on clinical language understanding tasks.These tasks encompass a wide spectrum, ranging from named entity recognition and relation extraction to natural language inference, multi-modal medical applications, document classification, and question-answering.Additionally, we conduct an extensive comparison of the most recent state-of-the-art LLMs in the healthcare domain, while also assessing the utilization of various open-source LLMs and highlighting their significance in healthcare applications.Furthermore, we present the essential performance metrics employed to evaluate LLMs in the biomedical domain, shedding light on their effectiveness and limitations.Finally, we summarize the prominent challenges and constraints faced by large language models in the healthcare sector, offering a holistic perspective on their potential benefits and shortcomings.This review provides a comprehensive exploration of the current landscape of LLMs in healthcare, addressing their role in transforming medical applications and the areas that warrant further research and development.</p>
<p>Introduction</p>
<p>Deep Learning provides an intelligent way to understand human behaviors, emotions and human healthcare [1,2,3,4].Recent developments in clinical language understanding have ushered in the potential for a paradigm shift in the healthcare sector.These advancements hold the promise of ushering in a new era characterized by the deployment of intelligent systems designed to bolster decision-making, expedite diagnostic processes, and elevate the quality of patient care.In essence, these systems have the capacity to serve as indispensable aids to healthcare professionals as they grapple with the ever-expanding body of medical knowledge, decipher intricate patient records, and formulate highly tailored treatment plans.This transformative potential has ignited considerable enthusiasm within the healthcare community [5,6,7].</p>
<p>The immense value of lage language models (LLMs) lies in their ability to process and synthesize colossal volumes of medical literature, patient records, and the ever-expanding body of clinical research.Healthcare data [8,9] is inherently complex, heterogeneous, and often overwhelming in scale.LLMs act as a powerful force multiplier, aiding healthcare professionals struggling with information overload.By automating the analysis of medical texts, extracting crucial insights, and applying that knowledge, LLMs are poised to drive groundbreaking research and enhance patient care, significantly improving and contributing to the progression of the healthcare and medical domain.</p>
<p>• Section 2 provides a foundational understanding of LLMs, covering their key architectures such as Transformers, foundational models, and multi-modal capabilities.• In section 3, the focus shifts to the application of LLMs in healthcare, discussing their use cases and the metrics for assessing their performance within clinical settings.• Section 4 critically examines the challenges associated with LLMs in healthcare, including issues related to explainability, security, bias, and ethical considerations.• The paper concludes by summarizing the findings, highlighting the transformative potential of LLMs while acknowledging the need for careful implementation to navigate their limitations and ethical implications.</p>
<p>Review of Large Language Models</p>
<p>Large language models have emerged as a notable advancement in the field of natural language processing (NLP) and have attracted considerable interest in recent times [16,10].These models exhibit notable attributes such as their considerable number of parameters, pre-training on vast collections of textual data, and fine-tuning for specific downstream objectives [17,18,13].By leveraging these key characteristics, large language models demonstrate exceptional performance across a wide range of NLP tasks.This section presents a comprehensive discussion of the concept, architecture, and pioneering examples of large language models.Furthermore, we explore the pre-training methodology and the significance of transfer learning in facilitating these models to achieve exceptional performance across diverse tasks [19].</p>
<p>Large Language models, built upon the Transformer architecture, have been specifically engineered to enhance the efficiency of natural language data processing in comparison to earlier iterations.The Transformer architecture, as proposed by [20], utilizes a self-attention mechanism to capture the contextual relationships between words in a sentence.</p>
<p>This mechanism facilitates the model's ability to assign varying degrees of significance to distinct words during the prediction process, rendering it especially suitable for handling long-range dependencies in language.</p>
<p>The key aspects of large language models encompass their substantial magnitude [21,22], pre-training on vast text corpora [23,13], and subsequent fine-tuning tailored towards specific tasks [24].These models possess a substantial number of parameters, ranging from hundreds of millions to billions, which allows them to effectively capture intricate patterns and nuances within language.Pre-training is commonly conducted on diverse datasets devoid of task-specific annotations, enabling the model to acquire knowledge from a broad spectrum of linguistic instances and develop a comprehensive grasp of language.Following pre-training, the model undergoes a further fine-tuning process using smaller datasets that are appropriate to the task at hand.This allows the model to successfully adapt to and perform well on specific natural language processing (NLP) tasks.</p>
<p>The progression of natural language processing (NLP) has been characterized by a series of significant advancements.At the outset, recurrent neural networks (RNNs) facilitated the retention of context in natural language processing (NLP) tasks.Nevertheless, recurrent neural networks (RNNs) were found to have several shortcomings when it comes to effectively capturing long-range dependencies.The advent of Transformers has had a transformative impact by effectively addressing the challenge of capturing distant word relationships.Subsequently, large language models like Llama 2 [13], GPT-4 [11] emerged, powered by extensive training data, significantly advancing NLP capabilities in understanding and generating human-like text.This progression signifies a continuous cycle of innovation, with each stage building upon the strengths and limitations of its predecessor.In the subsequent section, we delineate significant phases of development within the continuum of progress in the landscape of natural language processing (NLP).</p>
<p>In the domain of healthcare, specialized adaptations of BERT, namely BioBERT [14] and ClinicalBERT [15], were introduced to address a variety of challenges in comprehending clinical language.GPT-3 (Generative Pre-trained Transformer 3), developed by OpenAI, is one of the largest language models to date, with 175 billion parameters [10].</p>
<p>Recently, OpenAI introduced the GPT-3.5 and its successor, GPT-4 (OpenAI, 2023) [11], alongside Google AI's Bard, both of which have emerged as cutting-edge Large Language Models (LLMs), displaying remarkable capabilities across diverse applications, including healthcare and medicine [6].</p>
<p>Transformers</p>
<p>The Transformers architecture, introduced in "Attention is All You Need," [20] has revolutionized natural language processing.The primary novelty of this model is its utilization of the self-attention mechanism, which allows for the assessment of the importance of input tokens by considering their relevance to the given task.In this setup, multiple attention heads work in parallel, allowing the model to focus on various aspects of the input whereas positional encoding conveys relative token positions.Given an input sequence X of length N , the self-attention mechanism [25,26,27] computes attention scores A(i, j) between all token pairs (i, j).Three learned matrices, Query (Q), Key (K), and Value (V ), are obtained by linear projections of X.
Attention(Q, K, V ) = sof tmax( QK T √ d k )V
Here, d k represents the dimension of key vectors.The softmax function normalizes scores.The output for each token is then computed as a weighted sum of value vectors for all tokens j.Multi-Head Attention extends this mechanism by computing multiple attention sets in parallel, concatenated and linearly transformed to form the final output.</p>
<p>Transformers consist of stacked encoder-decoder blocks, adapting to diverse tasks.The training occurs via unsupervised or semi-supervised learning on vast text corpora, using gradient-based optimization.Transformers have become foundational in natural language processing due to their capacity to handle sequential data, capture long-range dependencies, and adapt to various tasks with minimal fine-tuning.They extend beyond text, finding applications in healthcare, recommendation systems, image generation, and other domains.</p>
<p>Large Foundational Models</p>
<p>The advent of Large Foundational Models, exemplified by GPT-3 (Brown et al., 2020) [10] and Stable Diffusion (Rombach et al., 2022) [28], ushers in a transformative era in the field of machine learning and generative artificial intelligence.Researchers have introduced the term "foundation model" to delineate machine learning models that undergo training on extensive, diverse, and unlabeled datasets, endowing them with the ability to adeptly tackle a broad spectrum of general tasks.These encompass tasks related to language comprehension, text and image generation, and natural language dialogue.Large foundational models are massive AI architectures trained on extensive quantities of unlabeled data, predominantly employing self-supervised learning methods.This approach to training yields models of exceptional versatility, enabling them to excel across a wide spectrum of tasks, ranging from image classification and natural language processing to question-answering, consistently delivering outstanding levels of accuracy.</p>
<p>These models particularly shine in tasks demanding generative capabilities and human interaction, including the creation of marketing content or intricate artwork based on minimal prompts.Nevertheless, adapting and integrating these models into enterprise applications may present specific challenges [29].</p>
<p>Multi-modal Language Models</p>
<p>A Multi-Modal Large Language Model (MLLM) represents a groundbreaking advancement in the fields of artificial intelligence (AI) and natural language processing (NLP).In contrast to conventional language models focused solely on textual data, MLLMs possess the unique ability to process and generate content across multiple modalities, including text, images, audio, and video.This novel approach significantly expands the capabilities of AI applications, allowing machines not only to comprehend and generate text but also to interpret and integrate information from various sensory inputs.The integration of multiple modalities enables MLLMs to bridge the gap between human communication and machine understanding, making them versatile tools with the potential to transform diverse fields.This theoretical introduction highlights the transformative potential of MLLMs and their central role in pushing the boundaries of artificial intelligence, affecting areas such as image and speech recognition, content generation, and interactive AI applications [30].</p>
<p>Multi-modal large language models (MLLMs) are designed to process and integrate information from multiple data sources, such as text, images, and audio, to perform a variety of tasks.These models leverage deep learning techniques to understand and generate content across different modalities, enhancing their applicability in real-world scenarios.For instance, Visual ChatGPT combines text and visual inputs to address complex queries [31], while systems like BLIP-2 utilize a Qformer to integrate visual features with textual data for enhanced image-text interactions [32].MLLMs are particularly effective in tasks like visual question answering (VQA), where they can interpret and respond to queries based on visual content.The integration of modalities allows these models to offer more comprehensive responses and handle a broader range of interactions than single-modality models.The iterative training processes, often involving stages of freezing certain components while fine-tuning others, enable these models to maintain robust language capabilities while adapting to new modalities and tasks.Recently, the integration of the Mixture of Experts (MoE) architecture into multi-modal large language models (MLLMs) has significantly advanced their capabilities.This approach employs multiple specialized sub-models, each fine-tuned for specific types of data or tasks such as image recognition or language processing.By selectively activating the most relevant experts based on the input and task, MoE allows MLLMs to dynamically adapt to the demands of multimodal data integration.This enhances the precision of the model in handling complex multimodal interactions and optimizes computational resources.Models like MoVA [33] and MoE-LLaVA [34] leverage MoE strategies effectively, improving performance while maintaining manageable computational costs during both training and inference phases.</p>
<p>The adaptability and efficiency of MoE within MLLMs thus contribute significantly to their scalability and efficacy in real-world applications across varied tasks and data types [35].</p>
<p>3 Large Language Models in Healthcare and Medical Domain</p>
<p>Language models have become a revolutionary force in the constantly changing world of healthcare and medicine, revolutionising how medical researchers and practitioners engage with data, patients, and huge corpus of medical knowledge [36].The use of language models in the medical field has undergone a significant metamorphosis, from the early days of simple rule-based systems, feature extraction, and keyword matching to the arrival of cutting-edge technologies like Transformers, and Large Language Models (LLMs) such as GPT-v4 [11].These language models have overcome the constraints of conventional methods, enabling more complex natural language generation and interpretation.</p>
<p>Several pioneering large language models have significantly influenced the landscape of NLP.The emergence of the Transformer architecture [20] marked a significant milestone in the realm of natural language processing, leading to the emergence of expansive pre-trained language models like the BERT [37] and RoBERTa [38].In this section, we will first talk about the current large language models specifically for medical applications, in section 3.1.Then, in section 3.2 we will talk about the use cases of various LLMs that designed mainly for patients, experts, and medical materials.2017 Named entity recognition Wuhan University code</p>
<p>BERT (Bidirectional Encoder</p>
<p>Large Language Models for Medical and Healthcare Applications</p>
<p>Figure 1 provides a comprehensive overview of the progression in biomedical language model (LM) development from 2019 to 2023, emphasizing a logarithmic growth in model complexity and parameter count.It describes the evolutionary trajectories of various domain-specific adaptations of prominent models such as BioBERT, and GPT-2, along with the inception of more advanced systems like MedPaLM.The sizes of the illustrated models are proportional to their parameter volumes, showcasing a consistent trend towards larger, more capable models.This is culminated in the emergence of Large Language Models (LLMs) by 2023, which signifies a pivotal shift towards architectures with substantially heightened computational requirements and potential performance in biomedical text analysis and generation tasks.</p>
<p>On the other hand, table 1 provides an insightful overview of leading large language models within the healthcare domain.</p>
<p>Recently, "BioMistral" was published as a a collection of open-source pre-trained large language models for medical domains.In 2023, "Med-PaLM 2" and "Radiology-Llama2" emerged as key players, addressing medical question answering and radiology tasks, respectively.The "DeID-GPT" model extends its capabilities to de-identification, while "Med-HALT" specializes in hallucination testing.Simultaneously, "ChatCAD" offers valuable support in the realm of computer-aided diagnosis."BioGPT" showcases versatility by handling classification, relation extraction, and question answering."GatorTron" excels in semantic textual similarity and medical question answering, whereas "BioMedLM" narrows its focus to biomedical question answering."BioBART" demonstrates prowess in dialogue, summarization, entity linking, and NER."ClinicalT5" tackles classification and NER, while "KeBioLM" specializes in biomedical pre-training, NER, and relation extraction.Before the advent of language models or transformers, convolutional and recurrent neural networks represented the state of the art in the field.These models collectively represent remarkable strides in healthcare NLP, providing accessible source code or models for further exploration and practical application.In recent years, the emergence of large language models has catalyzed a transformative shift in the healthcare landscape, offering unprecedented opportunities for innovation and advancement.The capability of comprehending and generating text that resembles that of humans has demonstrated remarkable potential across a wide range of healthcare applications [52].The applications of large language models in the healthcare sector are experiencing rapid growth.These models are being utilized for clinical decision support, medical record analysis, patient engagement, health information dissemination, etc.Their implementation holds the prospect to improve diagnostic accuracy, streamline administrative procedures, and ultimately enhance the efficiency, personalization, and comprehensiveness of healthcare delivery.This section delves into a comprehensive exploration of the multifaceted applications of large language models in healthcare, shedding light on their profound implications these applications bear on the trajectory of medical practices and the eventual outcomes experienced by patients.</p>
<p>• Medical Diagnosis: Certain clinical procedures may depend on the use of data analysis, clinical research, and recommendations [53,54].LLMs may potentially contribute to medical diagnosis by conducting analyses on patient symptoms, medical records, and pertinent data, potentially aiding in the identification of potential illnesses or conditions with a certain degree of accuracy.Large language models have the potential to contribute to several aspects such as clinical decision assistance, clinical trial recruiting, clinical data administration, research support, patient education, and other related areas [55,56].Corroborating this perspective, authors introduce a methodology that utilizes transformer models, namely BERT, RoBERTa, and DistilBERT, for the purpose of predicting COVID-19 diagnosis based on textual descriptions of acute alterations in chemosensation [57].Similarly, a number of alternative investigations have been undertaken within the literature, proposing strategies using large language models for the diagnosis of Alzheimer's disease [58] and dementia [59].Furthermore, a corpus of literature has emerged, advocating the integration of large language model chatbots to cater to analogous objective [60,61,62,63].</p>
<p>• Patient Care: Large Language Models have emerged as transformative tools with the capacity to significantly enhance the realm of patient care [64].Through the provision of personalised recommendations [65], customised treatment strategies, and continual monitoring of patients' advancements throughout their medical journeys [66], LLMs offer the promise of revolutionizing healthcare delivery.By harnessing the capabilities of LLMs, healthcare providers can ensure a more personalized and patient-centric approach to care.This technology enables the delivery of precise and well-informed medical guidance [67], aligning interventions with patients' distinct requirements and circumstances.The effective use of LLMs within clinical practise not only enhances patient outcomes but also enables healthcare professionals to make data-driven decisions, leading to enhanced patient care.As LLMs continue to advance, the potential for augmenting patient care through personalized recommendations and ongoing monitoring remains a promising trajectory in modern medicine [68].In essence, LLMs represent a pivotal leap forward, holding the capacity to reshape the landscape of patient care by fostering precision, adaptability, and patient-centeredness [69].</p>
<p>• Clinical Decision Support: Language models (LMs) have evolved into crucial decision support tools for healthcare professionals.By analyzing extensive medical data, LMs can provide evidence-based recommendations, enhancing diagnostic accuracy, treatment selection, and overall patient care.This fusion of artificial intelligence with healthcare expertise holds immense promise for improved medical decision-making.A body of existing research has illuminated promising prospects for the application of language models within clinical decision support, particularly within the domains of radiology [70], oncology [71] and dermatology [72].</p>
<p>• Medical Literature Analysis: Large language models (LLMs) exhibit remarkable efficiency in comprehensively reviewing and succinctly summarizing extensive volumes of medical literature.This capability aids both researchers and clinicians in maintaining topicality with cutting-edge developments and evidence-based methodologies, ultimately fostering informed and optimized healthcare practices.In a fast-evolving field like healthcare, the ability to maintain currency with the latest advancements is paramount, and LLMs can play a pivotal role in ensuring that healthcare remains at the forefront of innovation and evidence-based care delivery [73,74].</p>
<p>• Drug Discovery: Large Language Models, have a significant impact in facilitating drug discovery through their capacity to scrutinize intricate molecular structures, discern promising compounds with therapeutic potential, and forecast the efficacy and safety profiles of these candidates [75,76].Chemical language models have exhibited notable achievements in the domain of de novo drug design [77].In this corresponding study, authors explore the utilization of pre-trained biochemical language models to initialize targeted molecule generation models, comparing one-stage and two-stage warm start strategies, as well as evaluating compound generation using beam search and sampling, ultimately demonstrating that warm-started models outperform baseline models and the one-stage strategy exhibits superior generalization in terms of docking evaluation and benchmark metrics, while beam search proves more effective than sampling for assessing compound quality [78].</p>
<p>• Virtual Medical Assistants and Health Chatbots: LLMs may also serve as the underlying intelligence for health chatbots, revolutionizing the healthcare landscape by delivering continuous and personalized healthrelated support.These chatbots can offer medical advice, monitor health conditions, and even extend their services to encompass mental health support, a particularly pertinent aspect of healthcare given the growing awareness of mental well-being [63,60].</p>
<p>• Radiology and Imaging: Multi-modal visual-language models, through their integration of visual and textual data, hold significant promise for augmenting medical imaging analysis.Radiologists can benefit from these models as they facilitate the early identification of abnormalities in medical images and contribute to the generation of more precise and comprehensive diagnostic interpretations, ultimately advancing the accuracy and efficiency of diagnostic processes in the field of medical imaging [79,70,80,81,82,83,84].</p>
<p>• Automated Medical Report Synthesis from Imaging Data: Automated medical report generation from images is crucial for streamlining the time-consuming and error-prone task faced by pathologists and radiologists.This emerging field at the intersection of healthcare and artificial intelligence (AI) aims to alleviate the burden on experienced medical practitioners and enhance the accuracy of less-experienced ones.The integration of AI with medical imaging facilitates the automatic drafting of reports, encompassing abnormal findings, relevant normal observations, and patient history.Early efforts employed data-driven neural networks, combining convolutional and recurrent models for single-sentence reports, but limitations arose in capturing the complexity of real medical scenarios [5].Recent advances leverage large language models (LLMs) such as ChatCAD [70], enabling more sophisticated applications.ChatCAD enhances medical-image Computer-Aided Diagnosis networks, yielding significant improvements in report generation.ChatCAD+ further addresses writing style mismatches, ensuring universality and reliability across diverse medical domains, incorporating a template retrieval system for consistency with human expertise [44].In [85], authors use pre-trained language model (PLM) and in-context learning (ICL) to generate clinical note from doctor patient conversation.These integrated systems signify a pivotal advancement in automating medical report generation through the strategic utilization of LLMs.2019 Predicting hospital readmission Attention weights Visualisation</p>
<p>Explainable AI Methods for Interpreting Healthcare LLMs</p>
<p>Large Language Models (LLMs) have significantly advanced the healthcare domain, enhancing tasks such as medical diagnosis and patient monitoring.However, the complexity of these models necessitates interpretability for reliable decision-making [86].This section discusses "eXplainable and Interpretable Artificial Intelligence" (XIAI) and examines recent XIAI methods by their functionality and scope.Despite challenges, such as the difficulty in quantifying interpretability and the lack of standardized evaluation metrics, opportunities exist in integrating XIAI to add interpretability for LLMs in healthcare.Notable XIAI methods include SHAP [87], which quantifies feature contributions, LIME [88,89], which generates interpretable models through input perturbations, t-SNE for visualizing high-dimensional data [90], attention mechanisms that highlight key features [15], and knowledge graphs that structure contextual relationships [91], all of which provide crucial insights into model decision-making processes.</p>
<p>Existing research delves into explainability for LLMs in the healthcare domain.We have compiled a list in table 2, detailing XIAI attributes, summarizing recent research works focused on explainability methods for LLMs in the healthcare domain.This table includes evaluations of various models, highlighting their unique contributions to enhancing interpretability and reliability in medical applications.Each entry outlines the task, method, XAI attributes, and evaluation metrics, offering a clear overview of the advancements and effectiveness of XIAI techniques in improving decision-making processes in healthcare.</p>
<p>Future Trajectories of Large Language Models in Healthcare</p>
<p>As large language models (LLMs) continue to integrate into the healthcare sector, future developments promise to revolutionize patient care and medical research.A particularly promising avenue involves enhancing LLMs' capabilities to interpret and generate not only textual but also biomolecular data [101].This advancement could significantly improve applications in genomics and personalized medicine, enabling these models to predict individual responses to treatments based on genetic profiles, thereby advancing the precision of medical interventions.Furthermore, incorporating adaptive learning capabilities in real-time could transform LLMs into dynamic aids during surgical procedures or emergencies, where they might analyze data from medical devices on-the-fly [102] to offer critical decision support.</p>
<p>Another innovative trajectory for LLMs in healthcare is the development of federated learning systems [103].Such systems could facilitate the secure, privacy-preserving propagation of medical knowledge across institutions, improving model robustness and applicability across varied demographic groups without direct data sharing.This approach will not only enhance the privacy and security of patient data but will also enable a collective intelligence that could lead to more generalized healthcare solutions.</p>
<p>The potential of large language models (LLMs) in healthcare extends into the realms of explainable medical AI [104] and the utilization of multi-modal models incorporating sensor data.By integrating LLMs with wearable technologies [105], these advanced models can serve as continuous health monitors in non-clinical settings.</p>
<p>To further advance explainable medical AI, LLMs can be instrumental in deciphering the complexities of medical conditions and treatment outcomes.By processing and interpreting multi-modal data, including sensor readings, these models can contribute to a deeper understanding of patient health on a granular level.This may aid in the development of precise, targeted therapies, improving patient outcomes and enhancing the transparency of medical decisions.</p>
<p>Large Language Models (LLMs) are poised to revolutionize the healthcare domain by enhancing diagnostic accuracy, personalizing treatment plans, and optimizing operational efficiencies.By integrating LLMs into electronic health record systems, healthcare providers can more accurately diagnose conditions through natural language processing techniques that analyze clinical notes and patient histories.Moreover, LLMs assist in generating personalized treatment recommendations by analyzing vast datasets that include genetic information, clinical outcomes, and patient preferences.Furthermore, these models streamline administrative tasks by automating documentation, coding, and billing processes, thus reducing operational costs and allowing medical staff to focus more on patient care.As generative AI advances, its transformative impact on the healthcare sector is becoming increasingly significant.This technology is poised to revolutionize areas such as clinical trials, personalized medicine, and drug discovery.Additionally, its applications extend to enhancing natural language processing and understanding, improving medical imaging, and supporting virtual assistants in patient care.Generative AI also plays a crucial role in illness detection and screening, facilitating more accurate diagnostics.Moreover, it is being integrated into medical conversation tasks, voice generation, video generation, and image synthesis and manipulation within healthcare settings [106].These innovations are not only improving the efficiency of medical services but are also paving the way for new methods of patient interaction and treatment planning.As these applications continue to mature, LLMs will become integral in transforming healthcare services into more efficient, accurate, and personalized systems.</p>
<p>Performance Evaluation and Benchmarks</p>
<p>The medicine and healthcare industries largely acknowledge the potential of artificial intelligence (AI) to drive substantial progress in the delivery of healthcare.However, empirical evaluations have demonstrated that numerous artificial intelligence (AI) systems do not successfully achieve their desired translation goals, primarily because of intrinsic deficiencies that become evident only after implementation [107,108].In order to optimize the utilization of language models (LLMs) within healthcare settings, it is imperative to develop evaluation frameworks that possess the capacity to thoroughly evaluate their safety and quality.It is important to note that certain highly effective models, such as ChatGPT and PaLM 2 [109], are now not publicly available.The absence of accessibility gives rise to notable problems pertaining to transparency, which is a crucial factor in the medical domain and hinders the capacity to thoroughly examine the structure and results of the model.Consequently, this impedes endeavors to recognize and address biases and hallucinations.Thorough research is necessary to understand the specific performance characteristics and ramifications of utilizing publicly accessible, pre-trained language models in addressing the challenges in the healthcare and medical domains.Language models that have been pre-trained using medical data also encounter comparable difficulties.Therefore, the careful choice and implementation of suitable performance metrics to evaluate the language model assume great significance.</p>
<p>In table 4, we present a comprehensive catalog of performance metrics, including but not limited to the F1 score, BLEU, GLUE, and ROGUE, which constitute the standard evaluative criteria employed for the rigorous assessment of large language models operating within the healthcare and medical domain.This compendium of metrics serves as a  valuable reference, encapsulating the quantitative and qualitative measures utilized to gauge the efficacy, proficiency, and suitability of these models in diverse healthcare applications [108].</p>
<p>Quantitative Performance Comparison of LLMs in Healthcare Domain</p>
<p>Recent advancements in language models have been benchmarked against diverse datasets to evaluate their capabilities across various domains.One such comprehensive benchmark is the MMLU (Massive Multitask Language Understanding) [110], designed to assess the understanding and problem-solving abilities of language models.The MMLU comprises 57 tasks spanning topics such as elementary mathematics, US history, computer science, and law, requiring models to demonstrate a broad knowledge base and problem-solving skills.This benchmark provides a standardized method to test and compare various language models, including OpenAI GPT-4o, Mistral 7b, Google Gemini, and Anthropic Claude 3, among others.</p>
<p>The HumanEval benchmark is used to measure the functional correctness of code generated by LLMs from docstrings.This benchmark evaluates models based on their ability to generate code that passes provided unit tests, using the pass@k metric.If any of the 'k' solutions generated by the model pass all unit tests, the model is considered successful in solving the problem [111].Table 3 provides a concise summary of the performance of various LLMs on the MMLU and HumanEval (Coding) datasets [112].</p>
<p>In the healthcare domain, a variety of LLMs have been developed and evaluated on specific datasets such as MedQA, MedNLI [113], Tox21 [114], and PubMedQA [115].The GPT-4 (2024) model stands out in the MedQA dataset with an impressive accuracy of 93.06%, significantly outperforming other models like Med-PaLM 2 (CoT + SC) (2023), which achieves 83.7%, and Meerkat-7B (Ensemble) (2024), with 74.3%.In the MedNLI dataset, BioELECTRA-Base (2021) achieves the highest accuracy of 86.34%, closely followed by CharacterBERT (base, medical) (2020) at 84.95%.The Tox21 dataset highlights elEmBERT-V1 (2023) with an outstanding AUC of 0.961, making it the most effective in predicting chemical properties and toxicity.For the PubMedQA dataset, Meditron-70B (CoT + SC) (2023) and BioGPT-Large (1.5B) (2023) exhibit strong performance with accuracies of 81.6% and 81.0%, respectively [116].These findings underscore the variability in performance across different healthcare tasks, emphasizing the need for careful selection of models based on specific application requirements [117].Figure 4 presents a comparative performance analysis of various healthcare LLMs, highlighting their accuracy and AUC metrics across different datasets including MedQA, MedNLI, Tox21, and PubMedQA.</p>
<p>Limitations and Open Challenges</p>
<p>The integration of large language models (LLMs) in healthcare presents complex challenges, including the need for explainability in model decision-making, robust security and privacy measures to protect sensitive patient data, addressing biases and ensuring fairness in medical AI applications, mitigating the issue of hallucinations where models generate erroneous information, and establishing clear legal frameworks for the responsible use of LLMs in healthcare, all of which demand careful scrutiny and resolution to harness the full potential of these models for improving healthcare outcomes while upholding ethical and legal standards.</p>
<p>Model Explainability and Transparency</p>
<p>Large language models face notable challenges when applied to healthcare.Their recommendations often lack transparency due to their opaque nature, which can hinder acceptance among healthcare professionals who prioritize explainability in medical decision-making.Moreover, the presence of biases in the training data may compromise the accuracy of these models, potentially leading to incorrect diagnoses or treatment recommendations.It is therefore crucial for medical professionals to exercise caution and thoroughly review and validate the recommendations provided by large language models before integrating them into their clinical decision-making processes [127].In healthcare, the importance of interpretability and explainability for AI models utilized in medical imaging analysis and clinical risk prediction cannot be overstated.Inadequate transparency and explainability have the potential to undermine trustworthiness and hinder the validation of clinical recommendations.Consequently, effective governance underscores the continuous pursuit of transparency and interpretable frameworks, aiming to augment the decision-making process in the realm of healthcare [108].Large language models (LLMs) often function as "blackboxes", rendering it challenging to discern the underlying processes leading to specific conclusions or suggestions.In the healthcare context, where the repercussions of decisions are profound, it becomes imperative for practitioners to grasp the logic behind AI-generated outputs.The persistent endeavor to create models that are more interpretable and transparent remains an enduring challenge within the healthcare domain [128,129,130].</p>
<p>Security and Privacy Considerations</p>
<p>Large Language Models (LLMs) are used in medical research, which necessitates careful consideration of data privacy and security issues.Researchers are entrusted with the duty of managing extremely private patient data while enforcing rigorous compliance with current privacy laws.The use of LLMs in this setting raises concerns about a number of aspects of data processing, including as data protection, the possibility of re-identification, and the moral application of patient data.One notable issue is the inadvertent inclusion of personally identifiable information (PII) within pre-training datasets, which can compromise patient confidentiality.Additionally, LLMs can make privacy-invading inferences by deducing sensitive personal attributes from seemingly innocuous data, potentially violating individual privacy [131].Implementing strong measures like data anonymization, safe data storage procedures, and steadfast adherence to ethical standards are essential to addressing these issues.Together, these steps make up crucial safeguards meant to protect research participants' trust, maintain the integrity of research processes, and protect patient privacy.The importance of these factors is underscored by the necessity of balancing the significant contributions of LLMs [118] - [119] The federated learning model achieved a best perplexity value of 3.41 for English.</p>
<p>[120] The Transformer model achieved a test perplexity of 15.6 on the PSVG dataset, significantly outperforming the LSTM's perplexity of 20.7.</p>
<p>[91]</p>
<p>The lowest perplexity achieved was 3.86e-13 with manually designed prompts.</p>
<p>BLEU</p>
<p>The BLEU score assesses the quality of machine translation by comparing it to reference translations.</p>
<p>[121]</p>
<p>The best BLEU-1 score achieved was 13.9 by the ClinicalGPT model.</p>
<p>GLEU</p>
<p>GLEU score computes mean scores of various n-grams to assess text generation quality.</p>
<p>[121] The best GLEU score achieved was 2.2 by the Bloom-7B model.</p>
<p>[122] T-5 (fine-tuned) model achieved the best GLEU score of 11.38.</p>
<p>ROUGE</p>
<p>ROUGE score evaluates summarization and translation by measuring overlap with reference summaries.</p>
<p>[121] The best ROGUE-L score achieved was 21.3 by the Clini-calGPT model.</p>
<p>[122] T-5 (fine-tuned) model achieved the best ROGUE-L score of 24.85.</p>
<p>Distinct n-grams</p>
<p>Measures the diversity of generated responses by counting unique n-grams.</p>
<p>[122] On the Huatuo-26M dataset, the fine-tuned T5 model achieved Distinct-1 and Distinct-2 scores of 0.51 and 0.68, respectively.</p>
<p>F1 Score</p>
<p>The F1 score balances precision and recall, measuring a model's accuracy in identifying positive instances and minimizing false results.[123] The GatorTron-large model achieved the best F1 score of 0.9627 for medical relation extraction.</p>
<p>[46]</p>
<p>The GatorTron-large model achieved the best F1 score of 0.9000 for clinical concept extraction and 0.9627 for medical relation extraction.</p>
<p>[124] The multicenter Transformersbased model achieved an overall F1 score of 84.77% on the PsyNIT dataset.</p>
<p>[76]</p>
<p>The BERT-D2 model achieved an F1 score of 81.97% on the DDI Extraction 2013 corpus.</p>
<p>BERTScore</p>
<p>BERTScore calculates similarity scores between tokens in candidate and reference sentences, using contextual embeddings.</p>
<p>[125] -</p>
<p>[85] The Longformer-Encoder-Decoder (LEDlarge-PubMed) model achieved the best BERTScore F1 of 70.7.</p>
<p>Human Evaluation</p>
<p>Involves expert human assessors rating the quality of model-generated content, providing qualitative insights into its performance.</p>
<p>[126] The median performance for all human SCORE users was 65%, whereas ChatGPT correctly answered 71% of multiple-choice SCORE questions and 68% of Data-B questions.</p>
<p>Bias and Fairness</p>
<p>Researching ways to tackle and reduce biases in language models, while also comprehending their ethical ramifications, represents a pivotal research domain.It is imperative to create techniques for identifying, alleviating, and forestalling biases in large language models.A primary concern associated with Large Language Models (LLMs) pertains to the risk of producing misinformation or biased outputs.These models, drawing from extensive text data, encompass both dependable and unreliable sources, which can inadvertently result in the generation of inaccurate or misleading information.Furthermore, if the training data incorporates biases, such as gender or racial biases prevalent within scientific literature, LLMs can perpetuate and magnify these biases in their generated content.</p>
<p>To ensure the reliability and accuracy of information derived from LLMs, researchers must exercise caution and implement rigorous validation and verification processes.LLMs have the potential to amplify pre-existing biases inherent in their training data, particularly those linked to demographics, disease prevalence, or treatment outcomes.Consequently, the generated outputs may inadvertently reflect and perpetuate these biases, posing considerable challenges in achieving equitable and unbiased healthcare outcomes.</p>
<p>To address these challenges, researchers must remain vigilant in recognizing and mitigating biases within both the training data and the outputs generated by LLMs.This diligence is crucial for promoting fairness and inclusivity within the realm of biomedical research and healthcare applications, ultimately enhancing the ethical and equitable utility of LLMs in these domains [132].Prioritizing bias mitigation in LLMs is essential.Researchers should curate and preprocess training data diligently to reduce inherent biases and address sources of inequality.Routine audits and evaluations are necessary to identify and correct biases in model training and deployment.Collaborative efforts between domain experts, ethicists, and data scientists can establish guidelines and best practices for unbiased LLM development, fostering fairness and inclusivity in biomedical research and healthcare.</p>
<p>Hallucinations and Fabricated Information</p>
<p>Language models exhibit a proclivity for generating erroneous content, commonly referred to as hallucinations.This phenomenon is characterized by the production of text that appears plausible but lacks factual accuracy.This inherent trait poses a substantial risk when such generated content is employed for critical purposes, such as furnishing medical guidance or contributing to clinical decision-making processes.The consequences of relying on hallucinatory information in healthcare contexts can be profoundly detrimental, potentially leading to harmful or even catastrophic outcomes [133].</p>
<p>The gravity of this issue is exacerbated by the continuous advancement of Large Language Models (LLMs), which continually enhance their capacity to generate increasingly persuasive and believable hallucinations.Moreover, LLMs are often critiqued for their opacity, as they provide no discernible link to the original source of information, thereby creating a formidable barrier to the verification of the content they produce.To mitigate these risks, healthcare professionals must exercise extreme caution when utilizing LLMs to inform their decision-making processes, rigorously validating the accuracy and reliability of the generated information.</p>
<p>Current research endeavors are dedicated to addressing hallucination issues within Large Language Models (LLMs) in the healthcare and medical domain.The introduction of Med-HALT, a novel benchmark dataset, serves the purpose of evaluating hallucination phenomena in LLMs in medical contexts.Med-HALT encompasses two distinct test categories: reasoning-based and memory-based hallucination assessments.These tests have been meticulously designed to gauge the problem-solving and information retrieval capabilities of LLMs when operating within the medical domain [43].</p>
<p>Legal and Ethical Reasons</p>
<p>Ethical concerns extend to the generation of potentially harmful content by LLMs, especially when delivering distressing medical diagnoses without providing adequate emotional support.Moreover, the blurring line between LLM-generated and human-written text poses a risk of misinformation dissemination, plagiarism, and impersonation.</p>
<p>To address these challenges, rigorous auditing and evaluation of LLMs are essential, along with the development of regulations for their medical use.Thoughtful selection of training datasets, particularly within the medical domain, is crucial to ensure the responsible handling of sensitive data.These measures collectively strive to strike a balance between harnessing LLMs' potential and safeguarding patient privacy and ethical standards [131].</p>
<p>The European Union's AI Act and the United States' Health Insurance Portability and Accountability Act (HIPAA) are two significant regulatory frameworks impacting the deployment of AI in healthcare.The AI Act introduces comprehensive regulations, including the Artificial Intelligence Liability Directive (AILD), which addresses liability for AI-related damages.This directive ensures that victims are compensated and that preventive measures are cost-effective.</p>
<p>The AI Act classifies General Purpose AI (GPAI) models and imposes specific obligations on providers, including technical documentation, risk assessments, and transparency about training data [134].</p>
<p>In the United States, HIPAA sets stringent standards for the protection of patient data, impacting how LLMs handle sensitive information.Compliance with HIPAA requires robust data encryption, regular security assessments, and strict access controls to protect patient information.These regulations ensure that LLMs used in healthcare settings adhere to high standards of privacy and security, mitigating risks associated with data breaches and unauthorized access.</p>
<p>Other relevant laws and compliance frameworks include the General Data Protection Regulation (GDPR) in the EU, which emphasizes data protection and privacy, and the Medical Device Regulation (MDR) that ensures the safety and efficacy of AI-driven medical devices.These regulations collectively impact the deployment of generative AI in healthcare by ensuring legal accountability, protecting patient data, and promoting ethical standards in AI development and application.</p>
<p>The implementation of regulatory frameworks such as the EU's AI Act, HIPAA, GDPR, and MDR significantly impacts the deployment of LLMs and generative AI in healthcare by ensuring transparency, data protection, and patient safety.These regulations necessitate detailed documentation of AI models, advanced data encryption, strict access controls, and rigorous clinical testing, thereby increasing development costs and timelines.However, they also promote reliability, legal accountability, and ethical standards in AI development, fostering trust among users and stakeholders and encouraging the responsible and wider adoption of AI technologies in healthcare [135].</p>
<p>Conclusion</p>
<p>In conclusion, the integration of large language models (LLMs) in healthcare showcases immense potential for enhancing clinical language understanding and medical applications.These models offer versatility and sophistication, from</p>
<p>Figure 1 :
1
Figure 1: Scale of Medical Language Models: A Size Comparison</p>
<p>Figure 2 :
2
Figure 2: Schematic Representation of a Standard Multimodal Large Language Model (MLLM) Architecture</p>
<p>Representations from Transformers), introduced by Devlin et al. (2018)[37], revolutionized NLP by pre-training a deep bidirectional model on a large corpus and outperforming previous models on various tasks.RoBERTa (A Robustly Optimized BERT Pretraining Approach) byLiu et al. (2019) [38] demonstrated that further pre-training improvements and optimization could significantly enhance the performance of BERT.</p>
<p>Figure 3 :
3
Figure 3: Applications of Large Language Models in Healthcare</p>
<p>Figure 4 :
4
Figure 4: Comparative Performance of Healthcare LLMs</p>
<p>tuned) model achieved the best BLEU-1 score of 26.63.</p>
<p>Figure 5 :
5
Figure 5: Challenges of Large Language Models in Healthcare</p>
<p>Table 1 :
1
Summary of Large Language Models in the Healthcare Space
MethodYear TaskInstitutionSourceCodeBioMistral [39] 2024 Medical Question Answer-AvignonUniversité,modelingNantes UniversitéMed-PaLM 22023 Medical Question Answer-Google Research, Deep-[40]ingMindRadiology-2023 RadiologyUniversity of GeorgiaLlama2 [41]DeID-GPT [42] 2023 De-identificationUniversity of GeorgiacodeMed-HALT2023 Hallucination testSaama AI Researchcode[43]ChatCAD [44]2023 Computer-aided diagnosisShanghaiTech University codeBioGPT [45]2023 Classification, relation ex-Microsoft Researchcodetraction, question answer-ing, etc.GatorTron [46] 2022 Semantic textual similarity,University of Floridacodenatural language inference,and medical question an-sweringBioMedLM2022 Biomedical question an-Stanford CRFM, Mo-codesweringsaicMLBioBART [47]2022 Dialogue, summarization,Tsinghua University, In-codeentity linking, and NERternational Digital Econ-omy AcademyClinicalT5 [48] 2022 Classification, NERUniversity of Oregon,modelBaidu ResearchKeBioLM [49] 2021 Biomedical pre-training,Tsinghua University, Al-codeNER, and relation extrac-ibaba GrouptionCRNN [50]2017 Relation classificationIndian Institute of Tech-codenologyLSTM RNN[51]</p>
<p>Table 2 :
2
Summary of Recent XIAI Methods for LLMs in Healthcare
MethodYear TaskXIAI AttributesXIAIEvaluationMetricMentaLLaMA2024 Mental health analysisPrompt-based (ChatGPT w/ task-BART-score, Human[code] [94]specific instructions)EvalArgMed-2024 Clinical decision reasoningPrompt-based (Self-argumentation iter-Pred. accuracy withAgents [93]ations + symbolic solver)LLM evaluatorDiagnostic rea-2024 Medical Question AnsweringPrompt-based (Bayesian, differential di-Expert Evaluation,soning prompts(MedQA)agnosis, analytical, and intuitive reason-Inter-rater agreement[95]ing)SkinGEN [96]2024 Dermatological diagnosisVisual explanations (Stable Diffusion),Perceived explainabil-interactive frameworkity ratingsDR. KNOWS2023 Automated diagnosis generation Knowledge Graph (explainable diagnos--[91]tic pathway)Human-AI Col-2023 Clinical decision makingSalient features, counterfactual explana-AgreementLevel,laboration [97]tionsUsability Question-nairesChatGPT [92]2023 Mental health analysisPrompt-based (emotional cues andBART-score, Humanexpert-written few-shot examples)EvalCHiLL [98]2023 Clinical predictive tasks, ChestInterpretable features, linear modelsExpert Evaluation,X-ray report classificationClinical JudgementAlignmentTrap-VQA [99] 2022 Pathology Visual Question An-Grad-CAM, SHapley Additive exPlana-Qualitative Evalua-swering (PathVQA)tionstionVision Trans-2021 Covid-19 diagnosisSaliency mapsVisualisationformer [100]ClinicalBERT[code] [15]</p>
<p>Table 3 :
3
LLM Performance Benchmark
OrganizationModelMMLU ScoreCoding (HumanEval)Release DateOpenAIGPT-4 Opus88.7-May 2024AnthropicClaude 3.5 Sonnet 88.792.0June 2024AnthropicClaude 3 Opus86.8-March 2024OpenAIGPT-4 Turbo86.485.4April 2024OpenAIGPT-486.490.2April 2023MetaLlama 3 400B86.1--GoogleGemini 1.5 Pro85.984.1May 2024GoogleGemini Ultra83.7-December 2023OpenAIGPT-3.5 Turbo-73.2-MetaLlama 3 (70B)-81.7-MetaLlama 3 (8B)-62.2-GoogleGemini 1.5 Flash -74.3-</p>
<p>Table 4 :
4
Evaluation Metrics for Language Models in Healthcare Domain
Eval. MetricDescriptionReferencesKey HighlightsPerplexity, a probabilistic metric, quan-tifies the uncertainty in the predictionsPerplexityof a language model. Lower values indi-cate higher prediction accuracy and co-herence.
named entity recognition to question-answering, bolstering decision support and information retrieval.Comparative analyses of state-of-the-art LLMs and open-source options emphasize their significance in healthcare, promoting innovation and collaboration.Performance metrics drive continuous improvement but call for rigorous evaluation standards, considering potential biases and ethical concerns.However, challenges persist, including the need for robust training data, bias mitigation, and data privacy.LLMs in healthcare necessitate further research and interdisciplinary cooperation.LLMs promise transformative benefits, but their full potential hinges on addressing these challenges and upholding ethical standards.The ongoing journey of LLMs in healthcare demands collective efforts to harness their power for improved patient care while ensuring ethical and responsible application.
Multiscale 3d-shift graph convolution network for emotion recognition from human actions. Henglin Shi, Wei Peng, Haoyu Chen, Xin Liu, Guoying Zhao, IEEE Intelligent Systems. 3742022</p>
<p>Modality unifying network for visible-infrared person re-identification. Hao Yu, Xu Cheng, Wei Peng, Weihao Liu, Guoying Zhao, Proceedings of the IEEE/CVF International Conference on Computer Vision. the IEEE/CVF International Conference on Computer Vision2023</p>
<p>Micro-expression action unit detection with dual-view attentive similarity-preserving knowledge distillation. Yante Li, Wei Peng, Guoying Zhao, 2021 16th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2021). IEEE2021</p>
<p>Characterizing subtle facial movements via riemannian manifold. Xiaopeng Hong, Wei Peng, Mehrtash Harandi, Ziheng Zhou, Matti Pietikäinen, Guoying Zhao, ACM Transactions on Multimedia Computing. 153s2019Communications, and Applications (TOMM)</p>
<p>Kai He, Rui Mao, Qika Lin, Yucheng Ruan, Xiang Lan, Mengling Feng, Erik Cambria, arXiv:2310.05694A survey of large language models for healthcare: from data, technology, and applications to accountability and ethics. 2023arXiv preprint</p>
<p>Are large language models ready for healthcare? a comparative study on clinical language understanding. Yuqing Wang, Yun Zhao, Linda Petzold, arXiv:2304.053682023arXiv preprint</p>
<p>Leveraging generative ai and large language models: a comprehensive roadmap for healthcare integration. Ping Yu, Hua Xu, Xia Hu, Chao Deng, Healthcare. MDPI2023112776</p>
<p>Learning optimal k-space acquisition and reconstruction using physics-informed neural networks. Wei Peng, Li Feng, Guoying Zhao, Fang Liu, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2022</p>
<p>Generating realistic brain mris via a conditional diffusion probabilistic model. Wei Peng, Ehsan Adeli, Tomas Bosschieter, Sang , Hyun Park, Qingyu Zhao, Kilian M Pohl, International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer2023</p>
<p>Language models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Advances in neural information processing systems. 202033</p>
<p>. OpenAI. Gpt-4 technical report. 2023</p>
<p>One small step for generative ai, one giant leap for agi: A complete survey on chatgpt in aigc era. Chaoning Zhang, Chenshuang Zhang, Chenghao Li, Yu Qiao, Sheng Zheng, Sumit Kumar Dam, Mengchun Zhang, Jung Uk Kim, Seong Tae Kim, Jinwoo Choi, arXiv:2304.064882023arXiv preprint</p>
<p>Thibaut Hugo Touvron, Gautier Lavril, Xavier Izacard, Marie-Anne Martinet, Timothée Lachaux, Baptiste Lacroix, Naman Rozière, Eric Goyal, Hambro, arXiv:2302.13971Faisal Azhar, et al. Llama: Open and efficient foundation language models. 2023arXiv preprint</p>
<p>Biobert: a pre-trained biomedical language representation model for biomedical text mining. Jinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu Kim, Chan Ho So, Jaewoo Kang, Bioinformatics. 3642020</p>
<p>Clinicalbert: Modeling clinical notes and predicting hospital readmission. Kexin Huang, Jaan Altosaar, Rajesh Ranganath, arXiv:1904.053422019arXiv preprint</p>
<p>Fabio Petroni, Tim Rocktäschel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, Alexander H Miller, Sebastian Riedel, arXiv:1909.01066Language models as knowledge bases?. 2019arXiv preprint</p>
<p>Improving language understanding by generative pre-training. Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, 2018</p>
<p>Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, arXiv:2204.02311Scaling language modeling with pathways. 2022arXiv preprint</p>
<p>Language models are unsupervised multitask learners. Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, OpenAI blog. 1892019</p>
<p>Attention is all you need. Advances in neural information processing systems. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, Illia Polosukhin, 201730</p>
<p>Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity. William Fedus, Barret Zoph, Noam Shazeer, The Journal of Machine Learning Research. 2312022</p>
<p>Glam: Efficient scaling of language models with mixture-of-experts. Nan Du, Yanping Huang, Andrew M Dai, Simon Tong, Dmitry Lepikhin, Yuanzhong Xu, Maxim Krikun, Yanqi Zhou, Adams Wei Yu, Orhan Firat, International Conference on Machine Learning. PMLR2022</p>
<p>Pre-trained language models and their applications. Engineering. Haifeng Wang, Jiwei Li, Hua Wu, Eduard Hovy, Yu Sun, 2022</p>
<p>Jason Wei, Maarten Bosma, Y Vincent, Kelvin Zhao, Adams Wei Guu, Brian Yu, Nan Lester, Andrew M Du, Quoc V Dai, Le, arXiv:2109.01652Finetuned language models are zero-shot learners. 2021arXiv preprint</p>
<p>Refiner: Refining self-attention for vision transformers. Daquan Zhou, Yujun Shi, Bingyi Kang, Weihao Yu, Zihang Jiang, Yuan Li, Xiaojie Jin, Qibin Hou, Jiashi Feng, arXiv:2106.037142021arXiv preprint</p>
<p>Fibro-cosanet: pulmonary fibrosis prognosis prediction using a convolutional self attention network. Zabir Al Nazi, Rabbi Fazla, Md Amirul Mashrur, Shumit Islam, Saha, Physics in Medicine &amp; Biology. 66222250132021</p>
<p>Self-attention attribution: Interpreting information interactions inside transformer. Yaru Hao, Li Dong, Furu Wei, Ke Xu, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202135</p>
<p>High-resolution image synthesis with latent diffusion models. Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, Björn Ommer, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. the IEEE/CVF conference on computer vision and pattern recognition2022</p>
<p>A survey of hallucination in large foundation models. Amit Vipula Rawte, Amitava Sheth, Das, arXiv:2309.059222023arXiv preprint</p>
<p>Shukang Yin, Chaoyou Fu, Sirui Zhao, Ke Li, Xing Sun, Tong Xu, Enhong Chen, arXiv:2306.13549A survey on multimodal large language models. 2023arXiv preprint</p>
<p>Visual chatgpt: Talking, drawing and editing with visual foundation models. Chenfei Wu, Shengming Yin, Weizhen Qi, Xiaodong Wang, Zecheng Tang, Nan Duan, arXiv:2303.046712023arXiv preprint</p>
<p>Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models. Junnan Li, Dongxu Li, Silvio Savarese, Steven Hoi, International conference on machine learning. PMLR2023</p>
<p>Zhuofan Zong, Bingqi Ma, Dazhong Shen, Guanglu Song, Hao Shao, Dongzhi Jiang, Hongsheng Li, Yu Liu, Mova, arXiv:2404.13046Adapting mixture of vision experts to multimodal context. 2024arXiv preprint</p>
<p>Bin Lin, Zhenyu Tang, Yang Ye, Jiaxi Cui, Bin Zhu, Peng Jin, Junwu Zhang, Munan Ning, Li Yuan, arXiv:2401.15947Moe-llava: Mixture of experts for large vision-language models. 2024arXiv preprint</p>
<p>Cumo: Scaling multimodal llm with co-upcycled mixture. Jiachen Li, Xinyao Wang, Sijie Zhu, Chia-Wen Kuo, Lu Xu, Fan Chen, Jitesh Jain, Humphrey Shi, Longyin Wen, arXiv:2405.059492024of-experts. arXiv preprint</p>
<p>Large language models in medicine. Arun James Thirunavukarasu, Darren Shu, Jeng Ting, Kabilan Elangovan, Laura Gutierrez, Ting Fang Tan, Daniel Shu, Wei Ting, Nature Medicine. 2023</p>
<p>Bert: Pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, arXiv:1810.048052018arXiv preprint</p>
<p>Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov, arXiv:1907.11692Roberta: A robustly optimized bert pretraining approach. 2019arXiv preprint</p>
<p>Biomistral: A collection of open-source pretrained large language models for medical domains. Yanis Labrak, Adrien Bazoge, Emmanuel Morin, Pierre-Antoine Gourraud, Mickael Rouvier, Richard Dufour, arXiv:2402.103732024arXiv preprint</p>
<p>Towards expert-level medical question answering with large language models. Karan Singhal, Tao Tu, Juraj Gottweis, Rory Sayres, Ellery Wulczyn, Le Hou, Kevin Clark, Stephen Pfohl, Heather Cole-Lewis, Darlene Neal, arXiv:2305.096172023arXiv preprint</p>
<p>Zhengliang Liu, Yiwei Li, Peng Shu, Aoxiao Zhong, Longtao Yang, Chao Ju, Zihao Wu, Chong Ma, Jie Luo, Cheng Chen, arXiv:2309.06419Radiology-llama2: Best-in-class large language model for radiology. 2023arXiv preprint</p>
<p>Zhengliang Liu, Xiaowei Yu, Lu Zhang, Zihao Wu, Chao Cao, Haixing Dai, Lin Zhao, Wei Liu, Dinggang Shen, Quanzheng Li, arXiv:2303.11032Deid-gpt: Zero-shot text de-identification by gpt-4. 2023arXiv preprint</p>
<p>Med-halt: Medical domain hallucination test for large language models. Logesh Kumar Umapathi, Ankit Pal, Malaikannan Sankarasubbu, arXiv:2307.153432023arXiv preprint</p>
<p>Zihao Zhao, Sheng Wang, Jinchen Gu, Yitao Zhu, Lanzhuju Mei, Zixu Zhuang, Zhiming Cui, Qian Wang, Dinggang Shen, Chatcad+, arXiv:2305.15964Towards a universal and reliable interactive cad using llms. 2023arXiv preprint</p>
<p>Biogpt: generative pre-trained transformer for biomedical text generation and mining. Renqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon, Tie-Yan Liu, Briefings in Bioinformatics. 2364092022</p>
<p>Gatortron: A large clinical language model to unlock patient information from unstructured electronic health records. Xi Yang, Aokun Chen, Nima Pournejatian, Chang Hoo, Kaleb E Shin, Christopher Smith, Colin Parisien, Cheryl Compas, Mona G Martin, Ying Flores, Zhang, arXiv:2203.035402022arXiv preprint</p>
<p>Hongyi Yuan, Zheng Yuan, Ruyi Gan, Jiaxing Zhang, Yutao Xie, Sheng Yu, arXiv:2204.03905Biobart: Pretraining and evaluation of a biomedical generative language model. 2022arXiv preprint</p>
<p>Clinicalt5: A generative language model for clinical text. Qiuhao Lu, Dejing Dou, Thien Nguyen, Findings of the Association for Computational Linguistics: EMNLP 2022. 2022</p>
<p>Improving biomedical pretrained language models with knowledge. Zheng Yuan, Yijia Liu, Chuanqi Tan, Songfang Huang, Fei Huang, arXiv:2104.103442021arXiv preprint</p>
<p>Learning local and global contexts using a convolutional recurrent network model for relation classification in biomedical text. Desh Raj, Sunil Sahu, Ashish Anand, Proceedings of the 21st conference on computational natural language learning. the 21st conference on computational natural language learningCoNLL 2017. 2017</p>
<p>Long short-term memory rnn for biomedical named entity recognition. Chen Lyu, Bo Chen, Yafeng Ren, Donghong Ji, BMC bioinformatics. 182017</p>
<p>Language models show human-like content effects on reasoning. Ishita Dasgupta, Stephanie Cy Andrew K Lampinen, Antonia Chan, Dharshan Creswell, James L Kumaran, Felix Mcclelland, Hill, arXiv:2207.070512022arXiv preprint</p>
<p>Large language models encode clinical knowledge. Karan Singhal, Shekoofeh Azizi, Tao Tu, Sara Mahdavi, Jason Wei, Hyung Won Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen Pfohl, Nature. 2023</p>
<p>Language models are few-shot learners for prognostic prediction. Zekai Chen, Mariann Micsinai Balan, Kevin Brown, arXiv-23022023arXiv e-prints</p>
<p>The potential impact of chatgpt in clinical and translational medicine. Pinggui Vivian Weiwen Xue, William C Lei, Cho, Clinical and Translational Medicine. 1332023</p>
<p>Boosting transformers and language models for clinical prediction in immunotherapy. Zekai Chen, Mariann Micsinai Balan, Kevin Brown, arXiv:2302.126922023arXiv preprint</p>
<p>Text-based predictions of covid-19 diagnosis from self-reported chemosensory descriptions. Hongyang Li, Alyssa Richard C Gerkin, Raquel Bakke, Guillermo Norel, Christophe Cecchi, Masha Y Laudamiel, Kathrin Niv, John E Ohla, Valentina Hayes, Parma, Communications Medicine. 311042023</p>
<p>Ad-bert: Using pre-trained language model to predict the progression from mild cognitive impairment to alzheimer's disease. Chengsheng Mao, Jie Xu, Luke Rasmussen, Yikuan Li, Prakash Adekkanattu, Jennifer Pacheco, Borna Bonakdarpour, Robert Vassar, Li Shen, Guoqian Jiang, Journal of Biomedical Informatics. 1441044422023</p>
<p>Predicting dementia from spontaneous speech using large language models. Felix Agbavor, Hualou Liang, PLOS Digital Health. 112e00001682022</p>
<p>Fine-tuning a llm using reinforcement learning from human feedback for a therapy chatbot application. Desirée Bill, Theodor Eriksson, 2023</p>
<p>Conversational ai models for ophthalmic diagnosis: Comparison of chatgpt and the isabel pro differential diagnosis generator. Michael Balas, Edsel B Ing, JFO Open Ophthalmology. 11000052023</p>
<p>Psy-llm: Scaling up global mental health psychological services with ai-based large language models. Tin Lai, Yukun Shi, Zicong Du, Jiajie Wu, Ken Fu, Yichao Dou, Ziqi Wang, arXiv:2307.119912023arXiv preprint</p>
<p>Enhancing awareness and self-diagnosis of obstructive sleep apnea using ai-powered chatbots: The role of chatgpt in revolutionizing healthcare. Maham Bilal, Yumna Jamil, Dua Rana, Hussain Haider Shah, Annals of Biomedical Engineering. 2023</p>
<p>Chatgpt for healthcare services: An emerging stage for an innovative perspective. Mohd Javaid, Abid Haleem, Ravi Pratap Singh, BenchCouncil Transactions on Benchmarks, Standards and Evaluations. 311001052023</p>
<p>Using chatgpt to write patient clinic letters. The Lancet Digital Health. Thomas D Stephen R Ali, Hayley A Dobbs, Iain S Hutchings, Whitaker, 20235</p>
<p>The application of chatgpt in healthcare progress notes: A commentary from a clinical and research perspective. Josh Nguyen, Christopher A Pepping, Clinical and Translational Medicine. 1372023</p>
<p>Reliability of medical information provided by chatgpt: Assessment against clinical guidelines and patient information quality instrument. Louise Harriet, Shahi Walker, Christoph Ghani, Kuemmerli, Andreas Christian, Beat Nebiker, Dimitri Aristotle Peter Müller, Sebastian Raptis, Staubli Manuel, Journal of Medical Internet Research. 25e474792023</p>
<p>Docgpt: Impact of chatgpt-3 on health services as a virtual doctor. Linta Iftikhar, EC Paediatrics. 1212023</p>
<p>Exploring the potential of large language models in personalized diabetes treatment strategies. medRxiv. Hao Yang, Jiaxi Li, Siru Liu, Lei Du, Xiali Liu, Yong Huang, Qingke Shi, Jialin Liu, 2023</p>
<p>Chatcad: Interactive computer-aided diagnosis on medical image using large language models. Sheng Wang, Zihao Zhao, Xi Ouyang, Qian Wang, Dinggang Shen, arXiv:2302.072572023arXiv preprint</p>
<p>Large language models for oncological applications. Yiftach Vera Sorin, Eli Barash, Eyal Konen, Klang, Journal of Cancer Research and Clinical Oncology. 2023</p>
<p>Leveraging large language models in dermatology. Eleni Rubeta N Matin, Neil Linos, Rajan, 2023</p>
<p>The utility of chatgpt as an example of large language models in healthcare education, research and practice: Systematic review on the future perspectives and potential limitations. Malik Sallam, medRxiv. 2023</p>
<p>Evaluating large language models on medical evidence summarization. Liyan Tang, Zhaoyi Sun, Betina Idnay, Jordan G Nestor, Ali Soroush, Pierre A Elias, Ziyang Xu, Ying Ding, Greg Durrett, Justin F Rousseau, Digital Medicine. 611582023</p>
<p>Ai-based language models powering drug discovery and development. Zhichao Liu, Ruth A Roberts, Madhu Lal-Nag, Xi Chen, Ruili Huang, Weida Tong, Drug Discovery Today. 26112021</p>
<p>Bert-d2: Drug-drug interaction extraction using bert. Tapos Tanmoy, Pintu Datta, Zabir Chandra Shill, Nazi Al, 2022 International Conference for Advancement in Technology (ICONAT). IEEE2022</p>
<p>Chemical language models for de novo drug design: Challenges and opportunities. Francesca Grisoni, Current Opinion in Structural Biology. 791025272023</p>
<p>Exploiting pretrained biochemical language models for targeted drug design. Gökçe Uludogan, Elif Ozkirimli, Nilgün Kutlu O Ulgen, Arzucan Karalı, Özgür, Bioinformatics. 38Supplement_22022</p>
<p>Cephgpt-4: An interactive multimodal cephalometric measurement and diagnostic system with visual large language model. Lei Ma, Jincong Han, Zhaoxin Wang, Dian Zhang, arXiv:2307.075182023arXiv preprint</p>
<p>Medical diagnosis with large scale multimodal transformers-leveraging diverse data for more accurate diagnosis. Firas Khader, Gustav Mueller-Franzes, Tianci Wang, Tianyu Han, Soroosh Tayebi Arasteh, Christoph Haarburger, Johannes Stegmaier, Keno Bressem, Christiane Kuhl, Sven Nebelung, arXiv:2212.091622022arXiv preprint</p>
<p>Omkar Thawkar, Abdelrahman Shaker, Sahal Shaji Mullappilly, Hisham Cholakkal, Muhammad Rao, Salman Anwer, Jorma Khan, Fahad Laaksonen, Shahbaz Khan, arXiv:2306.07971Xraygpt: Chest radiographs summarization using medical vision-language models. 2023arXiv preprint</p>
<p>A chatgpt aided explainable framework for zero-shot medical image diagnosis. Jiaxiang Liu, Tianxiang Hu, Yan Zhang, Xiaotang Gai, Yang Feng, Zuozhu Liu, arXiv:2307.019812023arXiv preprint</p>
<p>Berthop: An effective vision-and-language model for chest x-ray disease diagnosis. Masoud Monajatipoor, Mozhdeh Rouhsedaghat, Liunian Harold Li, C-C Jay Kuo, Aichi Chien, Kai-Wei Chang, International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer2022</p>
<p>Transformer-based deep neural network language models for alzheimer's disease risk assessment from targeted speech. Alireza Roshanzamir, Hamid Aghajan, Mahdieh Soleymani, Baghshah , BMC Medical Informatics and Decision Making. 212021</p>
<p>Wanglab at mediqa-chat 2023: Clinical note generation from doctor-patient conversations using large language models. John Giorgi, Augustin Toma, Ronald Xie, Sondra Chen, Kevin An, Grace Zheng, Bo Wang, Proceedings of the 5th Clinical Natural Language Processing Workshop. the 5th Clinical Natural Language Processing Workshop2023</p>
<p>From explainable to interpretable deep learning for natural language processing in healthcare: How far from reality?. Guangming Huang, Yingya Li, Shoaib Jameel, Yunfei Long, Giorgos Papanastasiou, Computational and Structural Biotechnology Journal. 2024</p>
<p>Discrete-time survival analysis in the critically ill: a deep learning approach using heterogeneous data. Hans-Christian Thorsen-Meyer, Davide Placido, Benjamin Skov Kaas-Hansen, Anna P Nielsen, Theis Lange, Palle Annelaura B Nielsen, Jens Toft, Thomas Schierbeck, Piotr J Strøm, Chmura, NPJ digital medicine. 511422022</p>
<p>Explainable ai: classification of mri brain scans orders for quality improvement. Alwin Yaoxian Zhang, Sean Shao, Wei Lam, Marcus Eng Hock, Phua Hwee Ong, Ling Tang, Chan Ling, Proceedings of the 6th IEEE/ACM international conference on big data computing, applications and technologies. the 6th IEEE/ACM international conference on big data computing, applications and technologies2019</p>
<p>Word-level text highlighting of medical texts for telehealth services. Ozan Ozyegen, Devika Kabe, Mucahit Cevik, Artificial Intelligence in Medicine. 1271022842022</p>
<p>Interpretable segmentation of medical free-text records based on word embeddings. Adam Gabriel Dobrakowski, Agnieszka Mykowiecka, Małgorzata Marciniak, Wojciech Jaworski, Przemysław Biecek, Journal of Intelligent Information Systems. 572021</p>
<p>Leveraging a medical knowledge graph into large language models for diagnosis prediction. Yanjun Gao, Ruizhe Li, John Caskey, Dmitriy Dligach, Timothy Miller, Matthew M Churpek, Majid Afshar, arXiv:2308.143212023arXiv preprint</p>
<p>Towards interpretable mental health analysis with large language models. Kailai Yang, Shaoxiong Ji, Tianlin Zhang, Qianqian Xie, Ziyan Kuang, Sophia Ananiadou, arXiv:2304.033472023arXiv preprint</p>
<p>Argmed-agents: Explainable clinical decision reasoning with large language models via argumentation schemes. Shengxin Hong, Liang Xiao, Xin Zhang, Jianxia Chen, arXiv:2403.062942024arXiv preprint</p>
<p>Mentallama: interpretable mental health analysis on social media with large language models. Kailai Yang, Tianlin Zhang, Ziyan Kuang, Qianqian Xie, Jimin Huang, Sophia Ananiadou, Proceedings of the ACM on Web Conference 2024. the ACM on Web Conference 20242024</p>
<p>Diagnostic reasoning prompts reveal the potential for large language model interpretability in medicine. Thomas Savage, Ashwin Nayak, Robert Gallo, Ekanath Rangan, Jonathan H Chen, NPJ Digital Medicine. 71202024</p>
<p>Skingen: An explainable dermatology diagnosis-to-generation framework with interactive vision-language models. Bo Lin, Yingjing Xu, Xuanwen Bao, Zhou Zhao, Zuyong Zhang, Zhouyang Wang, Jie Zhang, Shuiguang Deng, Jianwei Yin, arXiv:2404.147552024arXiv preprint</p>
<p>Understanding the effect of counterfactual explanations on trust and reliance on ai for human-ai collaborative clinical decision making. Min Hun, Lee , Chong Jun Chew, Proceedings of the ACM on Human-Computer Interaction. 7CSCW22023</p>
<p>Chill: zeroshot custom interpretable feature extraction from clinical notes with large language models. Denis Jered Mcinerney, Geoffrey Young, Jan-Willem Van De Meent, Byron C Wallace, arXiv:2302.123432023arXiv preprint</p>
<p>Vision-language transformer for interpretable pathology visual question answering. Usman Naseem, Matloob Khushi, Jinman Kim, IEEE Journal of Biomedical and Health Informatics. 2742022</p>
<p>Vision transformer for covid-19 cxr diagnosis using chest x-ray feature corpus. Park, Kim, Oh, Seo, Lee, Kim, Moon, J C Lim, Ye, arXiv:2103.070552021arXiv preprint</p>
<p>Large language model for molecular chemistry. Jie Pan, Nature Computational Science. 312023</p>
<p>Juhao Liang, Ziwei Wang, Zhuoheng Ma, Jianquan Li, Zhiyi Zhang, Xiangbo Wu, Benyou Wang, arXiv:2403.04790Online training of large language models: Learn while chatting. 2024arXiv preprint</p>
<p>Federated learning of large language models with parameter-efficient prompt tuning and adaptive optimization. Tianshi Che, Ji Liu, Yang Zhou, Jiaxiang Ren, Jiwen Zhou, Huaiyu Victor S Sheng, Dejing Dai, Dou, arXiv:2310.150802023arXiv preprint</p>
<p>Explainability for large language models: A survey. Haiyan Zhao, Hanjie Chen, Fan Yang, Ninghao Liu, Huiqi Deng, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, Mengnan Du, ACM Transactions on Intelligent Systems and Technology. 1522024</p>
<p>Health-llm: Large language models for health prediction via wearable sensor data. Yubin Kim, Xuhai Xu, Daniel Mcduff, Cynthia Breazeal, Hae Won Park, arXiv:2401.068662024arXiv preprint</p>
<p>Large language models and generative ai's expanding role in healthcare. Saurabh Pahune, Noopur Rewatkar, 2024</p>
<p>Evaluation framework to guide implementation of ai systems into healthcare settings. Sandeep Reddy, Wendy Rogers, Ville-Petteri Makinen, Enrico Coiera, Pieta Brown, Markus Wenzel, Eva Weicken, Saba Ansari, Piyush Mathur, Aaron Casey, BMJ health &amp; care informatics. 2812021</p>
<p>Evaluating large language models for use in healthcare: A framework for translational value assessment. Sandeep Reddy, Informatics in Medicine Unlocked. 1013042023</p>
<p>. Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, arXiv:2305.104032023Palm 2 technical report. arXiv preprint</p>
<p>Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt, arXiv:2009.03300Measuring massive multitask language understanding. 2020arXiv preprint</p>
<p>Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde De, Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, arXiv:2107.03374Evaluating large language models trained on code. 2021arXiv preprint</p>
<p>Mmlu benchmark (massive multi-task language understanding. A I Klu, </p>
<p>Qiao Jin, Bhuwan Dhingra, William W Cohen, Xinghua Lu, arXiv:1904.02181Probing biomedical embeddings from language models. 2019arXiv preprint</p>
<p>Deeptox: toxicity prediction using deep learning. Andreas Mayr, Günter Klambauer, Thomas Unterthiner, Sepp Hochreiter, Frontiers in Environmental Science. 3802016</p>
<p>Qiao Jin, Bhuwan Dhingra, Zhengping Liu, William W Cohen, Xinghua Lu, arXiv:1909.06146Pubmedqa: A dataset for biomedical research question answering. 2019arXiv preprint</p>
<p>. Papers with Code. Medical papers with code. 2024</p>
<p>The drug-like molecule pre-training strategy for drug discovery. Jonghyun Lee, In-Soo Myeong, Yun Kim, IEEE Access. 112023</p>
<p>Differentiate chatgpt-generated and human-written medical texts. Wenxiong Liao, Zhengliang Liu, Haixing Dai, Shaochen Xu, Zihao Wu, Yiyang Zhang, Xiaoke Huang, Dajiang Zhu, Hongmin Cai, Tianming Liu, arXiv:2304.115672023arXiv preprint</p>
<p>Federated multilingual models for medical transcript analysis. Andrea Manoel, Mirian Del Carmen, Hipolito Garcia, Tal Baumel, Shize Su, Jialei Chen, Robert Sim, Dan Miller, Danny Karmon, Dimitrios Dimitriadis, Conference on Health, Inference, and Learning. PMLR2023</p>
<p>Vettag: improving automated veterinary diagnosis coding via large-scale language modeling. Yuhui Zhang, Allen Nie, Ashley Zehnder, Rodney L Page, James Zou, NPJ digital medicine. 21352019</p>
<p>Clinicalgpt: Large language models finetuned with diverse medical data and comprehensive evaluation. Guangyu Wang, Guoxing Yang, Zongxin Du, Longjun Fan, Xiaohu Li, arXiv:2306.099682023arXiv preprint</p>
<p>Jianquan Li, Xidong Wang, Xiangbo Wu, Zhiyi Zhang, Xiaolong Xu, Jie Fu, Prayag Tiwari, arXiv:2305.01526Xiang Wan, and Benyou Wang. Huatuo-26m, a large-scale chinese medical qa dataset. 2023arXiv preprint</p>
<p>A large language model for electronic health records. Xi Yang, Aokun Chen, Nima Pournejatian, Chang Hoo, Kaleb E Shin, Christopher Smith, Colin Parisien, Cheryl Compas, Anthony B Martin, Mona G Costa, Flores, NPJ Digital Medicine. 511942022</p>
<p>Advancing italian biomedical information extraction with large language models: Methodological insights and multicenter practical application. Claudio Crema, Mario Tommaso, Silvia Buonocore, Enea Fostinelli, Federico Parimbelli, Cira Verde, Marina Fundarò, Matteo Cotta Manera, Marco Ramusino, Alfredo Capelli, Costa, arXiv:2306.053232023arXiv preprint</p>
<p>Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, Yoav Artzi, Bertscore, arXiv:1904.09675Evaluating text generation with bert. 2019arXiv preprint</p>
<p>Evaluating capabilities of large language models: Performance of gpt4 on surgical knowledge assessments. medRxiv. Sahaj Brendin R Beaulieu-Jones, Margaret T Shah, Jayson S Berrigan, Shuo-Lun Marwaha, Gabriel A Lai, Brat, 2023</p>
<p>Chatgpt and large language models (llms) in healthcare: Opportunities and risks. Hazrat Ali, Junaid Qadir, Tanvir Alam, Mowafa Househ, Zubair Shah, 2023</p>
<p>A clinician's guide to large language models. Giovanni Briganti, Future Medicine AI. 02023FMAI</p>
<p>Interpretable medical diagnostics with structured data extraction by large language models. Aleksa Bisercic, Mladen Nikolic, Mihaela Van Der Schaar, Boris Delibasic, Pietro Lio, Andrija Petrovic, arXiv:2306.050522023arXiv preprint</p>
<p>Balanced and explainable social media analysis for public health with large language models. Yan Jiang, Ruihong Qiu, Yi Zhang, Peng-Fei Zhang, arXiv:2309.059512023arXiv preprint</p>
<p>Large language models in medicine: the potentials and pitfalls. Haiwen Jesutofunmi A Omiye, Gui, J Shawheen, James Rezaei, Roxana Zou, Daneshjou, arXiv:2309.000872023arXiv preprint</p>
<p>Chatgpt, bard, and large language models for biomedical research: Opportunities and pitfalls. Surendrabikram Thapa, Surabhi Adhikari, Annals of Biomedical Engineering. 2023</p>
<p>Opportunities and challenges for chatgpt and large language models in biomedicine and health. Qiao Shubo Tian, Lana Jin, Po-Ting Yeganova, Qingqing Lai, Xiuying Zhu, Yifan Chen, Qingyu Yang, Won Chen, Donald C Kim, Comeau, arXiv:2306.100702023arXiv preprint</p>
<p>Claudio Novelli, Federico Casolari, Philipp Hacker, Giorgio Spedicato, Luciano Floridi, arXiv:2401.07348Generative ai in eu law: liability, privacy, intellectual property, and cybersecurity. 2024arXiv preprint</p>
<p>Regulating chatgpt and other large generative ai models. Philipp Hacker, Andreas Engel, Marco Mauer, Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency. the 2023 ACM Conference on Fairness, Accountability, and Transparency2023</p>            </div>
        </div>

    </div>
</body>
</html>