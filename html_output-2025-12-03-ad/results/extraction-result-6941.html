<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6941 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6941</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6941</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-134.html">extraction-schema-134</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform self‑reflection or self‑critique, including the specific reflection method, number of generate‑then‑reflect iterations, tasks or benchmarks evaluated, performance before and after reflection, evaluation metrics, and any reported limitations or failure cases.</div>
                <p><strong>Paper ID:</strong> paper-278171621</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2504.20082v1.pdf" target="_blank">Evolution of AI in Education: Agentic Workflows</a></p>
                <p><strong>Paper Abstract:</strong> Artificial intelligence (AI) has transformed various aspects of education, with large language models (LLMs) driving advancements in automated tutoring, assessment, and content generation. However, conventional LLMs are constrained by their reliance on static training data, limited adaptability, and lack of reasoning. To address these limitations and foster more sustainable technological practices, AI agents have emerged as a promising new avenue for educational innovation. In this review, we examine agentic workflows in education according to four major paradigms: reflection, planning, tool use, and multi-agent collaboration. We critically analyze the role of AI agents in education through these key design paradigms, exploring their advantages, applications, and challenges. To illustrate the practical potential of agentic systems, we present a proof-of-concept application: a multi-agent framework for automated essay scoring. Preliminary results suggest this agentic approach may offer improved consistency compared to stand-alone LLMs. Our findings highlight the transformative potential of AI agents in educational settings while underscoring the need for further research into their interpretability, trustworthiness, and sustainable impact on pedagogical impact.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6941.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6941.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform self‑reflection or self‑critique, including the specific reflection method, number of generate‑then‑reflect iterations, tasks or benchmarks evaluated, performance before and after reflection, evaluation metrics, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CRITIC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>CRITIC (Tool-Interactive Critiquing)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A reflection framework that enables LLMs to validate and refine their outputs by interacting with external tools (search, code interpreters, calculators) in a verify-then-correct loop to detect and fix errors.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_name</strong></td>
                            <td>CRITIC (tool-interactive critiquing)</td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_description</strong></td>
                            <td>Generate an initial output, call external verification tools to critique/verify (e.g., search for facts, run code for math), then revise the output based on these tool-generated critiques (a verify-then-correct cycle).</td>
                        </tr>
                        <tr>
                            <td><strong>iteration_type</strong></td>
                            <td>generate-then-reflect (tool-verified revise)</td>
                        </tr>
                        <tr>
                            <td><strong>num_iterations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Free-form question answering; mathematical/programmatic reasoning; content generation (toxicity mitigation)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Tasks where factual accuracy or executable correctness can be validated using external tools (web search for facts, code interpreters for math/programs), and content generation where toxicity needs detection.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_before_reflection</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_after_reflection</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>improvement_observed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Requires external tools and repeated verification loops, increasing resource use; scalability and computational cost concerns; external tools can inject biases or errors (propagating incorrect external sources); data privacy concerns when calling external services.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Evolution of AI in Education: Agentic Workflows', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6941.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6941.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform self‑reflection or self‑critique, including the specific reflection method, number of generate‑then‑reflect iterations, tasks or benchmarks evaluated, performance before and after reflection, evaluation metrics, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Reflexion</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Reflexion (Verbal Reinforcement/Verbal RL Feedback)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework using verbal reinforcement learning feedback: agents treat feedback as episodic memory and iteratively adjust strategies via verbalized critiques stored as long-term memory to improve multi-step decision-making and reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Reflexion: Language Agents with Verbal Reinforcement Learning Feedback</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_name</strong></td>
                            <td>Reflexion (verbal reinforcement)</td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_description</strong></td>
                            <td>Agent generates an action/output, receives verbal feedback (converted from scalar/binary signals into detailed textual feedback), stores feedback as episodic memory, and uses this memory to iteratively refine future outputs/strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>iteration_type</strong></td>
                            <td>generate-then-reflect (verbal-feedback memory-based iteration)</td>
                        </tr>
                        <tr>
                            <td><strong>num_iterations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Sequential decision-making, multi-step logical reasoning, programming/debugging</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Tasks requiring multi-step planning and correction where patterns of errors can be learned across episodes and corrected using stored verbalized feedback.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_before_reflection</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_after_reflection</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>improvement_observed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>May require many episodes and memory capacity to store/use feedback; potential propagation/reinforcement of biased or incorrect self-feedback; resource demands for episodic storage and iteration; limited reporting of precise iteration counts or standardized metrics in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Evolution of AI in Education: Agentic Workflows', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6941.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6941.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform self‑reflection or self‑critique, including the specific reflection method, number of generate‑then‑reflect iterations, tasks or benchmarks evaluated, performance before and after reflection, evaluation metrics, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SELF-REFINE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SELF-REFINE (Iterative Refinement with Self-Feedback)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A self-refinement framework where models produce initial outputs, generate self-feedback, and iteratively revise outputs to improve quality (used for feedback generation, code optimization, dialogue and essay refinement).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>SELF-REFINE: Iterative Refinement with Self-Feedback</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_name</strong></td>
                            <td>SELF-REFINE (self-feedback iterative refinement)</td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_description</strong></td>
                            <td>Generate an initial response, produce self-feedback (critique) about weaknesses and improvements, then use that feedback to produce a refined response; repeat as needed to incrementally improve output quality.</td>
                        </tr>
                        <tr>
                            <td><strong>iteration_type</strong></td>
                            <td>generate-then-reflect (recursive self-critique / iterative refinement)</td>
                        </tr>
                        <tr>
                            <td><strong>num_iterations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Feedback generation, automated essay scoring, dialogue generation, code optimization</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Tasks where iterative polishing improves readability, correctness, or pedagogical usefulness; used to refine feedback and outputs over multiple passes.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_before_reflection</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_after_reflection</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>improvement_observed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Iterative cycles are resource intensive which limits scalability in resource-constrained settings; potential to reinforce internal biases; privacy concerns when processing sensitive student data; exact iteration counts and standardized performance gains not reported in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Evolution of AI in Education: Agentic Workflows', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6941.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6941.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform self‑reflection or self‑critique, including the specific reflection method, number of generate‑then‑reflect iterations, tasks or benchmarks evaluated, performance before and after reflection, evaluation metrics, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DeepSeek</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DeepSeek (open-source advanced reasoning model)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source model/framework that incorporates reinforcement learning and structured cognitive reasoning to iteratively refine outputs and integrate external feedback for complex problem-solving.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>DeepSeek (evaluated as DeepSeek 67b and DeepSeek 1.3b in experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Open-source AI model claimed to include advanced reasoning and reinforcement-learning-based iterative refinement; used in the paper's benchmarks as stand-alone models.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>67B; 1.3B</td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_name</strong></td>
                            <td>Iterative reasoning / reinforcement-guided self-refinement (as described)</td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_description</strong></td>
                            <td>Model architecture supports iterative refinement using reinforcement learning and incorporation of external feedback/prior knowledge to improve outputs over iterations (description provided by the authors/references).</td>
                        </tr>
                        <tr>
                            <td><strong>iteration_type</strong></td>
                            <td>iterative refinement (described conceptually); not clearly reported as applied in experiments</td>
                        </tr>
                        <tr>
                            <td><strong>num_iterations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Automated essay scoring (ASAP 2.0 benchmark) as a stand-alone model baseline in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Holistic scoring of student argumentative essays on a 1–6 rubric (ASAP 2.0 dataset, ~17k essays).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Mean Absolute Error (MAE); standard deviation of error reported</td>
                        </tr>
                        <tr>
                            <td><strong>performance_before_reflection</strong></td>
                            <td>DeepSeek 67b MAE 0.7345; DeepSeek 1.3b MAE 1.6956 (stand-alone baselines, no reflection applied in the paper)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_after_reflection</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>improvement_observed</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Stand-alone DeepSeek models showed higher MAE and high variability (especially 1.3b), indicating inconsistency in grading; the paper does not report application of DeepSeek's reflection capabilities in these experiments, so no before/after reflection comparisons are provided.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Evolution of AI in Education: Agentic Workflows', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6941.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e6941.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform self‑reflection or self‑critique, including the specific reflection method, number of generate‑then‑reflect iterations, tasks or benchmarks evaluated, performance before and after reflection, evaluation metrics, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MASS verification</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MASS (Multi-Agent Scoring System) — verification / multi-report mechanism</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>In-paper multi-agent verification mechanism where a lead agent synthesizes scores from specialized subagents and requests additional reports when subagent feedback diverges, serving as an ensemble/verification form of self-check.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4o (lead agent); subagents: specialized scoring agents</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Multi-agent architecture built on GPT-4o where subagents independently evaluate content (content vs language mechanics) and a lead agent aggregates and conditionally requests additional reports when feedback diverges.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_name</strong></td>
                            <td>Multi-agent verification / conditional multi-report request</td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_description</strong></td>
                            <td>Two specialized subagents independently score different essay aspects; the lead agent consolidates outputs and, if subagent reports diverge widely, it requests multiple additional reports from subagents to verify and refine the final score (an intra-system verification/consensus loop).</td>
                        </tr>
                        <tr>
                            <td><strong>iteration_type</strong></td>
                            <td>conditional multi-report verification (ensemble / verify-and-aggregate rather than repeated single-agent self-revision)</td>
                        </tr>
                        <tr>
                            <td><strong>num_iterations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Automated essay scoring on ASAP 2.0 dataset</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Holistic scoring of student-written argumentative essays on a 1–6 rubric (ASAP 2.0, ~17,000 essays).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Mean Absolute Error (MAE); standard deviation of error; paired t-test and Wilcoxon signed-rank test p-values reported</td>
                        </tr>
                        <tr>
                            <td><strong>performance_before_reflection</strong></td>
                            <td>Stand-alone GPT-4o MAE 0.6129, Std Dev 0.9555</td>
                        </tr>
                        <tr>
                            <td><strong>performance_after_reflection</strong></td>
                            <td>MASS (multi-agent) MAE 0.5612, Std Dev 0.8295</td>
                        </tr>
                        <tr>
                            <td><strong>improvement_observed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Multi-agent verification increases token usage and processing time, raising computational cost and environmental impact; orchestration overhead and potential supervisor bottlenecks; paper notes need to minimize interactions while maintaining performance and warns of general multi-agent coordination challenges (possible inconsistencies if coordination breaks down).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Evolution of AI in Education: Agentic Workflows', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing <em>(Rating: 2)</em></li>
                <li>Reflexion: Language Agents with Verbal Reinforcement Learning Feedback <em>(Rating: 2)</em></li>
                <li>SELF-REFINE: Iterative Refinement with Self-Feedback <em>(Rating: 2)</em></li>
                <li>Using Generative AI and Multi-Agents to Provide Automatic Feedback <em>(Rating: 1)</em></li>
                <li>Agentic design patterns part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance <em>(Rating: 1)</em></li>
                <li>DeepSeek <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6941",
    "paper_id": "paper-278171621",
    "extraction_schema_id": "extraction-schema-134",
    "extracted_data": [
        {
            "name_short": "CRITIC",
            "name_full": "CRITIC (Tool-Interactive Critiquing)",
            "brief_description": "A reflection framework that enables LLMs to validate and refine their outputs by interacting with external tools (search, code interpreters, calculators) in a verify-then-correct loop to detect and fix errors.",
            "citation_title": "CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing",
            "mention_or_use": "mention",
            "model_name": null,
            "model_description": null,
            "model_size": null,
            "reflection_method_name": "CRITIC (tool-interactive critiquing)",
            "reflection_method_description": "Generate an initial output, call external verification tools to critique/verify (e.g., search for facts, run code for math), then revise the output based on these tool-generated critiques (a verify-then-correct cycle).",
            "iteration_type": "generate-then-reflect (tool-verified revise)",
            "num_iterations": null,
            "task_name": "Free-form question answering; mathematical/programmatic reasoning; content generation (toxicity mitigation)",
            "task_description": "Tasks where factual accuracy or executable correctness can be validated using external tools (web search for facts, code interpreters for math/programs), and content generation where toxicity needs detection.",
            "evaluation_metric": null,
            "performance_before_reflection": null,
            "performance_after_reflection": null,
            "improvement_observed": true,
            "limitations_or_failure_cases": "Requires external tools and repeated verification loops, increasing resource use; scalability and computational cost concerns; external tools can inject biases or errors (propagating incorrect external sources); data privacy concerns when calling external services.",
            "uuid": "e6941.0",
            "source_info": {
                "paper_title": "Evolution of AI in Education: Agentic Workflows",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "Reflexion",
            "name_full": "Reflexion (Verbal Reinforcement/Verbal RL Feedback)",
            "brief_description": "A framework using verbal reinforcement learning feedback: agents treat feedback as episodic memory and iteratively adjust strategies via verbalized critiques stored as long-term memory to improve multi-step decision-making and reasoning.",
            "citation_title": "Reflexion: Language Agents with Verbal Reinforcement Learning Feedback",
            "mention_or_use": "mention",
            "model_name": null,
            "model_description": null,
            "model_size": null,
            "reflection_method_name": "Reflexion (verbal reinforcement)",
            "reflection_method_description": "Agent generates an action/output, receives verbal feedback (converted from scalar/binary signals into detailed textual feedback), stores feedback as episodic memory, and uses this memory to iteratively refine future outputs/strategies.",
            "iteration_type": "generate-then-reflect (verbal-feedback memory-based iteration)",
            "num_iterations": null,
            "task_name": "Sequential decision-making, multi-step logical reasoning, programming/debugging",
            "task_description": "Tasks requiring multi-step planning and correction where patterns of errors can be learned across episodes and corrected using stored verbalized feedback.",
            "evaluation_metric": null,
            "performance_before_reflection": null,
            "performance_after_reflection": null,
            "improvement_observed": true,
            "limitations_or_failure_cases": "May require many episodes and memory capacity to store/use feedback; potential propagation/reinforcement of biased or incorrect self-feedback; resource demands for episodic storage and iteration; limited reporting of precise iteration counts or standardized metrics in this review.",
            "uuid": "e6941.1",
            "source_info": {
                "paper_title": "Evolution of AI in Education: Agentic Workflows",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "SELF-REFINE",
            "name_full": "SELF-REFINE (Iterative Refinement with Self-Feedback)",
            "brief_description": "A self-refinement framework where models produce initial outputs, generate self-feedback, and iteratively revise outputs to improve quality (used for feedback generation, code optimization, dialogue and essay refinement).",
            "citation_title": "SELF-REFINE: Iterative Refinement with Self-Feedback",
            "mention_or_use": "mention",
            "model_name": null,
            "model_description": null,
            "model_size": null,
            "reflection_method_name": "SELF-REFINE (self-feedback iterative refinement)",
            "reflection_method_description": "Generate an initial response, produce self-feedback (critique) about weaknesses and improvements, then use that feedback to produce a refined response; repeat as needed to incrementally improve output quality.",
            "iteration_type": "generate-then-reflect (recursive self-critique / iterative refinement)",
            "num_iterations": null,
            "task_name": "Feedback generation, automated essay scoring, dialogue generation, code optimization",
            "task_description": "Tasks where iterative polishing improves readability, correctness, or pedagogical usefulness; used to refine feedback and outputs over multiple passes.",
            "evaluation_metric": null,
            "performance_before_reflection": null,
            "performance_after_reflection": null,
            "improvement_observed": true,
            "limitations_or_failure_cases": "Iterative cycles are resource intensive which limits scalability in resource-constrained settings; potential to reinforce internal biases; privacy concerns when processing sensitive student data; exact iteration counts and standardized performance gains not reported in this review.",
            "uuid": "e6941.2",
            "source_info": {
                "paper_title": "Evolution of AI in Education: Agentic Workflows",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "DeepSeek",
            "name_full": "DeepSeek (open-source advanced reasoning model)",
            "brief_description": "An open-source model/framework that incorporates reinforcement learning and structured cognitive reasoning to iteratively refine outputs and integrate external feedback for complex problem-solving.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "DeepSeek (evaluated as DeepSeek 67b and DeepSeek 1.3b in experiments)",
            "model_description": "Open-source AI model claimed to include advanced reasoning and reinforcement-learning-based iterative refinement; used in the paper's benchmarks as stand-alone models.",
            "model_size": "67B; 1.3B",
            "reflection_method_name": "Iterative reasoning / reinforcement-guided self-refinement (as described)",
            "reflection_method_description": "Model architecture supports iterative refinement using reinforcement learning and incorporation of external feedback/prior knowledge to improve outputs over iterations (description provided by the authors/references).",
            "iteration_type": "iterative refinement (described conceptually); not clearly reported as applied in experiments",
            "num_iterations": null,
            "task_name": "Automated essay scoring (ASAP 2.0 benchmark) as a stand-alone model baseline in this paper",
            "task_description": "Holistic scoring of student argumentative essays on a 1–6 rubric (ASAP 2.0 dataset, ~17k essays).",
            "evaluation_metric": "Mean Absolute Error (MAE); standard deviation of error reported",
            "performance_before_reflection": "DeepSeek 67b MAE 0.7345; DeepSeek 1.3b MAE 1.6956 (stand-alone baselines, no reflection applied in the paper)",
            "performance_after_reflection": null,
            "improvement_observed": null,
            "limitations_or_failure_cases": "Stand-alone DeepSeek models showed higher MAE and high variability (especially 1.3b), indicating inconsistency in grading; the paper does not report application of DeepSeek's reflection capabilities in these experiments, so no before/after reflection comparisons are provided.",
            "uuid": "e6941.3",
            "source_info": {
                "paper_title": "Evolution of AI in Education: Agentic Workflows",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "MASS verification",
            "name_full": "MASS (Multi-Agent Scoring System) — verification / multi-report mechanism",
            "brief_description": "In-paper multi-agent verification mechanism where a lead agent synthesizes scores from specialized subagents and requests additional reports when subagent feedback diverges, serving as an ensemble/verification form of self-check.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4o (lead agent); subagents: specialized scoring agents",
            "model_description": "Multi-agent architecture built on GPT-4o where subagents independently evaluate content (content vs language mechanics) and a lead agent aggregates and conditionally requests additional reports when feedback diverges.",
            "model_size": null,
            "reflection_method_name": "Multi-agent verification / conditional multi-report request",
            "reflection_method_description": "Two specialized subagents independently score different essay aspects; the lead agent consolidates outputs and, if subagent reports diverge widely, it requests multiple additional reports from subagents to verify and refine the final score (an intra-system verification/consensus loop).",
            "iteration_type": "conditional multi-report verification (ensemble / verify-and-aggregate rather than repeated single-agent self-revision)",
            "num_iterations": null,
            "task_name": "Automated essay scoring on ASAP 2.0 dataset",
            "task_description": "Holistic scoring of student-written argumentative essays on a 1–6 rubric (ASAP 2.0, ~17,000 essays).",
            "evaluation_metric": "Mean Absolute Error (MAE); standard deviation of error; paired t-test and Wilcoxon signed-rank test p-values reported",
            "performance_before_reflection": "Stand-alone GPT-4o MAE 0.6129, Std Dev 0.9555",
            "performance_after_reflection": "MASS (multi-agent) MAE 0.5612, Std Dev 0.8295",
            "improvement_observed": true,
            "limitations_or_failure_cases": "Multi-agent verification increases token usage and processing time, raising computational cost and environmental impact; orchestration overhead and potential supervisor bottlenecks; paper notes need to minimize interactions while maintaining performance and warns of general multi-agent coordination challenges (possible inconsistencies if coordination breaks down).",
            "uuid": "e6941.4",
            "source_info": {
                "paper_title": "Evolution of AI in Education: Agentic Workflows",
                "publication_date_yy_mm": "2025-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing",
            "rating": 2,
            "sanitized_title": "critic_large_language_models_can_selfcorrect_with_toolinteractive_critiquing"
        },
        {
            "paper_title": "Reflexion: Language Agents with Verbal Reinforcement Learning Feedback",
            "rating": 2,
            "sanitized_title": "reflexion_language_agents_with_verbal_reinforcement_learning_feedback"
        },
        {
            "paper_title": "SELF-REFINE: Iterative Refinement with Self-Feedback",
            "rating": 2,
            "sanitized_title": "selfrefine_iterative_refinement_with_selffeedback"
        },
        {
            "paper_title": "Using Generative AI and Multi-Agents to Provide Automatic Feedback",
            "rating": 1,
            "sanitized_title": "using_generative_ai_and_multiagents_to_provide_automatic_feedback"
        },
        {
            "paper_title": "Agentic design patterns part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance",
            "rating": 1,
            "sanitized_title": "agentic_design_patterns_part_1_four_ai_agent_strategies_that_improve_gpt4_and_gpt35_performance"
        },
        {
            "paper_title": "DeepSeek",
            "rating": 1
        }
    ],
    "cost": 0.014897750000000001,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Evolution of AI in Education: Agentic Workflows</p>
<p>Firuz Kamalov 
Department of Electrical Engineering
Canadian University Dubai
DubaiUnited Arab Emirates</p>
<p>David Santandreu Calonge 
Centre for Teaching and Learning
Mohamed bin Zayed University of Artificial Intelligence
Abu DhabiUnited Arab</p>
<p>Emirates</p>
<p>Linda Smail 
College of Interdisciplinary Studies
Zayed University
DubaiUnited Arab Emirates</p>
<p>Dilshod Azizov 
Mohamed bin Zayed University of Artificial Intelligence
Abu DhabiUnited Arab Emirates</p>
<p>Dimple R Thadani 
Department of Management, Marketing, and Information Systems
Hong Kong Baptist University
Hong Kong SAR</p>
<p>Theresa Kwong 
Centre for Holistic Teaching and Learning
Hong Kong Baptist University
Hong Kong SAR</p>
<p>Amara Atif 
School of Computer Science
University of Technology Sydney
SydneyAustralia</p>
<p>Evolution of AI in Education: Agentic Workflows
FB7F344324B3E0E7892EFBECAF2FB5EEAI AgentsEducationArtificial IntelligenceAutomated Essay ScoringLLMGPTSustainability
Artificial intelligence (AI) has transformed various aspects of education, with large language models (LLMs) driving advancements in automated tutoring, assessment, and content generation.However, conventional LLMs are constrained by their reliance on static training data, limited adaptability, and lack of reasoning.To address these limitations and foster more sustainable technological practices, AI agents have emerged as a promising new avenue for educational innovation.In this review, we examine agentic workflows in education according to four major paradigms: reflection, planning, tool use, and multi-agent collaboration.We critically analyze the role of AI agents in education through these key design paradigms, exploring their advantages, applications, and challenges.To illustrate the practical potential of agentic systems, we present a proof-of-concept application: a multi-agent framework for automated essay scoring.Preliminary results suggest this agentic approach may offer improved consistency compared to stand-alone LLMs.Our findings highlight the transformative potential of AI agents in educational settings while underscoring the need for further research into their interpretability, trustworthiness, and sustainable impact on pedagogical impact.</p>
<p>Introduction</p>
<p>Artificial intelligence (AI) has rapidly evolved in recent years, increasingly permeating various aspects of modern society, including education.The emergence of large language models (LLMs) has particularly expanded AI's capabilities, creating opportunities to develop educational tools that not only enhance learning outcomes but also raise awareness of sustainable practices.Early applications in education largely relied on foundational models such as GPT or their fine-tuned variants (ChatGPT).While these models facilitated notable advancements in instruction and student support, they also operated under inherent constraints-limited adaptability, lack of nuanced reasoning, and reliance on static training data-that underscore the importance of ongoing research into sustainable, responsible AI innovations.</p>
<p>A new generation of AI technologies seeks to overcome the limitations of the foundational models through the development of AI agents that function autonomously.AI agents utilize reflection, planning, and a wide range of tools to perform tasks with minimal human intervention.At the core of most AI agents lie sophisticated LLMs; however, their agentic layer distinguishes them from traditional systems by enabling more complex capabilities and autonomy.Specifically, agentic design leverages real-time information retrieval and dynamic task decomposition, reducing the reliance on dated or incomplete training data.As a result, AI agents are able to outperform stand-alone LLMs on numerous benchmark evaluations (Hong et al., 2024;Wu et al., 2024), demonstrating the considerable promise of agentic workflows in education (Guo et al., 2024).</p>
<p>Although the implementation of AI agents within educational settings has begun to be investigated (Yusuf et al., 2025;Dai et al., 2024), their integration into educational settings requires careful examination and strategic implementation.Educational tasks require robust, trustworthy, and interpretable systems.Further research is needed to determine how AI-driven agents influence different learning environments, student populations, and pedagogical methods.</p>
<p>The primary goal of this paper is to provide a comprehensive review of existing AI agentic paradigms within the context of education.We focus on four major design paradigms: 1) reflection, 2) planning, 3) tool use, and 4) multi-agent collaboration.These paradigms are "crucial for boosting LLM productivity and enhancing performance" (Singh et al., 2024, p.1).We first describe each paradigm individually, discussing their conceptual foundations and respective advantages, practical applications, and associated challenges within educational contexts.Our analysis provides a comprehensive understanding of how these paradigms can effectively leverage AI agents to overcome the limitations of conventional large language models.</p>
<p>To further illustrate the potential of an agentic approach in education, we present a proof-of-concept application: a multi-agent system designed for automated essay scoring (MASS).The results show that our proposed agentic framework achieves increased consistency and reliability in evaluating written work compared to stand-alone LLMs (https://github.com/AzizovDilshod/Multi-agent-System-for-Essay-Assessment/tree/main).</p>
<p>The rest of the manuscript is organized as follows.In Section 2, we provide a conceptual overview of AI agents and agentic workflows.Crucially, we propose our categorization of agentic workflows in education in terms of four major paradigms (Figure 2.4).Section 3, describes the structured literature review methodology used to analyze the role and potential of AI agentic workflows in education.Our findings are synthesized narratively within Section 4, dedicating a subsection to each paradigm.Section 5 details our proposed multi-agent system for automated essay scoring, outlining its architecture, implementation, and empirical results.Finally, Section 6 concludes with a discussion on the limitations of existing approaches and directions for future work in advancing agentic solutions for education.</p>
<p>2 Background: AI Agents and Agentic Workflows An AI agent can be defined as a system that utilizes an LLM as its core reasoning engine to determine the control flow of an application, interacting with its environment to achieve specific goals (Wang et al., 2023a;Xi et al., 2023).An agentic workflow refers to the structured process through which such autonomous or semi-autonomous agents operate.Unlike traditional LLMs, which are often constrained by the static knowledge embedded during training, AI agents are designed for dynamic interaction.They can actively retrieve real-time information, utilize various tools (e.g., calculators, databases, web search), and employ reasoning strategies to execute complex tasks (Fig. 2.1).This capacity for autonomous action with limited human intervention makes agentic workflows a powerful paradigm for building sophisticated LLM-based applications.</p>
<p>Fig. 2.1</p>
<p>In the basic agentic workflow, the agent interacts with its environment based on its goals and abilities.</p>
<p>The shift towards agentic systems is partly driven by the evolving landscape of AI development.While past progress in LLMs was fueled by scaling data and computation, limitations in data availability and computational resources are encouraging a focus on enhancing inference-time performance (Zeng et al., 2024).Techniques such as chain-of-thought prompting, self-consistency, ReAct (Reasoning and Acting), and reflection, which are often incorporated into agentic workflows, have been significant drivers of recent performance improvements (Wei et al., 2022;Yao et al., 2023;Shinn et al., 2023).</p>
<p>Evidence suggests that agentic systems can outperform their stand-alone LLM counterparts across various domains.For example, benchmark results on tasks like HumanEval show significant performance gains when agentic frameworks are built upon base models like GPT-3.5 and GPT-4 (Fig. 2.2) (Ng, 2024).Similar improvements have been observed in coding benchmarks like TransCoder and MBPP (Zhong et al., 2024).In education, preliminary studies indicate that agentic systems can enhance tasks such as automated scoring (Lee et al., 2024;Guo et al., 2024), demonstrating the potential of these approaches within the educational domain.</p>
<p>Fig. 2.2</p>
<p>Performance of GPT 3.5 and GPT-4 (zero-shot) on HumanEval along with agentic frameworks built on top of GPT (Ng, 2024).</p>
<p>Conceptually, AI agents are forming a distinct "application" layer in the evolving AI technology stack (Fig. 2.3).While foundational models, cloud infrastructure, and hardware remain crucial, the agent layer focuses on orchestrating these components to execute complex, goal-oriented tasks, abstracting underlying complexity and enabling more seamless user interaction.Fig. 2. 3 The new AI stack featuring the emerging layer of Applications.</p>
<p>Agentic Workflow</p>
<p>A general agentic workflow often involves several key phases, though specific implementations vary:</p>
<ol>
<li>Planning: The agent receives a goal, decomposes it into smaller, manageable sub-tasks, and sequences these tasks.2. Information Retrieval/Tool Use: The agent identifies information needs for each sub-task and utilizes available tools (e.g., web search, databases, APIs, other agents) to gather necessary data or perform specific actions.</li>
</ol>
<p>Task Execution &amp; Refinement:</p>
<p>The agent executes the planned tasks, monitors progress, potentially reflects on outcomes or feedback, and dynamically adjusts the plan or generates new tasks as needed until the overall goal is achieved.</p>
<p>The degree of "agenticness" can vary widely, from a simple system using a single tool to complex multi-agent collaborations.As the technology matures, agents are expected to become increasingly autonomous and capable (e.g., OpenAI's advancements, DeepSeek-R1).</p>
<p>Four major paradigms underpin many current agentic approaches (Ng, 2024;Singh et al., 2024), as shown in Figure 2.4:</p>
<ol>
<li>Reflection: The agent analyzes its past actions or outputs to identify errors or areas for improvement and refine its future behavior.2. Planning: The agent explicitly creates and follows a sequence of steps or sub-goals to achieve a complex objective.3. Tool Use: The agent leverages external resources or functions (e.g., calculators, code execution, web search, APIs) to augment its capabilities.4. Multi-agent Collaboration: Multiple specialized agents work together, communicating and coordinating their actions to achieve a common goal.</li>
</ol>
<p>These paradigms, which form the basis of our review in Section 4, represent distinct but often complementary strategies for building effective AI agents.</p>
<p>AI Agent Platforms</p>
<p>Several platforms facilitate the development and implementation of agentic systems, such as AutoGen, CrewAI, LangGraph, MetaGPT, and Phidata (Table 2.1).These frameworks provide varying levels of structure, flexibility, and support for different agent architectures, enabling researchers and practitioners (including educators) to build custom agent-based applications.</p>
<p>Literature Search Strategy</p>
<p>A systematic search was conducted across major academic databases, including Google Scholar, Scopus, Web of Science, and the ACM Digital Library.Search terms included combinations and variations of primary keywords such as "AI agents," "agentic workflows," "large language models," and "education," combined with paradigm-specific terms like "reflection," "planning," "tool use," "multi-agent systems," "autonomous agents," "agentic AI," and related concepts (e.g., "ReAct," "Reflexion," "chain-of-thought," "CRITIC," "SELF-REFINE").</p>
<p>Application-specific terms such as "automated tutoring," "personalized learning," "educational simulation," "automated scoring," and "adaptive learning" were also used to capture relevant educational contexts.</p>
<p>Selection Criteria and Scope</p>
<p>The review focused on publications primarily from 2020 to 2024, capturing the rapid advancements following the widespread adoption of powerful LLMs.Given the fast-paced nature of AI agent research, the selection included peer-reviewed journal articles and conference proceedings, alongside significant and highly cited arXiv preprints which constitute a substantial portion of the cited works ( In total, approximately 93 sources were identified and synthesized for the core of this review.</p>
<p>Papers were included if they met the following criteria:</p>
<p>• Discussed the concepts, mechanisms, or architectures of AI agents or agentic workflows.</p>
<p>• Focused on one or more of the four target paradigms (reflection, planning, tool use, multi-agent collaboration).</p>
<p>• Applied or discussed the potential application of these agentic paradigms within educational settings (higher education, K-12, professional training) or addressed tasks directly relevant to education (assessment, feedback, tutoring, simulation).</p>
<p>• Addressed the advantages, challenges, or ethical considerations of using AI agents in education.</p>
<p>Papers were excluded if they focused solely on foundational LLM capabilities without an agentic layer, dealt with AI applications in education unrelated to agentic workflows (e.g., traditional machine learning for prediction), were not available in English, or were primarily commercial advertisements lacking technical or conceptual depth.</p>
<p>Analysis Framework</p>
<p>The selected literature was analyzed using a framework structured around the four core paradigms.For each paradigm, the analysis focused on extracting and synthesizing information related to:</p>
<p>Synthesis and Presentation</p>
<p>The findings were synthesized narratively within Section 4, dedicating a subsection to each paradigm.Tables were used to summarize key studies (e.g., Table 4</p>
<p>Agentic Paradigms in Education</p>
<p>As outlined in Section 2, agentic workflows can be broadly categorized into four key paradigms: reflection, planning, tool use, and multi-agent collaboration.This section reviews each paradigm, discussing its foundations, specific roles and applications in education, and associated challenges.</p>
<p>Reflection Systems</p>
<p>AI-driven Reflection systems are designed to enable agents to evaluate their performance, identify areas for improvement, and iteratively refine their approaches to achieve tasks more effectively.By continually monitoring and adjusting strategies, these systems embody principles of sustainable growth-where perpetual learning and responsible resource use guide progress.This paradigm aligns closely with foundational principles from the science of learning, particularly those emphasizing the importance of metacognition and active engagement in learning processes (Kosslyn, 2017).In educational contexts, reflection systems offer transformative potential not only by fostering adaptive learning experiences and enhancing teaching methodologies and student outcomes but also by promoting awareness of sustainable practices.Through iterative feedback loops, such systems can encourage learners and educators alike to consider long-term impacts, optimize resource utilization, and integrate environmental stewardship into the learning process.</p>
<p>These systems incorporate mechanisms that allow AI agents to assess their actions retrospectively, drawing lessons from successes and failures.Inspired by human cognition, these systems employ methods such as performance analysis, error detection, and strategic adaptation.Central to this is the concept of "deep processing," wherein the deliberate examination of processes and outcomes enhances understanding and memory retention (Kosslyn, 2017).For AI agents, this means leveraging past experiences to refine their strategies, leading to improved task execution.</p>
<p>Reflection systems in AI often use frameworks such as reinforcement learning and causal reasoning to model the effects of decisions and/or actions in achieving desired outcomes.</p>
<p>Recent advancements in agentic design patterns emphasize the value of structured reflection to optimize task planning, execution, and adaptability (DeepLearning.ai,2024).By implementing self-assessment loops, AI agents can iteratively improve their responses to complex challenges, demonstrating enhanced capabilities over time.</p>
<p>Mechanisms of Reflection Systems</p>
<p>Reflection systems are underpinned by several key mechanisms that define their functionality and potential.These mechanisms include interactive feedback loops, verbal reinforcement, and external verification and self-correction.Each mechanism provides a distinct but complementary pathway for enabling AI agents to reflect, learn, and adapt.These mechanisms build on both internal evaluation processes and external tools, creating a hybrid structure to address diverse challenges such as error detection, adaptability, and knowledge gaps.Together, they enable AI agents to iteratively analyze their outputs, refine their processes, and adjust their strategies with increasing autonomy and accuracy.</p>
<p>Interactive Feedback</p>
<p>Modern advancements in reflection systems focus on integrating external feedback mechanisms, such as the CRITIC framework (Gou et al., 2024).CRITIC represents a cutting-edge approach to reflection systems by empowering AI agents to self-correct through tool-interactive critiquing.This framework enables LLMs to validate and refine their outputs by engaging with external tools, including search engines, code interpreters, and calculators.By mimicking human behaviors of cross-referencing and interactive improvement, CRITIC enhances the ability of AI systems to identify and address errors in real-time.</p>
<p>A key feature of CRITIC is its "verify-then-correct" cycle, where external tools are used to evaluate the accuracy, coherence, and reliability of the AI's initial outputs.Based on critiques generated through these interactions, the AI refines its responses in iterative loops.This method mirrors the metacognitive processes of self-assessment and strategic adaptation found in human cognition.For example, in tasks such as free-form question answering, CRITIC leverages search engines to verify factual accuracy.In mathematical reasoning, it employs code interpreters to validate the logic and correctness of programmatic solutions.Additionally, CRITIC has demonstrated its effectiveness in reducing toxicity in content generation by utilizing external evaluation tools to identify and mitigate harmful language.</p>
<p>The integration of CRITIC into reflection systems marks a significant evolution in AI design by emphasizing the importance of external feedback as a complement to internal processing.</p>
<p>Traditional reflection systems rely primarily on self-generated assessments, which can be limited by the model's inherent knowledge gaps or biases.CRITIC addresses this limitation by incorporating external sources of truth, creating a hybrid system that combines the strengths of internal metacognitive processes with the objectivity of external validation.This hybrid approach has proven to yield substantial improvements in both accuracy and adaptability across a variety of tasks where precise and unbiased outputs are essential, such as generating financial models or scientific analyses.</p>
<p>Verbal Reinforcement</p>
<p>Frameworks like Reflexion (Shinn et al., 2023) utilize verbal reinforcement to guide agents in self-improvement.Reflexion agents process feedback as episodic memory, enabling them to iteratively adjust their actions and strategies, achieving state-of-the-art performance in diverse domains such as decision-making, reasoning, and programming (Shinn et al., 2023).Reflexion's key innovation lies in its ability to transform binary or scalar feedback into detailed, actionable insights that are stored as long-term memory.This memory enables agents to recognize patterns of errors and adapt their approaches over multiple iterations, significantly enhancing performance across various tasks, including sequential decision-making and complex reasoning.</p>
<p>Beyond theoretical advancements, Reflexion has shown particular promise in multi-step logical reasoning tasks, where verbal reinforcement allows agents to identify and address gaps in their reasoning chains.This mechanism is also critical in areas where adaptability is required, such as debugging software or conducting multi-stage workflows involving dependency tracking.A unique aspect of SELF-REFINE is its ability to achieve significant performance gains with minimal computational resources.For instance, in code optimization tasks, SELF-REFINE not only improves efficiency but also enhances readability by iteratively refining algorithms based on self-provided feedback.Similarly, in dialogue generation, it transforms generic or incomplete responses into engaging and contextually appropriate conversations.This iterative capability is particularly effective in workflows where incremental improvement is vital, such as creating high-quality translations, polishing creative writing, or refining policy documents.</p>
<p>A new innovative addition to reflection systems is the integration of advanced reasoning frameworks such as DeepSeek (DeepSeek-R1), an open-source AI model designed for complex problem-solving.DeepSeek employs reinforcement learning and cognitive reasoning strategies, enabling it to iteratively refine its output and perform tasks with heightened precision.These capabilities are especially relevant to reflection systems, where iterative feedback and self-correction are central to improving performance over time.</p>
<p>DeepSeek ability to incorporate external feedback and prior knowledge aligns with the goals of reflection systems in education.For instance, its structured reasoning framework can enhance the functionality of educational tools by analyzing student responses, identifying logical inconsistencies, and refining explanations or feedback to better support learning objectives.This mirrors the iterative refinement seen in frameworks like CRITIC and SELF-REFINE but expands on them by incorporating a broader range of reasoning and external validation mechanisms.</p>
<p>By leveraging advanced reasoning, DeepSeek could strengthen reflection systems' capacity to adapt to diverse educational contexts.Its open-source nature also lowers barriers to implementation, providing a flexible platform for integrating reflection capabilities into intelligent tutoring systems, automated grading tools, or collaborative learning environments.DeepSeek exemplifies how cutting-edge AI models can deepen the scope of reflection systems by incorporating sophisticated reasoning, thereby promoting accuracy and adaptability in educational applications.</p>
<p>The combination of CRITIC, Reflexion, SELF-REFINE, and DeepSeek showcases the evolution of reflection systems in AI.Together, these frameworks highlight the transformative potential of integrating internal and external feedback mechanisms, enabling AI agents to achieve higher levels of adaptability, accuracy, and reliability.These mechanisms collectively drive innovation across technical and creative domains, demonstrating the potential of reflection systems to redefine complex problem-solving and iterative improvement tasks.As reflection systems continue to advance, their applications in education are likely to expand, fostering more intelligent and human-like AI systems.</p>
<p>Reflection Systems in Education</p>
<p>In the field of education, reflection systems have emerged as transformative tools, offering new opportunities to enhance teaching, learning, and assessment.By leveraging iterative feedback, verbal reinforcement, and external verification &amp; self-correction mechanisms, these systems enable AI-driven tools to provide dynamic, personalized, and effective educational experiences.</p>
<p>Reflection systems are increasingly employed in intelligent tutoring systems (ITS), where they enable real-time adaptation to student needs.These systems monitor student interactions, detect areas of struggle, and refine instructional strategies accordingly.For example, an ITS powered by frameworks like SELF-REFINE analyzes student errors in mathematics and iteratively adjusts its explanations, tailoring them to the learner's understanding.This approach not only deepens comprehension but also fosters metacognitive practices by prompting students to reflect on their problem-solving strategies (Rouzegar &amp; Makrehchi, 2024;Madaan et al., 2023).</p>
<p>Another promising application is in feedback generation and refinement.Reflection systems such as SELF-REFINE iteratively enhance feedback quality, making it more actionable and personalized.For example, in automated essay scoring, these systems provide detailed critiques on grammar, structure, and argumentation, enabling students to refine their writing over multiple revisions.By aligning with principles of deliberate practice, where iterative feedback drives skill acquisition, these systems contribute to long-term learning and improvement (Madaan et al., 2023).</p>
<p>Reflection systems also play a vital role in collaborative learning environments, where they enhance group dynamics and ensure equitable participation.AI agents embedded in group projects analyze patterns of engagement, identify disparities in contributions, and recommend interventions to balance collaboration.For instance, tools based on Reflexion can monitor the flow of a group discussion, highlight under-participating members, and suggest prompts to ensure their active involvement (Shinn et al., 2023).These capabilities align with collaborative pedagogical practices, fostering accountability and collective success.</p>
<p>In addition, reflection systems are instrumental in promoting metacognitive skills among learners.By tracking attention, engagement, and learning behaviors, these systems encourage students to reflect on their strategies and optimize their performance.For example, platforms integrating CRITIC can analyze a student's engagement with learning materials and suggest adjustments to improve focus and retention.This reflective feedback helps learners develop self-regulation and deeper awareness of their learning processes (Cukurova, 2024;Gou et al., 2024).</p>
<p>In automated grading, reflection systems are utilized to ensure fairness and accuracy in assessments.By cross-referencing student responses with validated sources, these systems refine grading algorithms to minimize bias and errors.For instance, frameworks like CRITIC incorporate external tools such as search engines and knowledge graphs to validate grading decisions, ensuring consistency and objectivity.This iterative refinement process addresses common challenges in large-scale assessments, where uniformity and reliability are critical (Gou et al., 2024;Yesilyurt, 2023).</p>
<p>Educational simulations also benefit from reflection systems, which enable students to practice real-world skills in immersive, AI-driven environments.In tools like PitchQuest, a multi-agent educational simulation, reflection mechanisms allow students to refine their performance through iterative feedback from AI-generated mentors and evaluators.These systems provide tailored guidance, fostering experiential learning and skill development in simulated settings (Mollick et al., 2024).</p>
<p>Similarly, the EduAgent framework leverages generative AI to simulate student behaviors in educational environments, enabling both instructors and AI systems to refine their instructional methods.This system models diverse student personas, providing dynamic interactions that help educators test and optimize learning strategies.By incorporating reflection mechanisms, EduAgent can iteratively adapt its simulations based on real-time performance data, ensuring that interactions remain realistic and pedagogically effective.Such advancements highlight the role of generative AI in creating more adaptable and reflective learning simulations (XU et al., 2024).</p>
<p>DeepSeek further enriches the potential of reflection systems in education by introducing advanced reasoning capabilities tailored to complex educational settings.DeepSeek enables systems to analyze nuanced student behaviors, refine instructional strategies, and provide personalized feedback.For example, DeepSeek can identify logical inconsistencies in a student's problem-solving approach and refine its explanations iteratively to enhance conceptual understanding.Its reinforcement learning framework supports dynamic adaptability, making it an invaluable tool for addressing individual differences in student learning styles and progress (Romero, 2024, DeepSeek, 2024).</p>
<p>By integrating DeepSeek reasoning capabilities, reflection systems can advance the development of educational simulations and ITS platforms, where real-time evaluation and adjustment are critical.This includes applications in automated essay scoring, where the system assesses nuances such as argument coherence and writing style.Moreover, DeepSeek's ability to adaptively model complex behaviors enables it to simulate realistic student personas, enriching teacher training and curriculum testing environments.</p>
<p>Reflection systems in education are a powerful means of personalizing instruction, fostering metacognition, and improving collaborative learning.As these systems continue to evolve, they will play a central role in creating adaptive, intelligent learning environments that align with the diverse needs of students and educators.</p>
<p>Planning Systems</p>
<p>To fully harness the power of LLMs in education, it is crucial to explore and implement agentic design patterns that enable AI agents to autonomously select options, plan, process, revise, solve, and execute complex tasks.By decomposing these complex tasks into smaller, more manageable subtasks-often involving interaction with external tools and resources ( In decomposition, the LLM fully decomposes the primary task first into a set of constituent sub-tasks.Subsequently, the LLM generates independent sub-plans for each of these sub-tasks, outlining the specific actions required for their fulfillment before execution starts.Finally, these sub-tasks are executed sequentially, ensuring the completion of each sub-task in a predetermined order until the overarching task is achieved (Singh, 2024;Xu et al., 2023).</p>
<p>In the interleaved approach, decomposition, planning, and execution are intricately intertwined.Rather than conducting a complete initial decomposition of the overarching task, the LLM Agent commences with a partial decomposition, typically focusing on an initial sub-task.Concurrently, planning and execution pertaining to this sub-task are initiated.As each sub-task is addressed, the agent dynamically adapts by identifying and incorporating newly recognized sub-tasks into the planning and execution process.The iterative cycle of decomposition, planning, and execution fosters a degree of flexibility, enabling the agent to effectively respond to unforeseen environmental complexities or emergent changes (Singh, 2024;Xu et al., 2023).The two prominent approaches to enhance the planning process are usually referred to as ReACT and ReWOO in the literature (Xu et al., 2023).</p>
<p>ReACT is a framework that emphasizes the iterative interplay between reasoning and acting.It involves the following steps:(1) Reasoning: The agent analyzes the current situation, identifies potential actions, and predicts their outcomes; (2) Acting: The agent executes the chosen action, interacting with the environment; (3) Observing: The agent perceives the consequences of its action, updating its understanding of the world; and (4) Reflecting: The agent evaluates the outcome, adjusts its plan if necessary, and repeats the cycle.</p>
<p>In ReWOO, the agent can leverage a broader range of knowledge and context to inform its decision-making.The key steps in ReWOO are: (1) The planner generates a comprehensive plan, considering various possibilities and constraints; (2) The generated plan instructs the worker to interact with the environment, use tools, and collect evidence.The worker adapts/adjusts the plan in real-time based on new information or changing circumstances; and</p>
<p>(3) The solver receives the full plan and generates the final response.There is a strong connection between the interleaved approach in ReWOO and the concept of interleaving in cognitive load theory.Both approaches emphasize the benefits of mixing things up.In cognitive load theory, it is about mixing practice; in ReWOO, it is about mixing planning, execution, and decomposition.</p>
<p>Both aim to enhance performance by challenging the student/agent.Interleaving in cognitive load theory challenges students to discriminate between concepts, while the interleaved approach in ReWOO challenges the agent to adapt to a dynamic environment.Cognitive load theory focuses on how the human brain processes information (Hultberg et al., 2018), while the interleaved approach in ReWOO focuses on the agent's decision-making process and its interaction with the environment.</p>
<p>In essence, both interleaving approaches share the underlying principle of breaking down rigid structures and introducing flexibility to improve performance.In cognitive load theory, this flexibility enhances learning and memory, while in ReWOO, it enhances an agent's ability to navigate and adapt to complex situations.</p>
<p>Planning systems are, therefore, a critical component of AI agents, enabling them to (1) Define clear objectives/goals/outcomes for the agent's actions; (2) Generate Plans and create a sequence of actions to achieve the goals; and (3) Execute the planned actions, "accomplish a task end-to-end" (Masterman et al., 2024, p.1), monitoring progress and adapting as needed.</p>
<p>In terms of planning, agentic planning systems can be categorized into the following five categories, as shown in</p>
<p>Simple Planners</p>
<p>Simple Planners can perform basic planning by breaking down simple tasks into a sequence of actions.They may use simple search algorithms or rule-based systems to generate plans.However, they lack the ability to handle complex or dynamic environments.</p>
<p>Goal-Oriented Planners</p>
<p>Goal-Oriented Planners can define and pursue specific goals.They can generate and execute plans to achieve these goals, considering constraints and available resources.They may also be able to adapt their plans based on feedback or unexpected events.</p>
<p>Learning Planners Learning Planners can learn from past experiences and improve their planning capabilities over time.They can adapt their planning strategies based on successes and failures, leading to more efficient and effective plans.(e.g.WebAgent, Gur et al., 2023)</p>
<p>Self-Improving Planners</p>
<p>Self-Improving Planners can not only learn from past experiences but also actively seek out new information and knowledge to improve their planning capabilities.They can continuously refine their planning algorithms and strategies, leading to increasingly sophisticated and autonomous behavior.</p>
<p>The planning process is shown in Figure 4. • This goal provides direction for the planning process.</p>
<p>Data Analysis &amp; Understanding:</p>
<p>• The input data is processed using machine learning to identify patterns and gather insights.</p>
<p>Action Modeling:</p>
<p>• The agent identifies potential actions that can be taken to move toward the goal 4. Plan Generation:</p>
<p>• The agent uses a planning algorithm (e.g., search algorithms like depth-first search, breadth-first search, or A* -heuristic search) to explore possible sequences of actions, considering constraints and possible outcomes.</p>
<p>Refinement &amp; Simulation:</p>
<p>• The agent may refine the plan based on feedback or new information, simulating outcomes to ensure efficiency and effectiveness.</p>
<p>Execution &amp; Monitoring:</p>
<p>• The agent executes the chosen plan, carries out the sequence of actions, and monitors its performance.7. Learning &amp; Feedback:</p>
<p>• The agent learns from the outcomes and feedback (loop), improving its planning capabilities for future tasks.</p>
<p>The planning process, which involves the formulation of a sequence of actions to achieve specific goals, holds significant potential for transforming educational practices and outcomes.By leveraging the structured, adaptive, and goal-oriented nature of AI planning, educators can create personalized learning experiences, design curricula, optimize resource allocation, and enhance decision-making processes in educational settings.AI planning systems, which are designed to solve complex problems by breaking them down into manageable steps, can be applied to curriculum design, individualized learning pathways, and administrative tasks, thereby addressing some of the most pressing challenges in education today.</p>
<p>One of the most promising applications of AI planning in education is the development of personalized learning experiences (Kaswan et al., 2024;Sajja et al., 2024).Current educational models often adopt a one-size-fits-all approach, which fails to account for the unique learning preferences and paces of individual students.AI planning agents can address this limitation by analyzing vast amounts of data on student performance, engagement (in class or online), and behavior to create customized learning plans.For instance, an AI system can assess a student's strengths and weaknesses in a particular subject, identify gaps in knowledge, and generate a tailored sequence of learning activities to address those gaps (Kikalishvili, 2024).This adaptive learning process ensures that students receive targeted support and challenges, thereby maximizing their learning potential (Kabudi et al., 2021).Moreover, AI planning can dynamically adjust these learning pathways in real-time based on ongoing assessments, ensuring the educational experience remains relevant and effective as students progress (Hyper-personalization). Research by Copyleaks (2024) indicated that 87% of educators and 78% of students believed that AI could revolutionize education through personalized learning experiences.</p>
<p>AI planning agents can further enhance personalization by generating detailed, constantly updated journey maps and reports for individual students or cohorts.These journey maps analyze and visualize the digital and physical multi-touchpoint experiences of students from enrollment to graduation, using techniques such as knowledge tracing (Shehata et al., 2023) and predictive modeling based on academic results, GPA, interests, selected study programs, study plans, and academic advisors' reports.Such comprehensive views of student journeys enable institutions to identify critical interaction points, align academic programs and support services with evolving student needs, facilitate collaboration across institutional departments, and support data-driven decision-making for recruitment, engagement, retention, and alumni relations.</p>
<p>In Despite its numerous advantages, the implementation of AI planning in education is not without challenges.One of the primary concerns is the ethical use of data, as AI systems rely on vast amounts of personal information to function effectively.Ensuring the privacy and security of student data is paramount, and institutions must establish robust policies and safeguards to protect sensitive information.Additionally, there is a risk of algorithmic bias (Chan, 2023), where AI systems may inadvertently perpetuate existing inequalities or reinforce stereotypes.To mitigate/minimize this risk, it is essential to develop AI planning models that are transparent, accountable (Habbal et al., 2024), and regularly audited for fairness.</p>
<p>In conclusion, the planning process in AI agents offers a powerful framework for addressing some of the most pressing challenges in education, from personalizing learning experiences to optimizing resource allocation and enhancing decision-making.By leveraging the structured, adaptive, and goal-oriented nature of AI planning, educators can create more effective, efficient, and equitable educational systems.However, realizing the full potential of AI planning in education requires careful consideration of ethical, technical, and practical issues, as well as a commitment to fostering collaboration and innovation among all stakeholders.</p>
<p>Tool-use systems</p>
<p>In the domain of AI agents, the concept of "tools-use" refers to any functions or capabilities that the model can utilize to enhance its performance (Dwivedi et al., 2021).These tools enable agents to interact with external data sources, thereby facilitating the flow of information by retrieving or sending data and information to these sources.For instance, an AI agent designed as an educational tutor for high school mathematics.This persona is equipped with a deep understanding of mathematical concepts and the specific tasks it must accomplish, along with a suite of tools that facilitate various functions.These tools may include a graphing calculator for visualizing complex equations, a database of educational resources for providing supplementary materials, and a communication interface for sending personalized feedback to students via email or a messaging platform.The agent can analyze a student's performance on practice problems, identify areas of difficulty, and then use its tools to generate tailored practice exercises or recommend videos and articles that explain challenging concepts.</p>
<p>A notable benefit of adopting an agent-based approach, as opposed to relying solely on prompting-based language models, lies in the agents' ability to address complex problems through the coordinated application of multiple tools (Shinn et al., 2023).Such tools empower agents to engage with external data sources, interact with existing APIs, and execute a variety of functions that significantly enhance their problem-solving capabilities.Tasks that necessitate extensive tool utilization are often intertwined with those that require intricate reasoning.Both single-agent and multi-agent architectures can effectively tackle challenging tasks by integrating reasoning and tool-calling mechanisms.</p>
<p>Many methodologies involve iterative processes of reasoning, memory utilization, and reflection to navigate and resolve problems with efficacy (Shinn et al., 2023;Shin et al., 2024).This often involves decomposing larger issues into smaller, more manageable subproblems that can be addressed sequentially using the appropriate tools, as explained above.Prior research (i.e., Dwivedi et al., 2021;Yao et al., 2023;Gao, 2024) indicates that while breaking down complex problems into smaller components can facilitate effective solutions, single-agent patterns frequently encounter challenges when faced with the lengthy sequences of actions required to complete these tasks.</p>
<p>4.3.1.Components and Mechanisms of Tool-Use Systems</p>
<p>The tool-use components and mechanisms in AI agents are fundamental for enabling dynamic interactions with external data sources and functionalities.This mechanism allows agents to execute complex tasks by leveraging various tools, thereby enhancing their capabilities to provide accurate and contextually relevant outputs.The following table summarizes the basic components and Processes of Tool-use in AI agents.</p>
<p>Components Processes described</p>
<p>Prompting and Tool Invocation The agent initiates tool use through specially formatted requests.</p>
<p>Upon recognizing strings, a post-processing component triggers the appropriate tool, executes the function, and returns the results for further processing.</p>
<p>Iterative Reasoning</p>
<p>The tool use mechanism often involves iterative reasoning, where the agent reflects on previous outputs and adjusts its approach based on the information retrieved from external sources.</p>
<p>Content Management</p>
<p>Context management is crucial when multiple tools are available.The agent must determine the most relevant tools for the current task, often employing heuristics to prioritize tool selection.</p>
<p>Multi-Agent Collaboration-ready tool</p>
<p>In complex scenarios, multiple agents may collaborate, each employing specialized tools to address subproblems.This enhances efficiency and allows for parallel processing of tasks.</p>
<p>The tool use mechanism in AI agents encompasses several key components and processes that enhance their functionality (see Table 4.3).Prompting and Tool Invocation begins the process, where the agent initiates tool use through specially formatted requests.Upon recognizing these strings, a post-processing component activates the appropriate tool, executing the designated function and returning results for further analysis.This leads to Iterative Reasoning, where the agent reflects on previous outputs, adjusting its approach based on new insights gained from external sources.Effective Content Management is essential as well, especially when multiple tools are available; the agent must discern the most relevant tools for the current task, often utilizing heuristics to prioritize tool selection.Finally, in more complex scenarios, multi-agent collaboration comes into play, allowing multiple agents to work together, each leveraging specialized tools to tackle subproblems.This collaborative approach not only enhances efficiency but also facilitates parallel processing of tasks, resulting in a more robust and adaptive system.</p>
<p>Indeed, "tools" are specific functions or capabilities that the AI agent can invoke.Each tool corresponds to a goal followed by an action, such as retrieving data, performing calculations, or interacting with third-party applications.-"Visualize the class composition with simple statistics and figures"</p>
<p>Tool Selection</p>
<p>The agent evaluates available tools based on the task's context and formulates a plan for invoking the necessary functions</p>
<p>• Web-search (e.g.Google Search API for retrieving current information) • SMTP Email Sender for sending automated emails • OpenCV Library for performing image recognition • SQL Database Connector to retrieve user-specific information.</p>
<p>Execution of Tool Functions</p>
<p>The agent constructs tool invocation strings and executes the associated functions</p>
<p>• Sending requests to APIs (e.g., Twitter API for social media interactions).• Code execution tool: executing Python code</p>
<p>Data Processing and Reflection</p>
<p>Once the tools return results, the agent processes the incoming data, incorporating it into its understanding of the task.The agent may then reflect on this information, iterating its reasoning to refine its output.</p>
<p>• Pandas: A library for data manipulation and analysis in Python.An AI agent can use Pandas to clean, transform, and analyze datasets.• NumPy: A library for numerical computing in Python.An agent can utilize NumPy for performing mathematical operations on large arrays and matrices.• Apache Spark: A unified analytics engine for large-scale data processing.An AI agent can use Spark to handle big data processing tasks efficiently.</p>
<p>Output Generation</p>
<p>The agent synthesizes the information gathered through tool use and generates a coherent response or action.This output is informed by both the initial task and the insights gained from the tools The operational framework of AI agents (see Table 4.4) involves a series of structured steps designed to effectively address user tasks through tool utilization.Tool Initiation marks the beginning of this process, as the agent receives a task or query that necessitates tool use.For example, a user might prompt the agent with, "Who is the program leader of XXX in the University of YYY, analyze his/her publications, and send a Happy New Year email to her, wishing him/her good luck in her career," or "Visualize the class composition with simple statistics and figures."Following this, in the Tool Selection phase, the agent evaluates the context of the task and formulates a plan for invoking the necessary functions, considering tools such as the Google Search API for retrieving current information, SMTP Email Sender for sending automated emails, OpenCV Library for performing image recognition, and SQL Database Connector for accessing user-specific data.In the Execution of Tool Functions step, the agent constructs tool invocation strings and executes the associated functions, which may include sending requests to APIs like the Twitter API for social media interactions or executing Python code for data analysis.After the tools return results, the agent enters the Data Processing and Reflection phase, where it processes the incoming data to deepen its understanding of the task.This can involve using libraries like Pandas for data manipulation (Wang et al., 2024), NumPy for numerical computations, or Apache Spark for large-scale data processing.Finally, in the Output Generation step, the agent synthesizes the information gathered through tool use and generates a coherent response or action, informed by both the initial task and insights gained.This output may leverage tools like Matplotlib for data visualization (Wang et al., 2024), TensorFlow for model retraining based on new data, Scikit-learn for evaluating model performance, and Jupyter Notebooks for documenting processing steps and reflecting on outcomes.Through these steps, AI agents effectively navigate complex tasks, utilizing a variety of tools and models to deliver accurate and contextually relevant results.</p>
<p>Type of Tool-Use Systems</p>
<p>Aforementioned, within the tool-use systems paradigm, tools are essential for enhancing the capabilities of AI agents, allowing them to perform complex tasks effectively.These tools can be categorized into several groups based on their functionalities and applications.In Table 4.5 below, we outline key types of tool-use systems, providing descriptions and examples for each type.</p>
<p>Simulation and Modeling</p>
<p>Allows AI agents to create and manipulate models of real-world scenarios for training, assessment, and simulations.They foster experiential learning opportunities.</p>
<p>AnyLogic: simulation modeling, MATLAB: mathematical modeling</p>
<p>Interaction and Communication Tools</p>
<p>Interaction and Communication</p>
<p>Facilitates interactions between AI agents and users or between multiple agents, enhancing collaboration and feedback mechanisms.</p>
<p>Chatbot frameworks such as Rasa for conversational interfaces, Zoom API: virtual meetings.</p>
<p>Governance and Evaluation Tools</p>
<p>Monitoring and Evaluation</p>
<p>Helps assess performance and engagement metrics, providing insights into user interactions and outcomes.</p>
<p>Google Analytics for tracking user engagement, formative assessment tools for real-time feedback.</p>
<p>Ethics and Fairness</p>
<p>Focuses on ensuring that AI systems operate within ethical guidelines, promoting fairness and accountability in decision-making processes.</p>
<p>Fairness Indicators for evaluating model fairness, AI ethics frameworks for compliance with ethical standards.</p>
<p>Development and Deployment Tools</p>
<p>Development and Collaboration</p>
<p>Supports the collaborative development of AI applications, allowing teams to work together effectively while building and deploying AI systems.</p>
<p>GitHub for version control and collaboration, Jupyter</p>
<p>Notebooks for interactive coding and sharing of AI models.</p>
<p>Deployment and Scaling</p>
<p>Assists in the deployment of AI applications and their scaling to accommodate larger user bases or more complex tasks, ensuring efficiency in operation.</p>
<p>Docker for containerization,</p>
<p>Kubernetes for orchestration of containerized applications.</p>
<p>By utilizing a combination of these types of tools, AI agents can effectively process data, interact with users, and create meaningful learning experiences.As the integration of AI in education continues to evolve, understanding these tool-use systems in the educational settings will be critical for optimizing their application and maximizing the benefits for learners and educators alike.</p>
<p>Tool -Use systems in Education</p>
<p>Tool-use systems in education leverage the capabilities of AI agents to enhance learning experiences through dynamic interactions with various educational resources.These systems facilitate personalized and effective learning environments by coordinating multiple tools tailored to specific educational tasks (Chin et al., 2010;Ouyang &amp; Jiao, 2021).For example, AI agents can utilize adaptive learning platforms and educational APIs to provide real-time feedback and support individualized learning paths, aligning with the AI-supported, learner-as-collaborator paradigm (Ouyang &amp; Jiao, 2021).</p>
<p>One significant advantage of tool-use systems is their ability to actively engage learners.By integrating tools for document annotation, quiz generation, and performance analytics, AI agents assist educators in tracking student progress and adapting instructional strategies accordingly (Baker et al., 2019).This collaborative approach fosters a co-creation of knowledge between AI systems and students, thus enhancing the learning process (Holmes et al., 2019;Luckin &amp; Cukurova, 2019).Additionally, these systems provide substantial benefits to teachers.AI agents can automate administrative tasks such as grading and attendance tracking, allowing teachers to focus more on instructional activities and student engagement.By analyzing student performance data, AI can also offer insights into class trends and individual student needs, enabling teachers to tailor their instruction more effectively.This data-driven approach helps educators identify which students may require additional support, ultimately improving learning outcomes (Luckin et al., 2016).Moreover, the iterative reasoning capabilities inherent in tool-use systems allow AI agents to reflect on previous interactions and adjust their strategies based on the evolving needs of learners.This reflective practice is essential in educational contexts, as understanding a student's unique learning trajectory can lead to more effective interventions (Zawacki-Richter et al., 2019).For instance, utilizing data analytics tools enables AI agents to identify patterns in student performance data, recommending personalized resources that cater to individual strengths and weaknesses.(Popenici, 2023), and promote learner agency.In conclusion, tool-use systems in education represent a transformative approach, enabling AI agents to enhance engagement, support personalized learning, and facilitate collaborative practices.As these systems continue to evolve, their effective implementation will be critical in shaping the future of education, making it more responsive to the diverse needs of learners (Ouyang &amp; Jiao, 2021).</p>
<p>Multi Agent Systems</p>
<p>Recent advancements in natural language processing (NLP) have led to the emergence of highly capable agents that draw on LLMs for complex reasoning, tool usage, and real-time adaptation to novel observations (Xie et al., 2023; Wang et al., 2023b).As the variety and complexity of tasks suited to LLMs continue to grow, an effective approach to amplifying agent performance is to employ multiple agents working in tandem.Beyond improving efficiency, such collaboration also offers pathways to developing more sustainable AI-driven systems.Previous research shows that multi-agent approaches can foster divergent thinking (Liang et al., 2023), enhance factual accuracy and reasoning (Du et al., 2024), and provide systematic validation (Wu et al., 2024).By orchestrating multiple AI agents, educational platforms can leverage collective intelligence to tackle interdisciplinary challenges-including those related to sustainability-while optimizing resources and reinforcing long-term viability.</p>
<p>A key motivation for using multi-agent systems is the capacity of chat-optimized LLMs to comprehend and respond to feedback.When multiple LLM-based agents communicate-either with one another or with human collaborators-they can exchange reasoning steps, observations, critiques, and validation through dialogue.In addition, LLMs have demonstrated the ability to decompose complex tasks into smaller, more manageable subtasks.Multi-agent dialogues can facilitate task partitioning and subsequent reintegration in an intuitive manner that allows a more efficient and organized problem-solving process.</p>
<p>In contrast, single-agent systems face several limitations.First, when a single agent is equipped with multiple tools, it may struggle to make optimal decisions about which tool to use for a specific task.Second, as task complexity escalates, an overwhelming amount of contextual information can exceed the capacity of a single agent to manage effectively.Third, many real-world scenarios require multiple areas of specialization, which a single agent may not fully encompass.By dividing tasks among specialized agents with diverse expertise, a multi-agent paradigm can mitigate these issues and maintain more manageable contexts.As a result, multi-agent systems offer a promising avenue for dealing with the increasingly complex and specialized tasks in real-world applications.</p>
<p>Multi-agent approach presents several practical advantages, including modularity, specialization, and control.While the multi-agent approach is similar to the "planning" paradigm, it provides greater control over individual components of the system.Increased control and modularity allow to reduce the amount of hallucinations which is a major challenge in LLM-based applications.A summary of the advantages of the multi-agent approach is presented in Table 4.7.</p>
<p>Table 4.7 Advantages of multi-agent systems.</p>
<p>Benefit Description</p>
<p>Modularity Using separate agents simplifies the development and maintenance of agentic systems by allowing isolated updates or replacements without disrupting the entire system.Specialization Dedicated, expert agents can be assigned to specific domains, boosting overall performance through focused expertise.</p>
<p>Control</p>
<p>Clear and explicit mechanisms for agent interactions (e.g., conversations) enable better oversight rather than relying solely on function calls.</p>
<p>Multi Agent Architectures</p>
<p>There exist several architectures for implementing the multi-agent approach.In the "supervisor" architecture, a lead LLM delegates tasks to the subagents in the system.In the "network" architecture, each agent can communicate with another agent in the system.Table 4.7 below outlines several common multi-agent designs, along with their defining characteristics and potential challenges.</p>
<p>Limitations</p>
<p>Despite their distinct advantages, multi-agent systems also present several challenges.Compared to single-agent approaches, coordinating multiple agents typically increases token usage and processing time.The increased resource consumption amplifies computational costs and environmental impact.Therefore, an important research goal is minimizing the number of interactions required while maintaining agent performance.Another key issue is effectively chaining and orchestrating individual agents in the system, as improper coordination can diminish the overall system's performance.Finally, given the propensity for LLMs to hallucinate, relying on communicative agents to handle tasks may lead to incomplete or inaccurate outputs (Agnihotri &amp; Chug, 2020).Addressing these issues will be crucial for the broader adoption and sustainability of multi-agent solutions.</p>
<p>Multi agent systems can be complex to develop and require careful coordination to ensure agents remain aligned with the intended instructional goals.Without proper design, an agent-based system may suffer from inconsistencies.A breakdown in communication among agents can lead to learner confusion or reduced engagement.Biases in agent decision-making can skew interactions, and complex simulations may burden the system.Since agent-based interactions vary, students may receive significantly different experiences, which can undermine the fairness and consistency of instruction.</p>
<p>5 Illustrative Application: Multi-agent scoring system To provide a concrete example of how agentic paradigms, specifically multi-agent collaboration, can be applied in an educational context, we developed a proof-of-concept Multi-Agent Scoring System (MASS) for automated essay grading.Essay writing is a fundamental skill, yet manual grading is time-consuming and potentially subjective.Automated Grading Systems (AGS) aim to address these issues, but single-LLM approaches can suffer from inconsistency and biases like over-praise (Guo et al., 2024).</p>
<p>As a proof of concept for the use of AI agents in education, we propose an automatic essay grading system based on a multi-agent approach.The proposed system consists of two independent subagents that are supervised by the lead agent (Fig 5 .1).The first subagent scores an essay based on the content.It checks how well the essay is organized, clear coherence and progression of ideas using appropriate examples, reasons, and other evidence to support its position.The second agent checks if the essay is free of errors in grammar, usage, typos, and mechanics.The lead agent combines the feedback from each subagent to produce the final score.By focusing each subagent on a specific facet of essay writing, we aim to obtain more accurate feedback.Furthermore, to increase grading consistency, the lead agent is conditioned to request multiple reports from the subagents in case of widely divergent feedback.The proposed multi-agent scoring system (MASS) is based on GPT-4o.We benchmark the MASS against several stand-alone LLMs: GPT-4o, DeepSeek 67b, and DeepSeek 1.3b.We use the ASAP 2.0 Dataset for our evaluation (Crossley et al., 2024).The dataset comprises about 17000 student-written argumentative essays.Each essay was scored on a scale of 1 to 6 based on a holistic rubric.The code and the technical details of the evaluation are available on GitHub (https://github.com/AzizovDilshod/Multi-agent-System-for-Essay-Assessment/tree/main).The results of the evaluation are summarized in Table 5.1.The results show the advantages of the proposed MASS based on GPT-4o over stand-alone LLMs for automated essay grading.</p>
<p>The MASS achieves the lowest mean absolute error (MAE) of 0.5612, indicating that its predictions align more closely with the ground truth scores than those of single LLMs.In contrast, the stand-alone GPT-4o model has a higher MAE of 0.6129, while the DeepSeek models perform worse, with DeepSeek 67b at 0.7345 and DeepSeek 1.3b at 1.6956.Moreover, the statistical tests show that the p-values for both the paired t-test and Wilcoxon signed-rank test are 0.0 across all comparisons.It indicates that the differences in MAE between MASS and each of the single-LLM models are highly statistically significant.</p>
<p>One of the key advantages of MASS is its lower standard deviation of 0.8295, suggesting that it produces more consistent scores across different essays.In comparison, the stand-alone GPT-4o model has a higher standard deviation (0.9555), and DeepSeek 67b and 1.3b exhibit even greater variability (1.0102 and 1.7666, respectively).The high variability in DeepSeek 1.3b's predictions reinforces concerns about grading inconsistency, which is a known limitation of AGS based on a single LLM.</p>
<p>Looking ahead, the implementation of agentic AI also presents opportunities to advance sustainability in educational contexts.By reducing computational redundancy through targeted task decomposition and collaborative agent frameworks, these systems can minimize energy use and resource consumption.Moreover, strategically designed reflection and planning processes can optimize the allocation of computing resources, directly addressing the rising environmental costs associated with large-scale AI.The holistic approach encourages the development of educational platforms that not only excel in adaptability and performance but also uphold principles of ecological responsibility and long-term viability</p>
<p>The superior performance of MASS can be attributed to its multi-agent architecture, where separate subagents focus on different aspects of essay quality-content and language mechanics-before the lead agent synthesizes their outputs.The structured approach reduces errors stemming from over-praise and over-inference, which are common pitfalls in single-LLM grading.Additionally, the verification mechanism introduced in MASS can lead to more refined and balanced scoring.</p>
<p>Conclusion</p>
<p>In this paper, we explored how emerging AI agents can address the limitations of conventional LLMs in education.Our analysis was based on four key design paradigms-reflection, planning, tool use, and multi-agent collaboration.The survey of existing literature revealed the potential for the agentic workflows to offer greater adaptability, enhanced reasoning, and more consistent performance in educational settings.Furthermore, the proposed proof-of-concept multi-agent essay scoring system demonstrated the advantages of agentic workflows over stand-alone LLMs.</p>
<p>By incorporating real-time data, iterative feedback loops, and strategic task decomposition, AI agents overcome the static nature of traditional LLMs, making them powerful reasoning 'partners' or assistive tools.The new paradigm enables the delivery of more robust and trustworthy AI-driven solutions for educational needs in a variety of tasks.In particular, the multi-agent essay-scoring framework highlights how collaborative systems can improve reliability, consistency, and scalability of AI systems in education.</p>
<p>Looking ahead, the implementation of agentic AI also presents opportunities to advance sustainability in educational contexts.By reducing computational redundancy through targeted task decomposition and collaborative agent frameworks, these systems can minimize energy use and resource consumption.Moreover, strategically designed reflection and planning processes can optimize the allocation of computing resources, directly addressing the rising environmental costs associated with large-scale AI.This holistic approach encourages the development of educational platforms that not only excel in adaptability and performance but also uphold principles of ecological responsibility and long-term viability.</p>
<p>Despite our findings, integrating agentic workflows into diverse educational contexts holds several unresolved challenges.Achieving transparency in decision-making processes, ensuring fairness and accountability, and establishing ethical guidelines remain notable concerns.Designing systems that reliably transfer across heterogeneous learner populations and different pedagogical settings also warrants further investigation.Finally, the interplay between human instructors, learners, and AI agents must be systematically studied to ensure that agentic solutions support rather than supplant meaningful educational interactions.</p>
<p>Future Research</p>
<p>There are several avenues for future research to address the remaining challenges in deployment of AI agents in education.These include refining AI architectures to improve interpretability, exploring various strategies that better align with specific pedagogical goals, and developing policy frameworks to ensure fair and equitable deployment of AI agents in classroom settings.To address skepticism and resistance from stakeholders, including teachers, parents, and policymakers, research should focus on making AI agent reasoning transparent to educators and students (Explainable AI (XAI)).</p>
<p>Educational environments are dynamic and new technologies are constantly being introduced.Future research could focus on developing AI agents that are adaptive, context-aware, and can adapt to changing student needs, languages, culture, learning preferences, context (s) (disadvantaged, refugee, remote, etc.) to avoid exacerbating the digital divide.It is also important to study the effectiveness of low-cost or open-source AI solutions in under-resourced schools and communities.Additionally, more longitudinal research is needed to understand the long-term effects of AI on student learning outcomes, skills, teacher practices, and the overall educational ecosystem.It is crucial to investigate whether prolonged exposure to AI agents affects students' ability to be creative, engage in self-directed learning or collaborate with peers.Finally, closer cooperation between AI developers and educators is required to achieve better systems that take into account the needs of the students and instructors.</p>
<p>With breakthroughs happening daily and innovation pushing the boundaries of what is possible, intelligent, agentic workflows offer a transformative promise: to reshape the very fabric of education and unlock/ augment human potential on an unprecedented scale.</p>
<p>Fig. 2 . 4
24
Fig. 2.4 Description of the four major agentic paradigms</p>
<p>Fig. 4 . 1
41
Fig. 4.1 The sequence of the agentic planning process</p>
<p>Fig. 5 . 1
51
Fig. 5.1 The proposed multi-agent assessment system (MASS) for automated essay grading.</p>
<p>Table 2 . 1 .
21
Platforms for building and implementing agentic systems.
FrameworkKey FeaturesProsConsAutoGen (Wu etOpen-source, flexible-Highly customizable-Steep learningal., 2024)design, active community-Integrates withcurve -Potentiallyvarious tools andless structured thanhuman feedbackother frameworksMetaGPTStandardized prompt-Excels in-Heavy reliance on(Hong et al.,sequences, a rich libraryorchestrating complexasyncio -Less2024)of predefined agentsagent interactions -generalizable agentReduces customrolescoding
Ng, 2024;Singh et al., 2024;Xi et al., 2023)eview methodology to analyze the role and potential of AI agentic workflows in education.The primary objective is to synthesize current research and identify key trends, applications, benefits, and challenges associated with four major agentic paradigms: reflection, planning, tool use, and multi-agent collaboration, as identified in recent surveys and framework discussions (e.g.,Ng, 2024;Singh et al., 2024;Xi et al., 2023).</p>
<p>Defining the paradigm's core principles, mechanisms, and key enabling techniques (e.g., citing works like Wei et al., 2022 for CoT; Yao et al., 2023 for ReAct; Xu et al., 2023 for ReWOO; Gou et al., 2024 for CRITIC).
2. Educational Applications: Identifying and categorizing reported or proposed uses ineducation, drawing on specific examples from the literature (e.g., Viswanathan et al.,2022, Mollick et al., 2024 for multi-agent applications; Madaan et al., 2023 for reflectionin feedback).3. Advantages: Summarizing the benefits highlighted in the literature compared tonon-agentic approaches or traditional methods.4. Challenges and Future Directions: Consolidating reported limitations, implementationhurdles, ethical concerns (e.g., drawing on Bender et al., 2021; Chan, 2023; Kamalov etal., 2023), and suggested avenues for future research.
1. Conceptual Foundations:</p>
<p>Table 3 .
3
(Mollick et al., 2024;Zhang et al., 2024b)rks like CRITIC, SELF-REFINE, and DeepSeek rely on repeated cycles of evaluation and refinement, making them resource-intensive and limiting their scalability in resource-constrained educational settings(Gou et al., 2024;Madaan et al., 2023).Addressing this challenge will require innovations in computational efficiency and system optimization.Data privacy and security also remain critical concerns.Reflection systems analyze vast amounts of sensitive user data, including learning patterns and performance metrics, which must be safeguarded against misuse or unauthorized access.Adherence to regulations is essential to maintaining trust and ensuring the ethical use of AI in education (U.S.Department of Education, 2023).Thus, it is important to design systems that are both secure and transparent.Another issue is the propagation of biases in feedback.Self-generated or externally sourced feedback loops may inadvertently reinforce errors or perpetuate biases present in training data or external verification tools.For example, tools like search engines or code evaluators integrated into reflection systems may introduce inaccuracies if they themselves contain biases or errors(Shinn et al., 2023;Bender et al., 2021).To mitigate this, future systems will need mechanisms to identify and address such biases proactively.Collaborative frameworks, where multiple AI agents engage in reflective dialogues or interact with human educators, are another promising direction.Such systems could leverage the complementary strengths of AI and human expertise to deliver more robust and reliable feedback (DeepLearning.ai,2024).Finally, advancements in real-time adaptive feedback offer significant potential for education.For instance, during group activities, reflection systems could monitor team dynamics in real-time and provide actionable recommendations to improve collaboration(Mollick et al., 2024;Zhang et al., 2024b).These innovations, coupled with efforts to ensure transparency and address bias, will help reflection systems become more effective and equitable tools for education.
SourceDomainSummaryMadaan etFeedbackIntroduce SELF-REFINE, a framework that iterativelyal. (2023)Refinementenhances feedback quality for tasks such as essay scoring,dialogue generation, and code optimization.Shinn et al.CollaborativePropose Reflexion, which uses verbal reinforcement to(2023)Learningrefine actions iteratively, improving group participation andactive learning in educational projects.CukurovaMetacognitiveHighlight how reflective systems track engagement andet al.Practiceslearning behaviors, encouraging students to optimize their(2024)learning strategies for better performance.Gou et al.AutomatedPresent CRITIC, a system that integrates external(2024)Gradingverification tools to enhance grading accuracy and fairness,particularly in large-scale assessments.Xu et al.EducationalPropose EduAgent, a framework using generative AI to(2024)Simulationssimulate realistic student behaviors, enabling teachertraining and curriculum optimization.Mollick etEducationalPropose PitchQuest, a simulation platform where reflectional. (2024)Simulationssystems provide iterative feedback to refine learners'performance in experiential learning settings.DeepSeekIntelligentIntroduce DeepSeek, an open-source AI model using(2024)Tutoringadvanced reasoning and reinforcement learning to enhanceITS through interactive elements such as simulations,quizzes, and problem-solving exercises that engagestudents and enhance their understanding of complexconcepts.
(Cukurova, 2024;Kosslyn, 2017)ionsDespite their distinct advantages, multi-agent systems also present several challenges.One major challenge is computational complexity, which arises from the iterative nature of reflection systems.Reflection systems also face difficulties in generalizing across diverse educational contexts.While effective in specific domains, these systems often struggle to adapt to varied disciplines, cultural contexts, or instructional styles(Luckin et al., 2016).Ensuring flexibility and adaptability remains a critical area of research to enable broader deployment.Additionally, the lack of transparency in how reflection systems generate feedback raises ethical concerns.Students and educators need clear explanations of how these systems arrive at decisions to build trust and accountability in their use(Zhang et al., 2024a).Despite these challenges, the future of reflection systems in education is promising.Integrating multimodal feedback sources, such as speech, handwriting, and gestures, could greatly enhance the depth and quality of feedback(Cukurova, 2024;Kosslyn, 2017).For instance, systems could analyze a combination of verbal explanations and written solutions to provide comprehensive feedback tailored to individual learners.</p>
<p>Table 4 .
4
2.
Table 4.2. Agentic Planning SystemsReactive Planners Reactive Planners lack explicit planning capabilities. They operatebased on simple stimulus-response rules or pre-defined behaviors.They react to immediate changes in their environment withoutconsidering long-term goals or consequences.</p>
<p>(Yusuf et al., 2025)ization, AI planning can significantly enhance curriculum design by optimizing the sequencing and delivery of educational content.Curriculum development requires careful consideration of learning outcomes, prerequisite knowledge, constructive alignment, and logical progression.AI systems can analyze these factors and design coherent, efficient curricula.For instance, an AI planning agent can determine the optimal sequence for teaching topics, ensuring that students build foundational knowledge before tackling advanced material.This structured approach not only improves learning outcomes but also reduces cognitive load.Moreover, AI agents can continuously adapt curricula by automatically updating program maps when new courses are added, considering student-specific prerequisites and interests.They can also suggest electives from other programs aligned with career goals or research interests and align assessment tasks closely with specific learning outcomes, enabling comprehensive evaluation and performance predictions.AI planning capabilities extend further into educational decision-making, providing insights and recommendations to support evidence-based practices.Educational decision-making often involves complex trade-offs and uncertainties, such as determining effective teaching strategies or assessing policy impacts.AI systems can analyze historical and real-time data to generate predictive models and scenario analyses(Hao et al., 2024).For example, an AI agent can simulate potential outcomes of various interventions or teaching methodologies, thereby recommending the most effective actions.Personalized recommendation systems that continuously learn from user interactions can help plan comprehensive teaching and learning activities that align with learning outcomes, student engagement, and assessment strategies(Yusuf et al., 2025).Based on this analysis, AI planning agents can design targeted interventions to support underserved populations, such as providing additional resources to schools in low-income areas or offering personalized tutoring to students who are at risk of falling behind.
Furthermore, AI planning can facilitate the delivery of education in remote orresource-constrained settings (Kouam &amp; Muchowe, 2025) through the use of digital platformsand adaptive technologies (Shah &amp; Calonge, 2023). By leveraging AI to bridge gaps in accessand quality (Aderibigbe et al., 2023), educators can work toward creating a more inclusive andequitable educational system.Moreover, AI planning can foster collaborative learning environments, essential for developingcritical thinking, communication, and teamwork skills. AI agents facilitate collaboration byorganizing group activities, assigning roles based on individual student abilities, and monitoringprogress. Systems like Bland AI provide real-time feedback and multilingual guidance, helpinggroups overcome challenges and remain goal-focused.AI planning is also instrumental in optimizing resource allocation within educational institutions,addressing challenges related to limited resources like time, funding, and personnel. Forinstance, AI agents can analyze student enrollment data, faculty availability, and classroomcapacity to create optimal timetables, allocate budgets effectively, prioritize projects, andstreamline administrative processes. By automating these tasks, educators and administratorscan concentrate on strategic initiatives and direct student engagement. Additionally, planningagents can select and organize educational resources tailored to individual student profiles,adjusting difficulty levels in real-time and visualizing information through mind maps. Such visualrepresentations help students connect new information to their existing knowledge, therebyreducing cognitive load and enhancing learning (Hultberg &amp; Calonge, 2017).
(Kamalov et al., 2023)on of AI planning into education also has the potential to address issues of equity and access(Kamalov et al., 2023), which remain significant barriers to achieving universal quality education.AI systems can analyze data on student demographics, socioeconomic status, and geographic location to identify disparities in educational opportunities and outcomes.</p>
<p>Table 4 .
4
3.Components and Mechanisms of Tool-Use Systems.</p>
<p>Table 4 .
4
4. Tool-use System (Operational Framework)</p>
<p>Example Steps Description of Goals and Actions Examples of Tools and Models used
1. Tool InitiationThe session begins with theFor example, user input prompts -agent receiving a task or"Who is the program leader XXX ofquery that necessitates toolUniversity of XXX, analyses his/ herusepublications and send an "Happy NewYear" email to him/her and wish theperson good luck in his/her career".</p>
<p>Table 4 .
4
5. Type of Tool-use System
Type of ToolsDescriptionsExamplesData andData ProcessingFocuses on the collection,Pandas: dataInformationand Analysismanipulation, and analysis ofmanipulation, ApacheProcessingdata to extract meaningfulSpark : large-scaleToolsinsights. They enable AIdata processing,agents to handle largeGoogle search enginedatasets and performAPIs for web enquiriesdata-driven decision-making.Natural LanguageEmpowers AI agents toSpaCy: textProcessing (NLP)understand, interpret, andprocessing, NLTK:generate human language,linguistic data analysisfacilitating communicationbetween the agent and users.They enhance the ability toprocess textual informationeffectivelyComputer VisionEnables AI agents to interpretOpenCV: imageand analyze visualprocessing,information from the world,TensorFlow: deepallowing for tasks such aslearning applicationsimage recognition and videoin visionanalysis, which are crucial insimulations and interactiveYolo: object detectionenvironments.algorithm</p>
<p>Table 4 .
4
(Ouyang &amp; Jiao, 2021)) relevant literature of tool-use systems in education.4.6 Tool-use systems in Education 4.3.4.Limitations and ChallengesDespite the advantages, the implementation of tool-use systems in education faces several limitations and challenges.One significant issue is the seamless integration of various educational tools and platforms.The literature emphasizes the necessity for robust interoperability standards to ensure smooth data flow between systems(Pinkwart, 2016).Without these standards, the effectiveness of tool-use systems can be significantly hampered, leading to fragmented learning experiences.More importantly, concerns about data privacy and Hultberg et al., 2024;Kamalov et al., 2023)in educational settings are critical challenges.As AI systems collect and analyze vast amounts of student data via multiple tools , ensuring the security and privacy of this information becomes paramount(Kamalov et al., 2023).The potential for bias in AI algorithms and tools also raises ethical questions about fairness and equity in educational outcomes(Ouyang &amp; Jiao, 2021).Another challenge is the need for educators to adapt to these new tools and technologies by upskilling and reskilling (Santandreu Calonge et al., 2025).Many educators may lack the necessary training and support to effectively implement and integrate AI-driven tools into their teaching practices (Zawacki-Richter et al., 2019).This gap can lead to resistance to adopting AI tools, limiting their potential benefits in the classroom.To tackle these challenges, educational institutions must develop comprehensive frameworks that guide the implementation of AI tool-use systems.This includes establishing clear data management guidelines, fostering collaboration between educators, students and AI developers (Santandreu Calonge et al., 2025), and ensuring alignment with pedagogical goals(Ouyang &amp; Jiao, 2021).By prioritizing these aspects, educational stakeholders can harness the potential of tool-use systems to transform, 'super-personalise' learning experiences
Author(s)SummaryRelevant Tool-UsetypeSellar &amp; GulsonAnalyzed AI's impact on education policy andEthics and Fairness tools(2020)governance. The tool used brought in policyimplications of AI in education.Winters et al.Explored digital structural violence in educationEthics and Fairness tools(2020)and strategies to combat it. The tool assisted inimplementation of strategies addressinginequities in educational technology.Ouyang &amp; JiaoIdentified three paradigms of AI in education:Communication and(2021)AI-directed (Intelligent Tutoring Systems),Interaction toolsAI-supported (Dialogue-based TutoringSystems), and AI-empowered.Barua (2024)Explored LLMs' potential in creatingSimulation and Modelingautonomous agents with various capabilitiestoolsacross domains. LLMs used for tasks likecustomer service, healthcare diagnostics, andemail responses</p>
<p>Table 4 .
4
Yang et al., 2025)23)ectures In adaptive learning environments, for instance, individual agents can address distinct facets of the learning process-such as identifying knowledge gaps, adjusting content difficulty, or providing personalized feedback-thereby accommodating diverse learning styles and paces.The use of multi-agent systems in education predates the advent of LLMs(Apoki et al., 2022).Viswanathan et al. (2022) propose a multi-agent system consisting of several specialized agents: Jade Gateway Agent, Control Agent, Learning Style Detector Agent, Adaptive Course Organizer Agent, and User Interface Agent.Similarly, Ivanova et al. (2023) present a design based on Learner Agent, Content Agent, and Pedagogical Agent to construct a personalized e-learning system.Similarly, Axac et al. (2023) propose a multi-agent system that integrates computer vision to construct an online learning platform.One promising avenue for further development involves integrating LLMs into the existing multi-agent frameworks.Educational simulations represent another active area of multi-agent design application.Developing simulations can be both resource-intensive and time-consuming; however, advancements in generative AI provide potential solutions to these challenges.Mollick et al. (2024)propose "PitchQuest," a multi-agent AI system for educational simulations.The system offers personalized learning experiences by allowing students to practice skills in scenarios populated by AI-generated stakeholders.The proposed prototype features multiple agents, including Mentor Agent, Investor Agent, Evaluator Agent, Progress Agent, and Class Insights Agent.In medical education,Wei et al. (2024)propose "MEDCO," a multi-agent system that simulates realistic training environments by incorporating roles such as patient, doctor, and radiologist.Their design promotes interactive, multidisciplinary learning and enhances students' question-asking and collaboration skills in a virtual setting(Williams &amp; Li, 2023).Yang et al., 2025).While multi-agent systems for automated grading have been explored to a limited extent, Guo et al. (2024) describe a system with two AI agents: one generates feedback, and the other validates and refines it.This approach significantly reduces instances of over-praise and over-inference, thereby yielding more accurate and pedagogically sound feedback.Yesilyurt (2023) similarly investigates the potential of multi-agent assessment and feedback mechanisms within language learning contexts, further underscoring the promise of multi-agent systems in enhancing educational processes.
Architecture Key CharacteristicsPotential ChallengesSingle-Utilizes a single LLM that can call-Subject to previously noted(Baseline)multiple tools. -Represents the simplestlimitations such assetup.overwhelmed context andinsufficient specialization.Network-Composed of numerous agents, each-Less predictable behavior. -with its own tools and the ability to callPotentially expensive due toupon other agents. -Often employed bynumerous LLM calls. -projects such as Swarm or Crew AI. -Time-consuming and complexLacks a designated "leader," allowing anyto manage in production.agent to invoke any other agent at anytime.Supervisor-Utilizes a single "supervisor" agent that-Over-reliance on thedecides which sub-agent to call next. -supervisor agent for optimalSub-agents focus on specific domains,orchestration. -Potentialenhancing specialization. -A simplifiedbottleneck if the supervisorvariant treats sub-agents as tools used byagent is overwhelmed.the main agent, where the main agent'stool calls handle inter-agentcommunication.Hierarchical-Builds on the supervisor model by-Complexity increases withintroducing multiple layers of supervisoreach additional supervisoryagents. -Allows for large, domain-specificlayer. -May require extensivesystems to be organized in tiers.coordination across tiers.Custom-Tailored specifically to the requirements-Development can beof a given domain. -Often combinesresource-intensive due toelements from supervisor or hierarchicalbespoke design. -Requiresmodels with custom domain logic.ongoing maintenance forevolving domain needs.
3.4.4MultiAgent Systems in EducationMulti-agent systems have been increasingly employed in various educational contexts.They are particularly beneficial in complex tasks that demand the coordination of multiple components.</p>
<p>Table 4 .
4
8. Multi-agent Approaches in Education
SourceDomainSummaryMollick etSimulationPropose PitchQuest, a venture capital pitching simulator.al. (2024)Enables personalized learning through AI-generatedstakeholders and includes multiple agents (Mentor, Investor,Evaluator, Progress, Class Insights).Wei et al.SimulationIntroduce MEDCO, a multi-agent system that simulates(2024)real-world training environments by incorporating patient,doctor, and radiologist roles, fostering interactive,multidisciplinary learning in a virtual setting.Zhang et al.SimulationPropose SimClass, a multi-agent classroom simulation(2024b)framework that mimics traditional classroom interactions byintegrating real user participation and enabling collaborative,role-based teaching dynamics.Jin et al.SimulationPropose TeachTune, a simulated student agent system to test(2024)and tune the performance of pedagogical conversationalagentsMa et al.SimulationPropose AI4Education framework for modeling virtual student(2024)agents used for teacher training.Guo et al.AutomatedDevelop a multi-agent system featuring two AI agents-one(2024)Gradinggenerating feedback and the other validating/refining it-forautomatically scoring student responses with the aim ofreducing over-praise and over-inference errors.YesilyurtAutomatedExplore multi-agent assessment and feedback mechanisms in(2023)Gradinglanguage learning contexts, emphasizing how multi-agentsystems can support more nuanced and effective studentfeedback.</p>
<p>Table 5 .
5
1 Comparison of MASS vs single LLMs in automatic essay grading.
ModelMAEStd Dev of ErrorDeepSeek 1.3B1.6961.767DeepSeek 67B0.7351.010GPT-4o0.6130.956Llama 3.3 70B0.6140.783MASS0.5610.830
Statements &amp; DeclarationsThe authors declare that no funds, grants, or other support were received during the preparation of this manuscript.
Agent-e: From autonomous web navigation to foundational design principles in agentic systems. T Abuelsaad, D Akkil, P Dey, A Jagmohan, A Vempaty, R Kokku, arXiv:2407.130322024arXiv preprint</p>
<p>Artificial intelligence in developing countries: bridging the gap between potential and implementation. A O Aderibigbe, P E Ohenhen, N K Nwaobia, J O Gidiagba, E C Ani, Computer Science &amp; IT Research Journal. 432023</p>
<p>A systematic literature survey of software metrics, code smells and refactoring techniques. M Agnihotri, A Chug, Journal of Information Processing Systems. 1642020</p>
<p>The role of pedagogical agents in personalised adaptive learning: A review. U C Apoki, A M A Hussein, H K M Al-Chalabi, C Badica, M L Mocanu, Sustainability. 141164422022</p>
<p>The Agent-Based Learning Platform. N Axak, M Kushnaryov, A Tatarnykov, ICST. 2023, September</p>
<p>Educ-AI-tion rebooted? Exploring the future of artificial intelligence in schools and colleges. T Baker, L Smith, N Anissa, 2019</p>
<p>Exploring autonomous agents through the lens of large language models: A review. S Barua, arXiv:2404.044422024arXiv preprint</p>
<p>On the dangers of stochastic parrots: Can language models be too big?. E M Bender, T Gebru, A Mcmillan-Major, S Shmitchell, Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency. the 2021 ACM Conference on Fairness, Accountability, and Transparency2021</p>
<p>A comprehensive AI policy education framework for university teaching and learning. International journal of educational technology in higher education. C K Y Chan, 20232038</p>
<p>What is an agent?. H Chase, 2024. June</p>
<p>Dynamic learning experiences in multi-agent systems for education. F Chen, L Zhao, S Hu, C Lu, J Clune, arXiv:2408.08435arXiv:2311.032892023. 2024arXiv preprintAutomated design of agentic systems</p>
<p>Preparing students for future learning with teachable agents. D B Chin, I M Dohmen, B H Cheng, M A Oppezzo, C C Chase, D L Schwartz, Educational Technology Research and Development. 5862010</p>
<p>Bridging the Gap: AI Adoption and Perspectives in Education. Copyleaks, 2024. 2024</p>
<p>Learning Agency Lab -Automated Essay Scoring 2.0. Kaggle. S Crossley, P Baffour, J King, L Burleigh, W Reade, M Demkin, 2024</p>
<p>Crewai, CrewAI Website. </p>
<p>M Cukurova, arXiv:2403.16081The Interplay of Learning, Analytics, and Artificial Intelligence in Education. 2024arXiv preprint</p>
<p>Artificial intelligence and multimodal data in the service of human decision-making: A case study in debate tutoring. M Cukurova, C Kent, R Luckin, British Journal of Educational Technology. 5062019</p>
<p>Effects of artificial intelligence-powered virtual agents on learning outcomes in computer-based simulations: A meta-analysis. C P Dai, F Ke, Y Pan, J Moon, Z Liu, Educational Psychology Review. 361312024</p>
<p>Agentic Design Patterns: Reflection. DeepLearning.ai.2024</p>
<p>Deepseek, DeepSeek official website. 2024. January 2025</p>
<p>Harnessing large language models to auto-evaluate the student project reports. H Du, Q Jia, E Gehringer, X Wang, Computers and Education: Artificial Intelligence. 71002682024</p>
<p>Improving Factuality and Reasoning in Language Models through Multiagent Debate. Y Du, S Li, A Torralba, J B Tenenbaum, I Mordatch, Forty-first International Conference on Machine Learning. </p>
<p>Y K Dwivedi, L Hughes, E Ismagilova, G Aarts, C Coombs, T Crick, . . Williams, M D , Artificial Intelligence (AI): Multidisciplinary perspectives on emerging challenges, opportunities, and agenda for research. 202157101994</p>
<p>CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing. ICLR 2024. Z Gou, 2024</p>
<p>S Guo, E Latif, Y Zhou, X Huang, X Zhai, arXiv:2411.07407Using Generative AI and Multi-Agents to Provide Automatic Feedback. 2024arXiv preprint</p>
<p>Repackaging authority: Artificial intelligence, automated governance and education trade shows. K N Gulson, K Witzenberger, Journal of Education Policy. 2020</p>
<p>A real-world webagent with planning, long context understanding. I Gur, H Furuta, A Huang, M Safdari, Y Matsuo, D Eck, A Faust, arXiv:2307.128562023arXiv preprintand program synthesis</p>
<p>Artificial Intelligence Trust, risk and security management (AI trism): Frameworks, applications, challenges and future research directions. A Habbal, M K Ali, M A Abuzaraida, Expert Systems with Applications. 1224422024</p>
<p>H Hao, Y Wang, J Chen, Empowering Scenario Planning with Artificial Intelligence: A Perspective on Building Smart and Resilient Cities. Engineering. 2024</p>
<p>Artificial intelligence in education: Promises and implications for teaching and learning. W Holmes, M Bialik, C Fadel, 2019Center for Curriculum Redesign</p>
<p>MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework. S Hong, M Zhuge, J Chen, X Zheng, Y Cheng, J Wang, C Zhang, The Twelfth International Conference on Learning Representations. </p>
<p>Thought cloning: Learning to think while acting by imitating human thinking. S Hu, J Clune, Advances in Neural Information Processing Systems. 202436</p>
<p>Automated design of agentic systems. S Hu, C Lu, J Clune, arXiv:2408.084352024arXiv preprint</p>
<p>Reflexion: Language Agents with Verbal Reinforcement Learning Feedback. P S Huang, arXiv:2303.176512023arXiv preprint</p>
<p>Comparing and assessing four AI chatbots' competence in economics. P T Hultberg, D Santandreu Calonge, F Kamalov, L Smail, Plos one. 195e02978042024</p>
<p>Promoting long-lasting learning through instructional design. P Hultberg, D S Calonge, A E S Lee, Journal of the Scholarship of Teaching and Learning. 1832018</p>
<p>Effective teaching of economics: A constrained optimization problem?. P T Hultberg, D S Calonge, The Journal of Economic Education. 4842017</p>
<p>An Agent-Oriented Architecture for Strategy-Based Personalized E-Learning. T Ivanova, V Terzieva, K Todorova, 2021 Big Data, Knowledge and Control Systems Engineering (BdKCSE). IEEE2021, October</p>
<p>H Jin, M Yoo, J Park, Y Lee, X Wang, J Kim, arXiv:2410.04078TeachTune: Reviewing Pedagogical Agents Against Diverse Student Profiles with Simulated Students. 2024arXiv preprint</p>
<p>AI-enabled adaptive learning systems: A systematic mapping of the literature. T Kabudi, I Pappas, D H Olsen, Computers and Education: Artificial Intelligence. 21000172021</p>
<p>New era of artificial intelligence in education: Towards a sustainable multifaceted revolution. F Kamalov, D Santandreu Calonge, I Gurrib, Sustainability. 1516124512023</p>
<p>AI in personalized learning. K S Kaswan, J S Dhatterwal, R P Ojha, Advances in Technological Innovations in Higher Education. CRC Press2024</p>
<p>Unlocking the potential of GPT-3 in education: Opportunities, limitations, and recommendations for effective integration. S Kikalishvili, Interactive Learning Environments. 3292024</p>
<p>Assessing the role of AI technology in mitigating the equity gap in educational access in Zimbabwe: Barriers and implications. A W Kouam, R M F; &amp; Muchowe, Journal of Applied Learning &amp; Teaching. 812025</p>
<p>The Science of Learning: Mechanisms and Principles. S M Kosslyn, 2017MIT Press</p>
<p>Langchain, LangGraph Website. </p>
<p>Applying large language models and chain-of-thought for automatic scoring. G G Lee, E Latif, X Wu, N Liu, X Zhai, Computers and Education: Artificial Intelligence. 61002132024</p>
<p>Encouraging divergent thinking in large language models through multi-agent debate. T Liang, Z He, W Jiao, X Wang, Y Wang, R Wang, . . Tu, Z , arXiv:2305.191182023arXiv preprint</p>
<p>Designing educational technologies in the age of AI: A learning sciences-driven approach. R Luckin, M Cukurova, British Journal of Educational Technology. 5062019</p>
<p>Intelligence unleashed: An argument for AI in education. R Luckin, W Holmes, M Griffiths, L B Forcier, 2016Pearson Education</p>
<p>Y Ma, S Hu, X Li, Y Wang, S Liu, K H Cheong, arXiv:2410.15701Students Rather Than Experts: A New AI For Education Pipeline To Model More Human-Like And Personalised Early Adolescents. 2024arXiv preprint</p>
<p>SELF-REFINE: Iterative Refinement with Self-Feedback. A Madaan, 2023Preprint</p>
<p>The landscape of emerging ai agent architectures for reasoning, planning, and tool calling: A survey. T Masterman, S Besen, M Sawtell, A Chao, arXiv:2404.115842024arXiv preprint</p>
<p>. E Mollick, L Mollick, N Bach, L J Ciccarelli, B Przystanski, D Ravipinto, 10.48550/arXiv.2407.12796arXiv:2407.127962024arXiv preprintAI agents and education: Simulated practice at scale</p>
<p>Agentic design patterns part 1: Four AI agent strategies that improve GPT-4 and GPT-3.5 performance. DeepLearning. A Ng, 2024. March 20</p>
<p>Artificial Intelligence in Education: The Three Paradigms. F Ouyang, P Jiao, 10.1016/j.caeai.2021.100020ID: 100020Computers and Education: Artificial Intelligence. 22021</p>
<p>Another 25 years of AIED? Challenges and opportunities for intelligent educational technologies of the future. N Pinkwart, International Journal of Artificial Intelligence in Education. 2622016</p>
<p>The critique of AI as a foundation for judicious use in higher education. S Popenici, Journal of Applied Learning and Teaching. 622023</p>
<p>Chatdev: Communicative agents for software development. C Qian, W Liu, H Liu, N Chen, Y Dang, J Li, . . Sun, M , Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics. Long Papers. the 62nd Annual Meeting of the Association for Computational Linguistics2024. August1</p>
<p>DeepSeek is Chinese, but its AI models rival OpenAI. The Algorithmic Bridge. Alberto Romero, 2024</p>
<p>H Rouzegar, M Makrehchi, arXiv:2406.13903Generative AI for Enhancing Active Learning in Education: A Comparative Study of GPT-3.5 and GPT-4 in Crafting Customized Test Questions. 2024arXiv preprint</p>
<p>Artificial intelligence-enabled intelligent assistant for personalized and adaptive learning in higher education. R Sajja, Y Sermet, M Cikmaz, D Cwiertny, I Demir, Information. 15105962024</p>
<p>Upskilling and reskilling in the United Arab Emirates: Future-proofing careers with AI skills. D Santandreu Calonge, F Kamalov, P Medina Aguerrebere, L Hassock, L Smail, D Yousef, . . Abdulla, N , Journal of Adult and Continuing Education. 2025. 14779714251315288</p>
<p>Becoming information centric: The emergence of new cognitive infrastructures in education policy. S Sellar, K N Gulson, Journal of Education Policy. 2019</p>
<p>Refugees' experiences with online higher education: Impact and implications through the pandemic. M Shah, D S Calonge, Journal of Applied Learning and Teaching. 612023</p>
<p>Enhancing video-based learning using knowledge tracing: Personalizing students' learning experience with ORBITS. S Shehata, D S Calonge, P Purnell, M Thompson, Proceedings of the 18th workshop on innovative use of NLP for Building Educational Applications. the 18th workshop on innovative use of NLP for Building Educational Applications2023, July. 2023</p>
<p>Enhancing ai systems with agentic workflows patterns in large language model. A Singh, A Ehtesham, S Kumar, T T Khoei, IEEE World AI IoT Congress. 2024. May. 2024IEEE</p>
<p>P Singh, What is Agentic AI Planning Pattern?. 2024. November 24</p>
<p>Impact of misinformation from generative AI on user information processing: How people understand misinformation from generative AI. D Shin, A Koerber, J S Lim, 10.1177/146144482412340402024New Media &amp; Society0</p>
<p>Reflexion: Language Agents with Verbal Reinforcement Learning. N Shinn, 2023Preprint</p>
<p>Language models don't always say what they think: unfaithful explanations in chain-of-thought prompting. M Turpin, J Michael, E Perez, S Bowman, Advances in Neural Information Processing Systems. 202436</p>
<p>Artificial intelligence and the future of teaching and learning: Insights and recommendations. 2023U.S. Department of Education, Office of Educational Technology.</p>
<p>Enhancement of online education system by using a multi-agent approach. N Viswanathan, S Meacham, F F Adedoyin, Computers and Education: Artificial Intelligence. 31000572022</p>
<p>X Wang, Y Chen, L Yuan, Y Zhang, Y Li, H Peng, H Ji, arXiv:2402.01030Executable code actions elicit better llm agents. 2024arXiv preprint</p>
<p>Medco: Medical education copilots based on a multi-agent framework. H Wei, J Qiu, H Yu, W Yuan, arXiv:2408.124962024arXiv preprintECCV 2024 Workshop</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. J Wei, X Wang, D Schuurmans, M Bosma, F Xia, E Chi, . . Zhou, D , Advances in neural information processing systems. 202235</p>
<p>Medco: A multi-agent copilot system for medical education. E Williams, C Li, arXiv:2310.201952023arXiv preprint</p>
<p>N Winters, R Eynon, A Geniets, J Robson, K Kahn, Can we avoid digital structural violence in future learning systems? Learning, Media and Technology. 202045</p>
<p>Artificial intelligence: Transforming the future of feedback in education. T Wongvorachan, K W Lai, O Bulut, Y.-S Tsai, G Chen, Journal of Applied Testing Technology. 2022</p>
<p>S Xu, X Zhang, L Qin, 10.48550/arXiv.2404.07963EduAgent: Generative student agents in learning. 2024</p>
<p>B Xu, Z Peng, B Lei, S Mukherjee, Y Liu, D Xu, arXiv:2305.18323Rewoo: Decoupling reasoning from observations for efficient augmented language models. 2023arXiv preprint</p>
<p>Autogen: Enabling next-gen LLM applications via multi-agent conversations. Q Wu, G Bansal, J Zhang, Y Wu, B Li, E Zhu, . . Wang, C , First Conference on Language Modeling. 2024, October</p>
<p>MathChat: Converse to Tackle Challenging Math Problems with LLM Agents. Y Wu, F Jia, S Zhang, H Li, E Zhu, Y Wang, . . Wang, C , ICLR 2024 Workshop on Large Language Model (LLM) Agents. 2024</p>
<p>Z Xi, W Chen, X Guo, W He, Y Ding, B Hong, . . Gui, T , arXiv:2309.07864The rise and potential of large language model based agents: A survey. 2023arXiv preprint</p>
<p>J Yang, E Latif, Y He, X Zhai, arXiv:2501.06704Fine-tuning ChatGPT for Automatic Scoring of Written Scientific Explanations in Chinese. 2025arXiv preprint</p>
<p>Edge-cloud polarization and collaboration: A comprehensive survey for ai. J Yao, S Zhang, Y Yao, F Wang, J Ma, J Zhang, IEEE Transactions on Knowledge and Data Engineering. 3572022</p>
<p>Tree of thoughts: Deliberate problem solving with large language models. S Yao, D Yu, J Zhao, I Shafran, T Griffiths, Y Cao, K Narasimhan, Advances in Neural Information Processing Systems. 202436</p>
<p>Ai-enabled assessment and feedback mechanisms for language learning: Transforming pedagogy and learner experience. Y E Yesilyurt, Transforming the language teaching experience in the age of ai. IGI Global2023</p>
<p>Pedagogical AI conversational agents in higher education: a conceptual framework and survey of the state of the art. H Yusuf, A Money, D Daylamani-Zad, Educational technology research and development. 2025</p>
<p>Systematic review of research on artificial intelligence applications in higher education -Where are the educators?. O Zawacki-Richter, V I Marín, M Bond, F Gouverneur, International Journal of Educational Technology in Higher Education. 39162019</p>
<p>Enhancing LLMs for Impression Generation in Radiology Reports through a Multi-Agent System. F Zeng, Z Lyu, Q Li, X Li, arXiv:2412.068282024arXiv preprint</p>
<p>Agentic Large Language Models for Generating Large-Scale Urban Daily Activity Patterns. Y Zhang, K Zhang, Y Pang, Y Sekimoto, 2024 IEEE International Conference on Big Data (BigData). IEEE2024a, December</p>
<p>Z Zhang, D Zhang-Li, J Yu, L Gong, J Zhou, Z Liu, L Hou, J Li, arXiv:2406.19226Simulating classroom education with llm-empowered agents. 2024barXiv preprint</p>
<p>L Zhong, Z Wang, J Shang, arXiv:2402.16906Ldb: A large language model debugger via verifying runtime execution step-by-step. 2024arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>