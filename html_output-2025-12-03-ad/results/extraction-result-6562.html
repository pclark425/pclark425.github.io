<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6562 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6562</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6562</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-129.html">extraction-schema-129</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <p><strong>Paper ID:</strong> paper-263334469</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2310.00280v2.pdf" target="_blank">Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION</a></p>
                <p><strong>Paper Abstract:</strong> , symbolic reasoning, commonsense reasoning, and semi-structured reasoning. The results illustrate that our method achieves substantial performance gains over previous strong baselines. Moreover, each mode</p>
                <p><strong>Cost:</strong> 0.026</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6562.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6562.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Corex-Discuss</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Corex Discuss Mode (multi-agent group discussion)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Corex collaboration paradigm where agents are split into teams that iteratively discuss reasoning chains for up to T rounds to refine factuality and preserve diversity of rationales; a judge agent selects outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-Turbo-0613</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Group discussion (Corex: Discuss)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>multi-agent collaboration / ensemble</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Arithmetic (aggregate, Table 1)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Grade-school and other arithmetic reasoning datasets (GSM8K, AddSub, SVAMP, etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>83.1</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>CoT-SC(10)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>-1.5</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Discuss preserves factuality and diversity of rationales, enabling teams to refine reasoning without forcing a single consensus; authors report Discuss is effective on factual-knowledge tasks and reaches consensus quickly for most problems.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6562.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6562.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Corex-Review-NL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Corex Review Mode (NL reasoning chains)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Corex paradigm where a primary agent produces a chain-of-thought and other agents sequentially review and revise the NL reasoning chain to reduce cumulative errors and misinterpretations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-Turbo-0613</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Sequential peer review of Chain-of-Thought (Corex: Review NL)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>multi-agent collaborative verification</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>mixed</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Arithmetic (aggregate, Table 1)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Grade-school and other arithmetic reasoning datasets</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>84.6</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>CoT-SC(10)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>0.0</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Review mode reduces cumulative reasoning errors via iterative critiques; each review cycle generally improves performance though occasional oscillations occur; authors highlight Review NL's effectiveness for mathematical and counting tasks when using NL-based fixes.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6562.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6562.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Corex-Review-Code</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Corex Review Mode (code/PAL)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Corex paradigm where the primary agent generates programmatic solutions (PAL) that are sequentially reviewed and corrected by other agents, with final code executed to obtain answers.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-Turbo-0613</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Sequential peer review with Program-Aided Language Model (Corex: Review Code)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>multi-agent collaborative verification + tool-augmented execution</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>mixed</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Arithmetic (aggregate, Table 1)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Grade-school and harder arithmetic problems including code-executable solutions (e.g., GSM-Hard)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>86.7</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>CoT-SC(10)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>2.1</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Review Code repairs buggy programs and mitigates problem misinterpretation; reviewers iteratively receive predecessors' feedback enabling progressively refined code; authors report large gains for hard arithmetic and counting tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6562.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6562.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Corex-Retrieve</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Corex Retrieve Mode (model-to-model faithfulness ranking)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Corex paradigm where one agent (retriever) evaluates a pool of candidate (chain, answer) pairs produced by other agents and selects the most faithful pair by scoring faithfulness between chain and answer.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-Turbo-0613</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Retriever-based faithfulness ranking (Corex: Retrieve)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>ensemble + retrieval-based model-to-model evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Arithmetic (aggregate, Table 1)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Grade-school and other arithmetic reasoning datasets</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>86.3</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>CoT-SC(10)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>1.7</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Retrieve selects the most faithful chain+answer pair rather than majority-voting purely on answers; authors report Retrieve often outperforms majority voting with fewer sampled chains and is reference-free (model-to-model).</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6562.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e6562.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CoT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chain-of-Thought prompting (CoT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The single-model chain-of-thought prompting technique where an LLM is prompted to produce intermediate reasoning steps leading to an answer.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-Turbo-0613</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Chain-of-Thought</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>sequential / single-model</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>single style</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Arithmetic (aggregate, Table 1)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Grade-school arithmetic reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>80.9</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>CoT-SC(10)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>-3.7</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>CoT produces explicit reasoning chains but can suffer from cumulative errors and plateauing text quality; Corex methods are compared against CoT variants and often improve upon CoT via multi-agent interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6562.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e6562.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CoT-SC(10)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Self-Consistency with Chain-of-Thought (10 samples)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Self-consistency decoding samples multiple CoT reasoning paths from a single model and selects the final answer by majority vote.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-Turbo-0613</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Self-Consistency (CoT-SC)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>ensemble / majority-vote</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>homogeneous</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Arithmetic (aggregate, Table 1)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Grade-school arithmetic reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>84.6</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Self-consistency improves CoT by ensembling multiple sampled chains via majority voting but can be computationally expensive and vulnerable to incorrect-majority overpowering correct but minority answers; Corex aims to reduce those drawbacks.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6562.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e6562.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ComplexCoT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Complexity-based Chain-of-Thought (ComplexCoT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An ensemble-style CoT variant that selects answers from candidate chains with higher reasoning complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-Turbo-0613</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Complexity-based consistency (ComplexCoT)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>ensemble / heuristic selection</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>homogeneous</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Commonsense (aggregate, Table 2)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Commonsense and factual reasoning (StrategyQA, CSQA, OpenBookQA, BoolQ, ARC-c)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>77.5</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>ComplexCoT prioritizes candidate chains judged to have higher reasoning complexity; the paper reports Corex surpasses ComplexCoT on some datasets (e.g., StrategyQA) without elaborate prompt engineering.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6562.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e6562.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PAL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Program-Aided Language Model (PAL)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method where LLMs generate programs as intermediate steps which are executed (e.g., by a Python interpreter) to obtain numerically correct outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-Turbo-0613</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Program-Aided Language Model (PAL)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>tool-augmented / code-execution</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>single/tool-augmented</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Symbolic (aggregate, Table 3)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Symbolic reasoning tasks from BIG-Bench (Date, Object Counting, Penguins, Colored Objects, Repeat Copy)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>88.3</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>CoT-SC(10)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>7.8</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>PAL provides computational accuracy by offloading arithmetic/computation to interpreters but can still suffer from misinterpretation and buggy code; Corex Review Code combines PAL with multi-agent review to reduce these errors further.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6562.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e6562.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Corex-Discuss-CommonSense</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Corex Discuss Mode (commonsense tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Discuss mode applied to commonsense/factual reasoning datasets; teams exchange factual corrections and judges decide.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-Turbo-0613</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Group discussion (Corex: Discuss)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>multi-agent collaboration / ensemble</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Commonsense & Factual (aggregate, Table 2)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Commonsense QA and factual reasoning (StrategyQA, CSQA, OpenBookQA, BoolQ, ARC-c)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>76.8</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>CoT-SC(10)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>0.3</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Discuss yields modest gains on commonsense tasks by enhancing factuality; authors note that Discuss is competent for tasks relying on factual knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6562.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e6562.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Corex-Review-NL-CommonSense</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Corex Review Mode (NL) on commonsense</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Sequential peer-review of NL chains applied to commonsense tasks to detect and correct flawed reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-Turbo-0613</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Sequential peer review of Chain-of-Thought (Corex: Review NL)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>multi-agent collaborative verification</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>mixed</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Commonsense & Factual (aggregate, Table 2)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Commonsense & factual reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>76.4</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>CoT-SC(10)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>-0.1</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Review NL is applied with only NL chains on commonsense tasks; provides improvements but more limited than Retrieve in some cases.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6562.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e6562.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Corex-Retrieve-CommonSense</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Corex Retrieve Mode on commonsense</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Retriever agent ranks candidate chains by faithfulness to choose the final answer on commonsense datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-Turbo-0613</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Retriever-based faithfulness ranking (Corex: Retrieve)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>ensemble + retrieval-based model-to-model evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Commonsense & Factual (aggregate, Table 2)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Commonsense & factual reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>77.6</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>CoT-SC(10)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>1.1</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Retrieve consistently facilitates improvements across general tasks by selecting the most faithful explanation+answer pair; retriever model capability has modest impact since candidate quality bounds performance.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6562.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e6562.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CoT-CommonSense</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chain-of-Thought prompting on commonsense tasks</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Single-model CoT evaluated on commonsense and factual QA datasets as baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-Turbo-0613</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Chain-of-Thought</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>sequential / single-model</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>single style</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Commonsense & Factual (aggregate, Table 2)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Commonsense & factual reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>74.8</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>CoT-SC(10)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>-1.7</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>CoT is a baseline for commonsense tasks; multi-agent modes in Corex yield modest but consistent improvements.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6562.12">
                <h3 class="extraction-instance">Extracted Data Instance 12 (e6562.12)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CoT-SC-CommonSense</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Self-Consistency (CoT-SC(10)) on commonsense</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Majority-vote over multiple CoT samples applied to commonsense tasks as a strong baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-Turbo-0613</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Self-Consistency (CoT-SC(10))</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>ensemble / majority-vote</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>homogeneous</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Commonsense & Factual (aggregate, Table 2)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Commonsense & factual reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>76.5</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Serves as a primary baseline; paper contrasts Corex with CoT-SC showing Corex can match or exceed results with fewer inferences and better faithfulness considerations.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6562.13">
                <h3 class="extraction-instance">Extracted Data Instance 13 (e6562.13)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Corex-Discuss-Symbolic</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Corex Discuss Mode on symbolic reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Discuss mode applied to symbolic tasks from BIG-Bench to foster factual checks and diverse reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-Turbo-0613</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Group discussion (Corex: Discuss)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>multi-agent collaboration / ensemble</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Symbolic (aggregate, Table 3)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Symbolic reasoning tasks (Date, Object Counting, Penguins, Colored Objects, Repeat Copy)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>80.7</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>CoT-SC(10)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>0.2</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Discuss helps factual aspects of symbolic tasks but PAL-based collaboration (Review Code) especially improves tasks like Repeat Copy where CoT-SC struggles to be consistent.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6562.14">
                <h3 class="extraction-instance">Extracted Data Instance 14 (e6562.14)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Corex-Review-NL-Symbolic</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Corex Review Mode (NL) on symbolic reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Sequential NL reviewing applied to symbolic tasks to refine reasoning chains and reduce errors.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-Turbo-0613</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Sequential peer review (Corex: Review NL)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>multi-agent collaborative verification</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>mixed</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Symbolic (aggregate, Table 3)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Symbolic reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>82.0</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>CoT-SC(10)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>1.5</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Review NL improves consistency and reasoning reliability on symbolic tasks; authors note Review Code can be particularly strong on Repeat Copy when combined with PAL.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6562.15">
                <h3 class="extraction-instance">Extracted Data Instance 15 (e6562.15)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Corex-Review-Code-Symbolic</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Corex Review Mode (Code) on symbolic reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>PAL-based primary solution reviewed sequentially by agents, used for symbolic tasks to fix code and interpretation errors.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-Turbo-0613</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Sequential peer review with PAL (Corex: Review Code)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>multi-agent collaborative verification + tool execution</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>mixed</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Symbolic (aggregate, Table 3)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Symbolic reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>91.1</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>PAL</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>2.8</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Review Code achieves particularly high accuracy on symbolic tasks; iterative review eliminates bugs and misinterpretations in generated programs, outperforming both PAL alone and majority-vote approaches in some tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6562.16">
                <h3 class="extraction-instance">Extracted Data Instance 16 (e6562.16)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Corex-Retrieve-Symbolic</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Corex Retrieve Mode on symbolic reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Retriever scores candidate chain+answer pairs and selects the most faithful for symbolic tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-Turbo-0613</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Retriever-based faithfulness ranking (Corex: Retrieve)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>ensemble + retrieval-based evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Symbolic (aggregate, Table 3)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Symbolic reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>85.6</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>CoT-SC(10)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>5.1</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Retrieve offers more judicious answer selection than majority voting on counting tasks by focusing on faithfulness between chain and prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6562.17">
                <h3 class="extraction-instance">Extracted Data Instance 17 (e6562.17)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CoT-Symbolic</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chain-of-Thought baseline on symbolic reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Single-model CoT evaluated on symbolic BIG-Bench tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-Turbo-0613</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Chain-of-Thought</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>sequential / single-model</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>single style</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Symbolic (aggregate, Table 3)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Symbolic reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>73.8</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>CoT-SC(10)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>-6.7</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>CoT struggles on tasks like Repeat Copy; PAL and collaborative approaches can substantially outperform naive CoT in symbolic settings.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6562.18">
                <h3 class="extraction-instance">Extracted Data Instance 18 (e6562.18)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PAL-Symbolic</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PAL baseline on symbolic reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Program-aided baseline where generated programs are executed to obtain results on symbolic tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-Turbo-0613</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Program-aided language modeling (PAL)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>tool-augmented / code-execution</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>single/tool-augmented</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Symbolic (aggregate, Table 3)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Symbolic reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>88.3</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>CoT-SC(10)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>7.8</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>PAL excels in tasks requiring precise computation; combining PAL with multi-agent review (Corex-Review Code) further reduces bugs and misinterpretations.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6562.19">
                <h3 class="extraction-instance">Extracted Data Instance 19 (e6562.19)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Corex-Discuss-SemiStructured</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Corex Discuss Mode on semi-structured reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Discuss mode applied to semi-structured tasks (financial QA) to combine factual checks and collaborative reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-Turbo-0613 (16k for TAT-QA where needed)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Group discussion (Corex: Discuss)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>multi-agent collaboration / ensemble</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Semi-structured (FinQA & ConvFinQA aggregate, Table 4)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Numerical reasoning over tabular and textual financial reports (FinQA, ConvFinQA)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy (official scripts)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>53.5</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>CoT-SC(10)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>-1.4</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Discuss provides modest improvement over CoT on semi-structured tasks but Review Code and Retrieve show larger gains due to code-synthesis and faithfulness selection.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6562.20">
                <h3 class="extraction-instance">Extracted Data Instance 20 (e6562.20)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Corex-Review-Code-SemiStructured</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Corex Review Code on semi-structured reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>PAL-based primary solutions reviewed and executed to handle semi-structured financial QA, reducing computational errors.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-Turbo-0613 (GPT-3.5-Turbo-16k for some datasets)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Sequential review + PAL execution (Corex: Review Code)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>multi-agent collaborative verification + tool execution</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>mixed</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Semi-structured (FinQA & ConvFinQA aggregate, Table 4)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Financial question answering spanning tables and text</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy (official scripts)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>55.1</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>CoT-SC(10)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>0.2</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Review Code attains the best average among Corex modes for semi-structured tasks by repairing programs and ensuring computational fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6562.21">
                <h3 class="extraction-instance">Extracted Data Instance 21 (e6562.21)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Corex-Retrieve-SemiStructured</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Corex Retrieve Mode on semi-structured reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Retriever evaluates candidate explanatory chains and selects the most faithful for semi-structured financial QA.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-Turbo-0613 (16k for TAT-QA when used)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Retriever-based faithfulness ranking (Corex: Retrieve)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>ensemble + retrieval-based evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Semi-structured (FinQA & ConvFinQA aggregate, Table 4)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Financial QA (table+text)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy (official scripts)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>56.6</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>CoT-SC(10)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>1.7</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Retrieve improves final-answer faithfulness by selecting chain+answer pairs; authors note reduced computational cost relative to majority-vote ensembles while retaining or improving accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6562.22">
                <h3 class="extraction-instance">Extracted Data Instance 22 (e6562.22)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CoT-SemiStructured</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chain-of-Thought baseline on semi-structured reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>CoT baseline evaluated on semi-structured financial QA datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-Turbo-0613</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Chain-of-Thought</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>sequential / single-model</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>single style</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Semi-structured (FinQA & ConvFinQA aggregate, Table 4)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Financial numerical reasoning over tables and text</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy (official scripts)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>48.3</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>CoT-SC(10)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>-6.6</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>CoT shows lower performance on semi-structured tasks; PAL and Corex modes that leverage code or faithfulness selection perform better.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6562.23">
                <h3 class="extraction-instance">Extracted Data Instance 23 (e6562.23)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CoT-SC-SemiStructured</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Self-Consistency (CoT-SC(10)) on semi-structured reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Majority-vote ensemble of CoT chains used as a baseline for semi-structured tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-Turbo-0613</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Self-Consistency (CoT-SC(10))</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>ensemble / majority-vote</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>homogeneous</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Semi-structured (FinQA & ConvFinQA aggregate, Table 4)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Financial QA over tables and text</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy (official scripts)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>54.9</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Self-consistency improves over single CoT but at much higher computational cost; Corex achieves comparable or better performance at substantially lower token/inference cost.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6562.24">
                <h3 class="extraction-instance">Extracted Data Instance 24 (e6562.24)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Model-Judge-Effect</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Judge model capability effect in Discuss mode</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Empirical observation that the capability of the judge model in Discuss mode positively correlates with task performance, particularly as task complexity increases.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4-0613 / Claude-Instant-1.2 (analyzed as judges)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Judge role in multi-agent discussion</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>multi-agent orchestration / role assignment</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>mixed</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Across tasks (analysis section)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>General analysis of effect of judge model capability</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy (task-specific)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Authors report that stronger judges improve final decisions in Discuss mode; by contrast, retriever capability has modest effect because candidate quality sets an upper bound.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Chain of thought prompting elicits reasoning in large language models <em>(Rating: 2)</em></li>
                <li>Self-consistency improves chain of thought reasoning in language models <em>(Rating: 2)</em></li>
                <li>Pal: Program-aided language models <em>(Rating: 2)</em></li>
                <li>Complexity-based prompting for multi-step reasoning <em>(Rating: 2)</em></li>
                <li>Improving factuality and reasoning in language models through multiagent debate <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6562",
    "paper_id": "paper-263334469",
    "extraction_schema_id": "extraction-schema-129",
    "extracted_data": [
        {
            "name_short": "Corex-Discuss",
            "name_full": "Corex Discuss Mode (multi-agent group discussion)",
            "brief_description": "A Corex collaboration paradigm where agents are split into teams that iteratively discuss reasoning chains for up to T rounds to refine factuality and preserve diversity of rationales; a judge agent selects outcomes.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-Turbo-0613",
            "model_size": null,
            "reasoning_method_name": "Group discussion (Corex: Discuss)",
            "reasoning_method_type": "multi-agent collaboration / ensemble",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "Arithmetic (aggregate, Table 1)",
            "task_description": "Grade-school and other arithmetic reasoning datasets (GSM8K, AddSub, SVAMP, etc.)",
            "performance_metric": "accuracy",
            "performance_value": 83.1,
            "comparison_target_method": "CoT-SC(10)",
            "performance_difference": -1.5,
            "statistical_significance": false,
            "analysis_notes": "Discuss preserves factuality and diversity of rationales, enabling teams to refine reasoning without forcing a single consensus; authors report Discuss is effective on factual-knowledge tasks and reaches consensus quickly for most problems.",
            "ablation_study_present": true,
            "uuid": "e6562.0",
            "source_info": {
                "paper_title": "Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "Corex-Review-NL",
            "name_full": "Corex Review Mode (NL reasoning chains)",
            "brief_description": "A Corex paradigm where a primary agent produces a chain-of-thought and other agents sequentially review and revise the NL reasoning chain to reduce cumulative errors and misinterpretations.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-Turbo-0613",
            "model_size": null,
            "reasoning_method_name": "Sequential peer review of Chain-of-Thought (Corex: Review NL)",
            "reasoning_method_type": "multi-agent collaborative verification",
            "reasoning_style_diversity": "mixed",
            "benchmark_name": "Arithmetic (aggregate, Table 1)",
            "task_description": "Grade-school and other arithmetic reasoning datasets",
            "performance_metric": "accuracy",
            "performance_value": 84.6,
            "comparison_target_method": "CoT-SC(10)",
            "performance_difference": 0.0,
            "statistical_significance": false,
            "analysis_notes": "Review mode reduces cumulative reasoning errors via iterative critiques; each review cycle generally improves performance though occasional oscillations occur; authors highlight Review NL's effectiveness for mathematical and counting tasks when using NL-based fixes.",
            "ablation_study_present": true,
            "uuid": "e6562.1",
            "source_info": {
                "paper_title": "Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "Corex-Review-Code",
            "name_full": "Corex Review Mode (code/PAL)",
            "brief_description": "A Corex paradigm where the primary agent generates programmatic solutions (PAL) that are sequentially reviewed and corrected by other agents, with final code executed to obtain answers.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-Turbo-0613",
            "model_size": null,
            "reasoning_method_name": "Sequential peer review with Program-Aided Language Model (Corex: Review Code)",
            "reasoning_method_type": "multi-agent collaborative verification + tool-augmented execution",
            "reasoning_style_diversity": "mixed",
            "benchmark_name": "Arithmetic (aggregate, Table 1)",
            "task_description": "Grade-school and harder arithmetic problems including code-executable solutions (e.g., GSM-Hard)",
            "performance_metric": "accuracy",
            "performance_value": 86.7,
            "comparison_target_method": "CoT-SC(10)",
            "performance_difference": 2.1,
            "statistical_significance": false,
            "analysis_notes": "Review Code repairs buggy programs and mitigates problem misinterpretation; reviewers iteratively receive predecessors' feedback enabling progressively refined code; authors report large gains for hard arithmetic and counting tasks.",
            "ablation_study_present": true,
            "uuid": "e6562.2",
            "source_info": {
                "paper_title": "Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "Corex-Retrieve",
            "name_full": "Corex Retrieve Mode (model-to-model faithfulness ranking)",
            "brief_description": "A Corex paradigm where one agent (retriever) evaluates a pool of candidate (chain, answer) pairs produced by other agents and selects the most faithful pair by scoring faithfulness between chain and answer.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-Turbo-0613",
            "model_size": null,
            "reasoning_method_name": "Retriever-based faithfulness ranking (Corex: Retrieve)",
            "reasoning_method_type": "ensemble + retrieval-based model-to-model evaluation",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "Arithmetic (aggregate, Table 1)",
            "task_description": "Grade-school and other arithmetic reasoning datasets",
            "performance_metric": "accuracy",
            "performance_value": 86.3,
            "comparison_target_method": "CoT-SC(10)",
            "performance_difference": 1.7,
            "statistical_significance": false,
            "analysis_notes": "Retrieve selects the most faithful chain+answer pair rather than majority-voting purely on answers; authors report Retrieve often outperforms majority voting with fewer sampled chains and is reference-free (model-to-model).",
            "ablation_study_present": true,
            "uuid": "e6562.3",
            "source_info": {
                "paper_title": "Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "CoT",
            "name_full": "Chain-of-Thought prompting (CoT)",
            "brief_description": "The single-model chain-of-thought prompting technique where an LLM is prompted to produce intermediate reasoning steps leading to an answer.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-Turbo-0613",
            "model_size": null,
            "reasoning_method_name": "Chain-of-Thought",
            "reasoning_method_type": "sequential / single-model",
            "reasoning_style_diversity": "single style",
            "benchmark_name": "Arithmetic (aggregate, Table 1)",
            "task_description": "Grade-school arithmetic reasoning",
            "performance_metric": "accuracy",
            "performance_value": 80.9,
            "comparison_target_method": "CoT-SC(10)",
            "performance_difference": -3.7,
            "statistical_significance": false,
            "analysis_notes": "CoT produces explicit reasoning chains but can suffer from cumulative errors and plateauing text quality; Corex methods are compared against CoT variants and often improve upon CoT via multi-agent interactions.",
            "ablation_study_present": false,
            "uuid": "e6562.4",
            "source_info": {
                "paper_title": "Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "CoT-SC(10)",
            "name_full": "Self-Consistency with Chain-of-Thought (10 samples)",
            "brief_description": "Self-consistency decoding samples multiple CoT reasoning paths from a single model and selects the final answer by majority vote.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-Turbo-0613",
            "model_size": null,
            "reasoning_method_name": "Self-Consistency (CoT-SC)",
            "reasoning_method_type": "ensemble / majority-vote",
            "reasoning_style_diversity": "homogeneous",
            "benchmark_name": "Arithmetic (aggregate, Table 1)",
            "task_description": "Grade-school arithmetic reasoning",
            "performance_metric": "accuracy",
            "performance_value": 84.6,
            "comparison_target_method": null,
            "performance_difference": null,
            "statistical_significance": false,
            "analysis_notes": "Self-consistency improves CoT by ensembling multiple sampled chains via majority voting but can be computationally expensive and vulnerable to incorrect-majority overpowering correct but minority answers; Corex aims to reduce those drawbacks.",
            "ablation_study_present": false,
            "uuid": "e6562.5",
            "source_info": {
                "paper_title": "Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "ComplexCoT",
            "name_full": "Complexity-based Chain-of-Thought (ComplexCoT)",
            "brief_description": "An ensemble-style CoT variant that selects answers from candidate chains with higher reasoning complexity.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-Turbo-0613",
            "model_size": null,
            "reasoning_method_name": "Complexity-based consistency (ComplexCoT)",
            "reasoning_method_type": "ensemble / heuristic selection",
            "reasoning_style_diversity": "homogeneous",
            "benchmark_name": "Commonsense (aggregate, Table 2)",
            "task_description": "Commonsense and factual reasoning (StrategyQA, CSQA, OpenBookQA, BoolQ, ARC-c)",
            "performance_metric": "accuracy",
            "performance_value": 77.5,
            "comparison_target_method": null,
            "performance_difference": null,
            "statistical_significance": false,
            "analysis_notes": "ComplexCoT prioritizes candidate chains judged to have higher reasoning complexity; the paper reports Corex surpasses ComplexCoT on some datasets (e.g., StrategyQA) without elaborate prompt engineering.",
            "ablation_study_present": false,
            "uuid": "e6562.6",
            "source_info": {
                "paper_title": "Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "PAL",
            "name_full": "Program-Aided Language Model (PAL)",
            "brief_description": "A method where LLMs generate programs as intermediate steps which are executed (e.g., by a Python interpreter) to obtain numerically correct outputs.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-Turbo-0613",
            "model_size": null,
            "reasoning_method_name": "Program-Aided Language Model (PAL)",
            "reasoning_method_type": "tool-augmented / code-execution",
            "reasoning_style_diversity": "single/tool-augmented",
            "benchmark_name": "Symbolic (aggregate, Table 3)",
            "task_description": "Symbolic reasoning tasks from BIG-Bench (Date, Object Counting, Penguins, Colored Objects, Repeat Copy)",
            "performance_metric": "accuracy",
            "performance_value": 88.3,
            "comparison_target_method": "CoT-SC(10)",
            "performance_difference": 7.8,
            "statistical_significance": false,
            "analysis_notes": "PAL provides computational accuracy by offloading arithmetic/computation to interpreters but can still suffer from misinterpretation and buggy code; Corex Review Code combines PAL with multi-agent review to reduce these errors further.",
            "ablation_study_present": false,
            "uuid": "e6562.7",
            "source_info": {
                "paper_title": "Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "Corex-Discuss-CommonSense",
            "name_full": "Corex Discuss Mode (commonsense tasks)",
            "brief_description": "Discuss mode applied to commonsense/factual reasoning datasets; teams exchange factual corrections and judges decide.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-Turbo-0613",
            "model_size": null,
            "reasoning_method_name": "Group discussion (Corex: Discuss)",
            "reasoning_method_type": "multi-agent collaboration / ensemble",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "Commonsense & Factual (aggregate, Table 2)",
            "task_description": "Commonsense QA and factual reasoning (StrategyQA, CSQA, OpenBookQA, BoolQ, ARC-c)",
            "performance_metric": "accuracy",
            "performance_value": 76.8,
            "comparison_target_method": "CoT-SC(10)",
            "performance_difference": 0.3,
            "statistical_significance": false,
            "analysis_notes": "Discuss yields modest gains on commonsense tasks by enhancing factuality; authors note that Discuss is competent for tasks relying on factual knowledge.",
            "ablation_study_present": true,
            "uuid": "e6562.8",
            "source_info": {
                "paper_title": "Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "Corex-Review-NL-CommonSense",
            "name_full": "Corex Review Mode (NL) on commonsense",
            "brief_description": "Sequential peer-review of NL chains applied to commonsense tasks to detect and correct flawed reasoning.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-Turbo-0613",
            "model_size": null,
            "reasoning_method_name": "Sequential peer review of Chain-of-Thought (Corex: Review NL)",
            "reasoning_method_type": "multi-agent collaborative verification",
            "reasoning_style_diversity": "mixed",
            "benchmark_name": "Commonsense & Factual (aggregate, Table 2)",
            "task_description": "Commonsense & factual reasoning",
            "performance_metric": "accuracy",
            "performance_value": 76.4,
            "comparison_target_method": "CoT-SC(10)",
            "performance_difference": -0.1,
            "statistical_significance": false,
            "analysis_notes": "Review NL is applied with only NL chains on commonsense tasks; provides improvements but more limited than Retrieve in some cases.",
            "ablation_study_present": true,
            "uuid": "e6562.9",
            "source_info": {
                "paper_title": "Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "Corex-Retrieve-CommonSense",
            "name_full": "Corex Retrieve Mode on commonsense",
            "brief_description": "Retriever agent ranks candidate chains by faithfulness to choose the final answer on commonsense datasets.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-Turbo-0613",
            "model_size": null,
            "reasoning_method_name": "Retriever-based faithfulness ranking (Corex: Retrieve)",
            "reasoning_method_type": "ensemble + retrieval-based model-to-model evaluation",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "Commonsense & Factual (aggregate, Table 2)",
            "task_description": "Commonsense & factual reasoning",
            "performance_metric": "accuracy",
            "performance_value": 77.6,
            "comparison_target_method": "CoT-SC(10)",
            "performance_difference": 1.1,
            "statistical_significance": false,
            "analysis_notes": "Retrieve consistently facilitates improvements across general tasks by selecting the most faithful explanation+answer pair; retriever model capability has modest impact since candidate quality bounds performance.",
            "ablation_study_present": true,
            "uuid": "e6562.10",
            "source_info": {
                "paper_title": "Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "CoT-CommonSense",
            "name_full": "Chain-of-Thought prompting on commonsense tasks",
            "brief_description": "Single-model CoT evaluated on commonsense and factual QA datasets as baseline.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-Turbo-0613",
            "model_size": null,
            "reasoning_method_name": "Chain-of-Thought",
            "reasoning_method_type": "sequential / single-model",
            "reasoning_style_diversity": "single style",
            "benchmark_name": "Commonsense & Factual (aggregate, Table 2)",
            "task_description": "Commonsense & factual reasoning",
            "performance_metric": "accuracy",
            "performance_value": 74.8,
            "comparison_target_method": "CoT-SC(10)",
            "performance_difference": -1.7,
            "statistical_significance": false,
            "analysis_notes": "CoT is a baseline for commonsense tasks; multi-agent modes in Corex yield modest but consistent improvements.",
            "ablation_study_present": false,
            "uuid": "e6562.11",
            "source_info": {
                "paper_title": "Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "CoT-SC-CommonSense",
            "name_full": "Self-Consistency (CoT-SC(10)) on commonsense",
            "brief_description": "Majority-vote over multiple CoT samples applied to commonsense tasks as a strong baseline.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-Turbo-0613",
            "model_size": null,
            "reasoning_method_name": "Self-Consistency (CoT-SC(10))",
            "reasoning_method_type": "ensemble / majority-vote",
            "reasoning_style_diversity": "homogeneous",
            "benchmark_name": "Commonsense & Factual (aggregate, Table 2)",
            "task_description": "Commonsense & factual reasoning",
            "performance_metric": "accuracy",
            "performance_value": 76.5,
            "comparison_target_method": null,
            "performance_difference": null,
            "statistical_significance": false,
            "analysis_notes": "Serves as a primary baseline; paper contrasts Corex with CoT-SC showing Corex can match or exceed results with fewer inferences and better faithfulness considerations.",
            "ablation_study_present": false,
            "uuid": "e6562.12",
            "source_info": {
                "paper_title": "Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "Corex-Discuss-Symbolic",
            "name_full": "Corex Discuss Mode on symbolic reasoning",
            "brief_description": "Discuss mode applied to symbolic tasks from BIG-Bench to foster factual checks and diverse reasoning.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-Turbo-0613",
            "model_size": null,
            "reasoning_method_name": "Group discussion (Corex: Discuss)",
            "reasoning_method_type": "multi-agent collaboration / ensemble",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "Symbolic (aggregate, Table 3)",
            "task_description": "Symbolic reasoning tasks (Date, Object Counting, Penguins, Colored Objects, Repeat Copy)",
            "performance_metric": "accuracy",
            "performance_value": 80.7,
            "comparison_target_method": "CoT-SC(10)",
            "performance_difference": 0.2,
            "statistical_significance": false,
            "analysis_notes": "Discuss helps factual aspects of symbolic tasks but PAL-based collaboration (Review Code) especially improves tasks like Repeat Copy where CoT-SC struggles to be consistent.",
            "ablation_study_present": true,
            "uuid": "e6562.13",
            "source_info": {
                "paper_title": "Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "Corex-Review-NL-Symbolic",
            "name_full": "Corex Review Mode (NL) on symbolic reasoning",
            "brief_description": "Sequential NL reviewing applied to symbolic tasks to refine reasoning chains and reduce errors.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-Turbo-0613",
            "model_size": null,
            "reasoning_method_name": "Sequential peer review (Corex: Review NL)",
            "reasoning_method_type": "multi-agent collaborative verification",
            "reasoning_style_diversity": "mixed",
            "benchmark_name": "Symbolic (aggregate, Table 3)",
            "task_description": "Symbolic reasoning",
            "performance_metric": "accuracy",
            "performance_value": 82.0,
            "comparison_target_method": "CoT-SC(10)",
            "performance_difference": 1.5,
            "statistical_significance": false,
            "analysis_notes": "Review NL improves consistency and reasoning reliability on symbolic tasks; authors note Review Code can be particularly strong on Repeat Copy when combined with PAL.",
            "ablation_study_present": true,
            "uuid": "e6562.14",
            "source_info": {
                "paper_title": "Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "Corex-Review-Code-Symbolic",
            "name_full": "Corex Review Mode (Code) on symbolic reasoning",
            "brief_description": "PAL-based primary solution reviewed sequentially by agents, used for symbolic tasks to fix code and interpretation errors.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-Turbo-0613",
            "model_size": null,
            "reasoning_method_name": "Sequential peer review with PAL (Corex: Review Code)",
            "reasoning_method_type": "multi-agent collaborative verification + tool execution",
            "reasoning_style_diversity": "mixed",
            "benchmark_name": "Symbolic (aggregate, Table 3)",
            "task_description": "Symbolic reasoning",
            "performance_metric": "accuracy",
            "performance_value": 91.1,
            "comparison_target_method": "PAL",
            "performance_difference": 2.8,
            "statistical_significance": false,
            "analysis_notes": "Review Code achieves particularly high accuracy on symbolic tasks; iterative review eliminates bugs and misinterpretations in generated programs, outperforming both PAL alone and majority-vote approaches in some tasks.",
            "ablation_study_present": true,
            "uuid": "e6562.15",
            "source_info": {
                "paper_title": "Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "Corex-Retrieve-Symbolic",
            "name_full": "Corex Retrieve Mode on symbolic reasoning",
            "brief_description": "Retriever scores candidate chain+answer pairs and selects the most faithful for symbolic tasks.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-Turbo-0613",
            "model_size": null,
            "reasoning_method_name": "Retriever-based faithfulness ranking (Corex: Retrieve)",
            "reasoning_method_type": "ensemble + retrieval-based evaluation",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "Symbolic (aggregate, Table 3)",
            "task_description": "Symbolic reasoning",
            "performance_metric": "accuracy",
            "performance_value": 85.6,
            "comparison_target_method": "CoT-SC(10)",
            "performance_difference": 5.1,
            "statistical_significance": false,
            "analysis_notes": "Retrieve offers more judicious answer selection than majority voting on counting tasks by focusing on faithfulness between chain and prediction.",
            "ablation_study_present": true,
            "uuid": "e6562.16",
            "source_info": {
                "paper_title": "Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "CoT-Symbolic",
            "name_full": "Chain-of-Thought baseline on symbolic reasoning",
            "brief_description": "Single-model CoT evaluated on symbolic BIG-Bench tasks.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-Turbo-0613",
            "model_size": null,
            "reasoning_method_name": "Chain-of-Thought",
            "reasoning_method_type": "sequential / single-model",
            "reasoning_style_diversity": "single style",
            "benchmark_name": "Symbolic (aggregate, Table 3)",
            "task_description": "Symbolic reasoning",
            "performance_metric": "accuracy",
            "performance_value": 73.8,
            "comparison_target_method": "CoT-SC(10)",
            "performance_difference": -6.7,
            "statistical_significance": false,
            "analysis_notes": "CoT struggles on tasks like Repeat Copy; PAL and collaborative approaches can substantially outperform naive CoT in symbolic settings.",
            "ablation_study_present": false,
            "uuid": "e6562.17",
            "source_info": {
                "paper_title": "Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "PAL-Symbolic",
            "name_full": "PAL baseline on symbolic reasoning",
            "brief_description": "Program-aided baseline where generated programs are executed to obtain results on symbolic tasks.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-Turbo-0613",
            "model_size": null,
            "reasoning_method_name": "Program-aided language modeling (PAL)",
            "reasoning_method_type": "tool-augmented / code-execution",
            "reasoning_style_diversity": "single/tool-augmented",
            "benchmark_name": "Symbolic (aggregate, Table 3)",
            "task_description": "Symbolic reasoning",
            "performance_metric": "accuracy",
            "performance_value": 88.3,
            "comparison_target_method": "CoT-SC(10)",
            "performance_difference": 7.8,
            "statistical_significance": false,
            "analysis_notes": "PAL excels in tasks requiring precise computation; combining PAL with multi-agent review (Corex-Review Code) further reduces bugs and misinterpretations.",
            "ablation_study_present": false,
            "uuid": "e6562.18",
            "source_info": {
                "paper_title": "Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "Corex-Discuss-SemiStructured",
            "name_full": "Corex Discuss Mode on semi-structured reasoning",
            "brief_description": "Discuss mode applied to semi-structured tasks (financial QA) to combine factual checks and collaborative reasoning.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-Turbo-0613 (16k for TAT-QA where needed)",
            "model_size": null,
            "reasoning_method_name": "Group discussion (Corex: Discuss)",
            "reasoning_method_type": "multi-agent collaboration / ensemble",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "Semi-structured (FinQA & ConvFinQA aggregate, Table 4)",
            "task_description": "Numerical reasoning over tabular and textual financial reports (FinQA, ConvFinQA)",
            "performance_metric": "accuracy (official scripts)",
            "performance_value": 53.5,
            "comparison_target_method": "CoT-SC(10)",
            "performance_difference": -1.4,
            "statistical_significance": false,
            "analysis_notes": "Discuss provides modest improvement over CoT on semi-structured tasks but Review Code and Retrieve show larger gains due to code-synthesis and faithfulness selection.",
            "ablation_study_present": true,
            "uuid": "e6562.19",
            "source_info": {
                "paper_title": "Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "Corex-Review-Code-SemiStructured",
            "name_full": "Corex Review Code on semi-structured reasoning",
            "brief_description": "PAL-based primary solutions reviewed and executed to handle semi-structured financial QA, reducing computational errors.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-Turbo-0613 (GPT-3.5-Turbo-16k for some datasets)",
            "model_size": null,
            "reasoning_method_name": "Sequential review + PAL execution (Corex: Review Code)",
            "reasoning_method_type": "multi-agent collaborative verification + tool execution",
            "reasoning_style_diversity": "mixed",
            "benchmark_name": "Semi-structured (FinQA & ConvFinQA aggregate, Table 4)",
            "task_description": "Financial question answering spanning tables and text",
            "performance_metric": "accuracy (official scripts)",
            "performance_value": 55.1,
            "comparison_target_method": "CoT-SC(10)",
            "performance_difference": 0.2,
            "statistical_significance": false,
            "analysis_notes": "Review Code attains the best average among Corex modes for semi-structured tasks by repairing programs and ensuring computational fidelity.",
            "ablation_study_present": true,
            "uuid": "e6562.20",
            "source_info": {
                "paper_title": "Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "Corex-Retrieve-SemiStructured",
            "name_full": "Corex Retrieve Mode on semi-structured reasoning",
            "brief_description": "Retriever evaluates candidate explanatory chains and selects the most faithful for semi-structured financial QA.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-Turbo-0613 (16k for TAT-QA when used)",
            "model_size": null,
            "reasoning_method_name": "Retriever-based faithfulness ranking (Corex: Retrieve)",
            "reasoning_method_type": "ensemble + retrieval-based evaluation",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "Semi-structured (FinQA & ConvFinQA aggregate, Table 4)",
            "task_description": "Financial QA (table+text)",
            "performance_metric": "accuracy (official scripts)",
            "performance_value": 56.6,
            "comparison_target_method": "CoT-SC(10)",
            "performance_difference": 1.7,
            "statistical_significance": false,
            "analysis_notes": "Retrieve improves final-answer faithfulness by selecting chain+answer pairs; authors note reduced computational cost relative to majority-vote ensembles while retaining or improving accuracy.",
            "ablation_study_present": true,
            "uuid": "e6562.21",
            "source_info": {
                "paper_title": "Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "CoT-SemiStructured",
            "name_full": "Chain-of-Thought baseline on semi-structured reasoning",
            "brief_description": "CoT baseline evaluated on semi-structured financial QA datasets.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-Turbo-0613",
            "model_size": null,
            "reasoning_method_name": "Chain-of-Thought",
            "reasoning_method_type": "sequential / single-model",
            "reasoning_style_diversity": "single style",
            "benchmark_name": "Semi-structured (FinQA & ConvFinQA aggregate, Table 4)",
            "task_description": "Financial numerical reasoning over tables and text",
            "performance_metric": "accuracy (official scripts)",
            "performance_value": 48.3,
            "comparison_target_method": "CoT-SC(10)",
            "performance_difference": -6.6,
            "statistical_significance": false,
            "analysis_notes": "CoT shows lower performance on semi-structured tasks; PAL and Corex modes that leverage code or faithfulness selection perform better.",
            "ablation_study_present": false,
            "uuid": "e6562.22",
            "source_info": {
                "paper_title": "Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "CoT-SC-SemiStructured",
            "name_full": "Self-Consistency (CoT-SC(10)) on semi-structured reasoning",
            "brief_description": "Majority-vote ensemble of CoT chains used as a baseline for semi-structured tasks.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-Turbo-0613",
            "model_size": null,
            "reasoning_method_name": "Self-Consistency (CoT-SC(10))",
            "reasoning_method_type": "ensemble / majority-vote",
            "reasoning_style_diversity": "homogeneous",
            "benchmark_name": "Semi-structured (FinQA & ConvFinQA aggregate, Table 4)",
            "task_description": "Financial QA over tables and text",
            "performance_metric": "accuracy (official scripts)",
            "performance_value": 54.9,
            "comparison_target_method": null,
            "performance_difference": null,
            "statistical_significance": false,
            "analysis_notes": "Self-consistency improves over single CoT but at much higher computational cost; Corex achieves comparable or better performance at substantially lower token/inference cost.",
            "ablation_study_present": false,
            "uuid": "e6562.23",
            "source_info": {
                "paper_title": "Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "Model-Judge-Effect",
            "name_full": "Judge model capability effect in Discuss mode",
            "brief_description": "Empirical observation that the capability of the judge model in Discuss mode positively correlates with task performance, particularly as task complexity increases.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4-0613 / Claude-Instant-1.2 (analyzed as judges)",
            "model_size": null,
            "reasoning_method_name": "Judge role in multi-agent discussion",
            "reasoning_method_type": "multi-agent orchestration / role assignment",
            "reasoning_style_diversity": "mixed",
            "benchmark_name": "Across tasks (analysis section)",
            "task_description": "General analysis of effect of judge model capability",
            "performance_metric": "accuracy (task-specific)",
            "performance_value": null,
            "comparison_target_method": null,
            "performance_difference": null,
            "statistical_significance": null,
            "analysis_notes": "Authors report that stronger judges improve final decisions in Discuss mode; by contrast, retriever capability has modest effect because candidate quality sets an upper bound.",
            "ablation_study_present": true,
            "uuid": "e6562.24",
            "source_info": {
                "paper_title": "Corex : P USHING THE B OUNDARIES OF C OMPLEX R EA - SONING THROUGH M ULTI -M ODEL C OLLABORATION",
                "publication_date_yy_mm": "2023-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Chain of thought prompting elicits reasoning in large language models",
            "rating": 2,
            "sanitized_title": "chain_of_thought_prompting_elicits_reasoning_in_large_language_models"
        },
        {
            "paper_title": "Self-consistency improves chain of thought reasoning in language models",
            "rating": 2,
            "sanitized_title": "selfconsistency_improves_chain_of_thought_reasoning_in_language_models"
        },
        {
            "paper_title": "Pal: Program-aided language models",
            "rating": 2,
            "sanitized_title": "pal_programaided_language_models"
        },
        {
            "paper_title": "Complexity-based prompting for multi-step reasoning",
            "rating": 2,
            "sanitized_title": "complexitybased_prompting_for_multistep_reasoning"
        },
        {
            "paper_title": "Improving factuality and reasoning in language models through multiagent debate",
            "rating": 1,
            "sanitized_title": "improving_factuality_and_reasoning_in_language_models_through_multiagent_debate"
        }
    ],
    "cost": 0.025988999999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Corex: PUSHING THE BOUNDARIES OF COMPLEX REA-SONING THROUGH MULTI-MODEL COLLABORATION</p>
<p>Qiushi Sun  qiushisun@u.nus.edu 
Zhangyue Yin 
Xiang Li xiangli@dase.ecnu.edu.cn 
Zhiyong Wu wuzhiyong@pjlab.org.cn 
Xipeng Qiu xpqiu@fudan.edu.cn 
Lingpeng Kong </p>
<p> Shark-NLP
Shanghai AI Laboratory  Fudan University  National University of Singapore  East China Normal University
The University of Hong Kong</p>
<p>Shanghai AI Laboratory</p>
<p>Corex: PUSHING THE BOUNDARIES OF COMPLEX REA-SONING THROUGH MULTI-MODEL COLLABORATION
98537E25DC42F57719B25FF6F59B01E9
Large Language Models (LLMs) are evolving at an unprecedented pace and have exhibited considerable capability in the realm of natural language processing (NLP) with world knowledge.Benefiting from ultra-large-scale training corpora, a single LLM can manage typical NLP tasks competently.However, its performance in executing complex tasks is still confined by the limitations of its internal representation.To push this boundary further, we introduce Corex, a suite of novel general-purpose strategies that transform LLMs into autonomous agents, pioneering multi-agent collaborations for task-solving.Inspired by human behaviors, Corex is constituted by diverse collaboration paradigms including Discuss, Review, and Retrieve modes, which collectively work towards enhancing the reasoning process.These paradigms foster task-agnostic approaches that enable LLM-based agents to "think outside the box," thereby overcoming common errors and providing better solutions.Through extensive experiments across four different types of reasoning tasks, we demonstrate that orchestrating multiple agents to work in concert yields better results compared to existing strong methods.Further analysis reveals the cost-effectiveness of Corex, while also exploring synergies between models of various scales and promoting annotation efficiency."A problem shared is a problem halved."-English Proverb</p>
<p>INTRODUCTION</p>
<p>Large Language Models (LLMs) have succeeded in advancing the state-of-the-arts for a series of Natural Language Processing (NLP) tasks (Brown et al., 2020;Chowdhery et al., 2022;OpenAI, 2023;Touvron et al., 2023;Zhao et al., 2023a, inter alia).Recent research (Wei et al., 2022a) indicates that scaling up models (Kaplan et al., 2020) can yield improvements in both performance and sample efficiency across a broad spectrum of downstream tasks.Notwithstanding their remarkable proficiency in language understanding and instruction following (Ouyang et al., 2022), the reasoning abilities of LLMs, often seen as a hallmark for assessing their potential, still present challenges (Suzgun et al., 2023;Huang &amp; Chang, 2023).Concurrently, there is a prevailing view that merely increasing the size might not adequately address their inherent limitations in solving reasoning tasks (Rae et al., 2022).</p>
<p>In response to this challenge, Wei et al. (2022b) put forth chain-of-thought (CoT) prompting that an LLM generates a series of intermediate steps toward a final answer, contrasting the use of "answeronly" prompts.Subsequently, various approaches have been put forward, such as self-consistency decoding (Wang et al., 2023e) which utilizes a majority voting mechanism to determine the final answer, and program-aided language models (PAL; Gao et al., 2022;Chen et al., 2022a) that leverage code generation to reduce errors in computations.Besides, curated prompts necessitate task-specific designs (Zheng et al., 2023a) have also been utilized to elicit more accurate predictions.Nevertheless, these approaches are confined within a static black box (Yao et al., 2023b), wherein the LLM relies exclusively on its internal representation for generating responses and is prone to generating unreliable answers (Ji et al., 2023;Yin et al., 2023b).These shortcomings underscore that relying # Python code def solution(): # Iterating through possible counts of queen bees for x in range(1, 700): if x + x + 2 + x + 4 == 700:</p>
<p>return 2<em>2</em>x # Return worker bee count</p>
<p>Codes fail to accurately reflect the problem statement.</p>
<blockquote>
<blockquote>
<blockquote>
<p>Python Interpreter &gt;&gt;&gt; None</p>
</blockquote>
</blockquote>
</blockquote>
<p>Misunderstanding the relationship between variables.Wrong calculation.</p>
<p>Review Retrieve Discuss</p>
<p>Figure 2: An intuitive illustration of Corex, employs LLM-based agents to collaboratively solve a problem.The strategies encompass the Discuss, Review, and Retrieve modes, leveraging both the reasoning process and code synthesis.This framework facilitates interactions between models that foster a collaborative environment for the derivation of a well-reasoned answer.solely on crafting decoding strategies and specialized prompts may not serve as a silver bullet for addressing complex reasoning tasks (Qiao et al., 2023).Moreover, recent studies (Huang et al., 2023;Valmeekam et al., 2023;Stechly et al., 2023) reveal that LLMs struggle to reach better responses through self-correction.Alternatively, transforming LLMs into autonomous agents and enabling them to "think outside the box" emerges as a promising yet underexplored pathway.</p>
<p>Within the realm of well-established sociological concepts, multiple cognitive processes interact and cooperate will produce a combined effect that is greater than the sum of their individual contributions (Luppi et al., 2022).This principle is echoed within artificial intelligence (Li et al., 2023a).Although the study of intelligent agents has been explored for decades (Minsky, 1988;2007), the advent of LLMs has rejuvenated interest and introduced novel challenges in this domain.An emerging perspective is that encouraging collaboration and communication between models could potentially pave the way for a new stage for enhancing complex reasoning capabilities.</p>
<p>In this study, we propose Corex, a suite of human-inspired strategies that leveraging multi-model collaboration to elicit reasoning for complex task-solving.To facilitate synergies between models, we first assign distinct personas to different models, followed by the design of various collaborative paradigms.This collective intelligence-based method aims to conquer prevalent obstacles in the current landscape of reasoning, as exemplified in Figure 1.It also endeavors to alleviate common issues observed in majority voting-based methods like self-consistency, where accurate responses might be overwhelmed by incorrect ones and exorbitant costs.To be specific, Corex configures LLMs as a group of autonomous agents, adopting the paradigms shown in Figure 2 for multi-model collaboration: (1) Discuss, utilizing group-based discussions among models to effectively enhance factuality and diversity of rationales, thereby reducing fallacies and hallucinations; (2) Review, enabling models to scrutinize reasoning chains or synthesized codes from their counterparts to ensure the correctness of generated contents, coupled with potential refinements; (3) Retrieve, aiming to enable the model to identify the most faithful option from a pool of candidate chains by ranking, facilitates a higher degree of alignment with the final response.Together, Discuss's critical analysis, Review's focus on reliability, and Retrieve's alignment with faithful response -create a comprehensive approach to complex reasoning tasks.</p>
<p>We conduct extensive experiments across four types of tasks: mathematical reasoning, symbolic reasoning, commonsense reasoning, and semi-structured reasoning.The results illustrate that our method achieves substantial performance gains over previous strong baselines.Moreover, each mode distinctly excels in different categories of tasks, showcasing its specific strengths.Further analysis reveals that, compared to existing schemes based on majority voting and curated prompts, Corex significantly reduces the reasoning overhead of the models, achieving multifaceted cost-effectiveness.</p>
<p>RELATED WORKS</p>
<p>Chain-of-Thought Prompting Elicits LLM Reasoning.Chain-of-Thought (CoT; Wei et al., 2022b) prompting, as one of the celebrated capabilities of recent LLMs, is a pivotal breakthrough for performing complex multi-step reasoning when provided with limited examples.Further variants show that CoT can be improved by adding certain "magic phrases" (Kojima et al., 2022), automated demonstrations construction (Zhang et al., 2023a), reasoning in different modalities (Zhang et al., 2023b;Yang et al., 2023;Yao et al., 2023c), and applying modular approaches (Khot et al., 2023).For robustness, researchers transform problems into interleaved reasoning chains (Zhou et al., 2023;Lyu et al., 2023) or adopt ensembling (Wang et al., 2022).Notably, self-consistency methods (Wang et al., 2023e) select answers from multiple reasoning paths by majority voting, have greatly elevated the performance of LLMs in complex reasoning.This approach has been further optimized by utilizing prompts with higher complexity (Fu et al., 2023c).Lately, Yao et al. (2023a) employ heuristic-guided search on "trees" constructed from thoughts to assist LLMs in navigating the problem space.External Knowledge &amp; Tool Utilization for LLM Reasoning.While LLMs exhibit significant capabilities, they are limited by a lack of real-world grounded experience (Petroni et al., 2020) and an inability to grasp complex arithmetic reasoning, given that their training is exclusively based on written text.Thus, researchers start utilizing external knowledge to assist models in accomplishing reasoning tasks (Nakano et al., 2022;Schick et al., 2023).For enhanced factuality and faithfulness, He et al. (2022) and Wang et al. (2023c) make use of external knowledge bases.Lately, Gao et al. (2023) ensure the factual correctness and verifiability of generated text by providing cited passage.</p>
<p>Another line is to delegate reasoning tasks to external tools (Qin et al., 2023), which are commonly used for addressing numerical problems.One of the representatives is program-aided Language model (Gao et al., 2022), known as PAL 1 .Such an approach utilizes LLMs to interpret NL problems, generating programs as intermediate reasoning steps (Chen et al., 2022a) that will be offloaded to a Python interpreter for execution to get final solutions (Ni et al., 2023).This method transforms reasoning into an NL2Code (Zan et al., 2023) task and has been demonstrated to excel when dealing with larger, non-integer numbers and enabling error corrections (Olausson et al., 2023).Beyond synthesizing programs, Liu et al. (2023a) integrate a computational physics engine into the language modeling process for simulation.Moreover, Chameleon (Lu et al., 2023a) augments LLMs by incorporating both tools and knowledge resources like web engines and image captioners.Multi-Model Synergy for Task Solving.Utilizing multiple LLMs collectively to solve problems is still in its preliminary stages, with a wealth of opportunities awaiting exploration.The cornerstone of collaboration is constructing a human-like reasoning architecture (Zhu et al., 2023) for LLMs under different environments (Liu et al., 2023b).Fu et al. (2023b) investigate whether multiple LLMs can autonomously enhance their performance through mutual interactions.Du et al. (2023) and Liang et al. (2023) explore enhancing the factuality of specific tasks, e.g., translation and arithmetic reasoning, by facilitating "debates" among multiple models.LLMs' collaboration has also been applied to software development (Qian et al., 2023) and text evaluation (Chan et al., 2023) by assigning identities to models to simulate the development process.Furthermore, from the perspective of social intelligence, inducing cognitive synergy and having them take on different characters (Wang et al., 2023f) during task execution has been proven to have significant potential (Sclar et al., 2023).Recently, the nascent exploration into artificial societies (Park et al., 2023) also seeks to harness collective intelligence to emulate the efficiency of human social structures (Li et al., 2023a;Webb et al., 2023).More recently, Yin et al. (2023a) proposed cross-model commutation based on network topological structures.</p>
<p>Corex</p>
<p>We propose Corex, a suite of collaborative reasoning approaches inspired by human social interactions.Three main components: Discuss, Review, and Retrieve modes are introduced in the following sections.Let us assume a set of LLM-based agents {A 1 , A 2 , . . ., A n } participating in multi-model collaboration.Each agent A i generates the corresponding reasoning chain c i and its prediction p i when facing a query q.</p>
<p>DISCUSS</p>
<p>Information exchange between models contributes to enhanced factuality (Wang et al., 2023a).In Discuss mode, our LLM-based agents are divided randomly into two groups, the Blue Team and the Green Team, with one reserved as a judge denoted as A j .The discussion within one team involves several rounds, limited to a maximum of T rounds of communications.In each round t (t = 1, 2, . . ., T ), the agents engage in iterative discussions2 to refine their reasoning chains and predictions.This dynamic interaction allows for the continual modification of viewpoints for q, as expressed by c Diverging from previous works (Du et al., 2023;Liang et al., 2023;Xiong et al., 2023) employing "debates" among LLMs, our approach adopts the concept of group discussions.We opt not to facilitate models in jointly exchanging their reasoning processes to converge on a single common answer for several reasons: (1) The limited context length inhibits the ability to hold the communication process, (2) A single final answer is not always correct, as erroneous consensus or biases among models can occur (Wang et al., 2023d), (3) Given the performance gaps among various LLMs, there is a risk of strong models "monopolizing" the collaborations, thereby overshadowing the insights from others.Therefore, we aim to preserve both the factuality and the diversity of thoughts among agents.</p>
<p>REVIEW</p>
<p>Within the scope of reasoning, both CoT and PAL are effective methods with distinct strengths.Grounded in natural language, CoT-based methods stand out for the generality and the clarity of explanations.In contrast, facilitated by programs, PAL guarantees computational accuracy (Zhao et al., 2023b).However, they both exhibit drawbacks due to the reliance on LLMs' internal representations.For CoT and its variants, issues are twofold: (1) Cumulative errors, where mistakes tend to amplify and propagate throughout the reasoning chain; and (2) A plateau in text quality that cannot be substantially improved through prompting (Xu et al., 2022;Li et al., 2023b).Alternatively, PAL faces its own challenges: (1) LLMs might misinterpret questions, which inadvertently results in technically correct yet misguided programs; and (2) Generated codes are not always error-free: LLMs may potentially write buggy codes, such as referencing undefined variables or engaging in "Division by Zero" operations.Inspired by recent efforts of LLMs peer-rating (Zheng et al., 2023b) and collaborative coding practices prevalent in software engineering, we introduce the Review mode to address the aforementioned issues through multi-agent collaboration.To be specific, a single agent A p is randomly selected to act as the primary agent.Initially, A p takes the responsibility of formulating corresponding reasoning chains for q along with the prediction,</p>
<blockquote>
<blockquote>
<blockquote>
<p>Python Interpreter &gt;&gt;&gt; 95</p>
</blockquote>
</blockquote>
</blockquote>
<p>Question: While building the house, Charlie noticed that they were running out of nails so he told his father he's going to buy some.If they still have 9 nails left and Charlie bought 2 boxes of nails, the big one containing 55 nails and the small one containing 31, how many nails will they have?p is then subjected to iterative reviews by the other agents that function as reviewers in a sequential manner, rigorously scrutinizing both the reasoning chain and the code formulated by A p or modified by preceding reviewers.It is crucial to highlight that each reviewer receives input from its predecessors, signifying that each subsequent review is grounded on the outcomes and feedback of the preceding ones, fostering a progressively refined solution.</p>
<p>The reviewing process is formalized as
S (i+1) p = R i (S (i) p , F i ),
where R i encapsulates the review outcome at the i th iteration and F i represents the feedback received.In essence, the solution set S .Specifically, the final prediction a (n1) p is chosen as the answer for q, and in instances where code is involved, the last revised version m (n1) p is executed by a Python interpreter to produce the outcome.</p>
<p>RETRIEVE</p>
<p>Agent2:</p>
<p>The composition of carbohydrates is described by option (C), amino bonding to form polysaccharides.So the answer is (C).</p>
<p>Agent3:</p>
<p>The correct answer is (D) saccharides bonding to form polysaccharides. Carbohydrates are composed of monosaccharides that can join together through a process called dehydration synthesis to form larger polysaccharides.So the answer is (D).</p>
<p>Agent4: Option (C), saccharides bonding to form polypeptides, describes the composition of carbohydrates.So the answer is (C).</p>
<p>Agent5(Retriever):</p>
<p>The confidence scores are: [0.9, 0.2, 0.9, 0.1].Agents 2, 4 made errors in their descriptions.Specifically, Agent 2 confused amino acids with saccharides, while Agent 4 incorrectly stated that saccharides bond to form polypeptides.In reality, saccharides bond to form polysaccharides. Thus, they are not faithful in their responses.Agents 1 and 3 are correct.In the final thread of work, we delve into the Retrieve mode to identify the most faithful answer through collaborations.While previous strategies based on majority voting mechanism (Wang et al., 2023e;Fu et al., 2023c) can mitigate the low-diversity issue of techniques such as beam-search (Li &amp; Jurafsky, 2016), they still present the following two significant challenges: (1) Correct answers risk being swayed by incorrect ones.(2) Despite facilitating a notable enhancement in performance, it exponentially escalates the computational burden and tends to reach a performance "saturation point" as the sampled chains increase.We attribute these drawbacks to the limited scope of majority voting techniques that singularly prioritize the prediction while overlooking the faithfulness of reasoning chains (Li et al., 2023c).In response, we propose the Retrieve mode, a paradigm specifically engineered to evaluate whether the answer can be expressed by the content (explanation) generated during reasoning (Jacovi &amp; Goldberg, 2020;Lanham et al., 2023).</p>
<p>Concretely, given a query q, we randomly select an agent A r from the pool of n agents to act as the retriever.The remaining agents {A 1 , A 2 , . . ., A n1 } independently perform CoT reasoning about q.Each of these agents derives its own reasoning chains c i and corresponding predictions p i .Together, they form a candidate pool, denoted by
P = {(c i , p i )} n1 i=1
The retriever A r then scrutinizes the candidates in P. For (c i , p i ), A r evaluates the faithfulness between c i and p i .Based on this assessment, the retriever assigns a confidence score s i in the range [0, 1], which is denoted as: s i = f r (c i , p i ) where f r indicates the retriever's evaluation process.After that, the most faithful response to the question q is then determined by the highest confidence:
(c * , p * ) = argmax (c i ,p i )P s i
Here, (c * , p * ) denotes the chain-prediction pair that the retriever considers most faithful, which will serve as the final answer for the query q.</p>
<p>Retrieve mode enables the selection of the most aligned combination of reasoning chains and answers from a diversified candidate pool.Distinct from previous text quality assessment methods, which rely on the log probability of sequences (Adiwardana et al., 2020) that is computationally inefficient and often unavailable for commercial LLMs, our approach is entirely predicated on model-to-model interactions (Chen et al., 2023) and is reference-free.</p>
<p>EXPERIMENT 4.1 EXPERIMENTAL SETUP</p>
<p>Tasks and Datasets.We evaluate Corex across four types of tasks: (1) Arithmetic reasoning across various difficulties, such as GSM8K (Cobbe et al., 2021) and GSM-Hard (Gao et al., 2022).( 2) Commonsense reasoning covering four datasets, exemplified by StrategyQA (Geva et al., 2021).</p>
<p>(3) Symbolic reasoning incorporating four tasks derived from BigBench (bench authors, 2023).( 4) Semi-structured understanding, like FinQA and ConvFinQA (Chen et al., 2021b;2022b).Detailed descriptions and statistics of tasks are listed in Appendix D.</p>
<p>Baselines.We compare our method with several widely used strong baselines.(1) Chain-of-Thought prompting (CoT; Wei et al., 2022b).(2) Self-Consistency (CoT-SC; Wang et al., 2023e), which employs a majority voting mechanism to select the most consistent answer from several reasoning chains as the final answer.(3) Complexity-based consistency (ComplexCoT; Fu et al., 2023c) that selects the majority answer from the candidates with higher reasoning complexity.(4) Program-aided language model (PAL; Gao et al., 2022;Chen et al., 2022a) that uses LLMs to generate programs as intermediate reasoning steps, while offloading the computation to a Python interpreter.</p>
<p>For simplicity and ease of understanding, we denote CoT-SC(x) and ComplexCoT(x) in our experiments and analysis to represent cases utilizing different reasoning paths, where "x" indicates the number of output chains.For all baseline methods, we adhere to the few-shot exemplars to ensure fair comparisons.Details can be found in Appendix B.</p>
<p>Implementation Details.We access OpenAI and Anthropic models through their respective APIs.Specifically, we employ GPT-3.5-Turbo-0613 for evaluating both Corex and baseline methods in the main experiments.Moreover, in further experiments and analysis involving different LLMs for collaboration, we also incorporate the use of GPT-4-0613 and Claude-Instant-1.2.The details of prompts and hyperparameter settings for both baselines and Corex are in Appendix F.</p>
<p>MAIN RESULTS</p>
<p>We report the results of Corex over four categories of tasks.For each kind of task, the best results are highlighted in bold and the second best results are marked with underline.For Review mode, we use Corex-Review NL and Corex-Review Code to describe the scenarios that use CoT or PAL respectively.All modes within Corex are configured to operate with 5 LLM-based agents, ensuring favorable cost-effectiveness.For Corex-Discuss, the upper bound of discussion rounds is set to 5. Mathematical Reasoning.Table 1 shows the results across arithmetic tasks with varying difficulties.</p>
<p>Our method achieves notable performance improvements on most benchmarks.</p>
<p>Broadly, we surpass the performance of CoT-SC(10) when only 5 agents are involved.Moreover, given the task-agnostic nature of Corex, it can tackle highly complex computational challenges like GSM-Hard through code synthesis.For problems of relatively lower complexity, the Retrieve mode can identify answers superior to those from majority voting.</p>
<p>Commonsense Reasoning.Table 2 showcases the performance of Corex in commonsense and factual reasoning tasks.Due to the nature of commonsense reasoning tasks, the Review mode only utilizes NL reasoning chains.We can observe that various modes contribute to performance enhancements.information and performing calculations simultaneously (Lu et al., 2023b), methods such as CoT-SC offer limited gains.However, through various cooperative paradigms, significant performance improvements can be achieved.Due to the context length restriction of GPT-3.5-Turbo,our experiments on TAT-QA utilized GPT-3.5-Turbo-16k, with the respective results being detailed in Appendix C.1, alongside the evaluations on the other tasks.</p>
<p>Following our extensive experiments across 18 tasks, it emerges that the Discuss mode is competent for tasks utilizing factual knowledge.For challenging mathematical and counting tasks, the Review mode serves to effectively mitigate errors within the reasoning chains and repair flawed code (further analysis of error-types is provided in Appendix C.4). Across various tasks, the Retrieve mode consistently facilitates performance improvements to varying degrees on general tasks.</p>
<p>ANALYSIS</p>
<p>In this section, we first aim to make the collaboration process transparent by delving into models' internal behaviors.Then, the influence of different backbones is examined to observe how model capability affects performance.Further, we assess the efficiency of Corex.</p>
<p>IN-DEPTH ANALYSIS OF Corex STRATEGIES</p>
<p>Analysis of Interaction Rounds in Discuss Mode.We study the number of rounds of communication in the Discuss mode of Corex on five tasks, as depicted in Figure 6.Consensus can be reached swiftly for the majority of problems by each team.However, Corex enables LLMs to engage in more exhaustive discussions for problems that are challenging to reach a consensus on (e.g., over 10% of ConvFinQA problems requiring more than 3 rounds), a small proportion of problems require more interactions.Through observation, we also notice that the Discuss mode exhibits favorable convergence properties, wherein the interactive process serves as a basis for the judge's decision-making.Performance Enhancement per Review.We explore the incremental performance gains achieved in specific tasks with each review cycle in the Review mode.As is demonstrated in Figure 7, we conduct analyses for Repeat Copy and GSM8K with Review Code , as long as BoolQ and Penguin with Review NL .The findings indicate that each review contributes to performance enhancement in general, yet occasional deviations leading to performance oscillations are also observed.Further analysis of error types and gains from collaborations is presented in Appendix C.4.</p>
<p>SYNERGIES BETWEEN DIFFERENT LLMS</p>
<p>Performance Variability with Diverse LLMs as Judges.The backbone LLMs of our agents can be diverse.In this part, we discuss the performance when employing different LLMs during the discussion.As shown in Figure 8, we deploy GPT-3.5-Turbo as players and examine the dynamics when different LLMs take the role of judges.The observations indicate that the capability of the judge positively correlates with task performance, with this relationship being evident as the complexity of tasks escalates.Empirically, This can be attributed to the judge's role, which requires understanding both the question and the reasoning process of both parties.</p>
<p>Utilizing Different LLMs as Retrievers.In Retrieve mode, the role of the retriever can be played by various LLMs.Based on the candidate answers from GPT-3.5-Turbo agents, we here explore the impact of model selection on the performance, as depicted in Figure 9. Unlike the discuss mode, our analysis reveals that the model capabilities exert a modest effect on the performance.Given that the performance upper bound is determined by the candidates' capabilities, the outcomes using different LLMs as retrievers show minimal variance on tasks like ARC-c.Notably, our findings indicate that without the need for especially potent models as retrievers, we can still achieve favorable results.</p>
<p>COST-EFFECTIVENESS OF MULTI-AGENT COLLABORATIONS</p>
<p>By encouraging collaboration between LLM-based agents, we manage to reduce the costs associated with reasoning tasks while achieving comparable or even superior performance.Figure 10: Cost-effectiveness analysis.the x-axis represents the computational costs, calculated in terms of input/output tokens, while the size of each dot is proportional to the avg.number of inferences by each method.</p>
<p>Based on our analysis conducted on AddSub illustrated in Figure 10, it reveals that all three modes of Corex consistently match or surpass the prowess of other strong baselines.Significantly, the computational cost of our approach is substantially diminished in comparison to methods using majority voting.In achieving equivalent performance, the resource consumption of Corex is confined to a mere 5-10% of that expended by other strategies.To substantiate the generality, we've provided additional experiments in Appendix C.2, which further demonstrate a similar trend.</p>
<p>Beyond the efficiency of computational costs, another advantage of Corex is its annotation efficiency, which reduces the reliance on curated demonstrations.Further experiments with varying numbers of demonstrations on this aspect can be found in Appendix C.3.</p>
<p>CONCLUSION</p>
<p>We introduce Corex in this paper, a suite of strategies that transform LLMs into autonomous agents, thereby leveraging multi-model collaboration for complex reasoning.This offers a preliminary exploration into the LLM-based multi-model ecosystems.Through unlocking the synergies among LLMs, Corex empowers reasoning with enhanced factuality, faithfulness, and reliability through various collaboration paradigms.We conduct extensive evaluations across 18 tasks within 4 categories, and the results demonstrate superior performance compared to previous solutions.Moreover, our methods also exhibit multiple notable advantages including being task-agnostic, cost-effective, and annotation-efficient.We hope that this work may serve as a foundation for further research, offering novel perspectives in complex reasoning, collective intelligence, and autonomous agents.</p>
<p>A LIMITATIONS AND BROADER IMPACTS</p>
<p>Considering performance constraints, open-source models were not incorporated in this study.However, we hold the view that the collaboration of several relatively weaker open-source models (Zhang et al., 2022;Touvron et al., 2023) might enable them to conquer tasks that only stronger commercial models (Bai et al., 2022;OpenAI, 2023) could previously accomplish.Since we have empirically demonstrated that model collaboration can help reduce redundant computations and resource usage, it is foreseeable that the efficiency can be further accentuated when integrating open-source models into the collaboration framework, making the development of general artificial intelligence more sustainable (Hessenthaler et al., 2022).Also, this may enhance the diversity to address the issues of biases and misconceptions inherent to a single model (Sun et al., 2022;Shaikh et al., 2023) can be mitigated, promoting the fairness of future AI systems (Hendrycks et al., 2021).</p>
<p>At the same time, we also observe the emergence of instability when integrating the functions of multiple LLMs.This highlights the need for better strategies to orchestrate the interaction among models with unique attributes and capabilities (Parsons &amp; McBurney, 2003;Dorri et al., 2018), which we identified as a pivotal direction for future research.</p>
<p>C.3 ANNOTATION EFFICIENCY ANALYSIS</p>
<p>Due to the scarcity and instability of curated prompts (Ye &amp; Durrett, 2022), we aim to mitigate reliance on them through multi-model collaboration.We conduct experiments in scenarios with varying numbers of demonstrations to assess the effectiveness of our approach.As depicted in Figure 13 and Figure 14, we demonstrate the performance of the Review mode and Retrieve mode under different shots.The results reveal a marginal impact of the number of few-shot examples on performance, underscoring the annotation efficiency of our approach.</p>
<p>Date</p>
<p>C.4 ANALYSIS OF ERROR WITH DIFFERENT TYPES</p>
<p>In section 5.1, we analyze the performance changes brought about by each review cycle.Here, we further delve into an analysis of the errors made by the models and how collaborations help in mitigating these errors on GSM8K and GSM-Hard datasets.</p>
<p>Our analysis focuses on the Review Code mode.The types of errors in this mode, as discussed in section 3.2, can be categorized into (1) Bugs, where generated codes are not always error-free, and</p>
<p>(2) Problem misinterpretation, where models produce technically correct yet misguided programs.As depicted in Figure 15, following the review process, there is a noticeable reduction in both types of errors committed by LLMs on GSM8K.Moreover, as illustrated in Figure 16, it can be observed that in more challenging problems from GSM-Hard, collaboration leads to the elimination of a greater number of errors caused by incorrect problem understanding.</p>
<p>D STATISTICS AND DETAILS OF DATASETS</p>
<p>The detailed information of each dataset is shown in the follow:</p>
<p>Arithmetic reasoning</p>
<p> Grade School Math (GSM8K; Cobbe et al., 2021): Linguistically diverse grade school math word problems created by human problem writers.The problems take between 2 and 8 steps to solve and involve elementary calculations using basic arithmetic operations. AddSub (Hosseini et al., 2014): A set of simple arithmetic word problems.</p>
<p> SVAMP (Patel et al., 2021): A challenge set for elementary-level Math Word Problems.</p>
<p> SingleOP, SingleEQ and MultiArith (Koncel-Kedziorski et al., 2016): Grade-school math dataset that aims at solving multi-sentence algebraic word problems. GSM-Hard (Gao et al., 2022): A harder version of the GSM8K dataset, constructed by replacing the numbers in the questions of GSM8K with larger numbers.</p>
<p>Table 6: Examples from mathematical reasoning datasets used in this work.</p>
<p>Dataset N Example</p>
<p>GSM8K (Cobbe et al., 2021) 1,319 A robe takes 2 bolts of blue fiber and half that much white fiber.How many bolts in total does it take?GSM-Hard (Gao et al., 2022) 1,319 A robe takes 2287720 bolts of blue fiber and half that much white fiber.How many bolts in total does it take?SVAMP (Patel et al., 2021) 1,000 Each pack of dvds costs 76 dollars.If there is a discount of 25 dollars on each pack.How much do you have to pay to buy each pack?SINGLEOP (Koncel-Kedziorski et al., 2016) 562 If there are 7 bottle caps in a box and Linda puts 7 more bottle caps inside, how many bottle caps are in the box?SINGLEEQ (Koncel-Kedziorski et al., 2016) 508 Benny bought a soft drink for 2 dollars and 5 candy bars.He spent a total of 27 dollars.How much did each candy bar cost?AddSub (Hosseini et al., 2014) 395 There were 6 roses in the vase.Mary cut some roses from her flower garden.There are now 16 roses in the vase.How many roses did she cut?MultiArith (Roy &amp; Roth, 2015) 600 The school cafeteria ordered 42 red apples and 7 green apples for students lunches.But, if only 9 students wanted fruit, how many extra did the cafeteria end up with?</p>
<p>Commonsense &amp; Factual reasoning</p>
<p> CommonsenseQA (CSQA; Talmor et al., 2019): CSQA is a multiple-choice question answering task.It requires complex semantic reasoning based on prior commonsense knowledge to answer the questions. StrategyQA (Geva et al., 2021): It is a commonsense QA task with Yes or No answer format that requires models to perform multi-hop reasoning to answer the questions.We use the open-domain setting (question-only set) from bench authors (2023).</p>
<p> OpenBookQA (Mihaylov et al., 2018): It is a multi-choice QA task to evaluate commonsense knowledge and promote reasoning over a fixed collection of knowledge.</p>
<p> ARC-c (Clark et al., 2018): A subset of the AI2 Reasoning Challenge, consisting of challenging science questions that require reasoning and a wide breadth of knowledge to answer the multiple-choice problems correctly.The original dataset is from https: //allenai.org/data/arc.</p>
<p> BoolQ (Clark et al., 2019): It is a knowledge-intensive task and the format is "Yes" or "No".Problems are extracted from real-world internet queries, aiming to foster models capable of contextual understanding to provide binary answers.OpenBookQA (Mihaylov et al., 2018) 500 In which location would a groundhog hide from a wolf?ARC-c (Clark et al., 2018) 1,172 An astronomer observes that a planet rotates faster after a meteorite impact.Which is the most likely effect of this increase in rotation?BoolQ (Clark et al., 2019) 3,270 Wherever a gene exists on a DNA molecule, one strand is the coding strand (or sense strand), and the other is the noncoding strand (also called the antisense strand, anticoding strand, template strand or transcribed strand).Question: does it matter which DNA strand is transcribed?</p>
<p>Symbolic Reasoning We select the following tasks from BIG-Bench (bench authors, 2023) and BIG-Bench Hard (BBH) (Suzgun et al., 2023), with Apache License v.2: https://github.com/google/BIG-bench/blob/main/LICENSE.</p>
<p> Date Understanding: A temporal reasoning task.Given a set of sentences about a particular date, answer the provided question in MM/DD/YYYY format.</p>
<p> Object Counting: Given a collection of possessions that a person has along with their quantities (e.g., three pianos, two strawberries, one table, and two watermelons), determine the number of a certain object/item class (e.g., fruits).</p>
<p> Penguins in a Table : Given a unique table of penguins (and sometimes some new information), answer a question about the attributes of the penguins.</p>
<p> Reasoning about Colored Objects: Given a context, answer a simple question about the color of an object on a surface.</p>
<p> Repeat Copy: Evaluate LLMs' capability to follow basic natural-language instructions nested within each example's input.</p>
<p>Semi-structured Understanding</p>
<p> FinQA (Chen et al., 2021b): Question-Answering pairs over financial reports written by experts, which includes financial QA pairs.</p>
<p> ConvFinQA (Chen et al., 2022b): A financial-related dataset designed to study the chain of numerical reasoning in conversational QA. 32 Repeat the word cat four times.After the second time, also say the word meow.</p>
<p> TAT-QA (Zhu et al., 2021): A QA dataset aiming to stimulate the progress of research over more complex and realistic tabular and textual data.</p>
<p>E CASE STUDIES</p>
<p>We have prepared case studies to provide a more intuitive understanding of the three collaboration paradigms.The cases are presented in Table 10, Table 11, and Table 12, each corresponding to a specific collaboration paradigm.</p>
<p>F PROMPTS</p>
<p>Owing to space constraints and in an effort to maintain a reasonable length for this paper, we present one exemplar of the prompts for each task in this section, as well as the system messages for collaboration.Melanie is selling 4 gumballs for 8 cents each.So for each gumball, she can get 8 / 4 = 2 cents.Therefore, she can get a total of 2 x 4 = 8 cents from selling the gumballs.The answer is 8 cents.</p>
<p>Candidates 2 and 3 are accurate in their computations, emphasizing that each gumball costs 8 cents and that Melanie would earn a total of 32 cents from the sale of all gumballs.In contrast, Candidates 1 and 4 mistakenly deduce the price per gumball, thereby providing an incorrect total earning.Therefore, the most faithful answers are provided by candidate 2 and candidate 3 with a confidence score of 1.</p>
<p>CSQA Q: What do people use to absorb extra ink from a fountain pen?Options: (A) shirt pocket (B) calligrapher's hand (C) inkwell (D) desk drawer (E) blotter A: The answer must be an item that can absorb ink.Of the above choices, only blotters are used to absorb ink.So the answer is (E).</p>
<p>CSQA COMPLEXITY-BASED Q: The building could accommodate many people.The entrance hall alone was impressive, being wide enough to admit a hundred shoulder to shoulder.But the building was owned by a billionaire and used only for his personal entertainment.How would you describe this place?Answer Choices: (A) convention center (B) public building (C) large building (D) school (E) town hall A: The answer should be somewhere that is not for the good and convenience of the people.</p>
<p>Of the above choices, large building is the only neural description of a building owned by a billionaire.So the answer is (C).</p>
<p>STRATEGYQA Q: Could Brooke Shields succeed at the University of Pennsylvania?A: Brooke Shields went to Princeton University.</p>
<p>Princeton University is about as academically rigorous as the University of Pennsylvania.Thus, Brooke Shields could also succeed at the University of Pennsylvania.So the answer is yes.STRATEGYQA COMPLEXITY-BASED Q: Can jackfruit be used as a weapon?A: Jackfruit is the fruit of a species of plant called the Jacktree.Jackfruit can weigh up to one hundred and twenty pounds.Jackfruit is covered in little spikes.Jackfruit can be thrown or flung at an enemy.</p>
<p>A weapon is a thing that is used to cause bodily harm.Thus, Jackfruit can be used as a weapon So the answer is yes.A: Dry surfaces will more likely cause more friction via rubbing than other smoother surfaces, hence dry palms will produce the most heat.So the answer is (A).</p>
<p>BOOLQ Q: is a cello and a bass the same thing?A: The cello is played sitting down with the instrument between the knees, whereas the double bass is played standing or sitting on a stool.So the answer is no.</p>
<p>Table 13: Examples of few-shot exemplars for CSQA, StrategyQA, OpenBookQA, ARC-c, and BoolQ respectively.6-shots are adopted for CSQA, 7-shots are adopted for StrategyQA, and 4-shots are adopted for OpenBookQA, ARC-c, and BoolQ.</p>
<p>Figure 1 :
1
Figure 1: A depiction of three prevalent errors observed across LLMs when employing CoT and PAL to conduct reasoning tasks.</p>
<p>Figure 3 :
3
Figure 3: Illustration of 2 rounds of discussion, reasoning chains omitted.</p>
<p>Figure 4 :
4
Figure 4: Illustration of reviewing erroneous code generated by other agents (first round).</p>
<p>p , informed by the feedback F i .Following the completion of all review iterations, the outcome is determined by the final iteration of the solution set S (n1) p</p>
<p>Question:</p>
<p>Which describes the composition of carbohydrates? (A) lipids bonding to form phospholipids (B) monomers bonding to form polymers (C) amino acids bonding to form polypeptides (D) saccharides bonding to form polysaccharides Agent1: The composition of carbohydrates involves saccharides bonding to form polysaccharides.So the answer is (D).</p>
<p>Figure 5 :
5
Figure 5: Illustration of retrieving faithful chains with answers.</p>
<p>Figure 6 :
6
Figure 6: Distribution of the number of discussions rounds required to reach consensus.</p>
<p>Figure 9 :
9
Figure 8: Comparison of using different LLMs as judges in Discuss mode.</p>
<p>Figure 11: Cost-effectiveness analysis for ARCc dataset.</p>
<p>Figure 12 :
12
Figure 12: Cost-effectiveness analysis for Penguins in a Table.</p>
<p>Figure 14 :
14
Figure 13: Few-shot performance of Review mode.</p>
<p>Figure 16 :
16
Figure 16: Error Types Analysis on GSM-Hard: Pre-and Post-collaboration.</p>
<p>for the question is incorrect.The code erroneously calculates the number of toys Uriah needs to remove by dividing the total weight of the removed comic books by each toy's weight, neglecting the total 15 pounds Uriah aims to remove.It overlooks the weight left to be removed after the comic books are out, leading to an incorrect answer.Here's the corrected code: def solution():"""Uriah's book bag is getting too heavy for him.He needs to remove 15 pounds from it.His comic books weigh 1/4 pound each and his toys weigh 1/2 pound each.If he removes 8717992 comic books, how many toys does he need to remove?"""An illustrative example of the retrieve process of Corex among five agents (four candidates and one retriever) over a mathematical problem from SingleEQ.Q: Melanie is selling 4 gumballs for eight cents each.How much money can Melanie get from selling the gumballs?Melanie is selling 4 gumballs for eight cents each.That means each gumball costs 8/4 = 2 cents.So from selling the 4 gumballs, Melanie can get 4 x 2 = 8 cents.The answer is 8 cents.Melanie is selling 4 gumballs for 8 cents each.So she can get 4 x 8 = 32 cents from selling the gumballs.The answer is 32 cents.Melanie is selling 4 gumballs for eight cents each.So she can get 4 x 8 = 32 cents from selling the gumballs.The answer is 32 cents.</p>
<p>OPENBOOKQA Q :
:
As you look deeper into a Marbel you can see Options: (A) the future (B) minut defects (C) colors (D) the other side A: Marbel is not transparent, so you can not see the other side.Marbel does not necessarily have multiple colors.You will see minut defects.So the answer is (B).ARC-C Q: George wants to warm his hands quickly by rubbing them.Which skin surface will produce the most heat?Options: (A) dry palms.(B) wet palms.(C) palms covered with oil.(D) palms covered with lotion.</p>
<p>Table 1 :
1
Comparison of accuracy on seven mathematical reasoning datasets using various Corex modes and strong baselines.
GSM8K SVAMP MultiArith SingleOP SingleEQ AddSub GSM-Hard Avg.CoT74.578.998.594.193.387.839.080.9ComplexCoT79.780.797.394.392.386.839.781.5CoT-SC(10)82.884.599.895.495.189.645.284.6PAL76.083.496.790.795.887.662.184.6Corex-Discuss76.282.698.794.893.789.745.983.1Corex-Review NL80.383.299.595.094.389.450.884.6Corex-Review Code79.285.898.393.696.989.663.686.7Corex-Retrieve82.585.699.896.196.690.953.086.3</p>
<p>Table 2 :
2
Comparison of performance on commonsense &amp; factual reasoning between various Corex modes and strong baselines.
StrategyQA CSQA OpenBookQA BoolQ ARC-c Avg.CoT65.376.782.665.184.274.8ComplexCoT63.177.5----CoT-SC(10)67.178.185.266.685.776.5Corex-Discuss68.478.983.466.986.376.8Corex-Review NL66.977.484.866.986.076.4Corex-Retrieve69.377.787.668.085.577.6
Notably, our approach surpasses ComplexCoT (over 6% on StrategyQA), achieving a significant improvement without resorting to intricate prompt design and example selection.Symbolic Reasoning.We report the results for symbolic reasoning in Table3.Empirical evidence substantiates that adopting multi-model collaboration can notably outperform most previous baselines on Big-Bench tasks.It is noteworthy that (1) CoT-SC struggles to ensure consistent outputs on the Repeat Copy.Conversely, through the integration of PAL-based collaboration, we manage to attain a remarkably high level of accuracy.(2) Compared to majority voting, both the Review and Retrieve modes enable more judicious answer selection in counting tasks.</p>
<p>Table 3 :
3
Comparison of accuracy on five symbolic reasoning datasets from Big-Bench (bench authors, 2023; Suzgun et al., 2023) using various Corex modes and other strong baselines.Semi-structured Reasoning.We demonstrate the results on FinQA and ConvFinQA in Table 4.It can be observed that for these two challenging tasks which require understanding heterogeneous Table 4: Comparison of Corex and strong baselines on FinQA and ConvFinQA.
Date Penguin Colored Objects Repeat Copy Avg.CoT82.081.588.043.873.8CoT-SC(10)87.986.294.853.180.5PAL81.291.386.893.888.3Corex-Discuss83.285.991.262.580.7Corex-Review NL84.092.092.459.482.0Corex-Review Code 82.793.391.696.991.1Corex-Retrieve84.692.695.668.885.6FinQA ConvFinQA Avg.CoT46.150.448.3CoT-SC(10)52.757.254.9PAL/PoT54.350.852.9Corex-Discuss50.256.753.5Corex-Review NL52.552.352.4Corex-Review Code55.954.255.1Corex-Retrieve55.457.756.6</p>
<p>Table 7 :
7
Examples from commonsense &amp; factual reasoning datasets used in this work.
DatasetN ExampleStrategyQA (Cobbe et al., 2021)2,290 Hydrogen's atomic number squared ex-ceeds number of Spice Girls?CommonsenseQA (CSQA; Talmor et al., 2019) 1,221 A robe takes 2 bolts of blue fiber and halfthat much white fiber. How many bolts intotal does it take?</p>
<p>Table 8 :
8
Examples from symbolic reasoning datasets used in this work.
DatasetN ExampleDate Understanding 250 Yesterday was April 30, 2021. What is the datetoday in MM/DD/YYYY?Object Counting250 I have an apple, three bananas, a strawberry,a peach, three oranges, a plum, a raspberry,two grapes, a nectarine, and a blackberry. Howmany fruits do I have?Penguins in a Table 146 A Here is a table where the first line is a headerand each subsequent line is a penguin: name,age, height (cm), weight (kg) Louis, 7, 50, 11Bernard, 5, 80, 13 Vincent, 9, 60, 11 Gwen, 8,70, 15 For example: the age of Louis is 7, theweight of Gwen is 15 kg, the height of Bernardis 80 cm. How many penguins are more than 5years old?Colored Objects250 On the desk, you see a bunch of items arrangedin a row: a gold textbook, a purple puzzle, ateal necklace, and a silver pencil. How manynon-gold items do you see to the right of thepencil?Repeat Copy</p>
<p>Table 9 :
9
Examples from semi-structured reasoning datasets used in this work.
DatasetN ExampleFinQA (Chen et al., 2021b)1,147 Question: what percentage of total facilities as mea-sured in square feet are leased? Text: unresolvedstaff comments not applicable. properties as of de-cember 26 , 2015 , our major facilities consisted of: ( square feet in millions ) united states countriestotal owned facilities. 30.7 17.2 47.9 leased facilities... Table: ( square feet in millions ) | unitedstates |othercountries | total owned facilities1 | 30.7 | 17.2 |47.9 leased facilities2 | 2.1 | 6.0 | 8.1 total facilities |32.8 | 23.2 | 56.0",ConvFinQA (Chen et al., 2022b)421 Question: what were the total accumulated othercomprehensive losses in 2015? Text: accumulatedother comprehensive losses : pmi's accumulatedother comprehensive losses , net of taxes , consistedof the following: reclassifications from other com-prehensive earnings the movements in accumulatedother comprehensive losses and the related tax im-pact , for each of the components above ... Table: (losses ) earnings ( in millions ) | ( losses ) earnings2015 | ( losses ) earnings 2014 | 2013 currency trans-lation adjustments | $ -6129 ( 6129 ) | $ -3929 ( 3929) | $ -2207 ( 2207 ) pension and other benefits | -3332( 3332 ) | -3020 ( 3020 ) | -2046 ( 2046 ) derivativesaccounted for as hedges | 59 | 123 | 63 total accumu-lated other comprehensive losses | $ -9402 ( 9402 ) |$ -6826 ( 6826 ) | $ -4190 ( 4190 )TAT-QA (Zhu et al., 2021)718 Question: What is the change in Other in 2019 from2018? Text: Sales by Contract Type: Substantiallyall of our contracts are fixed-price type contracts.Sales included in Other contract types represent costplus and time and material type contracts. On afixed-price type contract, we agree to perform thecontractual statement of work for a predeterminedsales price ... Table: 2014 | 2014 | Years EndedSeptember 30, | 2014 2014 | 2019 | 2018 | 2017 FixedPrice | $ 1,452.4 | $ 1,146.2 | $ 1,036.9 Other | 44.1 |56.7 | 70.8 Total sales | $1,496.5 | $1,202.9 | $1,107.7</p>
<p>Table 11 :
11
An illustrative example of the Review mode (one round) of Corex among two agents over a mathematical problem from GSM-Hard.Uriah's book bag is getting too heavy for him.He needs to remove 15 pounds from it.His comic books weigh 1/4 pound each and his toys weigh 1/2 pound each.If he removes 8717992 comic books, how many toys does he need to remove?</p>
<p>Q:def solution():"""Uriah's book bag is getting too heavy for him.He needs to remove 15 pounds from it.His comic books weigh 1/4 pound each and his toys weigh 1/2 pound each.If he removes 8717992 comic books, how many toys does he need to remove?"""</p>
<p>The idea of integrating LLMs with external PL interface was proposed byGao et al. (2022) andChen et al. (2022a) within the same timeframe. We refer to this approach as "PAL" in this paper.
Due to the context length limit of GPT-3.5-Turbo, only information from the previous round is stored during the discussion.
B IMPLEMENTATION DETAILSLLMs Settings and Prompts.We access OpenAI and Anthropic models through their respective paid APIs.Specifically, we utilize two versions of the OpenAI models: GPT-3.5-Turbo-0613 and GPT-4-0613, as well as Claude-Instant-1.2 from Anthropic.Following the settings of previous works, the temperature is set as 0 during the generation process.As for the prompts, we maintain the same number of exemplars per task as established by previous studies.The details and examples of prompts are listed in Appendix F. Regarding the complexitybased prompting baseline, we directly utilize the prompts provided byFu et al. (2023a).Evaluation.We use accuracy to evaluate the tasks of arithmetic reasoning, commonsense reasoning, and Symbolic reasoning.For semi-structured understanding, we employ the official evaluation scripts released along with the literature for FinQA(Chen et al., 2021b)and ConvFinQA(Chen et al., 2022b), as well as employing the same test split as inChen et al. (2022a).For TAT-QA(Zhu et al., 2021), we utilize the arithmetic part to enable the simultaneous use of both CoT-based methods and PAL.Among all the evaluations involve Corex-Discuss, the upper bound of rounds is set as 5.In the analysis part, due to the rate limits imposed and a restricted budget, we set an upper limit for our sample size.Consequently, each analysis is based on a maximum of 500 samples per run.We draw upon the design of the self-consistency baseline as delineated byWu et al. (2023), and partially refer to the benchmarking provided byWang et al. (2023b).PAL Details.We use Python 3.9.12 to execute the generated program by PAL in Review mode, following the similar settings fromGao et al. (2022)andChen et al. (2022a).Unlike Code-davinci-002(Chen et al., 2021a)employed in these works, GPT-3.5-Turbo is not optimized for generating programs, so we might anticipate a compromise in performance when using GPT-3.5-Turboas the backbone model.C EXTENDED RESULTS AND FURTHER ANALYSIS C.1 EVALUATIONS ON SEMI-STRUCTURED REASONINGAs is mentioned in section 4.2, due to the constraint of context length, we conduct experiments on the TAT-QA dataset with GPT-3.5-Turbo-16kalong with other two tasks.C.2 FURTHER COST-EFFECTIVENESS ANALYSISFor all computations related to cost-effectiveness, we define cost as the sum of: tokens of few-shot exemplars, query tokens, and output tokens.Here we conduct additional cost-effectiveness analysis on the ARC-c dataset and Penguins dataset, as shown in Figure11and Figure12.The x-axis represents the computational costs, calculated in terms of input/output tokens, while the size of each dot is proportional to the avg.number of inferences by each method.Jerry's analysis is mostly correct, but there is a small mistake in the final calculation.Angelo and Melanie think they should dedicate 3 hours to each of the 2 chapters, 3 hours x 2 chapters = 6 hours total.For the worksheets they plan to dedicate 1.5 hours for each worksheet, 1.5 hours x 4 worksheets = 6 hours total.Angelo and Melanie need to start with planning 12 hours to study, at 4 hours a day, 12 / 4 = 3 days.However, they need to include time for breaks and lunch.Every hour they want to include a 10-minute break, so 12 total hours x 10 minutes = 120 extra minutes for breaks.They also want to include 3 10-minute snack breaks, 3 x 10 minutes = 30 minutes.And they want to include 30 minutes for lunch each day, so 120 minutes for breaks + 30 minutes for snack breaks + 30 minutes for lunch = 180 minutes, or 180 / 60 minutes per hour = 3 extra hours.So Angelo and Melanie want to plan 12 hours to study + 3 hours of breaks = 15 hours total.They want to study no more than 4 hours each day, 15 hours / 4 hours each day = 3.75They will need to plan to study 4 days to allow for all the time they need.So the answer is 4.  OBJECT COUNTING: NL PROMPTS Q: I have a blackberry, a clarinet, a nectarine, a plum, a strawberry, a banana, a flute, an orange, and a violin.How many fruits do I have?A: Let's think step by step.We first identify the fruits on the list and include their quantity in parentheses:-blackberry (1) -nectarine (1) -plum (1) -strawberry (1) -banana (1) -orange (1) Now, let's add the numbers in parentheses: 1 + 1 + 1 + 1 + 1 + 1 = 6.So the answer is 6.OBJECT COUNTING: PAL PROMPTS Q: I have a peach, an onion, two garlics, a nectarine, a yam, a carrot, a potato, a head of broccoli, a cabbage, a banana, and a stalk of celery.How many vegetables do I have?# solution using Python: def solution():"""Q: I have a raspberry, a cat, a rabbit, a mouse, a pig, two snails, a fish, two cows, a snake, a goat, and a duck.How many animals do I have?REPEAT COPY: NL PROMPTS Q: Q: say java twice and data once, and then repeat all of this three times.A: Let's think step by step.java java data java java data java java data REPEAT COPY: PAL PROMPTS Q: say java twice and data once, and then repeat all of this three times.# solution using Python: def solution():"""Q: say java twice and data once, and then repeat all of this three times."""["java", "java", "data"]for i in range(3): result.extend(tmp)return " ".join(result)Table16: Examples of few-shot exemplars for Object Counting and Repeat Copy.For CoT, CoT-SC and PAL, 3-shots are adopted for Object Counting and 4-shots are adopted for Repeat Copy.PENGUINS: NL PROMPTS Q:Here is a table where the first line is a header and each subsequent line is a penguin: name, age, height (cm), weight (kg)Louis,7,50,11 Bernard,5,80,13 Vincent,9,60,11 Gwen,8,70,15For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.We now add a penguin to the table: James, 12, 90, 12 How many penguins are less than 8 years old?Options: (A) 1 (B) 2 (C) 3 (D) 4 (E) 5 A: Let's think step by step.This question focuses on age.We know the following: Louis is 7 years old, Bernard is 5 years old, Vincent is 9 years old, and Gwen is 8 years old.Now, we add James to this table: James is 12 years old.The penguins that are less than 8 years old are Louis and Bernard.There are 2 penguins less than 8 years old.So the answer is (B).PENGUINS: PAL PROMPTS Q:Here is a table where the first line is a header and each subsequent line is a penguin: name, age, height (cm), weight (kg)Louis,7,50,11 Bernard,5,80,13 Vincent,9,60,11 Gwen,8,70,15For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.We now add a penguin to the table: James, 12, 90, 12 How many penguins are less than 8 years old?Options: (A) 1 (B) 2 (C) 3 (D) 4 (E) 5""" Q: Here is a table where the first line is a header and each subsequent line is a penguin:  name, age, height (cm), weight (kg)Louis,7,50,11 Bernard,5,80,13 Vincent,9,60,11 Gwen,8,70,15For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.We now add a penguin to the
Towards a human-like open-domain chatbot. Daniel Adiwardana, Minh-Thang Luong, David R So, Jamie Hall, Noah Fiedel, Romal Thoppilan, Zi Yang, Apoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu, Quoc V Le, 2020CoRR</p>
<p>Training a helpful and harmless assistant with reinforcement learning from human feedback. ArXiv preprint, 2022. BIG bench authors. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova Dassarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, Transactions on Machine Learning Research. 2023</p>
<p>Language models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Ilya Sutskever, and Dario Amodei. Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford2020NeurIPS</p>
<p>Chateval: Towards better llm-based evaluators through multi-agent debate. Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang Zhang, Jie Fu, Zhiyuan Liu, 2023</p>
<p>Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde, Jared Kaplan, Harri Edwards, Yura Burda, Nicholas Joseph, Greg Brockman, arXiv:2107.03374Evaluating large language models trained on code. 2021aarXiv preprint</p>
<p>Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. Wenhu Chen, Xueguang Ma, Xinyi Wang, William W Cohen, 2022a</p>
<p>Exploring the use of large language models for reference-free text quality evaluation: An empirical study. Yi Chen, Rui Wang, Haiyun Jiang, Shuming Shi, Ruifeng Xu, 2023</p>
<p>FinQA: A dataset of numerical reasoning over financial data. Zhiyu Chen, Wenhu Chen, Charese Smiley, Sameena Shah, Iana Borova, Dylan Langdon, Reema Moussa, Matt Beane, Ting-Hao Huang, Bryan Routledge, William Yang, Wang , Proc. of EMNLP. of EMNLP2021b</p>
<p>ConvFinQA: Exploring the chain of numerical reasoning in conversational finance question answering. Zhiyu Chen, Shiyang Li, Charese Smiley, Zhiqiang Ma, Sameena Shah, William Yang, Wang , Proc. of EMNLP. of EMNLP2022b</p>
<p>Palm: Scaling language modeling with pathways. Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, 2022</p>
<p>BoolQ: Exploring the surprising difficulty of natural yes/no questions. Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, Kristina Toutanova, Proc. of NAACL. of NAACL2019</p>
<p>Think you have solved question answering? try arc, the ai2 reasoning challenge. Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, Oyvind Tafjord, 2018ArXiv</p>
<p>Training verifiers to solve math word problems. Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, John Schulman, 2021</p>
<p>Multi-agent systems: A survey. Ali Dorri, Salil S Kanhere, Raja Jurdak, IEEE Access. 2018</p>
<p>Improving factuality and reasoning in language models through multiagent debate. Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, Igor Mordatch, arXiv:2305.143252023arXiv preprint</p>
<p>Chain-of-thought hub: A continuous effort to measure large language models' reasoning performance. Yao Fu, Litu Ou, Mingyu Chen, Yuhao Wan, Hao Peng, Tushar Khot, 2023a</p>
<p>Improving language model negotiation with self-play and in-context learning from ai feedback. Yao Fu, Hao Peng, Tushar Khot, Mirella Lapata, 2023b</p>
<p>Complexity-based prompting for multi-step reasoning. Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, Tushar Khot, Proc. of ICLR. of ICLR2023c</p>
<p>Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, Graham Neubig, arXiv:2211.10435Pal: Program-aided language models. 2022arXiv preprint</p>
<p>Enabling large language models to generate text with citations. Tianyu Gao, Howard Yen, Jiatong Yu, Danqi Chen, 2023</p>
<p>Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies. Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, Jonathan Berant, 2021Transactions of the Association for Computational Linguistics</p>
<p>Rethinking with retrieval: Faithful large language model inference. Hangfeng He, Hongming Zhang, Dan Roth, 2022</p>
<p>Aligning AI with shared human values. Dan Hendrycks, Collin Burns, Steven Basart, Andrew Critch, Jerry Li, Dawn Song, Jacob Steinhardt, Proc. of ICLR. of ICLR2021</p>
<p>Bridging fairness and environmental sustainability in natural language processing. Marius Hessenthaler, Emma Strubell, Dirk Hovy, Anne Lauscher, Proc. of EMNLP. of EMNLP2022</p>
<p>Learning to solve arithmetic word problems with verb categorization. Mohammad Javad Hosseini, Hannaneh Hajishirzi, Oren Etzioni, Nate Kushman, Proc. of EMNLP. of EMNLP2014</p>
<p>Towards reasoning in large language models: A survey. Jie Huang, Kevin Chen, -Chuan Chang, Proc. of ACL Findings. of ACL Findings2023</p>
<p>Large language models cannot self-correct reasoning yet. Jie Huang, Xinyun Chen, Swaroop Mishra, Steven Huaixiu, Adams Wei Zheng, Xinying Yu, Denny Song, Zhou, 2023</p>
<p>Towards faithfully interpretable NLP systems: How should we define and evaluate faithfulness?. Alon Jacovi, Yoav Goldberg, Proc. of ACL. of ACL2020</p>
<p>Survey of hallucination in natural language generation. Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye , Jin Bang, Andrea Madotto, Pascale Fung, ACM Comput. Surv. 2023</p>
<p>Scaling laws for neural language models. Jared Kaplan, Sam Mccandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, Dario Amodei, 2020</p>
<p>Decomposed prompting: A modular approach for solving complex tasks. Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, Ashish Sabharwal, Proc. of ICLR. of ICLR2023</p>
<p>Large language models are zero-shot reasoners. Takeshi Kojima, Shane Shixiang, Machel Gu, Yutaka Reid, Yusuke Matsuo, Iwasawa, Proc. of NeurIPS. of NeurIPS2022</p>
<p>MAWPS: A math word problem repository. Rik Koncel-Kedziorski, Subhro Roy, Aida Amini, Nate Kushman, Hannaneh Hajishirzi, Proc. of NAACL. of NAACL2016</p>
<p>. Tamera Lanham, Anna Chen, Ansh Radhakrishnan, Benoit Steiner, Carson Denison, Danny Hernandez, Dustin Li, Esin Durmus, Evan Hubinger, Jackson Kernion, Kamil Lukoit, Karina Nguyen, Newton Cheng, Nicholas Joseph, Nicholas Schiefer, Oliver Rausch, Robin Larson, Sam Mccandlish, Sandipan Kundu, Saurav Kadavath, Shannon Yang, Thomas Henighan, ; Samuel, R Bowman, Ethan Perez, Jan Brauner,. 2023Timothy Maxwell, Timothy Telleen-Lawton, Tristan Hume, Zac Hatfield-Dodds, Jared KaplanMeasuring faithfulness in chain-of-thought reasoning</p>
<p>Camel: Communicative agents for "mind" exploration of large scale language model society, 2023a. Jiwei Li and Dan Jurafsky. Mutual information and diverse decoding improve neural machine translation. Guohao Li, Hasan Abed, Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, Bernard Ghanem, 2016ArXiv</p>
<p>Contrastive decoding: Open-ended text generation as optimization. Lisa Xiang, Ari Li, Daniel Holtzman, Percy Fried, Jason Liang, Tatsunori Eisner, Luke Hashimoto, Mike Zettlemoyer, Lewis, Proc. of ACL. of ACL2023b</p>
<p>Making language models better reasoners with step-aware verifier. Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen, Jian-Guang Lou, Weizhu Chen, Proc. of ACL. of ACL2023c</p>
<p>Encouraging divergent thinking in large language models through multi-agent debate. Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Zhaopeng Tu, Shuming Shi, arXiv:2305.191182023arXiv preprint</p>
<p>Mind's eye: Grounded language model reasoning through simulation. Ruibo Liu, Jason Wei, Shixiang Shane Gu, Te-Yen Wu, Soroush Vosoughi, Claire Cui, Denny Zhou, Andrew M Dai, Proc. of ICLR. of ICLR2023a</p>
<p>Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, Shudan Zhang, Xiang Deng, Aohan Zeng, Zhengxiao Du, Chenhui Zhang, Sheng Shen, Tianjun Zhang, Yu Su, Huan Sun, Minlie Huang, arXiv:2308.03688Yuxiao Dong, and Jie Tang. Agentbench: Evaluating llms as agents. 2023barXiv preprint</p>
<p>Pan Lu, Baolin Peng, Hao Cheng, Michel Galley, Kai-Wei Chang, Ying Nian Wu, Song-Chun Zhu, Jianfeng Gao, arXiv:2304.09842Chameleon: Plug-and-play compositional reasoning with large language models. 2023aarXiv preprint</p>
<p>Dynamic prompt learning via policy gradient for semi-structured mathematical reasoning. Pan Lu, Liang Qiu, Kai-Wei Chang, Ying Nian Wu, Song-Chun Zhu, Tanmay Rajpurohit, Peter Clark, Ashwin Kalyan, Proc. of ICLR. of ICLR2023b</p>
<p>A synergistic core for human brain evolution and cognition. Andrea I Luppi, Pedro Am Mediano, Fernando E Rosas, Negin Holland, Tim D Fryer, John , T O'brien, James B Rowe, David K Menon, Daniel Bor, Emmanuel A Stamatakis, Nature Neuroscience. 2022</p>
<p>Can a suit of armor conduct electricity? a new dataset for open book question answering. Qing Lyu, Shreya Havaldar, Adam Stein, Li Zhang, Delip Rao, Eric Wong, Marianna Apidianaki, Chris Callison-Burch, arXiv:2301.13379Proc. of EMNLP. Todor Mihaylov, Peter Clark, Tushar Khot, Ashish Sabharwal, of EMNLP2023. 2018arXiv preprintFaithful chain-of-thought reasoning</p>
<p>Marvin Minsky. The emotion machine: Commonsense thinking, artificial intelligence, and the future of the human mind. Marvin Minsky, 1988. 2007Simon and SchusterSociety of mind</p>
<p>Webgpt: Browser-assisted question-answering with human feedback. Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button, Matthew Knight, Benjamin Chess, and John Schulman2022</p>
<p>Lever: Learning to verify language-to-code generation with execution. Ansong Ni, Srini Iyer, Dragomir Radev, Ves Stoyanov, Wen-Tau Yih, Sida I Wang, Xi Victoria, Lin , Proc. of ICML. of ICML2023</p>
<p>Jianfeng Gao, and Armando Solar-Lezama. Demystifying gpt self-repair for code generation. Theo X Olausson, Jeevana Priya Inala, Chenglong Wang, 2023</p>
<p>OpenAI. GPT-4 technical report. 2023</p>
<p>Training language models to follow instructions with human feedback. Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Gray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, Ryan Lowe, Proc. of NeurIPS. of NeurIPS2022</p>
<p>Generative agents: Interactive simulacra of human behavior. Sung Joon, Joseph C Park, Carrie J O'brien, Meredith Ringel Cai, Percy Morris, Michael S Liang, Bernstein, In the 36th Annual ACM Symposium on User Interface Software and Technology (UIST '23). 2023</p>
<p>Argumentation-based communication between agents. Simon Parsons, Peter Mcburney, Subseries of Lecture Notes in Computer Science. 2003Lecture Notes in Artificial Intelligence</p>
<p>Are NLP models really able to solve simple math word problems?. Arkil Patel, Satwik Bhattamishra, Navin Goyal, Proc. of NAACL. of NAACL2021</p>
<p>How context affects language models' factual predictions. Fabio Petroni, Patrick Lewis, Aleksandra Piktus, Tim Rocktschel, Yuxiang Wu, Alexander H Miller, Sebastian Riedel, Proc. of AKBC. of AKBC2020</p>
<p>Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan Liu, Maosong Sun, Communicative agents for software development. 2023</p>
<p>Reasoning with language model prompting: A survey. Shuofei Qiao, Yixin Ou, Ningyu Zhang, Xiang Chen, Yunzhi Yao, Shumin Deng, Chuanqi Tan, Fei Huang, Huajun Chen, Proc. of ACL. of ACL2023</p>
<p>Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Runchu Tian, Ruobing Xie, Jie Zhou, Mark Gerstein, Dahai Li, Zhiyuan Liu, and Maosong Sun. Toolllm: Facilitating large language models to master 16000+ real-world apis. 2023</p>
<p>Scaling language models: Methods, analysis &amp; insights from training gopher. Sebastian Jack W Rae, Trevor Borgeaud, Katie Cai, Jordan Millican, Francis Hoffmann, John Song, Sarah Aslanides, Roman Henderson, Susannah Ring, Young, 2022</p>
<p>Solving general arithmetic word problems. Subhro Roy, Dan Roth, Proc. of EMNLP. of EMNLP2015</p>
<p>Toolformer: Language models can teach themselves to use tools. Timo Schick, Jane Dwivedi-Yu, Roberto Dess, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, Thomas Scialom, 2023</p>
<p>Minding language models' (lack of) theory of mind: A plug-and-play multi-character belief tracker. Melanie Sclar, Sachin Kumar, Peter West, Alane Suhr, Yejin Choi, Yulia Tsvetkov, Proc. of ACL. of ACL2023</p>
<p>On second thought, let's not think step by step! bias and toxicity in zero-shot reasoning. Omar Shaikh, Hongxin Zhang, William Held, Michael Bernstein, Diyi Yang, Proc. of ACL. of ACL2023</p>
<p>Gpt-4 doesn't know it's wrong: An analysis of iterative prompting for reasoning problems. Kaya Stechly, Matthew Marquez, Subbarao Kambhampati, 2023</p>
<p>BERTScore is unfair: On social bias in language model-based metrics for text generation. Tianxiang Sun, Junliang He, Xipeng Qiu, Xuanjing Huang, Proc. of EMNLP. of EMNLP2022</p>
<p>Challenging BIG-bench tasks and whether chain-of-thought can solve them. Mirac Suzgun, Nathan Scales, Nathanael Schrli, Sebastian Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha Chowdhery, Quoc Le, Ed Chi, Denny Zhou, Jason Wei, Proc. of ACL Findings. of ACL Findings2023</p>
<p>CommonsenseQA: A question answering challenge targeting commonsense knowledge. Alon Talmor, Jonathan Herzig, Nicholas Lourie, Jonathan Berant, Proc. of NAACL. of NAACL2019</p>
<p>Llama 2: Open foundation and fine-tuned chat models. Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, 2023</p>
<p>Can large language models really improve by self-critiquing their own plans?. Karthik Valmeekam, Matthew Marquez, Subbarao Kambhampati, 2023</p>
<p>Cunxiang Wang, Xiaoze Liu, Yuanhao Yue, Xiangru Tang, Tianhang Zhang, Cheng Jiayang, Yunzhi Yao, Wenyang Gao, Xuming Hu, Zehan Qi, Yidong Wang, Linyi Yang, Jindong Wang, Xing Xie, Zheng Zhang, Yue Zhang, Survey on factuality in large language models: Knowledge, retrieval and domain-specificity. 2023a</p>
<p>HugNLP: A unified and comprehensive library for natural language processing. Jianing Wang, Nuo Chen, Qiushi Sun, Wenkang Huang, Chengyu Wang, Ming Gao, Proc. of CIKM. of CIKM2023b</p>
<p>Boosting language models reasoning with chain-of-knowledge prompting. Jianing Wang, Qiushi Sun, Nuo Chen, Xiang Li, Ming Gao, 2023cArXiv preprint</p>
<p>Large language models are not fair evaluators. Peiyi Wang, Lei Li, Liang Chen, Dawei Zhu, Binghuai Lin, Yunbo Cao, Qi Liu, Tianyu Liu, Zhifang Sui, 2023d</p>
<p>Rationale-augmented ensembles in language models. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Denny Zhou, 2022</p>
<p>Self-consistency improves chain of thought reasoning in language models. Xuezhi Wang, Jason Wei, Dale Schuurmans, Ed H Quoc V Le, Sharan Chi, Aakanksha Narang, Denny Chowdhery, Zhou, Proc. of ICLR. of ICLR2023e</p>
<p>Unleashing cognitive synergy in large language models: A task-solving agent through multi-persona selfcollaboration. Zhenhailong Wang, Shaoguang Mao, Wenshan Wu, Tao Ge, Furu Wei, Heng Ji, 2023f</p>
<p>Emergent analogical reasoning in large language models. Taylor Webb, Keith J Holyoak, Hongjing Lu, Nature Human Behaviour. 2023</p>
<p>Emergent abilities of large language models. Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, William Fedus, Transactions on Machine Learning Research. 2022a</p>
<p>Chain of thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed H Chi, Denny Quoc V Le, Zhou, Proc. of NeurIPS. of NeurIPS2022b</p>
<p>OpenICL: An open-source framework for in-context learning. Zhenyu Wu, Yaoxiang Wang, Jiacheng Ye, Zhiyong Wu, Jiangtao Feng, Jingjing Xu, Yu Qiao, Proc. of ACL. of ACL2023</p>
<p>Examining the inter-consistency of large language models: An in-depth analysis via debate. Kai Xiong, Xiao Ding, Yixin Cao, Ting Liu, Bing Qin, 2023</p>
<p>Learning to break the loop: Analyzing and mitigating repetitions for neural text generation. Jin Xu, Xiaojiang Liu, Jianhao Yan, Deng Cai, Huayang Li, Jian Li, Proc. of NeurIPS. of NeurIPS2022</p>
<p>Mm-react: Prompting chatgpt for multimodal reasoning and action. Zhengyuan Yang, Linjie Li, Jianfeng Wang, Kevin Lin, Ehsan Azarnasab, Faisal Ahmed, Zicheng Liu, Ce Liu, Michael Zeng, Lijuan Wang, 2023</p>
<p>Tree of Thoughts: Deliberate problem solving with large language models. Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, Karthik Narasimhan, 2023a</p>
<p>React: Synergizing reasoning and acting in language models. Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Yuan Karthik R Narasimhan, Cao, Proc. of ICLR. of ICLR2023b</p>
<p>Beyond chain-of-thought, effective graph-of-thought reasoning in large language models. Yao Yao, Zuchao Li, Hai Zhao, 2023c</p>
<p>The unreliability of explanations in few-shot prompting for textual reasoning. Xi Ye, Greg Durrett, Proc. of NeurIPS. of NeurIPS2022</p>
<p>Exchange-of-thought: Enhancing large language model capabilities through cross-model communication. Zhangyue Yin, Qiushi Sun, Cheng Chang, Qipeng Guo, Junqi Dai, Xuanjing Huang, Xipeng Qiu, Proc. of EMNLP. of EMNLP2023a</p>
<p>Do large language models know what they don't know?. Zhangyue Yin, Qiushi Sun, Qipeng Guo, Jiawen Wu, Xipeng Qiu, Xuanjing Huang, Proc. of ACL Findings. of ACL Findings2023b</p>
<p>Large language models meet NL2Code: A survey. Daoguang Zan, Bei Chen, Fengji Zhang, Dianjie Lu, Bingchao Wu, Bei Guan, Wang Yongji, Jian-Guang Lou, Proc. of ACL. of ACL2023</p>
<p>Opt: Open pre-trained transformer language models. Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, 2022ArXiv preprint</p>
<p>Automatic chain of thought prompting in large language models. Zhuosheng Zhang, Aston Zhang, Mu Li, Alex Smola, Proc. of ICLR. of ICLR2023a</p>
<p>Multimodal chain-of-thought reasoning in language models. Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, Alex Smola, arXiv:2302.009232023barXiv preprint</p>
<p>Kun Wayne Xin Zhao, Junyi Zhou, Tianyi Li, Xiaolei Tang, Yupeng Wang, Yingqian Hou, Beichen Min, Junjie Zhang, Zican Zhang, Yifan Dong, Chen Du, Yushuo Yang, Zhipeng Chen, Jinhao Chen, Ruiyang Jiang, Yifan Ren, Xinyu Li, Zikang Tang, Peiyu Liu, Jian-Yun Liu, Ji-Rong Nie, Wen, A survey of large language models. 2023a</p>
<p>Automatic model selection with large language models for reasoning. Xu Zhao, Yuxi Xie, Kenji Kawaguchi, Junxian He, Qizhe Xie, ArXiv. 2023b</p>
<p>Progressive-hint prompting improves reasoning in large language models. Chuanyang Zheng, Zhengying Liu, Enze Xie, Zhenguo Li, Yu Li, 2023aArXiv preprint</p>
<p>Judging llm-as-a-judge with mt-bench and chatbot arena. Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, Hao Zhang, Joseph E Gonzalez, Ion Stoica, 2023b</p>
<p>Least-to-most prompting enables complex reasoning in large language models. Denny Zhou, Nathanael Schrli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Ed H Quoc V Le, Chi, Proc. of ICLR. of ICLR2023</p>
<p>TAT-QA: A question answering benchmark on a hybrid of tabular and textual content in finance. Fengbin Zhu, Wenqiang Lei, Youcheng Huang, Chao Wang, Shuo Zhang, Jiancheng Lv, Fuli Feng, Tat-Seng Chua, Proc. of ACL. of ACL2021</p>
<p>Solving math word problems via cooperative reasoning induced language models. Xinyu Zhu, Junjie Wang, Lin Zhang, Yuxiang Zhang, Yongfeng Huang, Ruyi Gan, Jiaxing Zhang, Yujiu Yang, Proc. of ACL. of ACL2023</p>            </div>
        </div>

    </div>
</body>
</html>