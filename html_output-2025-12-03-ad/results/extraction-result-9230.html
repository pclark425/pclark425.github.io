<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9230 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9230</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9230</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-162.html">extraction-schema-162</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-201666793</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/1908.09156v1.pdf" target="_blank">A framework for anomaly detection using language modeling, and its applications to finance</a></p>
                <p><strong>Paper Abstract:</strong> In the finance sector, studies focused on anomaly detection are often associated with time-series and transactional data analytics. In this paper, we lay out the opportunities for applying anomaly and deviation detection methods to text corpora and challenges associated with them. We argue that language models that use distributional semantics can play a significant role in advancing these studies in novel directions, with new applications in risk identification, predictive modeling, and trend analysis.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9230.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9230.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LSTM-LM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Long Short-Term Memory based Language Model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Recurrent neural-network language model using LSTM units that predicts next tokens in a sequence; the paper discusses using its input/output/hidden representations and generated token probabilities as signals for anomalies in text sequences.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Long Short-Term Memory.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LSTM-based language model</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>recurrent neural network (LSTM)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>text sequences (tokens / words / characters); can operate on n-grams or longer sequences</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>financial text (earnings call transcripts, SEC filings, credit agreements), social media (tweets) as examples</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>transcription/OCR errors, irregular/novel language, semantic anomalies, boilerplate/outlier phrases</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Train an LSTM language model to predict next token; use model outputs—(a) low output probability / high perplexity for tokens to flag likely transcription/OCR errors, (b) shifts in input/hidden vector distributions when fine-tuned to detect evolving semantic trends, and (c) learned parameters (weights) to identify unusual patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>n-gram language models, bag-of-words, unsupervised clustering, traditional statistical deviation methods (mentioned conceptually)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>No empirical results reported; conceptual limitations discussed include unseen domain-specific tokens being mistaken for anomalies (e.g., named entities), noise/variability in spoken language resembling anomalies, and fine-tuning overfitting or misclassifying company-specific terms.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Paper emphasizes using multiple layers of an LSTM (input vectors, hidden vectors, output probabilities, and weight tensors) as distinct sources of anomaly signals rather than relying only on output likelihood; highlights applying domain-specific training to reduce false positives in financial contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A framework for anomaly detection using language modeling, and its applications to finance', 'publication_date_yy_mm': '2019-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9230.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9230.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Fine-tuned LM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Pre-trained Language Model with Fine-tuning for Target Domain</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Transfer-learning approach where a language model pretrained on a large generic corpus is fine-tuned on domain-specific text, and shifts in representations or the fine-tuned model's outputs are used to detect anomalies or evolving trends.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Fine-tuned Language Models for Text Classification.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Pre-trained language model (fine-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>pretrained LM with fine-tuning (can be recurrent or transformer-based)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>text sequences, documents (reports, filings), transcripts</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>financial documents (SEC filings, earnings calls), sector-specific corpora</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>evolving semantic shifts, novel/outlier documents, company-specific anomalies (operating segments, idiosyncratic clauses)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Pre-train LM on large general or sector-historical corpus, then fine-tune on recent/target documents; detect anomalies via large shifts in hidden representations when moving from pre-training to fine-tuning, or by using top layers for classification of atypical content.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>training from scratch, simple statistical detection of n-gram deviations, supervised classifiers (mentioned conceptually)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Fine-tuned models may treat legitimate domain-specific/new named entities as anomalies; overfitting to particular companies can reduce generalization; pretraining corpora might lack domain vocabulary causing misclassification.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Paper frames large shifts in hidden-vector distributions caused by fine-tuning as indicators of evolving sectoral trends or novel phenomena, suggesting monitoring representation drift as a detection mechanism.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A framework for anomaly detection using language modeling, and its applications to finance', 'publication_date_yy_mm': '2019-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9230.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9230.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Attention</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Attention Mechanisms / Attention Weights</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Attention components (including transformer-style attention) allocate weight to input elements; the paper suggests using learned attention distributions as interpretable signals of anomalous or trigger words and patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Attention is All you Need.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Attention-based models (transformer attention)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>attention mechanism / transformer</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>text sequences, short texts (tweets) and longer documents</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>social media, financial text, engagement prediction examples discussed</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>trigger-word-driven anomalies (clickbait, bot-generated content, propagandistic language), attention spikes indicating unusual emphasis</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Train attention-based model for a downstream task (e.g., engagement prediction); analyze attention weight distributions to detect inputs that attract atypical attention patterns (e.g., words disproportionally driving engagement), flagging potential anomalies.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Paper notes explainability caveats: attention weights are informative but may not fully explain model decisions; no empirical evaluation provided in the paper for anomaly detection use.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Proposes using attention as an interpretable parameter-space signal for anomaly detection, e.g., to distinguish engaging/information-rich content from clickbait or bot-driven posts by inspecting which words receive high attention.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A framework for anomaly detection using language modeling, and its applications to finance', 'publication_date_yy_mm': '2019-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9230.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9230.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Embeddings</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Distributed Word/Document Embeddings (e.g., word2vec / doc2vec)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Static or contextual vector representations of words or documents; the paper discusses using embedding stability, nearest-neighbor changes, and centroid comparisons for detecting semantic anomalies and novelty.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Distributed representations of words and phrases and their compositionality.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Distributed word/document embeddings</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>vector-space distributed representations (static embeddings / contextualized embeddings referenced)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>words, n-grams, tweet/document vectors, centroid clusters</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>social media events, financial filings and reports</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>semantic irregularity, novelty, unreliable or shifted word usage</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Compare embedding stability across corpora/time (e.g., nearest-neighbor similarity) or compare event/document centroids to historical centroids to detect deviations; unusual neighbor changes or centroid distances indicate anomalies or novel events.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>unsupervised clustering, n-gram frequency comparisons (conceptual)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Embedding instability can be influenced by factors unrelated to true anomalies (e.g., training variability); contextual drift and sparse domain terms can lead to false positives.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Paper highlights embedding stability as a measurable property and suggests leveraging changes in nearest-neighbor structures or centroid comparisons as practical anomaly/novelty signals (cites echo-chamber detection and fake-news work).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A framework for anomaly detection using language modeling, and its applications to finance', 'publication_date_yy_mm': '2019-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9230.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e9230.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>n-gram smoothing</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Smoothed n-gram Language Models for Boilerplate / Abnormal Clause Detection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>N-gram based probability models applied to documents (e.g., SEC filings) where n-gram probabilities are compared across a company's past filings, sector filings, and peer filings to surface abnormal or boilerplate language.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Smoothed n-gram language model</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>n-gram statistical language model with smoothing</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>n-gram sequences (text snippets, clauses)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>SEC filings, credit agreements, long regulatory documents</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>boilerplate detection, abnormal clauses, rare phrase detection</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Compute smoothed n-gram probabilities for each n-gram and compare these probabilities against (a) the company's previous filings, (b) filings in the same sector, and (c) filings from companies with similar market cap to identify unusual n-grams (low probability) that merit analyst attention.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>manual inspection, simple frequency-based heuristics (conceptual)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>No quantitative evaluation reported here; potential limitations include sensitivity to corpus selection for comparisons and inability to capture deeper semantic novelty beyond n-gram surface forms.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Practical approach recommended for helping analysts skip boilerplate and focus on clauses that 'stand out' by cross-comparing n-gram probabilities across several reference corpora.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A framework for anomaly detection using language modeling, and its applications to finance', 'publication_date_yy_mm': '2019-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9230.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e9230.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Centroid-cluster novelty</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Centroid-based Real-time Novel Event Detection (tweet-vector clustering)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Method representing each short text (tweet) as a vector, clustering in real time, and comparing cluster centroids to historical event centroids to measure novelty and detect emerging events.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Real-Time Novel Event Detection from Social Media</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Centroid-based event clustering of vectorized tweets</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>embedding + clustering (real-time)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>short-text sequences (tweets), cluster centroids</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>social media (Twitter) event streams</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>novel events (novelty detection)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Encode tweets as vectors, form real-time clusters representing events, compute centroid for each event cluster, and assess novelty by comparing a cluster's centroid to centroids of older events; large centroid distance indicates novelty.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>The paper references this method as an example; limitations include reliance on embedding quality and sensitivity to cluster formation parameters; no performance numbers provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Used as a conceptual example of anomaly-as-novelty; demonstrates practical real-time pipeline combining embeddings, clustering, and centroid comparison to surface novel events.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A framework for anomaly detection using language modeling, and its applications to finance', 'publication_date_yy_mm': '2019-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9230.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e9230.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Output-likelihood scoring</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Sequence Likelihood / Output-Probability Scoring for Error Detection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Using language-model-generated token probability distributions (sequence likelihoods) to flag low-probability tokens or sequences as probable transcription/OCR errors or anomalies in structured text.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Language-model output probability scoring</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>any probabilistic language model (n-gram, RNN/LSTM, transformer)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>sequences of tokens from transcripts or OCR output</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>earnings call transcripts, OCR'd financial documents, image-to-text conversions</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>real-word errors, OCR/transcription mistakes, misrecognized characters/phrases</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Train domain-specific LM to capture formatting and domain conventions; compute predicted token probabilities during decoding; low-probability tokens or improbable punctuation/number patterns are marked as likely errors for correction or analyst review.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>local bigram/trigram error detection methods (cited as prior work), statistical spellchecking</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Unseen named entities and legitimate rare phrases can be misclassified as errors; domain mismatch between pretraining and target corpora exacerbates false positives.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Argues that domain-specific LMs reduce false positives by encoding domain conventions (e.g., numeric formatting) and that output probability signals are a natural unsupervised mechanism for detecting transcription/OCR anomalies.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A framework for anomaly detection using language modeling, and its applications to finance', 'publication_date_yy_mm': '2019-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9230.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e9230.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hidden-vector drift</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Monitoring Hidden Representation Drift for Trend/Anomaly Detection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Comparing distributions of hidden-layer vectors (from LMs) across time or corpora to detect evolving trends, semantic shifts, or anomalies in documents.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Hidden-layer representation monitoring</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>language model internal hidden states (RNN or transformer)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>hidden state vectors derived from text sequences/documents</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>sector-specific historical documents, recent filings, earnings calls</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>evolving semantic trends, sector shifts, novelty</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Pre-train model on historical sector documents, then fine-tune or evaluate on recent documents; measure distributional changes (drift) in hidden vectors for specific tokens or document types — large shifts signal anomalies or trend emergence.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Requires careful calibration to distinguish genuine semantic shifts from training or sampling variability; not evaluated empirically in paper.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Highlights representation drift as actionable signal: dramatic hidden-vector shifts after fine-tuning may indicate real-world semantic changes worth analyst attention.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A framework for anomaly detection using language modeling, and its applications to finance', 'publication_date_yy_mm': '2019-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Real-Time Novel Event Detection from Social Media <em>(Rating: 2)</em></li>
                <li>Detecting Errors within a Corpus using Anomaly Detection. <em>(Rating: 2)</em></li>
                <li>Fine-tuned Language Models for Text Classification. <em>(Rating: 2)</em></li>
                <li>Attention is All you Need <em>(Rating: 2)</em></li>
                <li>Distributed representations of words and phrases and their compositionality. <em>(Rating: 2)</em></li>
                <li>Linear) maps of the impossible: capturing semantic anomalies in distributional space <em>(Rating: 2)</em></li>
                <li>A simple real-word error detection and correction using local word bigram and trigram. <em>(Rating: 1)</em></li>
                <li>Unsupervised Topic Discovery by Anomaly Detection <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9230",
    "paper_id": "paper-201666793",
    "extraction_schema_id": "extraction-schema-162",
    "extracted_data": [
        {
            "name_short": "LSTM-LM",
            "name_full": "Long Short-Term Memory based Language Model",
            "brief_description": "Recurrent neural-network language model using LSTM units that predicts next tokens in a sequence; the paper discusses using its input/output/hidden representations and generated token probabilities as signals for anomalies in text sequences.",
            "citation_title": "Long Short-Term Memory.",
            "mention_or_use": "mention",
            "model_name": "LSTM-based language model",
            "model_type": "recurrent neural network (LSTM)",
            "model_size": null,
            "data_type": "text sequences (tokens / words / characters); can operate on n-grams or longer sequences",
            "data_domain": "financial text (earnings call transcripts, SEC filings, credit agreements), social media (tweets) as examples",
            "anomaly_type": "transcription/OCR errors, irregular/novel language, semantic anomalies, boilerplate/outlier phrases",
            "method_description": "Train an LSTM language model to predict next token; use model outputs—(a) low output probability / high perplexity for tokens to flag likely transcription/OCR errors, (b) shifts in input/hidden vector distributions when fine-tuned to detect evolving semantic trends, and (c) learned parameters (weights) to identify unusual patterns.",
            "baseline_methods": "n-gram language models, bag-of-words, unsupervised clustering, traditional statistical deviation methods (mentioned conceptually)",
            "performance_metrics": null,
            "performance_results": null,
            "comparison_to_baseline": null,
            "limitations_or_failure_cases": "No empirical results reported; conceptual limitations discussed include unseen domain-specific tokens being mistaken for anomalies (e.g., named entities), noise/variability in spoken language resembling anomalies, and fine-tuning overfitting or misclassifying company-specific terms.",
            "unique_insights": "Paper emphasizes using multiple layers of an LSTM (input vectors, hidden vectors, output probabilities, and weight tensors) as distinct sources of anomaly signals rather than relying only on output likelihood; highlights applying domain-specific training to reduce false positives in financial contexts.",
            "uuid": "e9230.0",
            "source_info": {
                "paper_title": "A framework for anomaly detection using language modeling, and its applications to finance",
                "publication_date_yy_mm": "2019-08"
            }
        },
        {
            "name_short": "Fine-tuned LM",
            "name_full": "Pre-trained Language Model with Fine-tuning for Target Domain",
            "brief_description": "Transfer-learning approach where a language model pretrained on a large generic corpus is fine-tuned on domain-specific text, and shifts in representations or the fine-tuned model's outputs are used to detect anomalies or evolving trends.",
            "citation_title": "Fine-tuned Language Models for Text Classification.",
            "mention_or_use": "mention",
            "model_name": "Pre-trained language model (fine-tuned)",
            "model_type": "pretrained LM with fine-tuning (can be recurrent or transformer-based)",
            "model_size": null,
            "data_type": "text sequences, documents (reports, filings), transcripts",
            "data_domain": "financial documents (SEC filings, earnings calls), sector-specific corpora",
            "anomaly_type": "evolving semantic shifts, novel/outlier documents, company-specific anomalies (operating segments, idiosyncratic clauses)",
            "method_description": "Pre-train LM on large general or sector-historical corpus, then fine-tune on recent/target documents; detect anomalies via large shifts in hidden representations when moving from pre-training to fine-tuning, or by using top layers for classification of atypical content.",
            "baseline_methods": "training from scratch, simple statistical detection of n-gram deviations, supervised classifiers (mentioned conceptually)",
            "performance_metrics": null,
            "performance_results": null,
            "comparison_to_baseline": null,
            "limitations_or_failure_cases": "Fine-tuned models may treat legitimate domain-specific/new named entities as anomalies; overfitting to particular companies can reduce generalization; pretraining corpora might lack domain vocabulary causing misclassification.",
            "unique_insights": "Paper frames large shifts in hidden-vector distributions caused by fine-tuning as indicators of evolving sectoral trends or novel phenomena, suggesting monitoring representation drift as a detection mechanism.",
            "uuid": "e9230.1",
            "source_info": {
                "paper_title": "A framework for anomaly detection using language modeling, and its applications to finance",
                "publication_date_yy_mm": "2019-08"
            }
        },
        {
            "name_short": "Attention",
            "name_full": "Attention Mechanisms / Attention Weights",
            "brief_description": "Attention components (including transformer-style attention) allocate weight to input elements; the paper suggests using learned attention distributions as interpretable signals of anomalous or trigger words and patterns.",
            "citation_title": "Attention is All you Need.",
            "mention_or_use": "mention",
            "model_name": "Attention-based models (transformer attention)",
            "model_type": "attention mechanism / transformer",
            "model_size": null,
            "data_type": "text sequences, short texts (tweets) and longer documents",
            "data_domain": "social media, financial text, engagement prediction examples discussed",
            "anomaly_type": "trigger-word-driven anomalies (clickbait, bot-generated content, propagandistic language), attention spikes indicating unusual emphasis",
            "method_description": "Train attention-based model for a downstream task (e.g., engagement prediction); analyze attention weight distributions to detect inputs that attract atypical attention patterns (e.g., words disproportionally driving engagement), flagging potential anomalies.",
            "baseline_methods": null,
            "performance_metrics": null,
            "performance_results": null,
            "comparison_to_baseline": null,
            "limitations_or_failure_cases": "Paper notes explainability caveats: attention weights are informative but may not fully explain model decisions; no empirical evaluation provided in the paper for anomaly detection use.",
            "unique_insights": "Proposes using attention as an interpretable parameter-space signal for anomaly detection, e.g., to distinguish engaging/information-rich content from clickbait or bot-driven posts by inspecting which words receive high attention.",
            "uuid": "e9230.2",
            "source_info": {
                "paper_title": "A framework for anomaly detection using language modeling, and its applications to finance",
                "publication_date_yy_mm": "2019-08"
            }
        },
        {
            "name_short": "Embeddings",
            "name_full": "Distributed Word/Document Embeddings (e.g., word2vec / doc2vec)",
            "brief_description": "Static or contextual vector representations of words or documents; the paper discusses using embedding stability, nearest-neighbor changes, and centroid comparisons for detecting semantic anomalies and novelty.",
            "citation_title": "Distributed representations of words and phrases and their compositionality.",
            "mention_or_use": "mention",
            "model_name": "Distributed word/document embeddings",
            "model_type": "vector-space distributed representations (static embeddings / contextualized embeddings referenced)",
            "model_size": null,
            "data_type": "words, n-grams, tweet/document vectors, centroid clusters",
            "data_domain": "social media events, financial filings and reports",
            "anomaly_type": "semantic irregularity, novelty, unreliable or shifted word usage",
            "method_description": "Compare embedding stability across corpora/time (e.g., nearest-neighbor similarity) or compare event/document centroids to historical centroids to detect deviations; unusual neighbor changes or centroid distances indicate anomalies or novel events.",
            "baseline_methods": "unsupervised clustering, n-gram frequency comparisons (conceptual)",
            "performance_metrics": null,
            "performance_results": null,
            "comparison_to_baseline": null,
            "limitations_or_failure_cases": "Embedding instability can be influenced by factors unrelated to true anomalies (e.g., training variability); contextual drift and sparse domain terms can lead to false positives.",
            "unique_insights": "Paper highlights embedding stability as a measurable property and suggests leveraging changes in nearest-neighbor structures or centroid comparisons as practical anomaly/novelty signals (cites echo-chamber detection and fake-news work).",
            "uuid": "e9230.3",
            "source_info": {
                "paper_title": "A framework for anomaly detection using language modeling, and its applications to finance",
                "publication_date_yy_mm": "2019-08"
            }
        },
        {
            "name_short": "n-gram smoothing",
            "name_full": "Smoothed n-gram Language Models for Boilerplate / Abnormal Clause Detection",
            "brief_description": "N-gram based probability models applied to documents (e.g., SEC filings) where n-gram probabilities are compared across a company's past filings, sector filings, and peer filings to surface abnormal or boilerplate language.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "Smoothed n-gram language model",
            "model_type": "n-gram statistical language model with smoothing",
            "model_size": null,
            "data_type": "n-gram sequences (text snippets, clauses)",
            "data_domain": "SEC filings, credit agreements, long regulatory documents",
            "anomaly_type": "boilerplate detection, abnormal clauses, rare phrase detection",
            "method_description": "Compute smoothed n-gram probabilities for each n-gram and compare these probabilities against (a) the company's previous filings, (b) filings in the same sector, and (c) filings from companies with similar market cap to identify unusual n-grams (low probability) that merit analyst attention.",
            "baseline_methods": "manual inspection, simple frequency-based heuristics (conceptual)",
            "performance_metrics": null,
            "performance_results": null,
            "comparison_to_baseline": null,
            "limitations_or_failure_cases": "No quantitative evaluation reported here; potential limitations include sensitivity to corpus selection for comparisons and inability to capture deeper semantic novelty beyond n-gram surface forms.",
            "unique_insights": "Practical approach recommended for helping analysts skip boilerplate and focus on clauses that 'stand out' by cross-comparing n-gram probabilities across several reference corpora.",
            "uuid": "e9230.4",
            "source_info": {
                "paper_title": "A framework for anomaly detection using language modeling, and its applications to finance",
                "publication_date_yy_mm": "2019-08"
            }
        },
        {
            "name_short": "Centroid-cluster novelty",
            "name_full": "Centroid-based Real-time Novel Event Detection (tweet-vector clustering)",
            "brief_description": "Method representing each short text (tweet) as a vector, clustering in real time, and comparing cluster centroids to historical event centroids to measure novelty and detect emerging events.",
            "citation_title": "Real-Time Novel Event Detection from Social Media",
            "mention_or_use": "mention",
            "model_name": "Centroid-based event clustering of vectorized tweets",
            "model_type": "embedding + clustering (real-time)",
            "model_size": null,
            "data_type": "short-text sequences (tweets), cluster centroids",
            "data_domain": "social media (Twitter) event streams",
            "anomaly_type": "novel events (novelty detection)",
            "method_description": "Encode tweets as vectors, form real-time clusters representing events, compute centroid for each event cluster, and assess novelty by comparing a cluster's centroid to centroids of older events; large centroid distance indicates novelty.",
            "baseline_methods": null,
            "performance_metrics": null,
            "performance_results": null,
            "comparison_to_baseline": null,
            "limitations_or_failure_cases": "The paper references this method as an example; limitations include reliance on embedding quality and sensitivity to cluster formation parameters; no performance numbers provided in this paper.",
            "unique_insights": "Used as a conceptual example of anomaly-as-novelty; demonstrates practical real-time pipeline combining embeddings, clustering, and centroid comparison to surface novel events.",
            "uuid": "e9230.5",
            "source_info": {
                "paper_title": "A framework for anomaly detection using language modeling, and its applications to finance",
                "publication_date_yy_mm": "2019-08"
            }
        },
        {
            "name_short": "Output-likelihood scoring",
            "name_full": "Sequence Likelihood / Output-Probability Scoring for Error Detection",
            "brief_description": "Using language-model-generated token probability distributions (sequence likelihoods) to flag low-probability tokens or sequences as probable transcription/OCR errors or anomalies in structured text.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "Language-model output probability scoring",
            "model_type": "any probabilistic language model (n-gram, RNN/LSTM, transformer)",
            "model_size": null,
            "data_type": "sequences of tokens from transcripts or OCR output",
            "data_domain": "earnings call transcripts, OCR'd financial documents, image-to-text conversions",
            "anomaly_type": "real-word errors, OCR/transcription mistakes, misrecognized characters/phrases",
            "method_description": "Train domain-specific LM to capture formatting and domain conventions; compute predicted token probabilities during decoding; low-probability tokens or improbable punctuation/number patterns are marked as likely errors for correction or analyst review.",
            "baseline_methods": "local bigram/trigram error detection methods (cited as prior work), statistical spellchecking",
            "performance_metrics": null,
            "performance_results": null,
            "comparison_to_baseline": null,
            "limitations_or_failure_cases": "Unseen named entities and legitimate rare phrases can be misclassified as errors; domain mismatch between pretraining and target corpora exacerbates false positives.",
            "unique_insights": "Argues that domain-specific LMs reduce false positives by encoding domain conventions (e.g., numeric formatting) and that output probability signals are a natural unsupervised mechanism for detecting transcription/OCR anomalies.",
            "uuid": "e9230.6",
            "source_info": {
                "paper_title": "A framework for anomaly detection using language modeling, and its applications to finance",
                "publication_date_yy_mm": "2019-08"
            }
        },
        {
            "name_short": "Hidden-vector drift",
            "name_full": "Monitoring Hidden Representation Drift for Trend/Anomaly Detection",
            "brief_description": "Comparing distributions of hidden-layer vectors (from LMs) across time or corpora to detect evolving trends, semantic shifts, or anomalies in documents.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "Hidden-layer representation monitoring",
            "model_type": "language model internal hidden states (RNN or transformer)",
            "model_size": null,
            "data_type": "hidden state vectors derived from text sequences/documents",
            "data_domain": "sector-specific historical documents, recent filings, earnings calls",
            "anomaly_type": "evolving semantic trends, sector shifts, novelty",
            "method_description": "Pre-train model on historical sector documents, then fine-tune or evaluate on recent documents; measure distributional changes (drift) in hidden vectors for specific tokens or document types — large shifts signal anomalies or trend emergence.",
            "baseline_methods": null,
            "performance_metrics": null,
            "performance_results": null,
            "comparison_to_baseline": null,
            "limitations_or_failure_cases": "Requires careful calibration to distinguish genuine semantic shifts from training or sampling variability; not evaluated empirically in paper.",
            "unique_insights": "Highlights representation drift as actionable signal: dramatic hidden-vector shifts after fine-tuning may indicate real-world semantic changes worth analyst attention.",
            "uuid": "e9230.7",
            "source_info": {
                "paper_title": "A framework for anomaly detection using language modeling, and its applications to finance",
                "publication_date_yy_mm": "2019-08"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Real-Time Novel Event Detection from Social Media",
            "rating": 2,
            "sanitized_title": "realtime_novel_event_detection_from_social_media"
        },
        {
            "paper_title": "Detecting Errors within a Corpus using Anomaly Detection.",
            "rating": 2,
            "sanitized_title": "detecting_errors_within_a_corpus_using_anomaly_detection"
        },
        {
            "paper_title": "Fine-tuned Language Models for Text Classification.",
            "rating": 2,
            "sanitized_title": "finetuned_language_models_for_text_classification"
        },
        {
            "paper_title": "Attention is All you Need",
            "rating": 2,
            "sanitized_title": "attention_is_all_you_need"
        },
        {
            "paper_title": "Distributed representations of words and phrases and their compositionality.",
            "rating": 2,
            "sanitized_title": "distributed_representations_of_words_and_phrases_and_their_compositionality"
        },
        {
            "paper_title": "Linear) maps of the impossible: capturing semantic anomalies in distributional space",
            "rating": 2,
            "sanitized_title": "linear_maps_of_the_impossible_capturing_semantic_anomalies_in_distributional_space"
        },
        {
            "paper_title": "A simple real-word error detection and correction using local word bigram and trigram.",
            "rating": 1,
            "sanitized_title": "a_simple_realword_error_detection_and_correction_using_local_word_bigram_and_trigram"
        },
        {
            "paper_title": "Unsupervised Topic Discovery by Anomaly Detection",
            "rating": 1,
            "sanitized_title": "unsupervised_topic_discovery_by_anomaly_detection"
        }
    ],
    "cost": 0.01204175,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>A framework for anomaly detection using language modeling, and its applications to finance</p>
<p>Armineh Nourbakhsh armineh.nourbakhsh@spglobal.com 
Grace Bang grace.bang@spglobal.com 
A framework for anomaly detection using language modeling, and its applications to finance
S&amp;P Global Ratings New York, NY S&amp;P Global Ratings New York, NYanomaly detectiondeviation analysisoutlier detectionneural networkslanguage modelingnatural language processingfinance
In the finance sector, studies focused on anomaly detection are often associated with time-series and transactional data analytics. In this paper, we lay out the opportunities for applying anomaly and deviation detection methods to text corpora and challenges associated with them. We argue that language models that use distributional semantics can play a significant role in advancing these studies in novel directions, with new applications in risk identification, predictive modeling, and trend analysis.</p>
<p>INTRODUCTION</p>
<p>The detection of anomalous trends in the financial domain has focused largely on fraud detection [23], risk modeling [1], and predictive analysis [7]. The data used in the majority of such studies is of time-series, transactional, graph or generally quantitative or structured nature. This belies the critical importance of semistructured or unstructured text corpora that practitioners in the finance domain derive insights from-corpora such as financial reports, press releases, earnings call transcripts, credit agreements, news articles, customer interaction logs, and social data.</p>
<p>Previous research in anomaly detection from text has evolved largely independently from financial applications. Unsupervised clustering methods have been applied to documents in order to identify outliers and emerging topics [2]. Deviation analysis has been applied to text in order to identify errors in spelling [16] and tagging of documents [4]. Recent popularity of distributional semantics [18] has led to further advances in semantic deviation analysis [20]. However, current research remains largely divorced from specific applications within the domain of finance.</p>
<p>In the following sections, we enumerate major applications of anomaly detection from text in the financial domain, and contextualize them within current research topics in Natural Language Processing.</p>
<p>FIVE VIEWS ON ANOMALY</p>
<p>Anomaly detection is a strategy that is often employed in contexts where a deviation from a certain norm is sought to be captured, especially when extreme class imbalance impedes the use of a supervised approach. The implementation of such methods allows for the unveiling of previously hidden or obstructed insights.</p>
<p>In this section, we lay out five perspectives on how textual anomaly detection can be applied in the context of finance, and how each application opens up opportunities for NLP researchers to apply current research to the financial domain.</p>
<p>Anomaly as error</p>
<p>Previous studies have used anomaly detection to identify and correct errors in text [4,16]. These are often unintentional errors that occur as a result of some form of data transfer, e.g. from audio to text, from image to text, or from one language to another. Such studies have direct applicability to the error-prone process of earnings call or customer call transcription, where audio quality, accents, and domain-specific terms can lead to errors. Consider a scenario where the CEO of a company states in an audio conference, 'Now investments will be made in Asia. ' However, the system instead transcribes, 'No investments will be made in Asia. ' There is a meaningful difference in the implication of the two statements that could greatly influence the analysis and future direction of the company. Additionally, with regards to the second scenario, it is highly unlikely that the CEO would make such a strong and negative statement in a public setting thus supporting the use of anomaly detection for error correction.</p>
<p>Optical-character-recognition from images is another error-prone process with large applicability to finance. Many financial reports and presentations are circulated as image documents that need to undergo OCR in order to be machine-readable. OCR might also be applicable to satellite imagery and other forms of image data that might include important textual content such as a graphical representation of financial data. Errors that result from OCR'd documents can often be fixed using systems that have a robust semantic representation of the target domain. For instance, a model that is trained on financial reports might have encoded awareness that emojis are unlikely to appear in them or that it is unusual for the numeric value of profit to be higher than that of revenue.</p>
<p>Anomaly as irregularity</p>
<p>Anomaly in the semantic space might reflect irregularities that are intentional or emergent, signaling risky behavior or phenomena. A sudden change in the tone and vocabulary of a company's leadership in their earnings calls or financial reports can signal risk. News stories that have abnormal language, or irregular origination or propagation patterns might be unreliable or untrustworthy. [22] showed that when trained on similar domains or contexts, distributed representations of words are likely to be stable, where stability is measured as the similarity of their nearest neighbors in the distributed space. Such insight can be used to assess anomalies in this sense. As an example, [12] identified cliques of users on Twitter who consistently shared news from similar domains.</p>
<p>Characterizing these networks as "echo-chambers, " they then represented the content shared by these echo-chambers as distributed representations. When certain topics from one echo-chamber began to deviate from similar topics in other echo-chambers, the content was tagged as unreliable. [12] showed that this method can be used to improve the performance of standard methods for fake-news detection.</p>
<p>In another study [24], the researchers hypothesized that transparent language in earnings calls indicates high expectations for performance in the upcoming quarters, whereas semantic ambiguity can signal a lack of confidence and expected poor performance. By quantifying transparency as the frequent use of numbers, shorter words, and unsophisticated vocabulary, they showed that a change in transparency is associated with a change in future performance.</p>
<p>Anomaly as novelty</p>
<p>Anomaly can indicate a novel event or phenomenon that may or may not be risky. Breaking news stories often emerge as anomalous trends on social media. [9] experimented with this in their effort to detect novel events from Twitter conversations. By representing each event as a real-time cluster of tweets (where each tweet was encoded as a vector), they managed to assess the novelty of the event by comparing its centroid to the centroids of older events.</p>
<p>Novelty detection can also be used to detect emerging trends on social media, e.g. controversies that engulf various brands often start as small local events that are shared on social media and attract attention over a short period of time. How people respond to these events in early stages of development can be a measure of their veracity or controversiality [10,13].</p>
<p>An anomaly in an industry grouping of companies can also be indicative of a company that is disrupting the norm for that industry and the emergence of a new sector or sub-sector. Often known as trail-blazers, these companies innovate faster than their competitors to meet market demands sometimes even before the consumer is aware of their need. As these companies continually evolve their business lines, their core operations are novel outliers from others in the same industry classification that can serve as meaningful signals of transforming industry demands.</p>
<p>Anomaly as semantic richness</p>
<p>A large portion of text documents that analysts and researchers in the financial sectors consume have a regulatory nature. Annual financial reports, credit agreements, and filings with the U.S. Securities and Exchange Commission (SEC) are some of these types of documents. These documents can be tens or hundreds of pages long, and often include boilerplate language that the readers might need to skip or ignore in order to get to the "meat" of the content. Often, the abnormal clauses found in these documents are buried in standard text so as not to attract attention to the unique phrases.</p>
<p>[17] used smoothed representations of n-grams in SEC filings in order to identify boilerplate and abnormal language. They did so by comparing the probability of each n-gram against the company's previous filings, against other filings in the same sector, and against other filings from companies with similar market cap. The aim was to assist accounting analysts in skipping boilerplate language and focusing their attention on important snippets in these documents. Similar methods can be applied to credit agreements where covenants and clauses that are too common are often ignored by risk analysts and special attention is paid to clauses that "stand out" from similar agreements.</p>
<p>Anomaly as contextual relevance</p>
<p>Certain types of documents include universal as well as contextspecific signals. As an example, consider a given company's financial reports. The reports may include standard financial metrics such as total revenue, net sales, net income, etc. In addition to these universal metrics, businesses often report their performance in terms of the performance of their operating segments. These segments can be business divisions, products, services, or regional operations. The segments are often specific to the company or its peers. For example, Apple Inc. 's segments might include "iPhone, " "iMac, " "iPad, " and "services. " The same segments will not appear in reports by other businesses.</p>
<p>For many analysts and researchers, operating segments are a crucial part of exploratory or predictive analysis. They use performance metrics associated with these segments to compare the business to its competitors, to estimate its market share, and to project the overall performance of the business in upcoming quarters. Automating the identification and normalization of these metrics can facilitate more insightful analytical research. Since these segments are often specific to each business, supervised models that are trained on a diverse set of companies cannot capture them without overfitting to certain companies. Instead, these segments can be treated as company-specific anomalies.</p>
<p>ANOMALY DETECTION VIA LANGUAGE MODELING</p>
<p>Unlike numeric data, text data is not directly machine-readable, and requires some form of transformation as a pre-processing step. In "bag-of-words" methods, this transformation can take place by assigning an index number to each word, and representing any block of text as an unordered set of these words. A slightly more sophisticated approach might chain words into continuous "n-grams" and represent a block of text as an ordered series of "n-grams" that have been extracted on a sliding window of size n. These approaches are conventionally known as "language modeling. " Since the advent of high-powered processors enabled the widespread use of distributed representations, language modeling has rapidly evolved and adapted to these new capabilities. Recurrent neural networks can capture an arbitrarily long sequence of text and perform various tasks such as classification or text generation [21]. In this new context, language modeling often refers to training a recurrent network that predicts a word in a given sequence of text [6]. Language models are easy to train because even though they follow a predictive mechanism, they do not need any labeled data, and are thus unsupervised. Figure 1 is a simple illustration of how a neural network that is composed of recurrent units such as Long-Short Term Memory (LSTM) [5] can perform language modeling. The are four main components to the network:</p>
<p>• The input vectors (x i ), which represent units (i.e. characters, words, phrases, sentences, paragraphs, etc.) in the input text. Occasionally, these are represented by one-hot vectors that assign a unique index to each particular input. More commonly, these vectors are adapted from a pre-trained corpus, where distributed representations have been inferred either by a simpler auto-encoding process [11] or by applying the same recurrent model to a baseline corpus such as Wikipedia [6]. • The output vectors (y i ), which represent the model's prediction of the next word in the sequence. Naturally, they are represented in the same dimensionality as x i s. • The hidden vectors (h i ), which are often randomly initialized and learned through backpropagation. Often trained as dense representations, these vectors tend to display characteristics that indicate semantic richness [14] and compositionality [11]. While the language model can be used as a text-generation mechanism, the hidden vectors are a strong side product that are sometimes extracted and reused as augmented features in other machine learning systems [3]. • The weights of the network (W i j ) (or other parameters in the network), which are tuned through backpropagation. These often indicate how each vectors in the input or hidden sequence is utilized to generate the output. These parameters play a big role in the way the output of neural networks are reverse-engineered or explained to the end user 1 .</p>
<p>The distributions of any of the above-mentioned components can be studied to mine signals for anomalous behavior in the context of irregularity, error, novelty, semantic richness, or contextual relevance.</p>
<p>Anomaly in input vectors</p>
<p>As previously mentioned, the input vectors to a text-based neural network are often adapted from publicly-available word vector corpora. In simpler architectures, the network is allowed to backpropagate its errors all the way to the input layer, which might cause the input vectors to be modified. This can serve as a signal for 1 As an example see https://tinyurl.com/y56drbnk anomaly in the semantic distributions between the original vectors and the modified vectors.</p>
<p>Analyzing the stability of word vectors when trained on different iterations can also signal anomalous trends [22].</p>
<p>Anomaly in output vectors</p>
<p>As previously mentioned, language models generate a probability distribution over a word (or character) in a sequence. These probabilities can be used to detect transcription or character-recognition errors in a domain-friendly manner. When the language model is trained on financial data, domain-specific trends (such as the use of commas and parentheses in financial metrics) can be captured and accounted for by the network, minimizing the rate of false positives.</p>
<p>Anomaly in hidden vectors</p>
<p>A recent advancement in text processing is the introduction of finetuning methods to neural networks trained on text [6]. Fine-tuning is an approach that facilitates the transfer of semantic knowledge from one domain (source) to another domain (target). The source domain is often large and generic, such as web data or the Wikipedia corpus, while the target domain is often specific (e.g. SEC filings). A network is pre-trained on the source corpus such that its hidden representations are enriched. Next, the pre-trained networks is retrained on the target domain, but this time only the final (or top few) layers are tuned and the parameters in the remaining layers remain "frozen. " The top-most layer of the network can be modified to perform a classification, prediction, or generation task in the target domain (see Figure 2).</p>
<p>Fine-tuning aims to change the distribution of hidden representations in such a way that important information about the source domain is preserved, while idiosyncrasies of the target domain are captured in an effective manner [15]. A similar process can be used to determine anomalies in documents. As an example, consider a model that is pre-trained on historical documents from a given sector. If fine-tuning the model on recent documents from the same sector dramatically shifts the representations for certain vectors, this can signal an evolving trend.</p>
<p>Anomaly in weight tensors and other parameters</p>
<p>Models that have interpretable parameters can be used to identify areas of deviation or anomalous content. Attention mechanisms [19] allow the network to account for certain input signals more than others. The learned attention mechanism can provide insight into potential anomalies in the input. Consider a language model that predicts the social media engagement for a given tweet. Such a model can be used to distinguish between engaging and information-rich content versus clickbait, bot-generated, propagandistic, or promotional content by exposing how, for these categories, engagement is associated with attention to certain distributions of "trigger words. " Table 1 lists four scenarios for using the various layers and parameters of a language model in order to perform anomaly detection from text.   </p>
<p>CHALLENGES AND FUTURE RESEARCH</p>
<p>Like many other domains, in the financial domain, the application of language models as a measurement for semantic regularity of text bears the challenge of dealing with unseen input. Unseen input can be mistaken for anomaly, especially in systems that are designed for error detection. As an example, a system that is trained to correct errors in an earnings call transcript might treat named entities such as the names of a company's executives, or a recent acquisition, as anomalies. This problem is particularly prominent in fine-tuned language models, which are pre-trained on generic corpora that might not include domain-specific terms.</p>
<p>When anomalies are of a malicious nature, such as in the case where abnormal clauses are included in credit agreements, the implementation of the anomalous content is adapted to appear normal. Thereby, the task of detecting normal language becomes more difficult.</p>
<p>Alternatively, in the case of language used by executives in company presentations such as earnings calls, there may be a lot of noise in the data due to the large degree of variability in the personalities and linguistic patterns of various leaders. The noise variability present in this content could be similar to actual anomalies, hence making it difficult to identify true anomalies.</p>
<p>Factors related to market interactions and competitive behavior can also impact the effectiveness of anomaly-detection models. In detecting the emergence of a new industry sector, it may be challenging for a system to detect novelty when a collection of companies, rather than a single company, behave in an anomalous way. The former may be the more common real-world scenario as companies closely monitor and mimic the innovations of their competitors. The exact notion of anomaly can also vary based on the sector and point in time. For example, in the technology sector, the norm in today's world is one of continuous innovation and technological advancements.</p>
<p>Additionally, certain types of anomaly can interact and make it difficult for systems to distinguish between them. As an example, a system that is trained to identify the operating segments of a company tends to distinguish between information that is specific to the company, and information that is common across different companies. As a result, it might identify the names of the company's board of directors or its office locations as its operating segments.</p>
<p>Traditional machine learning models have previously tackled the above challenges, and solutions are likely to emerge in the neural paradigms as well. Any future research in these directions will have to account for the impact of such solutions on the reliability and explainability of the resulting models and their robustness against adversarial data.</p>
<p>CONCLUSION</p>
<p>Anomaly detection from text can have numerous applications in finance, including risk detection, predictive analysis, error correction, and peer detection. We have outlined various perspectives on how anomaly can be interpreted in the context of finance, and corresponding views on how language modeling can be used to detect such aspects of anomalous content. We hope that this paper lays the groundwork for establishing a framework for understanding the opportunities and risks associated with these methods when applied in the financial domain.</p>
<p>Figure 1 :
1Illustration of a recurrent step in a language model. Excerpted from[8].</p>
<p>Figure 2 :
2A pre-trained model can be fine-tuned on a new domain, and applied to a classification or prediction task. Excerpted from[6].</p>
<p>Table 1 :
1Four scenarios for anomaly detection on text data using signals from various layers and parameters in a language model.</p>
<p>Credit risk analysis using machine and deep learning models. Peter Addo, Dominique Guegan, Bertrand Hassani, Risks. 638Peter Addo, Dominique Guegan, and Bertrand Hassani. 2018. Credit risk analysis using machine and deep learning models. Risks 6, 2 (2018), 38.</p>
<p>Unsupervised Topic Discovery by Anomaly Detection. Leon Cheng, Leon Cheng. 2013. Unsupervised Topic Discovery by Anomaly Detection.</p>
<p>Bert: Pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, arXiv:1810.04805arXiv preprintJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 (2018).</p>
<p>Detecting Errors within a Corpus using Anomaly Detection. Eleazar Eskin, 1st Meeting of the North American Chapter of the Association for Computational Linguistics. Eleazar Eskin. 2000. Detecting Errors within a Corpus using Anomaly Detection. In 1st Meeting of the North American Chapter of the Association for Computational Linguistics. https://www.aclweb.org/anthology/A00-2020</p>
<p>Long Short-Term Memory. Sepp Hochreiter, Jãĳrgen Schmidhuber, Neural Computation. 9Sepp Hochreiter and JÃĳrgen Schmidhuber. 1997. Long Short-Term Memory. Neural Computation 9, 8 (1997), 1735-1780.</p>
<p>Fine-tuned Language Models for Text Classification. Jeremy Howard, Sebastian Ruder, CoRR abs/1801.06146Jeremy Howard and Sebastian Ruder. 2018. Fine-tuned Language Models for Text Classification. CoRR abs/1801.06146 (2018).</p>
<p>Does trading volume contain information to predict stock returns? Evidence from China's stock markets. F Cheng, Lee, Oliver M Rui, Review of Quantitative Finance and Accounting. 14Cheng F Lee and Oliver M Rui. 2000. Does trading volume contain informa- tion to predict stock returns? Evidence from China's stock markets. Review of Quantitative Finance and Accounting 14, 4 (2000), 341-360.</p>
<p>Language modeling a billion words. Nicholas Leonard, Nicholas Leonard. 2016. Language modeling a billion words. http://torch.ch/ blog/2016/07/25/nce.html.</p>
<p>Real-Time Novel Event Detection from Social Media. Quanzhi Li, Armineh Nourbakhsh, Sameena Shah, Xiaomo Liu, 33rd IEEE International Conference on Data Engineering. San Diego, CA, USAQuanzhi Li, Armineh Nourbakhsh, Sameena Shah, and Xiaomo Liu. 2017. Real- Time Novel Event Detection from Social Media. In 33rd IEEE International Con- ference on Data Engineering, ICDE 2017, San Diego, CA, USA, April 19-22, 2017. 1129-1139.</p>
<p>Real-time Rumor Debunking on Twitter. Xiaomo Liu, Armineh Nourbakhsh, Quanzhi Li, Rui Fang, Sameena Shah, Proceedings of the 24th ACM International Conference on Information and Knowledge Management, CIKM 2015. the 24th ACM International Conference on Information and Knowledge Management, CIKM 2015Melbourne, VIC, AustraliaXiaomo Liu, Armineh Nourbakhsh, Quanzhi Li, Rui Fang, and Sameena Shah. 2015. Real-time Rumor Debunking on Twitter. In Proceedings of the 24th ACM International Conference on Information and Knowledge Management, CIKM 2015, Melbourne, VIC, Australia, October 19 -23, 2015. 1867-1870.</p>
<p>Distributed representations of words and phrases and their compositionality. Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, Jeff Dean, Advances in neural information processing systems. Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems. 3111-3119.</p>
<p>apping the echo-chamber: detecting and characterizing partisan networks on Twitter. Armineh Nourbakhsh, Xiaomo Liu, Quanzhi Li, Sameena Shah, Proceedings of the 2017 International Conference on Social Computing, Behavioral-Cultural Modeling, &amp; Prediction and Behavior Representation in Modeling and Simulation. the 2017 International Conference on Social Computing, Behavioral-Cultural Modeling, &amp; Prediction and Behavior Representation in Modeling and SimulationArmineh Nourbakhsh, Xiaomo Liu, Quanzhi Li, and Sameena Shah. 2017. "apping the echo-chamber: detecting and characterizing partisan networks on Twitter. In Proceedings of the 2017 International Conference on Social Computing, Behavioral- Cultural Modeling, &amp; Prediction and Behavior Representation in Modeling and Simulation.</p>
<p>Newsworthy Rumor Events: A Case Study of Twitter. Armineh Nourbakhsh, Xiaomo Liu, Sameena Shah, Rui Fang, Mohammad Mahdi Ghassemi, Quanzhi Li, IEEE International Conference on Data Mining Workshop, ICDMW 2015. Atlantic City, NJ, USAArmineh Nourbakhsh, Xiaomo Liu, Sameena Shah, Rui Fang, Mohammad Mahdi Ghassemi, and Quanzhi Li. 2015. Newsworthy Rumor Events: A Case Study of Twitter. In IEEE International Conference on Data Mining Workshop, ICDMW 2015, Atlantic City, NJ, USA, November 14-17, 2015. 27-32.</p>
<p>E Matthew, Mark Peters, Mohit Neumann, Matt Iyyer, Christopher Gardner, Kenton Clark, Luke Lee, Zettlemoyer, arXiv:1802.05365Deep contextualized word representations. arXiv preprintMatthew E Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. 2018. Deep contextualized word representations. arXiv preprint arXiv:1802.05365 (2018).</p>
<p>Learning to select data for transfer learning with Bayesian Optimization. Sebastian Ruder, Barbara Plank, 10.18653/v1/D17-1038Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics. the 2017 Conference on Empirical Methods in Natural Language Processing. Association for Computational LinguisticsCopenhagen, DenmarkSebastian Ruder and Barbara Plank. 2017. Learning to select data for transfer learn- ing with Bayesian Optimization. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguis- tics, Copenhagen, Denmark, 372-382. https://doi.org/10.18653/v1/D17-1038</p>
<p>A simple real-word error detection and correction using local word bigram and trigram. Pratip Samanta, B Bidyut, Chaudhuri, Proceedings of the 25th Conference on Computational Linguistics and Speech Processing. the 25th Conference on Computational Linguistics and Speech ProcessingROCLING 2013Pratip Samanta and Bidyut B. Chaudhuri. 2013. A simple real-word error detection and correction using local word bigram and trigram. In Proceedings of the 25th Conference on Computational Linguistics and Speech Processing (ROCLING 2013).</p>
<p>The Association for Computational Linguistics and Chinese Language Processing (ACLCLP). Kaohsiung, TaiwanThe Association for Computational Linguistics and Chinese Language Processing (ACLCLP), Kaohsiung, Taiwan, 211-220. https://www.aclweb.org/anthology/ O13-1022</p>
<p>Sameena Shah, Dietmar Dorr, Khalid Al-Kofahi, Jacob Sisk, Systems and methods for determining atypical language. n. d.Sameena Shah, Dietmar Dorr, Khalid Al-Kofahi, and Jacob Sisk. [n. d.]. Systems and methods for determining atypical language.</p>
<p>From Frequency to Meaning: Vector Space Models of Semantics. D Peter, Patrick Turney, Pantel, CoRR abs/1003.1141Peter D. Turney and Patrick Pantel. 2010. From Frequency to Meaning: Vector Space Models of Semantics. CoRR abs/1003.1141 (2010).</p>
<p>Attention is All you Need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Illia Kaiser, Polosukhin, Advances in Neural Information Processing Systems. I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. GarnettCurran Associates, Inc30Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz Kaiser, and Illia Polosukhin. 2017. Attention is All you Need. In Advances in Neural Information Processing Systems 30, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Eds.). Curran Associates, Inc., 5998-6008.</p>
<p>Linear) maps of the impossible: capturing semantic anomalies in distributional space. Maria Eva, Marco Vecchi, Roberto Baroni, Zamparelli, Proceedings of the Workshop on Distributional Semantics and Compositionality. the Workshop on Distributional Semantics and CompositionalityAssociation for Computational LinguisticsEva Maria Vecchi, Marco Baroni, and Roberto Zamparelli. 2011. (Linear) maps of the impossible: capturing semantic anomalies in distributional space. In Proceed- ings of the Workshop on Distributional Semantics and Compositionality. Association for Computational Linguistics, 1-9.</p>
<p>Stochastic Language Generation in Dialogue using Recurrent Neural Networks with Convolutional Sentence Reranking. Milica Tsung Hsien Wen, Dongho Gasic, Nikola Kim, Pei-Hao Mrksic, David Su, Steve Vandyke, Young, Tsung Hsien Wen, Milica Gasic, Dongho Kim, Nikola Mrksic, Pei-Hao Su, David Vandyke, and Steve Young. 2015. Stochastic Language Generation in Dialogue using Recurrent Neural Networks with Convolutional Sentence Reranking. (08 2015).</p>
<p>Laura Wendlandt, Jonathan K Kummerfeld, Rada Mihalcea, arXiv:1804.09692Factors influencing the surprising instability of word embeddings. arXiv preprintLaura Wendlandt, Jonathan K Kummerfeld, and Rada Mihalcea. 2018. Fac- tors influencing the surprising instability of word embeddings. arXiv preprint arXiv:1804.09692 (2018).</p>
<p>Intelligent financial fraud detection: A comprehensive review. Jarrod West, Maumita Bhattacharya, 10.1016/j.cose.2015.09.005Computers &amp; Security. 57Jarrod West and Maumita Bhattacharya. 2016. Intelligent financial fraud detection: A comprehensive review. Computers &amp; Security 57 (2016), 47 -66. https: //doi.org/10.1016/j.cose.2015.09.005</p>
<p>Hanging on Every Word: Natural Language Processing Unlocks New Frontier in Corporate Earnings Sentiment Analysis. Frank Zhao, Frank Zhao. 2017. Hanging on Every Word: Natural Language Processing Unlocks New Frontier in Corporate Earnings Sentiment Analysis. https://www.valuewalk. com/2017/09/natural-language-processing-corporate-earnings-sentiment/.</p>            </div>
        </div>

    </div>
</body>
</html>