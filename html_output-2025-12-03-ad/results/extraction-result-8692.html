<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8692 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8692</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8692</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-156.html">extraction-schema-156</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <p><strong>Paper ID:</strong> paper-245117749</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2112.05677v2.pdf" target="_blank">Concept Representation Learning with Contrastive Self-Supervised Learning</a></p>
                <p><strong>Paper Abstract:</strong> Concept-oriented deep learning (CODL) is a general approach to meet the future challenges for deep learning: (1) learning with little or no external supervision, (2) coping with test examples that come from a different distribution than the training examples, and (3) integrating deep learning with symbolic AI. In CODL, as in human learning, concept representations are learned based on concept exemplars. Contrastive self-supervised learning (CSSL) provides a promising approach to do so, since it: (1) uses data-driven associations, to get away from semantic labels, (2) supports incremental and continual learning, to get away from (large) fixed datasets, and (3) accommodates emergent objectives, to get away from fixed objectives (tasks). We discuss major aspects of concept representation learning using CSSL. These include dual-level concept representations, CSSL for feature representations, exemplar similarity measures and self-supervised relational reasoning, incremental and continual CSSL, and contrastive self-supervised concept (class) incremental learning. The discussion leverages recent findings from cognitive neural science and CSSL.</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8692.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8692.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Dual-level / Dual-coding</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Dual-level concept representations (dual-coding framework)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A functional account that conceptual knowledge is represented at two interacting levels: an embodied, modality-specific feature level derived from sensory experience, and an amodal, language-derived symbolic level; for concrete concepts both levels are associated.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Dual Coding of Knowledge in the Human Brain</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>dual-coding (dual-level) representation</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Concepts are functionally represented by two complementary formats: (1) embodied, modality-specific feature representations encoding sensory-derived properties (visual, auditory, tactile, etc.), and (2) an amodal symbolic representation derived from language experience; the two are associated for concrete concepts and support different kinds of conceptual access.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>hybrid (embodied/distributed + symbolic/amodal)</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Neuroimaging contrasts of concrete vs. abstract concepts; comparisons between congenitally blind and sighted individuals; activation patterns in anterior temporal lobe (ATL) and sensory cortex; behavioral differences for abstract vs. concrete concept processing.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Neuroimaging evidence shows dorsal ATL represents non-sensory, language-derived knowledge (including in congenitally blind participants) while sensory cortices represent sensory-derived properties in sighted people; abstract concepts elicit stronger left ATL and language-network activation compared with concrete concepts, supporting two complementary representational levels.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Presented as complementary to the hub-and-spoke model (similar in positing amodal hub + modality-specific spokes); evidence favors a hybrid account (both embodied and amodal representations) over purely sensory-only or purely amodal-only accounts for many concept types.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Paper notes the need for both systems but does not offer detailed functional limitations; implicit limitation is that a purely sensory representation cannot account for abstract concepts or conceptual knowledge present in congenitally blind individuals.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Adopting dual-level representations supports learning from few exemplars, separation of embodied feature learning (suitable for CSSL) and symbolic conceptual knowledge (concept graphs), and integration of deep learning with symbolic AI for conceptual understanding and transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Concept Representation Learning with Contrastive Self-Supervised Learning', 'publication_date_yy_mm': '2021-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8692.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8692.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hub-and-spoke</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hub-and-spoke semantic representation model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A functional model that integrates modality-specific 'spokes' encoding sensory/verbal elements with an amodal central 'hub' mediating between spokes to yield general semantic representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Concepts, Control, and Context: A Connectionist Account of Normal and Disordered Semantic Cognition</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>hub-and-spoke (amodal hub + modality-specific spokes)</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Functionally, semantic knowledge is distributed across modality-specific 'spokes' (sensory/verbal feature encoders) that are integrated by an amodal 'hub' (hidden units) which mediates between spokes and supports generalization and cross-modal conceptual access.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>hybrid (distributed modality-specific + amodal hub)</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Semantic dementia lesion evidence, neuroimaging localization (ventral-lateral ATL hub engagement), general semantic processing across modalities.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Lesion and imaging evidence identify an ATL hub region working with modality-specific regions to support general semantic processing; this supports a computational architecture where the hub mediates between different sensory/verbal inputs.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Described as similar to the dual-coding framework; both posit modality-specific representations plus an amodal integrative component, contrasting with purely distributed-only or purely symbolic-only models.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Paper does not present empirical counter-evidence; general limitations of hub models include underspecification of functional form of the hub and how symbolic/linguistic structure is represented within it.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Supports using an amodal symbolic layer (the hub) as the basis for linking embodied feature representations to higher-level concept structures (e.g., concept graphs) in CODL.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Concept Representation Learning with Contrastive Self-Supervised Learning', 'publication_date_yy_mm': '2021-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8692.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8692.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CSSL feature embeddings</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Contrastive Self-Supervised Learning feature representations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Functionally, CSSL learns distributed feature embeddings by pulling together augmentations of the same exemplar and pushing apart embeddings of different exemplars, yielding transferable, brain-like feature spaces usable as embodied concept representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A Visual Encoding Model Based on Contrastive Self-Supervised Learning for Human Brain Activity along the Ventral Visual Stream.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>distributed feature embeddings (contrastive)</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Conceptual (embodied) knowledge is represented as points or regions in a continuous high-dimensional feature space learned via contrastive objectives; positive pairs (augmented views of same exemplar) are encouraged to have similar embeddings while negative pairs are repelled, so concepts are functionally encoded as clusters/neighborhoods in embedding space.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>distributed, feature-based representation</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Visual encoding of ventral stream responses (model vs. brain representational dissimilarity matrices), classification and retrieval downstream tasks, exemplar-based learning and sample-scarce learning scenarios.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Cited studies using RDMs (correlation distance between representation pairs) and Kendall rank correlation show CSSL-derived embeddings are strong contenders for explaining ventral stream representations; CSSL yields feature spaces capturing important information usable in downstream classification/retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Presented as the computational realization of the embodied level of dual-level models and complementary to symbolic concept graphs; favors CSSL over generative/self-supervised approaches for extracting discriminative, brain-like features in visual domains.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Standard contrastive losses are feature-oriented and may not directly capture concept-level relations (the paper argues they are not suitable for contrasting concepts without modification); CSSL faces catastrophic forgetting in incremental/continual settings unless augmented with rehearsal/distillation strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>CSSL can provide the embodied feature representations for concept learning from few exemplars, supporting transfer and integration with symbolic systems; modifications (exemplar-oriented losses, relational reasoning) are needed to align feature embeddings with concept-level structure.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Concept Representation Learning with Contrastive Self-Supervised Learning', 'publication_date_yy_mm': '2021-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8692.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8692.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Concept graph (symbolic)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Concept graph (symbolic concept-level representation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A symbolic, amodal network representation of concepts and their relations used as the background knowledge base for conceptual understanding and linking to embodied feature representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Concept-Oriented Deep Learning.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>symbolic concept graph (semantic network)</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Concepts are functionally represented as nodes in a graph with labeled relations/arcs connecting them (hierarchies, attributes, instances); this amodal symbolic layer provides explicit structure for reasoning, disambiguation, and integration across modalities.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>symbolic / graph-based</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Symbolic reasoning and higher-level cognition, knowledge integration and transfer, linking to language-derived knowledge, and supporting conceptual understanding beyond perception.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Paper proposes using a concept graph (e.g., Microsoft Concept Graph) as the symbolic level in CODL, enabling integration of learned embodied feature representations with background conceptual structure; concept graphs provide the framework for conceptual understanding and transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Offered as complementary to distributed feature embeddings: embeddings supply perceptual grounding while the concept graph supplies symbolic, relational structure; neither format alone suffices for full conceptual understanding according to the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Symbolic graphs require curated/semi-curated knowledge and may not capture perceptual variability well; linking symbols to embodied feature clusters requires reliable alignment mechanisms (nontrivial).</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Using a concept graph permits emergent, task-general conceptual understanding, supports symbolic reasoning and integration with classical AI, and serves as the amodal counterpart to CSSL-derived embodied representations in CODL.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Concept Representation Learning with Contrastive Self-Supervised Learning', 'publication_date_yy_mm': '2021-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8692.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e8692.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Exemplar model / similarity</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Exemplar-based representation and exemplar similarity measures</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A functional framework in which concepts are represented via stored exemplars and category membership or concept representations arise from similarity relations among exemplars (pattern robustness, encoding–retrieval similarity).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Neural Pattern Similarity Across Concept Exemplars Predicts Memory After A Long Delay.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>exemplar-based representation</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Concepts are functionally represented by collections of exemplar encodings; similarity metrics among exemplar encodings (e.g., within-concept vs between-concept correlation differences) determine category coherence, memory predictions, and how new exemplars update concept representations.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>instance-based / similarity-based</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Episodic memory for concept–exemplar pairings, subsequent memory performance, pattern similarity analyses across exemplars, hierarchical categorization (superordinate/subordinate levels).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Pattern robustness (difference between within-concept and between-concept similarities) and encoding–retrieval similarity positively predict subsequent memory for concept-exemplar pairings; exemplar similarity predicts memory even when stimuli are not visually identical.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Exemplar-based representations emphasize stored instances and similarity computations vs. prototype or pure-symbolic abstractions; paper argues exemplar-based learning (few exemplars) is feasible and aligns with CSSL's exemplar-driven training but requires conceptual (not just feature) contrastive objectives.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Exemplar similarity alone may not capture higher-order relational structure or abstract concepts with few perceptual exemplars; need mechanisms to compute and leverage taxonomic levels (superordinate vs subordinate) and to avoid over-reliance on low-level overlap.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Using exemplars as training input for CSSL maps well onto human concept learning from few examples and supports incremental/conceptual updating; exemplar similarity measures should be integrated into contrastive objectives to produce concept-appropriate embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Concept Representation Learning with Contrastive Self-Supervised Learning', 'publication_date_yy_mm': '2021-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8692.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e8692.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Self-supervised relational reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Self-supervised relational reasoning (in CSSL)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A pretext-task-driven format that enforces learned representations to encode inter- and intra-concept relations by training a relation head to discriminate whether two encodings are from the same concept (intra) or different concepts (inter).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Self-Supervised Relational Reasoning for Representation Learning.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>relational (relation-head) representation</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Functionally, relations among exemplars (same vs different concept) are represented via a learned relation score computed over pairs of embeddings; training objectives push embeddings to form positive neighborhoods for intra-concept relations and repel embeddings for inter-concept relations, instantiating concept-level structure in embedding space.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>relation-centric / contrastive + relational</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Pretext discrimination tasks (intra- vs inter-reasoning), downstream classification and retrieval, capturing within-concept clustering and between-concept separation analogous to human relational concept learning.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The relation-head is trained with intra-reasoning loss (target relation score = 1 for same-exemplar augmentations) and inter-reasoning loss (target = 0 for different exemplars); minimizing these losses yields embeddings that cluster by concept and separate across concepts, and the relation head can be discarded after training while the backbone retains relationally organized features.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Augments standard feature-level contrastive objectives by explicitly encoding concept-level relations; argued to be more suitable than feature-only contrastive losses for learning concept-oriented embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Requires appropriate construction of positive and negative pairs (exemplar selection); if exemplars are scarce or noisy, relational supervision may be weak; paper does not provide quantitative benchmarks here but positions the method as a needed extension to feature-oriented CSSL.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Embedding explicit relational reasoning into self-supervision aligns learned representations more closely with concept-level structure, facilitating exemplar-based concept learning and better integration with symbolic concept representations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Concept Representation Learning with Contrastive Self-Supervised Learning', 'publication_date_yy_mm': '2021-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8692.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e8692.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Taxonomic / hierarchical</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Concept taxonomy / hierarchical representation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hierarchical format where concepts are organized in superordinate-subordinate relations (taxonomic tree), and representational similarity is analyzed across hierarchical levels (basic, subordinate, superordinate).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Concept-Oriented Deep Learning.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>taxonomic (hierarchical) representation</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Concepts are functionally organized into hierarchical categories (superordinate, basic, subordinate); representational measures (within-concept vs between-concept similarity) are computed with respect to levels in the taxonomy to capture category coherence at multiple granularities.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>symbolic/hierarchical (structured)</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Memory and categorization across hierarchical levels (basic-level effects), pattern robustness computed per hierarchical level, exemplar similarity analyses within and across taxonomic groups.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Pattern robustness computed at superordinate and subordinate levels reveals differences in within- vs between-concept similarity; human memory performance for concepts is linked to which taxonomic levels are accessed and remembered.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Hierarchical taxonomic structure complements exemplar and distributed representations by providing explicit category structure; it highlights granularity effects not captured by flat embedding clusters alone.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Taxonomies require explicit labels or grouping heuristics and may not emerge directly from feature-only contrastive learning without auxiliary supervision or relational objectives.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Incorporating taxonomic structure into exemplar selection, loss design, or symbolic graphs aids memory and categorization, and should be considered when designing CSSL objectives for concept learning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Concept Representation Learning with Contrastive Self-Supervised Learning', 'publication_date_yy_mm': '2021-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Dual Coding of Knowledge in the Human Brain <em>(Rating: 2)</em></li>
                <li>Concepts, Control, and Context: A Connectionist Account of Normal and Disordered Semantic Cognition <em>(Rating: 2)</em></li>
                <li>A Visual Encoding Model Based on Contrastive Self-Supervised Learning for Human Brain Activity along the Ventral Visual Stream. <em>(Rating: 2)</em></li>
                <li>Neural Pattern Similarity Across Concept Exemplars Predicts Memory After A Long Delay <em>(Rating: 2)</em></li>
                <li>Self-Supervised Relational Reasoning for Representation Learning <em>(Rating: 2)</em></li>
                <li>Concept-Oriented Deep Learning. <em>(Rating: 2)</em></li>
                <li>Continual Contrastive Self-supervised Learning for Image Classification <em>(Rating: 1)</em></li>
                <li>A Survey on Contrastive Self-Supervised Learning <em>(Rating: 1)</em></li>
                <li>Momentum Contrast for Unsupervised Visual Representation Learning <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8692",
    "paper_id": "paper-245117749",
    "extraction_schema_id": "extraction-schema-156",
    "extracted_data": [
        {
            "name_short": "Dual-level / Dual-coding",
            "name_full": "Dual-level concept representations (dual-coding framework)",
            "brief_description": "A functional account that conceptual knowledge is represented at two interacting levels: an embodied, modality-specific feature level derived from sensory experience, and an amodal, language-derived symbolic level; for concrete concepts both levels are associated.",
            "citation_title": "Dual Coding of Knowledge in the Human Brain",
            "mention_or_use": "use",
            "representational_format_name": "dual-coding (dual-level) representation",
            "representational_format_description": "Concepts are functionally represented by two complementary formats: (1) embodied, modality-specific feature representations encoding sensory-derived properties (visual, auditory, tactile, etc.), and (2) an amodal symbolic representation derived from language experience; the two are associated for concrete concepts and support different kinds of conceptual access.",
            "format_type": "hybrid (embodied/distributed + symbolic/amodal)",
            "cognitive_task_or_phenomenon": "Neuroimaging contrasts of concrete vs. abstract concepts; comparisons between congenitally blind and sighted individuals; activation patterns in anterior temporal lobe (ATL) and sensory cortex; behavioral differences for abstract vs. concrete concept processing.",
            "key_findings": "Neuroimaging evidence shows dorsal ATL represents non-sensory, language-derived knowledge (including in congenitally blind participants) while sensory cortices represent sensory-derived properties in sighted people; abstract concepts elicit stronger left ATL and language-network activation compared with concrete concepts, supporting two complementary representational levels.",
            "comparison_with_other_formats": "Presented as complementary to the hub-and-spoke model (similar in positing amodal hub + modality-specific spokes); evidence favors a hybrid account (both embodied and amodal representations) over purely sensory-only or purely amodal-only accounts for many concept types.",
            "limitations_or_counter_evidence": "Paper notes the need for both systems but does not offer detailed functional limitations; implicit limitation is that a purely sensory representation cannot account for abstract concepts or conceptual knowledge present in congenitally blind individuals.",
            "theoretical_claims_or_implications": "Adopting dual-level representations supports learning from few exemplars, separation of embodied feature learning (suitable for CSSL) and symbolic conceptual knowledge (concept graphs), and integration of deep learning with symbolic AI for conceptual understanding and transfer.",
            "uuid": "e8692.0",
            "source_info": {
                "paper_title": "Concept Representation Learning with Contrastive Self-Supervised Learning",
                "publication_date_yy_mm": "2021-12"
            }
        },
        {
            "name_short": "Hub-and-spoke",
            "name_full": "Hub-and-spoke semantic representation model",
            "brief_description": "A functional model that integrates modality-specific 'spokes' encoding sensory/verbal elements with an amodal central 'hub' mediating between spokes to yield general semantic representations.",
            "citation_title": "Concepts, Control, and Context: A Connectionist Account of Normal and Disordered Semantic Cognition",
            "mention_or_use": "mention",
            "representational_format_name": "hub-and-spoke (amodal hub + modality-specific spokes)",
            "representational_format_description": "Functionally, semantic knowledge is distributed across modality-specific 'spokes' (sensory/verbal feature encoders) that are integrated by an amodal 'hub' (hidden units) which mediates between spokes and supports generalization and cross-modal conceptual access.",
            "format_type": "hybrid (distributed modality-specific + amodal hub)",
            "cognitive_task_or_phenomenon": "Semantic dementia lesion evidence, neuroimaging localization (ventral-lateral ATL hub engagement), general semantic processing across modalities.",
            "key_findings": "Lesion and imaging evidence identify an ATL hub region working with modality-specific regions to support general semantic processing; this supports a computational architecture where the hub mediates between different sensory/verbal inputs.",
            "comparison_with_other_formats": "Described as similar to the dual-coding framework; both posit modality-specific representations plus an amodal integrative component, contrasting with purely distributed-only or purely symbolic-only models.",
            "limitations_or_counter_evidence": "Paper does not present empirical counter-evidence; general limitations of hub models include underspecification of functional form of the hub and how symbolic/linguistic structure is represented within it.",
            "theoretical_claims_or_implications": "Supports using an amodal symbolic layer (the hub) as the basis for linking embodied feature representations to higher-level concept structures (e.g., concept graphs) in CODL.",
            "uuid": "e8692.1",
            "source_info": {
                "paper_title": "Concept Representation Learning with Contrastive Self-Supervised Learning",
                "publication_date_yy_mm": "2021-12"
            }
        },
        {
            "name_short": "CSSL feature embeddings",
            "name_full": "Contrastive Self-Supervised Learning feature representations",
            "brief_description": "Functionally, CSSL learns distributed feature embeddings by pulling together augmentations of the same exemplar and pushing apart embeddings of different exemplars, yielding transferable, brain-like feature spaces usable as embodied concept representations.",
            "citation_title": "A Visual Encoding Model Based on Contrastive Self-Supervised Learning for Human Brain Activity along the Ventral Visual Stream.",
            "mention_or_use": "use",
            "representational_format_name": "distributed feature embeddings (contrastive)",
            "representational_format_description": "Conceptual (embodied) knowledge is represented as points or regions in a continuous high-dimensional feature space learned via contrastive objectives; positive pairs (augmented views of same exemplar) are encouraged to have similar embeddings while negative pairs are repelled, so concepts are functionally encoded as clusters/neighborhoods in embedding space.",
            "format_type": "distributed, feature-based representation",
            "cognitive_task_or_phenomenon": "Visual encoding of ventral stream responses (model vs. brain representational dissimilarity matrices), classification and retrieval downstream tasks, exemplar-based learning and sample-scarce learning scenarios.",
            "key_findings": "Cited studies using RDMs (correlation distance between representation pairs) and Kendall rank correlation show CSSL-derived embeddings are strong contenders for explaining ventral stream representations; CSSL yields feature spaces capturing important information usable in downstream classification/retrieval.",
            "comparison_with_other_formats": "Presented as the computational realization of the embodied level of dual-level models and complementary to symbolic concept graphs; favors CSSL over generative/self-supervised approaches for extracting discriminative, brain-like features in visual domains.",
            "limitations_or_counter_evidence": "Standard contrastive losses are feature-oriented and may not directly capture concept-level relations (the paper argues they are not suitable for contrasting concepts without modification); CSSL faces catastrophic forgetting in incremental/continual settings unless augmented with rehearsal/distillation strategies.",
            "theoretical_claims_or_implications": "CSSL can provide the embodied feature representations for concept learning from few exemplars, supporting transfer and integration with symbolic systems; modifications (exemplar-oriented losses, relational reasoning) are needed to align feature embeddings with concept-level structure.",
            "uuid": "e8692.2",
            "source_info": {
                "paper_title": "Concept Representation Learning with Contrastive Self-Supervised Learning",
                "publication_date_yy_mm": "2021-12"
            }
        },
        {
            "name_short": "Concept graph (symbolic)",
            "name_full": "Concept graph (symbolic concept-level representation)",
            "brief_description": "A symbolic, amodal network representation of concepts and their relations used as the background knowledge base for conceptual understanding and linking to embodied feature representations.",
            "citation_title": "Concept-Oriented Deep Learning.",
            "mention_or_use": "use",
            "representational_format_name": "symbolic concept graph (semantic network)",
            "representational_format_description": "Concepts are functionally represented as nodes in a graph with labeled relations/arcs connecting them (hierarchies, attributes, instances); this amodal symbolic layer provides explicit structure for reasoning, disambiguation, and integration across modalities.",
            "format_type": "symbolic / graph-based",
            "cognitive_task_or_phenomenon": "Symbolic reasoning and higher-level cognition, knowledge integration and transfer, linking to language-derived knowledge, and supporting conceptual understanding beyond perception.",
            "key_findings": "Paper proposes using a concept graph (e.g., Microsoft Concept Graph) as the symbolic level in CODL, enabling integration of learned embodied feature representations with background conceptual structure; concept graphs provide the framework for conceptual understanding and transfer.",
            "comparison_with_other_formats": "Offered as complementary to distributed feature embeddings: embeddings supply perceptual grounding while the concept graph supplies symbolic, relational structure; neither format alone suffices for full conceptual understanding according to the paper.",
            "limitations_or_counter_evidence": "Symbolic graphs require curated/semi-curated knowledge and may not capture perceptual variability well; linking symbols to embodied feature clusters requires reliable alignment mechanisms (nontrivial).",
            "theoretical_claims_or_implications": "Using a concept graph permits emergent, task-general conceptual understanding, supports symbolic reasoning and integration with classical AI, and serves as the amodal counterpart to CSSL-derived embodied representations in CODL.",
            "uuid": "e8692.3",
            "source_info": {
                "paper_title": "Concept Representation Learning with Contrastive Self-Supervised Learning",
                "publication_date_yy_mm": "2021-12"
            }
        },
        {
            "name_short": "Exemplar model / similarity",
            "name_full": "Exemplar-based representation and exemplar similarity measures",
            "brief_description": "A functional framework in which concepts are represented via stored exemplars and category membership or concept representations arise from similarity relations among exemplars (pattern robustness, encoding–retrieval similarity).",
            "citation_title": "Neural Pattern Similarity Across Concept Exemplars Predicts Memory After A Long Delay.",
            "mention_or_use": "use",
            "representational_format_name": "exemplar-based representation",
            "representational_format_description": "Concepts are functionally represented by collections of exemplar encodings; similarity metrics among exemplar encodings (e.g., within-concept vs between-concept correlation differences) determine category coherence, memory predictions, and how new exemplars update concept representations.",
            "format_type": "instance-based / similarity-based",
            "cognitive_task_or_phenomenon": "Episodic memory for concept–exemplar pairings, subsequent memory performance, pattern similarity analyses across exemplars, hierarchical categorization (superordinate/subordinate levels).",
            "key_findings": "Pattern robustness (difference between within-concept and between-concept similarities) and encoding–retrieval similarity positively predict subsequent memory for concept-exemplar pairings; exemplar similarity predicts memory even when stimuli are not visually identical.",
            "comparison_with_other_formats": "Exemplar-based representations emphasize stored instances and similarity computations vs. prototype or pure-symbolic abstractions; paper argues exemplar-based learning (few exemplars) is feasible and aligns with CSSL's exemplar-driven training but requires conceptual (not just feature) contrastive objectives.",
            "limitations_or_counter_evidence": "Exemplar similarity alone may not capture higher-order relational structure or abstract concepts with few perceptual exemplars; need mechanisms to compute and leverage taxonomic levels (superordinate vs subordinate) and to avoid over-reliance on low-level overlap.",
            "theoretical_claims_or_implications": "Using exemplars as training input for CSSL maps well onto human concept learning from few examples and supports incremental/conceptual updating; exemplar similarity measures should be integrated into contrastive objectives to produce concept-appropriate embeddings.",
            "uuid": "e8692.4",
            "source_info": {
                "paper_title": "Concept Representation Learning with Contrastive Self-Supervised Learning",
                "publication_date_yy_mm": "2021-12"
            }
        },
        {
            "name_short": "Self-supervised relational reasoning",
            "name_full": "Self-supervised relational reasoning (in CSSL)",
            "brief_description": "A pretext-task-driven format that enforces learned representations to encode inter- and intra-concept relations by training a relation head to discriminate whether two encodings are from the same concept (intra) or different concepts (inter).",
            "citation_title": "Self-Supervised Relational Reasoning for Representation Learning.",
            "mention_or_use": "use",
            "representational_format_name": "relational (relation-head) representation",
            "representational_format_description": "Functionally, relations among exemplars (same vs different concept) are represented via a learned relation score computed over pairs of embeddings; training objectives push embeddings to form positive neighborhoods for intra-concept relations and repel embeddings for inter-concept relations, instantiating concept-level structure in embedding space.",
            "format_type": "relation-centric / contrastive + relational",
            "cognitive_task_or_phenomenon": "Pretext discrimination tasks (intra- vs inter-reasoning), downstream classification and retrieval, capturing within-concept clustering and between-concept separation analogous to human relational concept learning.",
            "key_findings": "The relation-head is trained with intra-reasoning loss (target relation score = 1 for same-exemplar augmentations) and inter-reasoning loss (target = 0 for different exemplars); minimizing these losses yields embeddings that cluster by concept and separate across concepts, and the relation head can be discarded after training while the backbone retains relationally organized features.",
            "comparison_with_other_formats": "Augments standard feature-level contrastive objectives by explicitly encoding concept-level relations; argued to be more suitable than feature-only contrastive losses for learning concept-oriented embeddings.",
            "limitations_or_counter_evidence": "Requires appropriate construction of positive and negative pairs (exemplar selection); if exemplars are scarce or noisy, relational supervision may be weak; paper does not provide quantitative benchmarks here but positions the method as a needed extension to feature-oriented CSSL.",
            "theoretical_claims_or_implications": "Embedding explicit relational reasoning into self-supervision aligns learned representations more closely with concept-level structure, facilitating exemplar-based concept learning and better integration with symbolic concept representations.",
            "uuid": "e8692.5",
            "source_info": {
                "paper_title": "Concept Representation Learning with Contrastive Self-Supervised Learning",
                "publication_date_yy_mm": "2021-12"
            }
        },
        {
            "name_short": "Taxonomic / hierarchical",
            "name_full": "Concept taxonomy / hierarchical representation",
            "brief_description": "A hierarchical format where concepts are organized in superordinate-subordinate relations (taxonomic tree), and representational similarity is analyzed across hierarchical levels (basic, subordinate, superordinate).",
            "citation_title": "Concept-Oriented Deep Learning.",
            "mention_or_use": "use",
            "representational_format_name": "taxonomic (hierarchical) representation",
            "representational_format_description": "Concepts are functionally organized into hierarchical categories (superordinate, basic, subordinate); representational measures (within-concept vs between-concept similarity) are computed with respect to levels in the taxonomy to capture category coherence at multiple granularities.",
            "format_type": "symbolic/hierarchical (structured)",
            "cognitive_task_or_phenomenon": "Memory and categorization across hierarchical levels (basic-level effects), pattern robustness computed per hierarchical level, exemplar similarity analyses within and across taxonomic groups.",
            "key_findings": "Pattern robustness computed at superordinate and subordinate levels reveals differences in within- vs between-concept similarity; human memory performance for concepts is linked to which taxonomic levels are accessed and remembered.",
            "comparison_with_other_formats": "Hierarchical taxonomic structure complements exemplar and distributed representations by providing explicit category structure; it highlights granularity effects not captured by flat embedding clusters alone.",
            "limitations_or_counter_evidence": "Taxonomies require explicit labels or grouping heuristics and may not emerge directly from feature-only contrastive learning without auxiliary supervision or relational objectives.",
            "theoretical_claims_or_implications": "Incorporating taxonomic structure into exemplar selection, loss design, or symbolic graphs aids memory and categorization, and should be considered when designing CSSL objectives for concept learning.",
            "uuid": "e8692.6",
            "source_info": {
                "paper_title": "Concept Representation Learning with Contrastive Self-Supervised Learning",
                "publication_date_yy_mm": "2021-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Dual Coding of Knowledge in the Human Brain",
            "rating": 2,
            "sanitized_title": "dual_coding_of_knowledge_in_the_human_brain"
        },
        {
            "paper_title": "Concepts, Control, and Context: A Connectionist Account of Normal and Disordered Semantic Cognition",
            "rating": 2,
            "sanitized_title": "concepts_control_and_context_a_connectionist_account_of_normal_and_disordered_semantic_cognition"
        },
        {
            "paper_title": "A Visual Encoding Model Based on Contrastive Self-Supervised Learning for Human Brain Activity along the Ventral Visual Stream.",
            "rating": 2,
            "sanitized_title": "a_visual_encoding_model_based_on_contrastive_selfsupervised_learning_for_human_brain_activity_along_the_ventral_visual_stream"
        },
        {
            "paper_title": "Neural Pattern Similarity Across Concept Exemplars Predicts Memory After A Long Delay",
            "rating": 2,
            "sanitized_title": "neural_pattern_similarity_across_concept_exemplars_predicts_memory_after_a_long_delay"
        },
        {
            "paper_title": "Self-Supervised Relational Reasoning for Representation Learning",
            "rating": 2,
            "sanitized_title": "selfsupervised_relational_reasoning_for_representation_learning"
        },
        {
            "paper_title": "Concept-Oriented Deep Learning.",
            "rating": 2,
            "sanitized_title": "conceptoriented_deep_learning"
        },
        {
            "paper_title": "Continual Contrastive Self-supervised Learning for Image Classification",
            "rating": 1,
            "sanitized_title": "continual_contrastive_selfsupervised_learning_for_image_classification"
        },
        {
            "paper_title": "A Survey on Contrastive Self-Supervised Learning",
            "rating": 1,
            "sanitized_title": "a_survey_on_contrastive_selfsupervised_learning"
        },
        {
            "paper_title": "Momentum Contrast for Unsupervised Visual Representation Learning",
            "rating": 1,
            "sanitized_title": "momentum_contrast_for_unsupervised_visual_representation_learning"
        }
    ],
    "cost": 0.012730499999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Concept Representation Learning with Contrastive Self-Supervised Learning</p>
<p>Daniel T Chang dtchang43@gmail.com 
Concept Representation Learning with Contrastive Self-Supervised Learning
84FD9E7C66F88B1BB46C52B7E15F5FF5
Concept-oriented deep learning (CODL) is a general approach to meet the future challenges for deep learning: (1) learning with little or no external supervision, (2) coping with test examples that come from a different distribution than the training examples, and (3) integrating deep learning with symbolic AI.In CODL, as in human learning, concept representations are learned based on concept exemplars.Contrastive self-supervised learning (CSSL) provides a promisingapproach to do so, since it: (1) uses data-driven associations, to get away from semantic labels, (2) supports incremental and continual learning, to get away from (large) fixed datasets, and (3) accommodates emergent objectives, to get away from fixed objectives (tasks).We discuss major aspects of concept representation learning using CSSL.These include dual-level concept representations, CSSL for feature representations, exemplar similarity measures and self-supervised relational reasoning, incremental and continual CSSL, and contrastive self-supervised concept (class) incremental learning.The discussion leverages recent findings from cognitive neural science and CSSL.</p>
<p>Introduction</p>
<p>The origins, recent advances and future challenges of deep learning are discussed in [1].It points out that there are fundamental deficiencies of current deep learning that cannot be overcome by scaling alone.It suggests several directions for improvement:</p>
<ol>
<li>Supervised learning requires too much labeled data.Humans are able to generalize well with far less experience.Concepts are the foundation of human learning, understanding, and knowledge integration and transfer [2].Thus, to meet the future challenges for deep learning, it is crucial to explicitly incorporate concepts as fundamental tenets in deep learning.</li>
</ol>
<p>We previously proposed concept-oriented deep learning (CODL) [2] as a general approach to do so.CODL extends current deep learning (rote feature representation learning) with concept representation learning and conceptual understanding capability.CODL addresses some of the major limitations of current deep learning: interpretability, transferability, contextual adaptation, and requirement for lots of labeled training data.The major aspects of CODL include concept graph, concept representations, concept exemplars, and concept representation learning systems supporting incremental and continual learning.</p>
<p>In CODL, as in human learning, concept representations are learned based on concept exemplars [2] which are few typical instances of a concept.This is feasible due to the high-level, semantically-segmented nature of concepts, in contrast to the low-level, semantically-nonrepresentative nature of features.Significantly, it avoids the need to gather and create large datasets, which can be difficult or costly, to use for training.Concept representation learning can be done using supervised learning or unsupervised learning.In the former case, the concept exemplars are labeled with the concepts (and possibly their instances and attributes).In the latter case, the concept exemplars are unlabeled.In both cases, concept-invariant transformations can be applied to concept exemplars to improve training.</p>
<p>Unsupervised representation learning is nowadays called self-supervised learning, which highlights the fact that the learning leverages the (unlabeled) data's inherent co-occurrence relationships as the self-supervision.It uses pretext tasks to learn a general and transferrable feature representation.There are two main approaches to self-supervised learning [4]:</p>
<p> Generative: train an encoder to encode input x into a latent vector z and a decoder to reconstruct x from z.</p>
<p> Contrastive: train an encoder to encode input x into a latent vector z to measure similarity.</p>
<p>The most popular generative model is the autoencoder model with many variants.The Tiered Graph Autoencoder model [3], which we previously proposed, is a variant of the autoencoder model.</p>
<p>Contrastive self-supervised learning (CSSL) [5] aims at embedding augmented versions of the same sample (i.e., positive examples) close to each other while pushing away embeddings from different samples (i.e., negative examples).The three most common components of CSSL are encoders, pretext tasks and contrastive loss functions.Encoders are responsible for mapping the input samples to a latent space of embeddings.To train an encoder, a pretext task is used that utilizes contrastive loss for backpropagation.For images, two of the most common pretext tasks are color transformation and geometric transformation.Contrastive loss functions are generally based on similarity metrics which measure the closeness between the embeddings of two samples.The trained neural network backbone can be used in downstream tasks such as classification and sample retrieval.</p>
<p>The promises and objectives of CSSL are [6]:</p>
<p>• Data-driven associations: to get away from semantic categories (labels)</p>
<p>• Incremental and continual learning: to get away from (large) fixed datasets • Emergent objectives: to get away from fixed objectives (tasks) These match very well with those of CODL.In CODL, concept representations can be learned using unsupervised learning; CODL supports incremental and continual learning; and concept representations are generic and can be used for various tasks.</p>
<p>In this paper, we discuss major aspects of concept representation learning using CSSL.The discussion leverages recent findings from cognitive neural science and CSSL.</p>
<p>Dual-Level Concept Representations</p>
<p>Human brain has traditionally been assumed to represent knowledge through the embodiment of sensory experiences.</p>
<p>Recent behavioral and neuroimaging studies of visual knowledge with and without sensory experience [7], however, provide empirical evidence for the neural coding of non-sensory, language-derived knowledge, along with sensory-derived representation, in different brain systems.In particular, studies of neural activity patterns in congenitally blind and sighted groups have provided positive evidence for neural coding of non-sensory knowledge representation (for at least visual concepts) in dorsal ATL in the human brain, while also confirming the sensory-derived representation in the visual cortex in the sighted.Importantly, such coding of visual knowledge in dorsal ATL occurs not only in the blind but also the sighted brain, indicating that even when sensory-derived properties are available there are both sensory-derived and non-sensory representations.Other studies have found that abstract concepts (i.e., those without specific sensory referents, such as 'justice'), compared with concrete concepts (e.g., 'dog'), elicit stronger neural activation in the left ATL along with other regions encompassing the language network.</p>
<p>The dual-coding neural knowledge representation framework [7] is thus proposed as nature's solution to the challenges of knowledge representation.It consists of embodied, sensory-derived knowledge representations, from sensory experience, and symbolic, language-derived knowledge representations, from language experience.Sensor-derived representations are modality specific (visual, auditory, tactile, gustatory, olfactory, etc.); language-derived representations, on the other hand, are amodal.For concrete concepts, the two types of representations are associated.</p>
<p>The influential hub-and-spoke model [8] is similar to the dual-coding framework.The model consists of several sets of spoke units representing sensory and verbal elements of experience.There are also a set of hidden units (the hub) which do not receive external inputs but instead mediate between the various spokes.The spokes are modality specific, encode different information sources, and are integrated in the ventral-lateral ATL hub.The hub is the home of amodal, symbolic representations.The semantic hub and its modality-specific semantic white matter connections were recently identified [9] based on evidence from semantic dementia.The results show that the hub region works in concert with nine other regions in the semantic neural network for general semantic processing.</p>
<p>For concept representations, therefore, we use a dual-level model: the embodied level consists of concept-oriented feature representations [2], and the symbolic level consists of concepts in the form of a concept graph [2].The symbolic level may be linked to Microsoft Concept Graph, or something comparable, which serves as the common / background conceptual knowledge base and the framework for conceptual understanding.For concrete concepts, the two levels are associated / connected.The embodied level corresponds to sensory-derived knowledge representations of the dual-coding framework; the symbolic level corresponds to language-derived knowledge representations of that framework.</p>
<p>In this paper, we focus our discussion on learning the embodied level of concept representations (i.e., concept-oriented feature representations) using CSSL.</p>
<p>CSSL for Feature Representations</p>
<p>Visual encoding models [10] are computational models for understanding how information is processed along the visual stream.In humans, visual information is processed by a cascade of neural computations and the mapping from the input stimulus space to the brain activity space is nonlinear.A feature space is usually introduced to assist model building, which assumes that the nonlinear mapping from the input space to the activity space is entirely contained by the nonlinear mapping from the input space to the feature space, such that only linear mapping is required from the feature space to the activity space.The hierarchical information processing mechanism of deep neural networks is highly similar to that of the visual cortex.Hence, visual encoding models based on features extracted using deep neural networks have been extensively studied.In particular, CSSL proves to be an effective method to extract brain-like feature representations.</p>
<p>The CSSL model [10]  To evaluate the CSSL model's ability of characterizing brain representations [10], a representation dissimilarity matrix (RDM) is used to describe the model or brain representations, which is calculated as the correlation distance (1 -Pearson correlation coefficient r) between all pairs of model or brain representations.Kendall rank correlation coefficient is used to evaluate the similarity between a model RDM and a brain RDM.The results suggest that the CSSL model is a strong contender for explaining ventral stream visual representations.They also prove that CSSL is an effective learning method to extract useful information from samples.In fact, the contrast mechanism is an important mechanism of human learning.</p>
<p>For learning concept-oriented feature representations using CSSL, concept exemplars are used as input.The exemplars may be labeled or unlabeled.In the former case, the exemplars are labeled with the concepts (and possibly their instances and attributes).It is important to note that, unlike supervised learning, the labels are not used as targets in training.They are used to identify the learned feature representations in the embodied level as well as to associate these with concepts in the symbolic level.If the exemplars are unlabeled, pseudo labels are generated for candidate concepts, same as in human learning.</p>
<p>Exemplar Similarity Measures and Self-Supervised Relational Reasoning</p>
<p>For learning concept-oriented feature representations using concept exemplars as input, the commonly-used contrastive loss functions [5] are feature-oriented and not suitable for contrasting concepts.We need concept-oriented loss functions based on, e.g., exemplar similarity measures and self-supervised relational reasoning, which are discussed below.</p>
<p>Exemplar Similarity Measures</p>
<p>In human learning, each interaction we have with a concept (e.g., "dog" or "justice") is unique.To form a high-level representation of a concept, we must draw on similarities between (concept) exemplars to form new or updated conceptual knowledge.Two exemplar (pattern) similarity measures -pattern robustness and encoding-retrieval similarity -are particularly important [11].Pattern robustness indicates that a concept is robustly represented relative to other concepts; encoding-retrieval similarity positively predicts subsequent memory performance.Exemplar similarity is an important predictor of memory for novel concept-exemplar pairings even when the concept includes multiple exemplars.Importantly, established predictive relationships between exemplar similarity and subsequent memory do not require visually identical stimuli (i.e., are not simply due to low-level visual overlap between exemplars).</p>
<p>Any object or entity can be thought of as being in a set of hierarchically organized concepts, i.e., a concept taxonomy [2].</p>
<p>In a concept taxonomy, the concepts that are higher in the hierarchy (e.g., bird) are superordinate to the lower-level concepts; the lower-level concepts (e.g., sparrow) are subordinate to the higher-level ones.A person's ability to access a learned concept through these levels is important for memory, with some levels being remembered (e.g., basic levels [2]), while others are not.Pattern robustness [11] is defined as the difference between within-concept and between-concept similarities.</p>
<p>For superordinates (e.g., bird), the within-concept similarity is calculated for each superordinate level as the Pearson correlation coefficients between matching superordinate level exemplars.The values are Fisher-z corrected and averaged across all superordinate levels.The between-concept similarity is calculated in the same manner but across taxonomical groups (e.g., bird with non-bird groups).For subordinates (e.g., dove, sparrow), the calculation is done similarly.However, the between-concept similarity is always calculated between subordinates within the same superordinate level (e.g., bird).</p>
<p>Self-Supervised Relational Reasoning</p>
<p>An important factor in human learning is the acquisition of new knowledge by relating concepts.Relationships among concepts allow a person to ignore irrelevant perceptual features and focus on relevant non-obvious properties.Self-supervised relational reasoning [12] is proposed to exploit a similar mechanism in CSSL.It can be used as a pretext task to build feature representations in a neural network backbone, by training a relation head on unlabeled data to discriminate how concepts relate to themselves (intra-reasoning) and other concepts (inter-reasoning).Once the system (backbone + relation head) has been trained, the relation head is discarded, and the backbone is used in downstream tasks (e.g.classification, sample retrieval).</p>
<p>Intra-reasoning consists of coupling two random augmentations of the same exemplar {A(ϵ i ), A(ϵ i )}  "same" (positive pair), whereas inter-reasoning consists of coupling two random exemplars {A(ϵ i ), A(ϵ j ); i ≠ j}  "different" (negative pair).</p>
<p>An example is coupling two different views of the same apple to build the positive pair, and coupling an apple with a different fruit to build the negative pair.Intra-reasoning is thus within-concept, and inter-reasoning is between-concept.</p>
<p>The learning objective [12] consists of an intra-reasoning loss term and an inter-reasoning loss term.The intra-reasoning loss term is the sum of the differences between the relation score of the encodings of each positive pair and a target value of 1 (perfect correlation); the inter-reasoning loss term is the sum of the differences between the relation score of the encodings of each negative pair and a target value of 0 (perfect independence).The relation score is a learnable, probabilistic similarity measure (e.g.exemplar similarity measures).By minimizing the learning objective, each feature representation (encoding) is pushed towards a positive neighborhood (intra-reasoning) and repelled from a complementary set of negative neighborhoods (inter-reasoning).</p>
<p>CSSL Using Exemplars as Input</p>
<p>In human learning, learning a concept involves few exemplars and, further, the exemplars only need sufficient details to be distinguishable from exemplars of different concepts.This is in great contrast to current deep learning which requires large amount of data with great details.CSSL using exemplars as input, therefore, involves small datasets and requires only data with sufficient details that are suitable for use in exemplar similarity measures and self-supervised relational reasoning.</p>
<p>S3L [13] proposes a learning paradigm for CSSL that includes three parts: small dataset, small resolution, and small model.Various experiments show that the paradigm achieves significant benefits with small training cost, especially on small datasets.CSSL using exemplars as input matches this learning paradigm.</p>
<p>Incremental and Continual CSSL</p>
<p>In human learning, we learn concepts incrementally, with or without having existing concepts for comparison.And we continue to learn new concepts and new aspects of existing concepts.When presented with new concepts to learn, we leverage knowledge from previous concepts and integrate newly learned knowledge into previous concepts.Therefore, as discussed in [2], incremental and continual learning is a critical aspect of CODL.The main challenge for CSSL w.r.t.incremental and continual learning is the same as that for incremental and continual learning models in general.They suffer from catastrophic forgetting, i.e., training a model with data for new concepts and updating its parameters interferes with to CCSL in alleviating the catastrophic forgetting problem in CSSL.CCSL add incremental and continual learning support to base CSSL models (e.g., MoCo); CSS-CIL, on the other hand, adds CSSL support to base CIL models (e.g., exemplar-based methods, as discussed below).</p>
<p>Class Incremental Learning (CIL)</p>
<p>A CIL problem T consists of a sequence of N tasks [16].A task is a set of classes disjoint from classes in other (previous or future) tasks.Formally, T can be defined as:
T = [(C 1 , D 1 ), (C 2 , D 2 ), …, (C N , D N )],
where each task t is represented by a set of classes C t = {c t 1 , c t 2 , …, c t N^t } and training data D t .During training for task t, the incremental learner only has access to D t , and the tasks do not overlap in classes (i.e.C i ∩ C j = 0 if i ≠ j).</p>
<p>Traditionally, the objective of CIL is to learn a unified classifier from a sequence of data from different classes, via supervised learning, in which case [16]: D t = {(x 1 , y 1 ), (x 2 , y 2 ), …, (x m^t , y m^t )}, where x are input features for a training sample, and y is the label corresponding to x.The incremental learner is a deep neural network parameterized by weights θ:
o(x) = h(x; θ).
It is common to split the deep neural network into a feature extractor f(.) with weights φ and a linear classifier g(.) with weights ν:
o(x) = g(f(x; φ); ν).
This assumes all the nonlinearity of the deep neural network resides in the feature extractor.We note that the same is usually assumed in visual encoding models (see 3 CSSL for Feature Representations).</p>
<p>There are two main categories of CIL methods [16]: exemplar-based (rehearsal) methods that store a limited set of exemplars to prevent forgetting of previous classes; regularization-based methods that aim to minimize the impact of learning new classes on the weights that are important for previous classes.We focus on exemplar-based methods.The three crucial components of an exemplar-based method [17] include a memory buffer to store few exemplars from old classes (e.g., using herding heuristics), a forgetting constraint (e.g., knowledge distillation) to keep previous knowledge while learning new classes, and a learning system that balances old and new classes.iCaRL [18] is the most typical exemplar-based method and employs knowledge distillation as forgetting constraint.We note that CCSL adopts the exemplar-based method (see 5</p>
<p>Incremental and Continual CSSL).</p>
<p>6.2 Contrastive Self-Supervised CIL (CSS-CIL)</p>
<p>Self-Supervised Class Incremental Learning (SSCIL) [19]  SimCLR consists of four major components: (1) a data augmentation A module that transforms any given sample randomly resulting in two correlated views (i.e., a positive pair) of the same sample, (2) a neural network feature extractor f(.) that extracts feature representations from augmented samples, (3) a neural network projection head g(.) that maps feature representations to the latent space where contrastive loss is applied, and (4) a contrastive loss function L defined for a contrastive prediction task that identifies positive pairs.</p>
<p>To use the evaluation protocols, the feature extractor f t (.) is frozen after the training in phase t has completed.The Linear Evaluation Protocol (LEP) uses all of the class-sets {D indicates how much knowledge the model has at the phase t, where the D test is the test set of the full-dataset D.</p>
<p>Conclusion</p>
<p>Based on recent findings from cognitive neural science and contrastive self-supervised learning (CSSL), we find: (1) learning concept representations, which are general and transferable, is crucial to meet the future challenges for deep learning, and (2) CSSL provides a promising approach to learn concept representations at the embodied level (i.e., conceptoriented feature representations) based on concept exemplars.We discuss major aspects of concept representation learning using CSSL, particularly incremental and continual learning since it is infeasible and unrealistic to learn all concepts and their key attributes at once.For future work, we plan to explore exemplar-based concept (class) incremental learning with contrastive self-supervised relational reasoning and exemplar similarity measures.</p>
<p>2 .
2
Current deep learning systems are not robust to changes in distribution.Humans can quickly adapt to such changes with very few examples.3. Current deep learning is most successful at perception tasks.Humans can perform higher-level cognition.Specifically, the future challenges for deep learning involve (1) learning with little or no external supervision, (2) coping with test examples that come from a different distribution than the training examples, and (3) integrating deep learning with symbolic AI.</p>
<p>includes four modules: (1) data augmentation module, (2) encoder module, (3) feature representation extraction module, and (4) contrastive loss function module.It is based on SimCLRv2, a simple framework for contrastive learning of visual representations (see SimCLR in 6.2 Contrastive Self-Supervised CIL (CSS-CIL)).SimCLRv2 learns visual feature representations by maximizing the consistency between different views of the same sample (i.e., positive examples) and the distance between negative examples and anchor points.The anchor points, positive examples, and negative examples are created through data augmentation (flip, rotation, color distortion, etc.).The encoder is based on the ResNet50 encoder network.The deep convolutional encoder network can extract low-level, intermediate-level, and high-level features.The NT-Xent loss function is used to calculate the contrastive loss.</p>
<p>schemes to simulate CIL: random class scheme, semantic class scheme, and clustering scheme.SSCIL adopts SimCLR for CSSL support, and uses Linear Evaluation Protocol (LEP) and Generalization Evaluation Protocol (GEP) to evaluate the model's classification ability and robustness.</p>
<p>1 , D 2 , …, D t } trained thus far to fit a linear classifier M t (.) on top of the f t (.).The test accuracy LEP t = M t (f t (D t test )) indicates the model's ability to classify all known classes at the phase t, where D t test is the test set of the class-sets {D 1 , D 2 , …, D t }.The Generalization Evaluation Protocol (GEP), on the other hand, uses the full dataset D to fine-tune a linear classifier M t (.) on top of the f t (.).The test accuracy GEP t = M t (f t (D test ))</p>
<p>Acknowledgement: Thanks to my wife Hedy (郑期芳) for her support.previously learned concepts.This leads to a drastic drop in performance on previously learned concepts[14].As the number of incremental steps goes up, the performance degradation increases.Continual Contrastive Self-supervised Learning (CCSL)[14]is designed to alleviate the catastrophic forgetting problem in CSSL.First, it uses a rehearsal method which keeps a few exemplars from the previous data.Previous data are projected into feature embedding space and K-Mean algorithm is used to group the feature vectors by similarity.For each group, it stores the most consistent samples (i.e., exemplars) by measuring their feature vector variance.Second, instead of directly combining saved exemplars with the current dataset for training, it leverages self-supervised knowledge distillation to transfer contrastive information among previous data to the current network by mimicking similarity score distribution inferred by the old network over a set of saved exemplars.This strengthens the intra-contrast among previous data.Finally, note that when the network learns feature presentations of current data, the region of feature vectors of current data in embedding space may mix up with the region of feature vectors of previous data due to the lack of contrast between previous data and current data (called inter-contrast).Therefore, it builds an extra sample queue to assist the network to distinguish between previous and current data and prevent mutual interference while learning their own feature representations.CCSL adapts MoCo (Momentum Contrast)[14][15]as the base model.MoCo treats contrastive learning as dictionary look-up and builds a dynamic dictionary with a queue and a moving-average encoder.This enables building a large and consistent dictionary on-the-fly that facilitates CSSL.MoCo contains a query encoder f q (.), a key encoder f k (.), and a memory bank.An input x is first transformed to two views x q and x k .Then, x q and x k are fed into the encoders, f q and f k , respectively to get the query q and the positive key sample k + .The memory bank stores negative key samples {k 1 , k 2 , …, k n } of q.MoCo adopts a contrastive loss whose value is low when q is similar to the positive key k + and dissimilar to all negative keys k i .Furthermore, the query encoder parameters θ q are updated by back-propagation and the key encoder parameters θ k are updated by momentum strategy, respectively.Contrastive Self-Supervised Concept (Class) Incremental LearningFor concrete things (objects), 'concept' is usually referred to as 'class'; for abstract things (entities), 'concept' is commonly referred to as 'type'[2].Our discussion in the following focuses on concrete concepts.Therefore, we use the terms "concept" and "class" interchangeably.Class incremental learning (CIL)[16][17]is a special case of incremental (and continual) learning, where each incremental data consists of new class samples.Contrastive self-supervised CIL (CSS-CIL) provides an alternative approach
Deep learning for AI. Y Bengio, Y Lecun, G Hinton, G , Communications of the ACM. 6472021</p>
<p>Concept-Oriented Deep Learning. T Daniel, Chang, arXiv:1806.017562018arXiv preprint</p>
<p>Tiered Graph Autoencoders with PyTorch Geometric for Molecular Graphs. T Daniel, Chang, arXiv:1908.086122019arXiv preprint</p>
<p>Self-supervised Learning: Generative or Contrastive. X Liu, F Zhang, Z Hou, Z Wang, L Mian, J Zhang, J Tang, arXiv:2006.082182021arXiv preprint</p>
<p>A Survey on Contrastive Self-Supervised Learning. Ashish Jaiswal, Ramesh Ashwin, Mohammad Zaki Babu, Debapriya Zadeh, Fillia Banerjee, Makedon, Technologies. 20219</p>
<p>Self-Supervision for Learning from the Bottom Up. Alexei A Efros, ICLR 2021Invited Talk</p>
<p>Dual Coding of Knowledge in the Human Brain. Y Bi, Trends in Cognitive Sciences. 2510October 2021</p>
<p>Concepts, Control, and Context: A Connectionist Account of Normal and Disordered Semantic Cognition. P Hoffman, J L Mcclelland, M A Ralph, Psychological Review. 1252018</p>
<p>White Matter Basis for the Huband-spoke Semantic Representation: Evidence from Semantic Dementia. Y , Chen , L Huang, K Chen, J Ding, Y Zhang, Q Yang, Y Lv, Z Han, Q Guo, Brain. 14342020</p>
<p>A Visual Encoding Model Based on Contrastive Self-Supervised Learning for Human Brain Activity along the Ventral Visual Stream. Jingwei Li, Chi Zhang, Linyuan Wang, Penghui Ding, Lulu Hu, Bin Yan, Li Tong, Brain Sci. 1181004Aug. 2021</p>
<p>Neural Pattern Similarity Across Concept Exemplars Predicts Memory After A Long Delay. H Bruett, R C Calloway, N Tokowicz, M N Coutanche, NeuroImage. 2192020</p>
<p>Self-Supervised Relational Reasoning for Representation Learning. M Patacchiola, A Storkey, Advances in Neural Information Processing Systems. 202033</p>
<p>Rethinking Self-Supervised Learning: Small is Beautiful. Yun-Hao Cao, Jianxin Wu, arXiv:2103.135592021arXiv preprint</p>
<p>Continual Contrastive Self-supervised Learning for Image Classification. Zhiwei Lin, Yongtao Wang, Hongxiang Lin, arXiv:2107.017762021arXiv preprint</p>
<p>Momentum Contrast for Unsupervised Visual Representation Learning. K He, H Fan, Y Wu, S Xie, R Girshick, arXiv:1911.057222019arXiv preprint</p>
<p>Class-Incremental Learning: Survey and Performance Evaluation. M Masana, X Liu, B Twardowski, M Menta, A D Bagdanov, J Van De Weijer, CoRR. 2010.15277. 2020</p>
<p>Sudhanshu Mittal, Silvio Galesso, Thomas Brox, arXiv:1904.07734Essentials for Class Incremental Learning. 2021arXiv preprint</p>
<p>iCaRL: Incremental Classifier and Representation Learning. S.-A Rebuffi, A Kolesnikov, G Sperl, C H Lampert, 2017</p>
<p>Self-Supervised Class Incremental Learning. Zixuan Ni, Siliang Tang, Yueting Zhuang, arXiv:2111.112082021arXiv preprint</p>
<p>A Simple Framework for Contrastive Learning of Visual Representations. Ting Chen, Simon Kornblith, Mohammad Norouzi, Geoffrey Hinton, International Conference on Machine Learning. 2020119</p>            </div>
        </div>

    </div>
</body>
</html>