<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9590 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9590</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9590</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-166.html">extraction-schema-166</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using LLMs or related models to distill, extract, or discover quantitative laws, equations, or mathematical relationships from large collections of scholarly papers, including methods, results, challenges, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-a8fc2bef3eabe018fef37e7aa35a45df25b54670</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/a8fc2bef3eabe018fef37e7aa35a45df25b54670" target="_blank">Scientific hypothesis generation by large language models: laboratory validation in breast cancer treatment</a></p>
                <p><strong>Paper Venue:</strong> Journal of the Royal Society Interface</p>
                <p><strong>Paper TL;DR:</strong> The application of LLMs as a source of scientific hypotheses using the domain of breast cancer treatment is experimentally tested and it is concluded that LLMs are a valuable source of scientific hypotheses.</p>
                <p><strong>Paper Abstract:</strong> Large language models (LLMs) have transformed artificial intelligence (AI) and achieved breakthrough performance on a wide range of tasks. In science, the most interesting application of LLMs is for hypothesis formation. A feature of LLMs, which results from their probabilistic structure, is that the output text is not necessarily a valid inference from the training text. These are termed ‘hallucinations’, and are harmful in many applications. In science, some hallucinations may be useful: novel hypotheses whose validity may be tested by laboratory experiments. Here, we experimentally test the application of LLMs as a source of scientific hypotheses using the domain of breast cancer treatment. We applied the LLM GPT4 to hypothesize novel synergistic pairs of US Food and Drug Administration (FDA)-approved non-cancer drugs that target the MCF7 breast cancer cell line relative to the non-tumorigenic breast cell line MCF10A. In the first round of laboratory experiments, GPT4 succeeded in discovering three drug combinations (out of 12 tested) with synergy scores above the positive controls. GPT4 then generated new combinations based on its initial results, this generated three more combinations with positive synergy scores (out of four tested). We conclude that LLMs are a valuable source of scientific hypotheses.</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9590.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9590.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using LLMs or related models to distill, extract, or discover quantitative laws, equations, or mathematical relationships from large collections of scholarly papers, including methods, results, challenges, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative Pre-trained Transformer 4</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A general-purpose large language model used in this study to generate novel scientific hypotheses (drug combination hypotheses) via prompt engineering and iterative feedback from experimental results; the model was applied to propose combinations selective for MCF7 vs MCF10A cell lines.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Scientific Hypothesis Generation by Large Language Models: Laboratory Validation in Breast Cancer Treatment</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Described in the paper as a large LLM trained on a large fraction of internet text; the paper generically characterizes LLMs as deep neural networks mapping token strings to token strings and states they are trained on very large corpora (the paper notes 'very large numbers of both tokens (>10^4) and parameters (>10^12)'). No architecture or fine-tuning details beyond this are provided in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Biomedical research / experimental oncology (hypothesis generation for drug combinations in breast cancer cell lines)</td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>not_applicable</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Prompt engineering + iterative closed-loop workflow: authors provided engineered prompts requesting synergistic drug pairs (constraints included FDA-approved/non-cancer drugs, selectivity for MCF7 v MCF10A); after an initial experimental screen, GPT-4 was given summaries of results and prompted to generate follow-up hypotheses (human-in-the-loop prompting).</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Not a curated scholarly corpus — GPT-4 is described as pretrained on large general internet corpora (exact training set not specified). The study did not feed GPT-4 a corpus of scholarly papers to distill laws; prompts and examples used in the study are provided as supplementary materials.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Laboratory validation: automated wet-lab screening of hypothesized drug pairs on MCF7 and MCF10A cell lines; quantitative evaluation using SynergyFinder 3.0 to compute HSA (highest single agent) synergy scores, calculation of IC50 values, specificity (difference in HSA between cell lines), and statistical tests (ANOVA where applicable).</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>GPT-4 produced novel drug-pair hypotheses; in the first experimental round 3 of 12 GPT-4 hypotheses had HSA synergy scores above the positive controls. After providing GPT-4 with initial experimental results, it produced additional hypotheses; of 4 new combinations suggested, 3 had positive HSA synergy scores. Several combinations exhibited selective synergy for MCF7; individual-drug toxicities (IC50) and synergy metrics are reported.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_examples</strong></td>
                            <td>Notable successful hypotheses include: itraconazole + atenolol (HSA=4.83 MCF7), simvastatin + disulfiram (HSA=3.29 MCF7), dipyridamole + mebendazole (HSA=2.49 MCF7); follow-up successful pairs include disulfiram + simvastatin (HSA=4.75, max window 10.58) and disulfiram + fulvestrant (HSA=1.81).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Paper reports multiple limitations relevant to using LLMs for scientific knowledge extraction: hallucinations (factual errors in mechanistic explanations, e.g., incorrect claim about ergosterol synthesis in mammalian cells), epistemological uncertainty (unclear 'understanding' of prompts; negated explanations for controls), instruction-following failures (GPT-4 suggested only non-cancer drugs despite mixed prompt), forgetting/repetition across iterative prompts (recommending previously-tested combos), and variability across LLMs. The study did not use GPT-4 to extract quantitative laws from scholarly corpora.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Qualitative comparison to other LLMs (Gemini, PubMedGPT) was reported: outputs showed overlaps in core drug selections but variability in pair suggestions; no quantitative baseline metrics versus human experts or automated law-extraction methods were provided.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Scientific hypothesis generation by large language models: laboratory validation in breast cancer treatment', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9590.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9590.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using LLMs or related models to distill, extract, or discover quantitative laws, equations, or mathematical relationships from large collections of scholarly papers, including methods, results, challenges, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Gemini</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Gemini (LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Another large language model mentioned in the paper and compared qualitatively to GPT-4 and PubMedGPT for suggested drug selections; used only for output-comparison, not for lab-validated hypothesis generation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Scientific Hypothesis Generation by Large Language Models: Laboratory Validation in Breast Cancer Treatment</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Gemini</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Mentioned only briefly; the paper does not provide architecture, size, training data, or modification details for Gemini.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Biomedical suggestion generation (drug combination suggestion) — comparison context only</td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>not_applicable</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Used for comparative output generation alongside GPT-4 and PubMedGPT to assess overlap/divergence in drug suggestions; no iterative closed-loop experiments were reported for Gemini.</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Not specified in the paper for Gemini.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Qualitative comparison of suggested drugs and pairs; the paper notes similarities and notable differences but does not provide quantified metrics for Gemini's outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Paper reports that Gemini's suggestions had both overlaps and differences relative to GPT-4; pair suggestions showed greater variability than core drug selections. No lab validation of Gemini-generated hypotheses was performed.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_examples</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Paper notes variability between LLMs and non-uniform distributions of suggested drugs across models; specifics for Gemini are not provided. No claim that Gemini was used to distill quantitative laws from scholarly literature.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared qualitatively to GPT-4 and PubMedGPT in terms of overlap and variability of suggestions; no quantitative baselines provided.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Scientific hypothesis generation by large language models: laboratory validation in breast cancer treatment', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9590.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9590.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using LLMs or related models to distill, extract, or discover quantitative laws, equations, or mathematical relationships from large collections of scholarly papers, including methods, results, challenges, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PubMedGPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PubMedGPT (specialised biomedical LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A domain-specialized LLM trained on biomedical literature mentioned in the paper and compared qualitatively to GPT-4 and Gemini; suggested different drug pairs but with overlap in core drug selections.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Scientific Hypothesis Generation by Large Language Models: Laboratory Validation in Breast Cancer Treatment</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>PubMedGPT</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Described as a specialised LLM (trained on biomedical literature) in the discussion, but no architecture, size, or training details are provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Biomedical / PubMed literature domain (mentioned as specialized for biomedical text)</td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>not_applicable</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Used for qualitative comparison of suggestion outputs against GPT-4 and Gemini; the paper notes PubMedGPT recommended different drug pairs with strong overlap in core drug selections.</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Implied to be biomedical literature (PubMed) but not specified or used as an explicit input corpus within this study for law distillation.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Qualitative comparison only; no lab validation for PubMedGPT outputs in this study.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>PubMedGPT suggested different drug pairs but with overlap in core drug selections relative to GPT-4; authors remark this has advantages and drawbacks and suggest future analysis of pair frequency distributions per LLM.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_examples</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Paper notes model-to-model variability and that specialized LLMs can overlap on core items but differ on pairings; the study did not use PubMedGPT to extract or distill mathematical/quantitative laws from literature.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Qualitative comparison with GPT-4 and Gemini; no quantitative performance baselines provided.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Scientific hypothesis generation by large language models: laboratory validation in breast cancer treatment', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9590.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9590.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using LLMs or related models to distill, extract, or discover quantitative laws, equations, or mathematical relationships from large collections of scholarly papers, including methods, results, challenges, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Law_Distillation_Mentions</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mentions of using LLMs to distill quantitative laws from scholarly papers (query-specific negative finding)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>This paper does not report any use of LLMs (including GPT-4, Gemini, PubMedGPT) to distill, extract, or discover quantitative laws, equations, or explicit mathematical relationships from large collections of scholarly papers; the LLM application here is hypothesis generation for experimental validation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Scientific Hypothesis Generation by Large Language Models: Laboratory Validation in Breast Cancer Treatment</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>No methods, experiments, or results in this paper involve distilling quantitative laws or equations from scholarly corpora; instead the paper focuses on generating testable biological hypotheses (drug pairings) and validating them experimentally.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_examples</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>While the paper discusses general LLM limitations relevant to knowledge extraction (hallucination, epistemic uncertainty, instruction-following failures, variability across models), it provides no methodological detail or empirical results about extracting mathematical laws from literature.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Scientific hypothesis generation by large language models: laboratory validation in breast cancer treatment', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence <em>(Rating: 2)</em></li>
                <li>Advancing the Scientific Method with Large Language Models: From Hypothesis to Discovery <em>(Rating: 2)</em></li>
                <li>The automation of science <em>(Rating: 2)</em></li>
                <li>Science in the age of AI: How artificial intelligence is changing the nature and method of scientific research <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9590",
    "paper_id": "paper-a8fc2bef3eabe018fef37e7aa35a45df25b54670",
    "extraction_schema_id": "extraction-schema-166",
    "extracted_data": [
        {
            "name_short": "GPT-4",
            "name_full": "Generative Pre-trained Transformer 4",
            "brief_description": "A general-purpose large language model used in this study to generate novel scientific hypotheses (drug combination hypotheses) via prompt engineering and iterative feedback from experimental results; the model was applied to propose combinations selective for MCF7 vs MCF10A cell lines.",
            "citation_title": "Scientific Hypothesis Generation by Large Language Models: Laboratory Validation in Breast Cancer Treatment",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_description": "Described in the paper as a large LLM trained on a large fraction of internet text; the paper generically characterizes LLMs as deep neural networks mapping token strings to token strings and states they are trained on very large corpora (the paper notes 'very large numbers of both tokens (&gt;10^4) and parameters (&gt;10^12)'). No architecture or fine-tuning details beyond this are provided in the paper.",
            "scientific_domain": "Biomedical research / experimental oncology (hypothesis generation for drug combinations in breast cancer cell lines)",
            "law_type": "not_applicable",
            "method_description": "Prompt engineering + iterative closed-loop workflow: authors provided engineered prompts requesting synergistic drug pairs (constraints included FDA-approved/non-cancer drugs, selectivity for MCF7 v MCF10A); after an initial experimental screen, GPT-4 was given summaries of results and prompted to generate follow-up hypotheses (human-in-the-loop prompting).",
            "input_corpus_description": "Not a curated scholarly corpus — GPT-4 is described as pretrained on large general internet corpora (exact training set not specified). The study did not feed GPT-4 a corpus of scholarly papers to distill laws; prompts and examples used in the study are provided as supplementary materials.",
            "evaluation_method": "Laboratory validation: automated wet-lab screening of hypothesized drug pairs on MCF7 and MCF10A cell lines; quantitative evaluation using SynergyFinder 3.0 to compute HSA (highest single agent) synergy scores, calculation of IC50 values, specificity (difference in HSA between cell lines), and statistical tests (ANOVA where applicable).",
            "results_summary": "GPT-4 produced novel drug-pair hypotheses; in the first experimental round 3 of 12 GPT-4 hypotheses had HSA synergy scores above the positive controls. After providing GPT-4 with initial experimental results, it produced additional hypotheses; of 4 new combinations suggested, 3 had positive HSA synergy scores. Several combinations exhibited selective synergy for MCF7; individual-drug toxicities (IC50) and synergy metrics are reported.",
            "notable_examples": "Notable successful hypotheses include: itraconazole + atenolol (HSA=4.83 MCF7), simvastatin + disulfiram (HSA=3.29 MCF7), dipyridamole + mebendazole (HSA=2.49 MCF7); follow-up successful pairs include disulfiram + simvastatin (HSA=4.75, max window 10.58) and disulfiram + fulvestrant (HSA=1.81).",
            "limitations_challenges": "Paper reports multiple limitations relevant to using LLMs for scientific knowledge extraction: hallucinations (factual errors in mechanistic explanations, e.g., incorrect claim about ergosterol synthesis in mammalian cells), epistemological uncertainty (unclear 'understanding' of prompts; negated explanations for controls), instruction-following failures (GPT-4 suggested only non-cancer drugs despite mixed prompt), forgetting/repetition across iterative prompts (recommending previously-tested combos), and variability across LLMs. The study did not use GPT-4 to extract quantitative laws from scholarly corpora.",
            "baseline_comparison": "Qualitative comparison to other LLMs (Gemini, PubMedGPT) was reported: outputs showed overlaps in core drug selections but variability in pair suggestions; no quantitative baseline metrics versus human experts or automated law-extraction methods were provided.",
            "uuid": "e9590.0",
            "source_info": {
                "paper_title": "Scientific hypothesis generation by large language models: laboratory validation in breast cancer treatment",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "Gemini",
            "name_full": "Gemini (LLM)",
            "brief_description": "Another large language model mentioned in the paper and compared qualitatively to GPT-4 and PubMedGPT for suggested drug selections; used only for output-comparison, not for lab-validated hypothesis generation.",
            "citation_title": "Scientific Hypothesis Generation by Large Language Models: Laboratory Validation in Breast Cancer Treatment",
            "mention_or_use": "use",
            "model_name": "Gemini",
            "model_description": "Mentioned only briefly; the paper does not provide architecture, size, training data, or modification details for Gemini.",
            "scientific_domain": "Biomedical suggestion generation (drug combination suggestion) — comparison context only",
            "law_type": "not_applicable",
            "method_description": "Used for comparative output generation alongside GPT-4 and PubMedGPT to assess overlap/divergence in drug suggestions; no iterative closed-loop experiments were reported for Gemini.",
            "input_corpus_description": "Not specified in the paper for Gemini.",
            "evaluation_method": "Qualitative comparison of suggested drugs and pairs; the paper notes similarities and notable differences but does not provide quantified metrics for Gemini's outputs.",
            "results_summary": "Paper reports that Gemini's suggestions had both overlaps and differences relative to GPT-4; pair suggestions showed greater variability than core drug selections. No lab validation of Gemini-generated hypotheses was performed.",
            "notable_examples": null,
            "limitations_challenges": "Paper notes variability between LLMs and non-uniform distributions of suggested drugs across models; specifics for Gemini are not provided. No claim that Gemini was used to distill quantitative laws from scholarly literature.",
            "baseline_comparison": "Compared qualitatively to GPT-4 and PubMedGPT in terms of overlap and variability of suggestions; no quantitative baselines provided.",
            "uuid": "e9590.1",
            "source_info": {
                "paper_title": "Scientific hypothesis generation by large language models: laboratory validation in breast cancer treatment",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "PubMedGPT",
            "name_full": "PubMedGPT (specialised biomedical LLM)",
            "brief_description": "A domain-specialized LLM trained on biomedical literature mentioned in the paper and compared qualitatively to GPT-4 and Gemini; suggested different drug pairs but with overlap in core drug selections.",
            "citation_title": "Scientific Hypothesis Generation by Large Language Models: Laboratory Validation in Breast Cancer Treatment",
            "mention_or_use": "use",
            "model_name": "PubMedGPT",
            "model_description": "Described as a specialised LLM (trained on biomedical literature) in the discussion, but no architecture, size, or training details are provided in this paper.",
            "scientific_domain": "Biomedical / PubMed literature domain (mentioned as specialized for biomedical text)",
            "law_type": "not_applicable",
            "method_description": "Used for qualitative comparison of suggestion outputs against GPT-4 and Gemini; the paper notes PubMedGPT recommended different drug pairs with strong overlap in core drug selections.",
            "input_corpus_description": "Implied to be biomedical literature (PubMed) but not specified or used as an explicit input corpus within this study for law distillation.",
            "evaluation_method": "Qualitative comparison only; no lab validation for PubMedGPT outputs in this study.",
            "results_summary": "PubMedGPT suggested different drug pairs but with overlap in core drug selections relative to GPT-4; authors remark this has advantages and drawbacks and suggest future analysis of pair frequency distributions per LLM.",
            "notable_examples": null,
            "limitations_challenges": "Paper notes model-to-model variability and that specialized LLMs can overlap on core items but differ on pairings; the study did not use PubMedGPT to extract or distill mathematical/quantitative laws from literature.",
            "baseline_comparison": "Qualitative comparison with GPT-4 and Gemini; no quantitative performance baselines provided.",
            "uuid": "e9590.2",
            "source_info": {
                "paper_title": "Scientific hypothesis generation by large language models: laboratory validation in breast cancer treatment",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "Law_Distillation_Mentions",
            "name_full": "Mentions of using LLMs to distill quantitative laws from scholarly papers (query-specific negative finding)",
            "brief_description": "This paper does not report any use of LLMs (including GPT-4, Gemini, PubMedGPT) to distill, extract, or discover quantitative laws, equations, or explicit mathematical relationships from large collections of scholarly papers; the LLM application here is hypothesis generation for experimental validation.",
            "citation_title": "Scientific Hypothesis Generation by Large Language Models: Laboratory Validation in Breast Cancer Treatment",
            "mention_or_use": "mention",
            "model_name": null,
            "model_description": null,
            "scientific_domain": null,
            "law_type": null,
            "method_description": null,
            "input_corpus_description": null,
            "evaluation_method": null,
            "results_summary": "No methods, experiments, or results in this paper involve distilling quantitative laws or equations from scholarly corpora; instead the paper focuses on generating testable biological hypotheses (drug pairings) and validating them experimentally.",
            "notable_examples": null,
            "limitations_challenges": "While the paper discusses general LLM limitations relevant to knowledge extraction (hallucination, epistemic uncertainty, instruction-following failures, variability across models), it provides no methodological detail or empirical results about extracting mathematical laws from literature.",
            "baseline_comparison": null,
            "uuid": "e9590.3",
            "source_info": {
                "paper_title": "Scientific hypothesis generation by large language models: laboratory validation in breast cancer treatment",
                "publication_date_yy_mm": "2024-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence",
            "rating": 2,
            "sanitized_title": "the_future_of_fundamental_science_led_by_generative_closedloop_artificial_intelligence"
        },
        {
            "paper_title": "Advancing the Scientific Method with Large Language Models: From Hypothesis to Discovery",
            "rating": 2,
            "sanitized_title": "advancing_the_scientific_method_with_large_language_models_from_hypothesis_to_discovery"
        },
        {
            "paper_title": "The automation of science",
            "rating": 2,
            "sanitized_title": "the_automation_of_science"
        },
        {
            "paper_title": "Science in the age of AI: How artificial intelligence is changing the nature and method of scientific research",
            "rating": 1,
            "sanitized_title": "science_in_the_age_of_ai_how_artificial_intelligence_is_changing_the_nature_and_method_of_scientific_research"
        }
    ],
    "cost": 0.01132475,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Scientific Hypothesis Generation by Large Language Models: Laboratory Validation in Breast Cancer Treatment</h1>
<p>Abbi Abdel-Rehim ${ }^{1}$, Hector Zenil ${ }^{2,3}$, Oghenejokpeme Orhobor ${ }^{4}$, Marie Fisher ${ }^{5}$, Ross J. Collins ${ }^{5}$, Elizabeth Bourne ${ }^{5}$, Gareth W. Fearnley ${ }^{5}$, Emma Tate ${ }^{5}$, Holly X. Smith ${ }^{5}$, Larisa N. Soldatova ${ }^{6}$, Ross D. King<em>. ${ }^{1,7}$<br>${ }^{1}$ Department of Chemical Engineering and Biotechnology, University of Cambridge, CB3 0AS, U.K.<br>${ }^{2}$ Research Departments of Biomedical Computing and Digital Twins, School of Biomedical Engineering and Imaging Sciences, King's Institute for AI, King's College London, SE1 7EU, U.K.<br>${ }^{3}$ The Alan Turing Institute, British Library, London, NW1 2DB, U.K.<br>${ }^{4}$ The National Institute of Agricultural Botany, Cambridge, CB3 0LE, U.K.<br>${ }^{5}$ Arctoris Ltd, Oxford, OX14 4SA, UK.<br>${ }^{6}$ Department of Computing, Goldsmiths, University of London, SE14 6NW, U.K.<br>${ }^{7}$ Department of Computer Science and Engineering, Chalmers University, S-412 96 Göteborg, Sweden.<br></em>Ross King. Email: rk663@cam.ac.uk</p>
<h2>ABSTRACT</h2>
<p>Large language models (LLMs) have transformed AI and achieved breakthrough performance on a wide range of tasks. In science the most interesting application of LLMs is for hypothesis formation. A feature of LLMs, which results from their probabilistic structure, is that the output text is not necessarily a valid inference from the training text. These are termed "hallucinations" and are harmful in many applications. In science some hallucinations may be useful: novel hypotheses whose validity may be tested by laboratory experiments. Here, we experimentally test the application of LLMs as a source of scientific hypotheses using the domain of breast cancer treatment. We applied the LLM GPT4 to hypothesize novel synergistic pairs of FDA-approved non-cancer drugs that target the MCF7 breast cancer cell line relative to the non-tumorigenic breast cell line MCF10A. In the first round of laboratory experiments GPT4 succeeded in discovering three drug combinations (out of twelve tested) with synergy scores above the positive controls. GPT4 then generated new combinations based on its initial results, this generated three more combinations with positive synergy scores (out of four tested). We conclude that LLMs are a valuable source of scientific hypotheses.</p>
<h2>Keywords</h2>
<p>Machine learning, precision healthcare, predictive medicine, AI for science, drug discovery, closedloop AI-driven science</p>
<h1>INTRODUCTION</h1>
<p>The world has been stunned by the success of Large Language Models (LLMs). They have achieved breakthrough performance on a wide range of conversation-based tasks that previously required human intelligence. The overall architecture of LLMs is remarkably simple: they map input token strings to output token strings using deep neural networks (DNNs). Their power comes from being trained on very large general corpuses (substantial percentages of the whole text-based internet), and the use of very large numbers of both tokens ( $&gt;10^{\wedge} 4$ ) and parameters ( $&gt;10^{\wedge} 12$ ). The success of LLMs is surprising given that they don't use any explicit model of the world, nor explicit internal symbols, nor do they have any physical grounding in the world. All of these were assumed by most AI scientists to be essential for such intelligent behaviour.</p>
<p>LLMs can be applied to many aspects of science: to summarize texts (1, 2), to analyze data (3), to write papers and code (4), to formalize knowledge (5), to answer questions (6), etc. However, the most exciting application for LLMs in science is for generating novel hypotheses. Despite the clear potential of LLMs for hypothesis generation their utility for hypothesis generation has been little investigated.</p>
<p>The architecture of LLMs entails that the output string is the most likely one given the input string and the training data. For science these strings may be interpreted as scientific hypotheses. Due to their internal complexity and sophistication LLMs have the potential to go beyond existing text-based scientific hypothesis generation tools $(7,8,9)$. The generation of hypotheses by LLMs is closely related to the phenomena of "hallucinations". These are LLM outputs that are not valid inferences from the training data. Some hallucinations may be simply factually wrong. For others, their validity is uncertain. Hallucinations are a serious problem in many applications (9). For example, in science it is not acceptable to hallucinate (make up) false references. However, in scientific hypothesis generation hallucinations may be useful: probable novel hypotheses whose validity may be objectively tested by laboratory experiments (10).</p>
<p>Here we use laboratory experiments to test the utility of the general purpose LLM GPT4 for scientific hypothesis generation (Fig. 1). We employed breast cancer as the test domain. In our experiments breast cancer cells were exemplified by MCF7 (an epithelial breast cancer cell line); non-tumorigenic breast cells were exemplified by the epithelial cell line MCF10A. We provided GPT4 with a prompt that had several aims: 1) Identify novel drug combinations that would have a significant impact on MCF7 cell lines; 2) Avoid harming MCF10A the control cell line; and 3) Design combinations that were possibly synergistic. We also had additional requirements related to the drugs themselves: at least one of the drugs in every pair should not be an anti-neoplastic drug, and that the drugs should be affordable, accessible, and preferably FDA-approved. Prompts and the list of complete hypotheses are found in supplementary materials (Fig. S1-S3, Table S1). Interestingly, all the drug combinations hypothesized were exclusively non-cancer drugs (suggesting a possible limitation in GPT4 understanding of its instructions). The combinations were however novel, and we could not find any of them reported for breast cancer in the literature. We did find that several of the drugs had been investigated in the cancer literature, and that several of the drugs had been tested against MCF7 (Supplementary materials Appendix).</p>
<p>In addition to hypothesizing drug combination, we prompted GPT4 to provide two positive controls that are commonly used against breast cancer in clinic and likely have an impact on MCF7; as well as two negative control combinations that would be unlikely to cause harm to MCF7 (Fig. S2, S3). It may have been wiser to select the controls ourselves. But we judged that GPT4 did a fair job in its selections (Table 1b).</p>
<h1>RESULTS</h1>
<p>Using the method described below we screened the twelve pairs of compounds proposed by GPT4 (Table 1a). We investigated two properties of the pairs: 1) The specificity of the combination for MCF7 v MCF10A, and 2) The additivity/synergy of the combination. (Additivity occurs when the combination of the effects of two drugs is not less than either of the two drugs acting independently. Synergy describes the situation when the effect of the combination is greater than that of the most effective drug (highest single agent)). To determine drug additivities/synergies we employed SynergyFinder 3.0 to calculate HSA (highest single agent) synergy scores for all combinations (Table 2). There were six additive interactions combinations with positive synergy scores for MCF7: itraconazole + atenolol, simvastatin + disulfiram, dipyridamole + mebendazole, furosemide + mebendazole, disulfiram + hydroxychloroquine, and the positive control doxorubicin + cyclophosphamide. The initial three hypothesised combinations resulted in HSA scores surpassing those of the positive controls. Synergistic areas were found within the drug response matrices belonging to ten out of twelve of the hypothesized drug combinations (Table S2). We found that eight out of the twelve hypothesised combinations resulted in a higher HSA score in varying degrees for MCF7 compared to MCF10A (Table 2, cf. Table 2 and Table S3). In Table S12 we summarize the literature on the hypotheses proposed by GPT4 and the anti-cancer properties of the drugs selected. We found underlying support in literature for three out of the latter screened six combinations with positive synergy scores, while the remaining three remain unclear.</p>
<p>To better understand the utility of the paired compounds we tested the individual drugs (Table 3). From the drugs in the positive controls pairs only doxorubicin was found to result in an IC50 value below the maximum dose of 25 uM in both cell lines. For MCF7 there were five additional drugs that resulted in IC50 values below the same threshold, with Disulfiram and Niclosamide showing comparatively high toxicity (Table 3). Several more drugs were toxic to the cell lines, but failed to reduce the viability to such an extent where an IC50 value could be derived (Table S4 and S5). In total, twelve out of the eighteen non-control drugs showed toxicity towards MCF7: celecoxib, chloroquine, dipyridamole, disulfiram, hydroxychloroquine, itraconalzole, mebendazole, niclosamide, quinacrine, sildenafil and simvastatin. Out of these drugs, dipyridamole, disulfiram, mebendazole and quinacrine showed high specificity towards MCF7 (cf. Table S4 and S5). While many of these drugs had been studied in cancer cell lines, they are not cancer drugs. Fulvestrant, a positive control cancer drug also showed preference for MCF7.</p>
<p>Eleven out of eighteen compounds reduced viability of the control cell line MCF10A. When excluding the highest concentration of 25 uM , these numbers change to $6 / 18$ and $8 / 18$ compounds for MCF7 and MCF10A respectively. The ten drugs that showed highest toxicity towards MCF7 were re-screened to achieve sufficient replicates $(\mathrm{n}=3)$ in order to validate their toxicity.</p>
<p>In an additional experiment, twelve drugs were retested from the first round ( $\mathrm{n}&gt;=3$ replicates). An ANOVA two-way test with three replicates was used to calculate significance of changes to viability compared to the internal control drug Allopurinol for both cell lines (S6, S7). Two of the retested drugs were initially used as positive controls for MCF7 (doxorubicin and fulvestrant). Out of twelve retested drugs, dipyridamole, disulfiram, niclosamide and quinacrine significantly reduced the viability of MCF7 when considering concentrations up to $3.84 \mu \mathrm{M}$. The two positive control drugs doxorubicin and fulvestrant also targeted MCF7. When considering all concentrations (including $25 \mu \mathrm{M}$ which is quite high), all but hydroxychloroquine results in a significant impact on MCF7. Despite this, the toxicity of hydroxychloroquine at 25 uM is persistent and substantial. IC50 values could only be calculated for</p>
<p>5/11 compounds (Table S8), disulfiram and doxorubicin showing sub micromolar IC50 values of 0.059 and $0.3 \mu \mathrm{M}$ respectively. This was followed by niclosamide at $1.22 \mu \mathrm{M}$, quinacrine at $4.71 \mu \mathrm{M}$ and chloroquine at $10.62 \mu \mathrm{M}$. However, the remaining compounds were still toxic to MCF7 (Table S9). Calculated IC50, and viability values for MCF10A can be found in Tables S8 and S10.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">Drug1</th>
<th style="text-align: center;">Drug2</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">Doxorubicin</td>
<td style="text-align: center;">Cyclophosphamide</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Positive Control. <br> Combination FDA approved to treat Breast Cancer <br> Doxorubicin is an anthracycline that intercalates into DNA and inhibits topoisomerase II, causing DNA damage. Cyclophosphamide is an alkylating agent that causes DNA damage. <br> "The combination targets DNA integrity through multiple mechanisms, which may be effective in MCF7 cells with high proliferative capacity."</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: center;">Fulvestrant</td>
<td style="text-align: center;">Palbociclib</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Positive Control. <br> Individually FDA approved to treat Breast Cancer <br> Fulvestrant is a selective estrogen receptor degrader (SERD) that blocks and degrades estrogen receptors. Palbociclib is a CDK4/6 inhibitor that blocks cell cycle progression. <br> "The combination targets both estrogen signaling and cell cycle progression, which may be effective in estrogen receptor-positive MCF7 cells."</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">3</td>
<td style="text-align: center;">Allopurinol <br> (Xanthine Oxidase Inhibitor)</td>
<td style="text-align: center;">Omeprazole <br> (Proton Pump Inhibitor)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Negative Control <br> "Allopurinol is used to treat gout and hyperuricemia, and omeprazole is used to reduce stomach acid. Neither drug targets pathways relevant to MCF7 breast cancer cell growth or survival, and they are not expected to have an effect on MCF7 cells."</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">4</td>
<td style="text-align: center;">Diphenhydramine (Antihistamine)</td>
<td style="text-align: center;">Omeprazole (Proton Pump Inhibitor)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Negative Control <br> "Diphenhydramine and cetirizine are antihistamines used to treat allergy symptoms. Neither drug targets pathways relevant to MCF7 breast cancer cell growth or survival, and they are not expected to have an effect on MCF7 cells."</td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>Table 1b. GPT4 generated positive and negative control combinations.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Drug 1</th>
<th style="text-align: center;">Drug 2</th>
<th style="text-align: center;">HSA score (MCF7)</th>
<th style="text-align: center;">Specificity (MCF7)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Itraconazole</td>
<td style="text-align: center;">Atenolol</td>
<td style="text-align: center;">4.83</td>
<td style="text-align: center;">7.03</td>
</tr>
<tr>
<td style="text-align: center;">Simvastatin</td>
<td style="text-align: center;">Disulfiram</td>
<td style="text-align: center;">3.29</td>
<td style="text-align: center;">1.85</td>
</tr>
<tr>
<td style="text-align: center;">Dipyridamole</td>
<td style="text-align: center;">Mebendazole</td>
<td style="text-align: center;">2.49</td>
<td style="text-align: center;">3.69</td>
</tr>
<tr>
<td style="text-align: center;">Doxorubicin*</td>
<td style="text-align: center;">Cyclophoshamide*</td>
<td style="text-align: center;">1.02</td>
<td style="text-align: center;">3.27</td>
</tr>
<tr>
<td style="text-align: center;">Furosemide</td>
<td style="text-align: center;">Mebendazole</td>
<td style="text-align: center;">0.72</td>
<td style="text-align: center;">6.14</td>
</tr>
<tr>
<td style="text-align: center;">Disulfiram</td>
<td style="text-align: center;">Hydroxychloroquine</td>
<td style="text-align: center;">0.60</td>
<td style="text-align: center;">3.51</td>
</tr>
<tr>
<td style="text-align: center;">Acarbose</td>
<td style="text-align: center;">Itraconazole</td>
<td style="text-align: center;">$-1.36$</td>
<td style="text-align: center;">$-1.33$</td>
</tr>
<tr>
<td style="text-align: center;">Disulfiram</td>
<td style="text-align: center;">Sildenafil</td>
<td style="text-align: center;">$-1.63$</td>
<td style="text-align: center;">0.85</td>
</tr>
<tr>
<td style="text-align: center;">Allopurinol</td>
<td style="text-align: center;">Chloroquine</td>
<td style="text-align: center;">$-1.87$</td>
<td style="text-align: center;">2.24</td>
</tr>
<tr>
<td style="text-align: center;">Celecoxib</td>
<td style="text-align: center;">Quinacrine</td>
<td style="text-align: center;">$-2.21$</td>
<td style="text-align: center;">$-3.27$</td>
</tr>
<tr>
<td style="text-align: center;">Fulvestrant*</td>
<td style="text-align: center;">Palbociclib*</td>
<td style="text-align: center;">$-2.59$</td>
<td style="text-align: center;">$-0.49$</td>
</tr>
<tr>
<td style="text-align: center;">Memantine</td>
<td style="text-align: center;">Niclosamide</td>
<td style="text-align: center;">$-2.61$</td>
<td style="text-align: center;">$-2.23$</td>
</tr>
<tr>
<td style="text-align: center;">Disulfiram</td>
<td style="text-align: center;">Cimetidine</td>
<td style="text-align: center;">$-3.06$</td>
<td style="text-align: center;">$-8.17$</td>
</tr>
<tr>
<td style="text-align: center;">Allopurinol**</td>
<td style="text-align: center;">Omeprazole**</td>
<td style="text-align: center;">$-3.85$</td>
<td style="text-align: center;">$-6.2$</td>
</tr>
<tr>
<td style="text-align: center;">Atrovastatin</td>
<td style="text-align: center;">Metronidazole</td>
<td style="text-align: center;">$-4.84$</td>
<td style="text-align: center;">$-6.3$</td>
</tr>
<tr>
<td style="text-align: center;">Diphenhydramine**</td>
<td style="text-align: center;">Cetirizine**</td>
<td style="text-align: center;">$-9.25$</td>
<td style="text-align: center;">$-6.28$</td>
</tr>
</tbody>
</table>
<p>Table 2. HSA synergy score for each combination. "Specificity" indicates synergy score differences between the cell lines (HSA $<em _MCF10A="{MCF10A" _text="\text">{\text {MCF7 }}-$ HSA $</em>$ ). }<em>Positive controls, </em>*negative controls. Combinations selected for further validation are marked in bold. The combinations in blue have positive synergy scores .</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Drug</th>
<th style="text-align: center;">MCF7 IC50 <br> (uM)</th>
<th style="text-align: center;">MCF7 p-val</th>
<th style="text-align: center;">MCF10A IC50 <br> (uM)</th>
<th style="text-align: center;">MCF10A p-val</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Allopurinol**</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">---------</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">---------</td>
</tr>
<tr>
<td style="text-align: center;">Atenolol</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">$\mathbf{0 . 0 0 3}$</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">0.118</td>
</tr>
<tr>
<td style="text-align: center;">Celecoxib</td>
<td style="text-align: center;">5.325</td>
<td style="text-align: center;">$\mathbf{0 . 0 4 6}$</td>
<td style="text-align: center;">22.573</td>
<td style="text-align: center;">0.185</td>
</tr>
<tr>
<td style="text-align: center;">Disulfiram</td>
<td style="text-align: center;">0.204</td>
<td style="text-align: center;">$\mathbf{0 . 0 0 8}$</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">0.095</td>
</tr>
<tr>
<td style="text-align: center;">Fulvestrant*</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">$\mathbf{0 . 0 2 0}$</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">0.430</td>
</tr>
<tr>
<td style="text-align: center;">Itraconazole</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">$\mathbf{0 . 0 2 1}$</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">0.077</td>
</tr>
<tr>
<td style="text-align: center;">Sildenafil</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">$\mathbf{0 . 0 1 1}$</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">0.212</td>
</tr>
<tr>
<td style="text-align: center;">Cimetidine</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">$\mathbf{0 . 0 1 2}$</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">$\mathbf{0 . 0 2 3}$</td>
</tr>
<tr>
<td style="text-align: center;">Mebendazole</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">$\mathbf{0 . 0 2 5}$</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">$\mathbf{0 . 0 1 8}$</td>
</tr>
<tr>
<td style="text-align: center;">Metronidazole</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">$\mathbf{0 . 0 3 9}$</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">$\mathbf{0 . 0 3 1}$</td>
</tr>
<tr>
<td style="text-align: center;">Atorvastatin</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">0.131</td>
<td style="text-align: center;">3.795</td>
<td style="text-align: center;">$\mathbf{0 . 0 0 9}$</td>
</tr>
<tr>
<td style="text-align: center;">Chloroquine</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">0.202</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">$\mathbf{0 . 0 3 0}$</td>
</tr>
<tr>
<td style="text-align: center;">Doxorubicin*</td>
<td style="text-align: center;">0.303</td>
<td style="text-align: center;">0.054</td>
<td style="text-align: center;">0.435</td>
<td style="text-align: center;">$\mathbf{0 . 0 3 4}$</td>
</tr>
<tr>
<td style="text-align: center;">Memantine</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">0.834</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">$\mathbf{0 . 0 2 2}$</td>
</tr>
<tr>
<td style="text-align: center;">Niclosamide</td>
<td style="text-align: center;">0.699</td>
<td style="text-align: center;">0.066</td>
<td style="text-align: center;">0.061</td>
<td style="text-align: center;">$\mathbf{0 . 0 2 1}$</td>
</tr>
<tr>
<td style="text-align: center;">Acarbose</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">0.251</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">$\mathbf{0 . 0 1 9}$</td>
</tr>
<tr>
<td style="text-align: center;">Cetirizine**</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">0.210</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">0.257</td>
</tr>
<tr>
<td style="text-align: center;">Cyclophosphamide*</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">0.276</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">0.499</td>
</tr>
<tr>
<td style="text-align: center;">Diphenhydramine**</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">0.684</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">0.500</td>
</tr>
<tr>
<td style="text-align: center;">Dipyridamole</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">0.056</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">0.093</td>
</tr>
<tr>
<td style="text-align: center;">Furosemide</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">0.246</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">0.188</td>
</tr>
<tr>
<td style="text-align: center;">Hydroxychloroquine</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">0.118</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">0.944</td>
</tr>
<tr>
<td style="text-align: center;">Omeprazole**</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">0.082</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">0.245</td>
</tr>
<tr>
<td style="text-align: center;">Palbociclib*</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">0.414</td>
<td style="text-align: center;">$&gt;25$</td>
<td style="text-align: center;">0.650</td>
</tr>
<tr>
<td style="text-align: center;">Quinacrine</td>
<td style="text-align: center;">3.848</td>
<td style="text-align: center;">0.082</td>
<td style="text-align: center;">10.183</td>
<td style="text-align: center;">0.116</td>
</tr>
<tr>
<td style="text-align: center;">Simvastatin</td>
<td style="text-align: center;">5.634</td>
<td style="text-align: center;">0.106</td>
<td style="text-align: center;">7.17</td>
<td style="text-align: center;">0.120</td>
</tr>
</tbody>
</table>
<p>Table 3. Single drug treatments. For either cell line, the IC50 values were calculated and declared ( $n=1$ ). Significance ( $p$-value) of changes evoked by drug treatments when compared to positive control (Allopurinol) are also reported. ANOVA two-way significance is used for the samples, most of which are single replicates. P -values are declared for both cell lines. *=Positive controls, ** = negative controls. Numbers in bold significant $&lt;0.05$. Blue significant against MCF7. Red significant against MCF10A. Green significant against MCF7 and MCF10A</p>
<p>After the results from the first round of experiments were complete we investigated whether GPT4 could improve its hypotheses through use on the results from its initial hypotheses. We provided GPT4 with a summary of the results from the primary screen (Fig. S4), and prompted GPT4 to consider combinations containing drugs from the positive controls as well. GPT4 hypothesized four combinations based on this information: disulfiram + fulvestrant, disulfiram + mebendazole, mebendazole + quinacrine, and disulfiram + quinacrine (Table 4). In addition we re-tested three combinations that resulted in positive synergy scores from the primary screening achieving more</p>
<p>robust results, these combinations were disulfiram + simvastatin, disulfiram + hydroxychloroquine, and dipyridamole + mebendazole. Out of the seven combinations screened in the second iteration, six combinations showed varying degrees of synergy within the response matrices (Table 5). Of the newly hypothesized pairs we found three pairs with positive synergy scores: mebendazole + quinacrine, disulfiram + fulvestrant, and disulfiram + quinacrine. The remaining three re-tested combinations also showed consistent positive scores. The three combinations with the highest HSA scores also showed specificity (&gt;1 HSA score) towards MCF7. It is worth mentioning that the most synergistic $3 \times 3$ dose response window resulted in one of the combinations (disulfiram + simvastatin) having a synergy score $&gt;10$. Plots showing HSA synergy graphs for MCF7 and MCF10A derived from Synergyfinder 3.0 can be found in Supplementary Materials Appendix C1 and C2. HSA scores for MCF10A can be found in Table S11. When comparing the most synergistic dose-response windows across both cell lines, there were three combinations that showed substantially higher synergy against MCF7: Quinacrine + mebendazole ( $\Delta \mathrm{HSA}=2.73$ ), mebendazole+dipyridamole ( $\Delta \mathrm{HSA}=3.99$ ) and simvastatin+disulfiram (4.01) (Appendix D). In addition, the two latter combinations also showed areas of selective toxicity towards the MCF7 cell line.</p>
<table>
<thead>
<tr>
<th>Drug 1</th>
<th>Drug 2</th>
<th>HSA score</th>
<th>HSA score (max)</th>
<th>Specificity</th>
</tr>
</thead>
<tbody>
<tr>
<td>Disulfiram</td>
<td>Simvastatin</td>
<td>4.75</td>
<td>10.58</td>
<td>2.41</td>
</tr>
<tr>
<td>Disulfiram</td>
<td>Fulvestrant</td>
<td>1.81</td>
<td>4.60</td>
<td>0.03</td>
</tr>
<tr>
<td>Disulfiram</td>
<td>Quinacrine</td>
<td>1.53</td>
<td>4.47</td>
<td>0.6</td>
</tr>
<tr>
<td>Dipyridamole</td>
<td>Mebendazole</td>
<td>1.10</td>
<td>5.26</td>
<td>3.60</td>
</tr>
<tr>
<td>Disulfiram</td>
<td>Hydroxychloroquine</td>
<td>1.08</td>
<td>3.06</td>
<td>-1.86</td>
</tr>
<tr>
<td>Mebendazole</td>
<td>Quinacrine</td>
<td>0.56</td>
<td>5.54</td>
<td>1.09</td>
</tr>
<tr>
<td>Disulfiram</td>
<td>Mebendazole</td>
<td>-2.49</td>
<td>0.13</td>
<td>-1.83</td>
</tr>
</tbody>
</table>
<p>Table 5. Calculated HSA synergy scores for each combination. Two HSA scores are provided, the first considers the entire dose-response matrix, while the second (max) is based on the most synergistic 3-by-3 dose-window in the dose-response matrix. Specificity denotes the difference in the overall HSA synergy score between the two cell lines ( $\mathrm{HSA}<em _MCF10A="{MCF10A" _text="\text">{\text {MCF7 }}-\mathrm{HSA}</em>$ ) where positive values indicate higher synergy scores for MCF7.}</p>
<p>A final query was made to GPT4 requesting future experiments based on the final results. Three drug combinations were recommended: disulfiram + itraconazole, mebendazole + cimetidine, and quinacrine + celecoxib. Hypotheses for these combinations are reported in Table S13. Disulfiram + itraconazole were hypothesized to synergise based on increased oxidative stress and the inhibition of the hedgehog pathway. Mebendazole and cimetidine were also hypothesized to synergise due to their targets being involved in cell cycle progression and growth. The final combination quinacrine + celecoxib had been tested in the initial experiment, suggesting that GPT4 had already "forgotten" its previous recommendations.</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1. The overall structure of our experiments. GPT4 was previously trained on data on a large fraction of the text on the internet. We engineered prompts to request from GPT4 synergistic pairs of drugs that are toxic to the breast cancer cell line MCF7, but not to the non-cancer breast cell line MCF10a. These are the hypotheses that we experimentally tested using laboratory automation.</p>
<h1>DISCUSSION</h1>
<p>It is unclear to what extent GPT4 "understood" its prompt for hypothesis formation. This epistemological uncertainty is show in the relationship between the explanation of why a pair of drugs would target MCF7 rather than MCF10A (Table S1), and the explanation why MCF10A would not be targeted, where the MCF10A hypotheses are simply negations of the MCF7 ones. More convincing explanations for not targeting MCF10A would have provided us with more confidence in GPT4's understanding, and the utility of its hypotheses. The hypotheses also exhibited "hallucinations" in their explanations. This is most clearly illustrated by GPT4's hypothesis that itraconazole would "disrupt(ing) cell membrane integrity". This explanation presumably originated from the fact that itraconazole inhibits ergosterol synthesis, which disrupts cell membrane integrity. The factual error is that ergosterol synthesis is not present in mammalian cells. We asked GPT4 "is ergosterol synthesis present in mammalian cells". It replied "No, ergosterol synthesis is not present in mammalian cells. Ergosterol is a sterol found in the cell membranes of fungi and some protozoa, playing a role similar to cholesterol in mammalian cells..."</p>
<p>This study focused on GPT-4, but there are several other LLMs available. We compared the outputs from GPT-4, Gemini, and the specialised LLM PubMedGPT. The results revealed both similarities and notable differences in the selected drugs and their subsequent combinations (Appendix D). It was evident that LLMs generated non-uniform distributions in their drug suggestions, with certain drugs being consistently selected across models, while pairs exhibit greater variability. Despite this diversity, the suggestions remain consistent in their underlying choices. The specialised LLM PubMedGPT recommended different drug pairs but with a strong overlap in core drug selections-an aspect that has both advantages and drawbacks. In future studies, it may be useful to analyse pair frequency distributions per LLM.</p>
<p>We selected cancer treatment as our test domain because every cancer patient ideally requires a scientific research project to understand how best to treat them. In the past this was prohibitively expensive and out of reach for normal cancer patients. The cost of science currently has two main components: the cost of the human scientist's intelligence, and the laboratory costs. Now, thanks to the Al revolution, the cost of (machine) scientific intelligence is dropping. Economies of scale could also drive down the cost of the robotics required to automate personalized cancer research. We therefore envision a future where scientific research is cheap enough that every cancer patient can afford treatment based on a personalized research project.</p>
<p>Our empirical results demonstrate that the GPT4 succeeded in its primary task of forming novel and useful hypothesis. We therefore conclude that LLMs are an important source of novel scientific hypotheses for both human scientists and to the increasingly sophisticated Al systems designed to automate science (11).</p>
<h1>References</h1>
<ol>
<li>Van Veen, D., Van Uden, C., Blankemeier, L., Delbrouk, J-B., Aali, A. et al. Adapted large language models can outperform medical experts in clinical text summarization. Nat Med 30, 1134-1142 (2024).</li>
<li>Liu, P.J., Saleh, M., Pot, E., Goodrich, B., Sepassi, R., Kaiser, L. \&amp; Shazeer, N. Generating Wikipedia by summarizing long sequences. arXiv preprint arXiv:1801.10198 (2018).</li>
<li>Devlin J., Chang, M-W., Lee, K. \&amp; Toutanova, K. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. ArXiv Computation and Language. arXiv:1810.04805 [cs.CL] (2018).</li>
<li>Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. et al. Evaluating large language models trained on code, arXiv:2107.03374 [cs.LG] (2021).</li>
<li>Zhang, B., Reklos, I., Jain, N., Peñuela, A.M. \&amp; Simperl, E., Using Large Language Models for Knowledge Engineering (LLMKE): A Case Study on Wikidata. arXiv preprint arXiv:2309.08491 (2023).</li>
<li>Radford, A., Wu, J., Child, R., Luan, D., Amodei, D. \&amp; Sutskever, I., et al. Language models are unsupervised multitask learners. Technical Report, OpenAI blog, 1 (8): 9 (2019).</li>
<li>Sourati, J. \&amp; Evans, J.A. Accelerating science with human-aware artificial intelligence. Nat Hum Behav 7, 1682-1696 (2023).</li>
<li>Zenil, H., Tegner, J., Abrahao., F.S., Lavin, A., Kumar, V. et al. The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence, arXiv:2307.07522v3 [cs.AI] (2023).</li>
<li>Y. Zhang, i.a. M. Levin, J. Frey, J. Evans, A. Bundy and H. Zenil, Advancing the Scientific Method with Large Language Models: From Hypothesis to Discovery, npj Artificial Intelligence (in press).</li>
<li>Royal Society. Science in the age of AI: How artificial intelligence is changing the nature and method of scientific research. 978-1-78252-712-1 (2024).</li>
<li>Popper, K. The Logic of Scientific Discovery (Hutchinson, London, 1972).</li>
<li>King, R. D., Rowland, J., Oliver, S. G., Young, M., Aubrey, W. et. al. The automation of science. Science (New York, N.Y.), 324(5923), 85-89 (2009).</li>
</ol>
<h1>Acknowledgements</h1>
<p>Funding: This work has been supported by the UK Engineering and Physical Sciences Research Council (EPSRC) [EP/R022925/2, EP/W004801/1 and EP/X032418/1], and by the Wallenberg AI, Autonomous Systems and Software Program (WASP) funded by the Alice Wallenberg Foundation.</p>
<h2>Data availability</h2>
<p>All experimental data are available in the main text or within the supplementary information.</p>
<h1>Appendix</h1>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">Drug1</th>
<th style="text-align: center;">Drug2</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">Disulfiram (Alcoholism)</td>
<td style="text-align: center;">Simvastatin (Hypercholesterolemia)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">"Disruption of lipid rafts by simvastatin may enhance disulfiram-induced oxidative stress, leading to apoptosis in MCF7 cells."</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: center;">Celecoxib (Pain/Inflammation)</td>
<td style="text-align: center;">Quinacrine (Malaria/Anti-inflammatory)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">"Reduced inflammatory signaling by celecoxib may enhance quinacrine-induced impairment of autophagy, leading to apoptosis in MCF7 cells."</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">3</td>
<td style="text-align: center;">Acarbose (Diabetes)</td>
<td style="text-align: center;">Itraconazole (Fungal Infections)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">"Acarbose-induced glucose deprivation may enhance the effect of itraconazole on disrupting cell membrane integrity, leading to apoptosis in MCF7 cells."</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">4</td>
<td style="text-align: center;">Dipyridamole (Blood Thinner)</td>
<td style="text-align: center;">Mebendazole (Parasitic Infections)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">"Dipyridamole-induced increase in cAMP levels may enhance the effect of mebendazole on cell cycle arrest, leading to apoptosis in MCF7 cells."</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">5</td>
<td style="text-align: center;">Atorvastatin <br> (Hypercholesterolemia)</td>
<td style="text-align: center;">Metronidazole (Bacterial Infections)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">"Atorvastatin-induced disruption of lipid rafts may enhance the effect of metronidazole-induced DNA damage, leading to apoptosis in MCF7 cells."</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">6</td>
<td style="text-align: center;">Allopurinol (Gout)</td>
<td style="text-align: center;">Chloroquine (Malaria)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">"Allopurinol-induced reduction of uric acid may enhance the effect of chloroquine-induced impairment of autophagy, leading to apoptosis in MCF7."</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">7</td>
<td style="text-align: center;">Cimetidine (Gastric Acid <br> Reducer)</td>
<td style="text-align: center;">Disulfiram (Alcoholism)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">"Cimetidine-induced reduction of gastric acid may enhance the effect of disulfiram-induced oxidative stress and DNA damage in MCF7 cells."</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">8</td>
<td style="text-align: center;">Memantine (Alzheimer's)</td>
<td style="text-align: center;">Niclosamide (Parasitic Infections)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">"Memantine-induced reduction of glutamate excitotoxicity may enhance the effect of niclosamide-induced energy depletion, leading to cell death in MCF7 cells."</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">9</td>
<td style="text-align: center;">Furosemide (Diuretic)</td>
<td style="text-align: center;">Mebendazole (Parasitic Infections)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">"Furosemide-induced reduction of sodium reabsorption may enhance the effect of mebendazole on cell cycle arrest, leading to apoptosis in MCF7 cells."</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">10</td>
<td style="text-align: center;">Sildenafil (Erectile Dysfunction)</td>
<td style="text-align: center;">Disulfiram (Alcoholism)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">"Sildenafil-induced increase in cGMP levels may enhance the effect of disulfiraminduced oxidative stress and DNA damage in MCF7 cells."</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">11</td>
<td style="text-align: center;">Itraconazole (Fungal Infections)</td>
<td style="text-align: center;">Atenolol (Hypertension)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">"Atenolol-induced reduction of stress signaling may enhance the effect of itraconazole on disrupting cell membrane integrity, leading to apoptosis in MCF7 cells."</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">12</td>
<td style="text-align: center;">Hydroxychloroquine (Malaria, Rheumatoid Arthritis)</td>
<td style="text-align: center;">Disulfiram (Alcoholism)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">"Hydroxychloroquine-induced impairment of autophagy may enhance the effect of disulfiram-induced oxidative stress and DNA damage in MCF7 cells."</td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>Table 1a. GPT4 generated drug combination hypotheses.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">Drug1</th>
<th style="text-align: center;">Drug2</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">Disulfiram <br> (Alcoholism)</td>
<td style="text-align: center;">Fulvestrant <br> (Breast cancer)</td>
<td style="text-align: center;">$+$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">"Disulfiram exhibited the highest toxicity to MCF7 cells, and both Disulfiram and Fulvestrant preferentially targeted MCF7 over MCF10A. MCF7 is an estrogenreceptor positive cell line, and Fulvestrant is an estrogen receptor antagonist, which degrades the receptor. This combination could target the estrogendependent growth of MCF7 cells. Disulfiram's aldehyde dehydrogenase inhibitory action can further increase its toxicity to MCF7 cells."</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: center;">$\begin{gathered} \text { Mebendazole } \ \text { (Parasitic Infections) } \end{gathered}$</td>
<td style="text-align: center;">Quinacrine <br> (Malaria/Anti-inflammatory)</td>
<td style="text-align: center;">$+$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">"Both Mebendazole and Quinacrine preferentially targeted MCF7 cells. Mebendazole has anti-cancer properties, potentially by disrupting microtubule function. Quinacrine, though primarily an antimalarial, can exert anti-cancer effects, possibly due to its ability to intercalate with DNA and/or inhibit topoisomerase. This combination might have a multi-pronged effect on MCF7 cells, disrupting cellular division and DNA processes."</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">3</td>
<td style="text-align: center;">Disulfiram <br> (Alcoholism)</td>
<td style="text-align: center;">Mebendazole <br> (Parasitic Infections)</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">"As Disulfiram demonstrated the highest toxicity to MCF7 cells and Mebendazole also preferentially targeted MCF7, their combination might exert a compounded effect. The combined microtubule disruption by Mebendazole and the aldehyde dehydrogenase inhibition by Disulfiram could cripple the MCF7 cells at multiple fronts."</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">4</td>
<td style="text-align: center;">Disulfiram <br> (Alcoholism)</td>
<td style="text-align: center;">Quinacrine <br> (Malaria/Anti-inflammatory)</td>
<td style="text-align: center;">$+$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">"Disulfiram exhibited the highest toxicity toward MCF7 cells and has been shown to induce oxidative stress and inhibit proteasomal and NF-кB pathways, which are vital for cancer cell survival. Quinacrine, an antimalarial drug, also possesses anti-cancer properties, including the ability to inhibit NF-кB and autophagy, a survival mechanism often upregulated in cancer cells. The combination is expected to potentiate oxidative stress and inhibit survival pathways more effectively in MCF7 cells. Given that both drugs preferentially targeted MCF7 over MCF10A, their combination might enhance selectivity, exploiting their shared mechanisms for a synergistic effect."</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>Table 4. GPT4 drug combination recommendations based on results from the first screen. Synergy hypotheses are provided for each of the four combinations.</p>            </div>
        </div>

    </div>
</body>
</html>