<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2272 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2272</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2272</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-63.html">extraction-schema-63</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <p><strong>Paper ID:</strong> paper-53212155</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/1811.03392v1.pdf" target="_blank">Transformative Machine Learning</a></p>
                <p><strong>Paper Abstract:</strong> The key to success in machine learning (ML) is the use of effective data representations. Traditionally, data representations were hand-crafted. Recently it has been demonstrated that, given sufficient data, deep neural networks can learn effective implicit representations from simple input representations. However, for most scientific problems, the use of deep learning is not appropriate as the amount of available data is limited, and/or the output models must be explainable. Nevertheless, many scientific problems do have significant amounts of data available on related tasks, which makes them amenable to multi-task learning, i.e. learning many related problems simultaneously. Here we propose a novel and general representation learning approach for multi-task learning that works successfully with small amounts of data. The fundamental new idea is to transform an input intrinsic data representation (i.e., handcrafted features), to an extrinsic representation based on what a pre-trained set of models predict about the examples. This transformation has the dual advantages of producing significantly more accurate predictions, and providing explainable models. To demonstrate the utility of this transformative learning approach, we have applied it to three real-world scientific problems: drug-design (quantitative structure activity relationship learning), predicting human gene expression (across different tissue types and drug treatments), and meta-learning for machine learning (predicting which machine learning methods work best for a given problem). In all three problems, transformative machine learning significantly outperforms the best intrinsic representation.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2272.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2272.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Transformative Learning</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Transformative Machine Learning (extrinsic representation via pretrained task models)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A two-stage multi-task/transfer representation-learning method that converts intrinsic example descriptors into an extrinsic representation formed by the predictions of a set of pretrained models on related tasks, then trains final task-specific models on these extrinsic descriptors.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>general / multi-task scientific learning</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Improve prediction accuracy and explainability in scientific problems where many related tasks exist but each individual task has limited data, by learning a joint representation from predictions of models trained on related tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Typically per-task data is limited/scarce but there exist many related tasks providing substantial aggregate data; datasets are labeled for supervised problems; accessibility depends on domain repositories (e.g., ChEMBL, LINCS, OpenML).</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured tabular data (task-specific intrinsic descriptors) that can be converted to an extrinsic numeric vector of model predictions; high-dimensional when many tasks/models are available; sparse in some domains (e.g., binary molecular fingerprints).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High: problems often non-linear, high-dimensional, and heterogeneous across tasks; complexity arises from large chemical/biological search spaces and interactions between task and example features.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Applicable across both well-established domains (drug discovery, genomics) and meta-ML; builds on mature multi-task/transfer learning literature but provides a new representation approach.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High — the method emphasizes producing explainable descriptors (extrinsic features are interpretable as 'what other tasks predict about this example'), intended to support scientific insight and model interpretability.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Transformative Learning (extrinsic/task-prediction based representation)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Two-stage pipeline: (1) Train one predictive model per task using intrinsic descriptors. (2) For each task, apply all other task models to its examples to produce an extrinsic vector of predicted values (excluding models trained on the same examples), then train final models on these extrinsic descriptors. Optionally repeat (second-order) by treating extrinsic predictions as new intrinsic features and re-applying the pipeline. Non-linear learners (Random Forests, SVM) are used effectively to produce the extrinsic descriptors; linear Ridge as transformer was unsuccessful. The approach leverages multi-task similarity implicitly via the prediction-space projection and uses standard supervised learners in both stages.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>supervised learning / transfer & multi-task representation learning</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Well suited to problems with many related tasks where per-task data is limited and explainability is desired; less useful where no related tasks exist or when cost of running many cross-task predictions is prohibitive. Requires that pretrained task models can be trained (i.e., labeled data per task).</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Across three scientific domains, transformative representations reduced RMSE relative to intrinsic representations: QSAR RF: RMSE 0.1643 -> 0.1478 (~10.05% improvement); Gene expression RF: 0.0694 -> 0.0664 (~4.32%); Meta-learning RF: 0.1184 -> 0.0526 (~55.57%). Effectiveness depends on transformer/predictor pairing (RF/SVM transformers worked best; Ridge transformer did not improve results).</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Generally produced substantially better predictions than intrinsic representations, particularly when using non-linear methods to form the transformed representation; provided interpretable features that expose task relationships; computational overhead increased (need to predict all examples with all task models and retrain final models).</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High: can improve predictive performance and interpretability in scientific ML tasks (drug discovery, genomics, meta-ML) where many related tasks exist; can guide experiments, improve model selection, and reveal task/task and example/example relationships; scalable to many tasks but with higher compute than single-task baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared to original intrinsic-feature models (baseline) and to an 'all-in' single model approach: transformative learning outperformed intrinsic baselines across domains and avoids re-training a single monolithic model when tasks/data are added; also compared different transformer learners (RF, SVM, Ridge) showing non-linear transformers (RF, SVM) perform much better than linear Ridge for generating extrinsic descriptors.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Availability of many related tasks; quality of per-task pretrained models; non-linear learning methods to produce extrinsic features (RF/SVM); use of cross-validated exclusion when generating descriptors (avoid leakage); domains where interpretability of cross-task predictions is meaningful.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Projecting examples into a prediction-space formed by models trained on related tasks produces an informative, explainable representation that substantially improves supervised learning performance when per-task data is limited, provided the transformer is sufficiently non-linear.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Transformative Machine Learning', 'publication_date_yy_mm': '2018-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2272.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2272.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Transformative Learning — QSAR (Drug discovery)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Transformative Learning applied to Quantitative Structure–Activity Relationship (QSAR) modeling</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Applied transformative learning to chemical bioactivity prediction tasks (QSAR) using ChEMBL targets; intrinsic 1024-bit FCFP4 fingerprints were transformed into extrinsic descriptors via predictions of models trained on many related targets.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Transformative Machine Learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>drug discovery / QSAR modeling</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Predict biological activity (bioactivity/inhibition) of small molecules against protein targets (one predictive model per target). Tasks are related by similar target proteins and shared or related compounds.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Per-target dataset sizes ranged from ~30 to ~6,000 compounds (2,219 targets were extracted from ChEMBL); labeled activity data present; moderate-to-limited per-task data but large collection of related tasks — aggregate data abundant and accessible via ChEMBL.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured tabular data: 1,024-bit FCFP4 binary molecular fingerprints (sparse high-dimensional binary vectors); each example is a compound with associated activity label (regression).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High chemical-space complexity; non-linear relationships between molecular substructures and activity; number of variables = 1,024 fingerprint bits; heterogeneity across targets; models must generalize across chemical diversity.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Well-established domain with a long ML history and curated public datasets (ChEMBL); many baseline methods exist but no single universally best approach.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High — drug design requires interpretable/credible models and explanations for scientific/decision-making purposes; black-box DNNs often undesirable in this context.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Transformative Learning with Random Forest / SVM transformers and predictors</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Per-target Random Forests (500 trees) and Ridge regression models were trained on intrinsic fingerprint descriptors. For each compound, extrinsic descriptors were generated by predicting activity using all other target models (excluding models trained using that compound). The extrinsic vectors (2,218 features) were used to train final models (RF, SVM, Ridge) and compared against intrinsic baseline models. Cross-validation (10-fold) with identical splits was used to evaluate RMSE.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>supervised learning / transfer & multi-task representation learning</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Appropriate because many related QSAR tasks exist and per-target data is often limited; method leverages inter-target relatedness. Limitations: computational cost to generate extrinsic features (predict with all models) and need to avoid training-data leakage.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Using RF to generate transformed features and RF as final learner: mean RMSE improved from 0.1643 to 0.1478 (~10.05% improvement). SVM on transformed features showed similar ~10% improvement. Ridge used as transformer produced no improvement (Ridge TL % = 0.06% or negative depending pairing). Improvements measured as average RMSE across 2,212 problems with 10-fold CV.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Transformative learning produced a large improvement over the best intrinsic method (RF on fingerprints) and over a suite of 54 intrinsic approaches previously compared; best when non-linear methods (RF/SVM) are used to form extrinsic descriptors; linear Ridge failed to create beneficial transformed features.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Significant: better QSAR predictions can accelerate hit identification/lead optimization and reduce experimental costs; the extrinsic representation also aids interpretability by relating a compound's predictions across targets.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared to intrinsic fingerprint representations and a wide historical set of learning methods, transformative learning (with RF/SVM transformers) outperformed the best intrinsic approaches; linear-transform (Ridge) approach failed to improve performance.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Large number of related targets providing cross-task signal; use of non-linear learners to generate extrinsic features; careful cross-validation to avoid leakage; fingerprints as consistent intrinsic descriptors enabling model-sharing across tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>When many related QSAR tasks exist, representing compounds by how other target models predict them (an extrinsic, task-prediction space) yields substantially better and more explainable bioactivity models than standard intrinsic molecular fingerprints, provided non-linear transformers are used.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Transformative Machine Learning', 'publication_date_yy_mm': '2018-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2272.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2272.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Transformative Learning — Gene expression (LINCS)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Transformative Learning applied to gene expression prediction using LINCS perturbation data</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Used transformative learning to predict landmark-gene expression levels from experimental perturbation conditions (drug, cell type/site, dose, time) by converting intrinsic metadata and fingerprints into extrinsic descriptors via pretrained gene models.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Transformative Machine Learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>functional genomics / drug perturbation response prediction</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Predict expression levels of 978 landmark human genes under experimental perturbations (drug, cell type, dosage, time) to guide laboratory drug-discovery experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>LINCS Phase II: ~118,050 experimental conditions with expression for 978 genes; 1,795 drugs with valid chemical structures; converted to a 107,152 x 1,155 condition-feature matrix; per-gene training sets sampled with 7,000 train and 3,000 test examples — fairly abundant labeled data.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured tabular data combining categorical metadata (30 cell types, 14 cell sites, 83 dosages, 3 time points) encoded as one-hot Booleans and 1,024-bit chemical fingerprints per perturbagen; resulting matrix high-dimensional (~1,155 features) and dense/sparse mix.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High: gene expression is driven by complex, non-linear interactions among drug chemistry, cell-type context, dose and time; 978 separate but related regression tasks (one per gene).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Genomics and perturbation-response modeling are well-studied but biologically complex; existing large-scale datasets (LINCS) enable data-driven modeling though mechanistic understanding remains incomplete.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High — models are intended to guide experiments so interpretability and reliability are important; transformed representation offers improved explainability.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Transformative Learning with Random Forest and Ridge (as predictors) and RF/Ridge as transformers</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Gene models were trained per-gene using intrinsic metadata+fingerprints. Extrinsic descriptors were formed by predicting each example using models trained on other genes (500 descriptors used in transformation). Final models (RF and Ridge) were trained on transformed representations. Performance evaluated by RMSE; models used RF (500 trees) and Ridge (GLMNET) with internal cross-validation for regularization.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>supervised learning / multi-task representation learning</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable because many related gene-prediction tasks exist and data are abundant across tasks; allows borrowing strength across genes and conditions. Limitations: complexity of biological mechanisms and computational cost of generating extrinsic descriptors.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>RF on intrinsic representation RMSE 0.0694; RF on RF-transformed representation RMSE 0.0664 (~4.32% mean improvement across 978 genes). Ridge as final predictor benefited more when transformation was produced by RF (e.g., Ridge original 0.0724 -> RF-transformed 0.0673, ~7.04% improvement). Ridge used as transformer produced little or negative improvement.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Transformative learning improved prediction accuracy across almost all genes when non-linear transformers (RF) were used; linear transformation (Ridge) was less useful. RF-transform + RF or RF-transform + Ridge both produced gains, showing that a non-linear transformation followed by possibly linear final model can be effective.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Medium-to-high: improved predictions of drug perturbation effects on gene expression can prioritize experiments and reduce lab costs, and extrinsic features can help interpret cross-gene predictive relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared transformed vs intrinsic representations using RF and Ridge learners; RF-transformed representations outperformed intrinsic baselines widely; Ridge-transform did not improve results. No deep-learning approaches were applied here due to domain-data considerations.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Large, shared perturbation dataset (LINCS) providing many related tasks; inclusion of chemical fingerprints and experimental metadata; use of non-linear transformers (RF) to capture complex interactions; selection of sufficient number of transformer descriptors (500).</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>In high-dimensional biological response prediction with many related outputs, an extrinsic representation built from non-linear predictors across tasks improves accuracy and allows even linear final learners to benefit, indicating that the prediction-space encodes cross-task structure usefully.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Transformative Machine Learning', 'publication_date_yy_mm': '2018-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2272.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2272.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Transformative Learning — Meta-learning (OpenML)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Transformative Learning applied to meta-learning for selecting ML methods (OpenML dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Applied transformative learning to predict ML algorithm performance (AUC) on new datasets using intrinsic dataset meta-features transformed into extrinsic descriptors generated by pretrained meta-models from other datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Transformative Machine Learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>meta-machine learning / automated machine learning (AutoML)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Predict the performance (area under ROC curve) of specific machine-learning algorithm configurations on new datasets, given dataset meta-features (e.g., number of examples, missing values, percentage numeric features), to guide algorithm selection.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>From OpenML: 10,840 evaluations across 351 tasks and 53 methods; meta-datasets per method contained ~100–250 tasks; labeled performance data (AUC) available for many task-algorithm pairs; moderate-to-rich meta-dataset availability.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured tabular data: 21 scalar meta-features per dataset (statistical descriptors), low-to-moderate dimensionality; transformed extrinsic representation used 52 descriptors (predictions from other method-specific meta-models).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Moderate: performance prediction depends on dataset-level statistics and interactions with algorithm configurations, non-linear but lower-dimensional than chemical/genomics tasks; heterogeneity across datasets creates modeling challenges.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Meta-learning and AutoML are established research areas with public repositories (OpenML) and prior meta-learning studies.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium — interpretability useful for algorithm selection and trust, but primary goal is accurate ranking/prediction of algorithm performance; extrinsic features can increase interpretability by showing relationships between datasets via predicted performances.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Transformative Learning with RF/SVM/Ridge transformers and RF/SVM/Ridge final learners</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Meta-models per algorithm (trained on intrinsic meta-features) were used to create extrinsic descriptors for each dataset by predicting AUC with all other algorithm-specific meta-models (excluding models trained on that dataset). Transformed representations (52 features) were used to retrain predictors (RF, SVM, Ridge) for AUC prediction. Evaluated by RMSE under 10-fold CV.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>supervised learning / meta-learning / transfer learning</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable: many related tasks (datasets) and labeled algorithm-performance evaluations exist; transformed representation captures cross-algorithm relationships and substantially improves prediction accuracy. Limitations include reliance on prior evaluations in repositories and compute to produce extrinsic features.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Random Forest baseline on intrinsic rep: RMSE = 0.1184. RF trained on RF-transformed representation: RMSE = 0.0526 (~55.57% improvement). Ridge baseline 0.1403 -> RF-transformed 0.0710 (~49.39% improvement). SVM also showed large improvements (e.g., SVM baseline 0.1335 -> RF-transformed 0.0573, ~57.08%).</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Transformative learning yielded very large reductions in RMSE compared to intrinsic meta-features, demonstrating strong benefit from representing datasets by how other algorithm-specific meta-models predict them. As before, non-linear transformers (RF, SVM) were most effective; Ridge-transform sometimes produced worse or little changed performance when used to form transformed features.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High for AutoML and meta-learning workflows: more accurate predictions of algorithm performance enable better algorithm selection, reduced experimental evaluations and faster ML pipeline design; approach leverages public benchmarking repositories effectively.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Direct comparison to intrinsic meta-feature baselines and across transformer-predictor pairings. Transformative representations (especially RF-based) substantially outperformed intrinsic baselines across nearly all tested tasks; also contrasted with 'all-in' monolithic models and argued advantages of transformative learning (easier incremental updates, explicit task relations).</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Rich OpenML evaluation database with many task-method pairs; low-dimensional but informative meta-features that allow per-algorithm meta-models to capture useful cross-dataset signal; use of non-linear models to build transformation; careful exclusion of self-predictions to avoid leakage.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>When historical algorithm-performance data across many datasets are available, representing a dataset by predicted performances from other algorithm-specific meta-models creates a compact, highly informative feature space that dramatically improves meta-learning predictions of algorithm performance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Transformative Machine Learning', 'publication_date_yy_mm': '2018-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Meta-qsar: a large-scale application of meta-learning to drug design and discovery <em>(Rating: 2)</em></li>
                <li>OpenML: networked science in machine learning <em>(Rating: 2)</em></li>
                <li>Data portal for the library of integrated network-based cellular signatures (lincs) program: integrated access to diverse large-scale cellular perturbation response data <em>(Rating: 2)</em></li>
                <li>Learning many related tasks at the same time with backpropagation <em>(Rating: 2)</em></li>
                <li>Random forests <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2272",
    "paper_id": "paper-53212155",
    "extraction_schema_id": "extraction-schema-63",
    "extracted_data": [
        {
            "name_short": "Transformative Learning",
            "name_full": "Transformative Machine Learning (extrinsic representation via pretrained task models)",
            "brief_description": "A two-stage multi-task/transfer representation-learning method that converts intrinsic example descriptors into an extrinsic representation formed by the predictions of a set of pretrained models on related tasks, then trains final task-specific models on these extrinsic descriptors.",
            "citation_title": "here",
            "mention_or_use": "use",
            "scientific_problem_domain": "general / multi-task scientific learning",
            "problem_description": "Improve prediction accuracy and explainability in scientific problems where many related tasks exist but each individual task has limited data, by learning a joint representation from predictions of models trained on related tasks.",
            "data_availability": "Typically per-task data is limited/scarce but there exist many related tasks providing substantial aggregate data; datasets are labeled for supervised problems; accessibility depends on domain repositories (e.g., ChEMBL, LINCS, OpenML).",
            "data_structure": "Structured tabular data (task-specific intrinsic descriptors) that can be converted to an extrinsic numeric vector of model predictions; high-dimensional when many tasks/models are available; sparse in some domains (e.g., binary molecular fingerprints).",
            "problem_complexity": "High: problems often non-linear, high-dimensional, and heterogeneous across tasks; complexity arises from large chemical/biological search spaces and interactions between task and example features.",
            "domain_maturity": "Applicable across both well-established domains (drug discovery, genomics) and meta-ML; builds on mature multi-task/transfer learning literature but provides a new representation approach.",
            "mechanistic_understanding_requirements": "High — the method emphasizes producing explainable descriptors (extrinsic features are interpretable as 'what other tasks predict about this example'), intended to support scientific insight and model interpretability.",
            "ai_methodology_name": "Transformative Learning (extrinsic/task-prediction based representation)",
            "ai_methodology_description": "Two-stage pipeline: (1) Train one predictive model per task using intrinsic descriptors. (2) For each task, apply all other task models to its examples to produce an extrinsic vector of predicted values (excluding models trained on the same examples), then train final models on these extrinsic descriptors. Optionally repeat (second-order) by treating extrinsic predictions as new intrinsic features and re-applying the pipeline. Non-linear learners (Random Forests, SVM) are used effectively to produce the extrinsic descriptors; linear Ridge as transformer was unsuccessful. The approach leverages multi-task similarity implicitly via the prediction-space projection and uses standard supervised learners in both stages.",
            "ai_methodology_category": "supervised learning / transfer & multi-task representation learning",
            "applicability": "Well suited to problems with many related tasks where per-task data is limited and explainability is desired; less useful where no related tasks exist or when cost of running many cross-task predictions is prohibitive. Requires that pretrained task models can be trained (i.e., labeled data per task).",
            "effectiveness_quantitative": "Across three scientific domains, transformative representations reduced RMSE relative to intrinsic representations: QSAR RF: RMSE 0.1643 -&gt; 0.1478 (~10.05% improvement); Gene expression RF: 0.0694 -&gt; 0.0664 (~4.32%); Meta-learning RF: 0.1184 -&gt; 0.0526 (~55.57%). Effectiveness depends on transformer/predictor pairing (RF/SVM transformers worked best; Ridge transformer did not improve results).",
            "effectiveness_qualitative": "Generally produced substantially better predictions than intrinsic representations, particularly when using non-linear methods to form the transformed representation; provided interpretable features that expose task relationships; computational overhead increased (need to predict all examples with all task models and retrain final models).",
            "impact_potential": "High: can improve predictive performance and interpretability in scientific ML tasks (drug discovery, genomics, meta-ML) where many related tasks exist; can guide experiments, improve model selection, and reveal task/task and example/example relationships; scalable to many tasks but with higher compute than single-task baselines.",
            "comparison_to_alternatives": "Compared to original intrinsic-feature models (baseline) and to an 'all-in' single model approach: transformative learning outperformed intrinsic baselines across domains and avoids re-training a single monolithic model when tasks/data are added; also compared different transformer learners (RF, SVM, Ridge) showing non-linear transformers (RF, SVM) perform much better than linear Ridge for generating extrinsic descriptors.",
            "success_factors": "Availability of many related tasks; quality of per-task pretrained models; non-linear learning methods to produce extrinsic features (RF/SVM); use of cross-validated exclusion when generating descriptors (avoid leakage); domains where interpretability of cross-task predictions is meaningful.",
            "key_insight": "Projecting examples into a prediction-space formed by models trained on related tasks produces an informative, explainable representation that substantially improves supervised learning performance when per-task data is limited, provided the transformer is sufficiently non-linear.",
            "uuid": "e2272.0",
            "source_info": {
                "paper_title": "Transformative Machine Learning",
                "publication_date_yy_mm": "2018-11"
            }
        },
        {
            "name_short": "Transformative Learning — QSAR (Drug discovery)",
            "name_full": "Transformative Learning applied to Quantitative Structure–Activity Relationship (QSAR) modeling",
            "brief_description": "Applied transformative learning to chemical bioactivity prediction tasks (QSAR) using ChEMBL targets; intrinsic 1024-bit FCFP4 fingerprints were transformed into extrinsic descriptors via predictions of models trained on many related targets.",
            "citation_title": "Transformative Machine Learning",
            "mention_or_use": "use",
            "scientific_problem_domain": "drug discovery / QSAR modeling",
            "problem_description": "Predict biological activity (bioactivity/inhibition) of small molecules against protein targets (one predictive model per target). Tasks are related by similar target proteins and shared or related compounds.",
            "data_availability": "Per-target dataset sizes ranged from ~30 to ~6,000 compounds (2,219 targets were extracted from ChEMBL); labeled activity data present; moderate-to-limited per-task data but large collection of related tasks — aggregate data abundant and accessible via ChEMBL.",
            "data_structure": "Structured tabular data: 1,024-bit FCFP4 binary molecular fingerprints (sparse high-dimensional binary vectors); each example is a compound with associated activity label (regression).",
            "problem_complexity": "High chemical-space complexity; non-linear relationships between molecular substructures and activity; number of variables = 1,024 fingerprint bits; heterogeneity across targets; models must generalize across chemical diversity.",
            "domain_maturity": "Well-established domain with a long ML history and curated public datasets (ChEMBL); many baseline methods exist but no single universally best approach.",
            "mechanistic_understanding_requirements": "High — drug design requires interpretable/credible models and explanations for scientific/decision-making purposes; black-box DNNs often undesirable in this context.",
            "ai_methodology_name": "Transformative Learning with Random Forest / SVM transformers and predictors",
            "ai_methodology_description": "Per-target Random Forests (500 trees) and Ridge regression models were trained on intrinsic fingerprint descriptors. For each compound, extrinsic descriptors were generated by predicting activity using all other target models (excluding models trained using that compound). The extrinsic vectors (2,218 features) were used to train final models (RF, SVM, Ridge) and compared against intrinsic baseline models. Cross-validation (10-fold) with identical splits was used to evaluate RMSE.",
            "ai_methodology_category": "supervised learning / transfer & multi-task representation learning",
            "applicability": "Appropriate because many related QSAR tasks exist and per-target data is often limited; method leverages inter-target relatedness. Limitations: computational cost to generate extrinsic features (predict with all models) and need to avoid training-data leakage.",
            "effectiveness_quantitative": "Using RF to generate transformed features and RF as final learner: mean RMSE improved from 0.1643 to 0.1478 (~10.05% improvement). SVM on transformed features showed similar ~10% improvement. Ridge used as transformer produced no improvement (Ridge TL % = 0.06% or negative depending pairing). Improvements measured as average RMSE across 2,212 problems with 10-fold CV.",
            "effectiveness_qualitative": "Transformative learning produced a large improvement over the best intrinsic method (RF on fingerprints) and over a suite of 54 intrinsic approaches previously compared; best when non-linear methods (RF/SVM) are used to form extrinsic descriptors; linear Ridge failed to create beneficial transformed features.",
            "impact_potential": "Significant: better QSAR predictions can accelerate hit identification/lead optimization and reduce experimental costs; the extrinsic representation also aids interpretability by relating a compound's predictions across targets.",
            "comparison_to_alternatives": "Compared to intrinsic fingerprint representations and a wide historical set of learning methods, transformative learning (with RF/SVM transformers) outperformed the best intrinsic approaches; linear-transform (Ridge) approach failed to improve performance.",
            "success_factors": "Large number of related targets providing cross-task signal; use of non-linear learners to generate extrinsic features; careful cross-validation to avoid leakage; fingerprints as consistent intrinsic descriptors enabling model-sharing across tasks.",
            "key_insight": "When many related QSAR tasks exist, representing compounds by how other target models predict them (an extrinsic, task-prediction space) yields substantially better and more explainable bioactivity models than standard intrinsic molecular fingerprints, provided non-linear transformers are used.",
            "uuid": "e2272.1",
            "source_info": {
                "paper_title": "Transformative Machine Learning",
                "publication_date_yy_mm": "2018-11"
            }
        },
        {
            "name_short": "Transformative Learning — Gene expression (LINCS)",
            "name_full": "Transformative Learning applied to gene expression prediction using LINCS perturbation data",
            "brief_description": "Used transformative learning to predict landmark-gene expression levels from experimental perturbation conditions (drug, cell type/site, dose, time) by converting intrinsic metadata and fingerprints into extrinsic descriptors via pretrained gene models.",
            "citation_title": "Transformative Machine Learning",
            "mention_or_use": "use",
            "scientific_problem_domain": "functional genomics / drug perturbation response prediction",
            "problem_description": "Predict expression levels of 978 landmark human genes under experimental perturbations (drug, cell type, dosage, time) to guide laboratory drug-discovery experiments.",
            "data_availability": "LINCS Phase II: ~118,050 experimental conditions with expression for 978 genes; 1,795 drugs with valid chemical structures; converted to a 107,152 x 1,155 condition-feature matrix; per-gene training sets sampled with 7,000 train and 3,000 test examples — fairly abundant labeled data.",
            "data_structure": "Structured tabular data combining categorical metadata (30 cell types, 14 cell sites, 83 dosages, 3 time points) encoded as one-hot Booleans and 1,024-bit chemical fingerprints per perturbagen; resulting matrix high-dimensional (~1,155 features) and dense/sparse mix.",
            "problem_complexity": "High: gene expression is driven by complex, non-linear interactions among drug chemistry, cell-type context, dose and time; 978 separate but related regression tasks (one per gene).",
            "domain_maturity": "Genomics and perturbation-response modeling are well-studied but biologically complex; existing large-scale datasets (LINCS) enable data-driven modeling though mechanistic understanding remains incomplete.",
            "mechanistic_understanding_requirements": "High — models are intended to guide experiments so interpretability and reliability are important; transformed representation offers improved explainability.",
            "ai_methodology_name": "Transformative Learning with Random Forest and Ridge (as predictors) and RF/Ridge as transformers",
            "ai_methodology_description": "Gene models were trained per-gene using intrinsic metadata+fingerprints. Extrinsic descriptors were formed by predicting each example using models trained on other genes (500 descriptors used in transformation). Final models (RF and Ridge) were trained on transformed representations. Performance evaluated by RMSE; models used RF (500 trees) and Ridge (GLMNET) with internal cross-validation for regularization.",
            "ai_methodology_category": "supervised learning / multi-task representation learning",
            "applicability": "Applicable because many related gene-prediction tasks exist and data are abundant across tasks; allows borrowing strength across genes and conditions. Limitations: complexity of biological mechanisms and computational cost of generating extrinsic descriptors.",
            "effectiveness_quantitative": "RF on intrinsic representation RMSE 0.0694; RF on RF-transformed representation RMSE 0.0664 (~4.32% mean improvement across 978 genes). Ridge as final predictor benefited more when transformation was produced by RF (e.g., Ridge original 0.0724 -&gt; RF-transformed 0.0673, ~7.04% improvement). Ridge used as transformer produced little or negative improvement.",
            "effectiveness_qualitative": "Transformative learning improved prediction accuracy across almost all genes when non-linear transformers (RF) were used; linear transformation (Ridge) was less useful. RF-transform + RF or RF-transform + Ridge both produced gains, showing that a non-linear transformation followed by possibly linear final model can be effective.",
            "impact_potential": "Medium-to-high: improved predictions of drug perturbation effects on gene expression can prioritize experiments and reduce lab costs, and extrinsic features can help interpret cross-gene predictive relationships.",
            "comparison_to_alternatives": "Compared transformed vs intrinsic representations using RF and Ridge learners; RF-transformed representations outperformed intrinsic baselines widely; Ridge-transform did not improve results. No deep-learning approaches were applied here due to domain-data considerations.",
            "success_factors": "Large, shared perturbation dataset (LINCS) providing many related tasks; inclusion of chemical fingerprints and experimental metadata; use of non-linear transformers (RF) to capture complex interactions; selection of sufficient number of transformer descriptors (500).",
            "key_insight": "In high-dimensional biological response prediction with many related outputs, an extrinsic representation built from non-linear predictors across tasks improves accuracy and allows even linear final learners to benefit, indicating that the prediction-space encodes cross-task structure usefully.",
            "uuid": "e2272.2",
            "source_info": {
                "paper_title": "Transformative Machine Learning",
                "publication_date_yy_mm": "2018-11"
            }
        },
        {
            "name_short": "Transformative Learning — Meta-learning (OpenML)",
            "name_full": "Transformative Learning applied to meta-learning for selecting ML methods (OpenML dataset)",
            "brief_description": "Applied transformative learning to predict ML algorithm performance (AUC) on new datasets using intrinsic dataset meta-features transformed into extrinsic descriptors generated by pretrained meta-models from other datasets.",
            "citation_title": "Transformative Machine Learning",
            "mention_or_use": "use",
            "scientific_problem_domain": "meta-machine learning / automated machine learning (AutoML)",
            "problem_description": "Predict the performance (area under ROC curve) of specific machine-learning algorithm configurations on new datasets, given dataset meta-features (e.g., number of examples, missing values, percentage numeric features), to guide algorithm selection.",
            "data_availability": "From OpenML: 10,840 evaluations across 351 tasks and 53 methods; meta-datasets per method contained ~100–250 tasks; labeled performance data (AUC) available for many task-algorithm pairs; moderate-to-rich meta-dataset availability.",
            "data_structure": "Structured tabular data: 21 scalar meta-features per dataset (statistical descriptors), low-to-moderate dimensionality; transformed extrinsic representation used 52 descriptors (predictions from other method-specific meta-models).",
            "problem_complexity": "Moderate: performance prediction depends on dataset-level statistics and interactions with algorithm configurations, non-linear but lower-dimensional than chemical/genomics tasks; heterogeneity across datasets creates modeling challenges.",
            "domain_maturity": "Meta-learning and AutoML are established research areas with public repositories (OpenML) and prior meta-learning studies.",
            "mechanistic_understanding_requirements": "Medium — interpretability useful for algorithm selection and trust, but primary goal is accurate ranking/prediction of algorithm performance; extrinsic features can increase interpretability by showing relationships between datasets via predicted performances.",
            "ai_methodology_name": "Transformative Learning with RF/SVM/Ridge transformers and RF/SVM/Ridge final learners",
            "ai_methodology_description": "Meta-models per algorithm (trained on intrinsic meta-features) were used to create extrinsic descriptors for each dataset by predicting AUC with all other algorithm-specific meta-models (excluding models trained on that dataset). Transformed representations (52 features) were used to retrain predictors (RF, SVM, Ridge) for AUC prediction. Evaluated by RMSE under 10-fold CV.",
            "ai_methodology_category": "supervised learning / meta-learning / transfer learning",
            "applicability": "Highly applicable: many related tasks (datasets) and labeled algorithm-performance evaluations exist; transformed representation captures cross-algorithm relationships and substantially improves prediction accuracy. Limitations include reliance on prior evaluations in repositories and compute to produce extrinsic features.",
            "effectiveness_quantitative": "Random Forest baseline on intrinsic rep: RMSE = 0.1184. RF trained on RF-transformed representation: RMSE = 0.0526 (~55.57% improvement). Ridge baseline 0.1403 -&gt; RF-transformed 0.0710 (~49.39% improvement). SVM also showed large improvements (e.g., SVM baseline 0.1335 -&gt; RF-transformed 0.0573, ~57.08%).",
            "effectiveness_qualitative": "Transformative learning yielded very large reductions in RMSE compared to intrinsic meta-features, demonstrating strong benefit from representing datasets by how other algorithm-specific meta-models predict them. As before, non-linear transformers (RF, SVM) were most effective; Ridge-transform sometimes produced worse or little changed performance when used to form transformed features.",
            "impact_potential": "High for AutoML and meta-learning workflows: more accurate predictions of algorithm performance enable better algorithm selection, reduced experimental evaluations and faster ML pipeline design; approach leverages public benchmarking repositories effectively.",
            "comparison_to_alternatives": "Direct comparison to intrinsic meta-feature baselines and across transformer-predictor pairings. Transformative representations (especially RF-based) substantially outperformed intrinsic baselines across nearly all tested tasks; also contrasted with 'all-in' monolithic models and argued advantages of transformative learning (easier incremental updates, explicit task relations).",
            "success_factors": "Rich OpenML evaluation database with many task-method pairs; low-dimensional but informative meta-features that allow per-algorithm meta-models to capture useful cross-dataset signal; use of non-linear models to build transformation; careful exclusion of self-predictions to avoid leakage.",
            "key_insight": "When historical algorithm-performance data across many datasets are available, representing a dataset by predicted performances from other algorithm-specific meta-models creates a compact, highly informative feature space that dramatically improves meta-learning predictions of algorithm performance.",
            "uuid": "e2272.3",
            "source_info": {
                "paper_title": "Transformative Machine Learning",
                "publication_date_yy_mm": "2018-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Meta-qsar: a large-scale application of meta-learning to drug design and discovery",
            "rating": 2,
            "sanitized_title": "metaqsar_a_largescale_application_of_metalearning_to_drug_design_and_discovery"
        },
        {
            "paper_title": "OpenML: networked science in machine learning",
            "rating": 2,
            "sanitized_title": "openml_networked_science_in_machine_learning"
        },
        {
            "paper_title": "Data portal for the library of integrated network-based cellular signatures (lincs) program: integrated access to diverse large-scale cellular perturbation response data",
            "rating": 2,
            "sanitized_title": "data_portal_for_the_library_of_integrated_networkbased_cellular_signatures_lincs_program_integrated_access_to_diverse_largescale_cellular_perturbation_response_data"
        },
        {
            "paper_title": "Learning many related tasks at the same time with backpropagation",
            "rating": 2,
            "sanitized_title": "learning_many_related_tasks_at_the_same_time_with_backpropagation"
        },
        {
            "paper_title": "Random forests",
            "rating": 1,
            "sanitized_title": "random_forests"
        }
    ],
    "cost": 0.01553825,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Transformative Machine Learning
8 Nov 2018</p>
<p>Ivan Olier 
· Oghenejokpeme oghenejokpeme.orhobor@manchester.ac.uk 
Olier Department of Applied Mathematics
School of Computer Science
Liverpool John Moores University Liverpool
L3 3AFUK</p>
<p>University of Manchester Manchester
M13 9PLUK</p>
<p>School of Computer Science
Eindhoven University of Technology
5600MBEindhovenThe Netherlands</p>
<p>University of Manchester Manchester
M13 9PLUK</p>
<p>National Institute of Advanced Industrial Science and Technology
Alan Turing Institute
NW1 2DB, 135-0064London, TokyoUK, Japan</p>
<p>I Orhobor 
Joaquin Vanschoren j.vanschoren@tue.nl 
Ross D King ross.king@manchester.ac.uk 
Olier Department of Applied Mathematics
School of Computer Science
Liverpool John Moores University Liverpool
L3 3AFUK</p>
<p>University of Manchester Manchester
M13 9PLUK</p>
<p>School of Computer Science
Eindhoven University of Technology
5600MBEindhovenThe Netherlands</p>
<p>University of Manchester Manchester
M13 9PLUK</p>
<p>National Institute of Advanced Industrial Science and Technology
Alan Turing Institute
NW1 2DB, 135-0064London, TokyoUK, Japan</p>
<p>O I Orhobor 
J Vanschoren 
R D King 
Transformative Machine Learning
8 Nov 2018Received: date / Accepted: dateNoname manuscript No. (will be inserted by the editor)Multi-task learning · Transfer learning · Data tranformation · Machine learning
The key to success in machine learning (ML) is the use of effective data representations. Traditionally, data representations were hand-crafted. Recently it has been demonstrated that, given sufficient data, deep neural networks can learn effective implicit representations from simple input representations. However, for most scientific problems, the use of deep learning is not appropriate as the amount of available data is limited, and/or the output models must be explainable. Nevertheless, many scientific problems do have significant amounts of data available on related tasks, which makes them amenable to multi-task learning, i.e. learning many related problems simultaneously. Here we propose a novel and general representation learning approach for multi-task learning that works successfully with small amounts of data. The fundamental new idea is to transform an input intrinsic data representation</p>
<p>(i.e., handcrafted features), to an extrinsic representation based on what a pretrained set of models predict about the examples. This transformation has the dual advantages of producing significantly more accurate predictions, and providing explainable models. To demonstrate the utility of this transformative learning approach, we have applied it to three real-world scientific problems: drug-design (quantitative structure activity relationship learning), predicting human gene expression (across different tissue types and drug treatments), and meta-learning for machine learning (predicting which machine learning methods work best for a given problem). In all three problems, transformative machine learning significantly outperforms the best intrinsic representation.</p>
<p>Keywords Multi-task learning · Transfer learning · Data tranformation · Machine learning 1 Introduction</p>
<p>Machine learning (ML) is the branch of Artificial Intelligence (AI) that focuses on developing systems that can learn from experience. Rather than being explicitly told how to solve a problem, ML algorithms are able to learn from observations induction (Russell and Norvig, 2016). As ML algorithms have a generic ability to learn, rather than solve any particular problem, they are very widely applicable. The application of ML to science has a long history. The pioneering work was the development of learning algorithms for the analysis of mass-spectrometric data (Buchanan et al., 1968). Now, the significance of ML to science has been generally recognized, and ML is being applied to a wide variety of different scientific areas, such as functional genomics (King et al., 2009), physics (Schmidt and Lipson, 2009), drug discovery (Schneider, 2017), organic synthesis planning (Segler et al., 2018), materials science (Butler et al., 2018), and medicine (Esteva et al., 2017). Probably the most exciting current area of machine learning is that of deep neural networks (DNNs) (LeCun et al., 2015;Silver et al., 2016;Esteva et al., 2017). Thanks to advances in computer hardware and the availability of vast amounts of data, DNNs have been shown to be capable of such impressive tasks as beating World Champions at games such as Go (Silver et al., 2016), and diagnosing skin cancers better than human specialists (Esteva et al., 2017). In practice, however, DNNs are applicable only to a very small subset of scientific problems for which such large amounts of data are available. In addition, in most scientific problems, there is a requirement for human comprehensible models, while DNNs only provide black-box models.</p>
<p>Representation Learning</p>
<p>The key to success in machine learning (ML) is the use of effective data representations. Almost all machine learning is based on representations that use tuples of attributes, i.e. the data can be put into a single table, with the examples as rows, and the attributes (descriptors) as columns. An attribute is a proposition that is possibly true about an example. (Examples are described as tuples, and not vectors, as the order of the attributes does not matter -as long as it is the same for all the examples.) The attributes used to describe examples are intrinsic properties of the examples that are believed to be important: for example if one wished to learn about the effectiveness of a drug, then properties of its molecular structure may be useful attributes; similarly, if one wished to learn about chess positions, then the position of the white King might be a useful attribute. Typically, one attribute is singled out as the one we want to predict, and the other attributes contribute information to make this prediction. If this attribute is categorical then the problem is a discrimination/classification task, if the attribute is a real number then the problem is a regression one. Here, we focus on regression problems. The recent success of DNNs has been based on their ability to utilize multiple neural network layers, and large amounts of data, to learn how to convert raw input representations (e.g., image pixel values) into richer internal representations that are effective for learning. This internal conversion has been especially successful in problems where the only available attributes are very simple and minimal, such as pixel colour, brightness, position, etc. Due to this ability to learn effective internal representations, DNNs have succeeded in domains that had previously proved recalcitrant to ML, such as face recognition and learning to play GO. The archetypical case of this is face recognition, which was once considered to be intractable, but can now be solved with super-human ability on certain limited problems (Bengio, 2012).</p>
<p>Multi-task Learning and Transfer Learning</p>
<p>The large amounts of data required for DNNs to learn a good representation is unfortunately not available for many scientific problems. Nevertheless, many scientific problems do often present themselves as sets of related problems, which taken together, provide significant amounts of data, e.g. learning quantitative structure activity relationships (QSARs) for related targets (proteins). Multi-task learning (Caruana, 1997) is the branch of machine learning in which related problems (called tasks) are learned simultaneously, with the aim to exploit similarities between the tasks and thus obtain improved performance (Ando and Zhang, 2005;Evgeniou et al., 2005). The tasks are learned in parallel using a shared representation, so that what is learned from one task (e.g. one where more data is available) can also be used for another task. Multi-task Learning has been successful in many scientific application, such as HIV Therapy Screening (Bickel et al., 2008), analysis of genotype and gene expression data (Kim and Xing, 2010), discovery of highly important marker genes (Xu et al., 2011), modelling of disease progression (Zhou et al., 2011), disease prediction (Zhang et al., 2012), biological sequence classification (Widmer et al., 2010), and predicting small interfering RNA (siRNA) efficacy (Liu et al., 2010). Multi-task learning is closely related to the field of transfer learning (Thrun and Pratt, 1998), in which information is transferred from a specific source task to a specific target task. This can be done by forcing the target model to be structurally or otherwise similar to the source model(s). Neural networks are well suited to transfer learning as both the structure and the model parameters of the source models can be used as a good initializations for the target model, yielding a pre-trained model which can then be further fine-tuned using the available training data on the target task (Thrun and Mitchell, 1994;Baxter, 1995;Bengio, 2012;Caruana, 1995). Especially large image datasets, such as ImageNet (Krizhevsky et al., 2012), have been shown to yield pre-trained models that transfer well to other tasks (Donahue et al., 2014;Sharif Razavian et al., 2014). However, it has also been shown that this approach doesn't work well when the target task is not very similar (Yosinski et al., 2014). As such, it is often difficult to make transfer learning work for many scientific problems.</p>
<p>The success or failure of multi-task learning often crucially depends on the existence of a good task similarity measure. For instance, one could learn a common Bayesian prior over model parameters trained on multiple tasks and use this to measure between-task similarity (Xue et al., 2007;Bakker and Heskes, 2003), or clustering tasks into groups outright (Jacob et al., 2009;Argyriou et al., 2008;Evgeniou et al., 2005). However, it is usually not straightforward to find a similarity measure that works well.</p>
<p>Transformative Learning</p>
<p>We present transformative learning a novel method for transforming input representations into more effective ones. The fundamental new idea is to convert a representation based on intrinsic properties to an extrinsic representation based on the predictions on a set of pre-trained models, each trained on another tasks. This leverages available data from many related tasks to perform a combination of multi-task and transfer learning able to make predictions. Transformative learning has the dual advantages of enabling better predictions, and providing explainable explanations. The input to transformative learning is: (1) a set of related prediction problems, and (2) a set of related examples that have been applied to one or more of the prediction problems. Transformative learning is performed in two learning stages. In the first learning stage (Fig. 1), separate prediction models are learned for each problem, using the available examples, and their standard intrinsic attributes to describe the examples, producing n predictive models. In the second learning stage (Fig. 2), for each problem, the available examples are applied to the n−1 models to produce n − 1 predictive values. These values form the transformed representation. Instead of representing examples by intrinsic attributes, they are represented by what other models predict about them. This transformed extrinsic representation is used to learn the final predictive model. In transformative learning we learn task similarity and a joint representation at the same time. Instead of using a predefined similarity measure to pre-select a set of similar tasks, we project the different tasks into one joint numeric representation, and use a meta-learning algorithm to learn from this new representation how to make accurate predictions for the task at hand. To demonstrate the utility of transformative learning we have applied it to three real-world scientific problems: drug-design (quantitative structure activity relationship learning), predicting human gene expression (across different tissue types and drug treatments), and meta-machine learning (predicting how well machine learning method will work on problems).</p>
<p>Quantitative Structure Activity Relationship Learning</p>
<p>The standard Quantitative Structure Activity Relationship (QSAR) learning problem is: given a target (usually a protein) and a set of chemical compounds (small molecules) with associated bioactivities (normally inhibiting a target protein), learn a predictive mapping from molecular representation to activity. QSAR problems are suitable for transformative learning as they can be related by having related targets proteins (e.g. the problem of inhibiting mouse DHFR is similar to that of inhibiting human DHFR), and they can also be related by involving the same or chemically related small molecules.</p>
<p>Background</p>
<p>Drug development is one of the most important applications of science. It is an essential step in the treatment of almost all diseases. Developing a new drug is however slow and expensive. The average cost to bring a new drug to market is &gt; 2.5 billion US dollars (Mullard, 2014). A key step in drug development is learning QSARs (Martin, 2010;Cherkasov et al., 2014;Cumming et al., 2013). Almost every form of statistical and machine learning method has been applied to this problem, but no single method has been found to be always best (Olier et al., 2018). The most important QSAR dataset is the ChEMBL database (Gaulton et al., 2016), a medicinal chemistry database managed by the European Bioinformatics Institute (EBI). It is abstracted and curated from the scientific literature, and covers a significant fraction of the medicinal chemistry corpus. The data consist of information on the drug targets, the structures of the tested compounds (from which different intrinsic chemoinformatic repre-sentations may be calculated), and the bioactivities of the compounds on their targets. We extracted 2,219 targets from ChEMBL with a diverse number of chemical compounds, ranging from 30 to about 6,000, each target resulting in a dataset with as many examples as compounds (Olier et al., 2018). Chemical compounds were intrinsically described using a standard fingerprint representation (as it is the most commonly used in QSAR learning), where the presence or absence of a particular molecular substructure in a molecule (e.g. methyl group, benzene ring) is indicated by a Boolean variable. Specifically, we calculated the 1024 bits FCFP4 fingerprint representation using the Pipeline Pilot software from BIOVIA (Rogers and Hahn, 2010).</p>
<p>Results</p>
<p>We applied transformative learning to generate extrinsic descriptors of the chemical compounds. For this we selected two learning methods: Random Forest (RF, 500 trees) (Breiman, 2001), and Linear Regression with Ridge Penalization (Ridge, L2 = 10) (Hoerl and Kennard, 1970). This choice was based on the results from (Olier et al., 2018), where these two methods performed best for QSAR datasets using the 1,024 fingerprint representation. QSAR models were created, one for each dataset and learner. Then extrinsic descriptors were generated by predicting activity using all the models but excluding the one from compound was part of the training set. Therefore, 2,218 extrinsic descriptors were generated per chemical compound (i.e. 2,219 original datasets -1 training dataset). We performed a comparative assessment of the two QSAR data representations: the original intrinsic one based of molecular fingerprints, and the transformed data representation based on model predictions. For the comparison we applied three machine learning methods: Random Forest (RF, 500 trees), Linear Regression with Ridge Penalization (Ridge, L2 = 10), and Support Vector Machines (SVM, radial basis function kernel, width = 0.2) (Cortes and Vapnik, 1995). Method performance was measured using the root mean squared error (RMSE). RMSE, which values are in the same range as the response variable, is standard for regression tasks. 10-fold cross-validation was used across all experiments, with the same data splits to reduce bias risk.</p>
<p>All the experiments were performed in R (Team et al., 2013). Table 1 reports average RMSE performance on the test sets. First considering the application of Random Forest learning to transform the intrinsic chemical representation. Applying Random Forest learning a second time to the transformed representation was found to outperform the first Random Forest on 1,118 of the 2,212 problems. This corresponds to &gt; 10% mean improvement in RMSE. A similar result was found applying SVM to this transformed representation where SVM outperform the first SVM on 1,125 of the 2,212 problems, which also corresponds to a &gt;10% mean improvement in RMSE. These results are especially noteworthy as we know from previous work, where we compared 18 common learning methods with 3 different intrinsic representations on the same data, that Random Forest with the finger- print representation is the best method / intrinsic representation combination (Olier et al., 2018). Therefore, transformative learning has produced a large improvement over the best of 54 (18 x 6) intrinsic approaches. The transformed learning approach does not work well with Linear Regression with Ridge Penalization. Using Ridge Penalization as the learning method to transform the representation produces no improvement. Nor is Ridge Penalization successful at exploiting the transformed representation generated by random Forest.</p>
<p>Gene Expression Learning</p>
<p>As our second problem domain we selected the problem of predicting gene expression level. Our goal was to build a predictive models that given a drug and cancer cell type would be able to predict gene expression levels. These models can then be used to guide laboratory-based drug discovery experiments. Specifically, we utilized the Library of Integrated Network-based Cellular Signatures data (LINCS) (Koleti et al., 2017). This data describes the effect of drugs in cancer cell lines on the expression levels of 978 landmark human genes. The prediction problem is to learn models for each gene (978 models) that predict the genes expression level, given experimental conditions (cell type, drug, dosage), the related examples are the experimental condition (cell type, drug, dosage).</p>
<p>Background</p>
<p>We used LINCS Phase II data (accession code GSE70138), which consists of 118,050 experimental conditions, along with the corresponding expression levels for 978 landmark genes. We generated attributes for each perturbation condition using the accompanying metadata. Each experimental condition is associated with a perturbagen (drug), cell type and site, perturbagen dosage, and perturbagen time frame. In total, there are 30 cell types (ct), 14 cell sites (cs), 83 dosages (d) and 3 time points (tp). Of the 2,170 drugs in the dataset, 1,795 have valid chemical structures (canonical smiles codes) according to the  (Team et al., 2013). The RF experiments were performed using version 4.6-12 of the randomForest package, and the Ridge experiments were performed using version 2.0-13 of the GLMNET package. Model performance was calculated as the RMSE. For both, Random Forests and Ridge, we considered 500 descriptors in the transformative learning step. For both learning methods the same gene models were used in the generation of the first order descriptors.</p>
<p>Results</p>
<p>First considering the application of Random Forest learning to learn from the intrinsic representation. Applying Random Forest learning a second time to this transformed representation was found to outperform the first Random Forest on 977 of the 978 genes. This corresponds to a &gt; 4% mean improvement in RMSE. In contrast, applying Ridge learning to the transformed representation was found to outperform the first Random Forest on 862 of the 978 genes. This corresponds to a &gt; 2% mean improvement in RMSE, see Table 2. Then considering the application of Ridge learning to learn from the intrinsic representation. Applying Random Forest learning to this transformed representation was found to outperform the base Ridge models on 952 of the 978 genes. This corresponds to a &gt; 7% mean improvement in RMSE, see Table 2. In contrast applying Ridge learning to the Ridge learning transformed representation outperformed Ridge learning on only 415 of the 978 genes.</p>
<p>Meta-Learning for Machine Learning</p>
<p>In machine learning, a key challenge is to select the best algorithm to train a predictive model on a new task. One approach to this problem is to apply machine learning itself to predict the best techniques (Vanschoren, 2018). Hence, this is called meta-learning, and we select it as our third problem domain. In this type of meta-learning, the prediction problem is to predict the performance of a machine learning method (given an exact configuration) on a new task, given the characteristics of the training data (e.g. statistics of the training data distribution). Domain problems can be related by having similar data distributions, data defects (e.g. missing values), or by containing data being generated by similar processes. The properties used to describe the datasets themselves are typically called meta-features.</p>
<p>Background</p>
<p>Meta-learning for machine learning is feasible thanks to the creation of open repositories that collect datasets, meta-features, and experiment results. OpenML is an online machine learning platform where researchers can automatically log and share data, code, and experiments (Vanschoren et al., 2014). It brings together reproducible experiments from most major machine learning environments, such as WEKA (Java), mlr (R), and scikit-learn (Python). From OpenML we retrieved data from an earlier meta-learning study. 1 Although we had to exclude a few tasks and algorithms because they lacked sufficient evaluations in OpenML, this yielded a set of 10840 evaluations on 351 tasks (datasets) and 53 machine learning methods (called flows on OpenML) from mlr (Bischl et al., 2016). From each task, 21 dataset descriptors were extracted, such as the number of examples, number of missing values, and percentage of numeric features. We formed meta-datasets, one for each machine learning method. An observation within a meta-dataset represents an original OpenML task, and each feature, a dataset descriptor. The original aim of the study was to predict the area under the ROC (AUC). Therefore, in total, we produced 53 meta-datasets with a diverse number of OpenML tasks, ranging from above 100 to about 250. We applied transformative learning to transform the original representation of the datasets into extrinsic descriptors of the OpenML tasks. Three learners were selected to do the transformation: Random Forest (RF, 500 trees), Linear Regression with Ridge Penalization (Ridge, L2 = 10), and Support Vector Machines with Radial Basis Kernel Functions (SVM, σ = 0.2). The transformed descriptors were generated by predicting AUC using all available models but excluding the one from the which the OpenML task belonged.</p>
<p>In this way 52 extrinsic descriptors were generated for each OpenML task. Table 3 shows comparative performance results between the two data representation: the intrinsic original representation using data descriptors (i.e. number of instances, percentage of numeric features, etc), and the transformed extrinsic representation. We used similar learners as above (RF, 500 trees; Ridge, L=10; and SVM, σ = 0.2). For instance, when we train a Random Forest on the intrinsic representation and use it to predict the performance of learning algorithms on every dataset, those predictions have an RMSE of 0.1184 (first row in Table 3). Training the Random Forest learning on the transformed representation (which does not have access to the dataset we are predicting for) was found to outperform the first Random Forest on 51 of the 52 tasks, and yielding an RMSE of 0.526. This corresponds to an impressive &gt; 55% mean improvement in RMSE. Similarly, applying Ridge to the transformed representation was found to outperform the first Random Forest on all of the 52 tasks, which corresponds to &gt; 49% mean improvement in RMSE. Applying SVM to the transformed representation was found to outperform the first Random Forest on 50 of the 52 tasks, which corresponds to &gt; 57% mean improvement in RMSE. Likewise, applying an SVM to learn from the transformed representations was found to vastly outperform training on the intrinsic representation (third row in Table 3), corresponding to &gt; 27% mean improvement in RMSE. Learning on features transformed by the Random Forest learning was found to outperform the original SVM model on 50 of the 52 tasks and &gt; 20% mean improvement in RMSE, and using features transformed by Ridge was found to outperform the first SVM method on all of the 52 tasks, which corresponds to &gt; 25% mean improvement in RMSE. As with QSAR learning and gene expression prediction the application of Ridge learning to transform the representation was unsuccessful, with results little different from the original intrinsic representation.</p>
<p>Results</p>
<p>Discussion</p>
<p>Comparison with All-In Learning. A standard meta-learning approach, often used with DNNs, is to try to learn one large model that encompasses all the problems. In some circumstances this can work well. However, this approach has clear disadvantages compared to transformative learning:</p>
<p>-If new data occurs for a task, the whole model has to be relearned. -If a new task is added, the whole model has to be relearned.</p>
<p>-The relationships between tasks are not explicit.</p>
<p>-The relationships between examples are also not explicit.</p>
<p>Explainable AI. A major motivation of transformative learning is to develop a learning approach that provides explainable models. The transformed representation generates clearly understandable descriptors for learning. For example, using the example problem in Fig 2 of classifying animals, it is possible to classify an animal as a rabbit if it has a combination of properties of a donkey and kitten. This explainability is in marked contrast to the black-box nature of DNNs. Transformative learning also enables one to better understand the relationships between the learning tasks. This can be achieved by using the models for each task to predict all the examples, and then clustering the tasks by their predictions: which displays how the tasks are related in prediction space. Similarly, it is possible to better understand the relationships between examples by clustering them by their different model predictions: which shows how the examples are related in task space.</p>
<p>The Computational Cost of Transformative Learning. One disadvantage of transformative learning is its additional computational cost. With transformative learning, in addition to the standard learning process, it is necessary to: 1) use each task model to predict all the examples to form the transformed representation, and 2) learn new task models using the transformed representation. Both tasks are potentially computationally expensive. However, the cost of transformative learning is low compared to DNNs.</p>
<p>Transformative Learning using Linear Regression with Ridge Penalization.</p>
<p>Our results indicate that the use of Ridge to form a transformed representation does not result in improved predictions. This suggests that it is necessary for the learning method that forms the transformed representation to be non-linear. In contrast, the use of Ridge to make predictions based on the a transformed representation made by Random Forests and SVM can work well, as it does for Gene Expression prediction and Meta-learning for Machine Learning.</p>
<p>Second-Order Transformative Learning. In transformative learning the fundamental new idea is to transform the original, intrinsic data representation, to an extrinsic representation based on what a pre-trained set of models predict about the examples. Given the expectation that using the transformed representation produces better predictions than the original intrinsic representation, it is natural to extend the idea of transformative learning by applying it a second time, i.e. to use the predictions from the transformed representation to form a second-order transformed representation. As the predictions from the transformed representation are better than the ones from intrinsic representation, learning using second-order transformed representation should be more successful than with the first -order transformed representation. One clear disadvantage with this approach is the high-computational cost of using a second-order transformed representation.</p>
<p>Conclusions</p>
<p>In the past, machine learning was most commonly applied in bespoke ways to isolated problems. Now, with the ever-increasing availability of data, machine learning is being increasingly applied to large sets of related problems. This is motivating an increased interest in multi-task and transfer learning. We have developed a novel and general representation learning approach for multi-task learning, and we have demonstrated the success of this approach on three real-world scientific problems: drug-design, predicting human gene expression, and meta-learning for machine learning. In all three problems, transformative machine learning significantly outperforms the best intrinsic representations. We expect transformative learning to be of general application to scientific problems and beyond.</p>
<p>Fig. 2
2Transformative machine learning. First three predictive models are learnt for donkeys, kittens, and rabbits, as in standard ML(Fig 1). Then the kitten and rabbit models are used to predict the donkey examples. For each example in the donkey problem, the kitten model outputs a number, as does the rabbit model. These numbers are then collected into a tuple, and used as an extrinsic description of the example: the transformed description. ML is then used to learn a model that classifies examples as donkeys or not. This process is repeated for the kitten and rabbit problems.</p>
<p>Multiple training examples exist for each problem, each described by the same set of intrinsic attributes. The donkey training examples are used to learn a predictive model for donkeys, the kitten examples to learn a predictive model for kittens, and the rabbit examples to learn a predictive model for rabbits.Size 
Ears 
Cute 
Donkey </p>
<p>Big 
Big 
No 
1.0 </p>
<p>Small 
Big 
No 
0.3 </p>
<p>Predic5on 
Problem </p>
<p>Available Intrinsic 
Descriptors </p>
<p>Donkey </p>
<p>Predic5ve Model </p>
<ul>
<li></li>
</ul>
<p>Size 
Ears 
Cute 
Ki?en </p>
<p>Small 
Small 
Yes 
1.0 </p>
<p>Small 
Small 
No 
0.1 </p>
<p>Size 
Ears 
Cute 
Rabbit </p>
<p>Small 
Big 
Yes 
1.0 </p>
<p>Big 
Small 
Yes 
0.2 </p>
<ul>
<li></li>
<li></li>
</ul>
<p>Ki9en </p>
<p>Rabbit </p>
<p>Fig. 1 Standard machine learning. Here there are three related multi-task prediction prob-
lems: predicting whether an animal is a donkey or not, kitten or not, or rabbit or not. </p>
<p>Table 1
1QSAR Transformative Learning Results. Performance results as measured using the average RMSE after 10-fold cross-validation. In the table: 'Original rep.', 'TL -RF', and 'TL -Ridge' indicate performance using the original intrinsic data representation, transformed representation using random forest, and using ridge penalization, respectively; (%) indicates the performance improvement of each transformed representation, and is measured as RM SE original − RM SE T L /RM SE original * 100%Learning 
Method </p>
<p>Original 
rep. </p>
<p>TL -RF 
(%) 
TL -Ridge 
(%) </p>
<p>RF 
0.1643 
0.1478 
10.05 
0.1642 
0.06 
Ridge 
0.1654 
0.1655 
-0.06 
0.1701 
-2.84 
SVM 
0.1693 
0.1522 
10.10 
0.1693 
0.00 </p>
<p>Table 2
2Gene Expression Transformative Learning Results. Performance results were measured using the RMSE on a test set. Column names as inTable 1. Ridge). For the RF 500 trees were grown, a third of the total number of variables were considered at each split, and five observations were used in each terminal node. For Ridge the regularization parameter was chosen using 10-fold internal cross-validation. All the experiments were performed in RLearning 
Method </p>
<p>Original 
rep. </p>
<p>TL -RF 
(%) 
TL -Ridge 
(%) </p>
<p>RF 
0.0694 
0.0664 
4.32 
0.0675 
2.74 
Ridge 
0.0724 
0.0673 
7.04 
0.0726 
-0.27 </p>
<p>metadata. We converted the canonical smiles to the a 1,024 bit FCFP4 finger-
prints (fp) using RDKit (Landrum, 2016). For all perturbation conditions with 
valid canonical smiles as rows, we generated Boolean features with the follow-
ing columns: [ct 1 . . . ct 30 ][cs 1 . . . cs 14 ][d 1 . . . d 83 ][tp 1 . . . tp 3 ][f p 1 . . . f p 1024 ]. This 
generated a 107,152 1,155 experimental condition matrix, row and column 
identifiers included, which can be used as input for building models to predict 
the expression levels of the 978 genes using traditional machine learning tech-
niques. For each gene we generated both a train and test set with 7000 and 3000 
samples respectively. We did this by first randomly splitting the original per-
turbation condition data with 107,152 samples and their corresponding gene 
expression levels, into train and test sets of 70% and 30% respectively. Using 
this main train and test set, we randomly sampled train and test individuals 
for each gene. The gene expression levels for the 978 genes were normalised 
such that their values lie between 0.0 and 1.0. We used two learning algorithms 
for these experiments, Random Forests (RF) and Linear Regression with Ridge 
Penalization (</p>
<p>Table 3
3Meta-learning for Machine Learning Transformative Learning Results. Performance results as measured using the average RMSE after 10-fold cross-validation. Column names follow same naming as inTable 1.Learning 
Method </p>
<p>Original 
rep. </p>
<p>TL -RF 
(%) 
TL -Ridge (%) 
TL -SVM (%) </p>
<p>RF 
0.1184 
0.0526 
55.57 0.1236 
-4.39 0.0939 
20.69 
Ridge 
0.1403 
0.0710 
49.39 0.1356 
3.35 
0.1047 
25.37 
SVM 
0.1335 
0.0573 
57.08 0.1352 
-1.27 0.0972 
27.19 </p>
<p>Details can be found on https://www.openml.org/s/7.
Acknowledgements The authors would like to thank Rafael Mantovani for generating the original meta-learning data used in this study.
A framework for learning predictive structures from multiple tasks and unlabeled data. R K Ando, T Zhang, Journal of Machine Learning Research. 6R. K. Ando and T. Zhang. A framework for learning predictive structures from multiple tasks and unlabeled data. Journal of Machine Learning Research, 6(Nov):1817-1853, 2005.</p>
<p>Convex multi-task feature learning. A Argyriou, T Evgeniou, M Pontil, Machine Learning. 73A. Argyriou, T. Evgeniou, and M. Pontil. Convex multi-task feature learning. Machine Learning, 73(3):243-272, 2008.</p>
<p>Task clustering and gating for bayesian multitask learning. B Bakker, T Heskes, ; J Baxter, Proceedings of the eighth annual conference on Computational learning theory. the eighth annual conference on Computational learning theoryACM4Learning internal representationsB. Bakker and T. Heskes. Task clustering and gating for bayesian multitask learning. Journal of Machine Learning Research, 4(May):83-99, 2003. J. Baxter. Learning internal representations. In Proceedings of the eighth annual conference on Computational learning theory, pages 311-320. ACM, 1995.</p>
<p>Deep learning of representations for unsupervised and transfer learning. Y Bengio, Proceedings of ICML Workshop on Unsupervised and Transfer Learning. ICML Workshop on Unsupervised and Transfer LearningY. Bengio. Deep learning of representations for unsupervised and transfer learning. In Proceedings of ICML Workshop on Unsupervised and Transfer Learning, pages 17-36, 2012.</p>
<p>Multi-task learning for hiv therapy screening. S Bickel, J Bogojeska, T Lengauer, T Scheffer, Proceedings of the 25th international conference on Machine learning. the 25th international conference on Machine learningACMS. Bickel, J. Bogojeska, T. Lengauer, and T. Scheffer. Multi-task learning for hiv therapy screening. In Proceedings of the 25th international conference on Machine learning, pages 56-63. ACM, 2008.</p>
<p>mlr: Machine learning in r. B Bischl, M Lang, L Kotthoff, J Schiffner, J Richter, E Studerus, G Casalicchio, Z M Jones, Journal of Machine Learning Research. 17170B. Bischl, M. Lang, L. Kotthoff, J. Schiffner, J. Richter, E. Studerus, G. Casal- icchio, and Z. M. Jones. mlr: Machine learning in r. Journal of Machine Learning Research, 17(170):1-5, 2016. URL http://jmlr.org/papers/ v17/15-066.html.</p>
<p>Random forests. Machine learning. L Breiman, 45L. Breiman. Random forests. Machine learning, 45(1):5-32, 2001.</p>
<p>Heuristic DENDRAL: A program for generating explanatory hypotheses in organic chemistry. G Buchanan, E A Sutherland, Feigenbaum, Stanford UniversityBuchanan, G. Sutherland, and E. A. Feigenbaum. Heuristic DENDRAL: A program for generating explanatory hypotheses in organic chemistry. Stan- ford University, 1968.</p>
<p>Machine learning for molecular and materials science. K T Butler, D W Davies, H Cartwright, O Isayev, A Walsh, Nature. 5597715547K. T. Butler, D. W. Davies, H. Cartwright, O. Isayev, and A. Walsh. Machine learning for molecular and materials science. Nature, 559(7715):547, 2018.</p>
<p>Learning many related tasks at the same time with backpropagation. R Caruana, Advances in neural information processing systems. R. Caruana. Learning many related tasks at the same time with backpropaga- tion. In Advances in neural information processing systems, pages 657-664, 1995.</p>
<p>Qsar modeling: where have you been? where are you going to. R Caruana ; A. Cherkasov, E N Muratov, D Fourches, A Varnek, I I Baskin, M Cronin, J Dearden, P Gramatica, Y C Martin, R Todeschini, Journal of medicinal chemistry. 281Machine learningR. Caruana. Multitask learning. Machine learning, 28(1):41-75, 1997. A. Cherkasov, E. N. Muratov, D. Fourches, A. Varnek, I. I. Baskin, M. Cronin, J. Dearden, P. Gramatica, Y. C. Martin, R. Todeschini, et al. Qsar mod- eling: where have you been? where are you going to? Journal of medicinal chemistry, 57(12):4977-5010, 2014.</p>
<p>Support-vector networks. C Cortes, V Vapnik, Machine learning. 203C. Cortes and V. Vapnik. Support-vector networks. Machine learning, 20(3): 273-297, 1995.</p>
<p>Chemical predictive modelling to improve compound quality. J G Cumming, A M Davis, S Muresan, M Haeberlein, H Chen, Nature reviews Drug discovery. 1212948J. G. Cumming, A. M. Davis, S. Muresan, M. Haeberlein, and H. Chen. Chem- ical predictive modelling to improve compound quality. Nature reviews Drug discovery, 12(12):948, 2013.</p>
<p>Decaf: A deep convolutional activation feature for generic visual recognition. Y Donahue, O Jia, J Vinyals, N Hoffman, E Zhang, T Tzeng, Darrell, International conference on machine learning. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, E. Tzeng, and T. Dar- rell. Decaf: A deep convolutional activation feature for generic visual recog- nition. In International conference on machine learning, pages 647-655, 2014.</p>
<p>Dermatologist-level classification of skin cancer with deep neural networks. A Esteva, B Kuprel, R A Novoa, J Ko, S M Swetter, H M Blau, S Thrun, Nature. 5427639115A. Esteva, B. Kuprel, R. A. Novoa, J. Ko, S. M. Swetter, H. M. Blau, and S. Thrun. Dermatologist-level classification of skin cancer with deep neural networks. Nature, 542(7639):115, 2017.</p>
<p>Learning multiple tasks with kernel methods. T Evgeniou, C A Micchelli, M Pontil, Journal of Machine Learning Research. 6T. Evgeniou, C. A. Micchelli, and M. Pontil. Learning multiple tasks with kernel methods. Journal of Machine Learning Research, 6(Apr):615-637, 2005.</p>
<p>Ridge regression: Biased estimation for nonorthogonal problems. A Gaulton, A Hersey, M Nowotka, A P Bento, J Chambers, D Mendez, P Mutowo, F Atkinson, L J Bellis, E Cibrián-Uhalte, Nucleic acids research. A. E. Hoerl and R. W. Kennard45D1TechnometricsA. Gaulton, A. Hersey, M. Nowotka, A. P. Bento, J. Chambers, D. Mendez, P. Mutowo, F. Atkinson, L. J. Bellis, E. Cibrián-Uhalte, et al. The chembl database in 2017. Nucleic acids research, 45(D1):D945-D954, 2016. A. E. Hoerl and R. W. Kennard. Ridge regression: Biased estimation for nonorthogonal problems. Technometrics, 12(1):55-67, 1970.</p>
<p>Clustered multi-task learning: A convex formulation. J Jacob, F R Vert, Bach, Advances in neural information processing systems. Jacob, J.-p. Vert, and F. R. Bach. Clustered multi-task learning: A convex formulation. In Advances in neural information processing systems, pages 745-752, 2009.</p>
<p>Tree-guided group lasso for multi-task regression with structured sparsity. S Kim, E P Xing, ICML. S. Kim and E. P. Xing. Tree-guided group lasso for multi-task regression with structured sparsity. In ICML, pages 543-550, 2010.</p>
<p>The automation of science. R D King, J Rowland, S G Oliver, M Young, W Aubrey, E Byrne, M Liakata, M Markham, P Pir, L N Soldatova, Science. 3245923R. D. King, J. Rowland, S. G. Oliver, M. Young, W. Aubrey, E. Byrne, M. Li- akata, M. Markham, P. Pir, L. N. Soldatova, et al. The automation of science. Science, 324(5923):85-89, 2009.</p>
<p>Data portal for the library of integrated network-based cellular signatures (lincs) program: integrated access to diverse large-scale cellular perturbation response data. A Koleti, R Terryn, V Stathias, C Chung, D J Cooper, J P Turner, D Vidović, M Forlin, T T Kelley, A Durso, Nucleic acids research. 46D1A. Koleti, R. Terryn, V. Stathias, C. Chung, D. J. Cooper, J. P. Turner, D. Vi- dović, M. Forlin, T. T. Kelley, A. DUrso, et al. Data portal for the library of integrated network-based cellular signatures (lincs) program: integrated access to diverse large-scale cellular perturbation response data. Nucleic acids research, 46(D1):D558-D566, 2017.</p>
<p>Imagenet classification with deep convolutional neural networks. A Krizhevsky, I Sutskever, G E Hinton, Advances in neural information processing systems. A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems, pages 1097-1105, 2012.</p>
<p>Rdkit: open-source cheminformatics. G Landrum, G. Landrum. Rdkit: open-source cheminformatics http://www. rdkit. org, 2016.</p>
<p>Deep learning. nature. Y Lecun, G Bengio, Hinton, 521436LeCun, Y. Bengio, and G. Hinton. Deep learning. nature, 521(7553):436, 2015.</p>
<p>Multi-task learning for cross-platform sirna efficacy prediction: an in-silico study. Q Liu, V W Xu, H Zheng, Z Xue, Q Cao, Yang, BMC bioinformatics. 111181Liu, Q. Xu, V. W. Zheng, H. Xue, Z. Cao, and Q. Yang. Multi-task learning for cross-platform sirna efficacy prediction: an in-silico study. BMC bioinformatics, 11(1):181, 2010.</p>
<p>. C Martin, Tautomerism, Σ Hammett, Qsar , Journal of computer-aided molecular design. 246-7C. Martin. Tautomerism, hammett σ, and qsar. Journal of computer-aided molecular design, 24(6-7):613-616, 2010.</p>
<p>New drugs cost us $2.6 billion to develop. A Mullard, A. Mullard. New drugs cost us $2.6 billion to develop, 2014.</p>
<p>Meta-qsar: a large-scale application of meta-learning to drug design and discovery. N Olier, G R Sadawi, J Bickerton, C Vanschoren, L Grosan, R D Soldatova, King, Machine Learning. 107Olier, N. Sadawi, G. R. Bickerton, J. Vanschoren, C. Grosan, L. Soldatova, and R. D. King. Meta-qsar: a large-scale application of meta-learning to drug design and discovery. Machine Learning, 107(1):285-311, 2018.</p>
<p>Extended-connectivity fingerprints. D Rogers, M Hahn, Journal of chemical information and modeling. 505D. Rogers and M. Hahn. Extended-connectivity fingerprints. Journal of chem- ical information and modeling, 50(5):742-754, 2010.</p>
<p>Artificial intelligence: a modern approach. Malaysia; Pearson Education Limited. J Russell, P Norvig, J. Russell and P. Norvig. Artificial intelligence: a modern approach. Malaysia; Pearson Education Limited,, 2016.</p>
<p>Distilling free-form natural laws from experimental data. science. M Schmidt, H Lipson, 324M. Schmidt and H. Lipson. Distilling free-form natural laws from experimental data. science, 324(5923):81-85, 2009.</p>
<p>Automating drug discovery. G Schneider, Nature Reviews Drug Discovery. 17297G. Schneider. Automating drug discovery. Nature Reviews Drug Discovery, 17(2):97, 2017.</p>
<p>Planning chemical syntheses with deep neural networks and symbolic ai. M H Segler, M Preuss, M P Waller, Nature. 5557698604M. H. Segler, M. Preuss, and M. P. Waller. Planning chemical syntheses with deep neural networks and symbolic ai. Nature, 555(7698):604, 2018.</p>
<p>Cnn features off-the-shelf: an astounding baseline for recognition. A Sharif Razavian, H Azizpour, J Sullivan, S Carlsson, Proceedings of the IEEE conference on computer vision and pattern recognition workshops. the IEEE conference on computer vision and pattern recognition workshopsA. Sharif Razavian, H. Azizpour, J. Sullivan, and S. Carlsson. Cnn features off-the-shelf: an astounding baseline for recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition workshops, pages 806-813, 2014.</p>
<p>Mastering the game of go with deep neural networks and tree search. D Silver, A Huang, C J Maddison, A Guez, L Sifre, G Van Den Driessche, J Schrittwieser, I Antonoglou, V Panneershelvam, M Lanctot, nature. 5297587484D. Silver, A. Huang, C. J. Maddison, A. Guez, L. Sifre, G. Van Den Driessche, J. Schrittwieser, I. Antonoglou, V. Panneershelvam, M. Lanctot, et al. Mas- tering the game of go with deep neural networks and tree search. nature, 529(7587):484, 2016.</p>
<p>R: A language and environment for statistical computing. C Team, C. Team et al. R: A language and environment for statistical computing. 2013.</p>
<p>Learning one more thing. S Thrun, T M Mitchell, ; Carnegie-Mellon Univ Pittsburgh Pa Dept Of Computer Science, Technical reportS. Thrun and T. M. Mitchell. Learning one more thing. Technical report, CARNEGIE-MELLON UNIV PITTSBURGH PA DEPT OF COMPUTER SCIENCE, 1994.</p>
<p>Learning to learn: Introduction and overview. S Thrun, L Pratt, Learning to learn. SpringerS. Thrun and L. Pratt. Learning to learn: Introduction and overview. In Learning to learn, pages 3-17. Springer, 1998.</p>
<p>Meta-learning: A survey. J Vanschoren, arXiv:1810.03548arXiv preprintJ. Vanschoren. Meta-learning: A survey. arXiv preprint arXiv:1810.03548, 2018.</p>
<p>OpenML: networked science in machine learning. J Vanschoren, J N Van Rijn, B Bischl, L Torgo, ACM SIGKDD Explorations Newsletter. 152J. Vanschoren, J. N. Van Rijn, B. Bischl, and L. Torgo. OpenML: networked science in machine learning. ACM SIGKDD Explorations Newsletter, 15(2): 49-60, 2014.</p>
<p>Leveraging sequence classification by taxonomy-based multitask learning. J Widmer, Y Leiva, G Altun, Rätsch, Annual International Conference on Research in Computational Molecular Biology. SpringerWidmer, J. Leiva, Y. Altun, and G. Rätsch. Leveraging sequence clas- sification by taxonomy-based multitask learning. In Annual International Conference on Research in Computational Molecular Biology, pages 522- 534. Springer, 2010.</p>
<p>Multi-platform gene-expression mining and marker gene analysis. International journal of data mining and bioinformatics. H Xu, Q Xue, Yang, 5Xu, H. Xue, and Q. Yang. Multi-platform gene-expression mining and marker gene analysis. International journal of data mining and bioinfor- matics, 5(5):485-503, 2011.</p>
<p>Multi-task learning for classification with dirichlet process priors. X Xue, L Liao, B Carin, Krishnapuram, Journal of Machine Learning Research. 8Xue, X. Liao, L. Carin, and B. Krishnapuram. Multi-task learning for classification with dirichlet process priors. Journal of Machine Learning Research, 8(Jan):35-63, 2007.</p>
<p>How transferable are features in deep neural networks?. J Yosinski, J Clune, Y Bengio, H Lipson, Advances in neural information processing systems. J. Yosinski, J. Clune, Y. Bengio, and H. Lipson. How transferable are features in deep neural networks? In Advances in neural information processing systems, pages 3320-3328, 2014.</p>
<p>Multi-modal multi-task learning for joint prediction of multiple regression and classification variables in alzheimer's disease. D Zhang, A D N Shen, Initiative, NeuroImage. 592Zhang, D. Shen, A. D. N. Initiative, et al. Multi-modal multi-task learn- ing for joint prediction of multiple regression and classification variables in alzheimer's disease. NeuroImage, 59(2):895-907, 2012.</p>
<p>A multi-task learning formulation for predicting disease progression. J Zhou, L Yuan, J Liu, J Ye, Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining. the 17th ACM SIGKDD international conference on Knowledge discovery and data miningACMJ. Zhou, L. Yuan, J. Liu, and J. Ye. A multi-task learning formulation for predicting disease progression. In Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 814-822. ACM, 2011.</p>            </div>
        </div>

    </div>
</body>
</html>