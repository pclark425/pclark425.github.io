<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8685 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8685</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8685</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-156.html">extraction-schema-156</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <p><strong>Paper ID:</strong> paper-214605613</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2003.08978v2.pdf" target="_blank">Generating new concepts with hybrid neuro-symbolic models</a></p>
                <p><strong>Paper Abstract:</strong> Human conceptual knowledge supports the ability to generate novel yet highly structured concepts, and the form of this conceptual knowledge is of great interest to cognitive scientists. One tradition has emphasized structured knowledge, viewing concepts as embedded in intuitive theories or organized in complex symbolic knowledge structures. A second tradition has emphasized statistical knowledge, viewing conceptual knowledge as an emerging from the rich correlational structure captured by training neural networks and other statistical models. In this paper, we explore a synthesis of these two traditions through a novel neuro-symbolic model for generating new concepts. Using simple visual concepts as a testbed, we bring together neural networks and symbolic probabilistic programs to learn a generative model of novel handwritten characters. Two alternative models are explored with more generic neural network architectures. We compare each of these three models for their likelihoods on held-out character classes and for the quality of their productions, finding that our hybrid model learns the most convincing representation and generalizes further from the training observations.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8685.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8685.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Structured symbolic (programs)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Structured symbolic representations (programs, grammars, hierarchies, intuitive-theory style structures)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts are represented as explicit symbolic structures (programs, grammars, hierarchies) that encode compositional and causal relations among parts; learning and generalization are cast as induction over these symbolic hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>Structured symbolic representation (programs/grammars)</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Represents concepts as compositional symbolic expressions (programs, grammars, hierarchies) that explicitly encode parts, relations, and causal generative procedures; a concept is functionally a program that, when executed, generates observable exemplars.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>symbolic / theory-based</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Few-shot concept learning, generative concept synthesis (Omniglot character generation), causal/compositional generalization</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Prior work (e.g., BPL) shows that program-like, compositional representations support strong few-shot learning and can generate coherent new concepts; the paper cites these models as accounting for compositional and causal generalization but notes they often impose simplifying parametric assumptions that limit modeling of rich correlations in raw stimulus spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Contrasted with purely statistical neural representations: symbolic/program representations provide strong compositional/causal inductive bias (favoring systematic generalization) but are limited in capturing complex, nonparametric correlations; hybrid (neuro-symbolic) models are proposed to combine strengths of both.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Symbolic models (as instantiated in BPL) make rigid parametric assumptions (e.g., stroke independence priors) and thus can fail to capture the rich correlational and stylistic structure present in human drawings; this limits realism of unconditional samples.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Symbolic, program-like representations provide the necessary inductive structure to account for compositional and causal aspects of conceptual knowledge and support flexible generative generalization, but need to be augmented (e.g., with statistical components) to capture real-world correlational structure.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generating new concepts with hybrid neuro-symbolic models', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8685.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8685.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Statistical / distributed</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Statistical (distributed) representations learned by neural networks</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Conceptual knowledge is embodied in richly correlated, distributed latent representations acquired from data by neural networks, capturing emergent patterns and invariances rather than explicit symbolic rules.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>Statistical / distributed representation (neural-network latent embeddings)</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Represents concepts as high-dimensional distributed codes (latent vectors, recurrent states) learned from correlated observations; knowledge emerges from training dynamics and encodes statistical regularities rather than explicit compositional programs.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>distributed / statistical</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Generative modeling of strokes/characters (Omniglot), held-out log-likelihood on novel classes, sample diversity and nearest-neighbor novelty analyses</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Generic neural architectures (Baseline LSTM, H-LSTM) capture correlational structure and in some easier within-alphabet generalization (character-splits) perform well, but they generalize less well to novel alphabets and produce samples that often closely mirror training exemplars; they lack explicit causal/compositional structure, limiting systematic generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Compared to symbolic/program representations, distributed representations are better at modeling rich nonparametric correlations but worse at systematic compositional generalization; hybrid neuro-symbolic model aims to combine both.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Purely statistical models can overfit or memorize training exemplars (exemplar-like behavior), and have documented difficulty with systematic compositional generalization and tasks requiring explicit causal/compositional reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Distributed representations can capture complex stylistic and correlational structure present in human data, making them valuable for realistic generative samples, but they need structural inductive biases to match human-like compositional generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generating new concepts with hybrid neuro-symbolic models', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8685.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8685.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Neuro-Symbolic Hybrid (Full NS)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Full Neuro-Symbolic model (Full NS)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid generative model that uses a probabilistic program over stroke parts and a symbolic renderer combined with neural subnetworks (CNNs, LSTM with attention) to generate strokes conditioned on the current rendered canvas, integrating explicit compositional/causal structure with neural capture of correlational detail.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>Neuro-symbolic hybrid representation (program + distributed components)</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Represents concepts functionally as a symbolic probabilistic program that sequences parts (strokes) and relations, while subcomponents (location predictor, stroke generator) are implemented as neural networks that model complex, nonparametric correlations conditioned on rendered state; the canvas after each part acts as memory mediating dependencies.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>hybrid (symbolic + distributed)</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Held-out generalization to novel alphabets (alphabet-splits and holdout set), unconditional generation of novel characters, qualitative novelty (nearest-neighbor) analyses, log-likelihood on held-out classes</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Full NS achieved the best generalization (lowest negative log-likelihood) on alphabet-splits and on the held-out evaluation set, and its samples were more structurally coherent while being less direct copies of training exemplars (fewer samples closely mirrored nearest training neighbors) compared to purely neural baselines and BPL; qualitatively produced diverse, plausible novel characters.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Empirically outperformed two generic neural baselines (H-LSTM and Baseline LSTM) on the more stringent cross-alphabet and held-out tests; performed better than BPL at capturing correlational richness while retaining compositionality; favored by evidence when test concepts deviate substantially from training examples.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Although it enforces compositional/causal structure, the Full NS model restricts arbitrary information flow between parts (unlike monolithic neural nets) which could limit some dependencies; design choices (e.g., renderer as an intermediate) impose modeling constraints that may not capture all human strategies; results are on simple visual concepts (Omniglot), so generality to more complex domains is untested.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Demonstrates that combining explicit compositional/causal structure with neural components that model complex correlations yields representations that better match human-like creative generalization; supports the claim that neuro-symbolic formats can explain both structural inductive biases and rich stylistic variation in conceptual knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generating new concepts with hybrid neuro-symbolic models', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8685.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8685.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bayesian Program Learning (BPL)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bayesian Program Learning (BPL)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A parametric Bayesian model that represents characters as probabilistic programs composed of reusable parts and simple parametric distributions, demonstrating strong few-shot concept learning and the ability to sample new concepts from the program prior.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Human-level concept learning through probabilistic program induction</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>Probabilistic program / Bayesian program representation</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Represents concepts as probabilistic generative programs over parts and motor primitives, with explicit symbolic structure and parametric priors (e.g., stroke independence assumptions), enabling Bayesian inference over program hypotheses given observations.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>symbolic / probabilistic-program</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Few-shot learning on Omniglot, unconditional generation of novel characters, qualitative human-like sample comparisons</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>BPL captures compositional and causal structure and supports human-level few-shot learning; however, as noted in the paper, its parametric assumptions (e.g., largely independent stroke priors) limit its ability to capture the rich correlational structure and stylistic coherence of human drawings, yielding less realistic unconditional samples than hybrid models.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>BPL (symbolic) excels at compositional/few-shot generalization but underperforms at modeling fine-grained correlations compared to neuro-enhanced models; the Full NS hybrid aims to retain BPL's compositional strengths while improving correlational fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Simplifying parametric assumptions lead to generated characters that often lack rich correlation structure; independence assumptions about strokes limit realism of samples.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Program induction-style symbolic representations are powerful for explaining compositional and causal aspects of human concept learning, but need enhancements to model nonparametric stylistic correlations for realistic generation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generating new concepts with hybrid neuro-symbolic models', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8685.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e8685.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Exemplar-based representation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Exemplar-based representation / instance-memory</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts are represented as collections of observed exemplars (memory of instances), and generalization arises from similarity-based retrieval and recombination of stored examples rather than from explicit compositional rules.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>Exemplar-based representation</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Functionally, conceptual knowledge consists of stored exemplars and a similarity metric; new productions are generated by retrieving and possibly blending or perturbing nearest stored instances rather than by executing symbolic generative programs.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>instance-based / exemplar</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Nearest-neighbor similarity analyses of generated samples, character-splits generalization where within-alphabet exemplars may suffice</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The Baseline LSTM's strong performance in the easier 'character splits' and the observation that many of its generated samples closely mirrored nearest training examples suggest exemplar-like behavior; nearest-neighbor analyses showed Baseline/H-LSTM often produced samples that closely mimic training exemplars, whereas Full NS produced fewer direct mirrors.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Exemplar-like behavior can produce high within-domain likelihoods and realistic samples but fails at out-of-domain systematic generalization compared to symbolic or hybrid models; Full NS shows better generalization to novel alphabets than exemplar-leaning baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Exemplar representations struggle when test concepts deviate substantially from stored instances (e.g., novel alphabets) and cannot easily account for compositional recombination of parts to create genuinely novel structured concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Exemplar mechanisms can account for some aspects of human-like reproduction and stylistic consistency but are insufficient alone to explain creative compositional generalization; models that combine exemplar statistics with compositional structure are more plausible for human conceptual creativity.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generating new concepts with hybrid neuro-symbolic models', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8685.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e8685.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Intuitive theories / theory-based</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Intuitive theories / theory-based representations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts are embedded within broader intuitive theories that provide causal, functional, and role-based background knowledge, enabling explanation-based and theory-driven generalization beyond observed correlations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>Theory-based (intuitive theories) representation</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Represents concepts as nodes in a network of causal/functional beliefs (intuitive theories) that specify roles, mechanisms, and constraints; conceptual reasoning uses these background theories to guide inductive inferences and creative hypothesis construction.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>theory-based / structured</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Explanatory generalization, creative synthesis (e.g., generating novel recipes or plausible novel characters), accounts of conceptual coherence and substitution judgments</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The paper cites the tradition that theory-based representations explain how people understand roles, causal procedures, and allowable substitutions—supporting creative generalization (e.g., chef example)—and motivates the need for models that encode causal/compositional knowledge to explain human imaginative behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Theory-based accounts emphasize causal and functional constraints beyond what statistical correlations provide; the paper argues hybrids that explicitly encode causal/compositional structure (as in Full NS) better capture theory-like knowledge than pure statistical models.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Intuitive-theory style representations can be difficult to specify and learn from raw high-dimensional data without strong inductive biases or symbolic structure; purely theory-based parametric implementations may oversimplify real-world statistical structure.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Intuitive theories supply the high-level causal/compositional inductive biases necessary for creative, structured generalization; implementing these theories in hybrid models enables both explanation-driven inference and realistic data-driven variance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generating new concepts with hybrid neuro-symbolic models', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Human-level concept learning through probabilistic program induction <em>(Rating: 2)</em></li>
                <li>How to grow a mind: Statistics, structure, and abstraction <em>(Rating: 2)</em></li>
                <li>A rational analysis of rule-based concept learning <em>(Rating: 1)</em></li>
                <li>A neural representation of sketch drawings <em>(Rating: 2)</em></li>
                <li>The discovery of structural form <em>(Rating: 2)</em></li>
                <li>The role of theories in conceptual coherence <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8685",
    "paper_id": "paper-214605613",
    "extraction_schema_id": "extraction-schema-156",
    "extracted_data": [
        {
            "name_short": "Structured symbolic (programs)",
            "name_full": "Structured symbolic representations (programs, grammars, hierarchies, intuitive-theory style structures)",
            "brief_description": "Concepts are represented as explicit symbolic structures (programs, grammars, hierarchies) that encode compositional and causal relations among parts; learning and generalization are cast as induction over these symbolic hypotheses.",
            "citation_title": "",
            "mention_or_use": "mention",
            "representational_format_name": "Structured symbolic representation (programs/grammars)",
            "representational_format_description": "Represents concepts as compositional symbolic expressions (programs, grammars, hierarchies) that explicitly encode parts, relations, and causal generative procedures; a concept is functionally a program that, when executed, generates observable exemplars.",
            "format_type": "symbolic / theory-based",
            "cognitive_task_or_phenomenon": "Few-shot concept learning, generative concept synthesis (Omniglot character generation), causal/compositional generalization",
            "key_findings": "Prior work (e.g., BPL) shows that program-like, compositional representations support strong few-shot learning and can generate coherent new concepts; the paper cites these models as accounting for compositional and causal generalization but notes they often impose simplifying parametric assumptions that limit modeling of rich correlations in raw stimulus spaces.",
            "comparison_with_other_formats": "Contrasted with purely statistical neural representations: symbolic/program representations provide strong compositional/causal inductive bias (favoring systematic generalization) but are limited in capturing complex, nonparametric correlations; hybrid (neuro-symbolic) models are proposed to combine strengths of both.",
            "limitations_or_counter_evidence": "Symbolic models (as instantiated in BPL) make rigid parametric assumptions (e.g., stroke independence priors) and thus can fail to capture the rich correlational and stylistic structure present in human drawings; this limits realism of unconditional samples.",
            "theoretical_claims_or_implications": "Symbolic, program-like representations provide the necessary inductive structure to account for compositional and causal aspects of conceptual knowledge and support flexible generative generalization, but need to be augmented (e.g., with statistical components) to capture real-world correlational structure.",
            "uuid": "e8685.0",
            "source_info": {
                "paper_title": "Generating new concepts with hybrid neuro-symbolic models",
                "publication_date_yy_mm": "2020-03"
            }
        },
        {
            "name_short": "Statistical / distributed",
            "name_full": "Statistical (distributed) representations learned by neural networks",
            "brief_description": "Conceptual knowledge is embodied in richly correlated, distributed latent representations acquired from data by neural networks, capturing emergent patterns and invariances rather than explicit symbolic rules.",
            "citation_title": "",
            "mention_or_use": "use",
            "representational_format_name": "Statistical / distributed representation (neural-network latent embeddings)",
            "representational_format_description": "Represents concepts as high-dimensional distributed codes (latent vectors, recurrent states) learned from correlated observations; knowledge emerges from training dynamics and encodes statistical regularities rather than explicit compositional programs.",
            "format_type": "distributed / statistical",
            "cognitive_task_or_phenomenon": "Generative modeling of strokes/characters (Omniglot), held-out log-likelihood on novel classes, sample diversity and nearest-neighbor novelty analyses",
            "key_findings": "Generic neural architectures (Baseline LSTM, H-LSTM) capture correlational structure and in some easier within-alphabet generalization (character-splits) perform well, but they generalize less well to novel alphabets and produce samples that often closely mirror training exemplars; they lack explicit causal/compositional structure, limiting systematic generalization.",
            "comparison_with_other_formats": "Compared to symbolic/program representations, distributed representations are better at modeling rich nonparametric correlations but worse at systematic compositional generalization; hybrid neuro-symbolic model aims to combine both.",
            "limitations_or_counter_evidence": "Purely statistical models can overfit or memorize training exemplars (exemplar-like behavior), and have documented difficulty with systematic compositional generalization and tasks requiring explicit causal/compositional reasoning.",
            "theoretical_claims_or_implications": "Distributed representations can capture complex stylistic and correlational structure present in human data, making them valuable for realistic generative samples, but they need structural inductive biases to match human-like compositional generalization.",
            "uuid": "e8685.1",
            "source_info": {
                "paper_title": "Generating new concepts with hybrid neuro-symbolic models",
                "publication_date_yy_mm": "2020-03"
            }
        },
        {
            "name_short": "Neuro-Symbolic Hybrid (Full NS)",
            "name_full": "Full Neuro-Symbolic model (Full NS)",
            "brief_description": "A hybrid generative model that uses a probabilistic program over stroke parts and a symbolic renderer combined with neural subnetworks (CNNs, LSTM with attention) to generate strokes conditioned on the current rendered canvas, integrating explicit compositional/causal structure with neural capture of correlational detail.",
            "citation_title": "here",
            "mention_or_use": "use",
            "representational_format_name": "Neuro-symbolic hybrid representation (program + distributed components)",
            "representational_format_description": "Represents concepts functionally as a symbolic probabilistic program that sequences parts (strokes) and relations, while subcomponents (location predictor, stroke generator) are implemented as neural networks that model complex, nonparametric correlations conditioned on rendered state; the canvas after each part acts as memory mediating dependencies.",
            "format_type": "hybrid (symbolic + distributed)",
            "cognitive_task_or_phenomenon": "Held-out generalization to novel alphabets (alphabet-splits and holdout set), unconditional generation of novel characters, qualitative novelty (nearest-neighbor) analyses, log-likelihood on held-out classes",
            "key_findings": "Full NS achieved the best generalization (lowest negative log-likelihood) on alphabet-splits and on the held-out evaluation set, and its samples were more structurally coherent while being less direct copies of training exemplars (fewer samples closely mirrored nearest training neighbors) compared to purely neural baselines and BPL; qualitatively produced diverse, plausible novel characters.",
            "comparison_with_other_formats": "Empirically outperformed two generic neural baselines (H-LSTM and Baseline LSTM) on the more stringent cross-alphabet and held-out tests; performed better than BPL at capturing correlational richness while retaining compositionality; favored by evidence when test concepts deviate substantially from training examples.",
            "limitations_or_counter_evidence": "Although it enforces compositional/causal structure, the Full NS model restricts arbitrary information flow between parts (unlike monolithic neural nets) which could limit some dependencies; design choices (e.g., renderer as an intermediate) impose modeling constraints that may not capture all human strategies; results are on simple visual concepts (Omniglot), so generality to more complex domains is untested.",
            "theoretical_claims_or_implications": "Demonstrates that combining explicit compositional/causal structure with neural components that model complex correlations yields representations that better match human-like creative generalization; supports the claim that neuro-symbolic formats can explain both structural inductive biases and rich stylistic variation in conceptual knowledge.",
            "uuid": "e8685.2",
            "source_info": {
                "paper_title": "Generating new concepts with hybrid neuro-symbolic models",
                "publication_date_yy_mm": "2020-03"
            }
        },
        {
            "name_short": "Bayesian Program Learning (BPL)",
            "name_full": "Bayesian Program Learning (BPL)",
            "brief_description": "A parametric Bayesian model that represents characters as probabilistic programs composed of reusable parts and simple parametric distributions, demonstrating strong few-shot concept learning and the ability to sample new concepts from the program prior.",
            "citation_title": "Human-level concept learning through probabilistic program induction",
            "mention_or_use": "mention",
            "representational_format_name": "Probabilistic program / Bayesian program representation",
            "representational_format_description": "Represents concepts as probabilistic generative programs over parts and motor primitives, with explicit symbolic structure and parametric priors (e.g., stroke independence assumptions), enabling Bayesian inference over program hypotheses given observations.",
            "format_type": "symbolic / probabilistic-program",
            "cognitive_task_or_phenomenon": "Few-shot learning on Omniglot, unconditional generation of novel characters, qualitative human-like sample comparisons",
            "key_findings": "BPL captures compositional and causal structure and supports human-level few-shot learning; however, as noted in the paper, its parametric assumptions (e.g., largely independent stroke priors) limit its ability to capture the rich correlational structure and stylistic coherence of human drawings, yielding less realistic unconditional samples than hybrid models.",
            "comparison_with_other_formats": "BPL (symbolic) excels at compositional/few-shot generalization but underperforms at modeling fine-grained correlations compared to neuro-enhanced models; the Full NS hybrid aims to retain BPL's compositional strengths while improving correlational fidelity.",
            "limitations_or_counter_evidence": "Simplifying parametric assumptions lead to generated characters that often lack rich correlation structure; independence assumptions about strokes limit realism of samples.",
            "theoretical_claims_or_implications": "Program induction-style symbolic representations are powerful for explaining compositional and causal aspects of human concept learning, but need enhancements to model nonparametric stylistic correlations for realistic generation.",
            "uuid": "e8685.3",
            "source_info": {
                "paper_title": "Generating new concepts with hybrid neuro-symbolic models",
                "publication_date_yy_mm": "2020-03"
            }
        },
        {
            "name_short": "Exemplar-based representation",
            "name_full": "Exemplar-based representation / instance-memory",
            "brief_description": "Concepts are represented as collections of observed exemplars (memory of instances), and generalization arises from similarity-based retrieval and recombination of stored examples rather than from explicit compositional rules.",
            "citation_title": "",
            "mention_or_use": "mention",
            "representational_format_name": "Exemplar-based representation",
            "representational_format_description": "Functionally, conceptual knowledge consists of stored exemplars and a similarity metric; new productions are generated by retrieving and possibly blending or perturbing nearest stored instances rather than by executing symbolic generative programs.",
            "format_type": "instance-based / exemplar",
            "cognitive_task_or_phenomenon": "Nearest-neighbor similarity analyses of generated samples, character-splits generalization where within-alphabet exemplars may suffice",
            "key_findings": "The Baseline LSTM's strong performance in the easier 'character splits' and the observation that many of its generated samples closely mirrored nearest training examples suggest exemplar-like behavior; nearest-neighbor analyses showed Baseline/H-LSTM often produced samples that closely mimic training exemplars, whereas Full NS produced fewer direct mirrors.",
            "comparison_with_other_formats": "Exemplar-like behavior can produce high within-domain likelihoods and realistic samples but fails at out-of-domain systematic generalization compared to symbolic or hybrid models; Full NS shows better generalization to novel alphabets than exemplar-leaning baselines.",
            "limitations_or_counter_evidence": "Exemplar representations struggle when test concepts deviate substantially from stored instances (e.g., novel alphabets) and cannot easily account for compositional recombination of parts to create genuinely novel structured concepts.",
            "theoretical_claims_or_implications": "Exemplar mechanisms can account for some aspects of human-like reproduction and stylistic consistency but are insufficient alone to explain creative compositional generalization; models that combine exemplar statistics with compositional structure are more plausible for human conceptual creativity.",
            "uuid": "e8685.4",
            "source_info": {
                "paper_title": "Generating new concepts with hybrid neuro-symbolic models",
                "publication_date_yy_mm": "2020-03"
            }
        },
        {
            "name_short": "Intuitive theories / theory-based",
            "name_full": "Intuitive theories / theory-based representations",
            "brief_description": "Concepts are embedded within broader intuitive theories that provide causal, functional, and role-based background knowledge, enabling explanation-based and theory-driven generalization beyond observed correlations.",
            "citation_title": "",
            "mention_or_use": "mention",
            "representational_format_name": "Theory-based (intuitive theories) representation",
            "representational_format_description": "Represents concepts as nodes in a network of causal/functional beliefs (intuitive theories) that specify roles, mechanisms, and constraints; conceptual reasoning uses these background theories to guide inductive inferences and creative hypothesis construction.",
            "format_type": "theory-based / structured",
            "cognitive_task_or_phenomenon": "Explanatory generalization, creative synthesis (e.g., generating novel recipes or plausible novel characters), accounts of conceptual coherence and substitution judgments",
            "key_findings": "The paper cites the tradition that theory-based representations explain how people understand roles, causal procedures, and allowable substitutions—supporting creative generalization (e.g., chef example)—and motivates the need for models that encode causal/compositional knowledge to explain human imaginative behavior.",
            "comparison_with_other_formats": "Theory-based accounts emphasize causal and functional constraints beyond what statistical correlations provide; the paper argues hybrids that explicitly encode causal/compositional structure (as in Full NS) better capture theory-like knowledge than pure statistical models.",
            "limitations_or_counter_evidence": "Intuitive-theory style representations can be difficult to specify and learn from raw high-dimensional data without strong inductive biases or symbolic structure; purely theory-based parametric implementations may oversimplify real-world statistical structure.",
            "theoretical_claims_or_implications": "Intuitive theories supply the high-level causal/compositional inductive biases necessary for creative, structured generalization; implementing these theories in hybrid models enables both explanation-driven inference and realistic data-driven variance.",
            "uuid": "e8685.5",
            "source_info": {
                "paper_title": "Generating new concepts with hybrid neuro-symbolic models",
                "publication_date_yy_mm": "2020-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Human-level concept learning through probabilistic program induction",
            "rating": 2,
            "sanitized_title": "humanlevel_concept_learning_through_probabilistic_program_induction"
        },
        {
            "paper_title": "How to grow a mind: Statistics, structure, and abstraction",
            "rating": 2,
            "sanitized_title": "how_to_grow_a_mind_statistics_structure_and_abstraction"
        },
        {
            "paper_title": "A rational analysis of rule-based concept learning",
            "rating": 1,
            "sanitized_title": "a_rational_analysis_of_rulebased_concept_learning"
        },
        {
            "paper_title": "A neural representation of sketch drawings",
            "rating": 2,
            "sanitized_title": "a_neural_representation_of_sketch_drawings"
        },
        {
            "paper_title": "The discovery of structural form",
            "rating": 2,
            "sanitized_title": "the_discovery_of_structural_form"
        },
        {
            "paper_title": "The role of theories in conceptual coherence",
            "rating": 1,
            "sanitized_title": "the_role_of_theories_in_conceptual_coherence"
        }
    ],
    "cost": 0.0121155,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Generating new concepts with hybrid neuro-symbolic models</p>
<p>Reuben Feinman reuben.feinman@nyu.edu 
Center for Neural Science
Department of Psychology and Center for Data Science
New York University
Brenden M. Lake</p>
<p>New York University</p>
<p>Generating new concepts with hybrid neuro-symbolic models
Neural networkscompositionalitycausalitygenerative models
Human conceptual knowledge supports the ability to generate novel yet highly structured concepts, and the form of this conceptual knowledge is of great interest to cognitive scientists. One tradition has emphasized structured knowledge, viewing concepts as embedded in intuitive theories or organized in complex symbolic knowledge structures. A second tradition has emphasized statistical knowledge, viewing conceptual knowledge as an emerging from the rich correlational structure captured by training neural networks and other statistical models. In this paper, we explore a synthesis of these two traditions through a novel neuro-symbolic model for generating new concepts. Using simple visual concepts as a testbed, we bring together neural networks and symbolic probabilistic programs to learn a generative model of novel handwritten characters. Two alternative models are explored with more generic neural network architectures. We compare each of these three models for their likelihoods on held-out character classes and for the quality of their productions, finding that our hybrid model learns the most convincing representation and generalizes further from the training observations.</p>
<p>Introduction</p>
<p>People can synthesize new concepts in imaginative ways; architects design new houses, chefs invent new recipes, and entrepreneurs create new business models. The resulting productions exhibit novel variations but maintain important structural consistencies with known entities. In contrast, state-of-the-art generative models from machine learning struggle with creative imagination, producing samples that either closely mimic the training data or that exhibit anomalous characteristics . How do people create novel yet coherent new concepts? How can we understand these abilities in computational terms?</p>
<p>Human conceptual knowledge plays a central role in creative generalization. A chef knows not only a repertoire of recipes, but also understands that recipes are built from reusable ingredients (e.g. carrots, flour, butter), and that these ingredients satisfy specific roles (thickening, seasoning, greasing). Furthermore, a chef understands which ingredients can substitute for others (e.g. butter for oil when greasing) and which should never be combined (e.g. ketchup and milk). In addition, they understand that recipes are composed of reusable causal procedures (cutting, whisking, browning), and they know how to compose these procedures in terms of order and substitutability. This causal and compositional knowledge is essential to understanding a culinary concept, as opposed to merely executing it, and is essential to a chef's ability to create new culinary concepts such as "carrots tartar" or "pea guacamole."</p>
<p>There have been two traditions of work on computational models of conceptual knowledge. The first tradition emphasizes "structured knowledge" for capturing relations between concepts and correlations between conceptual features, viewing concepts as embedded in intuitive theories (Murphy &amp; Medin, 1985) or capturing structured knowledge through symbolic representations such as hierarchies, trees, grammars and programs (Kemp &amp; Tenenbaum, 2008, 2009Tenenbaum et al., 2011). This tradition has prioritized the compositional and causal nature of conceptual knowledge, as emphasized through accounts of concept learning as program induction (Goodman et al., 2008;Stuhlmuller et al., 2010;Lake et al., 2015;Goodman et al., 2015;Ellis et al., 2018;Lake &amp; Piantadosi, 2019). The Bayesian Program Learning (BPL) framework (Lake et al., 2015), for example, demonstrates how to learn programs from images to express the causal and compositional nature of concepts and background knowledge. Although these models offer a convincing account for how strong inductive biases support flexible generalization, they often make simplifying and rigid parametric assumptions about the distributions of concepts in pursuit of a structured representation. As a result, they so far have been unsuccessful in characterizing the most complex correlations and invariances associated with human concepts in raw, highdimensional stimulus spaces.</p>
<p>The second tradition in models of conceptual knowledge emphasizes "statistical knowledge," a more amorphous form of background knowledge that is often not amenable to symbolic description. In the statistics view, conceptual knowledge manifests as complex systems of patterns and correlations recorded from observations. The meaning of a word, for example, can be derived from its patterns of co-occurrance with other words (Deerwester et al., 1990). Similarly, latent representations of objects and other sensory stimuli can be derived from "suspicious coincidences" noted in the data (Barlow, 1989). The statistics view emphasizes emergence, where conceptual knowledge emerges from the interaction of simpler processes, as operationalized through training neural network architectures (McClelland, 2010). Although a powerful modeling tool, standard neural networks do not explicitly model the compositional and causal structure of concepts. As result, they have difficulty generalizing to examples that vary systematically from training (Marcus, 2003;Lake &amp; Baroni, 2018), and to novel tasks, especially those that demand more generative and creative abilities (Lake et al., 2017.</p>
<p>Our goal in this paper is to explore generative models of concepts at the interface of these structured and statistical traditions, offering new ways of synthesizing key ideas from each. Previous efforts to integrate these traditions have demonstrated ways of performing statistical inference over structured representations . This includes models of concept learning as Bayesian inference over fully-symbolic expressions in formal logical (Goodman et al., 2008;Piantadosi et al., 2016), or models of inductive reasoning supported by structured intuitive theories (Kemp &amp; Tenenbaum, 2009). In accounts of this nature, statistics is primary in selecting between structured symbolic hypotheses (Kemp &amp; Tenenbaum, 2008;Perfors et al., 2011;Lake et al., 2015;Lake &amp; Piantadosi, 2019), while only secondary in selecting the constrained parametric distributions encapsulated in those hypotheses (Gaussians, multinomials, etc.).</p>
<p>Here we aim to more thoroughly integrate the structured and statistical traditions through hybrid neuro-symbolic generative models. Our goal is to devise a causal generative model with explicit compositional structure, and with complex correlations represented implicitly through neural networks rather than simple parametric distributions. We use simple visual concepts -handwritten characters from the world's languages -as a case study for exploring neurosymbolic models of concept generation. The Omniglot dataset (Lake et al., 2015) of handwritten characters provides an excellent preliminary modeling environment: it contains a large number of natural, simple concepts that people learn and use, and it has been explored extensively in prior work from both cognitive science and AI. Following the mixture density network framework for handwriting generation (Graves, 2013), we explore three distinct generative neural architectures, varying the strength and form of inductive bias imposed on the model, including their position on the neurosymbolic spectrum and the fidelity in which compositionality and causality are presented. We evaluate the generalization capacity of these models by comparing their log-likelihoods on a holdout set of characters. Furthermore, we analyze the samples produced by each model, looking for characters that are qualitatively consistent but sufficiently dissimilar from the training set. We find that a hybrid neuro-symbolic architecture with the strongest form of compositional structure exhibits the best generalization performance, and that it generates characters that are highly consistent with human drawings. In contrast, our generic neural models exhibit weaker performance on the holdout set, and they produce characters that more closely mimic the training examples.</p>
<p>Related Work</p>
<p>In the machine learning community, there have been a number of works studying generative neural network models for handwritten characters, including DRAW (Gregor et al., 2015), AIR (Eslami et al., 2016) and SPIRAL (Ganin et al., 2018). Although these models learn a procedure to generate new characters, they do not use the human drawing data from Omniglot, and therefore the generative process may not reflect the true causal processes of human character production. Our goal is different in that we aim to model the causal process of human handwriting directly from drawing data. Ha &amp; Eck (2018) introduced a neural network architecture called Sketch-RNN to model human drawing data for simple objects like cats, firetrucks, and windmills. Although their goal loosely resembles our own, the Sketch-RNN model is trained on just a single class of objects at one time (e.g. "cat"), and it receives 70,000 examples from the class. In contrast, our motivation is to model human conceptual knowledge of handwriting concepts in general. This background knowledge plays a central role in creative generalization, enabling people to synthesize new concepts that deviate from the observed entities. We train our models on many character classes at once, providing only 20 training examples of each class and asking them to generate new character concepts. The Sketch-RNN model has not been applied in this way.</p>
<p>Most related to our work is the Bayesian Program Learning (BPL) approach of Lake et al. (2015) that was also applied to the simple visual concepts in Omniglot. BPL is a parametric Bayesian model that captures causal, compositional structure in human background knowledge of handwriting, and shows that these ingredients are important for few-shot learning of new character concepts. Beyond supporting fewshot learning, the BPL character prior can also generate new character concepts by unconditional sampling. Although a powerful demonstration of compositional representation, the BPL parametric model makes many simplifying assumptions about characters. For example, it assumes that strokes in a character are generated largely independently from each other in the prior (although they are strongly correlated in the posterior). As result, new characters generated by the model often lack the rich correlation structure of human drawings. We build on this work and develop a new neuro-symbolic model that represents the compositional structure of characters while using neural networks to capture richer correlations.</p>
<p>Omniglot Case Study</p>
<p>We use simple visual concepts as a case study for modeling conceptual structure and developing generative models of concepts. The Omniglot dataset contains human drawings of characters from 50 unique alphabets, providing a large set of cognitively natural concepts that are simple enough for evaluating models (Lake et al., 2015. In our experiments, we use drawings from the Omniglot background set to train our models, which contains 30 alphabets and a total of 19,280 unique drawings. We also use 10 alphabets from the Omniglot evaluation set as a holdout set for quantitative evaluations, reserving the remaining 10 alphabets for future work on few-shot classification.</p>
<p>In the drawing data, a stroke is represented as a variablelength sequence of pen locations {z 1 , ..., z T }, with z i ∈ R 2 (Fig. 2, left). As a pre-processing step, we convert each stroke into a minimal spline representation using least-squares optimization ( Fig. 2, right), borrowing the B-spline tools from Lake et al. (2015). The number of spline control points depends on the stroke complexity and is determined by a resid-  GenerateCharacter consists of sequentially reading from and rendering to an image canvas, which is initialized to zero. At each time step, the current canvas I is fed to procedure GenerateStroke, which produces a stroke sample. The canvas is first processed by the location model, a CNN-MLP architecture that processes the image and returns a Gaussian mixture model (GMM) distribution for the starting location of the next stroke y. The location y is then sampled and passed along with I to the stroke model. The stroke model processes I with a CNN and feeds the embedding to an LSTM with attention. The LSTM samples a stroke trajectory x sequentially one offset at a time using GMM outputs. The sampled stroke is passed to a symbolic renderer, and the updated image canvas is then processed by a termination model that decides whether to continue the character sample.
GenerateStroke(I) location model p(y | I) stroke model p(x | y, I) CNN MLP CNN LSTM y I I I I, y attention p(Δ 1 ) p(Δ 2 | Δ 1 ) p(Δ T | Δ 1:T−1 ) … y ∼ p ( y | I ) I, y, x x ∼ p ( x | y , I ) procedure GENERATECHARACTER I 0 . Initialize
ual threshold. Furthermore, we removed small strokes from the data using a threshold on the trajectory length. These processing steps help suppress noise and emphasize signal in the character drawings. Our generative models are trained to produce character drawings, where each drawing is represented as an ordered set of splines (strokes). The number of strokes, and the number of spline coordinates per stroke, are allowed to vary. </p>
<p>Neuro-Symbolic Model</p>
<p>Our primary interest is to test whether a hybrid neurosymbolic model can capture the compositional, causal structure in a large corpus of simple character concepts. The architecture and sampling procedure of our hybrid model, which we call the "Full Neuro-Symbolic" (Full NS) model, is given in Fig. 1. Compared to generic neural networks, the Full NS model lies closer to structure on the structure-statistics spectrum, possessing a much stronger inductive bias. As in BPL (Lake et al., 2015), the generative model is a probabilistic program that captures real compositional and causal structure by sampling characters as a sequence of parts and locations/relations. Unlike BPL, the model has a symbolic engine that renders each part to an image canvas before producing the next one, and parts are generated using a powerful recurrent neural network that encodes and attends to the current canvas. Although correlations between parts can be captured through a process of rendering and then encoding, the model does not allow arbitrary information to flow between parts and variables as in monolithic neural networks. The Full NS model represents a character as a sequence of strokes, with each stroke decomposed into a starting location y t ∈ R 2 , conveying the first spline control point, and a stroke trajectory x t = {∆ 1 , ..., ∆ N }, conveying deltas between spline control points. It generates characters one stroke at a time, using a symbolic renderer as an intermediate processing step after forming each stroke. An image canvas I is used as a memory state to convey information about previous strokes. At each time step t, the next stroke's starting location and trajectory are sampled with procedure GenerateStroke. In this procedure, the current image canvas I is first read by the location model ( Fig. 1; bottom middle), a convolutional neural network (CNN) that processes the image and returns a probability distribution for starting location y t :
y t ∼ p(y t | I).
A visualization of the density p(y t | I) is given in Fig. 3, "Location Prediction." The starting location y t is then passed along with the image canvas I to the stroke model ( Fig. 1;  bottom right), a Long Short-Term Memory (LSTM) architecture with a CNN-based image attention mechanism inspired by Xu et al. (2016). The stroke model samples the next stroke trajectory x t sequentially one offset at a time, selectively attending to different parts of the image canvas at each sample step and combining this information with the context of y t :</p>
<p>x t ∼ p(x t | y t , I). After each stroke, the model receives the current image canvas ("Input Canvas") and makes a series of predictions. Termination Prediction. First, the model predicts a termination probability p (blue bar), i.e. a probability of terminating the drawing. Location Prediction. Next, the model predicts a probability density for the next stroke's starting location. The heatmap indicates the predicted density, and the hollow red dot indicates the ground-truth location. Stroke Prediction. Finally, the model predicts an auto-regressive probability density for the next stroke's trajectory (the "stroke"). Red dots indicate the previous control points, heatmaps indicate the predicted density for the next control point, and hollow red dot indicates the ground-truth next control point.</p>
<p>A visualization of the auto-regressive density p(x t | y t , I) is given in Fig. 3, "Stroke Prediction." Mixture Outputs. Both our location model and stroke model follow a technique from Graves (2013), who proposed to use neural networks with mixture outputs to model handwriting data. The parameters θ = {π 1:K , µ 1:K , σ 1:K , ρ 1:K } output by our network specify a Gaussian mixture model (GMM) with K components ( Fig. 1; colored ellipsoids), where π k ∈ (0, 1) is the mixture weight of the k th component, µ k ∈ R 2 its means, σ k ∈ R 2 + its standard deviations, and ρ k ∈ (−1, 1) its correlation. In our location model, a single GMM describes the distribution p(y t | I). In our stroke model, the LSTM outputs one GMM at each timestep, describing p(∆ t |∆ 1:t−1 , y t , I).</p>
<p>Training. Our Full NS model provides a density function which can be used to score the log-likelihood for any character drawing. We train the model to maximize the loglikelihood (minimize log-loss) of the training set drawings, using mini-batch gradient descent with a batch size of 200 and the Adam update rule.</p>
<p>Alternative Models</p>
<p>In addition to our Full NS model, we explored two alternative models with more generic neural network architectures. In each alternative, we lesioned key structural ingredients of the Full NS model, hoping to test the importance of these ingredients to model performance.</p>
<p>Hierarchical LSTM. As one alternative neural model, we explored a hierarchical recurrent architecture (Sordoni et al., 2015;Ling et al., 2016;Chung et al., 2017), which we denote "Hierarchical LSTM" (H-LSTM). Like our Full NS architecture, the H-LSTM model is trained on causal data demonstrating how people actually produce drawings of characters. In addition, it models the compositional structure of characters by separating them into explicit stroke parts, which defines the hierarchy in the hierarchical LSTM. Unlike our Full NS model, however, the H-LSTM has no renderer and thus lacks any explicit causal knowledge of how motor actions become raw images of inked characters. Instead, information about the previous strokes is written to memory via recurrent connections and gating mechanisms. These transformations can propagate arbitrary correlations, and they must be learned entirely from the data. Specifically, at each time step t, the previous stroke x t−1 is read by a stroke encoder f enc , a bi-directional LSTM that processes the stroke and returns a fixed-length vector (red box in Fig. 4). This vector is then passed as an input to the character LSTM along with previous location y t−1 and previous hidden state h t−1 :
h t = f LSTM (y t−1 , f enc (x t−1 ), h t−1 ).
The new hidden state h t is then fed to the location model p(y t | h t ), a multi-layer perceptron that outputs a GMM distribution for the next stroke's starting location y t (green box in Fig. 4). The location is sampled from this distribution and passed as an input along with h t to the stroke model p(x t | h t , y t ), an LSTM that samples a stroke trajectory one offset at a time with GMM outputs (yellow box in Fig. 4):
y t ∼ p(y t | h t ) x t ∼ p(x t | h t , y t ).
Baseline LSTM. A second alternative is even less structured and represents the most purely statistical architecture we examined. For this model, we explored a naive unrolled LSTM, denoted "Baseline." This model is a reproduction of the unconditional version of Sketch-RNN (Ha &amp; Eck, 2018, Sec 3.3). Similar to Full NS and H-LSTM, the Baseline LSTM is trained on causal data demonstrating the process of producing character; however, it does not explicitly take the compositional structure of characters into account in the architecture itself. Instead, it uses a single RNN to model a character as one long sequence of pen actions with stroke breaks.</p>
<p>Following Sketch-RNN, we expand the binary pen state variable v t ∈ {0, 1} from Graves (2013) to a ternary variable v t ∈ {0, 1, 2} to handle multi-stroke drawings. Value 0 indicates that we are continuing the current stroke, 1 that we are ending the current stroke and starting a new one, and 2 that we are ending the drawing. The initial hidden and cell states of the LSTM are set to zero, and at each time step t, the previous offset ∆ t−1 , previous pen state v t−1 , and previous hidden state h t−1 are fed as inputs to the LSTM, which outputs new hidden state h t :
h t = f LSTM (∆ t−1 , v t−1 , h t−1 ).
An output layer receives h t and returns a categorical distribution for next pen state v t , as well as a GMM distribution for next offset ∆ t :
θ v = f v (h t ), v t ∼ p(v t | θ v ) θ ∆ = f ∆ (h t ), ∆ t ∼ p(∆ t | θ ∆ ).</p>
<p>Experiments</p>
<p>We evaluated the creative generalizations of our 3 neural network models using both quantitative and qualitative analyses. Each of our models estimates a probability density function for characters from training examples. This density function can be used to compute likelihoods for held-out characters and to generate new character samples. A generative model for characters that exhibits creative generalization should produce high likelihood scores for novel character concepts from  Table 1: Test losses from our 3 models. Losses indicate the average negative log-likelihood per test character (lower is better). In our alphabet splits task, we divide the background set into train/test splits such that the model must generalize to new characters from novel alphabets. In our "character splits task, we divide the background set such that the model must generalize to new characters from familiar alphabets. In our "holdout task, we provide the entire background set for training and use the held-out evaluation setwhich contains new characters from novel alphabets-for testing.</p>
<p>held-out classes. In addition, the model should generate new characters that are sufficiently dissimilar from the training examples, but that are structurally consistent with ground truth. In our quantitative analysis, we tested our models for their likelihood performance on novel character classes using a rigorous set of experiments with different train/test splits. In our qualitative analysis, we inspected character samples produced by each model, comparing them to characters from both BPL and ground truth and looking at nearest neighbors from the training set.</p>
<p>Evaluation on Held-Out Concepts</p>
<p>Methods. In our quantitative analysis, we evaluated our models for two different forms of likelihood generalization, corresponding to different train/test splits. In the first generalization task, denoted "character splits," we asked whether our models could generalize to new character classes from familiar alphabets. We created 3 train/test splits from the Omniglot background set, sampling 80% of characters per alphabet for train and 20% for test. In our second task, denoted "alphabet splits," we asked whether our models could generalize to new character classes from novel alphabets. We again sampled 3 train/test splits of size 80-20, this time splitting by alphabet. In both the "character splits" and "alphabet splits" tasks, we explored multiple hyperparameter configurations for our models, varying parameters such as the number of hidden layers, number of units per layer, and dropout probability. 1 Average validation loss across splits was used to select the best configuration for each model in each task. We then took our best configurations in each task and reported their validation losses on all 3 splits. As a final quantitative analysis, we tested our models on one additional task that extends the "alphabet splits" task. Our motivation was to provide a more rigorous analysis using a completely withheld test set as per standard practice in machine learning evaluations. We re-trained our best configurations of each model on the entire background set, using the hyperparameters selected from our "alphabet splits" task. We then reported losses on the evaluation set, which contains character drawings from 10 novel alphabets. Results. Results from our CV-splits experiments are given in Table 1, "Alphabet Splits" and "Character Splits." In our alphabet splits experiment, the Full NS model consistently outperformed its alternatives, exhibiting the best generalization performance in each of the 3 splits with losses of 13.77, 14.18 and 17.53, respectively (per character average). Thus, our neuro-symbolic architecture appears best equipped to capture overarching principles in handwriting concepts that generalize far outside of the training examples. In our character splits task, the Baseline LSTM exhibited best performance in 2 out of 3 splits, and the Full NS model in 1 of 3. The character splits test present a much easier generalization task, where exemplar-based learning could offer a suitable alternative to learning general structural principals. Although our naive Baseline model performs well, its lack of consistency across splits suggests that this model may rely on more of an exemplar-based technique for learning, which we investigate further in our sample analyses. Interestingly, the selected hyperparameter configuration for our Full NS model remained constant across the "alphabet" and "character" split tasks, whereas the configuration changed for both the Baseline and H-LSTM models.</p>
<p>Results for each model on the held-out set of characters are shown in Table 1, "Holdout." Similarly to the "alphabets" task, our Full NS model outperforms both alternative models on the holdout set, providing further support that this architecture learns the best general model of these simple visual concepts.</p>
<p>Generating New Concepts</p>
<p>Methods. In our qualitative analysis, we analyzed the 3 neural network models on their ability to produce novel visual concepts. We took our trained models from the previous experiment and sampled 36 characters from each model, following the model's causal generative procedure. In addition, we sampled 36 characters from the BPL character prior, and we selected 36 "ground truth" characters from Omniglot at random. Samples were then compared visually side-by-side.</p>
<p>As an additional qualitative analysis, we compared character samples from each model for their similarity to the training examples. Although the complexity and structural coherency of generated characters are important criteria, these observations alone provide insufficient evidence for a human- like generative process; a model that memorizes the training examples might produce samples with structural coherence and rich variations, but such a model does not account for the flexible ways that humans generate new concepts. In our second analysis, we took the character samples from our models and found the 5 most-similar training characters for each, using cosine distance in the last hidden layer of a CNN classifier as a metric space for perceptual similarity. The CNN was trained to classify characters from the Omniglot background set, a 964-way classification task.</p>
<p>Results. Fig. 5 shows samples from each of our three models, as well as from the BPL forward model 2 and from the Omniglot data (ground truth). Compared to BPL, the neuralenhanced models capture more correlational structure and character complexity. For instance, the Full NS model propagates stylistic and structural consistency across three strokes to form a Braille-like character, as shown by the sample in column 1, row 2. Fig. 6 Figure 7: Topologically-Organized character samples and their nearest Omniglot neighbors. We drew 100 character samples from our Full NS model and organized them into a 10x10 grid such that neighboring characters have similar drawing styles (left). We then found the "nearest neighbor" of each sample from the Omniglot character dataset and organized the neighbors into a corresponding 10x10 grid (right).</p>
<p>acters that closely mimic the nearest training examples in the majority (7/9 by our eyes) of cases. In contrast, our Full NS model produces only a few (3/9) characters that directly mirror the nearest training examples, suggesting that it can generalize further from the training observations.</p>
<p>To get an idea of the different character styles produced by our Full NS model, we sampled 100 characters from the model and organized them into a 10x10 grid such that neighboring characters have high perceptual similarity (Fig. 7, left). Characters were sampled at a lower level of stochasticity, using the temperature parameter proposed by Ha &amp; Eck (2018) to modify the entropy of the mixture density outputs (we used T = 0.5). The model produces characters in multiple distinct styles, with some having more angular, linebased structure and others relying on complex curves. In Fig.  7, (right) we plotted the most-similar Omniglot character for each sample in a corresponding grid. In many cases, samples from the model have a distinct style and are visually dissimilar from their nearest Omniglot neighbor.</p>
<p>Conclusion</p>
<p>We presented a new neuro-symbolic generative model of simple visual concepts. Our model successfully captures compositional and causal structure in handwritten character concepts, forming a representation that generalizes to new concepts. We tested our model by comparing its likelihood scores on a holdout set of novel characters, finding that it consistently outperforms two generic neural network alternatives when the test characters deviate significantly from the training examples. Furthermore, our generative model produces new character concepts with richer variations than simple parametric models, yet that remain structurally coherent and visually consistent with human productions.</p>
<p>Neuro-symbolic models offer a promising set of tools to express the rich background knowledge that enables creative imagination. These models can explain the nonparametric correlation structure embodied in conceptual knowledge while maintaining important inductive biases to account for the structured ways that people generate new concepts. We believe that models of this kind will be useful to explain a variety of human imaginative behaviors, such as when a chef creates the new recipe "pea guacamole." In future work, we'd like to explore applications of neuro-symbolic models to other types of concepts with varying complexity.</p>
<p>Figure 1 :
1Full neuro-symbolic (Full NS) model. Our Full NS model produces character samples one stroke at a time. The procedure</p>
<p>Figure 2 :
2Spline representation. Raw strokes (left) are converted into minimal splines (right) using least-squares optimization. Crosses (left) indicate pen locations and red dots (right) indicate spline control points.</p>
<p>Figure 3 :
3Predictions of the Full NS model for a test character.</p>
<p>Figure 4 :
4Hierarchical LSTM model. The model samples characters one stroke at a time, using a character-level LSTM as a memory state. At each time, the model samples a starting location for the next stroke from a location predictor (MLP), and a stroke trajectory from the stroke predictor (LSTM). These samples are then fed to the model as inputs for the next time, with the location fed directly and the trajectory processed by a stroke encoder (bi-directional LSTM).</p>
<p>Figure 5 :
5Character sample comparison. Characters generated by our Full NS, H-LSTM and Baseline LSTM models are shown side-byside, along with samples from the BPL forward model 2 as well as ground truth characters from Omniglot.</p>
<p>Figure 6 :
6Novelty of character samples. Character drawings sampled from each model were compared to their 5 nearest neighbors from the training set. Each row corresponds to one character sample from the model. The red box indicates the model sample, and the 5 nearest neighbors are shown in the succeeding columns.</p>
<p>shows a handful of character samples produced by each neural model plotted alongside their five nearest neighbors from the Omniglot training set. Both the H-LSTM and the Baseline LSTM models produce char-samples from Full NS 
model (T=0.5) </p>
<p>corresponding 
Omniglot neighbors </p>
<p>stroke key: </p>
<p>For details about hyperparameters, see Appendix A.
BPL character samples have been centered for better visual appearance; the actual samples often protrude outside of the image window. A more complex non-parametric BPL model was used in the visual Turing tests inLake et al. (2015) that has explicit re-use of character parts. Those samples were also centered.
AcknowledgementsWe thank Maxwell Nye, Josh Tenenbaum, Tuan-Anh Le, and Jay McClelland for helpful discussions regarding this work.Appendix A. Model HyperparametersHere we review the hyperparameters (HPs) used for each of our models, indicating which HPs were fixed and which were tuned. All neural networks with GMM output layers use 20 mixture components.Full NS. The Full NS model has 3 submodules: a location model, a stroke model, and a termination model. Each submodule uses a distinct CNN, and each receives an image canvas of size (28,28). The location and termination modelswhich return outputs for a single time step-each use a feedforward CNN architecture inspired byVinyals et al. (2016). The CNNs consist of a stack of 4 blocks, with each block i including a 3x3 convolution with K i filters, batch normalization, nonlinear activation f , 2x2 max-pooling, and dropout with rate p. These blocks are followed by a single fully-connected layer with D units, activation f and dropout p. Hyperparameters {K i }, f , p and D were selected from tuning. The stroke model uses a modified CNN architecture without spatial pooling, designed to convey high-resolution spatial information for visual attention. The CNN returns a feature map of size(64,14,14), which is then passed to an LSTM. The LSTM predicts the spline trajectory of the next stroke one offset at a time, attending to different parts of the feature map at each step. The HPs of the CNN were fixed, but the HPs of the LSTM were tuned, including the number of LSTM layers and number of units per layer.Hierarchical LSTM. The Hierarchical LSTM model has a character-level LSTM backbone and 3 submodules: a stroke encoder (BiLSTM), a location model (MLP), and a stroke model (LSTM). The number of LSTM layers, number of units per layer and dropout rate in the character-level LSTM were selected from tuning, but HPs of all submodules were fixed. The stroke encoder is a bidirectional LSTM with a single layer of 256 units. It outputs a fixed-length vector representation of the previous stroke, which is fed to the character LSTM as input. The location model is a 2-layer MLP that receives the current hidden state of the character LSTM and outputs a GMM for the next stroke's starting location. The stroke model is an LSTM with a single layer of 256 units and outputs a GMM at each time step for the next spline offset.Baseline LSTM. The Baseline LSTM is a single module. It has L LSTM layers, each with K units and dropout rate p. The values of L, K and p were selected from tuning.B. Samples with stroke decompositionInFig. 8, we show a larger collection of characters from our Full NS model, using color coding to convey the stroke composition of each sample. We produced character samples at two different levels of stochasticity, using a temperature parameter to modify the entropy of the mixture density outputs(Ha &amp; Eck, 2018, Eq.8). Samples are shown for temperature settings T = 1.0 and T = 0.5.
Unsupervised learning. H B Barlow, Neural Computation. 13Barlow, H. B. (1989). Unsupervised learning. Neural Computation, 1(3), 295-311.</p>
<p>Hierarchical multiscale recurrent neural networks. J Chung, S Ahn, Y Bengio, In ICLRChung, J., Ahn, S., &amp; Bengio, Y. (2017). Hierarchical multiscale recurrent neural networks. In ICLR.</p>
<p>Indexing by latent semantic analysis. S Deerwester, S T Dumais, G W Furnas, T K Landauer, R Harshman, JASIS. 41Deerwester, S., Dumais, S. T., Furnas, G. W., Landauer, T. K., &amp; Harshman, R. (1990). Indexing by latent semantic analysis. JASIS, 41, 391-407.</p>
<p>Learning to infer graphics programs from hand-drawn images. K Ellis, D Ritchie, A Solar-Lezama, J B Tenenbaum, NIPS. Ellis, K., Ritchie, D., Solar-lezama, A., &amp; Tenenbaum, J. B. (2018). Learning to infer graphics programs from hand-drawn images. In NIPS.</p>
<p>Attend, infer, repeat: Fast scene understanding with generative models. S M A Eslami, N Heess, T Weber, Y Tassa, D Szepesvari, K Kavukcuoglu, G E Hinton, NIPS. Eslami, S. M. A., Heess, N., Weber, T., Tassa, Y., Szepesvari, D., Kavukcuoglu, K., &amp; Hinton, G. E. (2016). Attend, infer, repeat: Fast scene understanding with generative models. In NIPS.</p>
<p>Synthesizing programs for images using reinforced adversarial learning. Y Ganin, T Kulkarni, I Babuschkin, S M A Eslami, O Vinyals, ICML. Ganin, Y., Kulkarni, T., Babuschkin, I., Eslami, S. M. A., &amp; Vinyals, O. (2018). Syn- thesizing programs for images using reinforced adversarial learning. In ICML.</p>
<p>A rational analysis of rule-based concept learning. N D Goodman, J B Tenenbaum, J Feldman, T L Griffiths, Cognitive Science. 32Goodman, N. D., Tenenbaum, J. B., Feldman, J., &amp; Griffiths, T. L. (2008). A rational analysis of rule-based concept learning. Cognitive Science, 32, 108-154.</p>
<p>Concepts in a probabilistic language of thought. N D Goodman, J B Tenenbaum, T Gerstenberg, The conceptual mind: New directions in the study of concepts. E. Margolis and S. LaurenceCambridge, MAMIT PressGoodman, N. D., Tenenbaum, J. B., &amp; Gerstenberg, T. (2015). Concepts in a proba- bilistic language of thought. In E. Margolis and S. Laurence (Ed.), The conceptual mind: New directions in the study of concepts (pp. 623-653). Cambridge, MA: MIT Press.</p>
<p>Generating sequences with recurrent neural networks. A Graves, arXiv:1308.0850arXiv preprintGraves, A. (2013). Generating sequences with recurrent neural networks. arXiv preprint arXiv:1308.0850.</p>
<p>DRAW: A recurrent neural network for image generation. K Gregor, I Danihelka, A Graves, D J Rezende, D Wierstra, ICML. Gregor, K., Danihelka, I., Graves, A., Rezende, D. J., &amp; Wierstra, D. (2015). DRAW: A recurrent neural network for image generation. In ICML.</p>
<p>A neural representation of sketch drawings. D Ha, D Eck, ICLR. Ha, D., &amp; Eck, D. (2018). A neural representation of sketch drawings. In ICLR.</p>
<p>The discovery of structural form. C Kemp, J B Tenenbaum, PNASKemp, C., &amp; Tenenbaum, J. B. (2008). The discovery of structural form. PNAS, 105(31), 10687-92.</p>
<p>Structured statistical models of inductive reasoning. C Kemp, J B Tenenbaum, Psychological Review. 116Kemp, C., &amp; Tenenbaum, J. B. (2009). Structured statistical models of inductive rea- soning. Psychological Review, 116, 20-58.</p>
<p>Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks. B M Lake, M Baroni, ICML. Lake, B. M., &amp; Baroni, M. (2018). Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks. In ICML.</p>
<p>B M Lake, S T Piantadosi, People Infer Recursive Visual Concepts from Just a Few Examples. Lake, B. M., &amp; Piantadosi, S. T. (2019). People Infer Recursive Visual Concepts from Just a Few Examples. Computational Brain &amp; Behavior.</p>
<p>Human-level concept learning through probabilistic program induction. B M Lake, R Salakhutdinov, J B Tenenbaum, Science. 350Lake, B. M., Salakhutdinov, R., &amp; Tenenbaum, J. B. (2015). Human-level concept learning through probabilistic program induction. Science, 350, 1332-1338.</p>
<p>The Omniglot challenge: A 3-year progress report. B M Lake, R Salakhutdinov, J B Tenenbaum, Behavioral Sciences. 29Lake, B. M., Salakhutdinov, R., &amp; Tenenbaum, J. B. (2019). The Omniglot challenge: A 3-year progress report. Behavioral Sciences, 29, 97-104.</p>
<p>Building machines that learn and think like people. B M Lake, T D Ullman, J B Tenenbaum, S J Gershman, Behavioral and Brain Sciences. 40253Lake, B. M., Ullman, T. D., Tenenbaum, J. B., &amp; Gershman, S. J. (2017). Building machines that learn and think like people. Behavioral and Brain Sciences, 40, E253.</p>
<p>Character-based neural machine translation. W Ling, I Trancoso, C Dyer, A Black, ICLR. Ling, W., Trancoso, I., Dyer, C., &amp; Black, A. (2016). Character-based neural machine translation. In ICLR.</p>
<p>The Algebraic Mind: Integrating Connectionism and Cognitive Science. G F Marcus, MIT PressCambridge, MAMarcus, G. F. (2003). The Algebraic Mind: Integrating Connectionism and Cognitive Science. Cambridge, MA: MIT Press.</p>
<p>Emergence in Cognitive Science. J L Mcclelland, Topics in Cognitive Science. 24McClelland, J. L. (2010). Emergence in Cognitive Science. Topics in Cognitive Science, 2(4), 751-770.</p>
<p>The role of theories in conceptual coherence. G L Murphy, D L Medin, Psychological Review. 923Murphy, G. L., &amp; Medin, D. L. (1985). The role of theories in conceptual coherence. Psychological Review, 92(3), 289-316.</p>
<p>The learnability of abstract syntactic principles. A Perfors, J B Tenenbaum, T Regier, Cognition. 1183Perfors, A., Tenenbaum, J. B., &amp; Regier, T. (2011). The learnability of abstract syntactic principles. Cognition, 118(3), 306-338.</p>
<p>The logical primitives of thought: Empirical foundations for compositional cognitive models. S T Piantadosi, J B Tenenbaum, N D Goodman, Psych. Rev. Piantadosi, S. T., Tenenbaum, J. B., &amp; Goodman, N. D. (2016). The logical primitives of thought: Empirical foundations for compositional cognitive models. Psych. Rev..</p>
<p>A hierarchical recurrent encoder-decoder for generative context-aware query suggestion. A Sordoni, Y Bengio, H Vahabi, C Lioma, J G Simonsen, J Y Nie, CIKM. Sordoni, A., Bengio, Y., Vahabi, H., Lioma, C., Simonsen, J. G., &amp; Nie, J. Y. (2015). A hierarchical recurrent encoder-decoder for generative context-aware query sugges- tion. In CIKM.</p>
<p>Learning Structured Generative Concepts. A Stuhlmuller, J B Tenenbaum, N D Goodman, In CogSciStuhlmuller, A., Tenenbaum, J. B., &amp; Goodman, N. D. (2010). Learning Structured Generative Concepts. In CogSci.</p>
<p>How to grow a mind: Statistics, structure, and abstraction. J B Tenenbaum, C Kemp, T L Griffiths, N D Goodman, Science. 3316022Tenenbaum, J. B., Kemp, C., Griffiths, T. L., &amp; Goodman, N. D. (2011). How to grow a mind: Statistics, structure, and abstraction. Science, 331(6022), 1279-1285.</p>
<p>Matching networks for one shot learning. O Vinyals, C Blundell, T Lillicrap, D Wierstra, NIPS. Vinyals, O., Blundell, C., Lillicrap, T., &amp; Wierstra, D. (2016). Matching networks for one shot learning. In NIPS.</p>
<p>Show, attend and tell: Neural image caption generation with visual attention. K Xu, J L Ba, R Kiros, K Cho, A Courville, R Salakhutdinov, . . Bengio, Y , ICML. Xu, K., Ba, J. L., Kiros, R., Cho, K., Courville, A., Salakhutdinov, R., . . . Bengio, Y. (2016). Show, attend and tell: Neural image caption generation with visual attention. In ICML.</p>            </div>
        </div>

    </div>
</body>
</html>