<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8290 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8290</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8290</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-152.html">extraction-schema-152</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <p><strong>Paper ID:</strong> paper-275212629</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2501.01203v2.pdf" target="_blank">HetGCoT: Heterogeneous Graph-Enhanced Chain-of-Thought LLM Reasoning for Academic Question Answering</a></p>
                <p><strong>Paper Abstract:</strong> Academic question answering (QA) in heterogeneous scholarly networks presents unique challenges requiring both structural understanding and interpretable reasoning. While graph neural networks (GNNs) capture structured graph information and large language models (LLMs) demonstrate strong capabilities in semantic comprehension, current approaches lack integration at the reasoning level. We propose HetGCoT, a framework enabling LLMs to effectively leverage and learn information from graphs to reason interpretable academic QA results. Our framework introduces three technical contributions: (1) a framework that transforms heterogeneous graph structural information into LLM-processable reasoning chains, (2) an adaptive metapath selection mechanism identifying relevant subgraphs for specific queries, and (3) a multi-step reasoning strategy systematically incorporating graph contexts into the reasoning process. Experiments on OpenAlex and DBLP datasets show our approach outperforms all sota baselines. The framework demonstrates adaptability across different LLM architectures and applicability to various scholarly question answering tasks.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8290.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8290.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HetGCoT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Heterogeneous Graph-Enhanced Chain-of-Thought</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework that converts heterogeneous graph structural patterns (metapaths) into confidence-weighted natural language reasoning chains and integrates them into a multi-step chain-of-thought pipeline for LLM-based academic question answering.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>HetGCoT (framework)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A hybrid system combining: (1) Heterogeneous Graph Transformer (HGT) node embeddings; (2) FastGTN to learn relation importance and score metapaths; (3) metapath naturalization (template-based NL descriptions with confidence weights); and (4) a 4-step chain-of-thought multi-step reasoning process consumed by a fine-tuned LLM (evaluated with different LLM backbones).</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['chain-of-thought (CoT) multi-step decomposition', 'metapath naturalization (graph -> natural language)', 'adaptive metapath selection (FastGTN learned importance weights)', 'structured multi-step reasoning (graph structure analysis, content analysis, collaboration analysis, answer generation)']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>HetGCoT first uses HGT embeddings to generate candidate metapath instances, scores them with FastGTN-learned relation importance weights, and transforms top metapaths into natural-language statements prefixed with confidence scores. These naturalized metapaths are presented to an LLM within a structured four-step CoT prompt: (1) Graph Structure Analysis, (2) Content Analysis, (3) Collaboration Analysis, (4) Answer Generation. The LLM is fine-tuned to condition answer generation on these metapath contexts weighted by confidence.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>both</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>The framework enforces structural diversity by stratified top-k selection from multiple metapath templates (k=5 per template). Ablations remove components/steps (e.g., HGT+CoT vs full HetGCoT, and removal of specific reasoning steps) to assess the contribution of each reasoning subcomponent; model-scale experiments test same framework across LLM sizes.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Custom academic QA benchmarks derived from OpenAlex and DBLP: (1) journal recommendation (primary), (2) authorship identification (paper-author reasoning), (3) collaboration discovery (author-author reasoning).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Journal recommendation (OpenAlex): Hit 96.48%, H@1 92.21%, F1 79.90%, NDCG 91.29%. Journal recommendation (DBLP): Hit 85.31%, H@1 83.70%, F1 64.55%, NDCG 83.49%. Authorship (OpenAlex): Hit 84.42%, H@1 74.12%, F1 82.22%, NDCG 90.00%. Collaboration (OpenAlex): Hit 58.79%, H@1 29.60%, F1 50.91%, NDCG 41.86%. (Full task breakdowns are reported in Tables 2 and 3 of the paper.)</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>Naturalized, confidence-weighted metapaths provide interpretable structural evidence that the LLM uses during CoT steps; the multi-step decomposition improves transparency and correctness; removing specific reasoning steps reduces performance (collaboration step removal had largest negative impact). Larger LLMs gain more from HetGCoT-provided graph contexts, indicating capacity-dependent utilization of structural reasoning cues.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>Integrating heterogeneous graph structural information as naturalized, confidence-weighted metapaths into a multi-step CoT process substantially improves LLM performance and interpretability on academic QA tasks, and adaptive metapath selection plus structured reasoning steps are critical contributors to the gains.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'HetGCoT: Heterogeneous Graph-Enhanced Chain-of-Thought LLM Reasoning for Academic Question Answering', 'publication_date_yy_mm': '2025-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8290.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8290.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4o mini</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4o mini (evaluated LLM backbone)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A generative pre-trained transformer used as the primary LLM backbone in experiments; fine-tuned on structured reasoning examples and prompted with the HetGCoT multi-step CoT templates.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4o mini</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A transformer-based LLM (commercial nomenclature used by authors) fine-tuned in the paper on structured academic QA CoT examples; used both in pure-LM settings and integrated with HetGCoT graph contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['chain-of-thought (CoT) prompting', 'fine-tuning on structured reasoning examples', 'integration with graph-derived naturalized metapaths (when used inside HetGCoT)']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>The paper reports GPT-4o mini run as (a) pure LM, (b) CoT-enabled LM via prompt engineering (system + user messages specifying four-step reasoning), and (c) fine-tuned with graph-derived metapath contexts. CoT is implemented via explicit multi-step prompts; metapaths are included as textual evidence prefixed by confidence scores.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>both</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Direct comparisons include: zero-shot (pure LM) vs. CoT prompting vs. HetGCoT integration (LLM + graph contexts). Ablation study contrasts HGT+CoT and full HetGCoT to quantify graph+CoT gains.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Journal recommendation (OpenAlex, DBLP) primarily; also evaluated on authorship and collaboration QA.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>GPT-4o mini (pure): Hit 69.80%, H@1 58.60%, F1 31.77%, NDCG 64.98% (OpenAlex). GPT-4o mini + CoT: Hit 75.14%, H@1 58.62%, F1 49.50%, NDCG 70.83% (OpenAlex). GPT-4o mini as LLM backbone inside HetGCoT achieved the framework's top results (see HetGCoT entry).</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>CoT prompting improves Hit and F1 compared with pure zero-shot outputs, but adding structured graph-derived evidence (HetGCoT) yields substantially larger gains and more interpretable explanations. The paper notes LLM output instability across runs and that fine-tuning improves but does not eliminate this.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>Chain-of-thought prompting improves performance over zero-shot LLMs, but structured integration of graph contexts via HetGCoT yields much larger performance improvements and interpretability gains.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'HetGCoT: Heterogeneous Graph-Enhanced Chain-of-Thought LLM Reasoning for Academic Question Answering', 'publication_date_yy_mm': '2025-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8290.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8290.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLaMA-3 8B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLaMA-3 8-billion parameter model (evaluated with CoT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open/academic family LLM used in experiments with CoT prompting and also evaluated under HetGCoT integration to test framework plug-and-play and scale effects.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-3 8B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A transformer-based 8B-parameter foundation model (LLaMA-3 family) evaluated with chain-of-thought prompting and with HetGCoT-provided graph contexts to measure adaptability and performance scaling.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['chain-of-thought (CoT) prompting', 'integration with HetGCoT graph contexts (in some experiments)']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>LLaMA-3 8B is evaluated with explicit CoT prompts (four-step reasoning) and as a backbone receiving the naturalized metapath contexts produced by HetGCoT. The implementations follow the same prompt templates and fine-tuning procedure described for other LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>both</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Compared zero-shot LLaMA-3 8B vs. LLaMA-3 8B + CoT and LLaMA-3 8B + HetGCoT (see Table 4 for model-adaptability results).</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Journal recommendation on OpenAlex (and DBLP in cross-dataset experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>LLaMA-3 8B + CoT (baseline in Table 2): Hit 71.23%, H@1 59.21%, F1 33.64%, NDCG 70.72% (OpenAlex). LLaMA-3 8B zero-shot: Hit 52.47% vs. +HetGCoT: Hit 75.33% (Table 4), showing large gains when combined with HetGCoT.</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>Larger foundation models (here LLaMA-3 8B) obtain larger absolute improvements from HetGCoT graph contexts compared to smaller models, suggesting model capacity affects how well graph-augmented reasoning is used.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>CoT helps LLaMA-3 8B over zero-shot baseline, and integrating graph-derived metapath contexts via HetGCoT substantially increases performance; model capacity amplifies the benefit.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'HetGCoT: Heterogeneous Graph-Enhanced Chain-of-Thought LLM Reasoning for Academic Question Answering', 'publication_date_yy_mm': '2025-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8290.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8290.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Graph+LLM baselines</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Graph-augmented LLM methods (GraphCoT, Graph of Thoughts, Think-on-Graph, GraphPrompter, PathRAG)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A set of prior methods that augment LLM reasoning with graph-structured information, used as comparative baselines in experiments against HetGCoT.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GraphCoT / Graph of Thoughts / Think-on-Graph / GraphPrompter / PathRAG</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Representative graph+LLM approaches: GraphCoT augments CoT by explicit reasoning on graph structure; Graph of Thoughts models reasoning process as graph search; Think-on-Graph executes deep reasoning directly on knowledge graphs; GraphPrompter uses soft prompts to incorporate graph features; PathRAG uses relational path-based retrieval for retrieval-augmented generation.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['graph-augmented chain-of-thought', 'graph-structured reasoning (reasoning-as-graph)', 'retrieval-augmented generation via relational paths', 'soft prompting of graph features']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>Each baseline supplies structural/graph evidence to LLMs in different manners: GraphCoT provides explicit graph-based reasoning steps; Graph of Thoughts frames the internal reasoning as a graph search; Think-on-Graph executes reasoning operations on knowledge graphs; GraphPrompter uses soft prompts encoding graph info; PathRAG retrieves relational paths as evidence for the LLM to condition on.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Paper includes these as direct comparative baselines on the same OpenAlex/DBLP journal recommendation tasks; performance is reported in Table 2 to contrast different graph+LLM integration strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Journal recommendation on OpenAlex and DBLP (same tasks as HetGCoT comparisons).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>OpenAlex (selected baselines): PathRAG Hit 76.87%, H@1 66.49%, F1 35.76%, NDCG 75.62%; GraphPrompter Hit 84.83%, H@1 82.68%, F1 72.37%, NDCG 83.79%; GraphCoT Hit 90.47%, H@1 88.25%, F1 75.39%, NDCG 89.59%; Graph of Thoughts Hit 92.57%, H@1 90.48%, F1 76.37%, NDCG 89.86%; Think-on-Graph Hit 92.85%, H@1 89.27%, F1 75.36%, NDCG 88.36%. HetGCoT outperforms all these baselines (see HetGCoT entry).</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>Graph-augmented LLM methods outperform pure GNNs and pure LLMs, indicating structural evidence is beneficial; however, HetGCoT's adaptive metapath selection and multi-step CoT naturalization produce superior performance and explanations. Different graph+LLM methods vary substantially in performance depending on how structural evidence is represented and integrated.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>While multiple prior graph+LLM approaches markedly improve over pure LLMs/GNNs, HetGCoT's particular strategy of adaptive metapath selection, confidence weighting, and naturalized CoT leads to the best observed performance on the paper's academic QA benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'HetGCoT: Heterogeneous Graph-Enhanced Chain-of-Thought LLM Reasoning for Academic Question Answering', 'publication_date_yy_mm': '2025-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on Graph Structures <em>(Rating: 2)</em></li>
                <li>Graph of Thoughts <em>(Rating: 2)</em></li>
                <li>Metapath of Thoughts: Verbalized metapaths in heterogeneous graph as contextual augmentation to LLM <em>(Rating: 2)</em></li>
                <li>Think-on-Graph: Deep and responsible reasoning of large language model with knowledge graph <em>(Rating: 2)</em></li>
                <li>PathRAG: Pruning graph-based retrieval augmented generation with relational paths <em>(Rating: 1)</em></li>
                <li>Can we soft prompt LLMs for graph learning tasks? <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8290",
    "paper_id": "paper-275212629",
    "extraction_schema_id": "extraction-schema-152",
    "extracted_data": [
        {
            "name_short": "HetGCoT",
            "name_full": "Heterogeneous Graph-Enhanced Chain-of-Thought",
            "brief_description": "A framework that converts heterogeneous graph structural patterns (metapaths) into confidence-weighted natural language reasoning chains and integrates them into a multi-step chain-of-thought pipeline for LLM-based academic question answering.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "HetGCoT (framework)",
            "model_description": "A hybrid system combining: (1) Heterogeneous Graph Transformer (HGT) node embeddings; (2) FastGTN to learn relation importance and score metapaths; (3) metapath naturalization (template-based NL descriptions with confidence weights); and (4) a 4-step chain-of-thought multi-step reasoning process consumed by a fine-tuned LLM (evaluated with different LLM backbones).",
            "reasoning_methods": [
                "chain-of-thought (CoT) multi-step decomposition",
                "metapath naturalization (graph -&gt; natural language)",
                "adaptive metapath selection (FastGTN learned importance weights)",
                "structured multi-step reasoning (graph structure analysis, content analysis, collaboration analysis, answer generation)"
            ],
            "reasoning_methods_description": "HetGCoT first uses HGT embeddings to generate candidate metapath instances, scores them with FastGTN-learned relation importance weights, and transforms top metapaths into natural-language statements prefixed with confidence scores. These naturalized metapaths are presented to an LLM within a structured four-step CoT prompt: (1) Graph Structure Analysis, (2) Content Analysis, (3) Collaboration Analysis, (4) Answer Generation. The LLM is fine-tuned to condition answer generation on these metapath contexts weighted by confidence.",
            "reasoning_diversity": "both",
            "reasoning_diversity_experimental_setup": "The framework enforces structural diversity by stratified top-k selection from multiple metapath templates (k=5 per template). Ablations remove components/steps (e.g., HGT+CoT vs full HetGCoT, and removal of specific reasoning steps) to assess the contribution of each reasoning subcomponent; model-scale experiments test same framework across LLM sizes.",
            "task_or_benchmark": "Custom academic QA benchmarks derived from OpenAlex and DBLP: (1) journal recommendation (primary), (2) authorship identification (paper-author reasoning), (3) collaboration discovery (author-author reasoning).",
            "performance_results": "Journal recommendation (OpenAlex): Hit 96.48%, H@1 92.21%, F1 79.90%, NDCG 91.29%. Journal recommendation (DBLP): Hit 85.31%, H@1 83.70%, F1 64.55%, NDCG 83.49%. Authorship (OpenAlex): Hit 84.42%, H@1 74.12%, F1 82.22%, NDCG 90.00%. Collaboration (OpenAlex): Hit 58.79%, H@1 29.60%, F1 50.91%, NDCG 41.86%. (Full task breakdowns are reported in Tables 2 and 3 of the paper.)",
            "qualitative_findings": "Naturalized, confidence-weighted metapaths provide interpretable structural evidence that the LLM uses during CoT steps; the multi-step decomposition improves transparency and correctness; removing specific reasoning steps reduces performance (collaboration step removal had largest negative impact). Larger LLMs gain more from HetGCoT-provided graph contexts, indicating capacity-dependent utilization of structural reasoning cues.",
            "explicit_comparison": false,
            "key_claims_or_conclusions": "Integrating heterogeneous graph structural information as naturalized, confidence-weighted metapaths into a multi-step CoT process substantially improves LLM performance and interpretability on academic QA tasks, and adaptive metapath selection plus structured reasoning steps are critical contributors to the gains.",
            "uuid": "e8290.0",
            "source_info": {
                "paper_title": "HetGCoT: Heterogeneous Graph-Enhanced Chain-of-Thought LLM Reasoning for Academic Question Answering",
                "publication_date_yy_mm": "2025-01"
            }
        },
        {
            "name_short": "GPT-4o mini",
            "name_full": "GPT-4o mini (evaluated LLM backbone)",
            "brief_description": "A generative pre-trained transformer used as the primary LLM backbone in experiments; fine-tuned on structured reasoning examples and prompted with the HetGCoT multi-step CoT templates.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-4o mini",
            "model_description": "A transformer-based LLM (commercial nomenclature used by authors) fine-tuned in the paper on structured academic QA CoT examples; used both in pure-LM settings and integrated with HetGCoT graph contexts.",
            "reasoning_methods": [
                "chain-of-thought (CoT) prompting",
                "fine-tuning on structured reasoning examples",
                "integration with graph-derived naturalized metapaths (when used inside HetGCoT)"
            ],
            "reasoning_methods_description": "The paper reports GPT-4o mini run as (a) pure LM, (b) CoT-enabled LM via prompt engineering (system + user messages specifying four-step reasoning), and (c) fine-tuned with graph-derived metapath contexts. CoT is implemented via explicit multi-step prompts; metapaths are included as textual evidence prefixed by confidence scores.",
            "reasoning_diversity": "both",
            "reasoning_diversity_experimental_setup": "Direct comparisons include: zero-shot (pure LM) vs. CoT prompting vs. HetGCoT integration (LLM + graph contexts). Ablation study contrasts HGT+CoT and full HetGCoT to quantify graph+CoT gains.",
            "task_or_benchmark": "Journal recommendation (OpenAlex, DBLP) primarily; also evaluated on authorship and collaboration QA.",
            "performance_results": "GPT-4o mini (pure): Hit 69.80%, H@1 58.60%, F1 31.77%, NDCG 64.98% (OpenAlex). GPT-4o mini + CoT: Hit 75.14%, H@1 58.62%, F1 49.50%, NDCG 70.83% (OpenAlex). GPT-4o mini as LLM backbone inside HetGCoT achieved the framework's top results (see HetGCoT entry).",
            "qualitative_findings": "CoT prompting improves Hit and F1 compared with pure zero-shot outputs, but adding structured graph-derived evidence (HetGCoT) yields substantially larger gains and more interpretable explanations. The paper notes LLM output instability across runs and that fine-tuning improves but does not eliminate this.",
            "explicit_comparison": true,
            "key_claims_or_conclusions": "Chain-of-thought prompting improves performance over zero-shot LLMs, but structured integration of graph contexts via HetGCoT yields much larger performance improvements and interpretability gains.",
            "uuid": "e8290.1",
            "source_info": {
                "paper_title": "HetGCoT: Heterogeneous Graph-Enhanced Chain-of-Thought LLM Reasoning for Academic Question Answering",
                "publication_date_yy_mm": "2025-01"
            }
        },
        {
            "name_short": "LLaMA-3 8B",
            "name_full": "LLaMA-3 8-billion parameter model (evaluated with CoT)",
            "brief_description": "An open/academic family LLM used in experiments with CoT prompting and also evaluated under HetGCoT integration to test framework plug-and-play and scale effects.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "LLaMA-3 8B",
            "model_description": "A transformer-based 8B-parameter foundation model (LLaMA-3 family) evaluated with chain-of-thought prompting and with HetGCoT-provided graph contexts to measure adaptability and performance scaling.",
            "reasoning_methods": [
                "chain-of-thought (CoT) prompting",
                "integration with HetGCoT graph contexts (in some experiments)"
            ],
            "reasoning_methods_description": "LLaMA-3 8B is evaluated with explicit CoT prompts (four-step reasoning) and as a backbone receiving the naturalized metapath contexts produced by HetGCoT. The implementations follow the same prompt templates and fine-tuning procedure described for other LLMs.",
            "reasoning_diversity": "both",
            "reasoning_diversity_experimental_setup": "Compared zero-shot LLaMA-3 8B vs. LLaMA-3 8B + CoT and LLaMA-3 8B + HetGCoT (see Table 4 for model-adaptability results).",
            "task_or_benchmark": "Journal recommendation on OpenAlex (and DBLP in cross-dataset experiments).",
            "performance_results": "LLaMA-3 8B + CoT (baseline in Table 2): Hit 71.23%, H@1 59.21%, F1 33.64%, NDCG 70.72% (OpenAlex). LLaMA-3 8B zero-shot: Hit 52.47% vs. +HetGCoT: Hit 75.33% (Table 4), showing large gains when combined with HetGCoT.",
            "qualitative_findings": "Larger foundation models (here LLaMA-3 8B) obtain larger absolute improvements from HetGCoT graph contexts compared to smaller models, suggesting model capacity affects how well graph-augmented reasoning is used.",
            "explicit_comparison": false,
            "key_claims_or_conclusions": "CoT helps LLaMA-3 8B over zero-shot baseline, and integrating graph-derived metapath contexts via HetGCoT substantially increases performance; model capacity amplifies the benefit.",
            "uuid": "e8290.2",
            "source_info": {
                "paper_title": "HetGCoT: Heterogeneous Graph-Enhanced Chain-of-Thought LLM Reasoning for Academic Question Answering",
                "publication_date_yy_mm": "2025-01"
            }
        },
        {
            "name_short": "Graph+LLM baselines",
            "name_full": "Graph-augmented LLM methods (GraphCoT, Graph of Thoughts, Think-on-Graph, GraphPrompter, PathRAG)",
            "brief_description": "A set of prior methods that augment LLM reasoning with graph-structured information, used as comparative baselines in experiments against HetGCoT.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GraphCoT / Graph of Thoughts / Think-on-Graph / GraphPrompter / PathRAG",
            "model_description": "Representative graph+LLM approaches: GraphCoT augments CoT by explicit reasoning on graph structure; Graph of Thoughts models reasoning process as graph search; Think-on-Graph executes deep reasoning directly on knowledge graphs; GraphPrompter uses soft prompts to incorporate graph features; PathRAG uses relational path-based retrieval for retrieval-augmented generation.",
            "reasoning_methods": [
                "graph-augmented chain-of-thought",
                "graph-structured reasoning (reasoning-as-graph)",
                "retrieval-augmented generation via relational paths",
                "soft prompting of graph features"
            ],
            "reasoning_methods_description": "Each baseline supplies structural/graph evidence to LLMs in different manners: GraphCoT provides explicit graph-based reasoning steps; Graph of Thoughts frames the internal reasoning as a graph search; Think-on-Graph executes reasoning operations on knowledge graphs; GraphPrompter uses soft prompts encoding graph info; PathRAG retrieves relational paths as evidence for the LLM to condition on.",
            "reasoning_diversity": "diverse",
            "reasoning_diversity_experimental_setup": "Paper includes these as direct comparative baselines on the same OpenAlex/DBLP journal recommendation tasks; performance is reported in Table 2 to contrast different graph+LLM integration strategies.",
            "task_or_benchmark": "Journal recommendation on OpenAlex and DBLP (same tasks as HetGCoT comparisons).",
            "performance_results": "OpenAlex (selected baselines): PathRAG Hit 76.87%, H@1 66.49%, F1 35.76%, NDCG 75.62%; GraphPrompter Hit 84.83%, H@1 82.68%, F1 72.37%, NDCG 83.79%; GraphCoT Hit 90.47%, H@1 88.25%, F1 75.39%, NDCG 89.59%; Graph of Thoughts Hit 92.57%, H@1 90.48%, F1 76.37%, NDCG 89.86%; Think-on-Graph Hit 92.85%, H@1 89.27%, F1 75.36%, NDCG 88.36%. HetGCoT outperforms all these baselines (see HetGCoT entry).",
            "qualitative_findings": "Graph-augmented LLM methods outperform pure GNNs and pure LLMs, indicating structural evidence is beneficial; however, HetGCoT's adaptive metapath selection and multi-step CoT naturalization produce superior performance and explanations. Different graph+LLM methods vary substantially in performance depending on how structural evidence is represented and integrated.",
            "explicit_comparison": true,
            "key_claims_or_conclusions": "While multiple prior graph+LLM approaches markedly improve over pure LLMs/GNNs, HetGCoT's particular strategy of adaptive metapath selection, confidence weighting, and naturalized CoT leads to the best observed performance on the paper's academic QA benchmarks.",
            "uuid": "e8290.3",
            "source_info": {
                "paper_title": "HetGCoT: Heterogeneous Graph-Enhanced Chain-of-Thought LLM Reasoning for Academic Question Answering",
                "publication_date_yy_mm": "2025-01"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on Graph Structures",
            "rating": 2,
            "sanitized_title": "graph_chainofthought_augmenting_large_language_models_by_reasoning_on_graph_structures"
        },
        {
            "paper_title": "Graph of Thoughts",
            "rating": 2,
            "sanitized_title": "graph_of_thoughts"
        },
        {
            "paper_title": "Metapath of Thoughts: Verbalized metapaths in heterogeneous graph as contextual augmentation to LLM",
            "rating": 2,
            "sanitized_title": "metapath_of_thoughts_verbalized_metapaths_in_heterogeneous_graph_as_contextual_augmentation_to_llm"
        },
        {
            "paper_title": "Think-on-Graph: Deep and responsible reasoning of large language model with knowledge graph",
            "rating": 2,
            "sanitized_title": "thinkongraph_deep_and_responsible_reasoning_of_large_language_model_with_knowledge_graph"
        },
        {
            "paper_title": "PathRAG: Pruning graph-based retrieval augmented generation with relational paths",
            "rating": 1,
            "sanitized_title": "pathrag_pruning_graphbased_retrieval_augmented_generation_with_relational_paths"
        },
        {
            "paper_title": "Can we soft prompt LLMs for graph learning tasks?",
            "rating": 1,
            "sanitized_title": "can_we_soft_prompt_llms_for_graph_learning_tasks"
        }
    ],
    "cost": 0.014232749999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>HetGCoT: Heterogeneous Graph-Enhanced Chain-of-Thought LLM Reasoning for Academic Question Answering
18 Jun 2025</p>
<p>Runsong Jia runsong.jia@uts.edu.au 
University of Technology Sydney
SydneyAustralia</p>
<p>Mengjia Wu mengjia.wu@uts.edu.au 
University of Technology Sydney
SydneyAustralia</p>
<p>Ying Ding ying.ding@ischool.utexas.edu 
University of Texas at Austin
AustinUnited States</p>
<p>Jie Lu jie.lu@uts.edu.au 
University of Technology Sydney
SydneyAustralia</p>
<p>Yi Zhang yi.zhang@uts.edu.au 
University of Technology Sydney
SydneyAustralia</p>
<p>HetGCoT: Heterogeneous Graph-Enhanced Chain-of-Thought LLM Reasoning for Academic Question Answering
18 Jun 20253BC65D061EE9C3C7BC4049A57496F241arXiv:2501.01203v2[cs.SI]
Academic question answering (QA) in heterogeneous scholarly networks presents unique challenges requiring both structural understanding and interpretable reasoning.While graph neural networks (GNNs) capture structured graph information and large language models (LLMs) demonstrate strong capabilities in semantic comprehension, current approaches lack integration at the reasoning level.We propose HetGCoT, a framework enabling LLMs to effectively leverage and learn information from graphs to reason interpretable academic QA results.Our framework introduces three technical contributions: (1) a framework that transforms heterogeneous graph structural information into LLM-processable reasoning chains, (2) an adaptive metapath selection mechanism identifying relevant subgraphs for specific queries, and (3) a multi-step reasoning strategy systematically incorporating graph contexts into the reasoning process.Experiments on OpenAlex and DBLP datasets show our approach outperforms all sota baselines.The framework demonstrates adaptability across different LLM architectures and applicability to various scholarly question answering tasks.</p>
<p>Introduction</p>
<p>Academic question answering in heterogeneous scholarly networks presents essential challenges in integrating structural knowledge with semantic understanding.QA tasks regarding publishing venue selection, paper authorship, and scientific collaboration all require systems to reason over complex networks of papers, authors, venues, and organizations while providing interpretable explanations (Shi et al., 2019;Wang et al., 2022).</p>
<p>The academic knowledge space is inherently heterogeneous, comprising diverse entities (e.g., papers, authors, venues and organizations) connected through various relationship types.Effective academic question answering systems must address three fundamental challenges: (1) modeling heterogeneous structures to capture complex relationships across different entity types and query contexts, (2) adaptively selecting relevant knowledge subgraphs based on query semantics rather than uniformly processing entire network structures, and (3) transforming structural knowledge into coherent natural language explanations that can justify answers across different academic QA scenarios.While these challenges manifest differently across different tasks, they share the common requirement of integrating graph-structured knowledge with semantic reasoning.</p>
<p>Current approaches to academic question answering have attempted to address these challenges through various strategies.However, existing methods face significant limitations in addressing these challenges holistically.Heterogeneous graph neural networks (HGNNs) can effectively model complex academic networks (Hu et al., 2020a), but struggle with: (1) adapting their representations to different query types and relationship patterns, (2) generating task-specific subgraph selections, and (3) producing natural language explanations for diverse academic QA scenarios.LLMs demonstrate strong semantic understanding (Chowdhery et al., 2022) but cannot directly process the rich structural information embedded in academic networks.Existing integration attempts typically focus on single tasks or treat graph information as auxiliary features through simple concatenation, failing to systematically incorporate structural patterns into the reasoning process across diverse academic QA scenarios (Zhao et al., 2023).</p>
<p>To address these limitations, we propose Het-GCoT (Heterogeneous Graph-Enhanced Chainof-Thought), a framework that integrates heterogeneous graph neural networks with large language models for academic question answering.HetGCoT transforms graph structural patterns into confidence-weighted natural language reason-ing chains through metapath naturalization, enabling LLMs to process complex academic relationships.The framework employs adaptive metapath selection using Heterogeneous Graph Transformer (HGT) (Hu et al., 2020b) embeddings and FastGTN-learned (Yao et al., 2021) importance weights to dynamically identify task-relevant subgraphs.Through a multistep chain-of-thought reasoning process, HetGCoT anchors on three taskdriven analytical foci: analyzing venue patterns for journal recommendation, temporal relationships for authorship queries, and collaboration networks for collaboration discovery.This integrated approach enables deep reasoning-level fusion of graph structures with language understanding across diverse academic QA scenarios.</p>
<p>Through extensive experiments on OpenAlex and DBLP datasets (Priem et al., 2022), we demonstrate HetGCoT's effectiveness across multiple academic QA tasks.For journal recommendation, our framework achieves 92.21% and 83.70% H@1 accuracy respectively.Moreover, we validate its generalizability on historical publication QA (author-paper reasoning) and author collaboration QA (author-paper-author reasoning), showing consistent improvements on general academic QA tasks.</p>
<p>The key contributions of this work include:</p>
<p> A unified framework for academic question answering that transforms heterogeneous graph structures into LLM-processable reasoning chains, enabling effective integration of structural and semantic understanding for academic question answering</p>
<p> An adaptive metapath selection mechanism that dynamically identifies relevant subgraphs based on query characteristics, supporting various academic QA scenarios</p>
<p> A flexible multi-step reasoning strategy that adapts to different academic QA tasks while maintaining systematic integration of graphderived contexts 2 Related Works</p>
<p>LLMs and Reasoning</p>
<p>LLMs have revolutionized natural language processing through their sophisticated understanding and generation capabilities.Building upon the Transformer architecture (Vaswani et al., 2017), prominent models including GPT (Brown et al., 2020), LLaMA (Touvron et al., 2023), Qwen (Bai et al., 2023), and PaLM (Chowdhery et al., 2022) have achieved remarkable performance across diverse language tasks.A pivotal advancement is chain-of-thought (CoT) reasoning (Wei et al., 2022), which enhances LLMs' ability to tackle complex problems through explicit intermediate reasoning steps.This approach has proven particularly effective for tasks requiring multi-step inference and logical decomposition.Extensions such as self-consistency (Wang et al., 2023) and tree-of-thought (Yao et al., 2023) further refine this capability, establishing structured reasoning frameworks for specialized domains.</p>
<p>Integration of GNNs and LLMs</p>
<p>The integration of graph neural networks with language models has emerged as a promising direction for leveraging both structural and semantic information.Recent work explores various integration strategies to combine the complementary strengths of both modalities.</p>
<p>Graph Prompting and Reasoning Methods: Several frameworks attempt to enhance LLMs with graph-based reasoning.GraphPrompter (Liu et al., 2024) explore soft prompting techniques for graph learning tasks with LLMs.Graph Chain-of-Thought (Jin et al., 2024) augments LLMs by explicitly reasoning on graph structures, while Graph of Thoughts (Besta et al., 2024) models the reasoning process itself as a graph structure.Think-on-Graph (Sun et al., 2023) proposes deep reasoning executed directly on knowledge graphs.</p>
<p>Retrieval-Augmented Approaches: PathRAG (Chen et al., 2025) enhances LLMs through graphbased retrieval using relational paths, while GNN-RAG (Mavromatis and Karypis, 2024) combines graph neural retrieval with language model reasoning.Generate-on-Graph (Chen et al., 2024) treats LLMs as both agents and knowledge graphs for incomplete QA tasks.</p>
<p>Heterogeneous Graph and Metapath Methods: For academic networks specifically, heterogeneous graph neural networks like HGT (Hu et al., 2020a) and HAN (Wang et al., 2019) model complex relationships between different entity types.Metapath-based techniques provide interpretable relationship modeling through typed connection sequences.Recent work such as Metapath of Thoughts (Solanki et al., 2024) verbalizes metapaths as contextual augmentation for LLMs.While these methods show promise, they typically focus on single tasks or treat graph information as auxiliary features rather than achieving deep reasoninglevel integration.Despite these advances, existing approaches face limitations in: (1) adaptively selecting taskrelevant subgraphs, (2) transforming heterogeneous structural patterns into natural language reasoning chains, and (3) systematically integrating graphderived contexts throughout the reasoning process.Our HetGCoT framework addresses these gaps by introducing adaptive metapath selection with learned importance weights, metapath naturalization for LLM processing, and a structured multistep reasoning strategy that deeply integrates graph knowledge at each reasoning stage.</p>
<p>Methodology</p>
<p>In this section, we present our proposed HetGCoT framework.Figure 1 illustrates the system architecture designed to address academic question answering through the integration of heterogeneous graph structural information with LLM reasoning capabilities.</p>
<p>We consider a heterogeneous academic graph G = (V, E, , ), where V = V p  V a  V v represents the set of nodes comprising papers (V p ), authors (V a ), and venues (V v ).E denotes the set of edges E = E P V  E P A , capturing paper-venue and paper-author relationships, with  : V  A mapping nodes to their types and  : E  R mapping edges to their relationship types.Given a query q (which could be a paper, author, or research topic), our task is to provide accurate answers with interpretable explanations.</p>
<p>Heterogeneous Academic Graph Construction</p>
<p>We construct a heterogeneous academic graph with three node types (papers, authors, venues) and two edge types (paper-venue, paper-author).Node features x v are initialized through:
x v = LayerNorm(concat(x text , x num )) (1)
where x text are Sentence-BERT (Reimers and Gurevych, 2019) encoded titles, abstracts, and keywords, and x num include citation counts, impact factors, and other numerical attributes.This framework can extend to additional node and edge types for different academic QA tasks.This comprehensive feature engineering ensures our model can leverage both content semantics and academic impact signals.</p>
<p>We then employ HGT to encode graph structure.HGT is particularly suitable for academic networks where nodes and relationships naturally possess varying semantic importance.Unlike traditional GNNs that treat all nodes homogeneously, Unlike traditional GNNs that treat all nodes homogeneously, HGT incorporates type-aware attention mechanisms that effectively capture this heterogeneity, allowing the model to differentiate between various node and edge types through specialized attention calculations:
h (l) i = jN (i) rR  (l) i,j,r  W (l) r h (l1) j (2)
where h</p>
<p>(l)</p>
<p>i represents the l-th layer embedding of node i, N (i) denotes its neighbors, R is the set of relation types,  (l) i,j,r are type-aware attention weights, and W (l) r are relation-specific transformation matrices.This encoding captures the semantic importance variations essential for subsequent metapath selection.</p>
<p>The model is trained with a link prediction objective tailored to the target task.The output embeddings encode both local neighborhood information and global patterns, forming the basis for metapath selection.</p>
<p>Adaptive Metapath Selection</p>
<p>We leverage metapaths to capture structured evidence in heterogeneous academic networks.Each metapath  represents a sequence of relations connecting different node types.</p>
<p>We define four metapath templates: (1) APVPA capturing venue-based author connections, (2) VPAPV identifying venue relationships through shared authors, (3) APA representing direct collaborations, and (4) OAPVPAO capturing institutional connections.These templates, inspired by heterogeneous network embedding approaches (Dong et al., 2017), comprehensively capture the semantic structures in academic heterogeneous graphs, providing rich relational contexts for academic QA tasks.</p>
<p>For each query node, we first generate a candidate pool of metapath instances by identifying semantically similar entities using cosine similarity of HGT embeddings as semantic starting points.This approach leverages the encoded structural representations to identify relevant subgraphs for exploration.</p>
<p>Unlike traditional approaches using manually defined importance, we employ FastGTN to learn relationship importance weights automatically:
H (l,c) =    |R| r=1  (c) l,r A (r) H (l1,c) W (l,c)   (3)
where H (l,c) denotes the representation at the l-th layer in channel c,  (c) l,r are the learned relation importance weights crucial for metapath scoring, A (r) represents the adjacency matrix for relation type r, and  is the activation function.</p>
<p>We train FastGTN with a self-encoding objective, minimizing reconstruction error for paper nodes.This approach offers two key advantages: it requires no additional labeling, enabling fully unsupervised learning of relation importance; and it forces the model to identify which relation combinations best preserve node semantics.Notably, we repurpose FastGTN as an explanation generator rather than a classifier, extracting relation importance weights that quantify the semantic significance of different metapaths.Importantly, we use frozen HGT embeddings as input features to Fast-GTN, ensuring complementarity between the two models: HGT provides node-level semantic embeddings, while FastGTN discovers global relation patterns.</p>
<p>After training, we extract relation importance weights from the model by averaging weights across all layers and channels.We then score each metapath instance by summing the learned importance weights of its constituent edges:
score norm () = (u,v) w (u,v) ||  (4)
where  denotes a metapath instance, w (u,v) represents the FastGTN-learned weight for edge (u, v) of type (u, v), and   [0, 1] controls length normalization, with larger values increasingly penalizing longer paths.</p>
<p>We employ a stratified selection strategy, taking the top-k paths from each template to ensure structural diversity rather than global ranking.This approach guarantees that all semantic templates are represented, the highest quality instances within each category are selected, and no single template dominates due to higher absolute scores.We empirically set k=5 to optimize the trade-off between contextual richness and prompt manageability.</p>
<p>Metapath Naturalization and Chain-of-Thought Enhanced Academic Reasoning</p>
<p>Metapath Naturalization To bridge the gap between graph structure and language models, we transform the selected metapaths into natural language descriptions.This transformation follows a template-based approach, where each metapath type is associated with a specific language template that captures its semantic meaning.Each natural language description is prefixed with a confidence score derived from the FastGTN path scoring mechanism, allowing the LLM to weigh structural evidence according to its reliability.This naturalization process converts graph structural patterns into coherent textual contexts that LLMs can effectively process and reason about.</p>
<p>Multi-step Reasoning Framework</p>
<p>We design a structured four-step reasoning framework that systematically integrates graph-derived information with content analysis.This CoT approach follows the cognitive process adaptable to different academic QA tasks: 1. Graph Structure Analysis: The model processes naturalized metapath (VPAPV, APVPA) information to understand structural patterns in the academic network, focusing on relationship evidence pointing to potential answers.</p>
<ol>
<li>
<p>Content Analysis: Examines the target paper's specific information (title, abstract, keywords, citation metrics) to identify thematic alignment with candidate answers.</p>
</li>
<li>
<p>Collaboration Analysis: Analyzes author collaboration patterns using author-centric metapaths (APA, OAPVPAO) to identify research communities and publication preferences.</p>
</li>
<li>
<p>Answer Generation: Synthesizes insights from the previous steps to generate answers with comprehensive explanations.</p>
</li>
</ol>
<p>Each reasoning step receives specifically tailored input information and questions that guide the reasoning process.This structured decomposition improves reasoning transparency while maintaining adaptability across different academic QA scenarios.</p>
<p>LLM Enhancement</p>
<p>We enhance the LLM's reasoning capabilities through prompt engineering and task-specific finetuning.The prompt template includes a system message defining the model's role as an aca-demic QA expert and establishing task-relevant constraints.The user message structures input according to our four-step reasoning process.</p>
<p>We fine-tune the model (GPT-4o mini) on datasets containing structured reasoning examples across academic QA tasks.During fine-tuning, we optimize the probability of generating correct answers conditioned on both query semantics and graph-derived contexts:
L = arg max  log P (a|q, M s ; ) (5) L = arg max  log mMs score norm (m)  P (a|q, naturalize(m); )(6)
where a denotes the target answer, q represents the input query, M s is the set of selected metapaths, score norm (m) are the FastGTN-learned confidence weights from Equation ( 4), and naturalize(m) transforms metapath m into natural language context for LLM processing.</p>
<p>This process teaches the model to: (1) interpret naturalized metapaths as structural evidence, (2) extract relevant information from multiple sources, and (3) generate evidence-supported answers connecting structural patterns with semantic understanding.</p>
<p>During inference, we construct task-specific prompts incorporating adaptive metapath information and query details.This integration creates transparency in the answering process, providing users with clear explanations grounded in both network structure and content semantics.</p>
<p>Experiments</p>
<p>Experimental Setup</p>
<p>Datasets We evaluate the proposed HetGCoT framework on two academic datasets, OpenAlex and DBLP.To ensure paper quality and the interpretability of results, we extracted a random subgraph from OpenAlex limited to journals ranked "A" or higher according to the CORE list (a widely used venue ranking system for computing research primarily in Australia and New Zealand), while for DBLP, we randomly sampled a subgraph from the entire dataset.We train the models separately on these two datasets.Table 1 summarises the statistics of the heterogeneous graphs extracted for our experiments.For each node type, we retain the Evaluation Metrics We report four metrics: Hit (%)-measures whether any of the true answers are found in the generated response, which is typically employed when evaluating LLMs; H@1 (%)-the accuracy of the top/first predicted answer; F1 (%)-harmonic mean of precision and recall; and NDCG (%)-which weights higher-ranked correct answers more heavily.</p>
<p>Baseline Methods</p>
<p>We compare HetGCoT with three categories of representative baseline methods:</p>
<p> We further conduct ablation studies with different LLM sizes: Qwen-2.5 1.5B, Qwen-2.5 7B, LLaMA-2 7B, LLaMA-2 13B, and LLaMA-3 8B, assessing the framework's adaptability to varying foundation-model capacities.</p>
<p>Results</p>
<p>Results on Journal Recommendation While our framework is designed for general academic QA tasks, we primarily demonstrate its effectiveness through journal recommendation due to its representative complexity and practical importance.Table 2 presents a comprehensive performance comparison of HetGCoT against all baseline methods on the OpenAlex and DBLP datasets.</p>
<p>The experimental results reveal several key insights.There is a clear performance improvement trend from pure GNN methods to pure LLM methods to graph+LLM integration methods, indicating the importance of combining structural information with language models.Pure GNN methods (e.g., GCN, GAT, HGT) show limited performance in capturing graph structural information, achieving up to 65.83% Hit rate and 22.36% H@1 accuracy.In contrast, pure LLM methods demonstrate stronger capabilities in semantic understanding, reaching 75.14% Hit rate.</p>
<p>Our HetGCoT framework outperforms all baseline methods across all metrics, achieving 96.48% Hit rate, 92.21% H@1, and 79.90% F1 score on OpenAlex on the journal recommendation task.This improvement can be attributed to our framework's structure-aware mechanism and multi-step reasoning strategy, which effectively integrates heterogeneous graph information with language model reasoning capabilities.Furthermore, HetGCoT maintains strong performance on the DBLP dataset, demonstrating that our method generalizes to different academic data environments.</p>
<p>Moreover, HetGCoT enhances the interpretability of academic QA through its structured reasoning approach.The adaptive metapath selection identifies the most relevant structural evidence for each query, while the four-step reasoning process generates transparent explanations that detail the model's analysis from graph patterns to semantic understanding, providing users with clear rationales for each answer.</p>
<p>Model Generalization Capability To validate the generalization capability of the HetGCoT framework, we applied it to more general academic question answering tasks beyond journal recommendation, including authorship identification QA (paperauthor relationships) and collaboration discovery QA (author-author relationships).As shown in Table 3, HetGCoT consistently improves performance across these tasks.For authorship identification QA, which requires understanding temporal relationships between authors and their publications, HetGCoT demonstrates substantial improvements over the zero-shot baseline across all datasets.Similarly, for the more challenging collaboration discovery QA task, which involves identifying collaboration patterns between authors, our framework delivers notable gains across all metrics.These results indicate that the combination of structure-aware mechanism and multi-step reasoning in HetGCoT effectively adapts to various general academic question answering scenarios.</p>
<p>Model Adaptability Experiments</p>
<p>To verify the plug-and-play nature of the HetGCoT framework and the effect of model scale on performance, we evaluated our method across different-sized LLMs on the Openalex dataset, with results shown in Table 4.</p>
<p>Two key trends emerge from the experimental results.First, the HetGCoT framework consistently improves performance across various LLM architectures, from smaller models like Qwen-2.5 1.5B to larger ones such as LLaMA-3 8B, demonstrating its plug-and-play nature.Second, we observe that larger models achieve more substantial gains when enhanced with HetGCoT.For instance, Qwen-2.5 7B improves from a zero-shot Hit rate of 47.00% to 78.67%, while smaller models show more modest improvements.This suggests that models with greater capacity can better exploit the heterogeneous graph information provided by our framework.</p>
<p>Ablation Study</p>
<p>To assess the contribution of each component in our framework, we conducted a series of ablation experiments on the Openalex Dataset, as shown in Figure 2.</p>
<p>The ablation study reveals the importance of each component in our framework.Comparing the zero-shot baseline with the HGT+CoT variant shows that incorporating chain-of-thought reasoning yields substantial performance gains.Further analysis of individual reasoning steps indicates that each contributes to the final performance, with step 2 (collaboration relationships) showing the  most impact when removed.The complete Het-GCoT framework outperforms all partial configurations, indicating that the four-step reasoning process works synergistically.These results validate our design rationale: effectively integrating heterogeneous graph information with each step of the chain-of-thought reasoning process can significantly enhance academic journal recommendation performance.</p>
<p>Conclusion</p>
<p>In this work, we proposed HetGCoT, a framework that integrates heterogeneous graph neural networks with large language models for academic question answering.Our framework introduces three main contributions: (1) a unified framework that transforms heterogeneous graph structural information into natural language reasoning chains, (2) an adaptive metapath selection mechanism that identifies relevant subgraphs for academic queries, and (3) a multi-step reasoning strategy that incorporates graph-derived contexts into chain-of-thought prompting.Through comprehensive experiments on OpenAlex and DBLP datasets, we demonstrated that HetGCoT significantly outperforms baseline methods.We also validated the framework's adaptability across different LLM architectures.Future work could extend this approach to more complex academic reasoning tasks, incorporate additional relationship types in scholarly networks, and scale to larger interdisciplinary datasets.The combination of structural graph information with language model reasoning presents promising directions for academic information processing systems.</p>
<p>Limitations</p>
<p>While our work demonstrates the effectiveness of integrating heterogeneous graph neural networks with LLMs, several limitations should be acknowledged.Firstly, the LLM outputs exhibit some instability across different runs, particularly for complex queries requiring multi-step reasoning.Although we fine-tuned the LLMs to improve stability, future work could explore more robust methods for ensuring consistent reasoning paths.Additionally, the computational requirements for processing large heterogeneous academic graphs remain considerable, potentially limiting real-time applications without further optimization.DBLP License.The DBLP computer science bibliography is provided under the Open Data Commons Attribution License (ODC-BY 1.0).This license permits use, sharing, and adaptation of the dataset with attribution.Details are available at https://opendatacommons.org/ licenses/by/1.0/.</p>
<p>Our dataset consists of three primary node types-papers, venues, and authors-each with distinct attribute sets as detailed in Table 5.The graph structure captures the relationships between these entities through directed edges.We split the data into training and test sets in a 9:1 ratio.(src: <paper_id>, dst: <author_id>), Attributes: {type: 'paperauthor'} Implementation Detail For Sentence-BERT, We obtain a single 768-dimensional embedding per node by concatenating its title, abstract, and keywords into a Sentence-BERT model.This 768dimensional vector is then augmented with two numeric attributes (total citation count and FWCI) to form a 770-dimensional feature vector for each paper node.</p>
<p>For HGT, We feed the 770-dimensional feature into a two-layer Heterogeneous Graph Transformer (HGT) with type-specific Q-K-V projections, 8 attention heads, and a hidden size of d = 387.The model is trained for 100 epochs using Adam (learning rate 1  10 3 ) on the paper-venue link-prediction task.Final per-node embeddings (h i  R 387 ) are saved for downstream use.</p>
<p>For TastGTN, a lightweight FastGTN autoencoder (7 layers, 8 channels, hidden size 64) is trained to reconstruct the frozen HGT embeddings (minimizing MSE(Z paper , h paper )) over 50 epochs with Adam (learning rate 3  10 3 ) on GPU.After training, we extract the learned relation-importance weights and score each candidate metapath by summing its edge weights.</p>
<p>A.2 Ablation Study</p>
<p>The details of our ablation study are shown in Table 6.</p>
<p>System Prompt</p>
<p>You are a professional academic journal recommendation expert.Your task is to recommend the three most suitable journals for publishing the provided paper information, following the specified reasoning steps, and to explain the reasons for each recommendation in detail.Please note:</p>
<p> Each paper can have only one correct publishing journal, which should be placed at the top of the recommendation list.</p>
<p> Please strictly follow the reasoning steps below and use the provided specific related information to answer within the given journal list.</p>
<p>User Prompt</p>
<p>Please recommend the three most suitable journals for publishing this paper based on the following information, strictly following the specified reasoning steps, and explain the reasons.</p>
<p>Step 1: Learn the graph structure information related to each journal based on the following predefined metapaths Question: Based on the following predefined metapaths, learn the graph structure information related to each journal.Step 4: Based on the above information, recommend the three most suitable journals for publishing this paper from the journal list below, sorted by probability from high to low, and explain the reasons Question: Based on the above analysis of the paper's content, authors' backgrounds, collaboration relationships, and the learned graph structure information, recommend the three most suitable journals for publishing this paper from the journal list below, sorted by probability from high to low, and provide detailed reasons for each recommendation.</p>
<p>System Prompt</p>
<p>You are an academic graph-reasoning assistant.Your task is to analyze academic collaboration networks to predict which researchers are most likely to be collaborators of a specific author.Please strictly follow the provided reasoning steps and use the provided graph structure information and paper context to make your predictions.</p>
<p> Each query focuses on one target author and requires selecting the three most likely collaborators from five candidates.</p>
<p> Please strictly follow the reasoning steps below and use the provided metapath information and paper descriptions.</p>
<p>User Prompt</p>
<p>Please identify the three most likely collaborators of the target author based on the following information, strictly following the specified reasoning steps.</p>
<p>Step 1: Graph Structure via Metapaths Question: Based on the following metapaths, learn the academic heterogeneous graph structure and author relationships.Based on the analysis, the three most likely collaborators are: 1. {author_1} 2. {author_2} 3. {author_3} Detailed explanation according to the reasoning procedure</p>
<p>Figure 1 :
1
Figure 1: HetGCoT Overall architecture.</p>
<p>Figure 2 :
2
Figure 2: Ablation study of HetGCoT framework components.</p>
<p>Identify the core themes and keywords of the paper, and define the paper's research field Question: Based on the following paper description, identify the core themes and keywords of the paper, its impact level, and determine its research field.Provided Information: [Paper Description] Paper [ ], titled [ ], has [ ] citations, FWCI (Field-Weighted Citation Impact) of [ ], authored by [ ], published in [ ], topics: [ ], abstract: [ ] -Step 3: Analyze the collaboration information of the authors Question: Based on the following collaboration relationships, analyze the collaboration status between the authors, their common research directions, and joint publications.Provided Information: [Collaboration Relationships] Author [ ] is affiliated with [ ], mainly publishes papers in journals such as . . .Author [ ] is affiliated with [ ], mainly publishes papers in journals such as . . .-</p>
<p>. . 2. . . .3. . . .Detailed explanation according to the reasoning procedure</p>
<p>Based on the following paper description, understand the research domain and collaboration context.Provided Information: [Paper Description] Paper [ ], titled [ ], has [ ] citations, FWCI (Field-Weighted Citation Impact) of [ ], published in [ ], topics: [ ], abstract: [ ] -Step 3: Make Prediction Question: Based on the above analysis of the graph structure and research context, choose the three most likely collaborators of author {author_id} from the researcher list below, sorted by probability from high to low.</p>
<p>Table 1 :
1
Statistics of experimental datasets.
FeatureOpenAlex DBLPTotal Nodes76,56962,443Total Edges105,29079,697Node Distributionvenue11151paper22,02817,850author54,43044,542Edge Distributionpaper-venue22,02817,850paper-author83,26261,847following attributes: venue (type, name); paper(type, keywords, abstract, citations, FWCI (field-weighted citation impact), title, year); author (type,organization, name). All textual fields are encodedusing Sentence-BERT, yielding initial node repre-sentations that capture semantic content in titles,abstracts, and keywords.</p>
<p>Table 2 :
2
Performance comparison of HetGCoT against baseline methods on the academic journal recommendation task.
OpenAlexDBLPCategoryMethodHit (%) H@1 (%) F1 (%) NDCG (%) Hit (%) H@1 (%) F1 (%) NDCG (%)GCN59.4913.9211.8257.0849.8412.4810.8553.29Pure GNNGAT60.1420.6816.0255.5458.2818.3912.5655.54HGT65.8322.3617.2060.5962.5820.7214.5959.70GPT-4o mini69.8058.6031.7764.9854.9444.8628.8755.56Pure LLMGPT-4o mini+CoT 75.1458.6249.5070.8361.6050.7440.2958.47LLaMA 3 8b+CoT 71.2359.2133.6470.7262.6752.7938.4759.68PathRAG76.8766.4935.7675.6267.6263.7849.7261.68GraphPrompter84.8382.6872.3783.7963.6461.6348.6558.28Graph+LLMGraphCoT90.4788.2575.3989.5972.7969.6252.6770.72Graph of Thoughts 92.5790.4876.3789.8680.0779.5259.8375.69Think-on-Graph92.8589.2775.3688.3683.7581.8962.7680.68OursHetGCoT96.4892.2179.9091.2985.3183.7064.5583.49</p>
<p>Table 3 :
3
Performance on general academic QA tasks.
OpenAlexDBLPTaskMethod Hit (%) H@1 (%) F1 (%) NDCG (%) Hit (%) H@1 (%) F1 (%) NDCG (%)AuthorshipZero-shot 32.6816.9719.2528.7136.6211.0732.2127.16IdentificationHetGCoT 84.4274.1282.2290.0086.1275.8682.7181.72CollaborationZero-shot 22.116.537.3715.2440.9115.0950.9135.92DiscoveryHetGCoT 58.7929.6050.9141.8667.7549.1157.7551.38</p>
<p>Table 4 :
4
Performance comparison of different-sized LLMs within the HetGCoT framework.
ModelHit (%) H@1 (%) F1 (%)Qwen-2.5 1.5B zeroshot10.405.803.58Qwen-2.5 1.5B+HetGCoT 15.336.674.40Qwen-2.5 7B zeroshot47.0046.0014.95Qwen-2.5 7B+HetGCoT78.6762.6734.70LLaMA-2 7b zeroshot25.3411.298.98LLaMA-2 7b+HetGCoT38.6334.2811.24LLaMA-2 13b zeroshot44.6832.7816.32LLaMA-2 13b+HetGCoT59.5646.4828.46LLaMA-3 8b zeroshot52.4731.4624.59LLaMA-3 8b+HetGCoT75.3365.3334.45</p>
<p>Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, and Karthik Narasimhan.2023.Tree of thoughts: Deliberate problem solving with large language models.arXiv preprint arXiv:2305.10601.
Ziniu Yao, Yiqing Xu, Wenming Zheng, Qionghai Dai,Chuxu Zhang, and Jiawei Han. 2021. Fastgtn: Fasterheterogeneous graph neural network training via type-wise subgraph batching. In Proceedings of the WebConference 2021, pages 2537-2547. ACM.Shirui Zhao, Dong Chang, Zhijie Tan, Philip S Yu, andShirui Pan. 2023. Unifying large language modelsand knowledge graphs: A roadmap. arXiv preprintarXiv:2306.08302.A AppendixA.1 Experiment Setup DetailDataset Detail We conduct experiments usingtwo publicly available academic datasets: Ope-nAlex and DBLP.OpenAlex License. OpenAlex is released un-der the Creative Commons Attribution 4.0 Interna-tional License (CC BY 4.0). This license allows forreuse, redistribution, and modification, providedthat proper attribution is given. More informationis available at https://creativecommons.org/licenses/by/4.0/.</p>
<p>Table 5 :
5
Node types and their attribute sets.
The complete node and edge templates followthis structure:Node Templates:</p>
<p>Table 8 :
8
Prompt template for journal recommendation.</p>
<p>Table 10 :
10
Prompt template for collaboration discovery (author-author relationships).</p>
<p>Algorithm 1 HetGCoT algorithm.G is a heterogeneous graph, q is the query, K is the number of selected metapaths per template and  is the length normalization factor 1: procedure HetGCoT(G, q, K, ) 2: H  HGT-ENCODE(G) Heterogeneous graph construction 3:A.3 AlgorithmThe pseudocode of our method is shown in Table7, and all experiments were conducted on two A100 GPUs.A.4 Prompt Templates System PromptYou are an academic graph-reasoning assistant.Your task is to analyze paper authorship patterns to predict which papers are most likely written by a specific author.Please strictly follow the provided reasoning steps and use the provided graph structure information and paper context to make your predictions. Each query focuses on one target author and requires selecting the three most likely papers from five candidates. Please strictly follow the reasoning steps below and use the provided metapath information and paper descriptions.User PromptPlease identify the three most likely papers written by the target author based on the following information, strictly following the specified reasoning steps.Step 1: Graph Structure via Metapaths Question: Based on the following metapaths, learn the academic heterogeneous graph structure and relationships.Step 3: Make Prediction Question: Based on the above analysis of the graph structure and paper context, choose the three most likely papers written by author {author} from the paper list below, sorted by probability from high to low.Provided Information:Based on the analysis, the three most likely papers are: 1. {paper_1} 2. {paper_2} 3. {paper_3} Detailed explanation according to the reasoning procedure Table9: Prompt template for authorship identification (paper-author relationships).
Jun Bai, Shuai Bai, Yuhui Chu, Zeyao Cui, Kun Dang, Xutong Deng, Jie Zhou, arXiv:2309.16609Qwen technical report. 2023</p>
<p>Graph of thoughts: Solving elaborate problems with large language models. Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Michal Podstawski, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Hubert Niewiadomski, Piotr Nyczyk, Torsten Hoefler, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial IntelligenceAAAI Press202438</p>
<p>Language models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Advances in Neural Information Processing Systems. 202033Amanda Askell, and 1 others</p>
<p>Pathrag: Pruning graph-based retrieval augmented generation with relational paths. Boyu Chen, Zirui Guo, Zidan Yang, Yuluo Chen, Junze Chen, Zhenghao Liu, Chuan Shi, Cheng Yang, arXiv:2502.149022025Preprint</p>
<p>Jiawei Chen, Yuanhang He, Yada Zhang, Jiachen Ji, Jie Tang, arXiv:2404.14741Generate-on-graph: Treat llm as both agent and knowledge graph for incomplete kgqa. 2024arXiv preprint</p>
<p>Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, arXiv:2204.02311Sebastian Gehrmann, and 1 others. 2022. Palm: Scaling language modeling with pathways. arXiv preprint</p>
<p>Metapath2vec: Scalable representation learning for heterogeneous networks. Yuxiao Dong, Nitesh V Chawla, Ananthram Swami, Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data MiningACM2017</p>
<p>Heterogeneous graph transformer. Z Hu, Y Dong, K Wang, Y Sun, Proceedings of The Web Conference 2020. The Web Conference 20202020a</p>
<p>Heterogeneous graph transformer. Ziniu Hu, Yuxiao Dong, Kuansan Wang, Yizhou Sun, Proceedings of The Web Conference 2020. The Web Conference 2020ACM2020b</p>
<p>Graph chain-of-thought: Augmenting large language models by reasoning on graphs. Chulin Bowen Jin, Jiawei Xie, Kashob Zhang, Yu Kumar Roy, Zheng Zhang, Ruirui Li, Xianfeng Li, Suhang Tang, Yu Wang, Jiawei Meng, Han, Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (ACL). the 62nd Annual Meeting of the Association for Computational Linguistics (ACL)Bangkok, ThailandAssociation for Computational Linguistics2024</p>
<p>Semi-supervised classification with graph convolutional networks. T N Kipf, M Welling, International Conference on Learning Representations. 2017</p>
<p>Can we soft prompt llms for graph learning tasks?. Zheyuan Liu, Xiaoxin He, Yijun Tian, Nitesh V Chawla, arXiv:2405.20139Gnnrag: Graph neural retrieval for large language model reasoning. ACM. Costas Mavromatis and George Karypis2024. 2024PreprintProceedings of the ACM Web Conference 2024 (WWW '24)</p>
<p>Openalex: A fully-open index of scholarly works, authors, venues, institutions, and concepts. Jason Priem, Heather Piwowar, Richard Orr, arXiv:2205.018332022arXiv preprint</p>
<p>Sentence-bert: Sentence embeddings using siamese bert-networks. Nils Reimers, Iryna Gurevych, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing. the 2019 Conference on Empirical Methods in Natural Language Processing2019</p>
<p>Heterogeneous information network embedding for recommendation. Chuan Shi, Binbin Hu, Wayne Xin Zhao, Philip S Yu, IEEE Transactions on Knowledge and Data Engineering. 3122019</p>
<p>Metapath of thoughts: Verbalized metapaths in heterogeneous graph as contextual augmentation to llm. Harshvardhan Solanki, Jyoti Singh, Yihui Chong, Ankur Teredesai, 2024Amazon ScienceTechnical report</p>
<p>M Sun, Y Tan, X Wang, Y Qian, T Cui, Y Yang, arXiv:2307.07697Think-on-graph: Deep and responsible reasoning of large language model with knowledge graph. 2023arXiv preprint</p>
<p>Marie-Anne Lachaux, and 1 others. Thibaut Hugo Touvron, Gautier Lavril, Xavier Izacard, Martinet, arXiv:2302.13971Llama: Open and efficient foundation language models. 2023arXiv preprint</p>
<p>Attention is all you need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, ukasz Kaiser, Illia Polosukhin, Advances in Neural Information Processing Systems. 2017</p>
<p>Graph attention networks. P Velikovi, G Cucurull, A Casanova, A Romero, P Li, Y Bengio, International Conference on Learning Representations. 2018</p>
<p>Heterogeneous graph attention network. Xiao Wang, Houye Ji, Chuan Shi, Bai Wang, Yanfang Ye, Peng Cui, Philip S Yu, Proceedings of The Web Conference. The Web Conference2019. 2019</p>
<p>Self-consistency improves chain of thought reasoning in language models. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Denny Zhou, International Conference on Learning Representations. 2023</p>
<p>A survey on heterogeneous graph neural networks. Zhichao Wang, Yuxiang Liu, Yuqian Ma, Xueqi Liu, Jinpeng Ma, Neural Computing and Applications. 2022</p>
<p>Chain-ofthought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, arXiv:2201.119032022arXiv preprintBrian Ichter, and 1 others</p>            </div>
        </div>

    </div>
</body>
</html>