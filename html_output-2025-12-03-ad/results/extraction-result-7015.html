<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7015 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7015</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7015</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-135.html">extraction-schema-135</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of graph-to-text representations used to convert graphs into textual sequences for language model training, including their description, encoding method, properties, datasets, models, evaluation metrics, performance outcomes, and any reported advantages or limitations.</div>
                <p><strong>Paper ID:</strong> paper-265659278</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2312.02706v2.pdf" target="_blank">Large Knowledge Model: Perspectives and Challenges</a></p>
                <p><strong>Paper Abstract:</strong> Humankind's understanding of the world is fundamentally linked to our perception and cognition, with \emph{human languages} serving as one of the major carriers of \emph{world knowledge}. In this vein, \emph{Large Language Models} (LLMs) like ChatGPT epitomize the pre-training of extensive, sequence-based world knowledge into neural networks, facilitating the processing and manipulation of this knowledge in a parametric space. This article explores large models through the lens of"knowledge". We initially investigate the role of symbolic knowledge such as Knowledge Graphs (KGs) in enhancing LLMs, covering aspects like knowledge-augmented language model, structure-inducing pre-training, knowledgeable prompts, structured CoT, knowledge editing, semantic tools for LLM and knowledgeable AI agents. Subsequently, we examine how LLMs can boost traditional symbolic knowledge bases, encompassing aspects like using LLM as KG builder and controller, structured knowledge pretraining, and LLM-enhanced symbolic reasoning. Considering the intricate nature of human knowledge, we advocate for the creation of \emph{Large Knowledge Models} (LKM), specifically engineered to manage diversified spectrum of knowledge structures. This promising undertaking would entail several key challenges, such as disentangling knowledge base from language models, cognitive alignment with human knowledge, integration of perception and cognition, and building large commonsense models for interacting with physical world, among others. We finally propose a five-"A"principle to distinguish the concept of LKM.</p>
                <p><strong>Cost:</strong> 0.017</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7015.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7015.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of graph-to-text representations used to convert graphs into textual sequences for language model training, including their description, encoding method, properties, datasets, models, evaluation metrics, performance outcomes, and any reported advantages or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Input-layer KG->Text</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Input-layer Knowledge Graph to Text Injection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A graph-to-text representation where KG triples relevant to entities in a sentence are converted into natural language fragments and appended or interleaved with the original text as data augmentation for language model training.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>Input-layer KG-to-text (triple expansion)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Entities in text are linked to a KG; corresponding triples are verbalized as short natural-language phrases or sentences and inserted into the input sequence (sentence expansion / triple insertion). No model architecture changes are required; the graph is represented as extra textual tokens describing triples.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_type</strong></td>
                            <td>sequential, token-based, lossy</td>
                        </tr>
                        <tr>
                            <td><strong>encoding_method</strong></td>
                            <td>Entity linking + triple-to-natural-language verbalization (triple insertion / sentence expansion)</td>
                        </tr>
                        <tr>
                            <td><strong>canonicalization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>average_token_length</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>knowledge-injecting pre-training / data augmentation</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BERT-style / generic LMs (examples: K-BERT, CoLAKE used in literature)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Off-the-shelf language encoders/decoders (e.g., BERT family) with no architectural modification; training objective remains standard MLM/next-token prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>impact_on_training</strong></td>
                            <td>Easy to implement as data augmentation; enables the same model to learn from both textual and converted-graph signals without architecture changes; reported to enrich contextual information for entities.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Semantic and structural signals from the original graph are partially lost when reduced to text; structural relationships are not fully exploited; can increase token budget and may introduce noisy or verbose context.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other</strong></td>
                            <td>Compared to intermediate- and objective-layer injection, input-layer injection is architecture-agnostic and simple but more lossy in preserving graph structure; the paper notes it avoids alignment issues but sacrifices structural signal fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Knowledge Model: Perspectives and Challenges', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7015.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7015.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of graph-to-text representations used to convert graphs into textual sequences for language model training, including their description, encoding method, properties, datasets, models, evaluation metrics, performance outcomes, and any reported advantages or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>K-BERT / CoLAKE (examples)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>K-BERT and CoLAKE (input-layer KG injection examples)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Representative systems that implement input-layer KG-to-text injection by expanding sentences with KG information; cited as practical instantiations of triple-to-text insertion.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>K-BERT: enabling language representation with knowledge graph.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>K-BERT style triple insertion</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>KG triples linked to sentence entities are inserted into token stream using special positional or invisible tokens to maintain sentence structure; KG facts are expressed as short textual fragments associated with entities.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_type</strong></td>
                            <td>sequential, token-based, lossy</td>
                        </tr>
                        <tr>
                            <td><strong>encoding_method</strong></td>
                            <td>Entity linking + triple insertion with special position handling (as in K-BERT)</td>
                        </tr>
                        <tr>
                            <td><strong>canonicalization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>average_token_length</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>pre-training / representation enrichment</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BERT (augmented pipeline)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>BERT-style encoder with the same architecture; input is augmented with KG-derived textual fragments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>impact_on_training</strong></td>
                            <td>Provides richer contextual signals for entities without changing model internals; simple to apply to existing pretrained architectures.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Converts structured facts to text which may dilute relational signals; positional hacks (invisible tokens) may be required to avoid breaking sentence semantics.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other</strong></td>
                            <td>Sits on the simpler end of injection strategies; compared to intermediate/objective injection it is simpler but preserves the least of the original graph structure.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Knowledge Model: Perspectives and Challenges', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7015.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7015.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of graph-to-text representations used to convert graphs into textual sequences for language model training, including their description, encoding method, properties, datasets, models, evaluation metrics, performance outcomes, and any reported advantages or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Graph-to-token</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Graph-to-token sequentialization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A form of graph-to-text representation where graph nodes and relations are embedded as individual tokens or token sequences intermixed with natural language tokens, preserving tokenized graph elements for LM training.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>Graph-to-token</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Nodes and relations are serialized into tokens (often short symbol tokens or pre-defined phrases) and incorporated into sequences fed to LMs; aims to keep graph elements in token form rather than fully naturalized text.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_type</strong></td>
                            <td>sequential, token-based, lossy (can be more faithful than free-form text)</td>
                        </tr>
                        <tr>
                            <td><strong>encoding_method</strong></td>
                            <td>Node/edge serialization into tokens (edge-list or attribute-first ordering); often interleaved with text</td>
                        </tr>
                        <tr>
                            <td><strong>canonicalization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>average_token_length</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>pre-training of language models on graph-structured data</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Large Language Models (LLM-centric approach)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Standard autoregressive or masked language models trained on sequences that include serialized graph tokens.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>impact_on_training</strong></td>
                            <td>Allows LMs to process graph elements with token-level granularity; can be used with standard LM losses (next-token / MLM) enabling unified training across modalities.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Still reduces the graph to a sequence and may fail to preserve higher-order structure (multi-hop relations); ordering decisions can inject bias; structural semantics can be degraded.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other</strong></td>
                            <td>More structured than pure natural-language verbalization (Graph-to-text) but less faithful than graph-native models (GNNs); designed to leverage LLM training pipelines at cost of potential structural loss.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Knowledge Model: Perspectives and Challenges', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7015.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e7015.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of graph-to-text representations used to convert graphs into textual sequences for language model training, including their description, encoding method, properties, datasets, models, evaluation metrics, performance outcomes, and any reported advantages or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Graph-to-text</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Graph-to-text full verbalization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A representation that converts graph triples or subgraphs into full natural-language sentences or paragraphs (e.g., triple -> sentence) to form corpora for language model training or instruction tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>Graph-to-text (full sentence verbalization)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>KG triples are turned into natural-language sentences (e.g., "Tim Cook is CEO of Apple.") and concatenated as a text corpus; entire graphs are verbalized as sequences of sentences for LM training.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_type</strong></td>
                            <td>sequential, hierarchical (sentence-level), lossy</td>
                        </tr>
                        <tr>
                            <td><strong>encoding_method</strong></td>
                            <td>Triple-to-sentence conversion; entity linking may be used to map graph nodes to surface forms; sequences formed by concatenating verbalized triples or narrative descriptions.</td>
                        </tr>
                        <tr>
                            <td><strong>canonicalization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>average_token_length</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>pre-training / instruction generation / knowledge distillation into LMs</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Autoregressive LMs or encoder-decoder LMs (LLM-centric)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Language models trained on verbalized KG corpora with standard LM objectives (next-token / seq2seq loss).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>impact_on_training</strong></td>
                            <td>Enables the use of standard LM training pipelines and objectives; useful for instruction generation and expanding LM knowledge coverage from structured sources.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Verbalization leads to loss of explicit relational structure and may increase ambiguity; factual nuance and graph topology may not be captured; large token cost for dense graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other</strong></td>
                            <td>Simpler to adopt than graph-native pretraining; compared to Graph-to-token it produces more natural language but may be less precise about structural relations; compared to GNN pretraining it is more scalable but more lossy.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Knowledge Model: Perspectives and Challenges', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7015.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e7015.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of graph-to-text representations used to convert graphs into textual sequences for language model training, including their description, encoding method, properties, datasets, models, evaluation metrics, performance outcomes, and any reported advantages or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>KG->Instructions</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Knowledge Graph to Instruction Dataset Conversion</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Conversion of KG triples and relations into instruction-style training examples (prompts + targets) to fine-tune LMs for information extraction, KGQA, or other structured tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>KG-to-instruction (instruction generation from KG)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Triples and graph relations are transformed into instruction-format examples (e.g., question/answer or extraction prompts) so that LMs can be instruction-tuned on structured-knowledge tasks; may include chains-of-thought like reasoning traces derived from graph relations.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_type</strong></td>
                            <td>sequential (instruction format), hierarchical (prompt + response), lossy</td>
                        </tr>
                        <tr>
                            <td><strong>encoding_method</strong></td>
                            <td>Template-based or programmatic conversion of triples/subgraphs into natural-language instructions/QA pairs; often uses entity labels and relation descriptions as inputs and targets.</td>
                        </tr>
                        <tr>
                            <td><strong>canonicalization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>average_token_length</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>WikiData (as used by example DeepKE-LLM), Protein KG (as used by InstructProtein)</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>instruction-tuning / knowledge extraction / KGQA / protein-function modeling</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Instruction-tuned LMs / protein language model (as in InstructProtein)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Base LLMs fine-tuned with large instruction datasets generated from KGs; InstructProtein used such instructions to train a protein language model for function modeling.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>impact_on_training</strong></td>
                            <td>Generates large-scale, structure-rich instruction corpora that improve generalization and task transfer; leverages KG structure to create high-density supervision for instruction tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Quality depends on KG accuracy; automatically generated instructions may propagate KG errors or introduce biases; may still abstract away detailed graph topology.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other</strong></td>
                            <td>Compared with raw triple verbalization, instruction-generation yields task-specific supervision and often better downstream task generalization; compared with supervised human-labeled instructions, it is scalable but potentially noisier.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Knowledge Model: Perspectives and Challenges', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7015.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e7015.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of graph-to-text representations used to convert graphs into textual sequences for language model training, including their description, encoding method, properties, datasets, models, evaluation metrics, performance outcomes, and any reported advantages or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Entity-tree RAG (Tree-RAG / KG-FiD)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Entity-tree / Graph-augmented Retrieval-Augmented Generation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Representations where graphs are serialized into hierarchical entity/topic trees or integrated with document chunks to enhance retrieval and contextual generation for LMs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>Entity-tree / document-specific KG serialization for RAG</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Documents are chunked and linked to KG entities; an entity/topic tree or a merged local+external KG is constructed and used alongside vector retrieval to surface relevant triples and paragraphs for generation; graph information is verbalized or used to re-rank retrieved context.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_type</strong></td>
                            <td>sequential (when verbalized) + hierarchical (entity tree), lossy when verbalized</td>
                        </tr>
                        <tr>
                            <td><strong>encoding_method</strong></td>
                            <td>Document chunking + entity linking + building hierarchical entity trees or local KGs; retrieval uses both vector indices and graph databases; retrieved triples may be converted to text for LM context.</td>
                        </tr>
                        <tr>
                            <td><strong>canonicalization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>average_token_length</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Retrieval-Augmented Generation (RAG) / KG-RAG / open-domain QA</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>RAG pipelines / Fusion-in-Decoder variants (KG-FiD cited as example)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>LM decoders conditioned on retrieved textual paragraphs and/or verbalized KG triples; some systems use GNNs to re-rank graph-augmented paragraphs before generation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>impact_on_training</strong></td>
                            <td>Improves retrieval relevance and answer accuracy by supplying structured context; helps mitigate hallucination by grounding generation in KG facts.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Requires building and maintaining graph indices; mapping between graph context and textual chunks is non-trivial; verbalizing graph context for decoder increases token use.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other</strong></td>
                            <td>Stronger grounding than pure vector retrieval; can outperform vanilla RAG when entity hierarchies or KG relations are important, but adds system complexity compared to simple RAG.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Knowledge Model: Perspectives and Challenges', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7015.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e7015.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of graph-to-text representations used to convert graphs into textual sequences for language model training, including their description, encoding method, properties, datasets, models, evaluation metrics, performance outcomes, and any reported advantages or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Structure-inducing (intra-sample) verbalization</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Intra-sample KG linking / structure-inducing pretraining (entity linking within sentences)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Representation that embeds graph-derived correlations into single training samples by linking entities in a sentence to external KGs and verbalizing relationships inline to induce structural signals during LM pretraining.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>Intra-sample KG verbalization (structure-inducing)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Entities inside individual samples are connected to external KG facts; these relations are introduced into the sample (e.g., as appended phrases or inline annotations) to enforce intra-sample relational constraints during pretraining.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_type</strong></td>
                            <td>sequential with intra-sample structural augmentation, lossy</td>
                        </tr>
                        <tr>
                            <td><strong>encoding_method</strong></td>
                            <td>Entity linking + inline triple insertion or appended relational sentences per sample; can be combined with auxiliary pretraining objectives.</td>
                        </tr>
                        <tr>
                            <td><strong>canonicalization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>average_token_length</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>structure-inducing pretraining / improving reasoning by adding structural signals</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Pretrained LMs with structure-inducing corpora</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Standard LMs pretrained on corpora augmented at the sample level with linked KG facts and possibly auxiliary objectives to enforce relational geometry.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>impact_on_training</strong></td>
                            <td>Reported to consistently improve downstream benchmarks that benefit from structured signals; helps activate reasoning abilities by increasing logical content in pretraining data.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Still relies on text sequences so some structural fidelity is lost; requires effective entity linking and high-quality KG facts; may increase pretraining complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other</strong></td>
                            <td>Compared to inter-sample structure constraints, intra-sample linking directly augments single inputs and more tightly couples graph facts with local context; compared to graph-native pretraining, it's more scalable but less faithful to topology.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Knowledge Model: Perspectives and Challenges', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7015.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e7015.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of graph-to-text representations used to convert graphs into textual sequences for language model training, including their description, encoding method, properties, datasets, models, evaluation metrics, performance outcomes, and any reported advantages or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Graph of Thoughts / KGoT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Graph of Thoughts / CoT enhanced by Knowledge Graphs (KGoT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A structured Chain-of-Thought style prompt representation where reasoning paths are modeled as graphs and KG structure is used to build or expand these reasoning graphs; graph nodes correspond to intermediate thoughts or facts and edges to reasoning steps.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Graph of thoughts: Solving elaborate problems with large language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>Graph-of-Thoughts / KG-enhanced CoT (KGoT)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Rather than a linear CoT, reasoning is represented as a graph (nodes = intermediate steps, edges = logical connections); KGs can seed or expand nodes and relations, and the graph can be linearized or verbalized as structured prompts for LMs.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_type</strong></td>
                            <td>hierarchical / graph-structured prompt, convertible to sequential text (lossy if verbalized)</td>
                        </tr>
                        <tr>
                            <td><strong>encoding_method</strong></td>
                            <td>Construct reasoning graph from KG relations and/or LM-generated nodes; when used with LMs, graph is typically converted to a sequence of prompted steps or branching prompts (tree/graph linearizations).</td>
                        </tr>
                        <tr>
                            <td><strong>canonicalization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>average_token_length</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>structured Chain-of-Thought prompting / complex problem solving</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLMs using advanced prompting (Graph-of-Thoughts)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Large autoregressive LMs guided by structured (graph/tree) CoT prompts, sometimes with iterative search over graph branches.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>impact_on_training</strong></td>
                            <td>Structured CoT (graph/tree) can substantially boost reasoning on complex tasks when integrated with KGs; KG-sourced structure aids coherence of multi-step reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Converting graphs to linear prompts loses branching topology; acquiring high-quality KG-based CoT is laborious; LMs may still struggle to fully exploit explicit graph structure.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other</strong></td>
                            <td>More expressive than linear CoT; when combined with KGs offers better structure and factual grounding, but implementation and acquisition costs are higher.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Knowledge Model: Perspectives and Challenges', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>K-BERT: enabling language representation with knowledge graph. <em>(Rating: 2)</em></li>
                <li>Colake: Contextualized language and knowledge embedding. <em>(Rating: 2)</em></li>
                <li>KG-BART: knowledge graphaugmented BART for generative commonsense reasoning. <em>(Rating: 2)</em></li>
                <li>KEPLER: A unified model for knowledge embedding and pre-trained language representation. <em>(Rating: 2)</em></li>
                <li>InstructProtein: Aligning human and protein language via knowledge instruction. <em>(Rating: 2)</em></li>
                <li>Tree of thoughts: Deliberate problem solving with large language models. <em>(Rating: 1)</em></li>
                <li>Graph of thoughts: Solving elaborate problems with large language models. <em>(Rating: 2)</em></li>
                <li>KG-FiD: Infusing knowledge graph in fusion-in-decoder for open-domain question answering. <em>(Rating: 2)</em></li>
                <li>T-RAG: lessons from the LLM trenches. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7015",
    "paper_id": "paper-265659278",
    "extraction_schema_id": "extraction-schema-135",
    "extracted_data": [
        {
            "name_short": "Input-layer KG-&gt;Text",
            "name_full": "Input-layer Knowledge Graph to Text Injection",
            "brief_description": "A graph-to-text representation where KG triples relevant to entities in a sentence are converted into natural language fragments and appended or interleaved with the original text as data augmentation for language model training.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "representation_name": "Input-layer KG-to-text (triple expansion)",
            "representation_description": "Entities in text are linked to a KG; corresponding triples are verbalized as short natural-language phrases or sentences and inserted into the input sequence (sentence expansion / triple insertion). No model architecture changes are required; the graph is represented as extra textual tokens describing triples.",
            "representation_type": "sequential, token-based, lossy",
            "encoding_method": "Entity linking + triple-to-natural-language verbalization (triple insertion / sentence expansion)",
            "canonicalization": null,
            "average_token_length": null,
            "dataset_name": null,
            "task_name": "knowledge-injecting pre-training / data augmentation",
            "model_name": "BERT-style / generic LMs (examples: K-BERT, CoLAKE used in literature)",
            "model_description": "Off-the-shelf language encoders/decoders (e.g., BERT family) with no architectural modification; training objective remains standard MLM/next-token prediction.",
            "performance_metric": null,
            "performance_value": null,
            "impact_on_training": "Easy to implement as data augmentation; enables the same model to learn from both textual and converted-graph signals without architecture changes; reported to enrich contextual information for entities.",
            "limitations": "Semantic and structural signals from the original graph are partially lost when reduced to text; structural relationships are not fully exploited; can increase token budget and may introduce noisy or verbose context.",
            "comparison_with_other": "Compared to intermediate- and objective-layer injection, input-layer injection is architecture-agnostic and simple but more lossy in preserving graph structure; the paper notes it avoids alignment issues but sacrifices structural signal fidelity.",
            "uuid": "e7015.0",
            "source_info": {
                "paper_title": "Large Knowledge Model: Perspectives and Challenges",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "K-BERT / CoLAKE (examples)",
            "name_full": "K-BERT and CoLAKE (input-layer KG injection examples)",
            "brief_description": "Representative systems that implement input-layer KG-to-text injection by expanding sentences with KG information; cited as practical instantiations of triple-to-text insertion.",
            "citation_title": "K-BERT: enabling language representation with knowledge graph.",
            "mention_or_use": "mention",
            "representation_name": "K-BERT style triple insertion",
            "representation_description": "KG triples linked to sentence entities are inserted into token stream using special positional or invisible tokens to maintain sentence structure; KG facts are expressed as short textual fragments associated with entities.",
            "representation_type": "sequential, token-based, lossy",
            "encoding_method": "Entity linking + triple insertion with special position handling (as in K-BERT)",
            "canonicalization": null,
            "average_token_length": null,
            "dataset_name": null,
            "task_name": "pre-training / representation enrichment",
            "model_name": "BERT (augmented pipeline)",
            "model_description": "BERT-style encoder with the same architecture; input is augmented with KG-derived textual fragments.",
            "performance_metric": null,
            "performance_value": null,
            "impact_on_training": "Provides richer contextual signals for entities without changing model internals; simple to apply to existing pretrained architectures.",
            "limitations": "Converts structured facts to text which may dilute relational signals; positional hacks (invisible tokens) may be required to avoid breaking sentence semantics.",
            "comparison_with_other": "Sits on the simpler end of injection strategies; compared to intermediate/objective injection it is simpler but preserves the least of the original graph structure.",
            "uuid": "e7015.1",
            "source_info": {
                "paper_title": "Large Knowledge Model: Perspectives and Challenges",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Graph-to-token",
            "name_full": "Graph-to-token sequentialization",
            "brief_description": "A form of graph-to-text representation where graph nodes and relations are embedded as individual tokens or token sequences intermixed with natural language tokens, preserving tokenized graph elements for LM training.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "representation_name": "Graph-to-token",
            "representation_description": "Nodes and relations are serialized into tokens (often short symbol tokens or pre-defined phrases) and incorporated into sequences fed to LMs; aims to keep graph elements in token form rather than fully naturalized text.",
            "representation_type": "sequential, token-based, lossy (can be more faithful than free-form text)",
            "encoding_method": "Node/edge serialization into tokens (edge-list or attribute-first ordering); often interleaved with text",
            "canonicalization": null,
            "average_token_length": null,
            "dataset_name": null,
            "task_name": "pre-training of language models on graph-structured data",
            "model_name": "Large Language Models (LLM-centric approach)",
            "model_description": "Standard autoregressive or masked language models trained on sequences that include serialized graph tokens.",
            "performance_metric": null,
            "performance_value": null,
            "impact_on_training": "Allows LMs to process graph elements with token-level granularity; can be used with standard LM losses (next-token / MLM) enabling unified training across modalities.",
            "limitations": "Still reduces the graph to a sequence and may fail to preserve higher-order structure (multi-hop relations); ordering decisions can inject bias; structural semantics can be degraded.",
            "comparison_with_other": "More structured than pure natural-language verbalization (Graph-to-text) but less faithful than graph-native models (GNNs); designed to leverage LLM training pipelines at cost of potential structural loss.",
            "uuid": "e7015.2",
            "source_info": {
                "paper_title": "Large Knowledge Model: Perspectives and Challenges",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Graph-to-text",
            "name_full": "Graph-to-text full verbalization",
            "brief_description": "A representation that converts graph triples or subgraphs into full natural-language sentences or paragraphs (e.g., triple -&gt; sentence) to form corpora for language model training or instruction tuning.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "representation_name": "Graph-to-text (full sentence verbalization)",
            "representation_description": "KG triples are turned into natural-language sentences (e.g., \"Tim Cook is CEO of Apple.\") and concatenated as a text corpus; entire graphs are verbalized as sequences of sentences for LM training.",
            "representation_type": "sequential, hierarchical (sentence-level), lossy",
            "encoding_method": "Triple-to-sentence conversion; entity linking may be used to map graph nodes to surface forms; sequences formed by concatenating verbalized triples or narrative descriptions.",
            "canonicalization": null,
            "average_token_length": null,
            "dataset_name": null,
            "task_name": "pre-training / instruction generation / knowledge distillation into LMs",
            "model_name": "Autoregressive LMs or encoder-decoder LMs (LLM-centric)",
            "model_description": "Language models trained on verbalized KG corpora with standard LM objectives (next-token / seq2seq loss).",
            "performance_metric": null,
            "performance_value": null,
            "impact_on_training": "Enables the use of standard LM training pipelines and objectives; useful for instruction generation and expanding LM knowledge coverage from structured sources.",
            "limitations": "Verbalization leads to loss of explicit relational structure and may increase ambiguity; factual nuance and graph topology may not be captured; large token cost for dense graphs.",
            "comparison_with_other": "Simpler to adopt than graph-native pretraining; compared to Graph-to-token it produces more natural language but may be less precise about structural relations; compared to GNN pretraining it is more scalable but more lossy.",
            "uuid": "e7015.3",
            "source_info": {
                "paper_title": "Large Knowledge Model: Perspectives and Challenges",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "KG-&gt;Instructions",
            "name_full": "Knowledge Graph to Instruction Dataset Conversion",
            "brief_description": "Conversion of KG triples and relations into instruction-style training examples (prompts + targets) to fine-tune LMs for information extraction, KGQA, or other structured tasks.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "representation_name": "KG-to-instruction (instruction generation from KG)",
            "representation_description": "Triples and graph relations are transformed into instruction-format examples (e.g., question/answer or extraction prompts) so that LMs can be instruction-tuned on structured-knowledge tasks; may include chains-of-thought like reasoning traces derived from graph relations.",
            "representation_type": "sequential (instruction format), hierarchical (prompt + response), lossy",
            "encoding_method": "Template-based or programmatic conversion of triples/subgraphs into natural-language instructions/QA pairs; often uses entity labels and relation descriptions as inputs and targets.",
            "canonicalization": null,
            "average_token_length": null,
            "dataset_name": "WikiData (as used by example DeepKE-LLM), Protein KG (as used by InstructProtein)",
            "task_name": "instruction-tuning / knowledge extraction / KGQA / protein-function modeling",
            "model_name": "Instruction-tuned LMs / protein language model (as in InstructProtein)",
            "model_description": "Base LLMs fine-tuned with large instruction datasets generated from KGs; InstructProtein used such instructions to train a protein language model for function modeling.",
            "performance_metric": null,
            "performance_value": null,
            "impact_on_training": "Generates large-scale, structure-rich instruction corpora that improve generalization and task transfer; leverages KG structure to create high-density supervision for instruction tuning.",
            "limitations": "Quality depends on KG accuracy; automatically generated instructions may propagate KG errors or introduce biases; may still abstract away detailed graph topology.",
            "comparison_with_other": "Compared with raw triple verbalization, instruction-generation yields task-specific supervision and often better downstream task generalization; compared with supervised human-labeled instructions, it is scalable but potentially noisier.",
            "uuid": "e7015.4",
            "source_info": {
                "paper_title": "Large Knowledge Model: Perspectives and Challenges",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Entity-tree RAG (Tree-RAG / KG-FiD)",
            "name_full": "Entity-tree / Graph-augmented Retrieval-Augmented Generation",
            "brief_description": "Representations where graphs are serialized into hierarchical entity/topic trees or integrated with document chunks to enhance retrieval and contextual generation for LMs.",
            "citation_title": "",
            "mention_or_use": "mention",
            "representation_name": "Entity-tree / document-specific KG serialization for RAG",
            "representation_description": "Documents are chunked and linked to KG entities; an entity/topic tree or a merged local+external KG is constructed and used alongside vector retrieval to surface relevant triples and paragraphs for generation; graph information is verbalized or used to re-rank retrieved context.",
            "representation_type": "sequential (when verbalized) + hierarchical (entity tree), lossy when verbalized",
            "encoding_method": "Document chunking + entity linking + building hierarchical entity trees or local KGs; retrieval uses both vector indices and graph databases; retrieved triples may be converted to text for LM context.",
            "canonicalization": null,
            "average_token_length": null,
            "dataset_name": null,
            "task_name": "Retrieval-Augmented Generation (RAG) / KG-RAG / open-domain QA",
            "model_name": "RAG pipelines / Fusion-in-Decoder variants (KG-FiD cited as example)",
            "model_description": "LM decoders conditioned on retrieved textual paragraphs and/or verbalized KG triples; some systems use GNNs to re-rank graph-augmented paragraphs before generation.",
            "performance_metric": null,
            "performance_value": null,
            "impact_on_training": "Improves retrieval relevance and answer accuracy by supplying structured context; helps mitigate hallucination by grounding generation in KG facts.",
            "limitations": "Requires building and maintaining graph indices; mapping between graph context and textual chunks is non-trivial; verbalizing graph context for decoder increases token use.",
            "comparison_with_other": "Stronger grounding than pure vector retrieval; can outperform vanilla RAG when entity hierarchies or KG relations are important, but adds system complexity compared to simple RAG.",
            "uuid": "e7015.5",
            "source_info": {
                "paper_title": "Large Knowledge Model: Perspectives and Challenges",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Structure-inducing (intra-sample) verbalization",
            "name_full": "Intra-sample KG linking / structure-inducing pretraining (entity linking within sentences)",
            "brief_description": "Representation that embeds graph-derived correlations into single training samples by linking entities in a sentence to external KGs and verbalizing relationships inline to induce structural signals during LM pretraining.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "representation_name": "Intra-sample KG verbalization (structure-inducing)",
            "representation_description": "Entities inside individual samples are connected to external KG facts; these relations are introduced into the sample (e.g., as appended phrases or inline annotations) to enforce intra-sample relational constraints during pretraining.",
            "representation_type": "sequential with intra-sample structural augmentation, lossy",
            "encoding_method": "Entity linking + inline triple insertion or appended relational sentences per sample; can be combined with auxiliary pretraining objectives.",
            "canonicalization": null,
            "average_token_length": null,
            "dataset_name": null,
            "task_name": "structure-inducing pretraining / improving reasoning by adding structural signals",
            "model_name": "Pretrained LMs with structure-inducing corpora",
            "model_description": "Standard LMs pretrained on corpora augmented at the sample level with linked KG facts and possibly auxiliary objectives to enforce relational geometry.",
            "performance_metric": null,
            "performance_value": null,
            "impact_on_training": "Reported to consistently improve downstream benchmarks that benefit from structured signals; helps activate reasoning abilities by increasing logical content in pretraining data.",
            "limitations": "Still relies on text sequences so some structural fidelity is lost; requires effective entity linking and high-quality KG facts; may increase pretraining complexity.",
            "comparison_with_other": "Compared to inter-sample structure constraints, intra-sample linking directly augments single inputs and more tightly couples graph facts with local context; compared to graph-native pretraining, it's more scalable but less faithful to topology.",
            "uuid": "e7015.6",
            "source_info": {
                "paper_title": "Large Knowledge Model: Perspectives and Challenges",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Graph of Thoughts / KGoT",
            "name_full": "Graph of Thoughts / CoT enhanced by Knowledge Graphs (KGoT)",
            "brief_description": "A structured Chain-of-Thought style prompt representation where reasoning paths are modeled as graphs and KG structure is used to build or expand these reasoning graphs; graph nodes correspond to intermediate thoughts or facts and edges to reasoning steps.",
            "citation_title": "Graph of thoughts: Solving elaborate problems with large language models.",
            "mention_or_use": "mention",
            "representation_name": "Graph-of-Thoughts / KG-enhanced CoT (KGoT)",
            "representation_description": "Rather than a linear CoT, reasoning is represented as a graph (nodes = intermediate steps, edges = logical connections); KGs can seed or expand nodes and relations, and the graph can be linearized or verbalized as structured prompts for LMs.",
            "representation_type": "hierarchical / graph-structured prompt, convertible to sequential text (lossy if verbalized)",
            "encoding_method": "Construct reasoning graph from KG relations and/or LM-generated nodes; when used with LMs, graph is typically converted to a sequence of prompted steps or branching prompts (tree/graph linearizations).",
            "canonicalization": null,
            "average_token_length": null,
            "dataset_name": null,
            "task_name": "structured Chain-of-Thought prompting / complex problem solving",
            "model_name": "LLMs using advanced prompting (Graph-of-Thoughts)",
            "model_description": "Large autoregressive LMs guided by structured (graph/tree) CoT prompts, sometimes with iterative search over graph branches.",
            "performance_metric": null,
            "performance_value": null,
            "impact_on_training": "Structured CoT (graph/tree) can substantially boost reasoning on complex tasks when integrated with KGs; KG-sourced structure aids coherence of multi-step reasoning.",
            "limitations": "Converting graphs to linear prompts loses branching topology; acquiring high-quality KG-based CoT is laborious; LMs may still struggle to fully exploit explicit graph structure.",
            "comparison_with_other": "More expressive than linear CoT; when combined with KGs offers better structure and factual grounding, but implementation and acquisition costs are higher.",
            "uuid": "e7015.7",
            "source_info": {
                "paper_title": "Large Knowledge Model: Perspectives and Challenges",
                "publication_date_yy_mm": "2023-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "K-BERT: enabling language representation with knowledge graph.",
            "rating": 2,
            "sanitized_title": "kbert_enabling_language_representation_with_knowledge_graph"
        },
        {
            "paper_title": "Colake: Contextualized language and knowledge embedding.",
            "rating": 2,
            "sanitized_title": "colake_contextualized_language_and_knowledge_embedding"
        },
        {
            "paper_title": "KG-BART: knowledge graphaugmented BART for generative commonsense reasoning.",
            "rating": 2,
            "sanitized_title": "kgbart_knowledge_graphaugmented_bart_for_generative_commonsense_reasoning"
        },
        {
            "paper_title": "KEPLER: A unified model for knowledge embedding and pre-trained language representation.",
            "rating": 2,
            "sanitized_title": "kepler_a_unified_model_for_knowledge_embedding_and_pretrained_language_representation"
        },
        {
            "paper_title": "InstructProtein: Aligning human and protein language via knowledge instruction.",
            "rating": 2,
            "sanitized_title": "instructprotein_aligning_human_and_protein_language_via_knowledge_instruction"
        },
        {
            "paper_title": "Tree of thoughts: Deliberate problem solving with large language models.",
            "rating": 1,
            "sanitized_title": "tree_of_thoughts_deliberate_problem_solving_with_large_language_models"
        },
        {
            "paper_title": "Graph of thoughts: Solving elaborate problems with large language models.",
            "rating": 2,
            "sanitized_title": "graph_of_thoughts_solving_elaborate_problems_with_large_language_models"
        },
        {
            "paper_title": "KG-FiD: Infusing knowledge graph in fusion-in-decoder for open-domain question answering.",
            "rating": 2,
            "sanitized_title": "kgfid_infusing_knowledge_graph_in_fusionindecoder_for_opendomain_question_answering"
        },
        {
            "paper_title": "T-RAG: lessons from the LLM trenches.",
            "rating": 1,
            "sanitized_title": "trag_lessons_from_the_llm_trenches"
        }
    ],
    "cost": 0.017168999999999997,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Large Knowledge Model: Perspectives and Challenges</p>
<p>Huajun Chen huajunsir@zju.edu.cn 
College of Computer Science
Zhejiang University
310027HangzhouChina</p>
<p>Large Knowledge Model: Perspectives and Challenges
E51F26A3A90ACDF9D4C52CF582EE4282
Humankind's understanding of the world is fundamentally linked to our perception and cognition, with human languages serving as one of the major carriers of world knowledge.In this vein, Large Language Models (LLMs) like ChatGPT epitomize the pre-training of extensive, sequence-based world knowledge into neural networks, facilitating the processing and manipulation of this knowledge in a parametric space.This article explores large models through the lens of "knowledge".We initially investigate the role of symbolic knowledge such as Knowledge Graphs (KGs) in enhancing LLMs, covering aspects like knowledge-augmented language model, structure-inducing pre-training, knowledgeable prompts, structured CoT, knowledge editing, semantic tools for LLM and knowledgeable AI agents.Subsequently, we examine how LLMs can boost traditional symbolic knowledge bases, encompassing aspects like using LLM as KG builder and controller, structured knowledge pretraining, and LLM-enhanced symbolic reasoning.Considering the intricate nature of human knowledge, we advocate for the creation of Large Knowledge Models (LKM), specifically engineered to manage diversified spectrum of knowledge structures.This promising undertaking would entail several key challenges, such as disentangling knowledge base from language models, cognitive alignment with human knowledge, integration of perception and cognition, and building large commonsense models for interacting with physical world, among others.We finally propose a five-"A" principle to distinguish the concept of LKM.</p>
<p>1 Language vs Knowledge</p>
<p>Human Language and World Knowledge</p>
<p>Humankind accumulates knowledge about the world in the processes of perceiving the world, with natural languages as the primary carrier of world knowledge [1].Historically, the vast majority of world knowledge has been described, documented, and passed on through natural languages.In addition to natural languages that record common-sense knowledge, human has also invented various scientific languages for describing specialized scientific knowledge, for examples, the mathematical languages that describe mathematical models [2,3], chemical languages such as SMILE for describing molecular structures [4,5], and genetic languages to model compositions of living organisms [6,7,8].</p>
<p>However, natural languages merely encode world knowledge through sequences of words, while human cognitive processes extend far beyond simple word sequences.Therefore, since early inceptions of AI, it has been a fundamental objective to explore machine-friendly formats for Knowledge Representations (KR) [9].Typical examples of these endeavors encompass Description Logics [10] for representing ontological knowledge, Prolog for rule-based logic [11], Semantic Networks for depicting conceptual relationships [12], and various others.</p>
<p>In traditional symbolic AI research, the logical structure and expressiveness of a KR is pivotal to the reasoning ability of the inference machines [9,10].Natural language sequences composed of simple words or concepts are generally considered to be unfavorable for machines to make inference, while arXiv:2312.02706v2[cs.AI] 26 Jun 2024 hierarchical taxonomies, complex ontologies, and rule-based logic are more conducive to machine reasoning.As highlighted later, even in the era of large models, there persists a positive correlation between the complexity level of data representations and the reasoning proficiency of large models.</p>
<p>Language Models vs Knowledge Graphs</p>
<p>Knowledge Graphs (KGs) model world entities, mental concepts and their relationships in form of graph structures, which are typically extracted or derived from natural language descriptions.With many inspirations from traditional symbolic AI, KGs integrate natural language descriptions and structure knowledge.Typical structural forms include: hierarchical structures(e.g., concept graphs), relational structures(e.g., relational entity graphs), temporal structures(e.g., event logic graphs), etc. Akin to natural languages, KGs encode knowledge symbolically, ensuring robust reliability, traceable reasoning, and human-centric interpretability.Large Language Models (LLMs) [13,14], such as ChatGPT, mark a paradigm shift in knowledge representation and processing.By autonomously compressing or projecting vast textual knowledge in form of human languages into neural networks, LLMs achieve a parameterized representation and handling of world knowledge.LLMs internalize deep word patterns and interactions from extensive text corpora, establishing a wider coverage of knowledge than conventional symbolic knowledge base.Advanced techniques like prompt or instruction tuning further imbue LLMs with prior human knowledge, expanding their generalization capacity and adaptability to new tasks.Unlike natural language and KGs, LLMs operate on a fully parameterized, machine-friendly basis, albeit less interpretable to humans.</p>
<p>As depicted in Figure 1, both LLMs and KGs are specifically developed for the representation and manipulation of knowledge.KGs provide highly accurate and interconnected knowledge, enabling controlled reasoning and enhanced human readability.Conversely,LLMs offer expansive coverage of knowledge, exhibit enhanced task generalization capabilities, and utilize a neural representation that optimizes machine efficiency.Yet, KGs face scalability challenges, are limited in their ability to extrapolate, and struggle with reasoning transferability.LLMs, despite their power, incur significant training costs, struggle with deep logical reasoning, and are susceptible to hallucination errors.</p>
<p>In this article, we aim to investigate large models through the lens of "knowledge".Our first focus is on how KGs can enhance LLMs.Topics include knowledge-augmented language modeling, structureinducing pre-training, knowledgeable prompts, structured Chains of Thought (CoT), semantic tools for LLMs, editing knowledge in large models, and the development of knowledgeable AI agents.We further examine the role of LLMs in enriching traditional symbolic knowledge bases, encompassing the utilizing of LLMs as KG builders and controllers, structured knowledge pre-training, LLM-driven symbolic reasoning.Acknowledging the intricate nature of human knowledge, we then conceptualize a Large Knowledge Model (LKM) in purpose to handle the diversity of structures of human knowledge.This may involve approaches of decoupling knowledge from language models, restructure pretraining with structure knowledge, building large commonsense model, among others.To distinguish the concept of LKM, we propose a five-"A" principle from the aspects of Augmented pretraing, Authentic knowledge, Accountable reasoning, Abundant knowledge coverage, and Aligned with knowledge.</p>
<p>Knowledge-Augmented Large Models</p>
<p>The first step towards Large Knowledge Models is to augment LLM with knowledge.In this context, "knowledge" specifically refers to more standardized semantic representations such as domain terminology or ontologies, more structured knowledge representations such as a KG, or richer logic descriptions such as text with CoT.We will discuss how knowledge can be effectively applied in various aspects in the life cycle of a LLM, including pre-training, fine-tuning with instructions, prompt engineering, Chain-of-Thought, AI agents, among others.</p>
<p>Expressiveness vs. Scaling Law: The Dichotomy in Knowledge Representation</p>
<p>Traditional research in symbolic Knowledge Representation (KR) mainly focuses on the link between representation expressiveness and reasoning ability, suggesting that more expressive or complex representations facilitate stronger reasoning.However, this perspective often overlooks a vital factor: the scale of knowledge also significantly influences reasoning.For example, the scaling law in large models [15] indicates that diversified reasoning abilities only emerge when the model reaches a Indeed, both expressiveness and scale act as balancing factors for reasoning capabilities as illustrated in Figure 3.More intricate representations result in more precise knowledge, like an ontology for KGs, thus enabling stronger reasoning, but incuring more challenging to acquire the knowledge in large scale.In contrast, simpler representations, like textual sequences for training large models, facilitate extensive coverage of knowledge but compromise delicate reasoning due to reduced precision.As we will delve deeper, this inherent contradiction forms the basis of the complementary nature of KGs and large models, driving advancements in augmenting large model with conventional symbolic KR.</p>
<p>LLM Pre-training with Knowledge Structure</p>
<p>Let's first address how to enhance the pre-training stage with various forms of knowledge.</p>
<p>Code Structure and Thought Logic</p>
<p>Numerous studies suggest that enhancing corpus structure or incorporating more logic into the training corpus can improve the reasoning performance of large models [16,17,18,19,20,21].For examples, code languages, characterized by their structured nature and abundant computational logic, would be more conducive to activating the reasoning capabilities of large models compared to natural languages [22,23].Similarly, Chain-of-Thought (CoT) prompts [24,25] contain more logical descriptions than ordinary text, thus being more effective in stimulating model reasoning ability.Further research reveals that CoT prompts are more effective when the model scale to a certain size, which can be explained as that a larger model contains more knowledge for reasoning, and the activation of these knowledge requires more logical prompts.</p>
<p>To delve deeper into the correlations between code structure and model reasoning, we introduce a study about "Reasoning with Program of Thoughts" [23].This research begins by establishing metrics for quantifying the complexity of code structure and code logic.For instance, codes featuring loop operations are considered as having richer computational logic and assigned with higher scores compared to those with mere variable assignment operations.Subsequently, we compile a series of code prompts with different levels of structure or logic scores, and assess their impact on model reasoning performance.Experimental analyses on various benchmarks reveal that the code prompts with higher structure or logic scores are more conducive to improving model reasoning performance.</p>
<p>Although the representation of code structure and CoT logic remains at a relatively simple level, it has nonetheless contributed to enhancing the reasoning capabilities of large models.It can be anticipated that the utilization of data representations with deeper logic and more complex structure, such as knowledge graphs, can further enhance the capabilities of models.</p>
<p>Knowledge-injecting Pre-training</p>
<p>Large models build their reasoning prowess by understanding sequences of words.To achieve deep reasoning similar to human cognitive processes, it's essential to progress beyond basic word semantics to the formation and comprehension of advanced concepts, entities, and their interconnections.Injecting knowledge graph with pre-training models is a promising strategy to enable such type of richer understanding and move beyond the limitations of simple word co-occurrences to embrace the complexity of higher-order reasoning.There exist several strategies for integrating knowledge graphs into pre-trained language models, broadly categorized based on the stage of integration: input layer, architecture layer, and objective layer as illustrated in Figure 4.   Input-layer Injection.At the input layer, the simplest strategy is to convert knowledge graphs into natural language descriptions, thus expanding the model's input without altering its architecture or training process.Notable examples include K-BERT [26] and CoLAKE [27], among others.The core idea revolves around leveraging the relationships between entities in knowledge graphs to enrich the contextual information of entities within sentences.Typically, the process begins with establishing connections between entities in sentences and those in the knowledge graph using entity linking technology.Subsequently, sentences are expanded with triples corresponding to these knowledge graph entities before being fed into the large model.Injecting knowledge at the input layer fundamentally serves as a form of data augmentation.These methods do not require modifications to the model's architecture and are compatible with various off-the-shelf models, making them easy to implement.Additionally, because both structured and textual knowledge are trained within the same model, this approach avoids mismatches between the textual representation space and the structured knowledge representation space.However, converting inherently structured graphs into text sequences inevitably leads to some loss of semantic representation, and the utilization of structural signals is not fully realized.</p>
<p> Intermediate-layer Injection.The second strategy involves initially employing structured knowledge representation learning methods, such as KG Embedding, to obtain vector representations of entities and relationships, which are then integrated into language models.Notable examples include ERNIE [28], KnowBERT [29], KG-BART [30], KT-NET [31], and BERT-MK [32].For instance, ERNIE starts by pre-training entity representations using TransE.The original textual input remains unchanged, following alignment and interaction with these entity vectors at the intermediate layer of the model with a simple attention mechanism.Since the entity vector representations have already learned the structured features from the original knowledge graphs, this approach better preserves the graph's structural semantics.However, since textual semantics and graph structure representations are derived from two different pre-training models, there might be interference between textual semantic signals and knowledge structure signals, potentially acting as noise to each other.</p>
<p> Objective-layer Injection.The third strategy employs knowledge injection at the objective level, often through multi-task learning and refined LOSS optimization.Notable examples include KEPLER [33], WKLM [34], JAKET [35], and BERT-MK [32].For instance, KE-PLER adds a KG embedding Loss on top of the standard masked prediction Loss, using a multi-task learning framework for simultaneous training.As the same encoder is used for both text and entity information, and a single Loss governs the learning of both KG embedding and language model pre-training, this method preserves more structural signals compared to input layer injection and avoid the need for explicit alignment between text and KG required by architecture layer injection.</p>
<p>Structure-inducing Pre-training</p>
<p>We have already mentioned that human knowledge is not a simple sequence of texts, but rather has a rich structure.In a study called "Structure-Inducing Pretraining" [36], the role of imposing relational structure in pretrained language models is investigated.The basic ideas involve crafting connections, either at inter-sample or intra-sample level, to enforce additional structural constraints on the geometric relationships within or between training samples.These constraints range from shallow, implemented via auxiliary pretraining objectives, to more intricate, implicitly integrated through strategies like data augmentation or sample-level contrastive learning.</p>
<p>A typical example of inter-sample structure constraints manifests in the injection of a protein-protein interaction network into the pretraining of a protein language model.This injection infuses the model with sample-level structural insights, i.e. the relational structures of protein interactions.A typical example of intra-sample structure manifests in the linking of entities within a sentence to an external knowledge graph, thereby introducing correlation information in a KG into the training sentences.</p>
<p>Both theoretical analysis and experimental verifications are performed and indicate a consistent improvement with structure-inducing across a variety of benchmarks.Another relevant research is so-called reStructured Pre-training [37].Rather than imposing external structural knowledge, as in those structure-inducing methods, reStructure approach delves into the structural signals inherent in the data itself.The world's data is rich with various structural signals in different formats.For instance, it could be as straightforward as the "next token" signal in a sentence, metadata for a given text, factual knowledge in a triple format, entity or relation annotations, dependency structures between words, and numerous others.To make LLMs better educated, it is justifiable to mine these structure signals automatically or semi-automatically, and restructure all of them into unified forms for pre-training models.</p>
<p>Knowledgeable Prompts</p>
<p>Next, we will explore how to utilize knowledge to enhance prompt instructions.</p>
<p>Prompt Engineering as Knowledge Engineering</p>
<p>Prompts refer to natural language text describing the instructions that an AI should perform, the context of instructions that an AI can inquire of, or the guidance to think that an AI can follow [38,24,39].It has been proven by numerous practices [40,41,42,43] that the quality of prompts has a huge impact on model outputs.By providing prompts or instructions with more specific details, the model can more accurately comprehend human intentions, leading to outputs that are more aligned with human instructions.</p>
<p>Prompt engineering is essentially comparable to knowledge engineering.Increasing number of research indicates that the complexity of prompts is closely correlated to model reasoning ability.The evolution of prompts ranges from mere textual prompt, CoT prompt with more logic descriptions to more structured prompts such as Program of Thoughts [22], Tree of Thoughts [44], and Graph of Thoughts [45], and even directly using logical rules as prompts [46].As the complexity and expressiveness of prompt representations increases, an improvement of model reasoning ability can be observed.However, there persist a trade-off between richness of prompt representations and scalability of prompts acquisition: higher expressiveness in prompts typically entail increased difficulty for acquisition, which is essentially similar to traditional knowledge engineering.Highquality prompt engineering is also time-consuming and laborious as like knowledge engineering.</p>
<p>Structured Chain of Thoughts</p>
<p>Chain of Thought (CoT) is a special type of prompts describing the thinking procedures that can guide large models to imitate human logical thinking.As previously discussed, employing more intricately structured CoT representations, such as Tree of Thoughts [44] or Graph of Thoughts [45], would bolsters the model's capacity for reasoning.</p>
<p>Moreover, KG is obviously conducive to enhancing the structure of CoT prompts.On the one hand, The structured knowledge in a KG proves useful in the formulation and generation of structured CoT prompts [19,16,17], to form a CoT knowledge graph (KGoT).On the other hand, through the entity linking technologies, structure correlations among concepts and entities in the KG can be used to expand and enhance CoT in natural language forms, making the textual CoT more in line with human thinking patterns based on associations,thereby enhancing their effectiveness in guiding AI reasoning.</p>
<p>KG to Instructions</p>
<p>Instruction tuning [38,39] refers to further training base models with task-specific instructions, typically converted from task-specific training data.Since data from various tasks are converted to an unified input form as instructions or prompts, instruction-tuning with massive downstream task would significantly improve model's generalization ability, that is, the ability to solve new problems or to complete new tasks.</p>
<p>Knowledge Graphs serve a dual roles of enhancing instruction-tuning.On the first hand, KGs can be directly injected into instruction prompts.For instances, KnowPrompt [47] utilizes the relational data in a KG to bolster the contextual depth of instruction prompts.Similarly, KANO [48] integrates structured knowledge from a chemical KG, sourced from Wikipedia, to refine functional prompts, thereby improving the learning process for molecular pretraining.</p>
<p>On the other hand, KGs can be directly converted to instructional datasets.As exemplified by DeepKE-LLM [49], a KG refined from WikiData is employed to automatically generate vast amount of training instructions for knowledge extraction.Essentially, these instructions converted from the KG represent a novel form of distant supervision, which leverages the structured information in KGs to generate instructions that guide models in understanding and extracting relevant information across diverse contexts.As shown in Figure 6, InstructProtein [50] introduces a knowledge graph-based instruction generation framework to construct a high-quality instruction datasets for training a protein language model .In particular, the instructions inherit the structural relations between proteins and function annotations in a protein knowledge graphs, which empowers the model to engage in the causal modeling of protein functions, akin to the chain-of-thought processes in natural languages.</p>
<p>Compared to free text, a KG is data corpus with richer logical structures and higher knowledge density.Many fields of knowledge graph data come from long-term artificial accumulation (such as Gene Ontology) or natural structured data transformation.Fully mining and using the knowledge structure contained in the knowledge graph (such as hierarchical concepts, entity relationship, temporal causality, rule logic, etc.) to enhance and enrich the prompt instruction or assist in the construction of more logical instruction data set, can help the model to complete more complex tasks.</p>
<p>KG-RAG: Knowledge-based Retrieval Augmented Generation</p>
<p>Retrieval-Augmented Generation (RAG) refers to the enhancement of large models' generative capabilities through querying an external knowledge base, which could be external search engines, domain-specific corpora, structured databases, or knowledge graphs.Due to its cost-effectiveness in training, avoidance of model hallucinations, and compliance with privacy and copyright standards, RAG has become an essential tool in large model applications.</p>
<p>Knowledge-augmented RAG leverages the conceptual hierarchies, entity connections, and logical rules within knowledge graphs to improve retrieval processes.The essence of RAG involves segmenting documents or images into data chunks, which are embedded and stored in a vector database for retrieval.The primary issue with chunking lies in the risk of losing the document's inherent logic and contextual relationships.Vector representations of these chunks offer merely a basic feature vector for similarity computation, falling short of capturing the deeper semantic connections among entities or concepts-a gap knowledge graphs were designed to bridge.</p>
<p>A practical way to apply KG-RAG is through the creation of entity or concept trees, enhancing RAG into versions like Entity-RAG or Topic-RAG.Using knowledge graphs to build hierarchical structures of concepts, topics, or entities, and connecting these elements within document chunks to the knowledge graphs, can significantly improve the retrieval process through these organized knowledge hierarchies.A typical example is Tree-RAG [51], which merges RAG search with an entity tree that enhances contextual retrieval in tandem with a vector database.This entity tree catalogs the hierarchy of organizational structures and their categories, such as departments and their subdivisions.The entity tree not only clarifies an entity's context within an organization but also boosts search across document chunks at an entity level, thus deepening the model's comprehension of entity relationships.</p>
<p>Another KG-RAG approach uses an entity graph to augment RAG.Initially, document chunks are processed using knowledge extraction to create a temporary, document-specific knowledge graph for RAG enhancement.When an external knowledge graph like WikiData is available, it's merged with the local graph and stored into a graph database.During retrieval, queries access both vector and graph databases to find relevant document chunks and associated triples, providing context for the large model to generate responses.KG-FiD [52] exemplifies this by blending retrieved paragraphs with external knowledge graphs.It firstly create a comprehensive KG that contains both paragraph-specific and external knowledge.Graph Neural Networks (GNN) are then used to semantically analyze and iteratively re-rank paragraphs based on their relevance, filtering out irrelevant content.This filtered content is then fed into the decoder as context, significantly improving response accuracy.</p>
<p>External knowledge can also enhance the generalization ability of large models.As discussed in RetroPrompt [53],large models usually rely on "mechanical memorization" to handle long-tailed or isolated samples rather than actually learning underlying patterns.This is one of the essential reasons why many large models have poor generalization ability in few-shot scenarios.It's like a student who only knows how to memorize things mechanically is relatively weak to extrapolate from one instance to others.RetroPrompt addresses this issue by decoupling knowledge from memory, and train a external knowledge base (not necessarily a KG here) independently.Prompts are then enriched by retrieving pertinent knowledge from the pretrained knowledge base.Experiments indicate that RetroPrompt manages to effectively improve the generalization ability of models particularly in few-shot scenarios.</p>
<p>KGs as References for Hallucination Mitigation</p>
<p>A well-known problem of large models is hallucination [54,55], where models generate responses based not on explicit textual evidence rather than on the amalgamation of implicit parameters within the neural network.Tackling these issues requires detecting those hallucination first.Knowledge graphs, known for their high accuracy and clear logical definitions due to manual verification, serve as an effective reference for detecting such issues.Their utility spans three key areas:</p>
<p> Fact Checking: This step compares the model's responses with the knowledge graph's triples to verify accuracy, relying on the graph's comprehensive coverage.</p>
<p> Logical Consistency: Utilizing the knowledge graph's logical structures to enhances the capacity to identify inaccuracies by examining the logical consistency of responses.</p>
<p> Validation Model Training: The strong semantic and logical integrity can be utilized to train a discriminator model that can assess or judge the accuracy of the generated content.</p>
<p>Knowledge graphs thus play a crucial role in improving large models' reliability by identifying hallucinations and detecting inaccuracies efficiently.</p>
<p>Large Model Knowledge Editing</p>
<p>In addition to detecting hallucinations, addressing this issue extends to directly correcting them.Just as we could query and interact with knowledge graphs in a symbolic space, we would also like to interrogate and manipulate the knowledge stored in the parameterized space of large models through query, edit, modify, delete, or update it.</p>
<p>Knowledge editing [56] is geared towards this purpose and aims to rectify incorrect knowledge, eliminate harmful content, or update outdated information parametrically.Yet, executing edits in the vast parameter space of large-scale neural models is a nontrivial task.It necessitates firstly locating the incorrect knowledge, then determining the scopes and boundaries of necessary modifications.Critically, because the knowledge within these models is highly interconnected, changing one piece of information could have far-reaching effects.</p>
<p>Efforts have been made to leverage knowledge graphs for generating structured data and enhancing reward feedback signals for large model optimization.The KnowPAT [57] framework introduces a novel approach by integrating domain-specific knowledge graphs into the model alignment process, enabling knowledge-informed human-machine alignment.This method unfolds in three succinct steps: first, it retrieves relevant information from the knowledge graph based on the input query; second, it constructs a knowledge preference set by using knowledge triples of varied quality to align model outputs with human preferences; finally, it applies this preference set to fine-tune and align the model, improving its performance and alignment with human knowledge and preferences.</p>
<p>Knowledge graphs could enhance large model knowledge editing in three ways.First, the validated, accurate content serves as a prime reference input for edits.Second, they help navigate the complex logical relationships essential for modifying model knowledge, offering a logic roadmap for adjusting parameters.However, unlike knowledge graphs, changes in large models' knowledge don't always revert cleanly due to their attention-based encoding, leading to potential errors or hallucinations.The most effective, albeit challenging, method involves using knowledge graphs from the start-during pre-training or fine-tuning-to guide the organization and storage of model knowledge, closely mirroring the symbolic representation of knowledge graphs.This would not only improve knowledge connectivity within the model but also simplifies the editing process by clearly defining the scope and effects of modifications [60].Building on this, as shown in Figure 8, the KnowPAT [57] framework leverages KGs to optimize large model alignment through the creation of partial order training data and enhanced reward feedback signals.KnowPAT's innovative strategy integrates domain-specific KGs into the alignment process for knowledge-driven human alignment.This process unfolds in three steps: firstly, extracting relevant KG information based on input queries; secondly, constructing a knowledge preference set from varied quality knowledge triples to align LLM outputs with human preferences; and finally, using this preference set for model fine-tuning, thereby enhancing both performance and alignment with human knowledge and preferences.</p>
<p>OpenAI's Weak-to-Strong generalization [61] reveals a future where AI surpasses human ability, highlighting a new challenge of guiding more powerful AIs with weaker human input.This contrasts with traditional models where a stronger human teacher supervises a weak AI.Knowledge graphs, while limited in scope, offer a targeted approach to align AI with human knowledge.The challenge lies in using these precise but smaller, weaker knowledge graphs to guide broader, less accurate AI models.This research direction focuses on refining AI understanding and application of human knowledge through detailed knowledge graphs, striving for AI systems that are both powerful and aligned with human values.</p>
<p>Semantic Tools for LLM</p>
<p>Tool-Augmented Language Models [62,63] are proposed to extend the functionalities of large models by integrating the ability to invoke external tools for problems solving beyond their native solution scope.These external tools can range from mathematical calculators, database interfaces to specific functional APIs.A complex task may require a orchestration of calling multiple tools, forming a complex tool calling logic.</p>
<p>Large models still face difficulties in autonomously learning such complex tool invocation logic, whereas knowledge graphs can be used in modeling the logic behind complex API combinations, a practice already prevalent in the traditional service computing architecture field [64].However, compared to the traditional software engineering field, by leveraging knowledge to model the logic of API calls and further guiding the process of API combination, with the language understanding capabilities of large models, we might not need to model the API relationships in very fine details.We might just need to provide textual descriptions of the tool's functions and how to invoke them, along with a simple description of the relationships between tools, such as the tool's hierarchical classification and simple associations.This could allow large models to learn the reasonable logic of tool invocation and combination on their own.LLMs such as ChatGPT enables the building of autonomous agents [65,66,67,68] that can solve complicated problems by communicating with each other.The deep relations between KGs and Agents rooted historically.Early KG technologies, such as RDF/OWL [69], were initially developed to enhance interactions among web-based agents and to act as a Knowledge Interchange Format [70].For instance, DAML [71], a forerunner to the OWL language, stands for a Agent Markup Language, underlining this connection.</p>
<p>Knowledgeable AI Agents</p>
<p>Knowledge could be a roadmap that leads to the destination.The advent of new LLM technologies would revolutionize the paradigm of knowledge exchange and interaction among agents.In scenarios where an agent's own knowledge is insufficient to solve a problem, it can autonomously seek assistance from other agents, bypassing the need for manually and accurately crafted knowledge exchange formats.This capability of LLM, together with accountability of KGs, foster more autonomous knowledge collaboration and paves the way for a more robust and effective community of agent collaborations.</p>
<p>KG-Augmented Large Multi-Modal Models</p>
<p>Large models are advancing towards integrating multiple modalities, enabling AI to master skills like seeing, hearing, and speaking, and enhancing interactions with the physical world.There has been substantial research on enhancing multi-modal processing with KGs.For instance, in zero-shot visual reasoning tasks, knowledge graphs are widely used to establish connections between new types of entities and known ones, assisting models to quickly gain the ability to recognize new types of entities by using knowledge graphs as a bridge for transfer learning [73].</p>
<p>Knowledge graphs can certainly be used to enhance the multi-modal generative capabilities of large models.For example, we can retrieve triples related to prompts from an external knowledge graph, and then use a large model to expand on these triples based on user input, enabling the large model to generate images that are richer in content and more in line with human expectations.In fact, the existing multi-modal large models are still quite weak in generating content that aligns with human cognitive concepts and intentions.We believe one reason for this is the lack of knowledge to constrain and control the generation process in these multi-modal large models.It's similar to how a human painter first forms a conceptual understanding of the objective world, and then uses the logical relationships between these concepts to constrain the creative process, ensuring that the content produced aligns with human cognition.</p>
<p>LLM-enhanced Symbolic Knowledge Bases</p>
<p>A second step towards Large Knowledge Model is to enhance conventional symbolic knowledge base with LLM.In this context, we take Knowledge Graphs as an exemplar type of such a symbolic KB.We will explore the multifaceted roleS of LLMs in enhancing various stages in the life-cycle of a KG including aspects such as KG building and management, structured knowledge pretraining, symbolic reasoning, and others.</p>
<p>Symbolic Knowledge Bases: A Necessity</p>
<p>Large language models like GPT showcase impressive knowledge representation and processing skills.However, they are not a one-size-fits-all solution.In many practical settings, symbolic systems prove to be sufficient or even superior.In critical scenarios requiring high reliability, the construction of a symbol-based knowledge base would ensure accuracy, offer traceable sources for its content, and provide enhanced interpretability.</p>
<p>Importantly, most existing information systems are developed symbolic representations.Often, there is no need to convert these into neural network representations for integration into large models, which can lead to a loss of transparency due to their "black box" nature.Looking forward, the future of intelligent systems likely lies in a hybrid approach that combines neural networks and symbolic systems, leveraging the strengths of each.A practical example of this is enhancing traditional symbolic knowledge bases with large models, which could be a more viable and scalable application in many real-world scenarios.</p>
<p>LLM as KG Builder</p>
<p>An in-depth evaluation of ChatGPT's capability in constructing a KG has been conducted [75].</p>
<p>According to the report, ChatGPT does have a notable ability to build a KG.For instance, ChatGPT can effectively generate a KG by giving only a simple instruction such as "create a KG for Zhejiang University", and easily format it into requested formats such as RDF/OWL.However, as GPT relies heavily on the AIGC model to generate the knowledge graph, the correctness rate is roughly 70-80% on average for common domains and even less than 20% for long-tail domains, due to its hallucination problem [75].When it comes to extracting knowledge from provided texts, ChatGPT's accuracy can exceed 90%.Despite this, its performance still falls short of the state-of-the-art (SOTA) achievements of existing small models in this domain [76,77,78].This discrepancy highlights the need for further refinement in LLM-based approach to KG construction and information extraction, particularly in balancing accuracy with the breadth of its generative capabilities.</p>
<p>In order to verify that the correct extraction from chatGPT does not come from knowledge seen before, that is, there is relevant knowledge in the training corpus, a fabricated KG [75] was designed and generated.Subsequently, we generate text based on these fictitious entities and relationships and presented them to ChatGPT for entity and relation extraction.The results were noteworthy: ChatGPT demonstrated a high degree of accuracy in identifying these fabricated entities and relations.This proficiency in generalized knowledge extraction is likely attributable to its instruction-driven tuning and the reward-based feedback learning mechanism.</p>
<p>Extraction is, in fact, a rather fundamental AI task.It is closely related to the concept of understanding, in that effective knowledge extraction from text is indicative of the model's semantic comprehension abilities.Therefore, it is anticipated that models fine-tuned with a focus on extraction instructions will not only excel in extraction tasks but also show enhanced performance across a broader spectrum of tasks [79,80].</p>
<p>We summarize the unique advantages of LLM as universal KG builder as follows.</p>
<p> Model-Centric Knowledge Extraction: In contrast to conventional methods of KG construction, ChatGPT leverages its extensive "model knowledge" and "generative inference" as additional components to extraction.This means that GPT can extract knowledge embedded within its own parameters or generate additional knowledge to enhance the extraction outcomes.This approach allows for the inclusion of additional knowledge in the results that may not be explicitly present in the source text.Such a strategy signifies a shift from a text-centric extraction to model-centric approach.</p>
<p> Instruction-driven Knowledge Extraction: As highlighted earlier, LLMs demonstrate remarkable precision in identifying previously unseen entity types and relations.This high level of accuracy is largely attributed to the advanced generalization capabilities enabled by instruction-driven learning.This adaptability enables LLMs to effectively process and recognize novel data inputs, transcending the limitations of traditional extraction methods heavily relying on laborious labeling efforts.</p>
<p> Generative Knowledge Graph Constructions: LLMs are equipped with powerful generative capabilities.In cases where knowledge is absent or insufficient in the model or source text, large models can still synthesize new knowledge for the KG.However, it is notable that while AIGC extends the depth and breadth of KGs, it also carries the risk of introducing incorrect knowledge.</p>
<p>LLM as KG Controller</p>
<p>Large models can function as potent controllers for managing and interacting with structured knowledge, primarily through their enhanced language understanding capabilities.These can be manifested in three aspects as depicted below:</p>
<p> Query Templates Enhancement : Traditional query answering methods for symbolic knowledge typically depend on manually crafted query templates.This process necessitates extensive maintenance of a vast amount of templates.Large models present an effective solution by automating the generation of high-quality templates, thereby ensuring greater consistency and lowering the costs associated with template maintenance. Text to Logical Query Parsing: Leveraging the language comprehension abilities of large models to convert natural language query into structured query formats (like SPARQL, Cypher, Gremlin, etc.) a more direct solution [19,81].This method frees programmers from the tedious and laborious task of manually devising query compositions, streamlining the process significantly. RAG-based KBQA [82]: Lastly, large models can enhance the retrieval process from structured knowledge bases by utilizing embedding-based techniques.This involves representing queries and the knowledge base in a high-dimensional space to improve the accuracy and relevance of the retrieved information.</p>
<p>Overall, these methods leverage the advanced language understanding capabilities of large models to make the interaction with structured knowledge more accessible, efficient, and user-friendly.</p>
<p>Boosting Symbolic Reasoning with Large Models</p>
<p>LLM Reasoning vs KG Reasoning</p>
<p>"Reasoning" refers to the cognitive process by which people derive conclusions from observed phenomena, combined with known facts, experiences, or rules [83,84].This fundamental AI challenge is widely studied across philosophy, computer science, and psychology.This article, however, focuses solely on reasoning within language models and knowledge graphs.</p>
<p>Both Knowledge Graphs (KGs) and Large Language Models (LLMs) support varied reasoning tasks.LLMs handle mathematical, commonsense, symbolic, logical, and multi-modal reasoning [83].KGs engage in concept reasoning, knowledge completion, multi-hop query reasoning, rule learning, inconsistency reasoning, and analogical reasoning [85,86,87,84].</p>
<p>Reasoning in KGs is based on explicitly acquired symbolic knowledge, making it interpretable and reliable.Techniques like graph neural networks or KG embedding enable reasoning in a vector space, yet KGs often lack the robustness and generalization capabilities of LLMs due to limited knowledge coverage.LLM reasoning [83] occurs in a parameterized, implicit space, depending heavily on the embedded knowledge.Unlike traditional methods, the reasoning abilities of LLMs scale with model size [88,89], enhancing their effectiveness on new tasks.However, this generative reasoning can lead to hallucinations, undermining result reliability.</p>
<p>LLM reasoning primarily focuses on leveraging textual semantics, while KG reasoning incorporates both textual semantics and the graph's structural knowledge.Here, we particularly explore how large models can enhance KG reasoning, which can be broadly categorized into three strategies as elaborated in the following sections</p>
<p>LLM-Centric Reasoning with KG</p>
<p>The first is LLM-Centric Reasoning which emphasizes the inference capabilities of large models to enhance KG reasoning directly.A simple approach in this vein is to reason with knowledge graphs with prompt engineering, where structured data from the knowledge graph is presented to a large model as contextual prompts for in-context learning.However, studies have shown that this method often performs even worse than traditional models like TransE, especially when textual information about entities is not included [75,90].This underperformance underscores the current large models' limited ability to effectively learn from structured data, leading to the development of new models that are specifically trained on graph data for improved performance.</p>
<p>Prompt engineering involves creating complex prompts, but large language models (LLMs) might struggle to grasp the structured data in knowledge graphs.A better strategy is to use the structured data from knowledge graphs to create instructions and employ instruction fine-tuning to improve LLM training [57].An example is illustrated in Figure 11.This approach integrates structured signals with instructional data to enhance the model's understanding of graph structures.It starts with pre-training using traditional KG embedding models to obtain initial entity and relationship embeddings, which include structured information.These embeddings are then combined with textual instructions for fine-tuning the LLM.Models fine-tuned this way typically outperform those without structural tuning and can even surpass traditional KG embedding models in tasks sensitive to structural details.The improved performance stems from the LLMs' strong language understanding abilities and their capacity to process structured information, enriched further by the embedded structured knowledge in the models.</p>
<p>KG-Centric Reasoning with LLM</p>
<p>The second is KG-Centric Reasoning which utilizes large models' language understanding abilities and structured training mechanisms to improve the reasoning performed by the knowledge graphs themselves.</p>
<p>This approach builds on traditional knowledge graph reasoning models such as KG Embedding, graph neural networks, and classical symbolic reasoning.However, it enhances these models by integrating the capabilities of large language models, which serve multiple supportive functions.Firstly, large models greatly enhance the understanding of language and semantics within the knowledge graph, improving how textual semantics are processed.Additionally, they enrich the reasoning process by integrating commonsense knowledge inherent in their training data.Furthermore, large models contribute by generating diverse and plausible reasoning chains, adding depth and breadth to the inference paths available within the knowledge graph.This integration of large models enhances the traditional reasoning capabilities, making the processes more dynamic and contextually rich.</p>
<p>Another approach in this vein is structured knowledge pre-training, which we will explore further in upcoming discussions on large graph models.This method does not strictly require the involvement of LLM.Instead, it utilizes architectures like Transformers to pre-train on knowledge graphs.The model, trained entirely on structured signals, then performs reasoning on the knowledge graphs.KGTransformer [92] exemplifies this approach.It employs several basic tasks for a KG, such as triple classification or head/tail prediction, to pretrain a structured knowledge graph.For downstream applications such as image classification, KGTransformer integrates a prompt fine-tuning mechanisms, which effectively harnesses the knowledge from the pretrained KG, thus enhancing downstream tasks' performance.</p>
<p>Synergistic Reasoning with KG and LLM</p>
<p>Lastly, a collaborative strategy combines the strengths of both large models and knowledge graphs, allowing them to work together interactively to achieve more sophisticated reasoning.On the one hand, a large language model can use a symbolic knowledge graph as an externally accessible tool.When it is necessary to give a definitive, reliable answer, the reasoning with a symbolic knowledge graph can be employed.On the other hand, when symbolic knowledge graph reasoning cannot derive an answer due to lack of knowledge, it is possible to use the extensive knowledge and high generalization ability of the large language model to give coarse-grained reasoning.Additionally, the interplay between LLMs (parametric, yet not entirely reliable) and KGs (symbolic, more interpretable) allows for their mutual enhancement and complementation.</p>
<p>Large Graph Model and Structured Knowledge Pretraining</p>
<p>Research shows that current large models often do not outperform traditional small models in tasks inherently reliant on structured knowledge, such as link prediction, association graph mining, subgraph analysis, or time-series prediction [75,93].The Large Graph Models [94,95] are then proposed for deriving insights from complex, graph-structured data, which is critical in a variety of advanced applications, including social network analysis, biological network analysis, and network security, among others.In this vein, we can develop special pre-training mechanisms tailored for encoding structured knowledge, transforming structured knowledge into instruction formats to boost model generalizability, or devising specific reward models for graph computation tasks.This approach is particularly valuable for big data analysis applications dependent on graph-structured data.</p>
<p>The implementation of large-scale graph models can be divided into three main approaches as surveyed in details in this article [94].</p>
<p> Graph-Centric Method.The first approach employs Graph Neural Networks (GNN-based Model), focusing primarily on traditional GNN algorithms across two main phases: pretraining and fine-tuning.The core architecture often utilizes the traditional Message Passing model or a Transformer model specially designed for graph structures.The Transformer model leverages attention mechanisms to assess the interaction weights among elements within the graph.During the pre-training phase, methods such as contrastive loss can be used, where graph data is augmented, deformed, or modified to create contrastive learning samples.These self-enhanced contrastive samples are then used to pre-train the model.In the fine-tuning phase, a variety of downstream graph tasks can be addressed, and model parameters can be fine-tuned for these tasks using prompt-based instructions. LLM-Centric Method.The second approach utilizes Large Language Models Model) and involves transforming graph data into sequences that mimic natural language for training with language models.This method encompasses two techniques: Graph-totoken and Graph-to-text.In the Graph-to-token technique, nodes and relationships from the graph structure are incorporated into natural language descriptions while retaining the token format of the graph.This allows the information to be processed by the language model while preserving the structural elements.Conversely, the Graph-to-text method translates graph descriptions into full-text narratives.This technique is particularly prevalent in knowledge graphs where each data triplet naturally corresponds to a sentence, facilitating direct conversion into text.Both methods convert inputs into natural language sequences, permitting the application of standard language model loss functions such as next-token prediction or masked prediction during pre-training.It's critical to recognize that these methods may involve some semantic loss, as the rich logical and semantic details present in graph structures can diminish when reduced to sequential formats. Synergistic Method.To mitigate the risk of semantic loss associated with relying solely on Large Language Models (LLMs), the third approach combines the capabilities of Graph Neural Networks (GNNs) and LLMs.In this hybrid model, LLMs can enhance GNNs by augmenting graph data before it is inputted into the GNN for prediction, leveraging the linguistic prowess of LLMs to enrich the data.Alternatively, GNNs can improve the performance of LLMs by providing structured signals that guide the reasoning process of the language models.This synergy can also extend to a bidirectional enhancement where both GNNs and LLMs align and refine each other's predictions, improving overall accuracy and coherence in outcomes.This integrated approach harnesses the strengths of both systems to overcome their individual limitations and boost their predictive capabilities.</p>
<p>4 From LLM to LKM Human knowledge, characterized by its complexity, is not optimally represented by mere sequences of free text.Our descriptions of the world often entail a variety of structured forms.One possible goal would be to create more advanced Large Knowledge Model (LKM) proficient in handling and deciphering the myriad structures of knowledge representation.This section aims to illuminate a roadmap and identify the key challenges in developing such a Large Knowledge Model.</p>
<p>Knowledge Soup: The Intricate Nature of Human Knowledge</p>
<p>The ability to process knowledge is one of the distinctive features that sets human intelligence apart from that of other species.For instance, lower life forms can only react directly to environmental stimuli, while smarter animals like cats and dogs are capable of selective actions based on perception, memory, and analogy.Humans, however, can abstract and induce knowledge from observations of the objective world and engage in complex reasoning through deduction, causation, analogy, and induction, thereby generating more rational behaviors.These higher-level intellectual activities are accomplished through knowledge, with natural language serving merely as one form of representing, carrying, and transmitting this knowledge.However, human knowledge is highly complex.</p>
<p>Figure 12: The Knowledge Soup Proposed by John Sowa [96] In the early studies of artificial intelligence knowledge representation, a concept known as "Knowledge Soup" was introduced by the renowned knowledge engineering scholar John Sowa [96].He believed that human knowledge plays a central role in cognitive behavior, but in reality, it is difficult to accurately represent and depict.He likened human knowledge to a bowl of soup: fluid rather than solidified, loosely organized rather than strictly defined, and dynamically changing rather than static.</p>
<p>The "soup" contains large solid chunks, fragmented particles, and flowing, formless liquids.Due to external heating or human influence, large particles are broken down into smaller ones, which dissolve into the liquid, while the liquid itself continuously evaporates and changes.This is akin to having large chunks of multimodal knowledge as well as fine-grained triplet knowledge or structured, logical, conceptual, and rule-based knowledge, alongside the fluid and formless liquid that could represent parameterized neural network knowledge.We can fragment large blocks of text to create fine-grained knowledge and further integrate this knowledge with modern neural networks, blending various types of knowledge together as like a fluid manner.</p>
<p>Decoupling World Knowledge from Large Models</p>
<p>The essential reason of the "largeness" in LLMs stem from the need for massive parameters to store vast amount of world knowledge.As highlighted by Bengio in a recent blog post [97], the parameters in these large models encompass two components: the World Model and the Inference Machine.</p>
<p>World models are used to store world knowledge, with actually a large portion of the neural network parameters serving as this purpose.The inference machine, responsible for reasoning computation, operate through the capabilities of language models.</p>
<p>Perhaps because human reasoning ability also heavily relies on language understanding ability, "Language" and "Knowledge" are actually inseparable in typical large language model.This blend of language and knowledge in large models is a departure from traditional symbolic AI systems such as expert systems, where components like the knowledge base and reasoning engine are implemented as independent modules.However, Bengio also pointed out that future large models should probably decouple the world model from the inference machine, so that part of the stored knowledge can be independently verified and maintained.</p>
<p>This implies the need to train a separate, likely very large knowledge model to handle the extensiveness of world knowledge, while conversely, to train a different language model, not necessarily have to be as large as nowadays' LLM, to perform reasoning tasks.This division allows for efficient allocation of model sizes according to their primary functions.Such a separation would allow the knowledge storage component to be independently verified and maintained, offering a potential approach to manage model size and enhance the verifiability and reliability of the model's knowledge.</p>
<p>In fact, the RAG (Retrieval-Augmented Generation) approach can be seen as a method of separating the knowledge base from larger models.In this setup, domain-specific knowledge bases are maintained and trained independently of the larger models.This allows for more focused and specialized handling of knowledge within these specific areas.</p>
<p>Cognitive Alignment with Human Knowledge</p>
<p>Numerous cognitive scientists posit that humans inherently favor structured thinking, tending to recall, reason, and plan via associative thinking.Recent research suggests that the way large models store knowledge lacks discernible patterns as like a KG [98].In other words, those knowledge that should be structured correlated does not show the expected associations in the parameter space, making it difficult for the model to make feasible correlations among knowledge pieces.There might be a sort of "cognitive gap" between the form of knowledge storage in large models and the organization of knowledge in the human mind.This cognitive gap becomes problematic in many critical scenarios when we expect the model to have more controllability, or to deal with deeper and more complex associative reasoning.</p>
<p>One way to alleviate this problem is to enhance the structure of the training corpus during the pretraining phase, known as restructure pretraining [95] or structure-inducing pretraining [36].That is, we can use automated or semi-automated methods to enhance the structured features of the text.For example, we can organize sentences more logically (essentially, CoT is a method to increase the structure and logic of texts).We can structure paragraphs more coherently, add links between words, create connections between training samples, or directly incorporating an external structured KG to structurally reinforce the entire training corpus.</p>
<p>This raise up an interesting question: how essentially knowledge is stored and activated in large model?Research in this area, known as "circuit pathways" [99], aims to explore how the neural substructures are formed as parameters and incrementally activated during predictions.More specific studies seek to uncover how components of triplet facts are stored and activated [100].Delving into the deep mechanisms of knowledge storage and reasoning in large language models is beyond this article's scope, but it raises several important questions: what factors shape the knowledge circuits within these models?Is the knowledge in human brain organized similarly to text sequences?The answer is likely not, suggesting that learning and activating such knowledge would require more advanced training techniques.</p>
<p>We need to align the representation, storage, and reasoning mechanisms of large models with the human brain's knowledge structures and cognitive processes.This alignment involves more than just adding structural signals or enhancing knowledge; it requires a fundamental overhaul of how knowledge is presented in training data, optimization functions, and constraints.By aligning the training data more closely with human cognitive structures, we can bridge the cognitive gap between large models and the human brain, enhancing the clarity, connectivity, and verifiability of the model's knowledge.This transformation could effectively turn a Large Language Model (LLM) into a Large Knowledge Model (LKM), aligning its knowledge structure more naturally with human cognitive processes.</p>
<p>Integration of Perception and Cognition</p>
<p>Knowledge Graphs fundamentally models abstract concepts or ontologies about the world.These ontologies in the human minds are formed through a cognitive process of abstract thinking, by which a myriad of world elements are firstly recognized and hierarchical concepts or ontological categories are further abstracted from understanding these elements.Large models learn rich knowledge about words and concepts from massive text corpora, excel in concept recognition and abstraction.This enables more advanced methods for tasks such as automated construction of conceptual hierarchies, ontological category expansion, attribute completion, ontology alignment, and concept normalization.</p>
<p>Demis Hassabis, co-founder of DeepMind, posed a thought-provoking question: "Can we build from our own perceptions, use deep learning systems, and learn from basic principles?Can we build up to higher-level thinking and symbolic thought?".Present large models still learn about the world from human-generated text corpora.Whether future large models can rely more on the model itself to learn world knowledge from the perceptual interaction with physical world, autonomously abstract concepts and ontologies about the world, and directly utilize this understanding about the physical world for decision-making, thereby achieving a profound integration of perception and cognition.</p>
<p>Commonsense Knowledge and Large World Model</p>
<p>A "world model" refers to a comprehensive model capable of accurately perceiving and understanding everything in the objective world and their complex relationships [101].Unlike language models that are primarily used for understanding human language, and vision models that are mainly for understanding visual data, world models need to process data across various modalities in both temporal and spacial dimensions.They aim to form a cognition of the world and interact with the physical environment to perform specific tasks.World models are essential for achieving general AI.They must not only handle multimodal sensory data but also learn the spatiotemporal representations of the world effectively.Importantly, world models ultimately need to establish a common-sense knowledge model about the world, enabling them to accurately grasp and understand the complex relationships between all things in the world, so that the AI can respond and act correctly in the physical world.</p>
<p>Knowledge models, especially common-sense knowledge models, are a crucial component of building world models.Commonsense knowledge encapsulates practical know-how and sound judgment about everyday situations, which is almost universally shared among humans.As defined by Marvin Minsky [102], commonsense knowledge encompasses "facts about events occurring in time, about the effects of actions by the knower and others, about physical objects and how they are perceived, and about their properties and their relations to one another."</p>
<p>Historically, the creation of commonsense knowledge bases has been a key challenge in AI, beginning with early projects like Cyc [103] and extending through initiatives such as ConceptNet [104], Yago [105], DBPedia [106], Wikidata [107], BabelNet [108], ATOMIC [109], and ASTER [110].These efforts aim to equip AI with robust commonsense knowledge bases.Yet, these systems often struggle with limited knowledge coverage and the reasoning capabilities of machines.Recent advancements in large language models like ChatGPT highlight significant potential in accumulating and applying commonsense knowledge, particularly due to their extensive knowledge coverage.Despite their strengths, these models face issues such as generating unreliable information (hallucination) and only supporting elementary commonsense reasoning tasks.</p>
<p>A promising direction for future research is to merge traditional commonsense knowledge bases with large language models to formulate a broad and integrated commonsense knowledge model.Such an approach could leverage the strengths of both systems to address their individual shortcomings, potentially leading to more robust and reliable Large World Model for AI in understanding and interacting with the real physical world.</p>
<p>Five-"A" Principle of LKM</p>
<p>In this final section, we strive to provide a general description on the concept of a Large Knowledge Model (LKM) and outline its pivotal characteristics.We outline the essential aspects of an LKM using a five-"A" framework as depicted in Figure 13.</p>
<p> Augmented Pretraining : Firstly, large knowledge models should be trained with a diverse range of knowledge structures rather than relying solely on sequential words.This can be achieved by incorporating additional logical elements into prompt instructions or by enhancing structural coherence, whether at the inter-sample or intra-sample level, as higlihgted in structure-inducing pretraining [36].The manner in which knowledge is stored within a large model should resemble the organization of knowledge in human mind.</p>
<p> Authentic Knoweldge: Secondly, large knowledge models should avoid generating hallucinations and offer authentic knowledge that can be independently verified.This can potentially be accomplished by decoupling knowledge representation from the language model, allowing for the independent maintenance, verification, and upgrading of the knowledge base.</p>
<p> Accountable Reasoning: Thirdly, the entire system should facilitate accountable reasoning processes that enhance both the reliability of answers and their interpretability to humans.This can be achieved by integrating symbolic reasoning over an external knowledge base with prompted reasoning by large language models.</p>
<p> Abundant Coverage: Fourthly, the entire system should offer abundant coverage of both general and domain-specific knowledge.This objective can be possibly accomplished by fostering the development of knowledgeable AI agents communities through a comprehensive integration of private knowledge bases, open commonsense knowledge, and LLM-based knowledge exchange among agent communities.</p>
<p> Aligend with Knowledge: Finally, the entire system should be in close alignment with human values and ethics, which have evolved as a form of advanced knowledge accumulated throughout the history of humanity.This could be probably achieved through the creation of sophisticated ethics knowledge bases and knowledge alignment technologies [57], which treat the ethic knowledge bases as aligning objectives.</p>
<p>Summary</p>
<p>Representing and processing world knowledge has been central to its objectives Since the advent of AI.Both large language models and knowledge graphs exhibit distinct advantages and limitations in handling world knowledge.Large language models excel in language comprehension, whereas knowledge graphs offer diversified methods for knowledge representations.A deeper integration of these two technologies promises a more holistic, reliable, and controllable approach to knowledge processing in the field of artificial intelligence.</p>
<p>Firstly, KGs can significantly contribute to various stages of LLM development.This include enhancing the model's capabilities and reducing training costs by refining the structure and logic of the training corpus or prompt instructions, and addressing the issue of hallucination generation.KGs are also poised to play a critical role in the evolution and future development of AI agent communities.</p>
<p>Secondly, LLMs can also contribute in multiple ways to the traditional knowledge graph technology stack.For instance, instruction-driven methodologies can facilitate knowledge extraction with enhanced generalization capabilities.The advanced language comprehension abilities of LLMs can be harnessed to significantly improve operations such as querying, answering, and updating structured knowledge.Moreover, the commonsense reasoning abilities of large models, grounded in natural language, can complement and strengthen the symbolic reasoning capabilities of knowledge graphs.</p>
<p>Lastly, the complexity of human knowledge necessitates the use of various structured descriptions to accurately depict the world.Sequential words alone fall short as the optimal medium for representing knowledge about world.The ultimate goal, therefore, is to develop a more advanced large knowledge model adept at interpreting the myriad structures of world knowledge.</p>
<p>Figure 1 :
1
Figure 1: Language, Knowledge, Language Models and Knowledge Graphs.</p>
<p>Figure 2 :
2
Figure 2: An Outline of the Whole Content Structure</p>
<p>Figure 3 :
3
Figure 3: The Dichotomy in Knowledge Representation</p>
<p>Figure 4 :
4
Figure 4: Knowledge Injection on Different Layers.</p>
<p>Figure 5 :
5
Figure 5: Structure-Augmented Pre-training</p>
<p>Figure 6 :
6
Figure 6: InstructProtein: an example of building instruction dataset with a KG[18]</p>
<p>Figure 7 :
7
Figure7: Editing knowledge in a LLM and a KG is quite different[58,59]</p>
<p>Figure 8 :
8
Figure 8: KnowPAT: an example of improving human alignment with a KG[57]</p>
<p>Figure 9 :
9
Figure 9: KnowAgent: an example of knowledgeable AI agent[72]</p>
<p>Figure 10 :
10
Figure10: Knowledge Graphs Meet Multi-modal Learning[74]</p>
<p>Figure 11 :
11
Figure 11: An example of augmenting LLM reasoning with a KG [91]</p>
<p>Figure 13 :
13
Figure 13: Five-"A" principle of LKM.</p>
<p>Input-layer Injection (c) Object-layer Injection
Token EmbeddingTim Cook is visiting Beijing NowToken EmbeddingKGE EmbeddingCEO_ofcapital_ofAppleChinatimcookisvisitingbeijingTim CookBeijing(a)(b) Intermediate-layer InjectionKGE Loss+MLM LossToken EmbeddingKGE EmbeddingToken EmbeddingToken Embeddingis an Americanwas founded onbusiness exe April 1, 1976, (Tim Cook,CEO_of,Apple)
On December 12, 1980, Apple (ticker symbol "AAPL") went ...</p>
<p>AcknowledgementsI would like to express my gratitude to all the members of the Knowledge Engine Lab at Zhejiang University for their invaluable support and contributions.Additionally, I would extend my sincere thanks to our collaborators for their partnership.Special appreciation goes to Dr. Mingyang Chen for his diligent content review.
G Yule, The study of language. Cambridge University Press20196th ed.</p>
<p>Let's verify step by step. Vineet Hunter Lightman, Yura Kosaraju, Harrison Burda, John Edwards ; Leike, Ilya Schulman, Karl Sutskever, Cobbe, CoRR, abs/2305.20050Jan. 2023Bowen Baker, Teddy Lee</p>
<p>Measuring mathematical problem solving with the MATH dataset. Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, Jacob Steinhardt, NeurIPS Datasets and Benchmarks. 2021</p>
<p>. Stanislaw Jastrzebski, Damian Lesniak, Wojciech Marian Czarnecki, CoRR, abs/1602.062892016Learning to SMILE(S</p>
<p>Seq2seq fingerprint: An unsupervised deep molecular embedding for drug discovery. Zheng Xu, Sheng Wang, Feiyun Zhu, Junzhou Huang, BCB. ACM2017</p>
<p>Gene ontology: tool for the unification of biology. Michael Ashburner, Catherine A Ball, Judith A Blake, David Botstein, Heather Butler, J Michael, Allan P Cherry, Kara Davis, Selina S Dolinski, Janan T Dwight, Midori A Eppig, David P Harris, Laurie Hill, Andrew Issel-Tarver, Suzanna Kasarskis, John C Lewis, Joel E Matese, Martin Richardson, Gerald M Ringwald, Gavin Rubin, Sherlock, Nature Genetics. 2512000</p>
<p>The gene ontology resource: 20 years and still going strong. The Gene, Ontology Consortium, Nucleic Acids Res. 472019</p>
<p>Ontoprotein: Protein pretraining with gene ontology embedding. Ningyu Zhang, Zhen Bi, Xiaozhuan Liang, Siyuan Cheng, Haosen Hong, Shumin Deng, Qiang Zhang, Jiazhang Lian, Huajun Chen, ICLR. OpenReview.net2022</p>
<p>What is a knowledge representation?. Randall Davis, Howard E Shrobe, Peter Szolovits, AI Mag. 1411993</p>
<p>An Introduction to Description Logic. Franz Baader, Ian Horrocks, Carsten Lutz, Ulrike Sattler, 2017Cambridge University Press</p>
<p>Fifty years of prolog and beyond. Philipp Krner, Michael Leuschel, Joo Barbosa, Santos Vtor, Vernica Costa, Manuel V Dahl, Hermenegildo, F Jos, Jan Morales, Daniel Wielemaker, Salvador Diaz, Abreu, Theory Pract. Log. Program. 2262022</p>
<p>What's in a link: Foundations for semantic networks. William A Woods, 1975</p>
<p>Kun Wayne Xin Zhao, Junyi Zhou, Tianyi Li, Xiaolei Tang, Yupeng Wang, Yingqian Hou, Beichen Min, Junjie Zhang, Zican Zhang, Yifan Dong, Chen Du, Yushuo Yang, Zhipeng Chen, Jinhao Chen, Ruiyang Jiang, Yifan Ren, Xinyu Li, Zikang Tang, Peiyu Liu, Jian-Yun Liu, Ji-Rong Nie, Wen, CoRR, abs/2303.18223A survey of large language models. 2023</p>
<p>Harnessing the power of llms in practice: A survey on chatgpt and beyond. Jingfeng Yang, Hongye Jin, Ruixiang Tang, Xiaotian Han, Qizhang Feng, Haoming Jiang, Bing Yin, Xia Hu, CoRR, abs/2304.137122023</p>
<p>Jared Kaplan, Sam Mccandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, Dario Amodei, arXiv:2001.08361Scaling laws for neural language models. 2020arXiv preprint</p>
<p>Think-on-graph: Deep and responsible reasoning of large language model with knowledge graph. Jiashuo Sun, Chengjin Xu, Lumingyuan Tang, Saizhuo Wang, Chen Lin, Yeyun Gong, Heung-Yeung Shum, Jian Guo, CoRR, abs/2307.076972023</p>
<p>Knowledge graph prompting sparks graph of thoughts in large language models. Yilin Wen, Zifeng Wang, Jimeng Sun, Mindmap, CoRR, abs/2308.097292023</p>
<p>Instructprotein: Aligning human and protein language via knowledge instruction. Zeyuan Wang, Qiang Zhang, Keyan Ding, Ming Qin, Xiang Zhuang, Xiaotong Li, Huajun Chen, CoRR, abs/2310.032692023</p>
<p>Chain of knowledge: A framework for grounding large language models with structured knowledge bases. Xingxuan Li, Ruochen Zhao, Ken Yew, Bosheng Chia, Lidong Ding, Bing, R Shafiq, Soujanya Joty, Poria, CoRR, abs/2305.132692023</p>
<p>Unifying large language models and knowledge graphs: A roadmap. Linhao Shirui Pan, Yufei Luo, Chen Wang, Jiapu Chen, Xindong Wang, Wu, CoRR, abs/2306.083022023</p>
<p>Knowledge-infused prompting: Assessing and advancing clinical text data generation with large language models. Ran Xu, Hejie Cui, Yue Yu, Xuan Kan, Wenqi Shi, Yuchen Zhuang, Wei Jin, Joyce C Ho, Carl Yang, CoRR, abs/2311.002872023</p>
<p>Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. Wenhu Chen, Xueguang Ma, Xinyi Wang, William W Cohen, CoRR, abs/2211.125882022</p>
<p>When do program-of-thoughts work for reasoning?. Zhen Bi, Ningyu Zhang, Yinuo Jiang, Shumin Deng, Guozhou Zheng, Huajun Chen, CoRR, abs/2308.154522023</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H Chi, V Quoc, Denny Le, Zhou, NeurIPS2022</p>
<p>Self-consistency improves chain of thought reasoning in language models. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H Chi, Sharan Narang, Aakanksha Chowdhery, Denny Zhou, ICLR. OpenReview.net2023</p>
<p>K-BERT: enabling language representation with knowledge graph. Weijie Liu, Peng Zhou, Zhe Zhao, Zhiruo Wang, Qi Ju, Haotang Deng, Ping Wang, AAAI. AAAI Press2020</p>
<p>Colake: Contextualized language and knowledge embedding. Tianxiang Sun, Yunfan Shao, Xipeng Qiu, Qipeng Guo, Yaru Hu, Xuanjing Huang, Zheng Zhang, COLING. International Committee on Computational Linguistics2020</p>
<p>ERNIE: enhanced language representation with informative entities. Zhengyan Zhang, Xu Han, Zhiyuan Liu, Xin Jiang, Maosong Sun, Qun Liu, ACL (1). Association for Computational Linguistics2019</p>
<p>Knowledge enhanced contextual word representations. Matthew E Peters, Mark Neumann, Robert L Logan, I V , Roy Schwartz, Vidur Joshi, Sameer Singh, Noah A Smith, EMNLP/IJCNLP (1). Association for Computational Linguistics2019</p>
<p>KG-BART: knowledge graphaugmented BART for generative commonsense reasoning. Ye Liu, Yao Wan, Lifang He, Hao Peng, Philip S Yu, AAAI. AAAI Press2021</p>
<p>Enhancing pre-trained language representations with rich knowledge for machine reading comprehension. An Yang, Quan Wang, Jing Liu, Kai Liu, Yajuan Lyu, Hua Wu, Qiaoqiao She, Sujian Li, ACL (1). Association for Computational Linguistics2019</p>
<p>Integrating graph contextualized knowledge into pre-trained language models. Bin He, Di Zhou, Jinghui Xiao, Xin Jiang, Qun Liu, Nicholas Jing Yuan, Tong Xu, EMNLP (Findings), volume EMNLP 2020 of Findings of ACL. Association for Computational Linguistics2020</p>
<p>KEPLER: A unified model for knowledge embedding and pre-trained language representation. Xiaozhi Wang, Tianyu Gao, Zhaocheng Zhu, Zhengyan Zhang, Zhiyuan Liu, Juanzi Li, Jian Tang, Trans. Assoc. Comput. Linguistics. 92021</p>
<p>Pretrained encyclopedia: Weakly supervised knowledge-pretrained language model. Wenhan Xiong, Jingfei Du, William Yang, Wang , Veselin Stoyanov, ICLR. OpenReview.net. 2020</p>
<p>JAKET: joint pre-training of knowledge graph and language understanding. Donghan Yu, Chenguang Zhu, Yiming Yang, Michael Zeng, AAAI. AAAI Press2022</p>
<p>Knowledge graph-enhanced molecular contrastive learning with functional prompt. B A Matthew, Brendan Mcdermott, Peter Yap, Marinka Szolovits, Zitnik, Nature Machine Intelligence. 52023</p>
<p>. Weizhe Yuan, Pengfei Liu, 2206.11147, 2022restructured pre-training. CoRR, abs/</p>
<p>Training language models to follow instructions with human feedback. Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll L Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F Christiano, Jan Leike, Ryan Lowe, NeurIPS. 2022</p>
<p>Finetuned language models are zero-shot learners. Jason Wei, Maarten Bosma, Y Vincent, Kelvin Zhao, Adams Wei Guu, Brian Yu, Nan Lester, Andrew M Du, Dai, V Quoc, Le, ICLR. OpenReview.net2022</p>
<p>Automatic chain of thought prompting in large language models. Zhuosheng Zhang, Aston Zhang, Mu Li, Alex Smola, ICLR. OpenReview.net. 2023</p>
<p>Large language models are human-level prompt engineers. Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, Jimmy Ba, ICLR. OpenReview.net. 2023</p>
<p>Autoprompt: Eliciting knowledge from language models with automatically generated prompts. Taylor Shin, Yasaman Razeghi, Robert L Logan, I V , Eric Wallace, Sameer Singh, EMNLP (1). Association for Computational Linguistics2020</p>
<p>Qiaoqiao She, and Yongdong Zhang. knn prompting: Beyond-context learning with calibration-free nearest neighbor inference. Benfeng Xu, Quan Wang, Zhendong Mao, Yajuan Lyu, ICLR. OpenReview.net. 2023</p>
<p>Tree of thoughts: Deliberate problem solving with large language models. Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, Karthik Narasimhan, CoRR, abs/2305.106012023</p>
<p>Graph of thoughts: Solving elaborate problems with large language models. Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski, Piotr Nyczyk, Torsten Hoefler, CoRR, abs/2308.096872023</p>
<p>PTR: prompt tuning with rules for text classification. Xu Han, Weilin Zhao, Ning Ding, Zhiyuan Liu, Maosong Sun, AI Open. 32022</p>
<p>Knowprompt: Knowledge-aware prompt-tuning with synergistic optimization for relation extraction. Xiang Chen, Ningyu Zhang, Xin Xie, Shumin Deng, Yunzhi Yao, Chuanqi Tan, Fei Huang, Luo Si, Huajun Chen, WWW. ACM2022</p>
<p>Knowledge graph-enhanced molecular contrastive learning with functional prompt. Yin Fang, Qiang Zhang, Ningyu Zhang, Zhuo Chen, Xiang Zhuang, Xin Shao, Xiaohui Fan, Huajun Chen, Nature Machine Intelligence. 52023</p>
<p>Ningyu Zhang, Jintian Zhang, Xiaohan Wang, Honghao Gui, Kangwei Liu, Yinuo Jiang, Xiang Chen, Shengyu Mao, Shuofei Qiao, Yuqi Zhu, Zhen Bi, Jing Chen, Xiaozhuan Liang, Yixin Ou, Runnan Fang, Zekun Xi, Xin Xu, Lei Li, Peng Wang, Mengru Wang, Yunzhi Yao, Bozhong Tian, Yin Fang, Guozhou Zheng, and Huajun Chen. Knowlm technical report. 2023</p>
<p>Instructprotein: Aligning human and protein language via knowledge instruction. Zeyuan Wang, Qiang Zhang, Keyan Ding, Ming Qin, Xiang Zhuang, Xiaotong Li, Huajun Chen, CoRR, abs/2310.032692023</p>
<p>T-RAG: lessons from the LLM trenches. Masoomali Fatehkia, Ji Kim Lucas, Sanjay Chawla, CoRR, abs/2402.074832024</p>
<p>Kg-fid: Infusing knowledge graph in fusion-indecoder for open-domain question answering. Donghan Yu, Chenguang Zhu, Yuwei Fang, Wenhao Yu, Shuohang Wang, Yichong Xu, Xiang Ren, Yiming Yang, Michael Zeng, ACL (1). Association for Computational Linguistics2022</p>
<p>Decoupling knowledge from memorization: Retrieval-augmented prompt learning. Xiang Chen, Lei Li, Ningyu Zhang, Xiaozhuan Liang, Shumin Deng, Chuanqi Tan, Fei Huang, Luo Si, Huajun Chen, NeurIPS2022</p>
<p>Trustworthy llms: a survey and guideline for evaluating large language models' alignment. Yang Liu, Yuanshun Yao, Jean-Francois Ton, Xiaoying Zhang, Ruocheng Guo, Hao Cheng, Yegor Klochkov, Muhammad Faaiz Taufiq, Hang Li, CoRR, abs/2308.053742023</p>
<p>Can knowledge graphs reduce hallucinations in llms? : A survey. Garima Agrawal, Tharindu Kumarage, Zeyad Alghami, Huan Liu, CoRR, abs/2311.079142023</p>
<p>Easyedit: An easy-to-use knowledge editing framework for large language models. Peng Wang, Ningyu Zhang, Xin Xie, Yunzhi Yao, Bozhong Tian, Mengru Wang, Zekun Xi, Siyuan Cheng, Kangwei Liu, Guozhou Zheng, Huajun Chen, CoRR, abs/2308.072692023</p>
<p>Knowledgeable preference alignment for llms in domain-specific question answering. Yichi Zhang, Zhuo Chen, Yin Fang, Lei Cheng, Yanxi Lu, Fangming Li, Wen Zhang, Huajun Chen, CoRR, abs/2311.065032023</p>
<p>Detoxifying large language models via knowledge editing. Mengru Wang, Ningyu Zhang, Ziwen Xu, Zekun Xi, Shumin Deng, Yunzhi Yao, Qishen Zhang, Linyi Yang, Jindong Wang, Huajun Chen, CoRR, abs/2403.144722024</p>
<p>A comprehensive study of knowledge editing for large language models. Ningyu Zhang, Yunzhi Yao, Bozhong Tian, Peng Wang, Shumin Deng, Mengru Wang, Zekun Xi, Shengyu Mao, Jintian Zhang, Yuansheng Ni, Siyuan Cheng, Ziwen Xu, Xin Xu, Jia-Chen Gu, Yong Jiang, Pengjun Xie, Fei Huang, Lei Liang, Zhiqiang Zhang, Xiaowei Zhu, Jun Zhou, Huajun Chen, CoRR, abs/2401.012862024</p>
<p>Editing large language models: Problems, methods, and opportunities. Yunzhi Yao, Peng Wang, Bozhong Tian, Siyuan Cheng, Zhoubo Li, Shumin Deng, Huajun Chen, Ningyu Zhang, CoRR, abs/2305.131722023</p>
<p>Weak-to-strong generalization: Eliciting strong capabilities with weak supervision. Collin Burns, Pavel Izmailov, Jan Hendrik Kirchner, Bowen Baker, Leo Gao, Leopold Aschenbrenner, Yining Chen, Adrien Ecoffet, Manas Joglekar, Jan Leike, Ilya Sutskever, Jeff Wu, CoRR, abs/2312.093902023</p>
<p>Augmented language models: a survey. Grgoire Mialon, Roberto Dess, Maria Lomeli, Christoforos Nalmpantis, Ramakanth Pasunuru, Roberta Raileanu, Timo Baptiste Rozire, Jane Schick, Asli Dwivedi-Yu, Edouard Celikyilmaz, Yann Grave, Thomas Lecun, Scialom, CoRR, abs/2302.078422023</p>
<p>Toolformer: Language models can teach themselves to use tools. Timo Schick, Jane Dwivedi-Yu, Roberto Dess, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, Thomas Scialom, CoRR, abs/2302.047612023</p>
<p>Adapting golog for composition of semantic web services. Sheila Mcilraith, Tran Cao, Son , 2002</p>
<p>Xipeng Qiu, Xuanjing Huan, and Tao Gui. The rise and potential of large language model based agents: A survey. Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan, Xiao Wang, Limao Xiong, Yuhao Zhou, Weiran Wang, Changhao Jiang, Yicheng Zou, Xiangyang Liu, Zhangyue Yin, Shihan Dou, Rongxiang Weng, Wensen Cheng, Qi Zhang, Wenjuan Qin, Yongyan Zheng, CoRR, abs/2309.078642023</p>
<p>Agents: An open-source framework for autonomous language agents. Wangchunshu Zhou, Yuchen Eleanor Jiang, Long Li, Jialong Wu, Tiannan Wang, Shi Qiu, Jintian Zhang, Jing Chen, Ruipu Wu, Shuai Wang, Shiding Zhu, Jiyu Chen, Wentao Zhang, Ningyu Zhang, Huajun Chen, Peng Cui, Mrinmaya Sachan, CoRR, abs/2309.078702023</p>
<p>Hugginggpt: Solving AI tasks with chatgpt and its friends in huggingface. Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, Yueting Zhuang, CoRR, abs/2303.175802023</p>
<p>CAMEL: communicative agents for "mind" exploration of large scale language model society. Guohao Li, Hasan Abed, Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, Bernard Ghanem, CoRR, abs/2303.177602023</p>
<p>From SHIQ and RDF to OWL: the making of a web ontology language. Ian Horrocks, F Peter, Frank Patel-Schneider, Van Harmelen, J. Web Semant. 112003</p>
<p>Knowledge interchange format. R Michael, Genesereth, KR. Morgan Kaufmann1991</p>
<p>Accessing information and services on the daml-enabled web. Grit Denker, Jerry R Hobbs, David L Martin, Srini Narayanan, Richard J Waldinger, SemWeb. CEUR Workshop Proceedings. CEUR-WS.org. 200140</p>
<p>Knowagent: Knowledge-augmented planning for llm-based agents. Yuqi Zhu, Shuofei Qiao, Yixin Ou, Shumin Deng, Ningyu Zhang, Shiwei Lyu, Yue Shen, Lei Liang, Jinjie Gu, Huajun Chen, CoRR, abs/2403.031012024</p>
<p>Knowledge-aware zero-shot learning: Survey and perspective. Jiaoyan Chen, Yuxia Geng, Zhuo Chen, Ian Horrocks, Jeff Z Pan, Huajun Chen, IJCAI. 2021</p>
<p>Knowledge graphs meet multi-modal learning: A comprehensive survey. Zhuo Chen, Yichi Zhang, Yin Fang, Yuxia Geng, Lingbing Guo, Xiang Chen, Qian Li, Wen Zhang, Jiaoyan Chen, Yushan Zhu, Jiaqi Li, Xiaoze Liu, Jeff Z Pan, Ningyu Zhang, Huajun Chen, CoRR, abs/2402.053912024</p>
<p>Llms for knowledge graph construction and reasoning: Recent capabilities and future opportunities. Yuqi Zhu, Xiaohan Wang, Jing Chen, Shuofei Qiao, Yixin Ou, Yunzhi Yao, Shumin Deng, Huajun Chen, Ningyu Zhang, CoRR, abs/2305.131682023</p>
<p>A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity. Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, Quyet V Do, Yan Xu, Pascale Fung, IJCNLP (1). Association for Computational Linguistics2023</p>
<p>Exploring the feasibility of chatgpt for event extraction. Jun Gao, Huan Zhao, Changlong Yu, Ruifeng Xu, CoRR, abs/2303.038362023</p>
<p>Zero-shot information extraction via chatting with chatgpt. Xiang Wei, Xingyu Cui, Ning Cheng, Xiaobin Wang, Xin Zhang, Shen Huang, Pengjun Xie, Jinan Xu, Yufeng Chen, Meishan Zhang, Yong Jiang, Wenjuan Han, CoRR, abs/2302.102052023</p>
<p>Instructie: A chinese instructionbased information extraction dataset. Honghao Gui, Jintian Zhang, Hongbin Ye, Ningyu Zhang, CoRR, abs/2305.115272023</p>
<p>Making language models better tool learners with execution feedback. Shuofei Qiao, Honghao Gui, Huajun Chen, Ningyu Zhang, CoRR, abs/2305.130682023</p>
<p>Nlqxform: A language model-based question to SPARQL transformer. Ruijie Wang, Zhiruo Zhang, Luca Rossetto, Florian Ruosch, Abraham Bernstein, CoRR, abs/2311.075882023</p>
<p>Improving multi-hop question answering over knowledge graphs using knowledge base embeddings. Apoorv Saxena, Aditay Tripathi, Partha P Talukdar, ACL. Association for Computational Linguistics2020</p>
<p>Reasoning with language model prompting: A survey. Shuofei Qiao, Yixin Ou, Ningyu Zhang, Xiang Chen, Yunzhi Yao, Shumin Deng, Chuanqi Tan, Fei Huang, Huajun Chen, ACL (1). Association for Computational Linguistics2023</p>
<p>Neural-symbolic entangled framework for complex query answering. Zezhong Xu, Wen Zhang, Peng Ye, Hui Chen, Huajun Chen, NeurIPS2022</p>
<p>Knowledge graph reasoning with logics and embeddings: Survey and perspective. Wen Zhang, Jiaoyan Chen, Juan Li, Zezhong Xu, Jeff Z Pan, Huajun Chen, CoRR, abs/2202.074122022</p>
<p>Inductive relation prediction using analogy subgraph embeddings. Jiarui Jin, Yangkun Wang, Kounianhua Du, Weinan Zhang, Zheng Zhang, David Wipf, Yong Yu, Quan Gan, ICLR. OpenReview.net. 2022</p>
<p>Ruleformer: Context-aware rule mining over knowledge graph. Zezhong Xu, Peng Ye, Hui Chen, Meng Zhao, Huajun Chen, Wen Zhang, COLING. International Committee on Computational Linguistics2022</p>
<p>Emergent abilities of large language models. Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, William Fedus, Trans. Mach. Learn. Res. 20222022</p>
<p>Language models are few-shot learners. Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, CoRR, abs/2005.14165Ilya Sutskever, and Dario Amodei. Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford2020</p>
<p>KICGPT: large language model with knowledge in context for knowledge graph completion. Yanbin Wei, Qiushi Huang, Yu Zhang, James T Kwok, EMNLP (Findings). Association for Computational Linguistics2023</p>
<p>Making large language models perform better in knowledge graph completion. Yichi Zhang, Zhuo Chen, Wen Zhang, Huajun Chen, CoRR, abs/2310.066712023</p>
<p>Structure pretraining and prompt tuning for knowledge graph transfer. Wen Zhang, Yushan Zhu, Mingyang Chen, Yuxia Geng, Yufeng Huang, Yajing Xu, Wenting Song, Huajun Chen, WWW. ACM2023</p>
<p>Chatgpt evaluation on sentence level relations: A focus on temporal, causal, and discourse relations. Chunkit Chan, Jiayang Cheng, Weiqi Wang, Yuxin Jiang, Tianqing Fang, Xin Liu, Yangqiu Song, CoRR, abs/2304.148272023</p>
<p>Towards graph foundation models: A survey and beyond. Jiawei Liu, Cheng Yang, Zhiyuan Lu, Junze Chen, Yibo Li, Mengmei Zhang, Ting Bai, Yuan Fang, Lichao Sun, Philip S Yu, Chuan Shi, CoRR, abs/2310.118292023</p>
<p>Graphgpt: Graph instruction tuning for large language models. Jiabin Tang, Yuhao Yang, Wei Wei, Lei Shi, Lixin Su, Suqi Cheng, Dawei Yin, Chao Huang, CoRR, abs/2310.130232023</p>
<p>The challenge of knowledge soup. John F Sowa, 2006</p>
<p>Scaling in the service of reasoning &amp; model-based ml. Yoshua Bengio, Edward J Hu, 2023</p>
<p>Structgpt: A general framework for large language model to reason over structured data. Jinhao Jiang, Kun Zhou, Zican Dong, Keming Ye, Wayne Xin Zhao, Ji-Rong Wen, CoRR, abs/2305.096452023</p>
<p>Interpretability in the wild: a circuit for indirect object identification in GPT-2 small. Kevin Ro, Wang , Alexandre Variengien, Arthur Conmy, Buck Shlegeris, Jacob Steinhardt, ICLR. OpenReview.net2023</p>
<p>Interpreting key mechanisms of factual recall in transformer-based language models. Ang Lv, Kaiyi Zhang, Yuhan Chen, Yulong Wang, Lifeng Liu, Ji-Rong Wen, Jian Xie, Rui Yan, CoRR, abs/2403.195212024</p>
<p>World models. David Ha, Jrgen Schmidhuber, CoRR, abs/1803.101222018</p>
<p>The emotion machine: Commonsense thinking, artificial intelligence, and the future of the human mind. Marvin Minsky, 2007Simon and Schuster</p>
<p>CYC: toward programs with common sense. Douglas B Lenat, V Ramanathan, Karen Guha, Dexter Pittman, Mary Pratt, Shepherd, Commun. ACM. 3381990</p>
<p>Conceptnet 5.5: An open multilingual graph of general knowledge. Robyn Speer, Joshua Chin, Catherine Havasi, AAAI. AAAI Press2017</p>
<p>Yago: a core of semantic knowledge. Fabian M Suchanek, Gjergji Kasneci, Gerhard Weikum, WWW. ACM2007</p>
<p>Dbpedia -A large-scale, multilingual knowledge base extracted from wikipedia. Jens Lehmann, Robert Isele, Max Jakob, Anja Jentzsch, Dimitris Kontokostas, Pablo N Mendes, Sebastian Hellmann, Mohamed Morsey, Sren Patrick Van Kleef, Christian Auer, Bizer, Semantic Web. 622015</p>
<p>Wikidata: a free collaborative knowledgebase. Denny Vrandecic, Markus Krtzsch, Commun. ACM. 57102014</p>
<p>Babelnet: Building a very large multilingual semantic network. Roberto Navigli, Simone Paolo, Ponzetto , ACL. The Association for Computer Linguistics2010</p>
<p>ATOMIC: an atlas of machine commonsense for if-then reasoning. Maarten Sap, Le Ronan, Emily Bras, Chandra Allaway, Nicholas Bhagavatula, Hannah Lourie, Brendan Rashkin, Noah A Roof, Yejin Smith, Choi, AAAI. AAAI Press2019</p>
<p>Aser: Towards large-scale commonsense knowledge acquisition via higher-order selectional preference over eventualities. Hongming Zhang, Xin Liu, Haojie Pan, Haowen Ke, Jiefu Ou, Tianqing Fang, Yangqiu Song, Artificial Intelligence. 3091037402022</p>            </div>
        </div>

    </div>
</body>
</html>