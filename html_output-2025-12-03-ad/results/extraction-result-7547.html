<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7547 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7547</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7547</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-138.html">extraction-schema-138</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <p><strong>Paper ID:</strong> paper-259164901</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2306.08018v5.pdf" target="_blank">Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models</a></p>
                <p><strong>Paper Abstract:</strong> Large Language Models (LLMs), with their remarkable task-handling capabilities and innovative outputs, have catalyzed significant advancements across a spectrum of fields. However, their proficiency within specialized domains such as biomolecular studies remains limited. To address this challenge, we introduce Mol-Instructions, a comprehensive instruction dataset designed for the biomolecular domain. Mol-Instructions encompasses three key components: molecule-oriented instructions, protein-oriented instructions, and biomolecular text instructions. Each component aims to improve the understanding and prediction capabilities of LLMs concerning biomolecular features and behaviors. Through extensive instruction tuning experiments on LLMs, we demonstrate the effectiveness of Mol-Instructions in enhancing large models' performance in the intricate realm of biomolecular studies, thus fostering progress in the biomolecular research community. Mol-Instructions is publicly available for ongoing research and will undergo regular updates to enhance its applicability.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7547.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7547.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLaMA-7B (Mol-Instructions, molecule)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLaMA-7B fine-tuned with Mol-Instructions for molecule-oriented tasks</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 7B-parameter LLaMA model instruction-tuned with the Mol-Instructions molecule-oriented subset to act as a text-based simulator for chemistry tasks (molecule description, molecule generation, reaction prediction, retrosynthesis, reagent prediction, molecular property prediction).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-7B (fine-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>instruction‑tuned (LoRA fine-tuning on Mol-Instructions molecule subset)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>chemistry / chemoinformatics</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Text-based simulation tasks: generate molecule descriptions from descriptors; generate molecular SELFIES from textual descriptions; forward reaction prediction (products from reactants/reagents); single-step retrosynthesis (reactants from product); reagent prediction (reagents given reactants→product); molecular property prediction (QM9 quantum properties).</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>Supervised instruction tuning: models trained on instruction entries (instruction + input → output). Task descriptions/templates were created by human authors and augmented by gpt-3.5-turbo; in evaluation the model is prompted with the instruction and input (no few‑shot examples reported). SELFIES strings used as canonical molecular descriptors; for some baselines SELFIES were converted to SMILES.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Generation: Exact match, BLEU, Levenshtein, fingerprint similarities (RDKit, MACCS, Morgan / Tanimoto), Validity (RDKit); Property prediction: MAE; General text tasks: BLEU/ROUGE/METEOR as applicable.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>Description-guided molecule design — Exact match: 0.002; BLEU: 0.345; Levenshtein: 41.367; RDKit fingerprint similarity: 0.231; MACCS: 0.412; Morgan: 0.147; Validity: 1.000. Reagent prediction — Exact: 0.044; BLEU: 0.224; Levenshtein: 23.167; RDKit: 0.237; MACCS: 0.364; Morgan: 0.213; Validity: 1.000. Forward reaction prediction — Exact: 0.045; BLEU: 0.654; Levenshtein: 27.262; RDKit: 0.313; MACCS: 0.509; Morgan: 0.262; Validity: 1.000. Retrosynthesis (single-step) — Exact: 0.009; BLEU: 0.705; Levenshtein: 31.227; RDKit: 0.283; MACCS: 0.487; Morgan: 0.230; Validity: 1.000. Molecular property prediction (QM9) — MAE: 0.555 (±0.013).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td>Baselines reported in the paper (selected examples): Description-guided molecule design — MolT5: RDKit 0.400 / MACCS 0.538 / Morgan 0.295 / Validity 0.773; Text+Chem T5: RDKit 0.352 / MACCS 0.474 / Morgan 0.353 / Validity 0.721. Forward reaction (examples): LLaMA (no Mol-Instructions): Exact 0.000 / BLEU 0.020 / RDKit 0.002. Molecular property prediction (MAE): ALPACA 322.109; BAIZE 261.343; CHATGLM-LLAMA 5.553; VICUNA 860.051; GALACTICA 0.568; OURS 0.555 (±0.013). (See Table 3 and Table 4 for full baseline table.)</td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['Instruction tuning with Mol-Instructions (task-specific data) improves performance relative to untuned LLMs', 'Model family and specialization: smaller domain-specific models (e.g., MolT5, Text+Chem T5) can outperform general LLMs on molecule-generation quality metrics', 'Representation choice: SELFIES chosen to improve validity over SMILES (SMILES prone to syntactic/chemical errors)', 'Training method: LoRA vs full finetune trade-offs (LoRA used for molecule/text; limits on modality adaptation)', 'Dataset diversity and size (large, diverse instruction set improves coverage)', 'Evaluation ambiguity: one textual description can map to multiple valid molecules (affects exact-match metrics)']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td>Tokenization: BPE using LLaMA tokenizer; molecules encoded as SELFIES. LoRA fine-tuning: r=16, alpha=16, dropout=0.05; batch size (molecule/text) = 800 / 1024 (see Table 9); learning rate 3e-4 for molecule/text LoRA; steps 40,000; warmup 1,000. Training hardware: LoRA training on 32GB V100 GPUs. Test sets: ~1k samples per task reserved for evaluation. Validation via RDKit for molecule validity and fingerprint similarity metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Despite improvements, LLMs still lag behind specialized smaller models for molecule generation; exact-match is very low (often near zero) because many valid molecules can match a description; Galactica produced negative property values in property prediction; some baseline LLMs produce generic or non-task-aligned outputs without instruction tuning; measuring correctness via text metrics is imperfect for chemical structure tasks; LoRA's modality limitations and tokenization treating molecules as text constrain performance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7547.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7547.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLaMA-7B (Mol-Instructions, protein)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLaMA-7B fine-tuned with Mol-Instructions for protein-oriented tasks</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 7B-parameter LLaMA model fully fine-tuned (with DeepSpeed ZeRO) on the protein-oriented portion of Mol-Instructions to perform protein function prediction, catalytic activity prediction, domain/motif prediction, functional description generation, and de novo text-driven protein design.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-7B (fine-tuned — full model for protein tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>full fine‑tuned on protein instruction dataset (DeepSpeed ZeRO optimization)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>molecular biology / protein engineering</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Text-based simulation tasks: predict GO terms (protein function), predict catalytic activity/reaction description, predict domains/motifs, generate functional descriptions, generate de novo amino-acid sequences satisfying textual design constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>Instruction tuning: textual templates mapping UniProt annotations to design constraints; models trained to map instruction+protein-sequence (or instruction-only for design) to outputs. For template and instruction variety, gpt-3.5 was used to enrich template styles. Protein design outputs were evaluated post-hoc (sequence alignment) rather than experimentally.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Protein understanding/generation: ROUGE for functional description generation; for function classification tasks metrics not explicitly enumerated in main text (task-level comparisons shown in figures). For protein design, sequence similarity via BLAST (sequence identity and p-value) was used as a proxy validation.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>Quantitative ROUGE improvements are reported graphically (Figure 5); explicit numeric example for protein design: generated sequence aligned to UniProt accession A0A518LQL6 with sequence identity 40.9% and BLAST p-value 7.7e-30 in residues 1-200, suggesting shared sequence signatures in NADPHX and metal ion binding regions.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td>Baselines included Alpaca-LoRA, Baize, ChatGLM-6B, Vicuna, Galactica and PMC-LLaMA-13B; figures show Mol-Instructions tuned LLaMA surpasses these baselines on protein tasks (no comprehensive numeric baseline table in main text).</td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['Long protein sequence lengths make tokenization and grammar capture challenging', 'Choice of fine-tuning strategy: full-model fine-tuning (with ZeRO) used for proteins vs LoRA for other modalities', 'Training data curation: clustering and redundancy removal (MMseqs at 90% identity) to reduce bias', 'Scarcity of directly applicable experimental labels for some tasks (e.g., de novo design), making evaluation indirect', 'Template design and selection of textual constraints affect design outcomes']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td>Protein fine-tuning: full model training with DeepSpeed ZeRO on 80GB A800 GPUs; batch size 96; learning rate 2e-5; steps 25,000; warmup 2,500 (see Table 9). Tokenization treated amino-acid sequences as text (BPE). Test sets ~1k samples per task.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Protein design validity was only assessed via sequence similarity searches (BLAST), not wet-lab validation; functional claims are provisional. Long-tail distribution of protein functions and limited labels limit predictive generalization. Treating sequences as plain text may miss biochemical priors; LoRA limitations motivate exploration of specialized biomolecular encoders.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7547.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7547.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLaMA-7B (Mol-Instructions, biotext)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLaMA-7B fine-tuned with Mol-Instructions for biomolecular text (NLP) tasks</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 7B-parameter LLaMA model instruction-tuned (LoRA) on the biomolecular text subset of Mol-Instructions to perform chemical entity recognition, chemical-protein and chemical-disease relation extraction, multiple-choice / true-false / open Q&A, and PubMed-derived QA (SELF-QUESTIONING).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-7B (fine-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>instruction‑tuned (LoRA) on biomolecular text instruction data</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>biomedical NLP / bioinformatics / chemoinformatics</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Text-based NLP tasks: named entity recognition (chemical entities), relation extraction (chemical-protein, chemical-disease), multiple-choice and open question answering, and generation of factual question-answer pairs from PubMed abstracts.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>Instruction-tuning using task-specific instruction templates (some templates and QA pairs produced by gpt-3.5-turbo using SELF-QUESTIONING); training examples are instruction+input→output; evaluation is done by prompting the model with instruction and document/text input.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Standard NLP metrics for NER and relation extraction (not numerically enumerated in main text) and ROUGE/BLEU for generated descriptions; the paper states use of 'general metrics for Q&A, entity recognition, and relation extraction' (likely precision/recall/F1 for extraction tasks).</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>Figures (Figure 6 and Figure 11) show consistent improvements over baselines on chemical entity recognition and relation extraction; exact numeric metrics are shown in supplemental figures but not fully tabulated in main text. Example dataset sizes: BC4CHEMD sampled 1,000 entries; BC5CDR contains 1,500 PubMed articles with 3,116 chemical-disease interactions used to build instructions.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td>Baselines include Alpaca-LoRA, Baize, ChatGLM-6B, Vicuna and models without Mol-Instructions tuning; untuned models often produced generic outputs or missed relations. Exact baseline numbers are presented graphically in the paper's figures.</td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['Availability of curated annotated corpora (BC4CHEMD, ChemProt, BC5CDR) affects extraction accuracy', 'Instruction tuning with domain-specific Q&A and extraction instructions markedly improves precision and relation extraction compared to general instruction datasets', 'Prompt/template design (SELF-QUESTIONING, GPT-aided generation) improves diversity and factuality of QA instructions', 'Model capacity and fine-tuning method (LoRA) influence final performance']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td>LoRA fine-tuning for text tasks: r=16, alpha=16, dropout=0.05; batch size for text = 1024; learning rate 3e-4; steps 40,000 for molecule/text (see Table 9). Tokenization used LLaMA BPE; training/validation/test splits with ~1k test samples per task.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Some models not fine-tuned with Mol-Instructions produced overly generic answers or missed relations; evaluation metrics for extraction were not exhaustively tabulated in main text; SELF-QUESTIONING generation required filtering to remove low-quality or overly reference-dependent questions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Galactica: A large language model for science <em>(Rating: 2)</em></li>
                <li>Translation between molecules and natural language <em>(Rating: 2)</em></li>
                <li>Unifying molecular and textual representations via multi-task language modelling <em>(Rating: 2)</em></li>
                <li>MolT5 (Translation between molecules and natural language) <em>(Rating: 1)</em></li>
                <li>Chemcrow: Augmenting large-language models with chemistry tools <em>(Rating: 1)</em></li>
                <li>Moleculegpt: Instruction following large language models for molecular property prediction <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7547",
    "paper_id": "paper-259164901",
    "extraction_schema_id": "extraction-schema-138",
    "extracted_data": [
        {
            "name_short": "LLaMA-7B (Mol-Instructions, molecule)",
            "name_full": "LLaMA-7B fine-tuned with Mol-Instructions for molecule-oriented tasks",
            "brief_description": "A 7B-parameter LLaMA model instruction-tuned with the Mol-Instructions molecule-oriented subset to act as a text-based simulator for chemistry tasks (molecule description, molecule generation, reaction prediction, retrosynthesis, reagent prediction, molecular property prediction).",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "LLaMA-7B (fine-tuned)",
            "model_size": "7B",
            "model_type": "instruction‑tuned (LoRA fine-tuning on Mol-Instructions molecule subset)",
            "scientific_domain": "chemistry / chemoinformatics",
            "simulation_task_description": "Text-based simulation tasks: generate molecule descriptions from descriptors; generate molecular SELFIES from textual descriptions; forward reaction prediction (products from reactants/reagents); single-step retrosynthesis (reactants from product); reagent prediction (reagents given reactants→product); molecular property prediction (QM9 quantum properties).",
            "prompting_strategy": "Supervised instruction tuning: models trained on instruction entries (instruction + input → output). Task descriptions/templates were created by human authors and augmented by gpt-3.5-turbo; in evaluation the model is prompted with the instruction and input (no few‑shot examples reported). SELFIES strings used as canonical molecular descriptors; for some baselines SELFIES were converted to SMILES.",
            "evaluation_metric": "Generation: Exact match, BLEU, Levenshtein, fingerprint similarities (RDKit, MACCS, Morgan / Tanimoto), Validity (RDKit); Property prediction: MAE; General text tasks: BLEU/ROUGE/METEOR as applicable.",
            "reported_accuracy": "Description-guided molecule design — Exact match: 0.002; BLEU: 0.345; Levenshtein: 41.367; RDKit fingerprint similarity: 0.231; MACCS: 0.412; Morgan: 0.147; Validity: 1.000. Reagent prediction — Exact: 0.044; BLEU: 0.224; Levenshtein: 23.167; RDKit: 0.237; MACCS: 0.364; Morgan: 0.213; Validity: 1.000. Forward reaction prediction — Exact: 0.045; BLEU: 0.654; Levenshtein: 27.262; RDKit: 0.313; MACCS: 0.509; Morgan: 0.262; Validity: 1.000. Retrosynthesis (single-step) — Exact: 0.009; BLEU: 0.705; Levenshtein: 31.227; RDKit: 0.283; MACCS: 0.487; Morgan: 0.230; Validity: 1.000. Molecular property prediction (QM9) — MAE: 0.555 (±0.013).",
            "baseline_accuracy": "Baselines reported in the paper (selected examples): Description-guided molecule design — MolT5: RDKit 0.400 / MACCS 0.538 / Morgan 0.295 / Validity 0.773; Text+Chem T5: RDKit 0.352 / MACCS 0.474 / Morgan 0.353 / Validity 0.721. Forward reaction (examples): LLaMA (no Mol-Instructions): Exact 0.000 / BLEU 0.020 / RDKit 0.002. Molecular property prediction (MAE): ALPACA 322.109; BAIZE 261.343; CHATGLM-LLAMA 5.553; VICUNA 860.051; GALACTICA 0.568; OURS 0.555 (±0.013). (See Table 3 and Table 4 for full baseline table.)",
            "factors_reported": [
                "Instruction tuning with Mol-Instructions (task-specific data) improves performance relative to untuned LLMs",
                "Model family and specialization: smaller domain-specific models (e.g., MolT5, Text+Chem T5) can outperform general LLMs on molecule-generation quality metrics",
                "Representation choice: SELFIES chosen to improve validity over SMILES (SMILES prone to syntactic/chemical errors)",
                "Training method: LoRA vs full finetune trade-offs (LoRA used for molecule/text; limits on modality adaptation)",
                "Dataset diversity and size (large, diverse instruction set improves coverage)",
                "Evaluation ambiguity: one textual description can map to multiple valid molecules (affects exact-match metrics)"
            ],
            "experimental_conditions": "Tokenization: BPE using LLaMA tokenizer; molecules encoded as SELFIES. LoRA fine-tuning: r=16, alpha=16, dropout=0.05; batch size (molecule/text) = 800 / 1024 (see Table 9); learning rate 3e-4 for molecule/text LoRA; steps 40,000; warmup 1,000. Training hardware: LoRA training on 32GB V100 GPUs. Test sets: ~1k samples per task reserved for evaluation. Validation via RDKit for molecule validity and fingerprint similarity metrics.",
            "limitations_or_failure_modes": "Despite improvements, LLMs still lag behind specialized smaller models for molecule generation; exact-match is very low (often near zero) because many valid molecules can match a description; Galactica produced negative property values in property prediction; some baseline LLMs produce generic or non-task-aligned outputs without instruction tuning; measuring correctness via text metrics is imperfect for chemical structure tasks; LoRA's modality limitations and tokenization treating molecules as text constrain performance.",
            "uuid": "e7547.0",
            "source_info": {
                "paper_title": "Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "LLaMA-7B (Mol-Instructions, protein)",
            "name_full": "LLaMA-7B fine-tuned with Mol-Instructions for protein-oriented tasks",
            "brief_description": "A 7B-parameter LLaMA model fully fine-tuned (with DeepSpeed ZeRO) on the protein-oriented portion of Mol-Instructions to perform protein function prediction, catalytic activity prediction, domain/motif prediction, functional description generation, and de novo text-driven protein design.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "LLaMA-7B (fine-tuned — full model for protein tasks)",
            "model_size": "7B",
            "model_type": "full fine‑tuned on protein instruction dataset (DeepSpeed ZeRO optimization)",
            "scientific_domain": "molecular biology / protein engineering",
            "simulation_task_description": "Text-based simulation tasks: predict GO terms (protein function), predict catalytic activity/reaction description, predict domains/motifs, generate functional descriptions, generate de novo amino-acid sequences satisfying textual design constraints.",
            "prompting_strategy": "Instruction tuning: textual templates mapping UniProt annotations to design constraints; models trained to map instruction+protein-sequence (or instruction-only for design) to outputs. For template and instruction variety, gpt-3.5 was used to enrich template styles. Protein design outputs were evaluated post-hoc (sequence alignment) rather than experimentally.",
            "evaluation_metric": "Protein understanding/generation: ROUGE for functional description generation; for function classification tasks metrics not explicitly enumerated in main text (task-level comparisons shown in figures). For protein design, sequence similarity via BLAST (sequence identity and p-value) was used as a proxy validation.",
            "reported_accuracy": "Quantitative ROUGE improvements are reported graphically (Figure 5); explicit numeric example for protein design: generated sequence aligned to UniProt accession A0A518LQL6 with sequence identity 40.9% and BLAST p-value 7.7e-30 in residues 1-200, suggesting shared sequence signatures in NADPHX and metal ion binding regions.",
            "baseline_accuracy": "Baselines included Alpaca-LoRA, Baize, ChatGLM-6B, Vicuna, Galactica and PMC-LLaMA-13B; figures show Mol-Instructions tuned LLaMA surpasses these baselines on protein tasks (no comprehensive numeric baseline table in main text).",
            "factors_reported": [
                "Long protein sequence lengths make tokenization and grammar capture challenging",
                "Choice of fine-tuning strategy: full-model fine-tuning (with ZeRO) used for proteins vs LoRA for other modalities",
                "Training data curation: clustering and redundancy removal (MMseqs at 90% identity) to reduce bias",
                "Scarcity of directly applicable experimental labels for some tasks (e.g., de novo design), making evaluation indirect",
                "Template design and selection of textual constraints affect design outcomes"
            ],
            "experimental_conditions": "Protein fine-tuning: full model training with DeepSpeed ZeRO on 80GB A800 GPUs; batch size 96; learning rate 2e-5; steps 25,000; warmup 2,500 (see Table 9). Tokenization treated amino-acid sequences as text (BPE). Test sets ~1k samples per task.",
            "limitations_or_failure_modes": "Protein design validity was only assessed via sequence similarity searches (BLAST), not wet-lab validation; functional claims are provisional. Long-tail distribution of protein functions and limited labels limit predictive generalization. Treating sequences as plain text may miss biochemical priors; LoRA limitations motivate exploration of specialized biomolecular encoders.",
            "uuid": "e7547.1",
            "source_info": {
                "paper_title": "Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "LLaMA-7B (Mol-Instructions, biotext)",
            "name_full": "LLaMA-7B fine-tuned with Mol-Instructions for biomolecular text (NLP) tasks",
            "brief_description": "A 7B-parameter LLaMA model instruction-tuned (LoRA) on the biomolecular text subset of Mol-Instructions to perform chemical entity recognition, chemical-protein and chemical-disease relation extraction, multiple-choice / true-false / open Q&A, and PubMed-derived QA (SELF-QUESTIONING).",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "LLaMA-7B (fine-tuned)",
            "model_size": "7B",
            "model_type": "instruction‑tuned (LoRA) on biomolecular text instruction data",
            "scientific_domain": "biomedical NLP / bioinformatics / chemoinformatics",
            "simulation_task_description": "Text-based NLP tasks: named entity recognition (chemical entities), relation extraction (chemical-protein, chemical-disease), multiple-choice and open question answering, and generation of factual question-answer pairs from PubMed abstracts.",
            "prompting_strategy": "Instruction-tuning using task-specific instruction templates (some templates and QA pairs produced by gpt-3.5-turbo using SELF-QUESTIONING); training examples are instruction+input→output; evaluation is done by prompting the model with instruction and document/text input.",
            "evaluation_metric": "Standard NLP metrics for NER and relation extraction (not numerically enumerated in main text) and ROUGE/BLEU for generated descriptions; the paper states use of 'general metrics for Q&A, entity recognition, and relation extraction' (likely precision/recall/F1 for extraction tasks).",
            "reported_accuracy": "Figures (Figure 6 and Figure 11) show consistent improvements over baselines on chemical entity recognition and relation extraction; exact numeric metrics are shown in supplemental figures but not fully tabulated in main text. Example dataset sizes: BC4CHEMD sampled 1,000 entries; BC5CDR contains 1,500 PubMed articles with 3,116 chemical-disease interactions used to build instructions.",
            "baseline_accuracy": "Baselines include Alpaca-LoRA, Baize, ChatGLM-6B, Vicuna and models without Mol-Instructions tuning; untuned models often produced generic outputs or missed relations. Exact baseline numbers are presented graphically in the paper's figures.",
            "factors_reported": [
                "Availability of curated annotated corpora (BC4CHEMD, ChemProt, BC5CDR) affects extraction accuracy",
                "Instruction tuning with domain-specific Q&A and extraction instructions markedly improves precision and relation extraction compared to general instruction datasets",
                "Prompt/template design (SELF-QUESTIONING, GPT-aided generation) improves diversity and factuality of QA instructions",
                "Model capacity and fine-tuning method (LoRA) influence final performance"
            ],
            "experimental_conditions": "LoRA fine-tuning for text tasks: r=16, alpha=16, dropout=0.05; batch size for text = 1024; learning rate 3e-4; steps 40,000 for molecule/text (see Table 9). Tokenization used LLaMA BPE; training/validation/test splits with ~1k test samples per task.",
            "limitations_or_failure_modes": "Some models not fine-tuned with Mol-Instructions produced overly generic answers or missed relations; evaluation metrics for extraction were not exhaustively tabulated in main text; SELF-QUESTIONING generation required filtering to remove low-quality or overly reference-dependent questions.",
            "uuid": "e7547.2",
            "source_info": {
                "paper_title": "Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models",
                "publication_date_yy_mm": "2023-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Galactica: A large language model for science",
            "rating": 2
        },
        {
            "paper_title": "Translation between molecules and natural language",
            "rating": 2
        },
        {
            "paper_title": "Unifying molecular and textual representations via multi-task language modelling",
            "rating": 2
        },
        {
            "paper_title": "MolT5 (Translation between molecules and natural language)",
            "rating": 1
        },
        {
            "paper_title": "Chemcrow: Augmenting large-language models with chemistry tools",
            "rating": 1
        },
        {
            "paper_title": "Moleculegpt: Instruction following large language models for molecular property prediction",
            "rating": 1
        }
    ],
    "cost": 0.0182565,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>MOL-INSTRUCTIONS: A LARGE-SCALE BIOMOLECU-LAR INSTRUCTION DATASET FOR LLMS
4 Mar 2024</p>
<p>Yin Fang 
College of Computer Science and Technology
Ant Group Joint Research Center for Knowledge Graphs
Zhejiang University ♠ ZJU
Zhejiang University ♡ Hangzhou Innovation Center
Zhejiang University</p>
<p>Xiaozhuan Liang 
College of Computer Science and Technology
Ant Group Joint Research Center for Knowledge Graphs
Zhejiang University ♠ ZJU
Zhejiang University ♡ Hangzhou Innovation Center
Zhejiang University</p>
<p>Ningyu Zhang 
College of Computer Science and Technology
Ant Group Joint Research Center for Knowledge Graphs
Zhejiang University ♠ ZJU
Zhejiang University ♡ Hangzhou Innovation Center
Zhejiang University</p>
<p>Kangwei Liu 
College of Computer Science and Technology
Ant Group Joint Research Center for Knowledge Graphs
Zhejiang University ♠ ZJU
Zhejiang University ♡ Hangzhou Innovation Center
Zhejiang University</p>
<p>Rui Huang 
College of Computer Science and Technology
Ant Group Joint Research Center for Knowledge Graphs
Zhejiang University ♠ ZJU
Zhejiang University ♡ Hangzhou Innovation Center
Zhejiang University</p>
<p>Zhuo Chen 
College of Computer Science and Technology
Ant Group Joint Research Center for Knowledge Graphs
Zhejiang University ♠ ZJU
Zhejiang University ♡ Hangzhou Innovation Center
Zhejiang University</p>
<p>Fan ♣ Xiaohui 
College of Computer Science and Technology
Ant Group Joint Research Center for Knowledge Graphs
Zhejiang University ♠ ZJU
Zhejiang University ♡ Hangzhou Innovation Center
Zhejiang University</p>
<p>Huajun Chen 
College of Computer Science and Technology
Ant Group Joint Research Center for Knowledge Graphs
Zhejiang University ♠ ZJU
Zhejiang University ♡ Hangzhou Innovation Center
Zhejiang University</p>
<p>MOL-INSTRUCTIONS: A LARGE-SCALE BIOMOLECU-LAR INSTRUCTION DATASET FOR LLMS
4 Mar 2024021AEE2752085F2E041136D94CC0AA5AarXiv:2306.08018v5[q-bio.QM]</p>
<p>{fangyin, liangxiaozhuan, kangweiliu, hrhr, zhuo.chen,fanxh}@zju.edu.cn,{zhangningyu, huajunsir}@zju.edu.ABSTRACT Large Language Models (LLMs), with their remarkable task-handling capabilities and innovative outputs, have catalyzed significant advancements across a spectrum of fields.However, their proficiency within specialized domains such as biomolecular studies remains limited.To address this challenge, we introduce Mol-Instructions, a comprehensive instruction dataset designed for the biomolecular domain.Mol-Instructions encompasses three key components: molecule-oriented instructions, protein-oriented instructions, and biomolecular text instructions.Each component aims to improve the understanding and prediction capabilities of LLMs concerning biomolecular features and behaviors.Through extensive instruction tuning experiments on LLMs, we demonstrate the effectiveness of Mol-Instructions in enhancing large models' performance in the intricate realm of biomolecular studies, thus fostering progress in the biomolecular research community.Mol-Instructions is publicly available for ongoing research and will undergo regular updates to enhance its applicability.</p>
<p>INTRODUCTION</p>
<p>Large Language Models (LLMs), such as GPT-4 (OpenAI, 2023a), Chinchilla (Hoffmann et al., 2022), PaLM (Chowdhery et al., 2023), Codex (Chen et al., 2021), LLaMA (Touvron et al., 2023), FLAN (Wei et al., 2022), and GLM (Zeng et al., 2023) have revolutionized the landscape of Natural Language Processing (NLP).These models, boasting billions of parameters, are meticulously trained on extensive text corpora and excel at generating human-like text and understanding intricate contexts.</p>
<p>To adapt LLMs for specific tasks, researchers employ instruction tuning techniques (Ouyang et al., 2022a;Sanh et al., 2022).This involves training the models with specialized instruction datasets, allowing them to acquire task-specific knowledge and patterns, thus enhancing their performance in specific domains.Numerous instruction datasets have already been developed for use in general domains.For instance, the Stanford Alpaca dataset (Taori et al., 2023) offers prompts, completions, and annotations tailored for controllable text generation.The GPT4All dataset (Anand et al., 2023) comprises a variety of formats, including code, stories, and dialogue, purposed for training and evaluating general-purpose language models.Similarly, the COIG dataset (Zhang et al., 2023a) integrates diverse corpora such as translated, exam, and human value alignment instructions, specifically oriented towards Chinese language processing.</p>
<p>With recent advancements, it's evident that LLMs extend beyond traditional text processing (Zhang et al., 2024;Tinn et al., 2023;Wang et al., 2023a).Their potential in biomolecular studies, covering structural biology, computational chemistry, and drug development, is particularly promising.Utilizing LLMs in this field could revolutionize our understanding and handling of biomolecular data, accelerating scientific innovations and drug discovery.</p>
<p>However, a major barrier to harnessing LLMs in the biomolecular domain is the lack of a dedicated dataset for this field.Despite the existence of several instruction datasets in general domains, a conspicuous gap remains when it comes to biomolecules.This gap arises from three main challenges: First, acquiring and annotating biomolecular data incurs significant costs, given the inherent complexity and rich depth of information contained within such data.Second, biomolecular computations span a broad knowledge spectrum, intertwining specialized insights from disparate areas including structural biology, computational chemistry, and drug development.Third, unlike the well-established frameworks in natural language processing, bioinformatics has no standardized lingua franca.Different applications often employ varied representations for biomolecules and their associated computations.This diversity amplifies the challenge of crafting a dataset that serves universally across the domain.To address this pressing need in the biomolecular domain, we introduce Mol-Instructions (CC BY-NC-SA 4.0), a dataset tailored to the unique challenges of biomolecular studies.This dataset, as delineated in Figure 1, is structured around three core components:</p>
<p>• Molecule-oriented instructions: This component delves into the realm of small molecules, emphasizing their inherent properties and behaviors.It sheds light on the fundamental challenges of diverse chemical reactions and molecular design, with 148,4K instructions across six tasks.• Protein-oriented instructions: Concentrating on biosciences, it covers 505K instructions spanning five categories of tasks.These tasks aim to predict the structure, function, and activity of proteins, and facilitate protein design based on textual directives.• Biomolecular text instructions: Primarily crafted for NLP tasks within the fields of bioinformatics and chemoinformatics, this portion includes six information extraction and Q&amp;A tasks represented through 53K instructions.</p>
<p>Creating this instruction dataset involves gathering and collecting biomolecular data from various licensed sources (detailed in Appendix A.2), followed by transforming this data into easily-followable instruction formats suitable for specific tasks.Our goal is to empower LLMs with domain-specific insights, enhancing their ability to decode and predict biomolecular features.This enhancement can revolutionize the interpretation of biomolecular data, streamline drug development, and unveil new realms of biomolecular research.With Mol-Instructions, large models are endowed with the ability to comprehend biology, opening the door to new scientific discoveries.To assess the real-world effectiveness of Mol-Instructions, we conduct an extensive series of evaluations.Employing the representative LLM as the foundational model, we perform instruction tuning for each of the three main categories of instructions.The results highlight the value of Mol-Instructions, demonstrating its ability to enhance the versatility and understanding of large models in the complex domain of biomolecular studies.</p>
<p>Table 1: Comparison with existing datasets.We employ the following abbreviations: HG -datasets curated by human effort, SI -datasets produced via self-instruct methods, MIX -dataset composed of both humanconstructed and machine-generated data, COL -dataset assembled from a variety of other datasets.</p>
<p>DATASETS # TYPE # INSTRUCTIONS COLLECTION USAGE</p>
<p>ACCESS struction data often boasts high quality, it's limited in volume, diversity, and innovation.Recognizing these limitations, there's been a shift toward semi-automated or fully automated instruction creation.For instance, Stanford Alpaca (Taori et al., 2023) employs the self-instruct approach (Wang et al., 2023b), utilizing a bootstrapping technique grounded in a set of handcrafted instructions to generate 52K diverse instructions.This innovative method has inspired numerous model-aided data collection endeavors, such as Baize (Xu et al., 2023), COIG (Zhang et al., 2023a), UltraChat (Ding et al., 2023), andShareGPT (sha, 2023), as detailed in Table 1.</p>
<p>Several studies have explored the intersection of text and biomolecules (Boiko et al., 2023;Bran et al., 2023;Zeng et al., 2022;Edwards et al., 2022;Nascimento &amp; Pimentel, 2023;Zhang et al., 2023b).For instance, Galactica (Taylor et al., 2022), a general scientific language model, incorporates a subset of instruction data related to molecules, proteins, and text during its pre-training phase.However, details of this particular dataset remain undisclosed.Other datasets, such as PCdes (Zeng et al., 2022), ChEBI-20 (Edwards et al., 2022), PubChemSTM (Liu et al., 2023), and MoMu (Su et al., 2022), pair molecules with textual descriptions.While these datasets are valuable, they are primarily geared toward training smaller models and lack an instructional format.This limitation curtails their direct utility for large language models.In contrast, Mol-Instructions covers a wider range of biomolecular tasks and a larger amount of data, achieved through a combined construction method of self-instruct, template-based conversion, and human-crafted task descriptions (as detailed in §3).</p>
<p>MOL-INSTRUCTIONS CONSTRUCTION</p>
<p>UNDERLYING PRINCIPLES</p>
<p>Large-scale To cater to the needs of LLMs, we've crafted Mol-Instructions to be expansive, incorporating over 2 million biomolecular instructions.This large volume provides broad and representative coverage of biomolecular sequences and structures, enabling models to grasp and navigate the complexities of biomolecules.</p>
<p>Diversity Mol-Instructions spans 17 subtasks across three types of biomolecules and includes diverse text descriptions that capture over 11 unique biomolecular properties.This extensive coverage fosters versatility in models trained with our dataset, priming them for various challenges in biomolecular research.</p>
<p>Quality</p>
<p>We prioritize the quality of our dataset to guarantee that it serves as a reliable foundation for deriving accurate, actionable, and practical insights.Each piece of biomolecular data undergoes rigorous scrutiny to ensure its accuracy and trustworthiness.</p>
<p>HUMAN-AI COLLABORATION TASK DESCRIPTION CREATION</p>
<p>A standard instruction entry is typically structured with three components: an instruction that clarifies the task, an input that serves as the task's input, and an output that embodies the expected outcome.</p>
<p>In real-world scenarios, task instructions exhibit a broad diversity to match the dynamic and diverse nature of human inquiries and requirements.To emulate this diversity, for each task, we begin with a clear and concise human-written description, which then serves as an input to gpt-3.5-turbo(OpenAI, 2023b).Leveraging its extensive knowledge and pattern recognition skills, the LLM generates diverse task descriptions, reflecting the wide spectrum of human question-framing styles (Figure 2 Sector 1).To ensure the quality of these descriptions, each one is subjected to a thorough manual review.This collaboration of human insight and machine intelligence not only enhances the diversity and creativity of task descriptions but also bolsters the robustness and adaptability of the instructions.</p>
<p>INFORMATION DERIVATION FROM EXISTING DATA</p>
<p>Since biomolecular data typically involves professional wet-lab experiments and expert chemists' summaries, our data is sourced from widely-used biochemistry databases (Kim et al., 2021;Wei et al., 2010;Lu &amp; Zhang, 2022;Wu et al., 2018;Ashburner et al., 2000;Consortium, 2023;Krallinger et al., 2015;2017;Li et al., 2016;Pal et al., 2022;Hendrycks et al., 2021).Based on these data sources, we can obtain the desired instruction data with appropriate processing.Some datasets undergo manual processing, with labels being directly appended to specific biomolecular data.This includes datasets with clearly delineated inputs and anticipated outcomes for various prediction endeavors, as well as datasets with predetermined questions and corresponding answers for Q&amp;A tasks.Processing such data is fairly direct: the labeled information is typically mapped to the respective input and output fields for each instruction entry.</p>
<p>Another class of data sources comes without explicit manual labels and requires techniques such as data mining and AI-assisted generation for extracting and selecting the ideal data, as depicted in Figure 2 Sector 2. With data mining, we strive for data comprehensiveness and adequacy by extracting additional relevant information from professional chemical research databases like PubChem (Kim et al., 2021).Specifically, we crawl valid molecule description texts and their corresponding PubChem Chemical Identifiers (CIDs), followed by retrieving the respective molecular descriptors.To focus the model's attention on description semantics, we replace the molecular nomenclature with the term "the molecule".On the AI-assisted generation front, we use scientific abstracts from PubMed (White, 2020) to generate Open Question instructions.Here, we task gpt-3.5-turbo to formulate questions and their corresponding answers based on the abstracts, structured as Q&amp;A pairs.This methodology efficiently produces a varied collection of Q&amp;A instructions, simplifying the construction of this particular task.For a more task-level detailed explanation, please refer to Appendix B.</p>
<p>TEMPLATE-BASED CONVERSION OF BIOLOGICAL DATA INTO TEXTUAL FORMAT</p>
<p>Certainly, not all data can be seamlessly transformed into ideal instruction sets.For some novel tasks, finding directly applicable data can be particularly challenging.This is especially true for protein design tasks, where previous studies often conditioned designs on broad categories (Madani et al., 2023) or fixed backbones (Dauparas et al., 2022), largely neglecting the bespoke functional and structural attributes (e.g., helical secondary structure, DNA binding domain, or transcription regulator activity).Conversely, we aim to devise instructions in textual form for de novo protein design tailored to user intent, enabling the design of composite properties of interest.Given the scarcity of directly applicable data for such tasks, we curate annotations from specific select within UniProtKB (Consortium, 2023).These annotations encapsulate the protein properties frequently explored or sought after by researchers in the field (detailed examples are in Appendix Table 6).</p>
<p>To effectively convert these structured annotations into textual format, we formulate a series of templates, illustrated in Figure 2 Sector 3 and Appendix Table 7.Each resulting textual annotation establishes criteria for protein design.By aggregating these functional descriptions and properties, we craft precise protein design instructions, ensuring that the synthesized protein meets the specified criteria.In practice, considering the model's input length limitations and training efficiency, we randomly select a subset of these conditions as design objectives.</p>
<p>QUALITY CONTROL</p>
<p>As the field stands, LLMs have not yet fully grasped the intricacies of biomolecular languages, falling short of their proficiency with human languages.To accelerate the model's capability to generate accurate biomolecules, we implement stringent quality assurance measures for our biomolecular data, detailed in Figure 2 Sector 4.</p>
<p>For small molecules, our process begins by eliminating chemically invalid SMILES strings from the initial dataset.Although external constraints (Landrum et al., 2013) can validate generated molecules, using a dependable molecular descriptor within molecular instructions is more effective.While SMILES (Weininger, 1988) strings remain a popular choice for molecular descriptors, models leveraging them often output strings that are either syntactically flawed or chemically inconsistent.To circumvent these issues, we opt for SELFIES (Krenn et al., 2022) as our molecular descriptor.With its tight rule set, SELFIES ensures the generation of valid molecules by allowing combinations of any symbols, eliminating common pitfalls associated with SMILES strings, such as producing illogical symbols or mismatched parentheses.</p>
<p>Alongside, we prioritize the integrity of our protein data by primarily sourcing entries from UniProtKB/Swiss-Prot (Consortium, 2023), a curated and manually annotated protein sequence database.To bolster the volume and variety of our data, we supplement with high-scoring annotations from UniProtKB/TrEMBL.Recognizing the risk of bias from redundant protein sequences, such as homologous sequences or closely-related protein variants within the Swiss-Prot and TrEMBL databases, we deploy a meticulous filtration process.Leveraging the MMseqs (Steinegger &amp; Söding, 2017) tool, we cluster protein sequences at a 90% similarity threshold, selecting functionally rich entries within each cluster as representatives and excluding the rest.This rigorous approach ensures our dataset comprises diverse, high-quality, and function-centric protein instructions devoid of redundancies.</p>
<p>A CLOSER LOOK AT MOL-INSTRUCTIONS</p>
<p>CATEGORIZATION AND POTENTIAL APPLICATIONS OF INSTRUCTION TASKS</p>
<p>As illustrated in Figure 3, Mol-Instructions is anchored around three core domains: moleculeoriented, protein-oriented, and biomolecular texts.Each category's instruction task covers the essential challenges within its domain, aspiring to drive forward the biomolecular field via the  Molecule-oriented instructions center on small molecules, delving into their natural properties and behaviors.It underscores the foundational challenges of various chemical reactions and molecular design, encompassing six tasks illustrated in Figure 3 (a).The objective is to understand and predict the chemical properties of molecules, improve molecule design, and increase the accuracy and speed of chemical reactions.In the areas of chemical and pharmaceutical design, the predictions from these tasks could expedite drug innovation and diminish developmental expenses.</p>
<p>Protein-oriented instructions are rooted in bioscience, primarily addressing issues pertinent to protein design and functionality.This segment spans five distinct categories, as detailed in Figure 3 (b).The endeavors here are directed towards predicting protein domains, functions, and activities, and facilitating protein design via textual instructions.Understanding the fundamentals of protein function and folding is crucial for realms such as disease diagnosis, treatment, and novel drug discovery.</p>
<p>Biomolecular text instructions concentrate primarily on NLP tasks related to bioinformatics and chemoinformatics.This category contains six information extraction and Q&amp;A tasks as shown in Figure 3 (c).The goals here are to interpret and extract pivotal information from biomedical literature, aiding researchers in swiftly accumulating insights and propelling their investigative pursuits.</p>
<p>DIVERSITY AND COMPLEXITY OF BIOMOLECULAR TRAITS</p>
<p>Figure 4 provides a comprehensive overview of the biomolecule distribution across different dimensions.For clarity in visualization, we've truncated the long-tail segments of the data, preserving its core essence.An exhaustive analysis is available in Appendix C.</p>
<p>Figure 4 (a-d) showcases the diverse characteristics of molecules.Bertz complexity serves as a crucial metric for assessing molecular complexity.Molecular weight, indicative of a molecule's scale and complexity, is instrumental in many chemical reactions.The atom count provides insight into a molecule's dimension and complexity, influencing its stability and reactivity.The ring count offers a Table 2: The predominant biomolecular characteristics encapsulated within the textual descriptions.</p>
<p>Features Example</p>
<p>Chemical properties It combines with metals to make fluorides such as sodium fluoride and calcium fluoride.</p>
<p>Physical properties</p>
<p>The molecule is a colorless, flammable gas that has a distinct, pungent smell.</p>
<p>Molecule Applications</p>
<p>Used as a flavoring, solvent, and polymerization catalyst.</p>
<p>Environment</p>
<p>The molecule is a metal that occurs naturally throughout the environment, in rocks, soil, water, and air.</p>
<p>Safety</p>
<p>Lethal by inhalation and highly toxic or lethal by skin absorption.</p>
<p>Formation</p>
<p>It is formed in foods that are rich in carbohydrates when they are fried, grilled, or baked.</p>
<p>Function</p>
<p>The designed protein must be able to regulate signal transduction.</p>
<p>Subcellular location The designed protein localizes to the mitochondrion.</p>
<p>Protein Structure</p>
<p>The target protein must exhibit Helix as its primary conformation.</p>
<p>Family &amp; Domain</p>
<p>The designed protein should contain PWWP domain that is essential for its function.</p>
<p>PTM / Processing Incorporate a signal peptide in the protein design.</p>
<p>lens into structural complexity and potential stability, with implications for chemical reactivity and probable biological activity.</p>
<p>In Figure 4 (e-j), we delve into the attributes of proteins within Mol-Instructions. Figure 4 (e-g) highlights the varied distribution of protein sequence lengths.Categorized according to the NCBI Taxonomy, these proteins encompass an expansive range of species and experimental strains, encapsulating 13,563 protein families and 643 superfamilies.Figures 4 (h-j) spotlight functional facets, such as domain, gene ontology, and catalytic activity annotations.The data exhibits a pronounced long-tail distribution, underscoring challenges in inferring functions for proteins, especially those with infrequent functions.</p>
<p>EXTENSIVE COVERAGE OF BIOMOLECULAR DESCRIPTIONS</p>
<p>In the burgeoning field of text-driven biomolecular design, our emphasis lies on the depth and diversity of biomolecular description texts.</p>
<p>As shown in Table 2, molecular text descriptions provide a comprehensive, multi-dimensional, and in-depth view of molecular information.Regarding information depth and breadth, the listed molecular properties offer a wide perspective, ranging from basic chemical attributes to specific application contexts.Such comprehensive coverage allows text descriptions to depict molecules in a varied and layered fashion.By understanding the expressed chemical and physical characteristics, one can grasp the essential features and reactive tendencies of molecules.Further, insights into their applications, environmental prevalence, and safety aspects offer a holistic understanding of their significance and associated safety considerations.</p>
<p>As detailed in Section §3.4,we convert biological insights and functional annotations of naturally occurring proteins into text-based design specifications.Table 2 highlights the diverse features of these proteins, considering five related aspects that cover their behavior in protein folding, maturation, processing, and their contribution to life processes.Unlike traditional de novo protein design that emphasizes protein generation grounded in physical principles, Mol-Instructions targets the creation of proteins with multifaceted desired traits.This challenges the models' capability to discern the intricate sampling space defined by the convergence of multiple attributes.</p>
<p>EXPLORING THE POTENTIAL OF MOL-INSTRUCTIONS</p>
<p>INSIGHTS FROM PERFORMANCE ANALYSIS</p>
<p>To investigate whether Mol-Instructions can enhance LLM's understanding of biomolecules, we perform instruction tuning on the three main domains of Mol-instructions, using LLama-7B (Touvron et al., 2023) as the foundation model.We additionally employ Alpaca-LoRA (Tloen, 2023), Baize-7B (Xu et al., 2023), ChatGLM-6B (Zeng et al., 2023), Vicuna (Chiang et al., 2023), Galactica (Taylor et al., 2022), Text+Chem T5 (Christofidellis et al., 2023), MolT5 (Edwards et al., 2022), and PMC-LLaMA-13B (Wu et al., 2023)     Assessing the accuracy of LLM-generated results in the life sciences field is inherently complex.Subjecting every output to expert review or wet-lab validation would be both time-consuming and impractical.Moreover, given that LLMs can produce varied outputs for the same input, ensuring uniform accuracy across all potential outcomes is a formidable challenge.While we utilize metrics commonly accepted in broader domains to evaluate output quality, these metrics capture only a slice of the overall picture.Quantitative experiments may shed light on performance on certain tasks, but they fall short of comprehensively addressing the evaluation challenges.</p>
<p>As shown in Figure 5, Mol-Instructions enhances the molecular understanding capabilities of LLMs, demonstrating notable improvements in every metric compared to baseline models, including even domain-specific smaller models.Notably, LLMs exhibit an impressive aptitude for predicting molecular properties, as detailed in Figure 3.In this specific task, Alpaca generated answers for a mere 2.62% of the samples, Baize for 0.62%, LLama for 54.5%, Vicuna for 0.14%, Galactica for 74%, whereas ChatGLM refrained from responding.Regarding molecular generation tasks, as depicted in Table 4, LLMs exhibit the capability to generate valid molecules, and compared to the baseline, these generated molecules exhibit a higher degree of similarity to reference molecules.This demonstrates that Mol-Instructions equips LLMs with new insights into molecular generation, chemical reaction prediction, and the synthesis of molecules based on specific instructions.However, the molecule generation capabilities of LLMs still exhibit a discernible gap when compared to specialized smaller models, mainly because LLMs are designed to handle a wider range of tasks at the expense of the specialized performance seen in more focused models.</p>
<p>As demonstrated in Figure 5, for various protein understanding tasks, the LLM tuned with Mol-Instructions can analyze proteins in accordance with specific requirements and exhibits a noteworthy capability in identifying fundamental protein characteristics.For the protein design task, the determination of target functional features for the generated sequences is challenging to validate experimentally.Therefore, as shown in Appendix F, we employ a straightforward approach of aligning the de novo protein sequence to the UniProtKB using BLAST (Camacho et al., 2009).We observe a significant sequence identity between the generated sequence and multiple proteins in the corresponding functional regions.Specifically, we identify the protein (UniProt Accession: A0A518LQL6) as the target protein to perform alignment, as it exhibits the highest sequence identity (40.9%, with a p-value of 7.7e − 30) with the generated sequence.Notably, the A0A518LQL6 protein and the generated protein share similar sequence signatures in the (6S)-NADPHX and metal ion binding regions (residues 1-200).This finding suggests that the generated protein fulfills the design requirements and has the potential for NADPHX epimerase activity.</p>
<p>Figure 6 shows the model's proficiency in comprehending biomolecular text instructions.By infusing the LLM with substantial knowledge from the biomolecular domain, the model demonstrates superior performance compared to the baseline in all NLP tasks.This further underscores the transformative potential of Mol-Instructions in bridging the gap between LLMs and intricate biomolecular studies.</p>
<p>HARNESSING THE POWER OF MOL-INSTRUCTIONS</p>
<p>To optimize researchers' utilization of Mol-Instructions, we suggest three pivotal directions to enhance general model exploration and drive progress in biomolecular understanding and drug design: First, use Mol-Instructions to assess cross-modal comprehension in general models, transitioning from human to life languages.These models should interpret user intentions and decode the biomolecular language, challenging their reasoning capabilities.Second, our work lays the groundwork for deeper biomolecular design exploration.Mol-Instructions cover a wide range of design criteria, by providing data related to biomolecular property prediction tasks, bolsters model understanding of biomolecules.Third, employ Mol-Instructions as essential data for tool learning in addressing complex biological issues.Though research highlights the advantages of specialized tools with foundational models (Qin et al., 2023), a gap exists in the availability of textual instructions, which our dataset addresses.</p>
<p>A ACCESSING AND UTILIZING MOL-INSTRUCTIONS</p>
<p>A.1 HOSTING AND ACCESS DETAILS Our dataset and associated models are securely hosted on GitHub and Hugging Face, which are well-recognized platforms for managing open-source projects.They provide vast accessibility and efficient management of extensive data and code repositories, guaranteeing unobstructed access to all potential users.To enable efficient usage of our resources, we provide comprehensive guidelines and instructions on the repository.These cover how to explore the dataset, understand its structure, and utilize the models.</p>
<p>A.2 DATA SOURCES AND LICENSE</p>
<p>As shown in Table 5, we detail the sources and data rights for all data components used in constructing the Mol-Instructionsdataset, including both biomolecules and textual descriptions.All data sources were rigorously scrutinized to ensure their licenses permit our kind of research and subsequent usage.Throughout the article, every mention or use of these data sources is properly and accurately cited.</p>
<p>A.3 USAGE GUIDELINES AND OBLIGATIONS</p>
<p>We assert that all data included in this work comply with the stipulations of the CC BY 4.0 License.We acknowledge our responsibility as licensors to facilitate open and fair use of the dataset while recognizing the creators' contributions.We accept all obligations related to enforcing this license and pledge our commitment to assist all potential users in understanding their rights and responsibilities under this license.</p>
<p>We assure that our dataset does not contain any personally identifiable or privacy-sensitive information.</p>
<p>We have enforced stringent quality control procedures and security checks to prevent the inclusion of harmful or malicious content.However, it is important to note that while we have taken considerable measures to ensure the dataset's safety and privacy, we do not bear responsibility for any issues that may arise from its use.</p>
<p>We emphatically urge all users to adhere to the highest ethical standards when using our dataset, including maintaining fairness, transparency, and responsibility in their research.Any usage of the dataset that may lead to harm or pose a detriment to society is strictly forbidden.</p>
<p>In terms of dataset maintenance, we pledge our commitment to provide necessary upkeep.This will ensure the continued relevance and usability of the dataset in light of evolving research landscapes.This commitment encompasses regular updates, error checks, and amendments in accordance with field advancements and user feedback.</p>
<p>B TASK DEFINITION AND DATA CONSTRUCTION B.1 MOLECULE-ORIENTED INSTRUCTIONS</p>
<p>Molecular description generation Molecular description generation entails the creation of a detailed textual depiction illuminating the structure, properties, biological activity, and applications of a molecule based on its molecular descriptors.It furnishes chemists and biologists with a swift conduit to essential molecular information, thus efficiently guiding their research and experiments.</p>
<p>To gather ample and authoritative molecular text annotation data, we chose PubChem (Kim et al., 2021) as the data source.PubChem, a freely accessible database managed by the National Center for Biotechnology Information (NCBI), is a valuable resource for chemical research.Many compounds in PubChem have text descriptions that come from direct submissions from various research institutions, and automated data mining and information extraction from scientific literature and patents.</p>
<p>Firstly, we commence with PubChem's Power User Gateway, which provides abstracts of PubChem compound records in XML format, facilitating the efficient retrieval and processing of chemical information.We crawl all valid molecular description texts along with the unique PubChem Chemical Identifier (CID) corresponding to the molecule, and employ the CID to retrieve the corresponding SMILES representation from all compounds documented in PubChem.Secondly, given that the SMILES provided by PubChem may not always be accurate, we filter out SMILES that contain syntactic errors or violate fundamental chemical principles, and convert all valid SMILES into SELFIES format.Note that we carry out this step in every task, and it will not be reiterated in the subsequent sections.Thirdly, to compel the model to focus on the semantics of the description, we follow Edwards et al. (2022) to replace the molecule's name in every description with "the molecule is...".Finally, we call the gpt-3.5-turbo to generate a diverse set of task descriptions via prompts, which we then randomly assign to each SELFIES-description pair.We have compiled a total of 331,261 instructions.</p>
<p>Description-guided molecule generation The significance of description-based molecule generation lies in its potential to streamline the process of molecular design by enabling the production of molecules that directly meet the criteria outlined in a given description.This facilitates a more targeted approach in the creation and optimization of novel molecules, with applications in diverse fields such as drug discovery and materials science.</p>
<p>In this phase, we repurpose the SELFIES-description pairs amassed from PubChem in the preceding task.Unlike before, in this instance, the instruction entries have the molecular description as the input and the SELFIES representation of the molecule as the output.We subsequently fabricate a series of task descriptions for description-guided molecule generation serving as the instruction.This results in a compilation of 331,261 instruction data entries.</p>
<p>Forward reaction prediction Forward reaction prediction pertains to the anticipatory determination of the probable product(s) of a chemical reaction, given specific reactants and reagents.This facilitates the optimization of research and development methodologies, curbs the extent of experimental speculation, and endorses greener chemistry practices by mitigating waste production.</p>
<p>To collect high-quality chemical reaction data, we focus on the USPTO dataset (Wei et al., 2010).This dataset encompasses a multitude of organic chemical reactions in SMILES format, extracted from American patents and patent applications.The general format is "reactant ≻ reagent ≻ product".</p>
<p>Typically, reagents are defined as chemical substances that do not appear in the main product.However, in an effort to simulate the real-world scenario of non-chemically specialized individuals, we undertake a more challenging task, one that does not separate reagents and reactants but requires the model to identify them independently.After preprocessing, we secure 138,768 standard instruction data entries.In each of these instruction entries, the input signifies the reactants and reagents in the reaction, with individual chemicals separated by a period ('.').Conversely, the output denotes the product of this reaction.</p>
<p>Retrosynthesis Retrosynthetic analysis is a pivotal synthetic methodology in organic chemistry that employs a reverse-engineering approach, initiating from the target compound and retroactively tracing potential synthesis routes and precursor molecules.This technique proves instrumental in sculpting efficient synthetic strategies for intricate molecules, thus catalyzing the evolution and progression of novel pharmaceuticals and materials.</p>
<p>In this task, we concentrate exclusively on single-step retrosynthesis.Our data collection comes from the manually processed USPTO 500MT dataset (Lu &amp; Zhang, 2022), which itself is meticulously refined from the USPTO database (Wei et al., 2010).Through preprocessing, we have obtained 143,536 standard instruction entries.In each entry, the input is the product, and the output is the reactants, with each reactant separated by a period ('.').</p>
<p>Reagent prediction Reagent prediction endeavors to ascertain the suitable catalysts, solvents, or ancillary substances required for a specific chemical reaction.This endeavor facilitates chemists in uncovering novel reaction types and mechanisms, identifying more optimal or eco-friendly reaction conditions, and ultimately streamlining the comprehensive chemical process to attain maximal cost-effectiveness and environmental stewardship.</p>
<p>Like retrosynthesis, the data for this task also originates from the USPTO 500K dataset (Lu &amp; Zhang, 2022).After processing, we have approximately 138,768 entries.In each instruction entry, the input is a chemical reaction from reactants to product, formatted as "reactant ≻≻ product".The expected output is the potential reagents that facilitate this reaction.</p>
<p>Property prediction Property prediction involves forecasting or estimating a molecule's inherent physical and chemical properties based on information derived from its structural characteristics.It facilitates high-throughput evaluation of an extensive array of molecular properties, enabling the virtual screening of compounds.Additionally, it provides the means to predict the unknown attributes of new molecules, thereby bolstering research efficiency and reducing development times.</p>
<p>In this task, we primarily focus on the quantum mechanics properties of molecules, with data drawn from the QM9 dataset of MoleculeNet (Wu et al., 2018).The dataset is replete with multiple property data associated with each molecule, leading to the creation of a distinctive instruction for every property linked to its corresponding molecule.For example, given molecule A and its properties P 1 , P 2 , and P 3 , we generate three distinct instructions, with each entry featuring molecule A as the input and the respective property (P 1 , P 2 , or P 3 ) as the output.Correspondingly, individual instructions mirror the property they represent.For a comprehensive understanding, please refer to Figure 8 (a).Following this procedure, we have derived 401,229 instruction entries after preprocessing.</p>
<p>Certainly, we acknowledge that the scope of properties presently collected might be somewhat narrow, not fully representing the comprehensive landscape of the molecular domain.Efforts will be made to continually optimize and enrich our instruction dataset.The initial intent of creating such a type of instruction is to investigate whether LLMs can yield pertinent output given identical input, but with varying instruction demands.</p>
<p>B.2 PROTEIN-ORIENTED INSTRUCTIONS</p>
<p>UniProtKB, a universal protein knowledgebase, is used as our data source.Concurrently, to safeguard the quality of proteins, we opt for entries from UniProtKB/Swiss-Prot, a highly reliable and manually annotated protein sequence database.We then augment our dataset by incorporating selected entries with high annotation scores from UniProtKB/TrEMBL, thus enhancing data volume and diversity.Further, to mitigate potential bias in training due to redundancy in protein sequence data, such as closely-related protein variants and homologous sequences with high sequence identity within Swiss-Prot and TrEMBL databases, we administer a stringent filtration process to purge redundant proteins from our dataset.First, We cluster these protein sequences based on a 90% similarity threshold using MMseqs (Steinegger &amp; Söding, 2017) tool (-min-seq-id 0.9), designate entries abundant in functional annotations within each cluster as representative proteins and dismissing the remainder.Second, MMseqs search (-min-seq-id 0.9) is executed using the representative proteins sourced from the TrEMNL as query database, and proteins from the Swiss-Prot as the target database.All TrEMNL sequences that align with a Swiss-Prot sequence, possessing 90% sequence identity or higher during this search, are subsequently eliminated.These measures intend to streamline the construction of high-quality, non-redundant protein function-oriented instruction data.</p>
<p>Protein design</p>
<p>In this work, we seek to construct instructions using the textual form to implement de novo protein design for user intent, which could conveniently design composite properties of interest.Formally, given the design requirements of users, models are required to generate protein amino acid sequences that align with those requirements.Hence, we select annotations from 20 features in the UniProt knowledgebase to generate the protein design requirements as instructions.As shown in Table 6, these features comprise the properties of proteins commonly studied or expected for target proteins by biological researchers.To better integrate this structural knowledge with instructions, we design a series of templates (see in Table 7) to convert the annotations into textual expected properties.Therefore, we could assemble the above functional descriptions and properties together into the protein design instructions (we see an annotation as an individual condition).Table 7 demonstrates examples of templates for the conversion of structural data into textual format.Thus, we obtain 200,000 instruction entries, with the input being the design requirement and the output being the ideal protein sequence.In this task, the provided target sequence serves merely as a reference, which contrasts with other functional prediction tasks that have a definitive ground truth.</p>
<p>Over time, the UniProt database has amassed an extensive collection of experimentally verified functional descriptions and annotations for proteins.This collection assists researchers in swiftly comprehending the roles and mechanisms these proteins play in various biological processes.Nevertheless, the swift augmentation in protein numbers within sequence databases, coupled with the diversity of their functions, poses a significant challenge for automated function prediction through computational approaches.In our work, we focus on three distinct functional annotation tasks and Protein function prediction For GO terms prediction, given the specific function prediction instruction and a protein sequence, models characterize the protein functions using the GO terms presented in three different domains (cellular component, biological process, and molecular function).In the acquired 116,458 instruction entries, the input is a protein sequence, and the output represents the function of that protein.</p>
<p>Catalytic activity prediction Meanwhile, the EC number, a numerical classification system for enzymes hinging on the chemical reactions they catalyze, is substituted with the corresponding reaction.This substitution aims to leverage the tacit knowledge ingrained in pre-trained language models, thereby encouraging the model to predict the reaction itself rather than the mere EC number.In the final 54,259 instruction entries, the input is a protein sequence, and the output refers to the catalytic activity of the protein and the chemical reactions it promotes.Domain/motif prediction We introduce the domain prediction task, which tasks language models with the identification of the domain type within a given protein sequence, which is defined as a compact folded three-dimensional structure.Each of the 46,028 instruction entries includes a protein sequence as the input, and the output refers to the domains or motifs that the protein may contain.</p>
<p>Functional description generation On the basis of the above functional prediction tasks, we design the functional description generation task, which not only evaluates the reasoning capability of the language model in determining the function of a protein sequence but also assesses the efficacy of the language model's text generation.After data preprocessing, we obtain 88,259 instruction entries, where the input is a protein sequence, and the output describes the protein's function, subcellular localization, and any biological processes it may be a part of.</p>
<p>B.3 BIOMOLECULAR TEXT INSTRUCTIONS</p>
<p>Chemical entity recognition Chemical Entity Recognition (CER) is a fundamental task in biomedical text mining and Natural Language Processing (NLP).It involves the identification and classification of chemical entities in textual data, such as scientific literature.These entities can encompass a broad range of concepts including chemical compounds, drugs, elements, ions or functional groups.Given the complexity and variety of chemical nomenclature, the CER task represents a significant challenge for LLMs, and their performance in this task can provide important insights into their overall capabilities in the biomedical domain.For this task, we employ the BC4CHEMD (Krallinger et al., 2015) dataset, in which the chemical entities have been manually identified and labeled by experts.To ensure a balanced representation of each task, and to equip the model with the ability to handle a wide array of tasks, we randomly sample 1,000 entries from the BC4CHEMD dataset.</p>
<p>Chemical-protein interaction extraction</p>
<p>We task language models with the nuanced role of annotating chemical-protein interactions.This endeavor seeks to explore the extent of biochemical and pharmacological knowledge encapsulated within these models.More specifically, the models are presented with excerpts from scientific literature and are required to not only identify distinct chemicals within the text but also to discern the specific nature of the interactions between them.This could involve, for instance, determining regulatory relationships between identified ligands and proteins.We utilize the ChemProt (Krallinger et al., 2017) dataset as the primary source and subsequently convert it into instruction data.In instances where multiple relationship triplets exist within a common scientific document, we consolidate them into a singular annotation separated and delineated by commas.</p>
<p>Chemical-disease interaction extraction</p>
<p>The goal of this task is to discern the relationships between chemicals and diseases from given medical literature, a concept known as chemical-induced disease (CID) relations.These CID relations are paramount in biomedical research, playing crucial roles in areas such as drug discovery, toxicology, and disease etiology.We utilize the BC5CDR Corpus (Li et al., 2016), which comprises 1,500 PubMed articles.These articles collectively feature 4,409 annotated chemicals, 5,818 diseases, and 3,116 chemical-disease interactions.Considering the analogous structure of the BC5CDR dataset to the ChemProt dataset, we employ an identical series of processing steps to convert the dataset entries to instructions.</p>
<p>Prompt:</p>
<p>Given a paragraph of paper, can you ask five questions and give answers that can be directed to the paragraph?List in the format of Question-Answer pair.</p>
<p>Paragraph: The outer membrane protein G (OmpG) nanopore is a monomeric β-barrel channel consisting of seven flexible extracellular loops.Its most flexible loop, loop 6, can be used to host high-affinity binding ligands for the capture of protein analytes, which induces characteristic current patterns for protein identification.At acidic pH, the ability of OmpG to detect protein analytes is hampered by its tendency toward the closed state, which renders the nanopore unable to reveal current signal changes induced by bound analytes.In this work, critical residues that control the pH-dependent gating of loop 6 were identified, and an OmpG nanopore that can stay predominantly open at a broad range of pHs was created by mutating pH-sensitive residues.A short single-stranded DNA was chemically tethered to the pH-insensitive OmpG to demonstrate the utility of the OmpG nanopore for sensing complementary DNA and a DNA binding protein at an acidic pH.</p>
<p>GPT-3.5 completion:</p>
<p>Q1: What is the OmpG nanopore?A1: The OmpG nanopore is a monomeric β-barrel channel consisting of seven flexible extracellular loops.</p>
<p>Q2: What is loop six used for?A2: Loop 6 is used to host high-affinity binding ligands for the capture of protein analytes, which induces characteristic current patterns for protein identification.</p>
<p>Q3: How can the tendency toward the closed state be addressed?A3: Critical residues that control the pH-dependent gating of loop 6 can be identified and an OmpG nanopore that can stay predominantly open at a broad range of pHs can be created by mutating these pH-sensitive residues.</p>
<p>Q4: How has the utility of the OmpG nanopore been demonstrated?A4: The utility of the OmpG nanopore has been demonstrated by chemically tethering a short singlestranded DNA to the pH-insensitive OmpG to sense complementary DNA and a DNA binding protein at an acidic pH.</p>
<p>Q5: What type of channel is the OmpG nanopore?A5: The OmpG nanopore is a monomeric β-barrel channel.Multiple-choice question We assemble a collection of 12,398 multiple-choice questions from the MedMCQA (Pal et al., 2022) and MMLU (Hendrycks et al., 2021) (Massive Multitask Language Understanding) datasets.Using the instruction-tuning approach, our objective is to inspire the professional capabilities of language models to answer diverse probes pertaining to biomolecules.The questions span the subjects in biology, chemistry, medicine and other vertical areas associated with biomolecular research.</p>
<p>True or False question The objective of the true or false question-answer task is to answer research questions with affirmative, negative, or uncertain responses (e.g., Do preoperative statins reduce atrial fibrillation after coronary artery bypass grafting?).In the initial PubMedQA dataset, each entry consists of a question, an abstract from a publication in PubMed (White, 2020) for reference, a single answer and a corresponding explanation for the answer.For this task, instead of rigidly designing an instruction that prompts models to refer to the materials for answering, we eliminate the references and treat the questions as complements to the subsequent open-ended questions, accommodating a wider variety of question types.Further, the ideal response to a given question should provide an accurate answer with a cogent and reasonable explanation.</p>
<p>Open question Open-ended questions are defined as those that simply pose the question, without imposing any constraints on the format of the response.This distinguishes them from questions with a predetermined answer format.We primarily gather the open-ended questions from the MedMCQA dataset, specifically selecting those pertaining to the domains of biochemistry, pharmacology and medicine.The original format of MedMCQA questions was a multiple-choice style, illustrated by questions such as, "In which of the following conditions are Leukotriene inhibitors highly effective?".However, we found that certain questions did not clearly communicate that the answers needed to be selected from the provided choices, for example, a question like "Antibody used in the treatment of RSV infection is:".Hence, we conveniently transform 27,574 questions into open-ended questions,</p>
<p>where the corresponding answer encompasses the description of the correct option and the explanation, namely MedMCQA-Open.</p>
<p>In order to delve deeper into the queries concerning biomolecules and bolster the language models' proficiency within the domains of chemistry and biology, we propose the SELF-QUESTIONING to expand the instruction data of open-ended question by employing GPT3 to extract factual questionanswer pairs from PubMed abstracts in the field of biomolecular research.The implementation of SELF-QUESTIONING consists of three steps: 1) data collection, 2) question-answer instance generation with the self-questioning approach, and 3) filtering low-quality questions.</p>
<p>First, we gather the complete abstracts from PubMed, the annual baseline released in December 2022.Each publication in PubMed comprises a title, abstract and Medical Subject Headings (MeSH).To focus on responding to questions about the biomolecular domain from users, we only consider those publications whose abstract and MeSH contain some specific keywords (e.g., protein, molecule) that probably pertain to the study of biomolecules.Second, it is challenging that expect models to generate high-quality and factual questions based on the provided reference materials.Nevertheless, we found that pretrained language models can achieve this when prompted with the instruction that requests the model to extract question-answer pairs.This approach ensures that the derived answers are properly aligned with the corresponding sources.A representative example of this generation process is illustrated in Figure 7. Third, to further ensure the overall quality of the produced questions, we incorporate an exclusion criterion that substantially eliminates questions closely tied to reference materials, for instance, questions such as "What is the purpose of the study?".These types of questions generally involve specific vocabulary terms such as "result", "study", "paragraph" and "article".By identifying such terms, we are able to exclude them from the pool of consideration effectively.We refer to the dataset containing 10,521 examples as PubMedQA-GPT.This is then combined with the MedMCQA-Open dataset to construct the instruction data.</p>
<p>C A MORE EXHAUSTIVE DATA ANALYSIS MOL-INSTRUCTIONS</p>
<p>Figure 4 provides a multi-faceted analysis of the diversity and complexity of molecules and proteins.</p>
<p>For the sake of clear presentation, only part of the coordinate coverage is displayed.A more comprehensive display of statistical data is provided in Table 8.Overall, these statistics reflect the broad and diverse nature of the biomolecules, which should contribute to the robustness and generalizability of models trained on them.Indeed, protein sequences are typically very long, which poses a significant challenge for LLMs to capture and understand their "grammar" or patterns.</p>
<p>Strategies for encoding and processing these lengthy sequences, as well as effective ways to guide LLMs in predicting or designing valid protein sequences, are crucial areas for further investigation.</p>
<p>D EXPERIMENTAL SETUP DETAILS</p>
<p>With the Mol-Instructions data, we employ the 7B LLaMA model as our foundation model in the entire experiment and conduct instruction tuning on the LLaMA model.In this work, due to the diversity of modalities and substantial variations in task difficulty, we train the LLaMA models on our three distinct datasets tailored to specific biomolecular problems, resulting in the development of three fine-tuned models.For each distinct task, we allocated almost 1k samples as the test set to compute metrics and evaluate the model's performance.The remaining samples were divided into training and validation sets at an 8:2 ratio.</p>
<p>Although tokenization is a crucial part of data processing, particularly when dealing with various modalities, this study does not delve into an extensive analysis of the sequential tokenization of different modalities.Therefore, we approach the protein amino acid sequence and the SELFIES string of molecules as human language and tokenize the data using the byte-pair encoding (BPE) algorithm.We utilize the identical tokenization model employed in the LLaMA model.We use the longest-padding strategy to pad the tokenized sequences to the longest sequence length in the batch.</p>
<p>We adopt the low-rank Adapter (LoRA) fine-tuning on the molecule and text-oriented datasets, an efficient method that reduces memory during training and keeps a small set of parameters trainable, while not updating pre-trained models.For protein-oriented instruction data, we perform full finetuning with the memory optimization technique, ZeRO implemented in the DeepSpeed library.Our models are trained using AdamW optimizer and linear learning rate scheduler.We conduct the LoRA training and generation on 32GB V100 GPUs while performing the full-model finetuning on the 80GB A800 GPUs.The exact hyperparameters we tune for each model are shown in Table 9.To evaluate the molecular understanding tasks, we utilize metrics like BLEU (Papineni et al., 2002), ROUGE (Lin, 2004), and METEOR (Banerjee &amp; Lavie, 2005) to assess the quality of the generated outputs by comparing them to reference answers.For molecule generation, we first validate whether the generated strings are valid molecules using RDKit (Landrum et al., 2013) and then compute their exact match with the reference solutions.However, it's important to note that a single textual description might correspond to multiple molecular structures.Moreover, expecting an LLM, even one fine-tuned with LoRA on specific instructions, to produce outputs that perfectly match reference data might be unrealistic.To accommodate these complexities and offer a more comprehensive evaluation, we further employ metrics that measure molecular similarity.These include similarity scores derived from RDKit/MACCS/Morgan fingerprints (Tanimoto, 1958;Schneider et al., 2015;Durant et al., 2002), as well as Levenshtein (Li &amp; Liu, 2007) and BLEU scores.For the molecular property prediction task, we employ MAE (mean absolute error) to quantify how accurately the model predicts continuous values.</p>
<p>E.2 PROTEIN METRICS</p>
<p>For protein understanding tasks, we esteem these tasks as the functional description task and employ ROUGE to quantify the quality of the generated descriptions for biological characteristics.</p>
<p>E.3 BIOTEXT METRICS</p>
<p>For NLP text tasks, we employ general metrics for Q&amp;A, entity recognition, and relation extraction to evaluate the generated outputs.</p>
<p>F ADDITIONAL RESULTS</p>
<p>Due to space constraints, only a portion of the results are displayed in the main text.The remaining results, which further illustrate the effectiveness of our Mol-Instructions, can be found in Figure 8, 9, 10, and 11.Please note that Galactica (Taylor et al., 2022), Text+Chem T5 (Christofidellis et al., 2023), and MolT5 (Edwards et al., 2022) only support the SMILES format.To accommodate this, we convert the SELFIES in our instructions to SMILES.It's also important to mention that MolT5 has not undergone instruction tuning, hence it only processes the "input" part of our instructions.</p>
<p>The analysis of the various experiments illustrated in Figure 8 reveals how Mol-Instructions guides LLMs in comprehending and executing specific molecular tasks.This guidance is evident in tasks such as molecule description generation and description-guided molecule design, where the dataset provides precise instructions that direct the model to produce detailed molecule descriptions and accurate designs.The performance of MolT5 is notably inferior to instruction-following models, exhibiting poor generalization capabilities.In tasks related to chemical reactions, such as forward reaction prediction, retrosynthesis, and reagent prediction, Mol-Instructions play a key role in instructing the model to predict reaction products, potential reactants, or correct reagents.Alpaca-LoRA, ChatGLM, Baize, and Vicuna in the absence of such specific instructions, produce outputs that are either too generic or not aligned with the task requirements.LLMs generally underperform in molecule generation compared to domain-specific smaller models, due to their broader focus which compromises task-specific specialization.For the property prediction tasks, Mol-Instructions help the model provide near-accurate estimations of various molecular properties such as HOMO, LUMO, and HOMO-LUMO gap energies.In comparison, Alpaca-LoRA's outputs, lacking guidance from specific instructions, deviate significantly from the actual values.Galactica consistently outputs negative values.</p>
<p>As demonstrated in the prediction instances illustrated in Figure 9 and 10, the fine-tuned model delivers consistent and user-specific protein analysis for functional annotation.For instance, the model accurately classifies a provided protein as the 23S rRNA (adenine(2503)-C(2))-methyltransferase within the context of catalytic activity prediction tasks.Moreover, while slight variations may arise in describing distinct functional traits relative to the annotations in the UniProtKB, it showcases remarkable potential in discerning the fundamental properties of proteins.</p>
<p>As showcased in Figure 11, in tasks related to chemical entities and their interactions, Mol-Instructions aids the model in identifying the correct entities and establishing meaningful relations between them.In contrast, models that are not fine-tuned with our instructions, such as Alpaca-LoRA, often produce outputs that are too generic or miss the specific relationships present in the data.When dealing with multiple-choice, True or False, or open questions, the model fine-tuned with Mol-Instructions not only provides the correct answers but also delivers them in a more detailed and well-structured manner.This demonstrates the effectiveness of Mol-Instructions in improving LLMs' understanding and performance in these question-answering tasks.</p>
<p>Overall, the results indicate that Mol-Instructions can improve the LLM's ability to execute moleculeoriented, protein-oriented, and biomolecular text tasks.It underscores the importance of having task-specific instructions to guide the model, particularly when dealing with specialized domains such as biochemistry.In comparison, models that lack such specific instruction-based tuning, like Alpaca-LoRA, may struggle to produce outputs that align with the specific requirements of the tasks.</p>
<p>Despite the promising results demonstrated above, there are also several limitations.First, while the experiments confirm that Mol-Instructions can aid LLMs in understanding and mastering biomolecular-related information to a certain extent, it should be clear that the model obtained by instruction tuning at this stage is merely a preliminary demonstration.Its application potential for real-world, production-level tasks is still limited.Moreover, to fully realize the potential of Mol-Instructions, more profound exploration and innovation in algorithmic improvement are needed.This includes optimizing instruction tuning methods, further refining the model's ability to understand and follow instructions, and enhancing its generalization capacity across various molecular tasks.Therefore, while Mol-Instructions represents a step forward in the use of instruction datasets for biomolecular tasks, there remains a significant scope for future research and development to maximize its utility and effectiveness.</p>
<p>G LIMITATIONS AND ETHICAL CONCERNS</p>
<p>The advancements in LLMs and their applications in the realm of biosciences, as showcased in our study, undeniably open avenues for a multitude of beneficial applications.However, with great power comes great responsibility.We recognize the necessity to discuss potential limitations and ethical concerns associated with such advancements.</p>
<p>G.1 POTENTIAL MISUSE IN BIOENGINEERING</p>
<p>The capability of LLMs to "forecast chemical reactions, architect new molecules as per instructions, and apprehend molecular structural attributes and reactive features" inevitably raises concerns.In the wrong hands, these capabilities might enable malicious actors to exploit the system for nefarious purposes, such as the synthesis of harmful biochemical agents or bioweapons.</p>
<p>Figure 1 :
1
Figure 1: Empowering Large Language Models with Mol-Instructions to unlock biomolecular domain.Both molecular and protein structures are represented as sequences.</p>
<p>Figure 2 :
2
Figure 2: The overview of data construction of Mol-Instructions, which comprises four sectors: human-AI collaboration task description creation ( §3.2), information derivation from existing data ( §3.3), conversion of biological data into a textual format via templates ( §3.4), and quality control ( §3.5).For detailed procedures for each task, please refer to Appendix B.</p>
<p>Figure 3 :
3
Figure 3: The compositional structure of Mol-Instructions.Mol-Instructions primarily encompasses tasks across three major categories: (a), (b) and (c).The task names are indicated above the horizontal lines, the sources of the original data and the sizes of the constructed instruction datasets are labeled below the horizontal lines, and the percentages on the pie charts represent the proportion of data within each major category.</p>
<p>Figure 4 :
4
Figure 4: Multidimensional analysis of biomolecular sequences.The left side illustrates the diversity of molecules within Mol-Instructions, encompassing molecules of varying complexity and distinct structures.On the right side, the analysis delves into the diversity of protein sequences within Mol-Instructions, considering different aspects such as sequence length, domain, and activity.training and utilization of LLMs.A comprehensive exposition on task definitions and instruction construction is provided in Appendix B.</p>
<p>Figure 5 :
5
Figure 5: The performance comparison on molecule and protein understanding tasks: molecule description generation (left), protein function, functional description, catalytic activity, and domain/motif prediction (right).</p>
<p>Figure 6 :
6
Figure 6: Results for bioinformatic NLP tasks.(C)ER denotes chemical entity recognition, (C-D)IE signifies chemical-disease interaction extraction, and (C-P)IE stands for chemical-protein interaction extraction.</p>
<p>Figure 7 :
7
Figure 7: An illustration of SELF-QUESTIONING method for generating factual question-answer pairs based on a given PubMed abstract derived from PubMed White (2020) in the biomolecular field.</p>
<p>Figure 8 :
8
Figure 8: Performance comparison of LLM tuning using instructions across molecule-oriented tasks.</p>
<p>Figure 9 :
9
Figure 9: Performance comparison of LLM tuning using instructions across protein-oriented tasks.(1/2)</p>
<p>Figure 10 :
10
Figure 10: Performance comparison of LLM tuning using instructions across protein-oriented tasks.(2/2)</p>
<p>Figure 11 :
11
Figure 11: Performance comparison of LLM tuning using instructions across biomolecular text tasks.</p>
<p>Table 3 :
3
Results of molecular property prediction tasks.
MODELMAE ↓Property PredictionALPACA322.109BAIZE261.343CHATGLM-LLAMA5.553VICUNA860.051GALACTICA0.568OURS↑0.555 0.013</p>
<p>Table 4 :
4
Results of molecular generation tasks.These tasks encompass description-guided molecule design, reagent prediction, forward reaction prediction, and retrosynthesis.
Description-guided Molecule DesignALPACA0.0000.00451.0880.0060.0290.0000.002BAIZE0.0000.00653.7960.0000.0000.0000.002CHATGLM0.0000.00453.1570.0050.0000.0000.005LLAMA0.0000.00359.8640.0050.0000.0000.003VICUNA0.0000.00660.3560.0060.0010.0000.001GALACTICA0.0000.19244.1520.1350.2480.0880.992TEXT+CHEM T50.0970.50841.8190.3520.4740.3530.721MOLT50.1120.54638.2760.4000.5380.2950.773OURS0.0020.34541.3670.2310.4120.1471.000Reagent PredictionALPACA0.0000.02629.0370.0290.0160.0010.186BAIZE0.0000.05130.6280.0220.0180.0040.099CHATGLM0.0000.01929.1690.0170.0060.0020.074LLAMA0.0000.00328.0400.0370.0010.0010.001VICUNA0.0000.01027.9480.0380.0020.0010.007GALACTICA0.0000.14130.7600.0360.1270.0510.995TEXT+CHEM T50.0000.22549.3230.0390.1860.0520.313OURS0.0440.22423.1670.2370.3640.2131.000Forward Reaction PredictionALPACA0.0000.06541.9890.0040.0240.0080.138BAIZE0.0000.04441.5000.0040.0250.0090.097CHATGLM0.0000.18340.0080.0500.1000.0440.108LLAMA0.0000.02042.0020.0010.0020.0010.039VICUNA0.0000.05741.6900.0070.0160.0060.059GALACTICA0.0000.46835.0210.1560.2570.0970.946TEXT+CHEM T50.2390.78220.4130.7050.7890.6520.762OURS0.0450.65427.2620.3130.5090.2621.000RetrosynthesisALPACA0.0000.06346.9150.0050.0230.0070.160BAIZE0.0000.09544.7140.0250.0500.0230.112CHATGLM0.0000.11748.3650.0560.0750.0430.046LLAMA0.0000.03646.8440.0180.0290.0170.010VICUNA0.0000.05746.8770.0250.0300.0210.017GALACTICA0.0000.45234.9400.1670.2740.1340.986TEXT+CHEM T50.1410.76524.0430.6850.7650.5850.698OURS0.0090.70531.2270.2830.4870.2301.000
MODEL EXACT↑ BLEU↑ LEVENSHTEIN↓ RDK FTS↑ MACCS FTS↑ MORGAN FTS↑ VALIDITY↑</p>
<p>Table 5 :
5
Data resources and licenses involved in our paper.Unless otherwise noted, the contents of the FDA website (www.fda.gov),both text and graphics, are not copyrighted.They are in the public domain and may be republished, reprinted and otherwise used freely by anyone without the need to obtain permission from FDA.Credit to the U.S. Food and Drug Administration as the source is appreciated but not required.
Data SourcesLicense URLLicense NotePubChemhttps://www.nlm.nih.gov/Works produced by the U.S. government are notweb_policies.htmlsubject to copyright protection in the United States.Any such works found on National Library ofMedicine (NLM) Web sites may be freely usedor reproduced without permission in the U.S.USPTOhttps://www.uspto.gov/It can be freely used, reused, and redistributed bylearning-and-resources/anyone.open-data-and-mobilityUniProtKBhttps://www.uniprot.org/You are free to: Share -copy and redistributehelp/licensethe material in any medium or format. Adapt -remix, transform, and build upon the material forany purpose, even commercially.BC4CHEMD, ChemProt, BC5CDRhttps://biocreative.The task data is freely available now for the re-bioinformatics.udel.search community.edu/tasks/biocreative-v/track-3-cdr/MoleculeNet, MMLU, PubMedQA, MedMCQAhttps://opensource.org/Permission is hereby granted, free of charge, tolicense/mit/any person obtaining a copy of this software andassociated documentation files (the "Software"), todeal in the Software without restriction, includingwithout limitation the rights to use, copy, modify,merge, publish, distribute, sublicense, and/or sellcopies of the Software, and to permit persons towhom the Software is furnished to do so.Agency for Toxic Substances and Disease Registryhttps://www.cdc.gov/Other/This site uses the AddThis service to allow visitors(ATSDR)disclaimer.htmlto bookmark and share website content on a varietyof social media sites. Visitors who use the AddThisservice to share content do not need to register orprovide any personal information.FDA Pharm Classeshttps://www.fda.gov/about-fda/about-website/website-policiesLiverToxhttps://www.nlm.nih.gov/Works produced by the U.S. government are notcopyright.htmlsubject to copyright protection in the United States.Any such works found on National Library ofMedicine (NLM) Web sites may be freely usedor reproduced without permission in the U.S.Drug Database, Clinicalinfo.hiv.govhttps://www.hiv.gov/Unless otherwise noted, material presented on theabout-us/mission-and-teamHIV.gov website is considered Federal governmentinformation and is in the public domain. Thatmeans this information may be freely copied anddistributed.Drug Bankhttps://creativecommons.Subject to the terms and conditions of this Pub-org/licenses/by-nc/4.0/lic License, the Licensor hereby grants You alegalcodeworldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Li-censed Rights in the Licensed Material to: repro-duce and Share the Licensed Material, in wholeor in part, for NonCommercial purposes only; andproduce, reproduce, and Share Adapted Materialfor NonCommercial purposes only.ChEBIhttps://creativecommons.You are free to: Share -copy and redistributeorg/licenses/by/4.0/the material in any medium or format. Adapt -remix, transform, and build upon the material forany purpose, even commercially.Yeast Metabolome Database (YMDB)http://www.ymdb.ca/YMDB is offered to the public as a freely availabledownloadsresource.LOTUS -the natural products occurrence database https://lotus.nprod.net/LOTUS is one of the biggest and best annotated re-sources for natural products occurrences availablefree of charge and without any restriction.GlyCosmos Glycoscience Portalhttps://glycosmos.org/You are free to: Share -copy and redistributelicensethe material in any medium or format. Adapt -remix, transform, and build upon the material forany purpose, even commercially.CAMEO Chemicalshttps://cameochemicals.CAMEO Chemicals and all other CAMEO prod-noaa.gov/help/reference/ucts are available at no charge to those organiza-terms_and_conditions.htm?tions and individuals (recipients) responsible ford_f=falsethe safe handling of chemicals.E. coli Metabolome Database (ECMDB)https://ecmdb.ca/citationsECMDB is offered to the public as a freely avail-able resource.</p>
<p>Table 8 :
8
Data statistics of biomolecules.
CharacteristicsMinMax Mean MedianBertz complexity0 36,222508206Molecular weight18,656273129Atom count1574199Ring count07532Sequence length2 39677455391Domain12215273Catalytic activity12404152Gene Ontology1 28924354</p>
<p>Table 9 :
9
Training hyperparameters for finetuning on different datasets.QV: two linear transformation matrices on the query and value states in the self-attention module.
Hyperparameter Molecule ProteinTextFinetune methodLoRAFull LoRABatch size800961024LR3e-42e-53e-4Steps40,00025,000840Warmup steps1,0002,500100LoRA r16-16LoRA α16-16LoRA dropout0.05-0.05LoRA layersQV-QVE EVALUATION METRICSE.1 MOLECULE METRICS
CONCLUSION AND FUTURE WORKIn this work, we introduce Mol-Instructions, a comprehensive instruction dataset specifically curated for biomolecular studies, bridging the gap in current resources and advancing LLM training in this specialized sphere. Looking ahead, we are committed to the ongoing enrichment and refinement of Mol-Instructions. We will incorporate a wider array of task types, instruction entries, and modalities, in line with the latest advances in chemical research and improvements in AI technology to meet broader chemical research needs and higher-level LLM training requirements. Moreover, given the distinct representation spaces of text and biomolecules, coupled with the limitations imposed by LoRA's training strategy, current LLMs have yet to master the biomolecular language as proficiently as they do human language. Exploring methods to expand the vocabulary, or incorporating bio language as a modality via biomolecular encoders(Fang et al., 2024; Rives et al., 2021;Lin et al., 2022; Cao et al., 2023;Pei et al., 2024), could be pivotal in honing the model's understanding and performance in biomolecular tasks.
ACKNOWLEDGMENTSWe would like to express gratitude to the anonymous reviewers for kind comments.This work was supported by the National Natural Science Foundation of China (No. 62206246), the Fundamental Research Funds for the Central Universities (226-2023-00138), Zhejiang Provincial Natural Science Foundation of China (No. LGG22F030011), Ningbo Natural Science Foundation (2021J190), CAAI-Huawei MindSpore Open Fund, Yongjiang Talent Introduction Programme (2021A-156-G), CCF-Baidu Open Fund, and Information Technology Center and State Key Lab of CAD&amp;CG, Zhejiang University.REPRODUCIBILITY STATEMENTAll data, code, and model weights can be found on GitHub 1 and Hugging Face 2,3,4,5 .For a detailed description of the dataset construction process, please refer to Appendix B. For specific experimental settings, please see Appendix D and E.ETHICS STATEMENTThis study was carried out in strict accordance with ethical guidelines and best practices in research.The biomolecular data utilized were sourced from publicly available datasets, and no proprietary or confidential data were used.Furthermore, we have obtained the necessary permissions and licenses for all third-party content incorporated in our dataset, as detailed in Appendix A.2.Rigorous quality control measures and security checks have been implemented to preclude the presence of any harmful or malicious content in our dataset.However, we recognize the profound implications and potential risks associated with the integration of LLMs and biomolecular knowledge.While our primary intent is to advance scientific understanding and contribute positively to society, we are acutely aware that these tools, in the wrong hands, could be misused.There exists the potential for malicious actors to harness the combined capabilities of LLMs and biomolecular data to generate harmful substances, such as biochemical weapons or illicit drugs.We strongly urge all users to adhere to the highest ethical standards when using our dataset, ensuring fairness, transparency, and responsibility in their research.Any usage of the dataset that may lead to harm or pose a detriment to society is strictly forbidden.Published as a conference paper at ICLR 2024 Table6: Twenty annotation features for formulating precise constraints for protein design.When it comes to features that lack specific types such as signal, which simply indicates the presence of a particular feature in a given protein, we utilize '-' to represent this in the 'Example' field.Table7: Templates for converting structured annotations of specific protein fields into textual form.In practice, we also utilized LLM (GPT-3.5) to enrich the style of the templates.Feature TemplateFunction For general function, the protein need meet that {function}.Pathway A protein that is capable of catalyzing reactions within the {pathway} with high efficiency and specificity.Co-factorThe protein must bind to {co-factor} in order to perform its enzymatic function.Catalytic activityThe protein should be designed to catalyze the following reaction {catalytic activity}.Gene Ontology (MF) The protein must be able to {molecular function}.Gene Ontology (BP) The designed protein must be able to regulate {biological process}.Gene Ontology (CC) The designed protein localizes to the {cellular component}.SignalIncorporate a signal peptide in the protein design.Coiled coilThe target protein must incorporate a coiled coil domain.MotifThe protein's functional design necessitates the inclusion of a {motif}.DomainThe designed protein should contain one or more {domains} that are essential for its function.Compositional biasThe protein should exhibit {compositional bias}.Topological domainThe {topological domain} of the protein should be designed to be flexible or rigid.TransmembraneThe protein should contain a {transmembrane} membrane-spanning region.DNA binding A protein with {DNA binding} capability for targeted gene regulation.Binding siteThe protein should be able to bind {binding site} ligand in a variety of conditionsActive siteThe designed protein must have a {active site} that is highly conserved among related enzymes.Secondary structureThe target protein must exhibit {Beta strand, Helix, Turn} as its primary conformation.one task dedicated to generating functional descriptions.Our goal is to assess the ability of generative language models to address a broad spectrum of functional prediction issues under a unified framework.Concretely, we consider two widely used classification schemes that organize these myriad protein functions, Gene Ontology (GO) Consortium(Ashburner et al., 2000)and Enzyme Commission (EC) numbers.Published as a conference paper at ICLR 2024G.3 MITIGATING RISKSAddressing the potential dangers is paramount.Some steps that can be taken include:• Regulated access: Limiting access to only verified research entities or individuals with a track record of ethical research.• Monitoring usage patterns: Implementing algorithms to detect patterns of misuse or exploration into potentially harmful domains.• Community oversight: Establishing a community-driven oversight mechanism where experts can review and approve specific uses or generated outcomes.• Transparent reporting: Encouraging users to report any unintended outcomes or potentially harmful use-cases they encounter.The ethical implications of AI, especially in sensitive domains like biosciences, cannot be stressed enough.While our work represents a step forward in harnessing the capabilities of LLMs for good, it is vital to move forward with caution, diligence, and an unwavering commitment to ethical principles.
. Sharegpt, April 2023</p>
<p>Gpt4all: Training an assistant-style chatbot with large scale data distillation from gpt-3.5-turbo. Yuvanesh Anand, Zach Nussbaum, Brandon Duderstadt, Benjamin Schmidt, Andriy Mulyar, 2023GitHub</p>
<p>Gene ontology: tool for the unification of biology. Michael Ashburner, Catherine A Ball, Judith A Blake, David Botstein, Heather Butler, Michael Cherry, Allan P Davis, Kara Dolinski, Selina S Dwight, Janan T Eppig, Nature genetics. 2512000</p>
<p>METEOR: an automatic metric for MT evaluation with improved correlation with human judgments. Satanjeev Banerjee, Alon Lavie, Proceedings of the Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization@ACL 2005. Jade Goldstein, Alon Lavie, Chin-Yew Lin, Clare R Voss, the Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization@ACL 2005Ann Arbor, Michigan, USAAssociation for Computational LinguisticsJune 29, 2005. 2005</p>
<p>Emergent autonomous scientific research capabilities of large language models. A Daniil, Robert Boiko, Gabe Macknight, Gomes, 10.48550/arXiv.2304.053322023</p>
<p>Sam Andres M Bran, Andrew D Cox, Philippe White, Schwaller, arXiv:2304.05376Chemcrow: Augmenting large-language models with chemistry tools. 2023arXiv preprint</p>
<p>BLAST+: architecture and applications. Christiam Camacho, George Coulouris, Ning Vahram Avagyan, Jason S Ma, Kevin Papadopoulos, Thomas L Bealer, Madden, 10.1186/1471-2105-10-421BMC Bioinform. 104212009</p>
<p>Instructmol: Multi-modal integration for building a versatile and reliable molecular assistant in drug discovery. He Cao, Zijing Liu, Xingyu Lu, Yuan Yao, Yu Li, 10.48550/arXiv.2311.162082023</p>
<p>Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Pondé De Oliveira Pinto, Jared Kaplan, Harrison Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Ilya Sutskever, and Wojciech Zaremba. Joshua Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr; Bob McGrew, Dario Amodei, Sam McCandlishJan LeikeEvaluating large language models trained on code. CoRR, abs/2107.03374, 2021</p>
<p>Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality. Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E Gonzalez, Ion Stoica, Eric P Xing, March 2023</p>
<p>Palm: Scaling language modeling with pathways. Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, Emily Vinodkumar Prabhakaran, Nan Reif, Ben Du, Reiner Hutchinson, James Pope, Jacob Bradbury, Michael Austin, Guy Isard, Pengcheng Gur-Ari, Toju Yin, Anselm Duke, Sanjay Levskaya, Sunipa Ghemawat, Henryk Dev, Xavier Michalewski, Vedant Garcia, Kevin Misra, Liam Robinson, Denny Fedus, Daphne Zhou, David Ippolito, Hyeontaek Luan, Barret Lim, Alexander Zoph, Ryan Spiridonov, Sepassi, J. Mach. Learn. Res. David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck242023</p>
<p>Unifying molecular and textual representations via multi-task language modelling. Dimitrios Christofidellis, Giorgio Giannone, Jannis Born, Ole Winther, Teodoro Laino, Matteo Manica, International Conference on Machine Learning, ICML 2023. Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, Jonathan Scarlett, Honolulu, Hawaii, USAPMLRJuly 2023. 2023202of Proceedings of Machine Learning Research</p>
<p>Hello dolly: Democratizing the magic of chatgpt with open models. Mike Conover, Matt Hayes, Matt Mathur, Xiangrui Meng, Jianwei Xie, Jun Wan, Ali Ghodsi, Patrick Wendell, Patrick Zaharia, 2023</p>
<p>Uniprot: the universal protein knowledgebase in 2023. 10.1093/nar/gkac1052The UniProt Consortium. 202351</p>
<p>Robust deep learning-based protein sequence design using proteinmpnn. Justas Dauparas, Ivan Anishchenko, Nathaniel Bennett, Hua Bai, Robert J Ragotte, Lukas F Milles, Alexis Basile Im Wicky, Rob J De Courbet, Neville Haas, Bethel, Science. 37866152022</p>
<p>Enhancing chat language models by scaling high-quality instructional conversations. Ning Ding, Yulin Chen, Bokai Xu, Yujia Qin, Shengding Hu, Zhiyuan Liu, Maosong Sun, Bowen Zhou, Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023. Houda Bouamor, Juan Pino, Kalika Bali, the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023SingaporeAssociation for Computational LinguisticsDecember 6-10, 2023. 2023</p>
<p>Reoptimization of MDL keys for use in drug discovery. Joseph L Durant, Burton A Leland, Douglas R Henry, James G Nourse, 10.1021/ci010132rJ. Chem. Inf. Comput. Sci. 4252002</p>
<p>Translation between molecules and natural language. Carl Edwards, Tuan Manh Lai, Kevin Ros, Garrett Honke, Kyunghyun Cho, Heng Ji, 10.18653/v1/2022.emnlp-main.26Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. Yoav Goldberg, Zornitsa Kozareva, Yue Zhang, the 2022 Conference on Empirical Methods in Natural Language ProcessingAbu Dhabi, United Arab EmiratesAssociation for Computational LinguisticsDecember 7-11, 202220222022</p>
<p>Domain-agnostic molecular generation with self-feedback. Yin Fang, Ningyu Zhang, Zhuo Chen, Xiaohui Fan, Huajun Chen, ICLR. OpenReview.net. 2024</p>
<p>Measuring massive multitask language understanding. Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt, 9th International Conference on Learning Representations, ICLR 2021, Virtual Event. AustriaMay 3-7, 2021. OpenReview.net, 2021</p>
<p>Oriol Vinyals, and Laurent Sifre. Training compute-optimal large language models. Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego De Las, Lisa Anne Casas, Johannes Hendricks, Aidan Welbl, Tom Clark, Eric Hennigan, Katie Noland, George Millican, Bogdan Van Den Driessche, Aurelia Damoc, Simon Guy, Karen Osindero, Erich Simonyan, Jack W Elsen, Rae, 10.48550/arXiv.2203.155562022</p>
<p>Pubchem in 2021: new data content and improved web interfaces. Sunghwan Kim, Jie Chen, Tiejun Cheng, Asta Gindulyte, Jia He, Siqian He, Qingliang Li, Benjamin A Shoemaker, Paul A Thiessen, Bo Yu, Leonid Zaslavsky, Jian Zhang, Evan Bolton, 10.1093/nar/gkaa971Nucleic Acids Res. 492021</p>
<p>The CHEMDNER corpus of chemicals and drugs and its annotation principles. Martin Krallinger, Obdulia Rabal, Florian Leitner, Miguel Vazquez, David Salgado, Zhiyong Lu, Robert Leaman, Yanan Lu, Donghong Ji, Daniel M Lowe, Roger A Sayle, Theresa Riza, Rafal Batista-Navarro, Torsten Rak, Tim Huber, Sérgio Rocktäschel, David Matos, Buzhou Campos, Hua Tang, Tsendsuren Xu, Keun Munkhdalai, S V Ho Ryu, P Ramanan, Slavko Senthil Nathan, Marko Zitnik, Lutz Bajec, Matthias Weber, Irmer, A Saber, Jan A Akhondi, Shuo Kors, Xin Xu, Utpal An, Asif Kumar Sikdar, Masaharu Ekbal, Yoshioka, M Thaer, Miji Dieb, Karin Choi, Madian Verspoor, C Lee Khabsa, Hongfang Giles, Ravikumar Liu, Andre Komandur Elayavilli, Francisco M Lamurias, Hong-Jie Couto, Dai, 10.1186/1758-2946-7-S1-S2J. Cheminformatics. Richard Tzong-Han Tsai, Caglar Ata, Tolga Can, Anabel Usie, Rui Alves, Isabel Segura-Bedmar, Paloma Martínez, Julen Oyarzabal, and Alfonso Valencia7S-12015</p>
<p>Marleen Rodenburg, Astrid Laegreid, Marius A. Doornenbal, Julen Oyarzábal, Anália Lourenc ¸o, and Alfonso Valencia. Overview of the biocreative vi chemical-protein interaction track. Martin Krallinger, Obdulia Rabal, Ahmad Saber, Martín Akhondi, Jesus Pérez Pérez, Gael Pérez Santamaría, Georgios Rodríguez, Ander Tsatsaronis, José Intxaurrondo, Antonio Baso, Umesh K López, Erin M Nandal, Ambika Van Buel, Chandrasekhar, 2017</p>
<p>Mario Krenn, Qianxiang Ai, Senja Barthel, Nessa Carson, Angelo Frei, Nathan C Frey, Pascal Friederich, Théophile Gaudin, Alberto Alexander Gayle, Kevin Maik Jablonka, Rafael F Lameiro, Dominik Lemm, Alston Lo, Mohamad Seyed, José Moosavi, Akshatkumar Manuel Nápoles-Duarte, Robert Nigam, Kohulan Pollice, Ulrich Rajan, Philippe Schatzschneider, Marta Schwaller, Berend Skreta, Felix Smit, Chong Strieth-Kalthoff, Gary Sun, Guido Tom, Andrew Falk Von Rudorff, Andrew D Wang, Adamo White, Young, 10.1016/j.patter.2022.100588Rose Yu, and Alán Aspuru-Guzik. SELFIES and the future of molecular string representations. 32022</p>
<p>Rdkit: A software suite for cheminformatics, computational chemistry, and predictive modeling. Greg Landrum, Greg Landrum. 8312013</p>
<p>Biocreative V CDR task corpus: a resource for chemical disease relation extraction. Jiao Li, Yueping Sun, Robin J Johnson, Daniela Sciaky, Chih-Hsuan Wei, Robert Leaman, Allan Peter Davis, Carolyn J Mattingly, Thomas C Wiegers, Zhiyong Lu, 10.1093/database/baw068Database J. Biol. Databases Curation. 2016. 2016</p>
<p>A normalized levenshtein distance metric. Yujian Li, Bi Liu, 10.1109/TPAMI.2007.1078IEEE Trans. Pattern Anal. Mach. Intell. 2962007</p>
<p>Rouge: A package for automatic evaluation of summaries. Chin-Yew Lin, Text summarization branches out. 2004</p>
<p>Language models of protein sequences at the scale of evolution enable accurate structure prediction. Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Allan Dos, Santos Costa, Maryam Fazel-Zarandi, Tom Sercu, Sal Candido, BioRxiv. 2022</p>
<p>Multi-modal molecule structure-text model for text-based retrieval and editing. Shengchao Liu, Weili Nie, Chengpeng Wang, Jiarui Lu, Zhuoran Qiao, Ling Liu, Jian Tang, Chaowei Xiao, Animashree Anandkumar, 10.1038/s42256-023-00759-6Nat. Mac. Intell. 5122023</p>
<p>Unified deep learning model for multitask reaction predictions with explanation. Jieyu Lu, Yingkai Zhang, 10.1021/acs.jcim.1c01467J. Chem. Inf. Model. 6262022</p>
<p>Cayque Monteiro Castro Nascimento and André Silva Pimentel. Do large language models understand chemistry? A conversation with chatgpt. Ali Madani, Ben Krause, Eric R Greene, Subu Subramanian, Benjamin P Mohr, James M Holton, Jose Luis OlmosJr, Caiming Xiong, Zachary Z Sun, Richard Socher, 10.1021/acs.jcim.3c00285Nature Biotechnology. 6362023. 2023J. Chem. Inf. Model.</p>
<p>10.48550/arXiv.2303.08774GPT-4 technical report. 2023aOpenAI</p>
<p>Training language models to follow instructions with human feedback. Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll L Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F Christiano, Jan Leike, Ryan Lowe, Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems. S Sanmi Koyejo, A Mohamed, Danielle Agarwal, K Belgrave, A Cho, Oh, NeurIPS; New Orleans, LA, USA2022. 2022. November 28 -December 9, 2022. 2022a</p>
<p>Training language models to follow instructions with human feedback. Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll L Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F Christiano, Jan Leike, Ryan Lowe, Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems. S Sanmi Koyejo, A Mohamed, Danielle Agarwal, K Belgrave, A Cho, Oh, NeurIPS; New Orleans, LA, USA2022. 2022. November 28 -December 9, 2022. 2022b</p>
<p>Medmcqa: A large-scale multi-subject multi-choice dataset for medical domain question answering. Ankit Pal, Logesh Kumar Umapathi, Malaikannan Sankarasubbu, Conference on Health, Inference, and Learning, CHIL 2022. Gerardo Flores, George H Chen, Tom J Pollard, Joyce C Ho, Tristan Naumann, PMLR7-8 April 2022. 2022174of Proceedings of Machine Learning Research</p>
<p>Bleu: a method for automatic evaluation of machine translation. Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu, 10.3115/1073083.1073135Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics. the 40th Annual Meeting of the Association for Computational LinguisticsPhiladelphia, PA, USAJuly 6-12, 2002. 2002</p>
<p>Biot5+: Towards generalized biological understanding with iupac integration and multi-task tuning. Qizhi Pei, Lijun Wu, Kaiyuan Gao, Xiaozhuan Liang, Yin Fang, Jinhua Zhu, Shufang Xie, Tao Qin, Rui Yan, arXiv:2402.178102024arXiv preprint</p>
<p>Tool learning with foundation models. Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding, Ganqu Cui, Zheni Zeng, Yufei Huang, Chaojun Xiao, Chi Han, Yi Ren Fung, Yusheng Su, Huadong Wang, Cheng Qian, Runchu Tian, Kunlun Zhu, Shihao Liang, Xingyu Shen, Bokai Xu, Zhen Zhang, Yining Ye, Bowen Li, Ziwei Tang, Jing Yi, Yuzhang Zhu, Zhenning Dai, Lan Yan, Xin Cong, Yaxi Lu, Weilin Zhao, Yuxiang Huang, Junxi Yan, Xu Han, Xian Sun, Dahai Li, Jason Phang, Cheng Yang, Tongshuang Wu, Heng Ji, Zhiyuan Liu, Maosong Sun, 10.48550/arXiv.2304.08354CoRR2023</p>
<p>Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences. Alexander Rives, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason Liu, Demi Guo, Myle Ott, C Lawrence Zitnick, Jerry Ma, Rob Fergus, 10.1073/pnas.2016239118Proc. Natl. Acad. Sci. USA. Natl. Acad. Sci. USA1182021</p>
<p>Artificial intelligence and biological misuse: Differentiating risks of language models and biological design tools. Jonas B Sandbrink, 10.48550/arXiv.2306.139522023</p>
<p>Multitask prompted training enables zero-shot task generalization. Victor Sanh, Albert Webson, Colin Raffel, Stephen H Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, Canwen Saiful Bari, Urmish Xu, Shanya Thakker, Eliza Sharma Sharma, Taewoon Szczechla, Gunjan Kim, Chhablani, V Nihal, Debajyoti Nayak, Jonathan Datta, Mike Chang, Tian-Jian, Han Jiang, Matteo Wang, Sheng Manica, Zheng Xin Shen, Harshit Yong, Rachel Pandey, Thomas Bawden, Trishala Wang, Jos Neeraj, Abheesht Rozen, Andrea Sharma, Thibault Santilli, Jason Févry, Alan Fries, Ryan Teehan, Teven Le Scao, Stella Biderman, Leo Gao, Thomas Wolf, Alexander M Rush, The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event. April 25-29, 2022. 2022OpenReview.net</p>
<p>Get your atoms in order -an opensource implementation of a novel and robust molecular canonicalization algorithm. Nadine Schneider, Roger A Sayle, Gregory A Landrum, 10.1021/acs.jcim.5b00543J. Chem. Inf. Model. 55102015</p>
<p>Could chatbots help devise the next pandemic virus?. Robert F Service, Science. 380665112112023</p>
<p>Mmseqs2 enables sensitive protein sequence searching for the analysis of massive data sets. Martin Steinegger, Johannes Söding, Nature biotechnology. 35112017</p>
<p>A molecular multimodal foundation model associating molecule graphs with natural language. Bing Su, Dazhao Du, Zhao Yang, Yujie Zhou, Jiangmeng Li, Anyi Rao, Hao Sun, Zhiwu Lu, Ji-Rong Wen, 10.48550/arXiv.2209.054812022</p>
<p>Elementary mathematical theory of classification and prediction. T Taffee, Tanimoto, 1958</p>
<p>Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, Tatsunori B Hashimoto, Stanford alpaca: An instruction-following llama model. GitHub repository. 2023</p>
<p>Galactica: A large language model for science. Ross Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony Hartshorn, Elvis Saravia, Andrew Poulton, Viktor Kerkez, Robert Stojnic, 10.48550/arXiv.2211.090852022</p>
<p>Fine-tuning large neural language models for biomedical natural language processing. Robert Tinn, Hao Cheng, Yu Gu, Naoto Usuyama, Xiaodong Liu, Tristan Naumann, Jianfeng Gao, Hoifung Poon, 10.1016/j.patter.2023.100729Patterns. 442023</p>
<p>. Tloen, Alpaca-Lora, 2023</p>
<p>Llama: Open and efficient foundation language models. Thibaut Hugo Touvron, Gautier Lavril, Xavier Izacard, Marie-Anne Martinet, Timothée Lachaux, Baptiste Lacroix, Naman Rozière, Eric Goyal, Faisal Hambro, Aurélien Azhar, Armand Rodriguez, Edouard Joulin, Guillaume Grave, Lample, 10.48550/arXiv.2302.139712023</p>
<p>Scientific discovery in the age of artificial intelligence. Hanchen Wang, Tianfan Fu, Yuanqi Du, Wenhao Gao, Kexin Huang, Ziming Liu, Payal Chandak, Shengchao Liu, Peter Van Katwyk, Andreea Deac, Anima Anandkumar, Karianne Bergen, Carla P Gomes, Shirley Ho, Pushmeet Kohli, Joan Lasenby, Jure Leskovec, Tie-Yan Liu, Arjun Manrai, Debora S Marks, Bharath Ramsundar, Le Song, Jimeng Sun, Jian Tang, Petar Velickovic, Max Welling, Linfeng Zhang, Connor W Coley, Yoshua Bengio, Marinka Zitnik, 10.1038/s41586-023-06221-2Nat. 62079722023a</p>
<p>Self-instruct: Aligning language models with self-generated instructions. Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, Hannaneh Hajishirzi, 10.18653/v1/2023.acl-long.754Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics. Long Papers. Anna Rogers, Jordan L Boyd-Graber, Naoaki Okazaki, the 61st Annual Meeting of the Association for Computational LinguisticsToronto, CanadaAssociation for Computational LinguisticsJuly 9-14, 2023. 2023b1ACL 2023</p>
<p>Finetuned language models are zero-shot learners. Jason Wei, Maarten Bosma, Y Vincent, Kelvin Zhao, Adams Wei Guu, Brian Yu, Nan Lester, Andrew M Du, Dai, V Quoc, Le, The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event. April 25-29, 2022. 2022OpenReview.net</p>
<p>A novel measure for evaluating classifiers. Jin-Mao Wei, Xiao-Jie Yuan, Qinghua Hu, Shu-Qin Wang, 10.1016/j.eswa.2009.11.040Expert Syst. Appl. 3752010</p>
<p>Smiles, a chemical language and information system. 1. introduction to methodology and encoding rules. David Weininger, 10.1021/ci00057a005J. Chem. Inf. Comput. Sci. 2811988</p>
<p>Pubmed 2.0. Medical reference services quarterly. Jacob White, 202039</p>
<p>Pmc-llama: Further finetuning llama on medical papers. Chaoyi Wu, Xiaoman Zhang, Ya Zhang, Yanfeng Wang, Weidi Xie, 10.48550/arXiv.2304.144542023</p>
<p>Moleculenet: a benchmark for molecular machine learning. Zhenqin Wu, Bharath Ramsundar, Evan N Feinberg, Joseph Gomes, Caleb Geniesse, S Aneesh, Karl Pappu, Vijay Leswing, Pande, Chemical science. 922018</p>
<p>Baize: An open-source chat model with parameter-efficient tuning on self-chat data. Canwen Xu, Daya Guo, Nan Duan, Julian J Mcauley, Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023. Houda Bouamor, Juan Pino, Kalika Bali, the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023SingaporeAssociation for Computational LinguisticsDecember 6-10, 2023. 2023</p>
<p>GLM-130B: an open bilingual pre-trained model. Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, Weng Lam Tam, Zixuan Ma, Yufei Xue, Jidong Zhai, Wenguang Chen, Zhiyuan Liu, Peng Zhang, Yuxiao Dong, Jie Tang, The Eleventh International Conference on Learning Representations, ICLR 2023. Kigali, RwandaMay 1-5, 2023. OpenReview.net, 2023</p>
<p>A deep-learning system bridging molecule structure and biomedical text with comprehension comparable to human professionals. Zheni Zeng, Yuan Yao, Zhiyuan Liu, Maosong Sun, Nature communications. 1318622022</p>
<p>Chinese open instruction generalist: A preliminary release. Ge Zhang, Yemin Shi, Ruibo Liu, Ruibin Yuan, Yizhi Li, Siwei Dong, Yu Shu, Zhaoqun Li, Zekun Wang, Chenghua Lin, Wenhao Huang, Jie Fu, 10.48550/arXiv.2304.079872023a</p>
<p>The future of molecular studies through the lens of large language models. Jinlu Zhang, Yin Fang, Xin Shao, Huajun Chen, Ningyu Zhang, Xiaohui Fan, 10.1021/acs.jcim.3c01977J. Chem. Inf. Model. 6432024</p>
<p>Moleculegpt: Instruction following large language models for molecular property prediction. Weitong Zhang, Xiaoyun Wang, Weili Nie, Joe Eaton, Brad Rees, Quanquan Gu, NeurIPS 2023 Workshop on New Frontiers of AI for Drug Discovery and Development. 2023b</p>            </div>
        </div>

    </div>
</body>
</html>