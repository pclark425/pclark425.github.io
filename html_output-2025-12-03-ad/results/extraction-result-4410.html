<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4410 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4410</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4410</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-101.html">extraction-schema-101</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, criteria, metrics, or frameworks for evaluating LLM-generated scientific theories, hypotheses, or explanations, including comparisons with human-generated theories.</div>
                <p><strong>Paper ID:</strong> paper-278782862</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2505.15747v2.pdf" target="_blank">Multi-modal Integration Analysis of Alzheimer's Disease Using Large Language Models and Knowledge Graphs</a></p>
                <p><strong>Paper Abstract:</strong> We propose a novel framework for integrating fragmented multi-modal data in Alzheimer's disease (AD) research using large language models (LLMs) and knowledge graphs. While traditional multimodal analysis requires matched patient IDs across datasets, our approach demonstrates population-level integration of MRI, gene expression, biomarkers, EEG, and clinical indicators from independent cohorts. Statistical analysis identified significant features in each modality, which were connected as nodes in a knowledge graph. LLMs then analyzed the graph to extract potential correlations and generate hypotheses in natural language. This approach revealed several novel relationships, including a potential pathway linking metabolic risk factors to tau protein abnormalities via neuroinflammation (r>0.6, p<0.001), and unexpected correlations between frontal EEG channels and specific gene expression profiles (r=0.42-0.58, p<0.01). Cross-validation with independent datasets confirmed the robustness of major findings, with consistent effect sizes across cohorts (variance<15%). The reproducibility of these findings was further supported by expert review (Cohen's k=0.82) and computational validation. Our framework enables cross modal integration at a conceptual level without requiring patient ID matching, offering new possibilities for understanding AD pathology through fragmented data reuse and generating testable hypotheses for future research.</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e4410.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e4410.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, criteria, metrics, or frameworks for evaluating LLM-generated scientific theories, hypotheses, or explanations, including comparisons with human-generated theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hypothesis Quality Scoring System</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hypothesis Quality Scoring System (Biological Plausibility / Literature Support / Testability)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 3-criterion, 1–5 Likert-style rubric used to rate LLM-generated hypotheses on biological plausibility, literature support, and empirical testability; applied to LLM outputs and used to prioritize hypotheses for expert review and downstream validation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_name</strong></td>
                            <td>Hypothesis Quality Scoring System</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_description</strong></td>
                            <td>Each LLM-generated hypothesis is rated on three explicit criteria — biological plausibility, literature support, and testability — using a 1–5 scale with detailed rubrics to standardize scoring. Two domain experts initially scored each hypothesis independently; scores were recorded and disagreements resolved by discussion. Scores were averaged to produce an overall quality profile per hypothesis and used to rank and select high-priority hypotheses for further validation.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_criteria</strong></td>
                            <td>Biological plausibility; Literature support (consistency with existing publications); Testability (whether a hypothesis yields clear, measurable experimental predictions).</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT 4o; Claude 3.5 Sonnet; Gemini 2.0 Flash</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Biomedical research (Alzheimer's disease)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>Mechanistic explanations / causal hypotheses</td>
                        </tr>
                        <tr>
                            <td><strong>human_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_results</strong></td>
                            <td>Applied to the set of LLM-generated hypotheses; the highest-rated hypothesis (metabolic → inflammation → tau) had mean impact/quality score 4.2/5. Experts later agreed strongly with plausibility ratings (expert-panel plausibility mean 4.3/5 for the top pathway). The rubric enabled differentiation among hypotheses (scores reported per-hypothesis in Table 4).</td>
                        </tr>
                        <tr>
                            <td><strong>automated_vs_human_evaluation</strong></td>
                            <td>Human-based scoring (domain experts) guided by a standardized rubric; outputs from LLMs were scored by humans rather than via fully automated metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Inter-expert scoring with consensus discussion; comparison of rubric scores with later expert-panel ratings and cross-validation outcomes (consistency between high rubric scores and reproducible findings across datasets was used as indirect validation).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Subjectivity remains despite rubrics; initial ratings used only two experts (later expanded), risking bias; rubric reliability depends on expert training and calibration; rubric does not directly assess causal validity (only plausibility/testability).</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>No standardized external benchmark; applied to hypotheses generated from the study's knowledge graph built from five modalities (MRI, EEG, biomarkers, clinical, gene expression) and validated against three independent validation cohorts.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Multi-modal Integration Analysis of Alzheimer's Disease Using Large Language Models and Knowledge Graphs", 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4410.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e4410.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, criteria, metrics, or frameworks for evaluating LLM-generated scientific theories, hypotheses, or explanations, including comparisons with human-generated theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM Consensus Scoring Framework</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Multi-model Consensus Scoring Framework for LLM Hypotheses</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework that compares independent outputs from multiple LLMs to derive a consensus score for each hypothesis, weighting agreement on mechanistic details more heavily than general observations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_name</strong></td>
                            <td>LLM Consensus Scoring Framework</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_description</strong></td>
                            <td>Each of the three LLMs (ChatGPT 4o, Claude 3.5 Sonnet, Gemini 2.0 Flash) analyzed the same knowledge graph independently. Hypotheses produced by each model were collated and aligned; a consensus score was computed from the degree of agreement across models (categorical and semantic matching), with increased weight for agreement on specific mechanistic details versus broad statements. This consensus measure was used to identify high-confidence model-derived hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_criteria</strong></td>
                            <td>Model agreement (presence/absence of same hypothesis); specificity/agreement on mechanistic details; literature consistency as cross-checked by each model's output.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT 4o; Claude 3.5 Sonnet; Gemini 2.0 Flash</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Biomedical research (Alzheimer's disease)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>Mechanistic explanations / integrative hypotheses</td>
                        </tr>
                        <tr>
                            <td><strong>human_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_results</strong></td>
                            <td>Overall model consensus rate reported as 78% for primary findings. ChatGPT produced more novel hypotheses (17) than Claude (12) and Gemini (11); Claude's output had higher literature consistency (87% of proposed relationships had some literature support). Consensus scoring highlighted the metabolic-inflammatory-tau pathway as high-consensus.</td>
                        </tr>
                        <tr>
                            <td><strong>automated_vs_human_evaluation</strong></td>
                            <td>Automated aggregation and scoring of model outputs (semantic matching) followed by human inspection; hybrid approach.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Comparison of consensus hypotheses against systematic literature review, expert panel ratings, and reproducibility in independent datasets; higher consensus hypotheses had greater subsequent validation (e.g., metabolic-inflammatory-tau pathway reproduced with variance <15%).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Semantic alignment of model outputs is non-trivial and may miss paraphrased or partial agreements; consensus can reinforce shared model biases; weighting choice (mechanistic detail vs general) is subjective and affects results.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>No external benchmark for LLM consensus; applied to the study's internal knowledge graph outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Multi-modal Integration Analysis of Alzheimer's Disease Using Large Language Models and Knowledge Graphs", 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4410.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e4410.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, criteria, metrics, or frameworks for evaluating LLM-generated scientific theories, hypotheses, or explanations, including comparisons with human-generated theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Expert Panel Review with Concordance Metrics</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Structured Expert Panel Review with Inter-rater Concordance (Cohen's κ)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A human-evaluation layer in which a multidisciplinary panel of domain experts rated LLM-generated hypotheses on validity, novelty, and clinical impact, and inter-rater agreement was quantified using Cohen's kappa.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_name</strong></td>
                            <td>Expert Panel Review with Concordance Metrics</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_description</strong></td>
                            <td>A panel of three domain experts (neurology, biomedical informatics, AD research) independently rated each hypothesis on scientific validity, novelty, and clinical impact. Concordance between raters was measured using Cohen's kappa to quantify reliability of the human evaluations; disagreements were then resolved through discussion to produce consensus ratings.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_criteria</strong></td>
                            <td>Scientific validity; Novelty; Potential clinical impact.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT 4o; Claude 3.5 Sonnet; Gemini 2.0 Flash</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Biomedical research (Alzheimer's disease)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>Mechanistic explanations / clinical impact hypotheses</td>
                        </tr>
                        <tr>
                            <td><strong>human_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_results</strong></td>
                            <td>Expert panel review produced strong agreement: Cohen's κ = 0.82 reported for LLM-generated hypotheses overall. The metabolic-inflammatory-tau pathway received high plausibility mean score 4.3/5. Expert panel helped confirm reproducibility and biological plausibility of top hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>automated_vs_human_evaluation</strong></td>
                            <td>Human-based evaluation with quantified inter-rater reliability; integrated with automated literature mining for additional evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Inter-rater reliability statistics (Cohen's kappa) and consistency of expert judgments with automated literature evidence and cross-validation results.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Expert judgments can be subjective and influenced by prior beliefs; small expert panel size may limit representativeness; potential for groupthink in consensus discussions.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>No external benchmark; experts evaluated hypotheses derived from the study's knowledge graph and LLM outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Multi-modal Integration Analysis of Alzheimer's Disease Using Large Language Models and Knowledge Graphs", 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4410.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e4410.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, criteria, metrics, or frameworks for evaluating LLM-generated scientific theories, hypotheses, or explanations, including comparisons with human-generated theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Automated Novelty Scoring</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Automated Literature-based Novelty Score (PubMed Count & Recency)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An automated metric that quantifies novelty of each proposed relationship by mining PubMed for prior publications matching the relationship and weighting by count and recency to produce a 'novelty score'.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_name</strong></td>
                            <td>Automated Novelty Scoring</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_description</strong></td>
                            <td>For every proposed relationship/hypothesis, structured queries combining key terms were executed against PubMed and other databases. The novelty score was computed from the number of matching publications, their recency, and degree of direct relevance; fewer and/or more recent matches yield higher novelty. This score was used alongside expert review to classify hypotheses as novel, partially supported, or previously described.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_criteria</strong></td>
                            <td>Number of matching publications; recency of matches; directness of evidence (direct mechanistic vs peripheral mention).</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT 4o; Claude 3.5 Sonnet; Gemini 2.0 Flash</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Biomedical research (Alzheimer's disease)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>Mechanistic explanations / proposed relationships</td>
                        </tr>
                        <tr>
                            <td><strong>human_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_results</strong></td>
                            <td>Systematic literature review indicated ~73% of proposed relationships were novel under this definition; EEG-gene relationships were almost entirely novel (only ~8% had prior mention). Novelty scores were used to prioritize follow-up.</td>
                        </tr>
                        <tr>
                            <td><strong>automated_vs_human_evaluation</strong></td>
                            <td>Automated literature-mining metric used in combination with human manual review (hybrid).</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Manual spot-checks by experts against automated search results and cross-referencing with domain knowledge; novelty designations compared to expert panel judgments.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Search-query design, term ambiguity, and database indexing limit sensitivity; possibility of false negatives (missed prior work) and false positives (superficial matches counted as support).</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Uses PubMed and similar literature databases; no labeled novelty benchmark was used.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Multi-modal Integration Analysis of Alzheimer's Disease Using Large Language Models and Knowledge Graphs", 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4410.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e4410.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, criteria, metrics, or frameworks for evaluating LLM-generated scientific theories, hypotheses, or explanations, including comparisons with human-generated theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Permutation-based Graph Validation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Permutation Testing for Knowledge Graph Structural Validation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A computational validation method that uses permutation testing to compare observed knowledge graph metrics against distributions from randomly generated graphs to assess non-randomness of identified cross-modal structures.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_name</strong></td>
                            <td>Permutation-based Graph Validation</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_description</strong></td>
                            <td>The observed knowledge graph metrics (clustering coefficient, path length, modularity, community structure) were compared to distributions generated by permuting node or edge assignments across 10,000 random graphs. Empirical p-values were computed to test whether the observed graph organization differs from chance.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_criteria</strong></td>
                            <td>Graph-level statistics: clustering coefficient, average path length, modularity, centrality distributions, community structure; empirical p-values from permutation distributions.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Biomedical network analysis (Alzheimer's disease multimodal integration)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>Structural validation of hypothesized relationships (network-level)</td>
                        </tr>
                        <tr>
                            <td><strong>human_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_results</strong></td>
                            <td>Permutation testing over 10,000 permutations produced p < 0.001 for graph structural measures, indicating the observed network organization was highly unlikely under random graphs; clustering coefficient, path length, and modularity significantly deviated from null distributions.</td>
                        </tr>
                        <tr>
                            <td><strong>automated_vs_human_evaluation</strong></td>
                            <td>Automated computational validation (statistical testing) independent of human raters.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Empirical null distributions from 10,000 random permutations; significance testing of observed metrics against these distributions.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Permutation tests assess non-randomness but do not validate causal correctness of edges; results depend on the null-generating procedure (how graphs are randomized) and thresholds used to create edges (e.g., |r|>0.3).</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>No external benchmark; validation performed against internally-generated randomized graphs derived from the study's knowledge graph.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Multi-modal Integration Analysis of Alzheimer's Disease Using Large Language Models and Knowledge Graphs", 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4410.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e4410.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, criteria, metrics, or frameworks for evaluating LLM-generated scientific theories, hypotheses, or explanations, including comparisons with human-generated theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Cross-dataset Reproducibility Framework</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Cross-validation with Independent Datasets and Reproducibility Metrics</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework that tests reproducibility of LLM-identified hypotheses by applying the same analysis to independent validation cohorts and quantifying consistency via effect-size variance and replication of statistical significance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_name</strong></td>
                            <td>Cross-dataset Reproducibility Framework</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_description</strong></td>
                            <td>Key relationships and hypotheses were tested in three additional independent datasets across modalities; metrics compared included correlation coefficients, effect sizes, p-values, variance of effect sizes across cohorts, and coefficient of variation for specific correlations. Replication required consistent effect direction and statistical significance (typically p<0.05) across validation cohorts.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_criteria</strong></td>
                            <td>Consistency of effect sizes (variance < threshold), statistical significance replication (p<0.05), coefficient of variation for key correlations, and reproducibility of central graph features.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT 4o; Claude 3.5 Sonnet; Gemini 2.0 Flash</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Biomedical research (Alzheimer's disease)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>Empirical reproducibility of proposed mechanistic relationships</td>
                        </tr>
                        <tr>
                            <td><strong>human_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_results</strong></td>
                            <td>The metabolic-inflammatory-tau pathway was replicated across three independent cohorts with effect-size variance <15% and mean correlations (e.g., inflammatory→tau mean r≈0.61). EEG-gene correlations were replicated but showed higher variability (coefficient of variation 23–31%); Fp1 alpha vs GSM701343 mean r≈0.46 across validations.</td>
                        </tr>
                        <tr>
                            <td><strong>automated_vs_human_evaluation</strong></td>
                            <td>Automated statistical replication tests augmented by human interpretation of biological plausibility (hybrid).</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Reapplication of the same statistical analyses to independent datasets and comparison of effect sizes and p-values; consistent replication considered supporting evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Validation limited by availability and size of independent datasets (some smaller); population-level integration cannot establish causality; heterogeneity across cohorts (protocols, preprocessing) can confound replication.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Three smaller independent validation cohorts from similar modalities used internally; no public benchmark dataset specifically for LLM-hypothesis evaluation was used.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Multi-modal Integration Analysis of Alzheimer's Disease Using Large Language Models and Knowledge Graphs", 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Unifying large language models and knowledge graphs: A roadmap <em>(Rating: 2)</em></li>
                <li>A survey of knowledge graph reasoning on graph types: Static, dynamic, and multi-modal <em>(Rating: 2)</em></li>
                <li>The ethics of ChatGPT in medicine and healthcare: a systematic review on Large Language Models (LLMs) <em>(Rating: 1)</em></li>
                <li>Multimodal foundation models: From specialists to general-purpose assistants <em>(Rating: 1)</em></li>
                <li>Privacy-preserving artificial intelligence in healthcare: Techniques and applications <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4410",
    "paper_id": "paper-278782862",
    "extraction_schema_id": "extraction-schema-101",
    "extracted_data": [
        {
            "name_short": "Hypothesis Quality Scoring System",
            "name_full": "Hypothesis Quality Scoring System (Biological Plausibility / Literature Support / Testability)",
            "brief_description": "A 3-criterion, 1–5 Likert-style rubric used to rate LLM-generated hypotheses on biological plausibility, literature support, and empirical testability; applied to LLM outputs and used to prioritize hypotheses for expert review and downstream validation.",
            "citation_title": "here",
            "mention_or_use": "use",
            "evaluation_method_name": "Hypothesis Quality Scoring System",
            "evaluation_method_description": "Each LLM-generated hypothesis is rated on three explicit criteria — biological plausibility, literature support, and testability — using a 1–5 scale with detailed rubrics to standardize scoring. Two domain experts initially scored each hypothesis independently; scores were recorded and disagreements resolved by discussion. Scores were averaged to produce an overall quality profile per hypothesis and used to rank and select high-priority hypotheses for further validation.",
            "evaluation_criteria": "Biological plausibility; Literature support (consistency with existing publications); Testability (whether a hypothesis yields clear, measurable experimental predictions).",
            "model_name": "ChatGPT 4o; Claude 3.5 Sonnet; Gemini 2.0 Flash",
            "model_size": null,
            "scientific_domain": "Biomedical research (Alzheimer's disease)",
            "theory_type": "Mechanistic explanations / causal hypotheses",
            "human_comparison": false,
            "evaluation_results": "Applied to the set of LLM-generated hypotheses; the highest-rated hypothesis (metabolic → inflammation → tau) had mean impact/quality score 4.2/5. Experts later agreed strongly with plausibility ratings (expert-panel plausibility mean 4.3/5 for the top pathway). The rubric enabled differentiation among hypotheses (scores reported per-hypothesis in Table 4).",
            "automated_vs_human_evaluation": "Human-based scoring (domain experts) guided by a standardized rubric; outputs from LLMs were scored by humans rather than via fully automated metrics.",
            "validation_method": "Inter-expert scoring with consensus discussion; comparison of rubric scores with later expert-panel ratings and cross-validation outcomes (consistency between high rubric scores and reproducible findings across datasets was used as indirect validation).",
            "limitations_challenges": "Subjectivity remains despite rubrics; initial ratings used only two experts (later expanded), risking bias; rubric reliability depends on expert training and calibration; rubric does not directly assess causal validity (only plausibility/testability).",
            "benchmark_dataset": "No standardized external benchmark; applied to hypotheses generated from the study's knowledge graph built from five modalities (MRI, EEG, biomarkers, clinical, gene expression) and validated against three independent validation cohorts.",
            "uuid": "e4410.0",
            "source_info": {
                "paper_title": "Multi-modal Integration Analysis of Alzheimer's Disease Using Large Language Models and Knowledge Graphs",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "LLM Consensus Scoring Framework",
            "name_full": "Multi-model Consensus Scoring Framework for LLM Hypotheses",
            "brief_description": "A framework that compares independent outputs from multiple LLMs to derive a consensus score for each hypothesis, weighting agreement on mechanistic details more heavily than general observations.",
            "citation_title": "here",
            "mention_or_use": "use",
            "evaluation_method_name": "LLM Consensus Scoring Framework",
            "evaluation_method_description": "Each of the three LLMs (ChatGPT 4o, Claude 3.5 Sonnet, Gemini 2.0 Flash) analyzed the same knowledge graph independently. Hypotheses produced by each model were collated and aligned; a consensus score was computed from the degree of agreement across models (categorical and semantic matching), with increased weight for agreement on specific mechanistic details versus broad statements. This consensus measure was used to identify high-confidence model-derived hypotheses.",
            "evaluation_criteria": "Model agreement (presence/absence of same hypothesis); specificity/agreement on mechanistic details; literature consistency as cross-checked by each model's output.",
            "model_name": "ChatGPT 4o; Claude 3.5 Sonnet; Gemini 2.0 Flash",
            "model_size": null,
            "scientific_domain": "Biomedical research (Alzheimer's disease)",
            "theory_type": "Mechanistic explanations / integrative hypotheses",
            "human_comparison": false,
            "evaluation_results": "Overall model consensus rate reported as 78% for primary findings. ChatGPT produced more novel hypotheses (17) than Claude (12) and Gemini (11); Claude's output had higher literature consistency (87% of proposed relationships had some literature support). Consensus scoring highlighted the metabolic-inflammatory-tau pathway as high-consensus.",
            "automated_vs_human_evaluation": "Automated aggregation and scoring of model outputs (semantic matching) followed by human inspection; hybrid approach.",
            "validation_method": "Comparison of consensus hypotheses against systematic literature review, expert panel ratings, and reproducibility in independent datasets; higher consensus hypotheses had greater subsequent validation (e.g., metabolic-inflammatory-tau pathway reproduced with variance &lt;15%).",
            "limitations_challenges": "Semantic alignment of model outputs is non-trivial and may miss paraphrased or partial agreements; consensus can reinforce shared model biases; weighting choice (mechanistic detail vs general) is subjective and affects results.",
            "benchmark_dataset": "No external benchmark for LLM consensus; applied to the study's internal knowledge graph outputs.",
            "uuid": "e4410.1",
            "source_info": {
                "paper_title": "Multi-modal Integration Analysis of Alzheimer's Disease Using Large Language Models and Knowledge Graphs",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "Expert Panel Review with Concordance Metrics",
            "name_full": "Structured Expert Panel Review with Inter-rater Concordance (Cohen's κ)",
            "brief_description": "A human-evaluation layer in which a multidisciplinary panel of domain experts rated LLM-generated hypotheses on validity, novelty, and clinical impact, and inter-rater agreement was quantified using Cohen's kappa.",
            "citation_title": "here",
            "mention_or_use": "use",
            "evaluation_method_name": "Expert Panel Review with Concordance Metrics",
            "evaluation_method_description": "A panel of three domain experts (neurology, biomedical informatics, AD research) independently rated each hypothesis on scientific validity, novelty, and clinical impact. Concordance between raters was measured using Cohen's kappa to quantify reliability of the human evaluations; disagreements were then resolved through discussion to produce consensus ratings.",
            "evaluation_criteria": "Scientific validity; Novelty; Potential clinical impact.",
            "model_name": "ChatGPT 4o; Claude 3.5 Sonnet; Gemini 2.0 Flash",
            "model_size": null,
            "scientific_domain": "Biomedical research (Alzheimer's disease)",
            "theory_type": "Mechanistic explanations / clinical impact hypotheses",
            "human_comparison": false,
            "evaluation_results": "Expert panel review produced strong agreement: Cohen's κ = 0.82 reported for LLM-generated hypotheses overall. The metabolic-inflammatory-tau pathway received high plausibility mean score 4.3/5. Expert panel helped confirm reproducibility and biological plausibility of top hypotheses.",
            "automated_vs_human_evaluation": "Human-based evaluation with quantified inter-rater reliability; integrated with automated literature mining for additional evidence.",
            "validation_method": "Inter-rater reliability statistics (Cohen's kappa) and consistency of expert judgments with automated literature evidence and cross-validation results.",
            "limitations_challenges": "Expert judgments can be subjective and influenced by prior beliefs; small expert panel size may limit representativeness; potential for groupthink in consensus discussions.",
            "benchmark_dataset": "No external benchmark; experts evaluated hypotheses derived from the study's knowledge graph and LLM outputs.",
            "uuid": "e4410.2",
            "source_info": {
                "paper_title": "Multi-modal Integration Analysis of Alzheimer's Disease Using Large Language Models and Knowledge Graphs",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "Automated Novelty Scoring",
            "name_full": "Automated Literature-based Novelty Score (PubMed Count & Recency)",
            "brief_description": "An automated metric that quantifies novelty of each proposed relationship by mining PubMed for prior publications matching the relationship and weighting by count and recency to produce a 'novelty score'.",
            "citation_title": "here",
            "mention_or_use": "use",
            "evaluation_method_name": "Automated Novelty Scoring",
            "evaluation_method_description": "For every proposed relationship/hypothesis, structured queries combining key terms were executed against PubMed and other databases. The novelty score was computed from the number of matching publications, their recency, and degree of direct relevance; fewer and/or more recent matches yield higher novelty. This score was used alongside expert review to classify hypotheses as novel, partially supported, or previously described.",
            "evaluation_criteria": "Number of matching publications; recency of matches; directness of evidence (direct mechanistic vs peripheral mention).",
            "model_name": "ChatGPT 4o; Claude 3.5 Sonnet; Gemini 2.0 Flash",
            "model_size": null,
            "scientific_domain": "Biomedical research (Alzheimer's disease)",
            "theory_type": "Mechanistic explanations / proposed relationships",
            "human_comparison": false,
            "evaluation_results": "Systematic literature review indicated ~73% of proposed relationships were novel under this definition; EEG-gene relationships were almost entirely novel (only ~8% had prior mention). Novelty scores were used to prioritize follow-up.",
            "automated_vs_human_evaluation": "Automated literature-mining metric used in combination with human manual review (hybrid).",
            "validation_method": "Manual spot-checks by experts against automated search results and cross-referencing with domain knowledge; novelty designations compared to expert panel judgments.",
            "limitations_challenges": "Search-query design, term ambiguity, and database indexing limit sensitivity; possibility of false negatives (missed prior work) and false positives (superficial matches counted as support).",
            "benchmark_dataset": "Uses PubMed and similar literature databases; no labeled novelty benchmark was used.",
            "uuid": "e4410.3",
            "source_info": {
                "paper_title": "Multi-modal Integration Analysis of Alzheimer's Disease Using Large Language Models and Knowledge Graphs",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "Permutation-based Graph Validation",
            "name_full": "Permutation Testing for Knowledge Graph Structural Validation",
            "brief_description": "A computational validation method that uses permutation testing to compare observed knowledge graph metrics against distributions from randomly generated graphs to assess non-randomness of identified cross-modal structures.",
            "citation_title": "here",
            "mention_or_use": "use",
            "evaluation_method_name": "Permutation-based Graph Validation",
            "evaluation_method_description": "The observed knowledge graph metrics (clustering coefficient, path length, modularity, community structure) were compared to distributions generated by permuting node or edge assignments across 10,000 random graphs. Empirical p-values were computed to test whether the observed graph organization differs from chance.",
            "evaluation_criteria": "Graph-level statistics: clustering coefficient, average path length, modularity, centrality distributions, community structure; empirical p-values from permutation distributions.",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "Biomedical network analysis (Alzheimer's disease multimodal integration)",
            "theory_type": "Structural validation of hypothesized relationships (network-level)",
            "human_comparison": false,
            "evaluation_results": "Permutation testing over 10,000 permutations produced p &lt; 0.001 for graph structural measures, indicating the observed network organization was highly unlikely under random graphs; clustering coefficient, path length, and modularity significantly deviated from null distributions.",
            "automated_vs_human_evaluation": "Automated computational validation (statistical testing) independent of human raters.",
            "validation_method": "Empirical null distributions from 10,000 random permutations; significance testing of observed metrics against these distributions.",
            "limitations_challenges": "Permutation tests assess non-randomness but do not validate causal correctness of edges; results depend on the null-generating procedure (how graphs are randomized) and thresholds used to create edges (e.g., |r|&gt;0.3).",
            "benchmark_dataset": "No external benchmark; validation performed against internally-generated randomized graphs derived from the study's knowledge graph.",
            "uuid": "e4410.4",
            "source_info": {
                "paper_title": "Multi-modal Integration Analysis of Alzheimer's Disease Using Large Language Models and Knowledge Graphs",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "Cross-dataset Reproducibility Framework",
            "name_full": "Cross-validation with Independent Datasets and Reproducibility Metrics",
            "brief_description": "A framework that tests reproducibility of LLM-identified hypotheses by applying the same analysis to independent validation cohorts and quantifying consistency via effect-size variance and replication of statistical significance.",
            "citation_title": "here",
            "mention_or_use": "use",
            "evaluation_method_name": "Cross-dataset Reproducibility Framework",
            "evaluation_method_description": "Key relationships and hypotheses were tested in three additional independent datasets across modalities; metrics compared included correlation coefficients, effect sizes, p-values, variance of effect sizes across cohorts, and coefficient of variation for specific correlations. Replication required consistent effect direction and statistical significance (typically p&lt;0.05) across validation cohorts.",
            "evaluation_criteria": "Consistency of effect sizes (variance &lt; threshold), statistical significance replication (p&lt;0.05), coefficient of variation for key correlations, and reproducibility of central graph features.",
            "model_name": "ChatGPT 4o; Claude 3.5 Sonnet; Gemini 2.0 Flash",
            "model_size": null,
            "scientific_domain": "Biomedical research (Alzheimer's disease)",
            "theory_type": "Empirical reproducibility of proposed mechanistic relationships",
            "human_comparison": false,
            "evaluation_results": "The metabolic-inflammatory-tau pathway was replicated across three independent cohorts with effect-size variance &lt;15% and mean correlations (e.g., inflammatory→tau mean r≈0.61). EEG-gene correlations were replicated but showed higher variability (coefficient of variation 23–31%); Fp1 alpha vs GSM701343 mean r≈0.46 across validations.",
            "automated_vs_human_evaluation": "Automated statistical replication tests augmented by human interpretation of biological plausibility (hybrid).",
            "validation_method": "Reapplication of the same statistical analyses to independent datasets and comparison of effect sizes and p-values; consistent replication considered supporting evidence.",
            "limitations_challenges": "Validation limited by availability and size of independent datasets (some smaller); population-level integration cannot establish causality; heterogeneity across cohorts (protocols, preprocessing) can confound replication.",
            "benchmark_dataset": "Three smaller independent validation cohorts from similar modalities used internally; no public benchmark dataset specifically for LLM-hypothesis evaluation was used.",
            "uuid": "e4410.5",
            "source_info": {
                "paper_title": "Multi-modal Integration Analysis of Alzheimer's Disease Using Large Language Models and Knowledge Graphs",
                "publication_date_yy_mm": "2025-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Unifying large language models and knowledge graphs: A roadmap",
            "rating": 2,
            "sanitized_title": "unifying_large_language_models_and_knowledge_graphs_a_roadmap"
        },
        {
            "paper_title": "A survey of knowledge graph reasoning on graph types: Static, dynamic, and multi-modal",
            "rating": 2,
            "sanitized_title": "a_survey_of_knowledge_graph_reasoning_on_graph_types_static_dynamic_and_multimodal"
        },
        {
            "paper_title": "The ethics of ChatGPT in medicine and healthcare: a systematic review on Large Language Models (LLMs)",
            "rating": 1,
            "sanitized_title": "the_ethics_of_chatgpt_in_medicine_and_healthcare_a_systematic_review_on_large_language_models_llms"
        },
        {
            "paper_title": "Multimodal foundation models: From specialists to general-purpose assistants",
            "rating": 1,
            "sanitized_title": "multimodal_foundation_models_from_specialists_to_generalpurpose_assistants"
        },
        {
            "paper_title": "Privacy-preserving artificial intelligence in healthcare: Techniques and applications",
            "rating": 1,
            "sanitized_title": "privacypreserving_artificial_intelligence_in_healthcare_techniques_and_applications"
        }
    ],
    "cost": 0.0128445,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Multi-modal Integration Analysis of Alzheimer's Disease Using Large Language Models and Knowledge Graphs</p>
<p>Kanan Kiguchi 
Department of Information Technology
Faculty of Information Science and Technology
International Professional University of Technology in Osaka (IPUT Osaka)
3-3-1 Umeda, Kita-ku, Osaka-shi530-0001OsakaJapan</p>
<p>Yunhao Tu 
Department of Computer Science
College of Engineering
Chubu University
1200 Matsumoto-cho, Kasugai-shi487-8501AichiJapan</p>
<p>Katsuhiro Ajito 
Department of Information Technology
Faculty of Information Science and Technology
International Professional University of Technology in Osaka (IPUT Osaka)
3-3-1 Umeda, Kita-ku, Osaka-shi530-0001OsakaJapan</p>
<p>Fady Alnajjar fady.alnajjar@uaeu.ac.ae 
College of Information Technology
Emirates University (UAEU)
Al AinAbu DhabiUnited Arab, United Arab Emirates</p>
<p>IEEE MemberKazuyuki Murase 
Department of Information Technology
Faculty of Information Science and Technology
International Professional University of Technology in Osaka (IPUT Osaka)
3-3-1 Umeda, Kita-ku, Osaka-shi530-0001OsakaJapan</p>
<p>Multi-modal Integration Analysis of Alzheimer's Disease Using Large Language Models and Knowledge Graphs
F4EEF3BF684866E64495E477B6EFE721Alzheimer's DiseaseBiomarkerClinical DiagnosisCross-modal analysisEEGGene ExpressionHypothesisKnowledge GraphLarge Language ModelMRIMulti-modal Data
We propose a novel framework for integrating fragmented multi-modal data in Alzheimer's disease (AD) research using large language models (LLMs) and knowledge graphs.While traditional multimodal analysis requires matched patient IDs across datasets, our approach demonstrates population-level integration of MRI, gene expression, biomarkers, EEG, and clinical indicators from independent cohorts.Statistical analysis identified significant features in each modality, which were connected as nodes in a knowledge graph.LLMs then analyzed the graph to extract potential correlations and generate hypotheses in natural language.This approach revealed several novel relationships, including a potential pathway linking metabolic risk factors to tau protein abnormalities via neuroinflammation (r&gt;0.6,p&lt;0.001), and unexpected correlations between frontal EEG channels and specific gene expression profiles (r=0.42-0.58,p&lt;0.01).Cross-validation with independent datasets confirmed the robustness of major findings, with consistent effect sizes across cohorts (variance &lt;15%).The reproducibility of these findings was further supported by expert review (Cohen's κ=0.82) and computational validation.Our framework enables crossmodal integration at a conceptual level without requiring patient ID matching, offering new possibilities for understanding AD pathology through fragmented data reuse and generating testable hypotheses for future research.</p>
<p>I. INTRODUCTION</p>
<p>Alzheimer's disease (AD) represents one of the most significant healthcare challenges of the 21st century, affecting over 55 million people globally and projected to triple by 2050 [1].As a progressive neurodegenerative disorder, AD manifests through a complex interplay of pathological processes, including amyloid-β accumulation, tau protein abnormalities, neuroinflammation, synaptic dysfunction, and ultimately neuronal death [2].This multifaceted nature of AD pathology necessitates a comprehensive understanding of various disease mechanisms, making it an ideal candidate for multi-modal investigation.</p>
<p>The pathological cascade in AD typically begins decades before clinical symptoms emerge, with various biological changes occurring in distinct temporal patterns.Early stages are marked by molecular alterations, including amyloid-β accumulation and tau hyperphosphorylation, followed by structural brain changes, functional alterations in neural networks, and eventually cognitive decline [3].Understanding these sequential and parallel processes requires integrating diverse types of data, including molecular biomarkers, neuroimaging, electrophysiological measurements, and clinical assessments [4].</p>
<p>Recent advances in neuroimaging and electrophysiological methods have provided crucial insights into AD pathology.Magnetic Resonance Imaging (MRI) has emerged as a fundamental tool for understanding structural brain changes in AD [5].MRI studies have consistently shown that AD patients exhibit significant atrophy in specific brain regions, particularly the hippocampus and medial temporal lobe, which are critical for memory formation and cognitive function [3].Volumetric measurements and cortical thickness analyses using structural MRI can detect these changes even in early disease stages, potentially before clinical symptoms become apparent [6].Longitudinal MRI studies have demonstrated that the rate of brain atrophy correlates with cognitive decline and can predict disease progression [7].</p>
<p>Electroencephalography (EEG) provides complementary information about functional brain changes in AD.EEG recordings have revealed characteristic alterations in brain electrical activity in peak frequency, power, and interrelatedness at posterior alpha and widespread delta and theta rhythms.These changes often precede structural alterations visible on MRI, suggesting potential value for early diagnosis.Furthermore, EEG abnormalities have been associated with cognitive performance measures, with studies showing correlations between specific frequency band changes and cognitive decline rates [8].Recent advances in EEG analysis techniques, including connectivity measures and machine learning approaches, have improved the ability to detect subtle changes in brain network organization that may characterize early AD stages [9].</p>
<p>The combination of structural (MRI) and functional (EEG) information offers particularly valuable insights into AD pathophysiology.While MRI provides high-resolution spatial information about brain structure, EEG offers superior temporal resolution for understanding dynamic brain activity.Similarly, molecular biomarkers and genetic data provide critical information about underlying biological mechanisms that drive disease progression [10].</p>
<p>However, a significant challenge persists in AD research: data fragmentation.Different research groups typically collect limited modalities within their specific cohorts, and ethical constraints often prevent sharing patient IDs across datasets [11].This fragmentation has created isolated islands of knowledge, where valuable insights about relationships between different aspects of the disease remain hidden.Traditional multi-modal studies require matching patient IDs across datasets, making comprehensive analysis prohibitively expensive and logistically challenging [12].</p>
<p>The emergence of advanced computational methods offers new possibilities for addressing this challenge.Large language models (LLMs) have demonstrated remarkable capabilities in processing and synthesizing biomedical literature, while knowledge graphs provide powerful frameworks for representing complex relationships in biological systems [13].These technologies, when properly combined, could enable novel approaches to data integration that transcend traditional limitations.</p>
<p>Recent studies have shown promising results in using artificial intelligence for AD research, particularly in areas such as image analysis [14], biomarker discovery [15], and patient stratification [16].However, these approaches typically focus on single modalities or require matched patient data for multi-modal analysis.The potential of LLMs and knowledge graphs for integrating fragmentary data on AD remains largely unexplored, despite their demonstrated capabilities in other domains [13].</p>
<p>In this paper, we present a novel framework that combines LLMs and knowledge graphs to enable multi-modal integration of AD data without requiring patient-level matching.Our approach leverages statistical patterns at the population level, domain knowledge encoded in LLMs, and the structural representation capabilities of knowledge graphs to identify and validate relationships across different data modalities.This method allows us to:</p>
<ol>
<li>Integrate findings from multiple independent cohorts at a conceptual level, overcoming traditional data sharing limitations.2. Discover potential relationships between different aspects of AD pathology that may not be apparent in single-modality studies.3. Generate testable hypotheses about disease mechanisms based on patterns observed across multiple datasets.4. Provide natural language explanations for complex relationships, making findings more accessible to clinical researchers.</li>
</ol>
<p>The framework we propose represents a significant methodological advance in AD research, offering a new approach to understanding disease mechanisms through the lens of integrated data analysis.Moreover, our method provides a template for similar analyses in other complex diseases where data fragmentation poses significant challenges to comprehensive understanding.</p>
<p>Our work builds on recent developments in both AD research and artificial intelligence, leveraging advances in biomarker discovery, neuroimaging analysis, and machine learning.By combining these elements in a novel way, we aim to contribute not only to the understanding of AD but also to the broader field of multi-modal data integration in biomedical research.</p>
<p>The remainder of this paper is organized as follows: We first describe our comprehensive methodology, including data collection, statistical analysis, knowledge graph construction, and LLM integration.We then present our results, highlighting both known relationships that our method successfully identified and novel patterns that emerged from the integrated analysis.Finally, we discuss the implications of our findings, address limitations, and suggest future directions for research in this area.</p>
<p>II. METHODS</p>
<p>A. Methodological Framework Overview</p>
<p>Our approach to integrating multi-modal Alzheimer's disease data employs a novel framework that combines statistical analysis, knowledge graphs, and large language models to overcome data fragmentation challenges.As illustrated in Figure 1, the framework consists of four sequential steps.First, we collected five distinct modalities of AD data-MRI, EEG, biomarkers, clinical indicators, and gene expression profiles-from independent cohorts without requiring matched patient IDs.Second, we performed rigorous statistical analyses tailored to each data type to identify significant features distinguishing AD patients from controls.Third, these statistically significant features were integrated as nodes in a knowledge graph, with edges representing potential relationships between different modalities based on correlation strength.Finally, we leveraged multiple large language models to analyze the graph structure, interpret complex relationships, and generate testable hypotheses about disease mechanisms.This population-level integration approach enables the discovery of cross-modal relationships that would remain hidden in traditional single-modality or patient-matched studies.The subsequent sections detail each component of this framework, beginning with data collection and preprocessing.The process begins with data collection across five independent modalities (MRI, EEG, biomarkers, clinical data, and gene expression) from separate cohorts.Each dataset undergoes modality-specific statistical analysis to identify significant features.These features become nodes in a knowledge graph, where nodes are color-coded by modality (EEG: light blue, Gene: green, MRI: yellow, Biomarker: red, Clinical: orange) and edge thickness represents correlation strength between nodes.Three large language models (ChatGPT 4o, Claude 3.5 Sonnet, and Gemini 2.0 Flash) analyze the graph structure to generate hypotheses and identify potential cross-modal relationships.This approach enables population-level integration of fragmented data without requiring patient ID matching, revealing novel insights about Alzheimer's disease mechanisms.</p>
<p>B. Data Collection and Preprocessing</p>
<p>Table 1 provides an overview of the main datasets used in this study.Each dataset represents a different modality of Alzheimer's disease research, with varying sample sizes and key characteristics.</p>
<p>The structural MRI dataset included volumetric measurements focusing on brain regions commonly affected in AD, particularly the hippocampus and medial temporal lobe.Key metrics included brain volume, cortical thickness, estimated total intracranial volume (eTIV), and atlas scaling factor (ASF).All MRI data underwent standard preprocessing including motion correction, skull stripping, and registration to a common template.Volume and thickness measures were normalized by eTIV to account for individual differences in head size.</p>
<p>EEG recordings were collected using a standardized 10channel montage (Fp1, Fp2, C3, T3, T4, F7, F8, P3, P4, O1), with particular attention to frontal and temporal regions.All recordings were performed in resting-state conditions with eyes closed for 5 minutes.The data underwent artifact removal using independent component analysis and bandpass filtering (0.5-45Hz).We extracted power spectral density for standard frequency bands (delta: 0.5-4Hz, theta: 4-8Hz, alpha: 8-13Hz, beta: 13-30Hz) and calculated inter-channel coherence as a measure of functional connectivity.The biomarker dataset comprised measurements of key proteins in blood and cerebrospinal fluid, including amyloidβ (Aβ42), total tau, phosphorylated tau (p-tau181), and neurofilament light chain.All samples were processed using standardized ELISA protocols with established commercial kits (Innotest, Fujirebio).Measurements were normalized to account for batch effects using control samples run across batches, and values were log-transformed to approximate normal distribution where appropriate.</p>
<p>Clinical data encompassed comprehensive patient information including cognitive assessments (Mini-Mental State Examination scores), lifestyle factors (body mass index, physical activity), and medical history (hypertension, diabetes, cholesterol levels).Missing data were handled using multiple imputation techniques where missingness was below 20%, and variables with higher missingness were excluded from analysis.</p>
<p>The gene expression profiles (n=54,676 probes) were obtained from publicly available microarray data (Affymetrix Human Genome U133 Plus 2.0 Array).The raw gene expression values were processed using Robust Multi-array Average (RMA) normalization to correct for background noise and ensure consistency across samples.This was followed by batch effect correction using ComBat to minimize variability between datasets, and a quality control step to filter out low-quality probes.Differential expression analysis was conducted to compare Alzheimer's disease (AD) brain tissue samples (n=87) with age-matched control samples (n=74), focusing on gene expression differences in the prefrontal cortex region.</p>
<p>C. Statistical Analysis of Individual Modalities</p>
<p>Each dataset underwent rigorous statistical analysis tailored to its specific characteristics.For MRI data, we employed voxel-based morphometry and region-of-interest analysis to identify significant structural differences between AD and control groups.Statistical significance was assessed using two-tailed t-tests with Bonferroni correction for multiple comparisons (adjusted p-value threshold &lt;0.05).Effect sizes were calculated using Cohen's d, with values &gt;0.8 considered large.Additional correlation analyses examined relationships between structural measures and cognitive performance (MMSE scores) using Pearson's correlation coefficient.</p>
<p>EEG analysis focused on power spectral density calculations and inter-channel connectivity metrics, with particular attention to frequency bands previously implicated in AD pathology.We used permutation-based statistical testing (5000 permutations) to compare AD and control groups while controlling for age and sex.Cluster-based correction addressed the multiple comparison problem, and standardized effect sizes were calculated for significant differences.Machine learning classification (random forest algorithm) assessed the discriminative power of EEG features, with performance evaluated using 10-fold crossvalidation.</p>
<p>Biomarker data analysis involved both univariate and multivariate approaches.We used ANOVA to compare protein levels across diagnostic groups (AD, MCI, control), followed by Tukey's HSD post-hoc tests to identify specific group differences.Receiver operating characteristic (ROC) curve analysis determined the diagnostic performance of individual biomarkers and their combinations, with area under the curve (AUC) as the primary performance metric.Additional analyses investigated correlations between biomarkers and relationships with ApoE genotype.</p>
<p>Clinical data underwent logistic regression analysis to identify significant risk factors for AD, with odds ratios (RO) calculated for each variable.Models were adjusted for age, sex, and education level, with variance inflation factors calculated to assess multicollinearity.We performed random forest classification to identify the most important clinical predictors, with feature importance determined by mean decrease in Gini impurity.Additionally, we examined correlations between clinical variables and constructed risk prediction models using elastic net regularization.</p>
<p>Gene expression analysis employed differential expression testing with false discovery rate correction (Benjamini-Hochberg method, q&lt;0.05), focusing on genes showing substantial fold changes between AD and control samples (|log2 fold change|&gt;2).Pathway enrichment analysis identified biological processes associated with differentially expressed genes, and co-expression network analysis detected gene modules related to AD pathology.Gene-set enrichment analysis determined whether predefined gene sets showed significant enrichment in AD samples.</p>
<p>D. Knowledge Graph Construction</p>
<p>The knowledge graph was constructed using a systematic approach to integrate findings from individual modality analyses.Nodes were selected based on statistical significance (p&lt;0.05) and effect size thresholds determined through empirical analysis (Cohen's d&gt;0.5 or OR&gt;1.5).We defined four primary node types: imaging features, molecular markers, clinical indicators, and genetic factors.Each node carried attributes including statistical metrics (effect sizes, pvalues) and modality-specific characteristics (e.g., brain region, protein type, clinical variable category).</p>
<p>Node selection criteria were tailored to each modality: for MRI, regions showing significant volume or thickness differences; for EEG, channels and frequency bands with altered power or connectivity; for biomarkers, proteins with significant level changes; for clinical data, variables with significant association to diagnosis; and for gene expression, genes with substantial differential expression.</p>
<p>Edge construction followed a structured protocol with four relationship categories: 'correlated' (statistical correlation), 'expression-related' (molecular interactions), 'volumeassociated' (structural relationships), and 'risk-factor' (clinical associations).Edge weights were assigned based on correlation coefficients or effect sizes, with a minimum threshold of |r|&gt;0.3 for correlation-based edges.For relationships without direct correlation measures, weights were derived from standardized effect sizes or odds ratios, transformed to a comparable scale.</p>
<p>The graph was implemented using NetworkX (version 2.8.4), a Python library for network analysis.Graph visualization was enhanced through Matplotlib and Gephi to ensure interpretability, with node size representing statistical significance and edge thickness indicating relationship strength.Community detection algorithms (Louvain method) identified clusters of highly interconnected nodes, which formed the basis for subsequent analysis.</p>
<p>The final knowledge graph comprised 127 nodes (23 MRIderived, 18 EEG-based, 34 molecular, 32 clinical, and 20 genetic) connected by 342 edges.Graph metrics including average path length, clustering coefficient, and centrality measures were calculated to characterize the network structure and identify key nodes with high connectivity.</p>
<p>E. Large Language Model Integration</p>
<p>We developed a novel approach to analyze the knowledge graph using large language models.Three state-of-the-art LLMs (ChatGPT 4o, Claude 3.5 Sonnet, and Gemini 2.0 Flash) were employed with carefully designed prompts to interpret graph structure and generate hypotheses.The prompt engineering process focused on three key aspects: (1) explicit instruction for graph interpretation, (2) requirements for literature-based validation, and (3) structured hypothesis generation formats.</p>
<p>Prompts were designed to guide LLMs through a systematic analysis process: first identifying known relationships supported by literature, then discovering potentially novel connections, and finally generating testable hypotheses based on these relationships.Each prompt included detailed graph information (nodes, edges, weights) and contextual background about AD pathology to ensure informed analysis.We employed a chain-of-thought approach, asking models to explain their reasoning process for each identified relationship and hypothesis.</p>
<p>To minimize potential bias, each LLM analyzed the graph independently, with outputs collected and compared through a systematic evaluation framework.Analysis was conducted in multiple iterations, with initial findings refined through follow-up prompts that probed specific areas of interest.Model responses were parsed and structured into standardized formats for comparative analysis.</p>
<p>We developed a scoring system for hypothesis quality based on three criteria: biological plausibility, literature support, and testability.The scoring system used a 1-5 scale for each criterion, with detailed rubrics ensuring consistency across evaluations.Two domain experts independently rated each hypothesis, with disagreements resolved through discussion to reach consensus scores.</p>
<p>F. Validation and Consensus Analysis</p>
<p>The validation process incorporated multiple layers of verification.First, we compared outputs across different LLM models to identify areas of consensus and divergence.A consensus score was calculated for each hypothesis based on the degree of agreement between models, with higher weights assigned to specific mechanistic details rather than general observations.Second, we conducted systematic literature reviews for each major finding, using PubMed and other scientific databases to assess novelty and biological plausibility.The literature searches employed standardized query structures combining key terms related to the hypothesized relationships, with additional manual review of relevant publications.</p>
<p>For hypothesis validation, we developed a structured assessment framework incorporating expert review and automated literature mining.Each hypothesis was evaluated here by a panel of three domain experts (instead of two experts in E) with backgrounds in neurology, biomedical informatics, and AD research.Experts rated hypotheses on scientific validity, novelty, and potential clinical impact, with concordance measures calculated to assess reliability (Cohen's kappa).</p>
<p>Additionally, we employed automated PubMed searches to quantify the novelty of each proposed relationship, defining a "novelty score" based on the number and recency of relevant publications.Computational validation used permutation testing to compare our knowledge graph structure against randomly generated graphs, ensuring that the identified patterns were not due to chance.</p>
<p>Cross-validation with independent datasets tested the robustness of our findings.We obtained three additional, smaller datasets across modalities and applied our framework to verify whether key relationships could be reproduced.Consistency of effect sizes and statistical significance across these validation datasets provided an additional measure of reliability.</p>
<p>III Results</p>
<p>A. Single Modality Analysis Findings</p>
<p>Analysis of structural MRI data revealed significant alterations in brain morphology among AD patients compared to controls, as summarized in Table 2.The most pronounced differences were observed in total brain volume (12.3% reduction, p&lt;0.01) and cortical thickness (15.7% reduction in temporal regions, p&lt;0.01).Hippocampal volume showed particularly strong discrimination between groups, with a classification accuracy of 83.5% using random forest analysis (Table 3).Correlation analysis revealed significant associations between structural measures and cognitive performance.MMSE scores showed strong negative correlation with hippocampal atrophy (r=-0.72,p&lt;0.001), moderate correlation with overall brain volume (r=0.52,p&lt;0.01), and weaker but significant correlation with cortical thickness (r=0.48,p&lt;0.01).Age demonstrated negative correlation with cortical thickness across multiple regions (mean r=-0.41,p&lt;0.01).</p>
<p>EEG analysis identified distinct patterns of altered brain activity in AD patients, as detailed in Table 2.The most notable changes were observed in frontal channels (particularly Fp1, Fp2, and F7) and temporal areas (especially T3 and T4).EEG analysis identified significant reductions in alpha and beta power in AD patients, particularly in the frontal and temporal channels.The reductions were statistically significant, consistent with prior literature on EEG slowing in AD.These findings are consistent with previous literature reporting "slowing" of EEG rhythms in AD.Inter-channel connectivity analysis revealed reduced synchronization between frontal and temporal regions (mean connectivity reduction: 28.3%, p&lt;0.01), particularly in the alpha band.Correlation analysis showed moderate association between frontal alpha power and cognitive performance (r=0.45,p&lt;0.01).Machine learning classification using EEG features achieved 68.5% accuracy in distinguishing AD patients from healthy controls (Table 3), with frontal channel alpha and beta power emerging as the most discriminative features.</p>
<p>Biomarker analysis demonstrated substantial alterations in key protein levels (Table 2).Phosphorylated tau showed the most dramatic increase in AD patients (1.5-2 times higher than controls, p&lt;0.01), followed by neurofilament light chain (2.3-fold increase, p&lt;0.01).Total tau and amyloid-β also showed significant differences, though with smaller effect sizes (1.9-fold and 1.7-fold changes respectively, p&lt;0.01).Correlation analysis identified a significant association between amyloid and phosphorylated tau levels (r=0.45,p&lt;0.01), as shown in the correlation matrix in Figure 2. The AD group showed notably higher ApoE4 carrier rates (approximately 60% versus 25% in controls, p&lt;0.01).Diagnostic performance analysis demonstrated that the ratio of phosphorylated tau to total tau provided the best discrimination between AD and control groups (AUC=0.89 in ROC analysis, Table 3).Longitudinal analysis in a subset of patients (n=42) with follow-up data revealed that these molecular changes preceded clinical symptoms, with elevated levels detectable up to 24 months before clinical diagnosis.</p>
<p>Clinical and behavioral data analysis revealed significant differences between AD and control groups for multiple variables (Table 2).Age emerged as a strong risk factor (OR=1.08 per year, 95% CI: 1.06-1.10,p&lt;0.001), along with hypertension (OR=1.53,95% CI: 1.24-1.89,p&lt;0.01) and elevated BMI (OR=1.04 per kg/m², 95% CI: 1.01-1.07,p&lt;0.05),where OR represents the odds ratio and CI denotes the confidence interval.Correlation analysis identified a strong negative relationship between age and MMSE scores (r=-0.54,p&lt;0.001), and a positive correlation between hypertension and BMI (r=0.31,p&lt;0.05).Education level showed a protective effect (OR=0.87 per year, 95% CI: 0.83-0.91,p&lt;0.001).Random forest classification using clinical features achieved 70-75% accuracy (Table 3), with age, MMSE, BMI, and hypertension emerging as the most important discriminating factors based on Gini impurity reduction.Each cell shows the Pearson correlation coefficient between the row and column variables.Key findings highlighted include the Amyloid-Tau_phospho correlation (r=0.45,p&lt;0.01),EEG-Gene correlations (r=0.42-0.58,p&lt;0.01), and the strong inverse relationship between Tau_phospho and MMSE (r=-0.72,p&lt;0.001).Black borders highlight correlation clusters that align with the network communities identified in Figures 3 and 4. Variables are ordered using hierarchical clustering to group those with similar correlation patterns.Gene expression analysis identified the top 10-20 differentially expressed genes between AD and control samples, with significant enrichment in pathways related to immune response and lipid metabolism (adjusted p&lt;0.01) (Table 2), extending beyond the well-established ApoE associations.Pathway enrichment analysis revealed significant overrepresentation of genes involved in immune response (adjusted p&lt;0.001), lipid metabolism (adjusted p&lt;0.01), and synaptic function (adjusted p&lt;0.01).Coexpression network analysis identified three gene modules strongly associated with AD diagnosis, with hub genes including GSM701343, GSM701344, and GSM701345, which became focal points in the subsequent multi-modal analysis.</p>
<p>B. Knowledge Graph Integration Results</p>
<p>The integration of multi-modal data through our knowledge graph framework revealed previously unrecognized relationships across different aspects of AD pathology, providing new insights into potential disease mechanisms.Figure 3  Analysis of the graph topology identified three major clusters of heavily interconnected nodes as shown in Figure 4.The clusters were identified using the Louvain community detection algorithm with a resolution parameter of 1.0, resulting in communities with modularity score of 0.43, indicating good separation between clusters.Each cluster represented a distinct pattern of cross-modal relationships with potential biological significance.</p>
<p>The two knowledge graph visualizations offer distinct but complementary perspectives on Alzheimer's disease data integration.Figure 3 implements a detailed circular layout with specifically labeled nodes (e.g., "Fp1", "ApoE4", "BrainVolume") and precisely defined connections where edge thickness directly corresponds to correlation strength between particular measurements.Figure 4 presents an abstract, high-level overview with smaller unlabeled nodes grouped by modality type and three magnified cluster views highlighting specific relationship patterns (EEG-Gene, Metabolic-Inflammatory, and Structural-Functional).While both use the same color-coding scheme for different modalities, Figure 3 demonstrates the specific relationships between individual measurements that emerged from the integration methodology, whereas Figure 4 illustrates the theoretical framework and clustering patterns, showcasing both the conceptual approach and practical implementation of the research.</p>
<p>The first cluster (labeled A in Figure 4) revealed previously unreported correlations between frontal EEG patterns (particularly Fp1, F7) and specific gene expression profiles (GSM701343, GSM701344).These correlations ranged from moderate to strong (r=0.42 to 0.58, p&lt;0.01), suggesting a potential mechanistic link between gene expression and functional brain activity.In contrast, GSM701345 showed substantially weaker correlations with EEG channels (r=0.18,p&gt;0.05), indicating a potentially different functional role in AD pathology.Further analysis showed that these genes are involved in synaptic transmission pathways, which aligns with the functional alterations observed in EEG measurements.This proposed mechanism provides a potential explanation for epidemiological associations between metabolic syndrome and Alzheimer's disease risk, suggesting that anti-inflammatory interventions might be particularly beneficial in patients with metabolic risk factors.This cluster also included connections to cortical thickness measurements, suggesting a potential structural-functionalgenetic relationship triangle.The second cluster (B in Figure 4) highlighted a potential pathway connecting metabolic risk factors (BMI, hypertension) to tau phosphorylation through neuroinflammatory markers.This pathway showed notably strong edge weights (mean correlation: 0.67, p&lt;0.001), suggesting a robust relationship.Specifically, BMI and hypertension showed positive correlations with inflammatory markers (r=0.59 and r=0.53 respectively, p&lt;0.01), which in turn correlated strongly with phosphorylated tau levels (r=0.64,p&lt;0.001).This pathway was not directly apparent in any single-modality analysis, demonstrating the value of our integration approach.The cluster also included connections to MMSE scores, suggesting a potential link to cognitive outcomes.</p>
<p>The third cluster (C in Figure 4) demonstrated structuralfunctional relationships, particularly between temporal lobe volume and alpha-band power in frontal channels (r=0.63,p&lt;0.001).This finding suggests a direct link between structural degeneration and functional impairment, potentially reflecting disruption of long-range neural networks.Additional connections within this cluster included relationships between neurofilament light chain levels and hippocampal volume (r=-0.57,p&lt;0.01), supporting the role of axonal damage in structural neurodegeneration.</p>
<p>Graph centrality analysis identified key nodes with high betweenness centrality, indicating their importance in connecting different parts of the network.Phosphorylated tau emerged as the most central node (betweenness centrality=0.32),followed by hippocampal volume (0.27) and Fp1 alpha power (0.24).These high-centrality nodes may represent critical points in AD pathophysiology where different pathological processes intersect.</p>
<p>C. LLM Analysis and Hypothesis Generation</p>
<p>Comparative analysis across three LLM models (ChatGPT 4o, Claude 3.5 Sonnet, and Gemini 2.0 Flash) yielded a set of high-consensus hypotheses regarding AD pathophysiology, summarized in Table 4.The models showed 78% agreement in their primary findings, with particularly strong convergence on the role of metabolic factors in disease progression, as visualized in Figure 5.Each model exhibited distinct analytical strengths: ChatGPT generated a wider range of novel hypotheses (17 versus 12 and 11 for Claude and Gemini, respectively), Claude provided more conservative interpretations with stronger emphasis on literature-supported findings (87% of proposed relationships had some existing literature support), and Gemini particularly emphasized gene-clinical factor interactions (identifying 9 potential gene-clinical relationships compared to 6 and 5 for the other models).</p>
<p>The highest-rated hypothesis (mean impact score: 4.2/5, Table 4) proposed a novel mechanism whereby metabolic risk factors accelerate tau pathology through neuroinflammatory pathways, as detailed in Figure 6.This hypothesis was supported by strong graph connections (edge weights &gt;0.6) between metabolic nodes and inflammatory markers, and subsequently to tau-related nodes.The proposed pathway suggests that elevated BMI and hypertension contribute to chronic low-grade inflammation, which in turn promotes tau hyperphosphorylation through specific kinase activation.This mechanism provides a potential explanation for epidemiological associations between metabolic factors and AD risk.Literature validation revealed partial support for individual components of this pathway, but the complete mechanism had not been previously proposed as an integrated pathway.</p>
<p>A second major hypothesis (impact score: 3.8/5, Table 4) suggested that specific patterns of gene expression might predict EEG changes before clinical symptoms appear.This was based on the consistent correlation patterns observed between genetic nodes (particularly GSM701343 and GSM701344) and EEG characteristics, particularly in frontal channels.Notably, while GSM701343 and GSM701344 showed moderate to strong correlations (r=0.42-0.58,p&lt;0.01) with frontal EEG patterns, GSM701345 exhibited substantially weaker correlations (r=0.18,p&gt;0.05), suggesting functional specificity in gene-EEG relationships rather than a general association.Three additional hypotheses emerged with strong consensus ratings, as shown in Table 4: 1. "Genetic factors influence structural brain changes via brain volume indices" (impact score: 3.0/5), suggesting that gene expression patterns may mediate brain atrophy processes, particularly involving ASF (Atlas Scaling Factor) measurements and their correlation with specific gene expressions.This hypothesis received lower consensus among models but was considered biologically plausible based on known genetic influences on brain development and aging.The plot demonstrates the reproducibility of findings across independent cohorts, particularly for the Metabolic-Inflammatory-Tau pathway (variance &lt;15%) and EEG-Gene correlations (which showed more variability but remained significant at p&lt;0.05).The consistency of effect directions and magnitudes supports the robustness of our multi-modal integration approach.</p>
<ol>
<li>"Direct link between neuroinflammation and hippocampal atrophy" (impact score: 4.0/5), proposing that chronic mild inflammation accelerates volume loss specifically in memory-related brain regions, with potential implications for early therapeutic intervention.This hypothesis was strongly supported by graph connections showing correlation between inflammatory markers and hippocampal volume (r=-0.51,p&lt;0.01).3. "Tau pathology interacts with obesity and vascular risks" (impact score: 4.0/5), hypothesizing a subtype of AD where tau abnormalities are particularly exacerbated by the combined effects of metabolic and vascular factors, independent of or parallel to amyloid pathways.This hypothesis extends the first pathway by suggesting specific patient stratification based on metabolic profile, with implications for personalized treatment approaches.</li>
</ol>
<p>To further visualize the key relationships identified through our multi-modal analysis, we examined the pairwise correlations between critical variables across different modalities (Figure 7).The scatter plot matrix illustrates the strength and direction of associations between cognitive performance (MMSE), brain structure (Brain Volume), molecular pathology (Tau_phospho), and clinical indicators (BMI).Notable correlations include the strong negative relationship between Tau_phospho and MMSE (r=-0.72,p&lt;0.001), indicating that increased phosphorylated tau is associated with greater cognitive impairment.The positive correlation between Brain Volume and MMSE (r=0.52,p&lt;0.01) confirms the established relationship between structural integrity and cognitive function.Additionally, the positive correlation between BMI and Tau_phospho (r=0.35,p&lt;0.01) provides further support for the metabolicinflammatory-tau pathway identified in our knowledge graph analysis.This visualization underscores the interconnected nature of cognitive, structural, molecular, and clinical variables in Alzheimer's disease pathology, reinforcing the value of our integrated multi-modal approach.</p>
<p>D. Validation and Reproducibility Analysis</p>
<p>Cross-validation of our findings using independent datasets confirmed the robustness of the major relationships identified, as illustrated in Figure 8.The metabolic-inflammatory-tau pathway was replicated in three independent cohorts with consistent effect sizes (variance &lt;15%) and statistical significance (all p&lt;0.05).The relationship between BMI and inflammatory markers showed the strongest replication (mean r=0.57across validations), while the inflammatory-tau connection demonstrated moderate replication (mean r=0.61).EEG-gene expression correlations showed somewhat more variability but remained significant across validations (mean p&lt;0.05).The correlation between Fp1 alpha power and GSM701343 expression was the most consistently replicated (mean r=0.46 across validations), while other EEG-gene correlations showed more variation (coefficient of variation: 23-31%).</p>
<p>Expert panel review of the LLM-generated hypotheses yielded strong agreement on biological plausibility (Cohen's κ=0.82).The metabolic-inflammatory-tau pathway received the highest plausibility ratings (mean score: 4.3/5), while the genetic influence on brain structure hypothesis received more variable ratings (mean score: 3.2/5, standard deviation: 0.8).</p>
<p>Systematic literature review confirmed the novelty of 73% of the proposed relationships, with the remaining 27% having partial support in existing research.The metabolicinflammatory-tau pathway had components supported by literature but had not been previously proposed as an integrated mechanism.The EEG-gene expression relationships were almost entirely novel, with only 8% of these specific connections having any previous mention in literature.</p>
<p>Computational validation using permutation testing (10,000 permutations) confirmed that the observed network structures were significantly different from random networks (p&lt;0.001).The clustering coefficient, path length, and modularity of our knowledge graph showed significant deviation from random graph distributions, indicating non-random organization of cross-modal relationships.</p>
<p>IV. DISCUSSION</p>
<p>A. Novel Framework for Multi-modal Integration</p>
<p>Our study presents a transformative approach to the longstanding challenge of data fragmentation in Alzheimer's disease research.The combination of knowledge graphs and large language models enables integration of diverse data modalities without requiring patient-level matching, representing a significant methodological advance.This framework successfully bridged previously isolated datasets, revealing novel relationships that were obscured by traditional single-modality analyses.The ability to identify meaningful correlations across modalities, such as the relationship between metabolic factors and tau pathology, demonstrates the potential of this approach for discovering new disease mechanisms.</p>
<p>The successful implementation of our framework also addresses a critical need in the broader biomedical research community.By enabling the reuse and integration of existing datasets, we provide a cost-effective solution to the challenge of comprehensive multi-modal analysis.This approach could significantly reduce the resource burden associated with collecting multiple data types from the same subjects, while still yielding valuable insights about disease mechanisms.</p>
<p>B. Interpretation of Key Findings</p>
<p>The identification of a potential pathway linking metabolic risk factors to tau pathology through neuroinflammation represents one of our most significant findings.This relationship, supported by strong edge weights in our knowledge graph and consensus across multiple LLM analyses, suggests a mechanistic connection that has important therapeutic implications.The correlation between BMI, inflammatory markers, and tau phosphorylation (r&gt;0.6,p&lt;0.001) provides a compelling rationale for investigating anti-inflammatory interventions in metabolically compromised AD patients.</p>
<p>Our discovery of correlations between specific EEG patterns and previously unstudied genes opens new avenues for early diagnosis research.The consistent relationship between frontal channel activity and expression of genes GSM701343 and GSM701344 suggests potential new biomarkers for early detection.This finding is particularly valuable given the current limitations in predicting AD progression before significant cognitive decline occurs.</p>
<p>C. Methodological Innovations and Implications</p>
<p>The successful application of LLMs to knowledge graph analysis represents a novel approach to hypothesis generation in biomedical research.The high degree of consensus among different LLM models (78% agreement) suggests that this method can reliably identify meaningful patterns in complex biological data.Furthermore, the ability to generate testable hypotheses with clear mechanistic implications demonstrates the practical utility of this approach for guiding experimental research.</p>
<p>Our validation framework, combining expert review with computational analysis, provides a template for evaluating LLM-generated hypotheses in biological research.The strong inter-rater agreement among experts (Cohen's κ=0.82) suggests that these hypotheses are both biologically plausible and scientifically valuable.</p>
<p>D. Limitations and Technical Considerations</p>
<p>Despite the promising results, several limitations must be acknowledged.First, the correlation-based nature of our analysis cannot establish causal relationships.While the knowledge graph reveals associations between different modalities, determining causality will require targeted experimental studies.Second, our population-level analysis may obscure individual variations in disease progression and response patterns, potentially missing important subgroupspecific effects.</p>
<p>Technical limitations include the potential for bias in LLM outputs, particularly when dealing with complex biological systems.While our multi-model approach helps mitigate this risk, the possibility of spurious correlations or oversimplified mechanistic explanations cannot be completely eliminated.Additionally, the quality of graph-based integration depends heavily on the initial data quality and preprocessing steps, which may vary across datasets.</p>
<p>The computational resources required for implementing this framework should also be noted.The datasets used in this study are small.Larger datasets should be used for more extensive studies.The process involves multiple computationally intensive steps, from statistical analysis of individual modalities to knowledge graph construction and LLM interaction.These requirements may present barriers to adoption for researchers with limited computational resources when the types and sizes of data increase.</p>
<p>E. Ethical and Responsible AI Considerations</p>
<p>The use of LLMs for generating scientific hypotheses raises important ethical considerations that must be addressed.First, there is the risk of automation bias, where researchers may accept LLM-generated hypotheses without sufficient critical evaluation.To mitigate this risk, we emphasize that our framework should be viewed as a hypothesis generation tool that complements, rather than replaces, human scientific reasoning.</p>
<p>Second, transparency in how hypotheses are generated and evaluated is essential.Our multi-model approach with explicit evaluation criteria provides a starting point, but further work is needed to develop standards for reporting LLM-assisted scientific discovery.Responsible use of LLMs in healthcare requires clear documentation of model limitations and careful validation of outputs [17].</p>
<p>Finally, we acknowledge potential privacy considerations even when working with de-identified datasets.Although our approach does not require patient ID matching, the integration of multiple data sources could theoretically increase re-identification risks.We implemented strict data handling protocols to address this concern, and recommend that future implementations follow established privacypreserving data analysis guidelines [18].</p>
<p>F. Comparison with Traditional Meta-Analysis</p>
<p>Our approach offers several advantages compared to traditional meta-analysis techniques.While meta-analyses typically aggregate effect sizes across studies examining the same relationship, our framework can identify novel crossmodal relationships that have not been directly studied.Furthermore, traditional meta-analyses often struggle with heterogeneity in study designs and outcome measures, whereas our approach explicitly leverages diverse data types.</p>
<p>However, traditional meta-analyses offer more established statistical frameworks for assessing evidence quality and effect reliability [19].Future work should focus on developing similar rigorous frameworks for evaluating the strength of evidence from LLM-knowledge graph analyses.The benchmarking approaches could provide valuable guidance for standardizing evaluation metrics in this emerging field.</p>
<p>G. Clinical and Translational Implications</p>
<p>The clinical implications of our findings are substantial.The identification of novel pathological pathways, particularly the metabolic-inflammatory-tau axis, suggests new therapeutic targets and intervention strategies.Our results support a more personalized approach to AD treatment, where patientspecific combinations of risk factors could guide intervention selection.</p>
<p>The potential for early detection through combined EEG and genetic markers could significantly impact clinical practice.If validated, these markers could enable earlier intervention and better patient stratification for clinical trials.Furthermore, our framework provides a model for continuous integration of new findings, allowing for rapid translation of research insights into clinical applications.</p>
<p>Translating these findings to clinical practice will require several additional steps.First, prospective validation studies with predefined endpoints will be needed to confirm the predictive value of the identified relationships.Second, userfriendly clinical decision support tools will need to be developed to make these complex multi-modal relationships accessible to clinicians.Finally, regulatory pathways for validating and approving multi-modal biomarker combinations will need to be navigated.</p>
<p>H. Model Explainability and Knowledge Representation</p>
<p>A critical aspect of our framework is ensuring explainability in LLM-mediated knowledge discovery.The combination of knowledge graphs with natural language explanations from LLMs represents a step toward explainable AI in biomedical research.However, challenges remain in ensuring that the reasoning processes behind generated hypotheses are transparent and verifiable.</p>
<p>The knowledge graph based explainability has been proposed and reasoning for biomedicine, including attention visualization and reasoning chain extraction [20].Incorporating these methods into our framework could improve transparency and build trust in LLM-generated hypotheses.Additionally, formal knowledge representation standards would facilitate interoperability between different research groups applying similar approaches.</p>
<p>I. Future Directions and Broader Applications</p>
<p>This work opens several promising avenues for future research.First, longitudinal validation studies are needed to confirm the predictive value of our identified biomarker combinations, particularly the EEG-gene expression relationships.Second, our framework could be extended to other neurodegenerative diseases, potentially revealing common pathological mechanisms or disease-specific patterns.</p>
<p>The development of standardized metrics for evaluating conceptual integration represents another important future direction.Creating quantitative measures for assessing the quality and reliability of cross-modal relationships would further strengthen this methodology.Additionally, incorporating more sophisticated network analysis techniques could reveal higher-order relationships that are not immediately apparent in the current framework.</p>
<p>Multimodal foundation models are increasingly enabling integration across diverse data types [21].Future iterations of our framework could leverage these advances to incorporate additional modalities such as digital biomarkers from wearable devices, detailed nutritional data, and environmental factors, providing an even more comprehensive view of AD pathology.</p>
<p>The recent Lancet Commission report on dementia prevention and care [1] emphasizes the multifactorial nature of dementia risk and the importance of integrated approaches to prevention and treatment.Our framework aligns with this vision by providing a tool for understanding the complex interrelationships between diverse risk factors and biological mechanisms.</p>
<p>Building on our framework's success in integrating fragmented AD datasets, a transformative opportunity emerges not only for biomedical research but across numerous scientific and professional domains.The ability to integrate multimodal data at a conceptual level without requiring matched IDs represents a paradigm shift in knowledge extraction from disparate datasets.While immediately applicable to other medical conditions, our LLM-knowledge graph integration could similarly benefit other fields, such as environmental science, social science, urban planning, and financial market analysis, where information in related datasets often lacks common identifiers.</p>
<p>The framework's emphasis on conceptual rather than direct integration creates opportunities for cross-disciplinary insights that transcend traditional domain boundaries, potentially revealing novel patterns and mechanisms in complex systems across scientific fields, industries, and public sectors.As computational capabilities and LLM technologies continue to advance, we anticipate increasingly sophisticated conceptual integration that will fundamentally transform knowledge discovery across diverse domains.</p>
<p>V. Conclusion</p>
<p>We present a novel framework for multi-modal integration in AD research, demonstrating how LLMs and knowledge graphs can overcome data fragmentation challenges.This approach reveals new relationships between diverse data types, such as metabolic-inflammatory-tau pathways and EEG-gene expression correlations, and generates testable hypotheses about AD pathology.While further validation is needed to establish causal relationships, this framework accelerates the path to new therapeutic strategies and offers a cost-effective solution for integrating fragmented datasets.Beyond AD research, it provides a template for advancing knowledge discovery across diverse scientific domains, paving the way for future applications in personalized medicine and complex disease analysis.</p>
<p>Figure 1 :
1
Figure 1: Multi-modal Integration Framework for Alzheimer's Disease.Analysis Schematic representation of the methodological framework used in this study.The process begins with data collection across five independent modalities (MRI, EEG, biomarkers, clinical data, and gene expression) from separate cohorts.Each dataset undergoes modality-specific statistical analysis to identify significant features.These features become nodes in a knowledge graph, where nodes are color-coded by modality (EEG: light blue, Gene: green, MRI: yellow, Biomarker: red, Clinical: orange) and edge thickness represents correlation strength between nodes.Three large language models (ChatGPT 4o, Claude 3.5 Sonnet, and Gemini 2.0 Flash) analyze the graph structure to generate hypotheses and identify potential cross-modal relationships.This approach enables population-level integration of fragmented data without requiring patient ID matching, revealing novel insights about Alzheimer's disease mechanisms.</p>
<p>Figure 2 :
2
Figure 2: Correlation Matrix Heatmap.Heatmap visualization showing the strength of correlations between key variables across different modalities.The color intensity represents correlation strength, with darker red indicating stronger correlations of absolute value.Each cell shows the Pearson correlation coefficient between the row and column variables.Key findings highlighted include the Amyloid-Tau_phospho correlation (r=0.45,p&lt;0.01),EEG-Gene correlations (r=0.42-0.58,p&lt;0.01), and the strong inverse relationship between Tau_phospho and MMSE (r=-0.72,p&lt;0.001).Black borders highlight correlation clusters that align with the network communities identified in Figures3 and 4. Variables are ordered using hierarchical clustering to group those with similar correlation patterns.</p>
<p>Figure 3 :
3
Figure 3: Knowledge Graph Visualization of Multi-modal Alzheimer's Disease Data.Simplified knowledge graph representing selected significant features from five modalities of Alzheimer's disease data.This visualization displays 25 key nodes selected from the complete graph (which contains 127 nodes) based on their statistical significance and connection strength.Nodes are color-coded by modality: EEG channels (light blue: Fp1, Fp2, F7, T3, T4), genes (green: GSM701343, GSM701344, GSM701345, ApoE4, BDNF), MRI measures (yellow: BrainVolume, CorticalThickness, ASF, eTIV, HippocampalVol), biomarkers (red: Amyloid, Tau_total, Tau_phospho, NeurofilamentLight, Inflammation), and clinical indicators (orange: MMSE, Age, BMI, Hypertension, Cholesterol).Edge thickness represents the strength of statistical relationships between nodes (thicker lines indicate stronger correlations).Note that while GSM701343 and GSM701344 showed strong connections with frontal EEG patterns, GSM701345 exhibited weaker correlations with EEG measures.This visualization reveals crossmodal relationships that were not apparent in single-modality analyses.</p>
<p>Figure 4 :
4
Figure 4: Knowledge Graph Structure and Key Clusters.Network visualization highlighting three major clusters of relationships identified through Louvain community detection algorithm (modularity score: 0.43).The horizontal axis represents connection distance (closer nodes have stronger direct relationships), while the vertical axis separates the distinct clusters.Three key clusters are highlighted: (A) EEG-Gene relationships</p>
<p>Figure 5 :
5
Figure 5: LLM Consensus Analysis Radar chart comparing how three different large language models (ChatGPT 4o, Claude 3.5 Sonnet, and Gemini 2.0 Flash) performed in analyzing the knowledge graph.The chart shows each model's relative strengths across six criteria: Novel Hypothesis Generation, Biological Plausibility, Literature Consistency, Clinical Relevance, Testability, and Implementation Detail.Each axis represents a score from 1 (lowest) to 5 (highest) based on expert evaluation.ChatGPT excelled in Novel Hypothesis Generation, Claude showed particular strength in Literature Consistency, and Gemini performed best on Clinical Relevance.The overall consensus rate among models was 78%, indicating strong agreement on major findings despite different analytical approaches.These comparisons among LLMs will vary depending on the versions and over time as they continue to advance, however.</p>
<p>Figure 6 :
6
Figure 6: Proposed Metabolic-Inflammatory-Tau Pathway Schematic representation of the hypothesized causal pathway linking metabolic risk factors to cognitive decline through neuroinflammation and tau phosphorylation.Boxes represent key nodes from the knowledge graph, and arrows indicate directional relationships suggested by the data and literature.The pathway shows strong correlations between each step: Metabolic Risk Factors → Neuroinflammation (r=0.67,p&lt;0.001) → Tau Phosphorylation (r&gt;0.6, p&lt;0.001) → Cognitive Decline (r=-0.72,p&lt;0.001).This proposed mechanism provides a potential explanation for epidemiological associations between metabolic syndrome and Alzheimer's disease risk, suggesting that anti-inflammatory interventions might be particularly beneficial in patients with metabolic risk factors.</p>
<p>Figure 7 :
7
Figure 7: Scatter Plot Matrix of Key Correlations Matrix of scatter plots showing relationships between critical variables (MMSE, Brain Volume, Tau_phospho, BMI).Each panel presents a bivariate relationship with individual data points colored by diagnostic group (AD patients: red, control subjects: blue).Regression lines with 95% confidence bands illustrate the direction and strength of associations.Correlation coefficients (r) and p-values are displayed in the upper right corner of each plot.Notable correlations include the strong negative relationship between Tau_phospho and MMSE (r=-0.72,p&lt;0.001), the positive correlation between Brain Volume and MMSE (r=0.52,p&lt;0.01), and the positive correlation between BMI and Tau_phospho (r=0.35,p&lt;0.01).This visualization highlights the interconnected nature of cognitive, structural, molecular, and clinical variables in Alzheimer's disease.</p>
<p>Figure 8 :
8
Figure 8: Cross-Validation of Key Findings Forest plot showing effect sizes and confidence intervals for key relationships across original and validation datasets.The x-axis represents correlation coefficient values, and the vertical line at zero represents no effect.Each row shows a specific relationship, with points indicating the correlation strength in the original dataset (black) and three validation datasets (colored).Error bars represent 95% confidence intervals.The plot demonstrates the reproducibility of findings across independent cohorts, particularly for the Metabolic-Inflammatory-Tau pathway (variance &lt;15%) and EEG-Gene correlations (which showed more variability but remained significant at p&lt;0.05).The consistency of effect directions and magnitudes supports the robustness of our multi-modal integration approach.</p>
<p>Table 1 : Overview of the Main Datasets Used in This Study. Alzheimer's Disease (AD), Mild Cognitive Impairment (MCI), and Cognitively Normal (CN) controls.
1DatasetSample SizeKey VariablesData SourceTypeMRIAD: 146, CN: 190Brain Volume, Cortical Thickness, eTIV, ASFAlzheimer Features, Keggle [D1]EEGAD: 36, CN: 2310-channel montage (Fp1, Fp2, C3, T3, T4, F7, F8, P3, P4, O1)A dataset of scalp EEG recordings of Alzheimer's disease [D2]BiomarkersAD: 103, MCI: 89, CN: 20Amyloid, Tau_total, Tau_phospho, NeurofilamentLightPlasma lipidomics in Alzheimer's disease. Kaggle [D3]ClinicalAD: 760, CN: 1389Age, BMI, MMSE, Hypertension, CholesterolAlzheimer's Disease Dataset. Kaggle [D4]Gene Expression54,676 probes AD: 87, CN: 74Log2 fold change, Expression profilesAlzheimer's Gene Expression Profiles. Kaggle [D5]</p>
<p>Table 2 : Summary of Single Modality Analysis Results
2ModalityKey FindingsStatisticalCorrelation withSignificanceCognitionMRIBrain volume reductionp&lt;0.01r=-0.72 with(12.3%)MMSECortical thickness reductionp&lt;0.01r≈0.5 (brain(15.7%)volume vsMMSE)EEGAlpha power reductionp&lt;0.05r=0.45 with(37.4%)cognitiveBeta power reductionp&lt;0.05performance(42.1%)Reduced inter-channelp&lt;0.01synchronization (28.3%)BiomarkersPhosphorylated tau increasep&lt;0.01tau/total tau ratio:(2.8-fold)AUC=0.89Neurofilament light increasep&lt;0.01(2.3-fold)Amyloid-tau correlationr=0.45,p&lt;0.01ClinicalAge-MMSE correlationr≈-0.5,N/AHypertension-BMIp&lt;0.001correlationr≈0.3,p&lt;0.05Gene10 genes with |log2 foldp&lt;0.01N/AExpressionchange|&gt;2</p>
<p>Table 3 : Classification Accuracy Across Modalities
3ModalityClassification AccuracyKey DiscriminatingFeaturesMRI75-80% (general)Brain Volume, Cortical83.5% (hippocampal)ThicknessEEG65-70%Frontal channel alpha/betapowerBiomarkersAUC=0.89Phosphorylated tau/totaltau ratioClinical70-75%Age,MMSE,BMI,HypertensionCombinedNot reportedN/A</p>
<p>Table 4 :
4
LLM-Generated Hypotheses with Consensus Ratings
HypothesisImpact ScoreSupporting EvidenceLLMConsensusMetabolic-4.2/5Edge weights &gt;0.6HighInflammatory-Taubetween metabolicacross allCascadenodes,modelsinflammatorymarkers, and tauEEG-Gene3.8/5CorrelationsModerateExpressionEarlybetweengeneticWarning Systemnodes and frontalEEG (r=0.42-0.58forGSM701343/344;weakforGSM701345)Genetic Influence on3.0/5AssociationsLow-Brain StructurebetweengeneModerateexpressionsandASF metricsNeuroinflammation-4.0/5CorrelationModerate-HippocampalbetweenHighAtrophy LinkinflammatorymarkersandhippocampalvolumeTau-Obesity-4.0/5ConnectionsModerate-VascularRiskbetween metabolicHighInteractionfactors and taupathology
AcknowledgmentThe authors acknowledge the use of LLMs, including Claude 3.7 Sonnet, ChatGPT 3.5, and Gemini 2.0 Flash, for assistance with grammar and structural editing of the manuscript text, as well as for generating data visualizations based on our research findings, besides the LLM model integration described in the Method section.All generated content was reviewed, verified, and approved by the authors before inclusion in this paper.This work was supported by IPUT Osaka for KA and KM, the Nitto Foundation, the Chubu University Grant K, and JSPS KAKENHI for YT, as well as by the UAEU for FAKANAN KIGUCHI was born in Okayama, Japan.She received her education at Osaka International University of Professional Sciences (IPUT Osaka) in the Faculty of Engineering, Department of Information Engineering, AI Strategy Course, where she was part of the first cohort at this newly established university.Her technical expertise includes Python, C/C++, Kotlin, JavaScript, HTML/CSS, and frameworks such as scikit-learn, TensorFlow, Keras, PyTorch, OpenCV, and various NLP tools.She has completed multiple internships, including roles at Matsuo Institute as a business strategist, NEL Inc. as a product manager, ZENKIGEN Inc. for data analysis, Apollo Inc. as a data scientist, and SoftBank for LLM technical verification.She has also participated in the "Solve for SDGs" project by the Japan Science and Technology Agency (JST), where she conducted research in the field of SDGs and technology in collaboration with Nagoya University and the University of Tsukuba.Ms. Kiguchi has received numerous awards throughout her academic career, including first place in national calligraphy competitions, the highest technical award in an international painting competition, and business contest awards such as the 2022 Winter KING Championship.She serves as the representative of the student organization Co-afl, which focuses on business contest participation and management.She is also active in the SoftBank Academia program since April 2024, where she was selected as the representative new student presenter to Masayoshi Son.Additionally, she has participated in marine business planning projects at the Nippon Foundation and has spoken at various events including TEDxTalk, the U-23 Summit, and events hosted by the Tokyo Metropolitan Government.
The global macroeconomic burden of Alzheimer's disease and other dementias: estimates and projections for 152 countries or territories. S Chen, Z Cao, A Nandi, N Counts, L Jiao, K Prettner, . . Bloom, D E , The Lancet Global Health. 1292024</p>
<p>The discovery of Alzheimer's disease. H Hippius, G Neundörfer, Dialogues in Clinical Neuroscience. 512003</p>
<p>Alzheimer disease. D S Knopman, H Amieva, R C Petersen, G Chételat, D M Holtzman, B T Hyman, . . Bradley, T Hyman, R A Nixon, D T Jones, Nature reviews Disease primers. 71332021</p>
<p>. Abdul Manap, A S Almadodi, R Sultana, S Sebastian, M G Kavani, K S Lyenouq, V E Shankar, A , 2024</p>
<p>Alzheimer's disease: A review on the current trends of the effective diagnosis and therapeutics. Frontiers in Aging Neuroscience. 161429211</p>
<p>The clinical use of structural MRI in Alzheimer disease. G B Frisoni, N C Fox, C R JackJr, P Scheltens, P M Thompson, Nature reviews neurology. 622010</p>
<p>Brain MRI image analysis for Alzheimer's disease (AD) prediction using deep learning approaches. A Singh, R Kumar, SN Computer Science. 511602024</p>
<p>Cognitive and MRI trajectories for prediction of Alzheimer's disease. S A Mofrad, A J Lundervold, A Vik, A S Lundervold, Scientific reports. 11121222021</p>
<p>Measures of resting state EEG rhythms for clinical trials in Alzheimer's disease: recommendations of an expert panel. C Babiloni, X Arakaki, H Azami, K Bennys, K Blinowska, L Bonanni, . . Guntekin, B , Alzheimer's &amp; Dementia. 1792021</p>
<p>A review of methods of diagnosis and complexity analysis of Alzheimer's disease using EEG signals. M Ouchani, S Gharibzadeh, M Jamshidi, M Amini, BioMed Research International. 2021154255692021</p>
<p>Molecular biomarkers of Alzheimer's disease: progress and prospects. T Lashley, J M Schott, P Weston, C E Murray, H Wellington, A Keshavan, . . Zetterberg, H , Disease models &amp; mechanisms. 115317812018</p>
<p>Data sharing in neurodegenerative disease research: challenges and learnings from the innovative medicines initiative public-private partnership model. A Bradshaw, N Hughes, D Vallez-Garcia, D Chokoshvili, A Owens, C Hansen, . . Steukers, L , Frontiers in neurology. 1411870952023</p>
<p>Revised criteria for diagnosis and staging of Alzheimer's disease: Alzheimer's Association Workgroup. C R JackJr, J S Andrews, T G Beach, T Buracchio, B Dunn, A Graf, . . Carrillo, M C , Alzheimer's &amp; Dementia. 2082024</p>
<p>Unifying large language models and knowledge graphs: A roadmap. S Pan, L Luo, Y Wang, C Chen, J Wang, X Wu, IEEE Transactions on Knowledge and Data Engineering. 3672024</p>
<p>Generalizable deep learning model for early Alzheimer's disease detection from structural MRIs. S Liu, A V Masurkar, H Rusinek, J Chen, B Zhang, W Zhu, . . Razavian, N , Scientific reports. 121171062022</p>
<p>Artificial intelligence for biomarker discovery in Alzheimer's disease and dementia. L M Winchester, E L Harshfield, L Shi, A Badhwar, A A Khleifat, N Clarke, . . Llewellyn, D J , Alzheimer's &amp; Dementia. 19122023</p>
<p>Genetic-based patient stratification in Alzheimer's disease. L Hernández-Lorenzo, F García-Gutiérrez, A Solbas-Casajús, S Corrochano, J A Matías-Guiu, J L Ayala, Scientific Reports. 14199702024</p>
<p>The ethics of ChatGPT in medicine and healthcare: a systematic review on Large Language Models (LLMs). npj. J Haltaufderheide, R Ranisch, 10.1038/s41746-024-01157-xDigit. Med. 71832024</p>
<p>Privacy-preserving artificial intelligence in healthcare: Techniques and applications. N Khalid, A Qayyum, M Bilal, A Al-Fuqaha, J Qadir, Computers in Biology and Medicine. 1581068482023</p>
<p>Salivary biomarkers for Alzheimer's disease: a systematic review with Meta-analysis. K Nijakowski, W Owecki, J Jankowski, A Surdacka, International Journal of Molecular Sciences. 25211682024</p>
<p>A survey of knowledge graph reasoning on graph types: Static, dynamic, and multi-modal. K Liang, L Meng, M Liu, Y Liu, W Tu, S Wang, . . He, K , IEEE Transactions on Pattern Analysis and Machine Intelligence. 2024</p>
<p>Multimodal foundation models: From specialists to general-purpose assistants. Foundations and Trends® in Computer Graphics and Vision. C Li, Z Gan, Z Yang, J Yang, L Li, L Wang, J Gao, 202416</p>
<p>Predicting the diagnosis of dementia from MRI data: added value to cognitive tests. T Habuza, N Zaki, Y Statsenko, F Alnajjar, S Elyassami, The 7th Annual International Conference on Arab Women in Computing in Conjunction with the 2nd Forum of Women in Research. 2021. August</p>
<p>Sources of Datasets used in this study. </p>
<p>A dataset of scalp EEG recordings of Alzheimer's disease, frontotemporal dementia and healthy subjects from routine EEG. A Miltiadous, Data. 8695May 2023</p>
<p>Plasma lipidomics in Alzheimer's disease. Kaggle. F Jozaghkar, Biomarkers. 2023</p>
<p>Alzheimer's Gene Expression Profiles. R El Kharoua, Gene Expression. 52023. 2022KaggleAlzheimer's Disease Dataset</p>            </div>
        </div>

    </div>
</body>
</html>