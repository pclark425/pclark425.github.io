<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1523 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1523</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1523</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-29.html">extraction-schema-29</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <p><strong>Paper ID:</strong> paper-04d65765bcbd8ad0cba8db50137a4bf97f900856</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/04d65765bcbd8ad0cba8db50137a4bf97f900856" target="_blank">Traversing the Reality Gap via Simulator Tuning</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> It is found that even optimised for different tasks that different physics engine perform better in certain scenarios and that friction and maximum actuator velocity are tightly bounded parameters that greatly impact the transference of simulated solutions.</p>
                <p><strong>Paper Abstract:</strong> The large demand for simulated data has made the reality gap a problem on the forefront of robotics. We propose a method to traverse the gap by tuning available simulation parameters. Through the optimisation of physics engine parameters, we show that we are able to narrow the gap between simulated solutions and a real world dataset, and thus allow more ready transfer of leaned behaviours between the two. We subsequently gain understanding as to the importance of specific simulator parameters, which is of broad interest to the robotic machine learning community. We find that even optimised for different tasks that different physics engine perform better in certain scenarios and that friction and maximum actuator velocity are tightly bounded parameters that greatly impact the transference of simulated solutions.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1523.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1523.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PyBullet</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PyBullet (Bullet physics via PyBullet Python module)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source physics simulator exposing the Bullet physics engine via a Python API; used here to simulate a Kinova 6DOF manipulator and object interactions for sim2real parameter tuning and evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Traversing the Reality Gap via Simulator Tuning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>PyBullet</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>A Python-accessible simulator that uses the Bullet rigid-body physics engine to model rigid-body dynamics, collisions and contacts, joint actuators, and simple material properties; intended for robotics, games and ML experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mechanics / robotics (rigid-body dynamics, contact mechanics)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>medium-fidelity rigid-body simulator: models gravity, rigid-body dynamics, collisions and contact forces with parameterized friction/restitution and discrete timesteps; actuator dynamics and some contact behaviours simplified compared to real hardware.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Includes gravity, collision response, lateral/rolling/sliding friction, restitution, joint limits, maximum joint velocity/torque, discrete timestep (configurable); simplified actuator models and sensor noise are not modelled in full detail; uses discrete time integration and solver settings that trade accuracy for compute.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Sim-to-real matching of robotic manipulation trajectories (wrist pose and final object placement) to a motion-capture dataset for manipulation and rolling-object tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>real-world motion-capture dataset / physical robot trajectories (Kinova manipulator and manipulated objects)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>Measured as Euclidean positional error between simulated and recorded wrist (and final object) trajectories; tuning PyBullet's parameters reduced error substantially for several tasks — e.g., for rolling-object tasks PyBullet's tuned fitness values were among the best (examples: Experiment 5 tuned fitness 0.0506, Experiment 6 tuned fitness 0.0552, units: positional error in dataset units). Overall tuning across engines produced improvements ranging from 14% (experiment 2) to 91% (experiment 6) compared to generic parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>Tuning simulator parameters (timestep, friction, max joint velocity, etc.) improved closeness-to-reality versus generic defaults. PyBullet performed best on several rolling-object tasks after tuning; no single engine was best for all tasks. Individual (larger) parameter sets sometimes made optimization harder and occasionally degraded results.</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Paper recommends at minimum: correct simulator timestep (use developer-recommended default), accurate lateral friction values for objects, and accurate maximum joint velocities per actuator; restitution matters for high-energy contacts. These features should be modelled accurately and not excessively randomized.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Generic PyBullet had very large errors (e.g. experiments 5 and 6: extremely large generic fitness values in Table II) before tuning for rolling tasks; individual (expanded) parameter tuning sometimes failed to converge or produced worse fitness due to higher dimensionality and noise; some PyBullet configurations required long compute time to converge.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Traversing the Reality Gap via Simulator Tuning', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1523.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1523.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>V-Rep</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>V-REP (CoppeliaSim) with multiple physics engines</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A versatile robot simulation framework (now CoppeliaSim) that can host several physics engines (Bullet, ODE, Newton) and provides a high-level interface for scene descriptions and scripting; used here with PyRep to run the dataset scenes and tune physics parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Traversing the Reality Gap via Simulator Tuning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>V-REP (CoppeliaSim)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>A robotics simulator providing scene management, scripting and interfaces to multiple underlying physics engines (Bullet versions, ODE, Newton) allowing comparison of engine behaviours while keeping a common scene/API.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mechanics / robotics (rigid-body dynamics, contact mechanics)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>medium-fidelity robotics simulation framework with per-engine fidelity depending on selected physics engine; abstracts physics engines and provides scripting/API; fidelity depends on chosen engine and engine parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Exposes parameters for timestep, friction (lateral/rolling/sliding), restitution, damping, mass/inertia, joint damping/limits, solver settings; some parameters require embedded scripts to access; simplified actuator and sensor modelling typical of rigid-body simulators.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Matching simulated manipulator and object trajectories to a motion-capture ground-truth dataset for sim2real evaluation across multiple physics engines.</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>real-world motion-capture dataset / physical robot trajectories</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>Tuned V-REP setups (using different physics engines) reduced Euclidean pose errors relative to generic settings. Performance depended on the chosen underlying engine (see per-engine entries); e.g., ODE achieved best tuned result on combined task (Experiment 11 best tuned fitness 1.7360), while Newton and Bullet variants performed better on specific tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>Because V-REP allows different physics engines, the paper shows that engine choice + parameter tuning matters: Newton was best for pure kinematics tasks, Bullet variants excelled in some object interactions, and ODE showed best results on certain experiments and the combined task. Tuning shared parameters consistently improved realism over generic defaults.</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Recommends ensuring correct timestep, object friction and actuator velocity parameters within V-REP; these are the most critical to achieve transfer for the tasks studied.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Some V-REP engine+parameter combinations produced noisy optimization landscapes (especially Bullet 2.78/2.83) leading to many generations and sometimes failing to converge within compute limits; not all engines model interactions equally well (Newton was faster to optimize but less accurate for object interactions).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Traversing the Reality Gap via Simulator Tuning', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1523.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1523.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bullet (2.78 / 2.83 / 2.85)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bullet physics engine (versions 2.78, 2.83, 2.85)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A widely-used open-source rigid-body physics engine used in both PyBullet and V-REP to simulate collisions, contacts and rigid-body dynamics; multiple versions were compared and tuned in this study.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Traversing the Reality Gap via Simulator Tuning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>Bullet (2.78 / 2.83 / 2.85)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>A rigid-body physics engine modeling collisions, contacts, friction, restitution, joint constraints and basic actuator parameters; available via PyBullet and as a backend in V-REP; offers tunable solver/time-step parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mechanics / robotics (rigid-body dynamics, contact mechanics)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>medium-fidelity rigid-body engine with tunable contact/friction/restitution and solver/timestep settings; models contact responses but simplifies complex contact phenomena and actuator dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Parameterizable timestep, friction types (lateral/rolling/sliding), restitution, damping, mass/inertia and joint limits; uses discrete time integration and iterative solvers; actuator dynamics simplified to torque/velocity limits in this work.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Sim-to-real alignment of manipulator and object trajectories (trajectory matching, object final placement) across diverse manipulation tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>real-world motion-capture dataset / physical robot</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>Tuned Bullet variants achieved low Euclidean errors on several tasks (e.g., Bullet 2.78 best on Experiment 3 with tuned fitness 0.0498; Bullet 2.83 best on Experiment 4 with tuned fitness 0.0629). Overall tuning reduced errors vs generic settings; improvements varied by task and engine version.</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>Different Bullet versions exhibited different performance per task after tuning; Bullet variants were among the best for certain object interactions. The study shows engine-version-dependent behaviour and that parameter tuning is necessary to approach reality.</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Accurate timestep and friction settings are critical; actuator velocity bounds also important; restitution matters for higher-energy contacts.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Bullet engines (particularly 2.78/2.83 in V-REP) sometimes produced noisy fitness landscapes that required many generations (often hitting 1000 generation cap) indicating optimization and fidelity challenges; without tuning Bullet could produce large errors on some tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Traversing the Reality Gap via Simulator Tuning', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1523.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1523.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ODE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Open Dynamics Engine (ODE)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source rigid-body dynamics engine used via V-REP in this study; models rigid-body dynamics, collisions and contacts with configurable parameters and solver settings.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Traversing the Reality Gap via Simulator Tuning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>ODE (Open Dynamics Engine)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>A rigid-body physics engine emphasizing articulated dynamics and collision/contact handling, accessible through V-REP; provides tunable friction, restitution, timestep, damping and joint parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mechanics / robotics (rigid-body dynamics, contact mechanics)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>medium-fidelity engine: models rigid-body dynamics and contacts with parameterized properties; simpler actuator/contact modeling relative to high-fidelity multi-physics simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Includes friction, restitution, damping, solver and timestep parameters; models contact and joint constraints but simplifies actuator dynamics and detailed material deformation.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Aligning simulated manipulator and object motion to motion-capture ground-truth for multiple manipulation tasks including kinematics and object interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>real-world motion-capture dataset / physical robot</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>ODE yielded some of the best tuned results for certain tasks (e.g., Experiments 9 and 10 tuned fitness ~0.0519 and 0.0503 respectively; Experiment 11 combined best tuned fitness 1.7360). Tuning reduced errors relative to generic defaults across experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>ODE performed strongly on several interaction and combined tasks after tuning; again, no single engine dominated across all task types. Shared-parameter tuning reliably improved performance across engines including ODE.</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Paper highlights the need for accurate timestep, lateral friction and joint velocity parameters in ODE to achieve realistic transfer; restitution important for high-energy contacts.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Some experiments remain challenging; combined experiment (11) still had larger residual error after tuning compared to single-task tuning, indicating limits to fidelity for generalisation across diverse tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Traversing the Reality Gap via Simulator Tuning', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1523.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1523.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Newton</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Newton Game Dynamics (Newton physics engine)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A physics engine accessible through V-REP used in this study; shown to be fast to optimize and relatively accurate for pure arm kinematics but less accurate for complex object interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Traversing the Reality Gap via Simulator Tuning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>Newton (physics engine)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>A rigid-body physics engine modeling collisions and dynamics; integrated via V-REP in the experiments; provides basic parameter controls (timestep, friction, restitution) and solver behaviors.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mechanics / robotics (rigid-body dynamics, contact mechanics)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>medium-fidelity engine with efficient simulation and simplified contact/interaction modeling; faster to optimize but may under-model complex contacts compared to other engines.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Supports timestep, friction and joint parameter tuning; tends to have less noisy search landscapes (fewer generations to converge) but less accurate object interaction fidelity in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Simulation of manipulator kinematics and simple interactions to match motion-capture trajectories and assess sim2real gap.</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>real-world motion-capture dataset / physical robot</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>Newton provided the best tuned performance for pure kinematics tasks (Experiments 1 and 2 tuned fitness 0.0973 and 0.0984 respectively) and was fastest to optimize (least compute hours), but was less accurate for object interaction tasks compared to some other engines.</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>Newton is easier to optimize (fewer generations) and good for kinematic-only tasks, whereas engines like PyBullet or ODE provide better interaction fidelity on tasks involving rolling or contact.</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Paper implies Newton's fidelity is sufficient for kinematics but recommends more detailed friction/actuator modeling for object interaction tasks; thus minimal fidelity depends on task complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Newton, while fast, 'does not provide accurate environmental interactions' compared with other physics engines — i.e., its lower fidelity for contacts can cause poorer transfer for manipulation tasks with object interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Traversing the Reality Gap via Simulator Tuning', 'publication_date_yy_mm': '2020-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Benchmarking Simulated Robotic Manipulation through a Real World Dataset <em>(Rating: 2)</em></li>
                <li>Quantifying the Reality Gap in Robotic Manipulation Tasks <em>(Rating: 2)</em></li>
                <li>Sim-to-Real: Learning Agile Locomotion For Quadruped Robots <em>(Rating: 2)</em></li>
                <li>Learning dexterous in-hand manipulation <em>(Rating: 2)</em></li>
                <li>Sim-to-real transfer of robotic control with dynamics randomization <em>(Rating: 2)</em></li>
                <li>Closing the Sim-to-Real Loop: Adapting Simulation Randomization with Real World Experience <em>(Rating: 2)</em></li>
                <li>Training Deep Networks with Synthetic Data: Bridging the Reality Gap by Domain Randomization <em>(Rating: 1)</em></li>
                <li>Gait optimization for roombots modular robots Matching simulation and reality <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1523",
    "paper_id": "paper-04d65765bcbd8ad0cba8db50137a4bf97f900856",
    "extraction_schema_id": "extraction-schema-29",
    "extracted_data": [
        {
            "name_short": "PyBullet",
            "name_full": "PyBullet (Bullet physics via PyBullet Python module)",
            "brief_description": "An open-source physics simulator exposing the Bullet physics engine via a Python API; used here to simulate a Kinova 6DOF manipulator and object interactions for sim2real parameter tuning and evaluation.",
            "citation_title": "Traversing the Reality Gap via Simulator Tuning",
            "mention_or_use": "use",
            "simulator_name": "PyBullet",
            "simulator_description": "A Python-accessible simulator that uses the Bullet rigid-body physics engine to model rigid-body dynamics, collisions and contacts, joint actuators, and simple material properties; intended for robotics, games and ML experiments.",
            "scientific_domain": "mechanics / robotics (rigid-body dynamics, contact mechanics)",
            "fidelity_level": "medium-fidelity rigid-body simulator: models gravity, rigid-body dynamics, collisions and contact forces with parameterized friction/restitution and discrete timesteps; actuator dynamics and some contact behaviours simplified compared to real hardware.",
            "fidelity_characteristics": "Includes gravity, collision response, lateral/rolling/sliding friction, restitution, joint limits, maximum joint velocity/torque, discrete timestep (configurable); simplified actuator models and sensor noise are not modelled in full detail; uses discrete time integration and solver settings that trade accuracy for compute.",
            "model_or_agent_name": null,
            "model_description": null,
            "reasoning_task": "Sim-to-real matching of robotic manipulation trajectories (wrist pose and final object placement) to a motion-capture dataset for manipulation and rolling-object tasks.",
            "training_performance": null,
            "transfer_target": "real-world motion-capture dataset / physical robot trajectories (Kinova manipulator and manipulated objects)",
            "transfer_performance": "Measured as Euclidean positional error between simulated and recorded wrist (and final object) trajectories; tuning PyBullet's parameters reduced error substantially for several tasks — e.g., for rolling-object tasks PyBullet's tuned fitness values were among the best (examples: Experiment 5 tuned fitness 0.0506, Experiment 6 tuned fitness 0.0552, units: positional error in dataset units). Overall tuning across engines produced improvements ranging from 14% (experiment 2) to 91% (experiment 6) compared to generic parameters.",
            "compares_fidelity_levels": true,
            "fidelity_comparison_results": "Tuning simulator parameters (timestep, friction, max joint velocity, etc.) improved closeness-to-reality versus generic defaults. PyBullet performed best on several rolling-object tasks after tuning; no single engine was best for all tasks. Individual (larger) parameter sets sometimes made optimization harder and occasionally degraded results.",
            "minimal_fidelity_discussion": "Paper recommends at minimum: correct simulator timestep (use developer-recommended default), accurate lateral friction values for objects, and accurate maximum joint velocities per actuator; restitution matters for high-energy contacts. These features should be modelled accurately and not excessively randomized.",
            "failure_cases": "Generic PyBullet had very large errors (e.g. experiments 5 and 6: extremely large generic fitness values in Table II) before tuning for rolling tasks; individual (expanded) parameter tuning sometimes failed to converge or produced worse fitness due to higher dimensionality and noise; some PyBullet configurations required long compute time to converge.",
            "uuid": "e1523.0",
            "source_info": {
                "paper_title": "Traversing the Reality Gap via Simulator Tuning",
                "publication_date_yy_mm": "2020-03"
            }
        },
        {
            "name_short": "V-Rep",
            "name_full": "V-REP (CoppeliaSim) with multiple physics engines",
            "brief_description": "A versatile robot simulation framework (now CoppeliaSim) that can host several physics engines (Bullet, ODE, Newton) and provides a high-level interface for scene descriptions and scripting; used here with PyRep to run the dataset scenes and tune physics parameters.",
            "citation_title": "Traversing the Reality Gap via Simulator Tuning",
            "mention_or_use": "use",
            "simulator_name": "V-REP (CoppeliaSim)",
            "simulator_description": "A robotics simulator providing scene management, scripting and interfaces to multiple underlying physics engines (Bullet versions, ODE, Newton) allowing comparison of engine behaviours while keeping a common scene/API.",
            "scientific_domain": "mechanics / robotics (rigid-body dynamics, contact mechanics)",
            "fidelity_level": "medium-fidelity robotics simulation framework with per-engine fidelity depending on selected physics engine; abstracts physics engines and provides scripting/API; fidelity depends on chosen engine and engine parameters.",
            "fidelity_characteristics": "Exposes parameters for timestep, friction (lateral/rolling/sliding), restitution, damping, mass/inertia, joint damping/limits, solver settings; some parameters require embedded scripts to access; simplified actuator and sensor modelling typical of rigid-body simulators.",
            "model_or_agent_name": null,
            "model_description": null,
            "reasoning_task": "Matching simulated manipulator and object trajectories to a motion-capture ground-truth dataset for sim2real evaluation across multiple physics engines.",
            "training_performance": null,
            "transfer_target": "real-world motion-capture dataset / physical robot trajectories",
            "transfer_performance": "Tuned V-REP setups (using different physics engines) reduced Euclidean pose errors relative to generic settings. Performance depended on the chosen underlying engine (see per-engine entries); e.g., ODE achieved best tuned result on combined task (Experiment 11 best tuned fitness 1.7360), while Newton and Bullet variants performed better on specific tasks.",
            "compares_fidelity_levels": true,
            "fidelity_comparison_results": "Because V-REP allows different physics engines, the paper shows that engine choice + parameter tuning matters: Newton was best for pure kinematics tasks, Bullet variants excelled in some object interactions, and ODE showed best results on certain experiments and the combined task. Tuning shared parameters consistently improved realism over generic defaults.",
            "minimal_fidelity_discussion": "Recommends ensuring correct timestep, object friction and actuator velocity parameters within V-REP; these are the most critical to achieve transfer for the tasks studied.",
            "failure_cases": "Some V-REP engine+parameter combinations produced noisy optimization landscapes (especially Bullet 2.78/2.83) leading to many generations and sometimes failing to converge within compute limits; not all engines model interactions equally well (Newton was faster to optimize but less accurate for object interactions).",
            "uuid": "e1523.1",
            "source_info": {
                "paper_title": "Traversing the Reality Gap via Simulator Tuning",
                "publication_date_yy_mm": "2020-03"
            }
        },
        {
            "name_short": "Bullet (2.78 / 2.83 / 2.85)",
            "name_full": "Bullet physics engine (versions 2.78, 2.83, 2.85)",
            "brief_description": "A widely-used open-source rigid-body physics engine used in both PyBullet and V-REP to simulate collisions, contacts and rigid-body dynamics; multiple versions were compared and tuned in this study.",
            "citation_title": "Traversing the Reality Gap via Simulator Tuning",
            "mention_or_use": "use",
            "simulator_name": "Bullet (2.78 / 2.83 / 2.85)",
            "simulator_description": "A rigid-body physics engine modeling collisions, contacts, friction, restitution, joint constraints and basic actuator parameters; available via PyBullet and as a backend in V-REP; offers tunable solver/time-step parameters.",
            "scientific_domain": "mechanics / robotics (rigid-body dynamics, contact mechanics)",
            "fidelity_level": "medium-fidelity rigid-body engine with tunable contact/friction/restitution and solver/timestep settings; models contact responses but simplifies complex contact phenomena and actuator dynamics.",
            "fidelity_characteristics": "Parameterizable timestep, friction types (lateral/rolling/sliding), restitution, damping, mass/inertia and joint limits; uses discrete time integration and iterative solvers; actuator dynamics simplified to torque/velocity limits in this work.",
            "model_or_agent_name": null,
            "model_description": null,
            "reasoning_task": "Sim-to-real alignment of manipulator and object trajectories (trajectory matching, object final placement) across diverse manipulation tasks.",
            "training_performance": null,
            "transfer_target": "real-world motion-capture dataset / physical robot",
            "transfer_performance": "Tuned Bullet variants achieved low Euclidean errors on several tasks (e.g., Bullet 2.78 best on Experiment 3 with tuned fitness 0.0498; Bullet 2.83 best on Experiment 4 with tuned fitness 0.0629). Overall tuning reduced errors vs generic settings; improvements varied by task and engine version.",
            "compares_fidelity_levels": true,
            "fidelity_comparison_results": "Different Bullet versions exhibited different performance per task after tuning; Bullet variants were among the best for certain object interactions. The study shows engine-version-dependent behaviour and that parameter tuning is necessary to approach reality.",
            "minimal_fidelity_discussion": "Accurate timestep and friction settings are critical; actuator velocity bounds also important; restitution matters for higher-energy contacts.",
            "failure_cases": "Bullet engines (particularly 2.78/2.83 in V-REP) sometimes produced noisy fitness landscapes that required many generations (often hitting 1000 generation cap) indicating optimization and fidelity challenges; without tuning Bullet could produce large errors on some tasks.",
            "uuid": "e1523.2",
            "source_info": {
                "paper_title": "Traversing the Reality Gap via Simulator Tuning",
                "publication_date_yy_mm": "2020-03"
            }
        },
        {
            "name_short": "ODE",
            "name_full": "Open Dynamics Engine (ODE)",
            "brief_description": "An open-source rigid-body dynamics engine used via V-REP in this study; models rigid-body dynamics, collisions and contacts with configurable parameters and solver settings.",
            "citation_title": "Traversing the Reality Gap via Simulator Tuning",
            "mention_or_use": "use",
            "simulator_name": "ODE (Open Dynamics Engine)",
            "simulator_description": "A rigid-body physics engine emphasizing articulated dynamics and collision/contact handling, accessible through V-REP; provides tunable friction, restitution, timestep, damping and joint parameters.",
            "scientific_domain": "mechanics / robotics (rigid-body dynamics, contact mechanics)",
            "fidelity_level": "medium-fidelity engine: models rigid-body dynamics and contacts with parameterized properties; simpler actuator/contact modeling relative to high-fidelity multi-physics simulations.",
            "fidelity_characteristics": "Includes friction, restitution, damping, solver and timestep parameters; models contact and joint constraints but simplifies actuator dynamics and detailed material deformation.",
            "model_or_agent_name": null,
            "model_description": null,
            "reasoning_task": "Aligning simulated manipulator and object motion to motion-capture ground-truth for multiple manipulation tasks including kinematics and object interactions.",
            "training_performance": null,
            "transfer_target": "real-world motion-capture dataset / physical robot",
            "transfer_performance": "ODE yielded some of the best tuned results for certain tasks (e.g., Experiments 9 and 10 tuned fitness ~0.0519 and 0.0503 respectively; Experiment 11 combined best tuned fitness 1.7360). Tuning reduced errors relative to generic defaults across experiments.",
            "compares_fidelity_levels": true,
            "fidelity_comparison_results": "ODE performed strongly on several interaction and combined tasks after tuning; again, no single engine dominated across all task types. Shared-parameter tuning reliably improved performance across engines including ODE.",
            "minimal_fidelity_discussion": "Paper highlights the need for accurate timestep, lateral friction and joint velocity parameters in ODE to achieve realistic transfer; restitution important for high-energy contacts.",
            "failure_cases": "Some experiments remain challenging; combined experiment (11) still had larger residual error after tuning compared to single-task tuning, indicating limits to fidelity for generalisation across diverse tasks.",
            "uuid": "e1523.3",
            "source_info": {
                "paper_title": "Traversing the Reality Gap via Simulator Tuning",
                "publication_date_yy_mm": "2020-03"
            }
        },
        {
            "name_short": "Newton",
            "name_full": "Newton Game Dynamics (Newton physics engine)",
            "brief_description": "A physics engine accessible through V-REP used in this study; shown to be fast to optimize and relatively accurate for pure arm kinematics but less accurate for complex object interactions.",
            "citation_title": "Traversing the Reality Gap via Simulator Tuning",
            "mention_or_use": "use",
            "simulator_name": "Newton (physics engine)",
            "simulator_description": "A rigid-body physics engine modeling collisions and dynamics; integrated via V-REP in the experiments; provides basic parameter controls (timestep, friction, restitution) and solver behaviors.",
            "scientific_domain": "mechanics / robotics (rigid-body dynamics, contact mechanics)",
            "fidelity_level": "medium-fidelity engine with efficient simulation and simplified contact/interaction modeling; faster to optimize but may under-model complex contacts compared to other engines.",
            "fidelity_characteristics": "Supports timestep, friction and joint parameter tuning; tends to have less noisy search landscapes (fewer generations to converge) but less accurate object interaction fidelity in experiments.",
            "model_or_agent_name": null,
            "model_description": null,
            "reasoning_task": "Simulation of manipulator kinematics and simple interactions to match motion-capture trajectories and assess sim2real gap.",
            "training_performance": null,
            "transfer_target": "real-world motion-capture dataset / physical robot",
            "transfer_performance": "Newton provided the best tuned performance for pure kinematics tasks (Experiments 1 and 2 tuned fitness 0.0973 and 0.0984 respectively) and was fastest to optimize (least compute hours), but was less accurate for object interaction tasks compared to some other engines.",
            "compares_fidelity_levels": true,
            "fidelity_comparison_results": "Newton is easier to optimize (fewer generations) and good for kinematic-only tasks, whereas engines like PyBullet or ODE provide better interaction fidelity on tasks involving rolling or contact.",
            "minimal_fidelity_discussion": "Paper implies Newton's fidelity is sufficient for kinematics but recommends more detailed friction/actuator modeling for object interaction tasks; thus minimal fidelity depends on task complexity.",
            "failure_cases": "Newton, while fast, 'does not provide accurate environmental interactions' compared with other physics engines — i.e., its lower fidelity for contacts can cause poorer transfer for manipulation tasks with object interactions.",
            "uuid": "e1523.4",
            "source_info": {
                "paper_title": "Traversing the Reality Gap via Simulator Tuning",
                "publication_date_yy_mm": "2020-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Benchmarking Simulated Robotic Manipulation through a Real World Dataset",
            "rating": 2
        },
        {
            "paper_title": "Quantifying the Reality Gap in Robotic Manipulation Tasks",
            "rating": 2
        },
        {
            "paper_title": "Sim-to-Real: Learning Agile Locomotion For Quadruped Robots",
            "rating": 2
        },
        {
            "paper_title": "Learning dexterous in-hand manipulation",
            "rating": 2
        },
        {
            "paper_title": "Sim-to-real transfer of robotic control with dynamics randomization",
            "rating": 2
        },
        {
            "paper_title": "Closing the Sim-to-Real Loop: Adapting Simulation Randomization with Real World Experience",
            "rating": 2
        },
        {
            "paper_title": "Training Deep Networks with Synthetic Data: Bridging the Reality Gap by Domain Randomization",
            "rating": 1
        },
        {
            "paper_title": "Gait optimization for roombots modular robots Matching simulation and reality",
            "rating": 1
        }
    ],
    "cost": 0.01362975,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Traversing the Reality Gap via Simulator Tuning</h1>
<p>Jack Collins ${ }^{1,2}$, Ross Brown ${ }^{2}$, Jürgen Leitner ${ }^{2,3,4}$ and David Howard ${ }^{1}$</p>
<h4>Abstract</h4>
<p>The large demand for simulated data has made the reality gap a problem on the forefront of robotics. We propose a method to traverse the gap by tuning available simulation parameters. Through the optimisation of physics engine parameters, we show that we are able to narrow the gap between simulated solutions and a real world dataset, and thus allow more ready transfer of leaned behaviours between the two. We subsequently gain understanding as to the importance of specific simulator parameters, which is of broad interest to the robotic machine learning community. We find that even optimised for different tasks that different physics engine perform better in certain scenarios and that friction and maximum actuator velocity are tightly bounded parameters that greatly impact the transference of simulated solutions.</p>
<p>Index Terms-Reality Gap, sim2real, Differential Evolution, Simulator</p>
<h2>I. INTRODUCTION</h2>
<p>Physics simulations attempt to model some pertinent facets of the real world in software. Simulations are necessarily simplified for computational feasibility, yet reflect real-world phenomena at a given level of veracity, the extent of which is the result of a trade-off between accuracy and computational time. In the domain of robotics, rigid-body simulators are frequently used as a large proportion of robots can be wellmodelled as rigid bodies. Robotics simulators reproduce the most important physical phenomena (i.e. gravity, collisions, etc.) but replace detailed modelling of complex phenomena with computationally faster, less accurate high-level representations and constraints. Robotics simulations variously rely on the replication of phenomena that are difficult to accurately replicate, e.g., simulating actuators (i.e. torque characteristics, gear backlash, ...), sensors (i.e. noise, latency, ...), and rendered images (i.e. reflections, refraction, textures, ...). This gap between reality and simulation is commonly referred to as the "Reality Gap".</p>
<p>Although conducting research in simulation means having to overcome the reality gap, the associated pros outweigh the cons for many learning-based approaches. In simulation there is no risk of damaging hardware whilst having access to robots that are not physically available. In addition, many instantiations of a scene can be run in parallel potentially faster than real-time, and human intervention is not required to manage experiments. With the current surge in data-driven techniques like Deep Learning, simulation data is either a prerequisite to using such techniques, or at least a more attainable</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Fig. 1. 3D plot of a robotic manipulators end effector trajectory comparing (i) real world, (ii) untuned simulator, and (iii) tuned simulator. See magnified Excerpt A which visualises the advantages of the tuned simulation over the generic simulation.
alternative to the (generally) expensive, laborious and nonscaleable collection of real-world data.</p>
<p>Of course, working in simulation only makes sense if the eventually-learned behaviour can transfer to reality. Sim2real research aspires to make any simulated behaviour seamlessly transfer to hardware and operate in real-world conditions. There are three prevalent ideologies within the sim2real community for overcome the reality gap, (i) data-driven improvement of simulation, (ii) generation of robust controllers, and (iii) a hybrid approach combining (i) and (ii). (i) augments the simulation with real-world data. This approach suffers as collection of data from the real world remains expensive. In comparison, (ii) must expose a controller to a wide range of environments through the randomisation of a subset of</p>
<p>simulation parameters or introduction of noise. Due to the controller being exposed to both realistic and (a large number of) unrealistic scenarios the creation of such controllers is time consuming. (iii) attempts to mitigate the disadvantages of collecting real world data by hand and simulating a large number of unrealistic training scenes but in doing so adds the complexity of integrating simulation and the real world into a single workflow.</p>
<p>In this work we build on past research that describes a method for recording data for comparison between reality and simulation [1], as well as the provision of metrics for a principled, numerical quantification of the differences between simulation and reality. Our extension investigates the optimisation of simulation parameters towards the goal of achieving real world simulation performance. We show that our approach is able to attain better performance than generic simulator parameters (as visualised in Figure 1) and is a promising method for traversing the reality gap. Our contributions aside from a method to optimise simulator parameters include an analysis as to the most influential parameters in achieving real world results.</p>
<p>The motivation for our work is to inform researchers and those applying sim2real techniques as to the important parameters to tune in simulation. As an extension of the results, further conclusions can be drawn as to the best data to collect from the real world to make realistic simulations, the parameters to randomise and the extent of learning approach refinement.</p>
<p>The question we endeavour to answer is; what are the simulation parameters that are most influential in arriving at a realistic simulation? Our experimentation involves optimising two popular rigid body simulators used by the robotics community to faithfully replicate the results of a series of tasks conducted by a real robot in a motion capture system. The tasks are a range of kinematic movements and object interactions performed by a robotic manipulator, and the results of this 'ground truth' are available as a publiclyaccessible dataset [2]. Optimisation of simulator parameters is via differential evolution, an Evolutionary Algorithm that performs well on high-dimensional optimisation problems.</p>
<h2>II. BACKGROUND</h2>
<h2>A. Simulation and Physics Engines</h2>
<p>Rigid-body simulators are a class of simulators that simplify the world into rigid objects that are potentially connected through (actuated or unactuated) joints. The use of rigid-body simulators is prevalent in robotics due to the widespread use of rigid robots in the field. Simulators are often modular, with the simulator acting as a high level interface, typically including a graphical user interface, API accessibility from external programming languages, plugins, importers, and scene description formats [3].</p>
<p>Robotic simulators utilise one or more of a number of physics engines. Common physics engines include Bullet [4], Dynamic Animation and Robotics Toolkit (DART) [5] and Open Dynamics Engine (ODE) [6], all of which are licensed under free software licenses. The physics engine operates below the simulator with the goal of providing physically accurate movement of objects instantiated in the simulator.</p>
<p>A multitude of user definable parameters are available to be tuned, however the exact number varies between engines and implementations. Parameters relate to the visual aspects (colours, textures, etc. ), material properties (frictions, restitution, etc.), object properties (mass, inertia, etc.), joint characteristics (type of constraint, actuation, etc.) and other more general physics engine properties (time step, solver settings, dampening, etc.). Although a large tunable parameter space represents an opportunity to adapt a physics engine to accurately replicate real-world conditions, it also results in a high-dimensional optimisation problem, where the effects of varying parts of this parameter space on simulator performance is not intuitive.</p>
<h2>B. Reality Gap</h2>
<p>With the well accepted problem of the reality gap the only way currently to guarantee a solution will perform as expected in reality is to create the solution in reality, to this end testrigs are a proven method for overcoming some of the issues associated with working in the real world [7], [8]. There are a range of approaches that have been raised in the past to cross the reality gap starting most notably with Jakobi et al. [9] using targeted noise to generate robust controllers. Other sim2real approaches have focused on tuning controllers [10], optimising transferable controllers [11], adding perturbations to the environment [12] and learning the target platforms actuator responses [13].</p>
<p>There are several methods of overcoming the reality gap using real-world data augmentation. The most common is to alter the generic simulator settings with more accurate parameters that are collected from real world measurements, derived from calculations, from researched values or experimentally [12], [14], [15]. Oftentimes parameters such as weight, physical dimensions, frictional coefficients, centre of mass, inertial properties, actuator control properties and more are used [16], [17]. Another common practice is to substitute a more accurate model of an actuator derived from the response of the physical robot or parameters from system identification, examples of this include work by Andrychowicz et al. [18] and Tan et al. [12].</p>
<p>To update parameters using recorded data there are several documented approaches with a portion of these updating simulation parameters live. One example of live parameter updates is by Moeckel et al. using a Kinect sensor coupled with background subtraction [19] to detect gait transference. Although motion capture systems that give accurate 6DOF pose are becoming increasingly common equipment in research labs, few methods have been reported that use them [18].</p>
<p>Domain randomisation is currently the most popular method for overcoming the reality gap in the machine learning domain. The parameters to be randomised are chosen according to the policy which is being learned, tasks that are entirely</p>
<p>visual or require computer vision focus on randomising the visual characteristics of a simulation (i.e. parameters relating to cameras, colours, textures, lighting, etc.) [20]. A policy that requires environmental interactions will randomise physical properties (i.e. mass, inertia, friction, etc. ) [21]. Randomised parameters are bounded with limits at initialisation which are hand picked by the user, these are often plausible ranges that will be found within the real world, although not necessarily accurate to the operating conditions of the target robot and environment.</p>
<p>By presenting such varied scenes to an agent, extensive amounts of time are required to learn. In particular, slow initial learning rates are noted, and approaches have attempted to overcome this by progressively increasing the variation experienced [22]. Accurate parameter ranges that are specific to the parameter settings would further reduce the landscape and lead to quicker training times, and this is one contribution of our work.</p>
<h2>C. Parameter Optimisation</h2>
<p>As discussed there are a large number of available parameters to optimise when applied to simulators and physics engines. As rigid-body simulators commonly used in robotics are non-differentiable [23] the optimisation of parameters relies on gradient free algorithms. Bayesian optimisation was considered for the task of finding a global minimum as it provides an efficient sampling method requiring reduced simulation evaluations [24]. However, Bayesian optimisation is limited in the number of variables it is able to optimise, common practice is to optimise up to 10 [25]. Extensions of Bayesian Optimisation have seen this extended further up to 30 variables using drop out [26].</p>
<p>Evolutionary Algorithms (EAs) are another class of blackbox optimisation algorithms that have been applied to problems with larger search spaces. Differential Evolution (DE) [27] is a popular EA, a global optimiser this is easily parallelisable and able to scale to a large number of variables. Algorithmic parameters for tuning include crossover rate $C R$, mutation weight $F$ and population size $N$ [28]. A good value for $C R$ has been found to be between 0.3 and 0.9 according to Ronkkonen et al. [29]. The population size is closely related to the mutation parameters, with problem dimensionality and problem properties also affecting the choice in population size. The recommended population size for $30-50$ dimension problems is $3 d-5 d$ from a review conducted by Piotrowski [30].</p>
<h2>III. Methodology</h2>
<p>Our approach to simulator optimisation can be segmented into several components as listed below:</p>
<ul>
<li>Real World Dataset Collection (Section III-A)</li>
<li>Robotic Simulations (Section III-B)</li>
<li>Simulator Parameter Selection (Section III-C)</li>
<li>Running the Optimisation Algorithm (Section III-D)</li>
</ul>
<h2>A. Dataset</h2>
<p>Our dataset is a publicly available collection of tasks completed by a robotic manipulator and recorded by a motion capture system [2]. The data gives a ground truth of the real world with 6DOF pose of the manipulator and manipulated objects recorded. There are 10 tasks in total, 2 of which are pure kinematics (no objects) and 8 of which involve nonprehensile manipulation. Tasks are purposefully elementary as they are foundational to larger compound tasks, making results derived from these tasks scale to harder and more complex applications. The manipulation tasks have interactions with objects including cubes, cuboids, cylinders and cones. Another useful property of the dataset is the contrast in object materials, with half the interaction tasks completed with plastic objects and the other half with exact wooden replicas. For a complete description of the dataset and its use in benchmarking reality, please see [2].</p>
<p>The dataset is released with simulation protocols that allow users to simulate the same scene and same control of the robot arm that is used in reality. All scenes use a levelled plane with a Kinova 6DOF robotic arm attached with KG-3 gripper and either none or one object to manipulate. Dataset users must follow the explicit instructions on scene setup, robot configuration and motor controls, but are able to change any of the other user definable parameters of their chosen simulator and physics engine.</p>
<h2>B. Simulation</h2>
<p>We selected two popular robotic simulators; PyBullet (version 2.5.8) [4] and V-Rep (version 3.6.2 now known as CoppeliaSim) [31], accessed through the PyRep interface [32]. The two simulators are chosen as they provide a common interface, and also provide easy access to a multitude of physics engines. Pybullet uses Bullet 2.85 whilst V-Rep uses Bullet 2.83 and Bullet 2.78. V-Rep also provides access to ODE and Newton physics.</p>
<p>PyBullet exposes a large number of settings to the user natively. V-Rep has an abstraction layer between the simulator and physics engines making it possible to interface with multiple different engines. Most of the same parameters accessible to the PyBullet interface are available in the V-Rep physics engines. However, as we use the PyRep interface not all parameters we require are accessible from the external API therefore we use embedded scripts within the simulator which are invoked from PyRep.</p>
<h2>C. Parameters</h2>
<p>From the 5 different physics engines available (including the 3 versions of Bullet) there are many parameters that create the same effect on the physics of the simulation that are either implemented using different methods, or different units. As such it was necessary to find the shared parameters that were directly comparable between physics engines, and settings that were not. We used two approaches; in the first we compared only those parameters available across all simulations and physics engines (Shared). In the second we allow each to</p>
<p>tune a fuller range of parameters that may be available (Individual). Table I documents all the Shared parameters and the Individual parameters that we chose to simulate. The Individual parameter optimisation included both the Shared and Individual parameters.</p>
<p>It would be infeasible to tune all available parameters. As positions (x,y,z), rotations (x,y,z,w) and inertias (xx,yy,zz) require multiple parameters each, it was impractical to create variables for the centre of masses, inertia position, inertia rotation and inertia tensor.</p>
<h2>D. Optimisation</h2>
<p>We use DE as implemented in the SciPy optimise module. DE follows the same approach as most EAs in that it begins with a randomly initialised population of a set number of individuals evolved across a number of generations. Individuals are a vector of parameters and child populations are the succeeding generation (or offspring) from parent populations with a chosen strategy dictating the creation of child populations.</p>
<p>We apply 'best1bin' strategy which iterates over the parent population creating a vector for each individual ( $X_{i}^{\prime}$ ) by mutating the fittest individual in the parent population ( $X_{\text {best }}$ ) by the difference between two randomly chosen individuals of the parent population, see Equation 1 where $F$ is the mutation factor. A child member is then created by choosing each parameter from either $X_{i}^{\prime}$ or the $i^{t h}$ parent as per a binomial distribution where the number must be less than the recombination rate to select the parameter from $X_{i}^{\prime}$. If a child vector is fitter than its parent it replaces it in the current population. In comparison to other strategies 'best1bin' has strong supporting evidence that it is a competitive strategy [33].</p>
<p>$$
X_{i}^{\prime}=X_{\text {best }}+F \times\left(X_{1 _ \text {rand }}+X_{2 _ \text {rand }}\right)
$$</p>
<p>The fitness objective is to minimise the 3D Euclidean distance between the simulator and reality, this value dictates the fitness used by the DE for a given population member. For tasks 1 and 2 (kinematic tasks) this is the distance between the wrist joint of the robotic manipulator in simulation ( $W_{x, y, z}^{s}$ ) and the dataset ( $W_{x, y, z}^{d}$ ) summed at 20 Hz throughout the duration of the simulation and divided by the number of data points ( $n_{\text {points }}$ ), see Equation 2. Tasks that include objects (simulation: $O_{x, y, z}^{s}$, dataset: $O_{x, y, z}^{d}$ ) use the combined euclidean distance of the arm and object, see Equation 3. The trajectory of the dataset object is a distribution as you can not create a mean object trajectory from multiple repeats where the object did not have the same start and end position. Therefore, we use the difference in the final position of the object in simulation and the dataset.</p>
<p>$$
f=\frac{\sum_{\text {points }} \sqrt{\sum_{i=x, y, z}\left(W_{i}^{d}-W_{i}^{s}\right)^{2}}}{n_{\text {points }}}
$$</p>
<p>$f=\frac{\sum_{\text {points }} \sqrt{\sum_{i=x, y, z}\left(W_{i}^{d}-W_{i}^{s}\right)^{2}}}{n_{\text {points }}}+\sqrt{\sum_{i=x, y, z}\left(O_{i}^{d}-O_{i}^{s}\right)^{2}}$</p>
<h2>IV. EXPERIMENTATION</h2>
<p>We define an optimisation as an application of DE to optimise an array of either shared or individual simulation parameters. In total there were 1100 optimisations completed that make up the results. This is broken down into:</p>
<ul>
<li>"Shared" and "Individual" parameters;</li>
<li>11 Experiments: 10 manipulation tasks from the dataset the $11^{\text {th }}$ a combination of all 10 ;</li>
<li>5 physics engines; and</li>
<li>10 repeats of each.</li>
</ul>
<p>A large number of experimental runs were required and as such were scheduled on a High Performance CPU Cluster (HPC). A singularity container with PyBullet, PyRep and VRep installed provided a distributed and scaleable deployment. Experiments $1-11$ were paired and scheduled onto a single node of the HPC, with each repeat given access to a single core. Each node was 20 cores of an Intel Xeon E5-2660 V3 processor with a clock speed of $2.6 \mathrm{GHz}, 25 \mathrm{MB}$ cache and 128 GB of memory.</p>
<p>The constants for the DE algorithm were 0.7 for $C R, 0.5-$ 1.0 for $F$ with dithering and a population of $N=1 D$ where $D$ is the length of the parameter array. The population was chosen to be low due to the large evaluation times of some physics engines and experiments paired with the limited amount of compute time. The experiment finished under one of three conditions:</p>
<ul>
<li>Convergence (i.e. when the standard deviation of the current population was less than one percent of the population mean), or</li>
<li>1000 DE generations completed, or</li>
<li>168 hrs of compute time (a hard constraint of the HPC).</li>
</ul>
<p>The number of variables tuned varied for Shared and Individual experiments. Shared experiments tuned 31 variables, Individual experiments tuned 57 (inclusive of the Shared variables). See Table I for more details.</p>
<h2>V. ReSults</h2>
<h2>A. Shared Parameters</h2>
<p>1) Performance: Table II shows the fitnesses for each experiment and physics engine when using generic simulator parameters. The fitness plots in Figure 2 demonstrate the convergence of the optimisations completed on the same physics engines, and the parameters shared between all physics engines. The smallest error obtained between simulation and the real world dataset for each experiment can be found in Table III.</p>
<p>Directly comparing the generic fitness values from Table II to the fitness values achieved when optimising shared parameters in Table III we see that the tuned fitness is lower than</p>
<p>TABLE I: List of Parameters Used for Optimisation and the Range Limits</p>
<table>
<thead>
<tr>
<th>Shared</th>
<th>Range</th>
<th>Individual</th>
<th>Range</th>
</tr>
</thead>
<tbody>
<tr>
<td>Time Step</td>
<td>[0.001,0.05]</td>
<td>Joint Damping (6 Joints)</td>
<td>[0.0001,0.9]</td>
</tr>
<tr>
<td>Mass (Links, Gripper, Objects)</td>
<td>[0.7<em>M,1.3</em>M]</td>
<td>Rolling Friction (Gripper,Floor, Objects)</td>
<td>[0.0001, 1.25]</td>
</tr>
<tr>
<td>Maximum Joint Torque (6 Joints)</td>
<td>[100,9000]</td>
<td>Sliding Friction (Gripper,Floor, Objects)</td>
<td>[0.0001, 1.25]</td>
</tr>
<tr>
<td>Maximum Joint Velocity (6 Joints)</td>
<td>[10,40]</td>
<td>Restitution (Gripper,Floor, Objects)</td>
<td>[0.0001,0.9]</td>
</tr>
<tr>
<td>Lateral Friction (Gripper,Floor, Objects)</td>
<td>[0.0001, 1.25]</td>
<td>Linear Damping (Gripper,Floor, Objects)</td>
<td>[0.0001,0.9]</td>
</tr>
<tr>
<td></td>
<td></td>
<td>Angular Damping (Gripper,Floor, Objects)</td>
<td>[0.0001,0.9]</td>
</tr>
</tbody>
</table>
<p>TABLE II: Fitness of Generic Physics Engine Settings</p>
<table>
<thead>
<tr>
<th>Experiment</th>
<th>PyBullet</th>
<th>Bullet2.78</th>
<th>Bullet2.83</th>
<th>ODE</th>
<th>Newton</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>0.1498</td>
<td>0.2660</td>
<td>0.2687</td>
<td>0.1800</td>
<td>0.1437</td>
</tr>
<tr>
<td>2</td>
<td>0.1283</td>
<td>0.1320</td>
<td>0.1582</td>
<td>0.1285</td>
<td>0.1147</td>
</tr>
<tr>
<td>3</td>
<td>0.1764</td>
<td>0.2533</td>
<td>0.2838</td>
<td>0.1943</td>
<td>0.2691</td>
</tr>
<tr>
<td>4</td>
<td>0.2107</td>
<td>0.2255</td>
<td>0.1966</td>
<td>0.1674</td>
<td>0.2877</td>
</tr>
<tr>
<td>5</td>
<td>491.2769</td>
<td>0.2967</td>
<td>0.3031</td>
<td>0.2909</td>
<td>0.2910</td>
</tr>
<tr>
<td>6</td>
<td>503.3037</td>
<td>0.6029</td>
<td>0.6096</td>
<td>0.5972</td>
<td>0.5977</td>
</tr>
<tr>
<td>7</td>
<td>0.1778</td>
<td>0.2500</td>
<td>0.3163</td>
<td>0.2370</td>
<td>0.2323</td>
</tr>
<tr>
<td>8</td>
<td>0.2132</td>
<td>0.3075</td>
<td>0.3412</td>
<td>0.2812</td>
<td>0.2759</td>
</tr>
<tr>
<td>9</td>
<td>0.1306</td>
<td>0.1950</td>
<td>0.1241</td>
<td>0.1171</td>
<td>0.1242</td>
</tr>
<tr>
<td>10</td>
<td>0.1242</td>
<td>0.1143</td>
<td>0.1155</td>
<td>0.1069</td>
<td>0.1176</td>
</tr>
<tr>
<td>11</td>
<td>995.8916</td>
<td>2.6433</td>
<td>2.7170</td>
<td>2.3005</td>
<td>2.4540</td>
</tr>
</tbody>
</table>
<p>TABLE III: Best Optimised Fitness by Experiment and Parameters Tuned</p>
<table>
<thead>
<tr>
<th>Experiment</th>
<th>Best Physics Engine Shared</th>
<th>Best Physics Engine Individual</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Newton (0.0973)</td>
<td>Newton (0.0973)</td>
</tr>
<tr>
<td>2</td>
<td>Newton (0.0984)</td>
<td>Newton (0.0984)</td>
</tr>
<tr>
<td>3</td>
<td>Bullet 2.78 (0.0498)</td>
<td>Bullet 2.78 (0.0498)</td>
</tr>
<tr>
<td>4</td>
<td>Bullet 2.83 (0.0629)</td>
<td>Bullet 2.78 (0.0673)</td>
</tr>
<tr>
<td>5</td>
<td>PyBullet (0.0506)</td>
<td>PyBullet (0.2407)</td>
</tr>
<tr>
<td>6</td>
<td>PyBullet (0.0552)</td>
<td>PyBullet (0.5641)</td>
</tr>
<tr>
<td>7</td>
<td>Bullet 2.78 (0.0551)</td>
<td>PyBullet (0.0551)</td>
</tr>
<tr>
<td>8</td>
<td>PyBullet (0.0442)</td>
<td>Bullet 2.78 (0.0744)</td>
</tr>
<tr>
<td>9</td>
<td>ODE (0.0519)</td>
<td>ODE (0.0482)</td>
</tr>
<tr>
<td>10</td>
<td>ODE (0.0503)</td>
<td>ODE (0.0487)</td>
</tr>
<tr>
<td>11</td>
<td>ODE (1.7360)</td>
<td>ODE (1.7714)</td>
</tr>
</tbody>
</table>
<p>all physics engines with generic parameters. Taking the best generic fitness and comparing it to the best tuned fitness for each experiment we see improvements ranging from $14\%$ for experiment 2 and $91\%$ for experiment 6 . The effect of tuning the shared parameters is therefore significant and provides a more realistic simulation closer aligned to the real world.</p>
<p>From Table III we see a correlation between the experiment 'type' and the physics engine with the least error. Newton was the best Physics Engine for Experiments 1 and 2, implying that it is able to better model arm kinematics without object interactions. PyBullet was best at experiments 5, 6 and 8, all of which include rolling objects. The clustering of experiments and physics engines indicates that no physics engine is best equipped to deal with all simulation scenarios but that physics engines can have heightened performance in select scenarios over other physics engines.</p>
<p>Newton took the least compute time, taking a total $279 h r s$ for all 11 experiments. Slowest was PyBullet at $662 h r s$. The time required to complete an optimisation gives some notion of</p>
<p>Shared Parameter Fitness Convergence
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Fig. 2. Convergence plots of all 11 experiments using shared parameters. Each subplot plots the line of best fitness throughout the generations averaged across the 10 repeats for each physics engine.
the difficulty, as experiment 11 (the combination of all dataset tasks, i.e. $1-10$ ) understandably took the longest. We note extended completion times for experiments 7 and 8 , which were cylinder rolling tasks.</p>
<p>Table 2 displays in the y-axis of each subplot the number of generations required for the optimisation to terminate. Newton was consistently the physics engine with the lowest number of evolutionary generations, whilst Bullet 2.83 and Bullet 2.78</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Fig. 3. Convergence plots of all 11 experiments using individual parameters. Each subplot plots the line of best fitness throughout the generations averaged across the 10 repeats for each physics engine.</p>
<p>had the most, terminating at 1000 generations for experiments 9 and 10 both of which were comparatively easy experiments. This is an interesting observation as it alludes to the fact that Newton is an easier environment to optimise within, with either a reduced search space or less noise, however, Newton does not provide accurate environmental interactions when compared with the other physics engines being reviewed. The large number of evolutionary generations required by both of V-Reps Bullet environments especially for the easier cuboid interactions implies a noisy landscape for fitness optimisation.</p>
<p>2) <em>Parameters:</em> From the Shared parameters we note a select few having a large impact on the performance of the Physics engine. We measure the importance of a parameters value as its deviation across the 10 optimisation repeats. Owing to the large amount of data generated, we include exemplar box and whisker plots in Figure 4 for most relevant data.</p>
<p>One of the most influential parameters found was the simulation timestep (see Figure 4), the deviation was consistently low across experiments and physics engines except for rolling tasks (experiments 5 – 8). The generic timestep value for V-Rep is 0.05sec and 0.0041sec for PyBullet. Pybullet's median value was 0.0042sec with a standard deviation of less than 0.0095sec for all experiments. Similarly, V-Rep Physics Engines were also very close to the generic timestep with the median for Bullet 2.78: 0.4304sec, Bullet 2.83: 0.0456sec, ODE: 0.0485sec and Newton: 0.0459sec. We therefore recommend setting the physics engine timestep to the recommended value as detailed by the developer of the simulator. The constrained value is very likely to be due to a reliance of other parameters that would need to be tuned that are physics engine specific.</p>
<p>Other parameters that largely influenced the realism of the simulation were the lateral friction of the manipulated objects i.e. wood and plastic frictions. The friction of the gripper and floor plane were not as influential except for Pybullet during the two rolling experiments where the floor plane had a standard deviation of 0.0097 and 0.1465. This is a very likely the reason why PyBullet had the lowest error for three of the rolling experiments.</p>
<p>It was expected that the parameters influencing the response of the joints would have a large impact on the fitness as there is a direct correlation between the measured wrist joint and actuator response. This assumption was found to be true for the maximum joint velocity, but no such trends could be found for the maximum torque. Experiments 1 – 4 consistently had statistically significant lower standard deviation across joints 1 – 5. Joint 6 was likely less influential in simulator realism due to the restricted amount of movement it experienced in the experiments and although experiments 5 – 10 did not display the same reliance on accurate joint velocity this is likely due to the experiments being more complex and the resulting optimisation harder. The results from the shared parameter optimisation show that we can perform contextsensitive tuning that is able to positively influence the realism of the simulation for all environments.</p>
<h3><em>B. Individual Parameters</em></h3>
<p>1) <em>Performance:</em> Figure 3 depicts the fitness convergence for the 57 individual parameters tuned. Made obvious by the plots is the difficulty that the extra parameters add as some physics engines fail to converge appropriately for certain experiments. When comparing the lowest error for each experiment as found in Table III, there are only three instances where the individual optimisation improves upon the shared parameters and 5 where the optimisation arrives at a worse solution. The added complexity of the additional parameters to tune is likely the cause of the worse fitnesses. Similar to the shared parameter optimisations the individual runs have a correlation between the best physics engine and the type of task, i.e. Newton is best at kinematics and PyBullet is best at 3 of the 4 tasks that include rolling objects.</p>
<p>Taking into account the mean final fitness instead of the absolute best the individual optimisation lessens the engine/experiment error 35 out of the 55 times. This is likely due to several reasons, (i) DE does not guarantee to find the</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Fig. 4. Box and Whisker Plot for each (i) physics engine and (ii) experiment. The subplots are all for the shared timestep parameter. This plot is meant as a exemplar of the other 30 parameter plots for individual optimisations and 56 parameter plots for shared optimisations.</p>
<p>optimal solution, (ii) the additional parameters add noise and complexity that make it harder to optimise, and (iii) due to termination of compute after 168<em>hrs</em> the algorithm is unable to complete optimisation without convergence. Termination at the maximum run time of individual parameter optimisations occurs on 14 out of 55 occasions.</p>
<p>2) <em>Parameters:</em> The influential parameters for individual optimisations were the same as those for shared. These being timestep, lateral friction and maximum joint velocity. In addition to these parameters there were two additional ones that had statistically significant standard deviations. The restitution of an object parameterizes the conservation of energy after a contact, only 9 of our 11 experiments contain contacts, most of which are at low speed. Experiment 9, interaction with a plastic cuboid, saw a standard deviation of less than 0.16 for three of the physics engines for the restitution value of plastic. This eludes to the fact that restitution could be an important factor given experiments that include contacts that are above a contact energy threshold.</p>
<p>The mass of arm links was another parameter that saw noticeably low standard deviations for individual parameter optimisations. Arm link masses produced an interesting result with links 1, 3, 4<em>and</em>5 displaying low standard deviations for Bullet 2.78, Bullet 2.83 and ODE on the simpler experiments i.e. experiments 1 – 4. The smaller deviations across the easier experiments is likely due to the reduced noise whilst optimising the parameters.</p>
<h2>VI. CONCLUSION</h2>
<p>In conclusion, we have investigated the influence of a range of simulation parameters on optimising 2 simulators and 5 physics engines towards more realistic simulations. Our method is significantly better than using generic simulator parameters with all simulation environments and all experiments achieving an improved fitness. This was achieved by using a real world dataset of motion capture recorded manipulation tasks and optimising both shared and individualised simulation parameters towards the dataset. The optimisation algorithm chosen was differential evolution (DE) due to the large number of optimisation parameters it is able to concurrently optimise and the non-differentiable nature of the problem. The fitness signal throughout the optimisation runs was the Euclidean distance error between the simulated wrist of the manipulator summed with the final placement error of any objects in the scene.</p>
<p>We found that the most important parameters that were shared between physics engines were simulation timestep, lateral object friction and joint velocity. From the expanded range of parameters we also found that it is likely for high energy contact tasks that the value of restitution is important.</p>
<p>To improve simulator performance we recommend that users start with (i) the default simulator timestep, (ii) researching or experimentally acquiring an accurate friction value, and (iii) recording or sourcing accurate maximum joint velocities for each actuator. These same parameters, if accurate, should not be excessively randomised as results indicate that the variation in these parameters are tightly bounded to the real world value.</p>
<h2>REFERENCES</h2>
<ul>
<li>[1] J. Collins, D. Howard, and J. Leitner, “Quantifying the Reality Gap in Robotic Manipulation Tasks,” in <em>2019 International Conference on Robotics and Automation (ICRA)</em>, 2019, pp. 6706–6712.</li>
<li>[2] J. Collins, J. McVicar, D. Wedlock, R. Brown, D. Howard, and J. Leitner, “Benchmarking Simulated Robotic Manipulation through a Real World Dataset,” <em>IEEE Robotics and Automation Letters</em>, p. 1, 2019.</li>
</ul>
<p>[3] M. Torres-Torriti, T. Arredondo, and P. Castillo-Pizarro, "Survey and comparative study of free simulation software for mobile robots," Robotica, vol. 34, no. 4, pp. 791-822, 2016.
[4] E. Coumans and Y. Bai, "Pybullet, a Python Module for Physics Simulation for Games, Robotics and Machine Learning," 2016. [Online]. Available: https://pybullet.org
[5] J. Lee, M. Grey, S. Ha, T. Kunz, S. Jain, Y. Ye, S. Srinivasa, M. Stilman, and C. Liu, "DART: Dynamic Animation and Robotics Toolkit," Journal of Open Source Software, vol. 3, no. 22, p. 500, 2018. [Online]. Available: https://doi.org/10.21105/joss. 00500
[6] R. Smith, "Open dynamics engine," 2005. [Online]. Available: https://www.ode.org/
[7] D. Howard and T. Merz, "A platform for the direct hardware evolution of quadcopter controllers," in IEEE International Conference on Intelligent Robots and Systems, vol. 2015-Decem. IEEE, 9 2015, pp. 4614-4619. [Online]. Available: http://ieeexplore.ieee.org/document/7354034/
[8] H. Heijnen, D. Howard, and N. Kottege, "A testbed that evolves hexapod controllers in hardware," in Proceedings - IEEE International Conference on Robotics and Automation. IEEE, 5 2017, pp. 1065-1071. [Online]. Available: http://ieeexplore.ieee.org/document/7989128/
[9] N. Jakobi, P. Husbands, and I. Harvey, "Noise and the reality gap: The use of simulation in evolutionary robotics," in Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics). Springer, Berlin, Heidelberg, 1995, vol. 929, pp. 704-720. [Online]. Available: http://link.springer.com/10.1007/3-540-59496-5_337
[10] H. Qiu, M. Garrait, D. Howard, and S. Anavatti, "Crossing the reality gap with evolved plastic neurocontrollers," arXiv preprint arXiv:2002.09854, 2020.
[11] S. Koos, J.-B. Mouret, and S. Doncieux, "Crossing the reality gap in evolutionary robotics by promoting transferable controllers," in Proceedings of the 12th annual conference on Genetic and evolutionary computation - GECCO '10, 2010, p. 119. [Online]. Available: http://portal.acm.org/citation.cfm?deid=1830483.1830505
[12] J. Tan, T. Zhang, E. Coumans, A. Iscen, Y. Bai, D. Hafner, S. Bohez, and V. Vanhoucke, "Sim-to-Real: Learning Agile Locomotion For Quadruped Robots," 4 2018. [Online]. Available: http://arxiv.org/abs/ 1804.10332
[13] J. Hwangbo, J. Lee, A. Dosovitskiy, D. Bellicoso, V. Tsounis, V. Koltun, and M. Hutter, "Learning agile and dynamic motor skills for legged robots," Science Robotics, vol. 4, no. 26, 2019. [Online]. Available: http://robotics.sciencemag.org/content/4/26/eaau5872
[14] J. Tan, Z. Xie, B. Boots, and C. K. Liu, "Simulation-based design of dynamic controllers for humanoid balancing," in 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2016, pp. 2729-2736.
[15] R. L. Williams, B. E. Carter, P. Gallina, and G. Rosati, "Dynamic model with slip for wheeled omnidirectional robots," IEEE Transactions on Robotics and Automation, vol. 18, no. 3, pp. 285-293, 2002.
[16] M. Gautier and W. Khalil, "On the identification of the inertial parameters of robots," in Proceedings of the 27th IEEE Conference on Decision and Control, 1988, pp. 2264-2269.
[17] Y. Chebotar, A. Handa, V. Makoviychuk, M. Macklin, J. Issac, N. Ratliff, and D. Fox, "Closing the Sim-to-Real Loop: Adapting Simulation Randomization with Real World Experience," in 2019 International Conference on Robotics and Automation (ICRA), 2019, pp. 8973-8979.
[18] M. Andrychowicz, B. Baker, M. Chociej, R. Jozefowicz, B. McGrew, J. Pachocki, A. Petron, M. Plappert, G. Powell, A. Ray, and others, "Learning dexterous in-hand manipulation," arXiv preprint arXiv:1808.00177, 2018.
[19] R. Moeckel, Y. N. Perov, A. T. Nguyen, M. Vespignani, S. Bonardi, S. Pouya, A. Sproewitz, J. v. d. Kieboom, F. Wilhelm, and A. J. Ijspeert, "Gait optimization for roombots modular robots Matching simulation and reality," in 2013 IEEE/RSJ International Conference on Intelligent Robots and Systems, 2013, pp. 3265-3272.
[20] J. Tremblay, A. Prakash, D. Acuna, M. Brophy, V. Jampani, C. Anil, T. To, E. Cameracci, S. Boochoon, and S. Birchfield, "Training Deep Networks with Synthetic Data: Bridging the Reality Gap by Domain Randomization," 2018.
[21] X. B. Peng, M. Andrychowicz, W. Zaremba, and P. Abbeel, "Sim-to-real transfer of robotic control with dynamics randomization," in 2018 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2018, pp. 1-8.
[22] OpenAI, I. Akkaya, M. Andrychowicz, M. Chociej, M. Litwin, B. McGrew, A. Petron, A. Paino, M. Plappert, G. Powell, R. Ribas, J. Schneider, N. Tezak, J. Tworek, P. Welinder, L. Weng, Q. Yuan, W. Zaremba, and L. Zhang, "Solving Rubik's Cube with a Robot Hand," 10 2019. [Online]. Available: http://arxiv.org/abs/1910.07113
[23] J. Degrave, M. Hermans, J. Dambre, and F. Wyffels, "A Differentiable Physics Engine for Deep Learning in Robotics," Frontiers in neurorobotics, vol. 13, p. 6, 3 2019. [Online]. Available: https://www.ncbi.nlm.nih.gov/pubmed/30899218https://www. ncbi.nlm.nih.gov/pmc/PMC6416213/
[24] J. Snoek, H. Larochelle, and R. P. Adams, "Practical Bayesian Optimization of Machine Learning Algorithms," in Proceedings of the 25th International Conference on Neural Information Processing Systems Volume 2, ser. NIPS12. Red Hook, NY, USA: Curran Associates Inc., 2012, pp. 2951-2959.
[25] Z. Wang, M. Zoghi, F. Hutter, D. Matheson, and N. De Freitas, "Bayesian Optimization in High Dimensions via Random Embeddings," in Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence, ser. IJCAI 13. AAAI Press, 2013, pp. 1778-1784.
[26] C. Li, S. Gupta, S. Rana, V. Nguyen, S. Venkatesh, and A. Shilton, "High Dimensional Bayesian Optimization Using Dropout," IJCAR International Joint Conference on Artificial Intelligence, pp. 20962102, 2 2018. [Online]. Available: http://arxiv.org/abs/1802.05400
[27] R. Storn and K. Price, "Differential Evolution A Simple and Efficient Heuristic for global Optimization over Continuous Spaces," Journal of Global Optimization, vol. 11, no. 4, pp. 341-359, 1997. [Online]. Available: https://doi.org/10.1023/A:1008202821328
[28] S. Das and P. N. Suganthan, "Differential Evolution: A Survey of the State-of-the-Art," IEEE Transactions on Evolutionary Computation, vol. 15, no. 1, pp. 4-31, 2011.
[29] J. Ronkkonen, S. Kukkonen, and K. V. Price, "Real-parameter optimization with differential evolution," in 2005 IEEE Congress on Evolutionary Computation, vol. 1, 2005, pp. 506-513.
[30] A. P. Piotrowski, "Review of Differential Evolution population size," Swarm and Evolutionary Computation, vol. 32, pp. 1-24, 2017. [Online]. Available: http://www.sciencedirect.com/science/article/ pii/S2210650216300268
[31] E. Rohmer, S. P. Singh, and M. Freese, "V-REP: A versatile and scalable robot simulation framework," in IEEE International Conference on Intelligent Robots and Systems. IEEE, 11 2013, pp. 1321-1326. [Online]. Available: http://ieeexplore.ieee.org/document/6696520/
[32] S. James, M. Freese, and A. J. Davison, "PyRep: Bringing V-REP to Deep Robot Learning," 6 2019. [Online]. Available: http://arxiv.org/abs/1906.11176
[33] E. Mezura-Montes, J. Velázquez-Reyes, and C. A. Coello Coello, "A Comparative Study of Differential Evolution Variants for Global Optimization," in Proceedings of the 8th Annual Conference on Genetic and Evolutionary Computation, ser. GECCO 06. New York, NY, USA: Association for Computing Machinery, 2006, pp. 485-492. [Online]. Available: https://doi.org/10.1145/1143997.1144086</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>This research was supported by a Data61 PhD Scholarship.
${ }^{1}$ Data61/CSIRO, Brisbane, Australia
${ }^{2}$ Queensland University of Technology (QUT), Brisbane, Australia
${ }^{3}$ Australian Centre for Robotic Vision (ACRV)
${ }^{4}$ LYRO Robotics Pty Ltd, Brisbane, Australia&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>