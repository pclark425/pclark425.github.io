<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7374 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7374</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7374</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-138.html">extraction-schema-138</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <p><strong>Paper ID:</strong> paper-275133416</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2412.19994v1.pdf" target="_blank">From Generalist to Specialist: A Survey of Large Language Models for Chemistry</a></p>
                <p><strong>Paper Abstract:</strong> Large Language Models (LLMs) have significantly transformed our daily life and established a new paradigm in natural language processing (NLP). However, the predominant pretraining of LLMs on extensive web-based texts remains insufficient for advanced scientific discovery, particularly in chemistry. The scarcity of specialized chemistry data, coupled with the complexity of multi-modal data such as 2D graph, 3D structure and spectrum, present distinct challenges. Although several studies have reviewed Pretrained Language Models (PLMs) in chemistry, there is a conspicuous absence of a systematic survey specifically focused on chemistry-oriented LLMs. In this paper, we outline methodologies for incorporating domain-specific chemistry knowledge and multi-modal information into LLMs, we also conceptualize chemistry LLMs as agents using chemistry tools and investigate their potential to accelerate scientific research. Additionally, we conclude the existing benchmarks to evaluate chemistry ability of LLMs. Finally, we critically examine the current challenges and identify promising directions for future research. Through this comprehensive survey, we aim to assist researchers in staying at the forefront of developments in chemistry LLMs and to inspire innovative applications in the field.</p>
                <p><strong>Cost:</strong> 0.02</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7374.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7374.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatMOF</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatMOF: an artificial intelligence system for predicting and generating metal-organic frameworks using large language models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A system that leverages a large language model (GPT-4) together with specialized ML models (MOFTransformer) and a genetic algorithm to predict properties of metal-organic frameworks (MOFs) and to generate candidate MOF structures.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Chatmof: an artificial intelligence system for predicting and generating metal-organic frameworks using large language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>instruction-tuned / large closed-source LLM used together with external ML models (MOFTransformer) and algorithmic tools (genetic algorithm)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>materials science / chemistry (metal-organic frameworks)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Predict MOF properties and generate novel MOF structures (property prediction and de novo generation)</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>classification/generation accuracy (percentage) reported for tasks (exact metric name not specified in survey)</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>95.7% (prediction task), 87.5% (generation task) reported for GPT-4 in ChatMOF</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['use of a specialized property predictor (MOFTransformer) as an external ML model', 'genetic algorithm for generation', 'use of a high-capability LLM (GPT-4) to coordinate/generate', 'integration of LLM with domain-specific ML tools']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From Generalist to Specialist: A Survey of Large Language Models for Chemistry', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7374.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7374.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Coscientist</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Coscientist: Autonomous chemical research with large language models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A GPT-4–driven system that autonomously designs, plans, and executes complex chemistry experiments across multiple tasks by orchestrating planning, tool usage, and robotic execution.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Autonomous chemical research with large language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>instruction-tuned / agentic LLM integrated with robotic control and experimental tooling</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>experimental chemistry / automated laboratory robotics</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Autonomous experimental design and execution (plan experiments, generate protocols, control robots, interpret results)</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>agent / planner style (ReAct-like planning and tool-invocation implied by survey description)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['LLM planning and reasoning capability (GPT-4)', 'integration with embodied robots and environment perception', 'syntactic validity of generated programs for domain-specific robot languages', 'data scarcity in domain-specific languages']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Survey notes challenges around data scarcity for generating syntactically valid domain-specific robot programs and general difficulties in integrating LLMs with experimental hardware; no quantitative failure rates reported in survey.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From Generalist to Specialist: A Survey of Large Language Models for Chemistry', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7374.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7374.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChemCrow</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChemCrow: Augmenting large language models with chemistry tools</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A system that augments LLMs with chemistry-specific tools/APIs (e.g., NameRXN, ReactionPredict, ReactionPlanner from IBM RXN4Chemistry) to plan syntheses and perform reaction planning tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Augmenting large language models with chemistry tools.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>LLM + external toolset (retrieval/ML-tool-augmented agent)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>synthetic chemistry / reaction planning</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Synthesis planning for target molecules (plans syntheses of insect repellent and organocatalysts described)</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>tool-augmented agentic prompting (call external reaction prediction and planning APIs)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['availability and quality of external reaction prediction/planner tools', "LLM's ability to orchestrate tool calls (agent behavior)", 'tool integration improves complex-task performance beyond pure LLM']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From Generalist to Specialist: A Survey of Large Language Models for Chemistry', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7374.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e7374.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BindGPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BindGPT: A scalable framework for 3D molecular design via language modeling and reinforcement learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A GPT-based model fine-tuned for 3D molecular design that uses external docking software as an environment signal (reward) and reinforcement learning (REINFORCE) to optimize molecules for binding properties.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Bindgpt: Ascalable framework for 3d molecular design via language modeling and reinforcement learning.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-based model (unnamed in survey)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>fine-tuned LLM with RL (REINFORCE) using external simulation-based reward</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>computational chemistry / molecular design (binding optimization)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Design 3D molecules optimized for docking/binding scores (molecular generation guided by docking feedback)</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>reinforcement learning from external simulation feedback (docking scores) — LLM acts as generator with reward signal</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>reward from docking software (used as optimization objective); no standardized accuracy metric reported in survey</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['use of docking software as reward signal', 'RL algorithm (REINFORCE) to incorporate environment feedback', 'domain-specific feedback improves alignment toward desired molecular properties']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Survey notes reliance on simulation/docking software for reward; no quantitative failure modes provided.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From Generalist to Specialist: A Survey of Large Language Models for Chemistry', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7374.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e7374.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLaMP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLaMP: Large language model made powerful for high-fidelity materials knowledge retrieval and distillation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hierarchical ReAct-style agent framework that enables LLMs to dynamically and recursively interact with structured materials databases (e.g., Materials Project) to ground LLM outputs on high-fidelity materials informatics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Llamp: Large language model made powerful for high-fidelity materials knowledge retrieval and distillation.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-series (implied)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>LLM agent with retrieval-augmented generation (RAG) / ReAct-style hierarchical agents</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>materials science / materials informatics</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Knowledge retrieval and grounded question answering for materials inquiries (interacting with Materials Project API to retrieve authoritative data)</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>retrieval-augmented prompting with agentic recursive queries (ReAct-like)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['access to structured database APIs (Materials Project)', 'hierarchical and recursive querying improves grounding', 'RAG reduces hallucinations compared to pure LLM outputs']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Survey highlights that many databases require API-specific access and queries, complicating tool integration; no numeric failure rates provided.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From Generalist to Specialist: A Survey of Large Language Models for Chemistry', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7374.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e7374.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hybrid instruction tuning (property tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hybrid instruction tuning on >1000 property tasks with LLaMA2-7b-chat (reported by Feng et al./related work)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An instruction-tuning approach that fine-tunes LLaMA2-7B-chat on a large suite (>1000) of property classification tasks, yielding notable improvements over prior LLM baselines on classification metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA2-7b-chat</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>instruction-tuned / task-specific SFT (multi-task)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>chemistry (molecular/property classification tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Property classification across many chemistry property tasks</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>multi-task supervised finetuning (hybrid instruction tuning) rather than pure zero-shot prompting</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>average improvement across classification tasks (percentage points)</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>up to 16.6% average improvement over leading LLM baselines across classification tasks (reported in survey)</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td>leading LLM baselines (unspecified in survey)</td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['volume and distribution of SFT data', 'multi-task SFT covering relevant chemistry tasks improves downstream classification', 'task distribution within SFT dataset determines model capabilities']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td>SFT dataset sizes reported generally 1.5M to 3M examples in related works; exact setup for this result not specified in survey</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Survey notes that SFT datasets' composition heavily influences abilities; exact per-task failures not enumerated.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From Generalist to Specialist: A Survey of Large Language Models for Chemistry', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7374.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e7374.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Chemical text mining (Zhang et al. 2024c)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Fine-tuning large language models for chemical text mining (as reported / extended by Zhang et al., 2024c)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Work on adapting LLMs for chemical text mining (joint NER and relation extraction) that can transform scientific text into structured outputs (simple English or JSON) achieving high exact accuracies with small annotated datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Fine-tuning large language models for chemical text mining.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>fine-tuned LLM for chemical text mining</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>chemistry / chemical literature mining</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Named entity recognition and relation extraction from chemical text, converting to structured outputs (e.g., JSON) or simplified English</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>supervised fine-tuning and task-specific adaptation (few-shot/minimal annotated data)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>exact accuracy (percent) on extraction tasks</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>exact accuracy ranging from 69% to 95% using minimal annotated data (reported in survey)</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['amount of annotated training data (minimal data used)', 'task formulation (joint NER+relation extraction) and output format', 'fine-tuning on domain-specific examples']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From Generalist to Specialist: A Survey of Large Language Models for Chemistry', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7374.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e7374.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MSNovelist / mass-spectrometry molecular generation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MSNovelist: de novo structure generation from mass spectra</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neural encoder-decoder system that attempts to generate molecular structures de novo from tandem mass spectrometry (MS/MS) data; reported accuracy in the survey is below 50%.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Msnovelist: de novo structure generation from mass spectra.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>MSNovelist (encoder-decoder neural network; not an LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>encoder-decoder neural network specialized for MS-to-structure generation (not a general LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>analytical chemistry / mass spectrometry (structure elucidation)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Generate molecular structures from tandem mass spectrometry (MS/MS) input</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>accuracy (exact structure generation / success rate)</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>less than 50% accuracy reported for de novo generation from tandem MS (survey cites this value)</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['richness and difficulty of spectral modality', 'limitations in extracting structural detail from spectra via purely neural generation']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Low generation accuracy (<50%); survey notes spectral modalities remain challenging and underexploited by LLM-like systems.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From Generalist to Specialist: A Survey of Large Language Models for Chemistry', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7374.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e7374.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MassSpecGym (benchmark)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MassSpecGym: A benchmark for the discovery and identification of molecules</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A benchmark focusing on characterization techniques such as tandem mass spectrometry (MS/MS) to evaluate models' abilities to elucidate molecular structures from spectra; intended to evaluate LLMs and other models on mass-spec tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Massspecgym: A benchmark for the discovery and identification of molecules.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>benchmark for evaluating models (including LLMs) on spectral-structure tasks</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>analytical chemistry / mass spectrometry</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Structure elucidation from MS/MS data and related characterization tasks</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>benchmark-specific metrics for discovery/identification tasks (not enumerated in survey)</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['difficulty of spectral modalities for current models', 'need for better exploitation of spectral information by LLMs/multimodal models']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Survey highlights that spectral tasks remain challenging and that existing neural methods show limited accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From Generalist to Specialist: A Survey of Large Language Models for Chemistry', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7374.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e7374.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChemDFM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChemDFM: Dialogue Foundation Model for Chemistry</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A dedicated chemistry LLM pre-trained on a large chemical text corpus (papers and chemistry books) designed to acquire rich chemistry knowledge and serve as an open-source top chemistry model.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Chemdfm: Dialoguefoundation model for chemistry.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChemDFM</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>pre-trained chemistry-specialized foundation LLM (continued pre-training on chemical corpus)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>chemistry (general chemistry knowledge and QA/generation)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>General chemistry language modeling and dialogue; improves chemistry knowledge and downstream chemistry tasks via domain pretraining</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>continued pre-training on domain-specific chemical text followed by instruction tuning (SFT) and possible RLHF as discussed generally</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['large-scale domain-specific pre-training corpus (34B tokens from papers, 49M tokens from books)', 'domain-specific pretraining improves chemistry knowledge and emergence as top open-source chemistry model']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td>Pretraining data: 3.9M chemical papers (34B tokens) + 1.4K chemistry books (49M tokens) collected before Jan 2022 (reported in survey)</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Survey notes data acquisition scale is immense and often copyright/restricted; exact downstream failure modes not enumerated in survey.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'From Generalist to Specialist: A Survey of Large Language Models for Chemistry', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Chatmof: an artificial intelligence system for predicting and generating metal-organic frameworks using large language models. <em>(Rating: 2)</em></li>
                <li>Autonomous chemical research with large language models. <em>(Rating: 2)</em></li>
                <li>Augmenting large language models with chemistry tools. <em>(Rating: 2)</em></li>
                <li>Bindgpt: Ascalable framework for 3d molecular design via language modeling and reinforcement learning. <em>(Rating: 2)</em></li>
                <li>Llamp: Large language model made powerful for high-fidelity materials knowledge retrieval and distillation. <em>(Rating: 2)</em></li>
                <li>Fine-tuning large language models for chemical text mining. <em>(Rating: 2)</em></li>
                <li>Msnovelist: de novo structure generation from mass spectra. <em>(Rating: 2)</em></li>
                <li>Massspecgym: A benchmark for the discovery and identification of molecules. <em>(Rating: 2)</em></li>
                <li>Chemdfm: Dialoguefoundation model for chemistry. <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7374",
    "paper_id": "paper-275133416",
    "extraction_schema_id": "extraction-schema-138",
    "extracted_data": [
        {
            "name_short": "ChatMOF",
            "name_full": "ChatMOF: an artificial intelligence system for predicting and generating metal-organic frameworks using large language models",
            "brief_description": "A system that leverages a large language model (GPT-4) together with specialized ML models (MOFTransformer) and a genetic algorithm to predict properties of metal-organic frameworks (MOFs) and to generate candidate MOF structures.",
            "citation_title": "Chatmof: an artificial intelligence system for predicting and generating metal-organic frameworks using large language models.",
            "mention_or_use": "mention",
            "model_name": "GPT-4",
            "model_size": null,
            "model_type": "instruction-tuned / large closed-source LLM used together with external ML models (MOFTransformer) and algorithmic tools (genetic algorithm)",
            "scientific_domain": "materials science / chemistry (metal-organic frameworks)",
            "simulation_task_description": "Predict MOF properties and generate novel MOF structures (property prediction and de novo generation)",
            "prompting_strategy": null,
            "evaluation_metric": "classification/generation accuracy (percentage) reported for tasks (exact metric name not specified in survey)",
            "reported_accuracy": "95.7% (prediction task), 87.5% (generation task) reported for GPT-4 in ChatMOF",
            "baseline_accuracy": null,
            "factors_reported": [
                "use of a specialized property predictor (MOFTransformer) as an external ML model",
                "genetic algorithm for generation",
                "use of a high-capability LLM (GPT-4) to coordinate/generate",
                "integration of LLM with domain-specific ML tools"
            ],
            "experimental_conditions": null,
            "limitations_or_failure_modes": null,
            "uuid": "e7374.0",
            "source_info": {
                "paper_title": "From Generalist to Specialist: A Survey of Large Language Models for Chemistry",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "Coscientist",
            "name_full": "Coscientist: Autonomous chemical research with large language models",
            "brief_description": "A GPT-4–driven system that autonomously designs, plans, and executes complex chemistry experiments across multiple tasks by orchestrating planning, tool usage, and robotic execution.",
            "citation_title": "Autonomous chemical research with large language models.",
            "mention_or_use": "mention",
            "model_name": "GPT-4",
            "model_size": null,
            "model_type": "instruction-tuned / agentic LLM integrated with robotic control and experimental tooling",
            "scientific_domain": "experimental chemistry / automated laboratory robotics",
            "simulation_task_description": "Autonomous experimental design and execution (plan experiments, generate protocols, control robots, interpret results)",
            "prompting_strategy": "agent / planner style (ReAct-like planning and tool-invocation implied by survey description)",
            "evaluation_metric": null,
            "reported_accuracy": null,
            "baseline_accuracy": null,
            "factors_reported": [
                "LLM planning and reasoning capability (GPT-4)",
                "integration with embodied robots and environment perception",
                "syntactic validity of generated programs for domain-specific robot languages",
                "data scarcity in domain-specific languages"
            ],
            "experimental_conditions": null,
            "limitations_or_failure_modes": "Survey notes challenges around data scarcity for generating syntactically valid domain-specific robot programs and general difficulties in integrating LLMs with experimental hardware; no quantitative failure rates reported in survey.",
            "uuid": "e7374.1",
            "source_info": {
                "paper_title": "From Generalist to Specialist: A Survey of Large Language Models for Chemistry",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "ChemCrow",
            "name_full": "ChemCrow: Augmenting large language models with chemistry tools",
            "brief_description": "A system that augments LLMs with chemistry-specific tools/APIs (e.g., NameRXN, ReactionPredict, ReactionPlanner from IBM RXN4Chemistry) to plan syntheses and perform reaction planning tasks.",
            "citation_title": "Augmenting large language models with chemistry tools.",
            "mention_or_use": "mention",
            "model_name": null,
            "model_size": null,
            "model_type": "LLM + external toolset (retrieval/ML-tool-augmented agent)",
            "scientific_domain": "synthetic chemistry / reaction planning",
            "simulation_task_description": "Synthesis planning for target molecules (plans syntheses of insect repellent and organocatalysts described)",
            "prompting_strategy": "tool-augmented agentic prompting (call external reaction prediction and planning APIs)",
            "evaluation_metric": null,
            "reported_accuracy": null,
            "baseline_accuracy": null,
            "factors_reported": [
                "availability and quality of external reaction prediction/planner tools",
                "LLM's ability to orchestrate tool calls (agent behavior)",
                "tool integration improves complex-task performance beyond pure LLM"
            ],
            "experimental_conditions": null,
            "limitations_or_failure_modes": null,
            "uuid": "e7374.2",
            "source_info": {
                "paper_title": "From Generalist to Specialist: A Survey of Large Language Models for Chemistry",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "BindGPT",
            "name_full": "BindGPT: A scalable framework for 3D molecular design via language modeling and reinforcement learning",
            "brief_description": "A GPT-based model fine-tuned for 3D molecular design that uses external docking software as an environment signal (reward) and reinforcement learning (REINFORCE) to optimize molecules for binding properties.",
            "citation_title": "Bindgpt: Ascalable framework for 3d molecular design via language modeling and reinforcement learning.",
            "mention_or_use": "mention",
            "model_name": "GPT-based model (unnamed in survey)",
            "model_size": null,
            "model_type": "fine-tuned LLM with RL (REINFORCE) using external simulation-based reward",
            "scientific_domain": "computational chemistry / molecular design (binding optimization)",
            "simulation_task_description": "Design 3D molecules optimized for docking/binding scores (molecular generation guided by docking feedback)",
            "prompting_strategy": "reinforcement learning from external simulation feedback (docking scores) — LLM acts as generator with reward signal",
            "evaluation_metric": "reward from docking software (used as optimization objective); no standardized accuracy metric reported in survey",
            "reported_accuracy": null,
            "baseline_accuracy": null,
            "factors_reported": [
                "use of docking software as reward signal",
                "RL algorithm (REINFORCE) to incorporate environment feedback",
                "domain-specific feedback improves alignment toward desired molecular properties"
            ],
            "experimental_conditions": null,
            "limitations_or_failure_modes": "Survey notes reliance on simulation/docking software for reward; no quantitative failure modes provided.",
            "uuid": "e7374.3",
            "source_info": {
                "paper_title": "From Generalist to Specialist: A Survey of Large Language Models for Chemistry",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "LLaMP",
            "name_full": "LLaMP: Large language model made powerful for high-fidelity materials knowledge retrieval and distillation",
            "brief_description": "A hierarchical ReAct-style agent framework that enables LLMs to dynamically and recursively interact with structured materials databases (e.g., Materials Project) to ground LLM outputs on high-fidelity materials informatics.",
            "citation_title": "Llamp: Large language model made powerful for high-fidelity materials knowledge retrieval and distillation.",
            "mention_or_use": "mention",
            "model_name": "LLaMA-series (implied)",
            "model_size": null,
            "model_type": "LLM agent with retrieval-augmented generation (RAG) / ReAct-style hierarchical agents",
            "scientific_domain": "materials science / materials informatics",
            "simulation_task_description": "Knowledge retrieval and grounded question answering for materials inquiries (interacting with Materials Project API to retrieve authoritative data)",
            "prompting_strategy": "retrieval-augmented prompting with agentic recursive queries (ReAct-like)",
            "evaluation_metric": null,
            "reported_accuracy": null,
            "baseline_accuracy": null,
            "factors_reported": [
                "access to structured database APIs (Materials Project)",
                "hierarchical and recursive querying improves grounding",
                "RAG reduces hallucinations compared to pure LLM outputs"
            ],
            "experimental_conditions": null,
            "limitations_or_failure_modes": "Survey highlights that many databases require API-specific access and queries, complicating tool integration; no numeric failure rates provided.",
            "uuid": "e7374.4",
            "source_info": {
                "paper_title": "From Generalist to Specialist: A Survey of Large Language Models for Chemistry",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "Hybrid instruction tuning (property tasks)",
            "name_full": "Hybrid instruction tuning on &gt;1000 property tasks with LLaMA2-7b-chat (reported by Feng et al./related work)",
            "brief_description": "An instruction-tuning approach that fine-tunes LLaMA2-7B-chat on a large suite (&gt;1000) of property classification tasks, yielding notable improvements over prior LLM baselines on classification metrics.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "LLaMA2-7b-chat",
            "model_size": "7B",
            "model_type": "instruction-tuned / task-specific SFT (multi-task)",
            "scientific_domain": "chemistry (molecular/property classification tasks)",
            "simulation_task_description": "Property classification across many chemistry property tasks",
            "prompting_strategy": "multi-task supervised finetuning (hybrid instruction tuning) rather than pure zero-shot prompting",
            "evaluation_metric": "average improvement across classification tasks (percentage points)",
            "reported_accuracy": "up to 16.6% average improvement over leading LLM baselines across classification tasks (reported in survey)",
            "baseline_accuracy": "leading LLM baselines (unspecified in survey)",
            "factors_reported": [
                "volume and distribution of SFT data",
                "multi-task SFT covering relevant chemistry tasks improves downstream classification",
                "task distribution within SFT dataset determines model capabilities"
            ],
            "experimental_conditions": "SFT dataset sizes reported generally 1.5M to 3M examples in related works; exact setup for this result not specified in survey",
            "limitations_or_failure_modes": "Survey notes that SFT datasets' composition heavily influences abilities; exact per-task failures not enumerated.",
            "uuid": "e7374.5",
            "source_info": {
                "paper_title": "From Generalist to Specialist: A Survey of Large Language Models for Chemistry",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "Chemical text mining (Zhang et al. 2024c)",
            "name_full": "Fine-tuning large language models for chemical text mining (as reported / extended by Zhang et al., 2024c)",
            "brief_description": "Work on adapting LLMs for chemical text mining (joint NER and relation extraction) that can transform scientific text into structured outputs (simple English or JSON) achieving high exact accuracies with small annotated datasets.",
            "citation_title": "Fine-tuning large language models for chemical text mining.",
            "mention_or_use": "mention",
            "model_name": null,
            "model_size": null,
            "model_type": "fine-tuned LLM for chemical text mining",
            "scientific_domain": "chemistry / chemical literature mining",
            "simulation_task_description": "Named entity recognition and relation extraction from chemical text, converting to structured outputs (e.g., JSON) or simplified English",
            "prompting_strategy": "supervised fine-tuning and task-specific adaptation (few-shot/minimal annotated data)",
            "evaluation_metric": "exact accuracy (percent) on extraction tasks",
            "reported_accuracy": "exact accuracy ranging from 69% to 95% using minimal annotated data (reported in survey)",
            "baseline_accuracy": null,
            "factors_reported": [
                "amount of annotated training data (minimal data used)",
                "task formulation (joint NER+relation extraction) and output format",
                "fine-tuning on domain-specific examples"
            ],
            "experimental_conditions": null,
            "limitations_or_failure_modes": null,
            "uuid": "e7374.6",
            "source_info": {
                "paper_title": "From Generalist to Specialist: A Survey of Large Language Models for Chemistry",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "MSNovelist / mass-spectrometry molecular generation",
            "name_full": "MSNovelist: de novo structure generation from mass spectra",
            "brief_description": "A neural encoder-decoder system that attempts to generate molecular structures de novo from tandem mass spectrometry (MS/MS) data; reported accuracy in the survey is below 50%.",
            "citation_title": "Msnovelist: de novo structure generation from mass spectra.",
            "mention_or_use": "mention",
            "model_name": "MSNovelist (encoder-decoder neural network; not an LLM)",
            "model_size": null,
            "model_type": "encoder-decoder neural network specialized for MS-to-structure generation (not a general LLM)",
            "scientific_domain": "analytical chemistry / mass spectrometry (structure elucidation)",
            "simulation_task_description": "Generate molecular structures from tandem mass spectrometry (MS/MS) input",
            "prompting_strategy": null,
            "evaluation_metric": "accuracy (exact structure generation / success rate)",
            "reported_accuracy": "less than 50% accuracy reported for de novo generation from tandem MS (survey cites this value)",
            "baseline_accuracy": null,
            "factors_reported": [
                "richness and difficulty of spectral modality",
                "limitations in extracting structural detail from spectra via purely neural generation"
            ],
            "experimental_conditions": null,
            "limitations_or_failure_modes": "Low generation accuracy (&lt;50%); survey notes spectral modalities remain challenging and underexploited by LLM-like systems.",
            "uuid": "e7374.7",
            "source_info": {
                "paper_title": "From Generalist to Specialist: A Survey of Large Language Models for Chemistry",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "MassSpecGym (benchmark)",
            "name_full": "MassSpecGym: A benchmark for the discovery and identification of molecules",
            "brief_description": "A benchmark focusing on characterization techniques such as tandem mass spectrometry (MS/MS) to evaluate models' abilities to elucidate molecular structures from spectra; intended to evaluate LLMs and other models on mass-spec tasks.",
            "citation_title": "Massspecgym: A benchmark for the discovery and identification of molecules.",
            "mention_or_use": "mention",
            "model_name": null,
            "model_size": null,
            "model_type": "benchmark for evaluating models (including LLMs) on spectral-structure tasks",
            "scientific_domain": "analytical chemistry / mass spectrometry",
            "simulation_task_description": "Structure elucidation from MS/MS data and related characterization tasks",
            "prompting_strategy": null,
            "evaluation_metric": "benchmark-specific metrics for discovery/identification tasks (not enumerated in survey)",
            "reported_accuracy": null,
            "baseline_accuracy": null,
            "factors_reported": [
                "difficulty of spectral modalities for current models",
                "need for better exploitation of spectral information by LLMs/multimodal models"
            ],
            "experimental_conditions": null,
            "limitations_or_failure_modes": "Survey highlights that spectral tasks remain challenging and that existing neural methods show limited accuracy.",
            "uuid": "e7374.8",
            "source_info": {
                "paper_title": "From Generalist to Specialist: A Survey of Large Language Models for Chemistry",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "ChemDFM",
            "name_full": "ChemDFM: Dialogue Foundation Model for Chemistry",
            "brief_description": "A dedicated chemistry LLM pre-trained on a large chemical text corpus (papers and chemistry books) designed to acquire rich chemistry knowledge and serve as an open-source top chemistry model.",
            "citation_title": "Chemdfm: Dialoguefoundation model for chemistry.",
            "mention_or_use": "mention",
            "model_name": "ChemDFM",
            "model_size": null,
            "model_type": "pre-trained chemistry-specialized foundation LLM (continued pre-training on chemical corpus)",
            "scientific_domain": "chemistry (general chemistry knowledge and QA/generation)",
            "simulation_task_description": "General chemistry language modeling and dialogue; improves chemistry knowledge and downstream chemistry tasks via domain pretraining",
            "prompting_strategy": "continued pre-training on domain-specific chemical text followed by instruction tuning (SFT) and possible RLHF as discussed generally",
            "evaluation_metric": null,
            "reported_accuracy": null,
            "baseline_accuracy": null,
            "factors_reported": [
                "large-scale domain-specific pre-training corpus (34B tokens from papers, 49M tokens from books)",
                "domain-specific pretraining improves chemistry knowledge and emergence as top open-source chemistry model"
            ],
            "experimental_conditions": "Pretraining data: 3.9M chemical papers (34B tokens) + 1.4K chemistry books (49M tokens) collected before Jan 2022 (reported in survey)",
            "limitations_or_failure_modes": "Survey notes data acquisition scale is immense and often copyright/restricted; exact downstream failure modes not enumerated in survey.",
            "uuid": "e7374.9",
            "source_info": {
                "paper_title": "From Generalist to Specialist: A Survey of Large Language Models for Chemistry",
                "publication_date_yy_mm": "2024-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Chatmof: an artificial intelligence system for predicting and generating metal-organic frameworks using large language models.",
            "rating": 2,
            "sanitized_title": "chatmof_an_artificial_intelligence_system_for_predicting_and_generating_metalorganic_frameworks_using_large_language_models"
        },
        {
            "paper_title": "Autonomous chemical research with large language models.",
            "rating": 2,
            "sanitized_title": "autonomous_chemical_research_with_large_language_models"
        },
        {
            "paper_title": "Augmenting large language models with chemistry tools.",
            "rating": 2,
            "sanitized_title": "augmenting_large_language_models_with_chemistry_tools"
        },
        {
            "paper_title": "Bindgpt: Ascalable framework for 3d molecular design via language modeling and reinforcement learning.",
            "rating": 2,
            "sanitized_title": "bindgpt_ascalable_framework_for_3d_molecular_design_via_language_modeling_and_reinforcement_learning"
        },
        {
            "paper_title": "Llamp: Large language model made powerful for high-fidelity materials knowledge retrieval and distillation.",
            "rating": 2,
            "sanitized_title": "llamp_large_language_model_made_powerful_for_highfidelity_materials_knowledge_retrieval_and_distillation"
        },
        {
            "paper_title": "Fine-tuning large language models for chemical text mining.",
            "rating": 2,
            "sanitized_title": "finetuning_large_language_models_for_chemical_text_mining"
        },
        {
            "paper_title": "Msnovelist: de novo structure generation from mass spectra.",
            "rating": 2,
            "sanitized_title": "msnovelist_de_novo_structure_generation_from_mass_spectra"
        },
        {
            "paper_title": "Massspecgym: A benchmark for the discovery and identification of molecules.",
            "rating": 2,
            "sanitized_title": "massspecgym_a_benchmark_for_the_discovery_and_identification_of_molecules"
        },
        {
            "paper_title": "Chemdfm: Dialoguefoundation model for chemistry.",
            "rating": 2,
            "sanitized_title": "chemdfm_dialoguefoundation_model_for_chemistry"
        }
    ],
    "cost": 0.0200395,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>From Generalist to Specialist: A Survey of Large Language Models for Chemistry
28 Dec 2024</p>
<p>Yang Han 
Department of Computer Science and Engineering MoE Key Lab of Artificial Intelligence
X-LANCE Lab
SJTU AI Institute Shanghai Jiao Tong University
ShanghaiChina</p>
<p>Suzhou Laboratory
SuzhouChina</p>
<p>Ziping Wan 
Suzhou Laboratory
SuzhouChina</p>
<p>Lu Chen chenlusz@sjtu.edu.cn 
Department of Computer Science and Engineering MoE Key Lab of Artificial Intelligence
X-LANCE Lab
SJTU AI Institute Shanghai Jiao Tong University
ShanghaiChina</p>
<p>Suzhou Laboratory
SuzhouChina</p>
<p>Suzhou Laboratory
SuzhouChina</p>
<p>Kai Yu 
Department of Computer Science and Engineering MoE Key Lab of Artificial Intelligence
X-LANCE Lab
SJTU AI Institute Shanghai Jiao Tong University
ShanghaiChina</p>
<p>Suzhou Laboratory
SuzhouChina</p>
<p>Xin Chen 
From Generalist to Specialist: A Survey of Large Language Models for Chemistry
28 Dec 2024D4A466343770EE8B9583205467DF062FarXiv:2412.19994v1[physics.chem-ph]
Large Language Models (LLMs) have significantly transformed our daily life and established a new paradigm in natural language processing (NLP).However, the predominant pretraining of LLMs on extensive web-based texts remains insufficient for advanced scientific discovery, particularly in chemistry.The scarcity of specialized chemistry data, coupled with the complexity of multi-modal data such as 2D graph, 3D structure and spectrum, present distinct challenges.Although several studies have reviewed Pretrained Language Models (PLMs) in chemistry, there is a conspicuous absence of a systematic survey specifically focused on chemistry-oriented LLMs.In this paper, we outline methodologies for incorporating domain-specific chemistry knowledge and multi-modal information into LLMs, we also conceptualize chemistry LLMs as agents using chemistry tools and investigate their potential to accelerate scientific research.Additionally, we conclude the existing benchmarks to evaluate chemistry ability of LLMs.Finally, we critically examine the current challenges and identify promising directions for future research.Through this comprehensive survey, we aim to assist researchers in staying at the forefront of developments in chemistry LLMs and to inspire innovative applications in the field. 1</p>
<p>Introduction</p>
<p>Recent years have witnessed remarkable advancements in daily life driven by LLMs.Competitive models like GPT-4 (Achiam et al., 2023) and Claude (Anthropic, 2024) have demonstrated exceptional abilities across diverse tasks, often matching or surpassing human-level performance, marking significant progress toward Artificial General Intelligence (AGI, Bubeck et al. (2023)).In sci- entific domains, LLMs have been applied to handle tasks involving natural language and various scientific data (e.g., molecules, proteins, DNA), showing promising results (Fang et al., 2023).Among these, chemistry LLMs, further tailored for chemical applications via additional training or advanced prompt engineering, have garnered significant attention.Before the advent of LLMs, there are lots of notable efforts towards chemistry, such as MolT5 (Edwards et al., 2022), Text2Mol (Edwards et al., 2021), MoMu (Su et al., 2022), Text+Chem T5 (Christofidellis et al., 2023).However, these models are built on PLMs like BERT (Devlin, 2018) and T5 (Raffel et al., 2020), requiring fine-tuning for specific tasks and lacking emergent abilities (Wei et al., 2022a), such as Chain-of-Thought (CoT, Wei et al. (2022b)) reasoning and tool-using capabilities (Qin et al., 2023).Existing reviews (Xiao et al., 2024;Liao et al., 2024;Pei et al., 2024a) have already discussed those PLMs in chemistry, such as Liao et al. (2024), which emphasize molecule encoding methods and pretraining objectives.More related works are discussed in the Appendix A. In contrast, our survey focuses on generative models with Transformer decoder ar-chitectures (Vaswani et al., 2017), addressing key challenges of general LLMs and reviewing existing approaches to adapt them for chemistry-specific tasks and applications.</p>
<p>General LLMs, such as the GPT (Ouyang et al., 2022;Achiam et al., 2023) and LLaMA series (Touvron et al., 2023a,b), have demonstrated impressive performance.However, they tend to underperform on chemistry-related tasks as shown in Figure 1.We identify three key challenges contributing to these limitations.</p>
<p>Challenge 1: domain knowledge is not enough.Most LLMs are pre-trained with the objective of predicting the next token based on web data sourced from the internet (Ouyang et al., 2022), as demonstrated by open-source models like LLaMa series (Touvron et al., 2023a,b).While some chemistry-related data exist within these datasets, the quantity is minimal, and there is a lack of data specifically tailored for chemistry.This deficiency extends to other crucial steps in the development of LLMs, such as supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF, Christiano et al. (2017); Stiennon et al. (2020)).</p>
<p>Challenge 2: multi-modal data is not perceived.Chemistry encompasses various modalities, including 1D sequences (Krenn et al., 2020), 2D molecular graphs (Duvenaud et al., 2015;Xu et al., 2018;Liu et al., 2019), and 3D structures (Schütt et al., 2018;Satorras et al., 2021;Atz et al., 2021).Additionally, there are numerous chemical spectra, such as Nuclear Magnetic Resonance (NMR, Simpson et al. (2012)), Liquid Chromatography-Tandem Mass Spectrometry (LC-MS, Seger (2012); Dührkop et al. (2015); Litsa et al. (2023)), and Infrared Spectroscopy (IR, Alberts et al. (2023)).These spectra contain substantial information that LLMs currently fail to fully exploit.</p>
<p>Challenge 3: chemistry tools are not utilized.Due to the core design of LLMs, they often struggle with retaining up-to-date knowledge and performing specific chemistry operations (Castro Nascimento and Pimentel, 2023;Schick et al., 2024).On the other hand, there are numerous powerful chemistry tools, such as the structure knowledge retrieval (PubChem (Kim et al., 2019), OPTIMADE (Evans et al., 2024)), and various expert-designed artificial intelligence systems tailored to address specific problems like reaction prediction (Pesciullesi et al., 2020), retrosynthesis planning (Segler et al., 2018) and so on.The absence of integration with these chemistry tools significantly hinders the performance of LLMs in the field of chemistry.</p>
<p>In this survey, we critically review current efforts addressing the three key challenges outlined in Figure 2. Additionally, we review the existing benchmarks used to evaluate the performance of chemistry LLMs and offer suggestions for future research directions.To the best of our knowledge, this is the first systematic survey reviewing existing approaches for transferring general LLMs to chemistry-specific LLMs in decoder architecture.</p>
<p>Domain Knowledge</p>
<p>Pre-training, SFT and RLHF have been the de facto way to enhance domain knowledge of LLMs.We will detail those methods in the following sections.</p>
<p>Pre-training</p>
<p>The natural of LLMs lay in language modeling, given a set of examples (x 1 , x 2 , ..., x n ) each composed of variable length sequences of symbols (s 1 , s 2 , .., s m ), language model is framed as a unsupervised distribution estimation and the joint probabilities over symbols can be formulated (Radford et al., 2019):
p(x) = n i=1 p(s n |s 1 , ..., s n−1 ),(1)
self-attention architectures like the Transformer can be applied to compute these conditional probabilities.Training on a large-scale corpus in this manner enables LLMs to capture rich language representations, refering to pre-training.Continue pre-training is prefered given the existence of advanced foundation models like LLaMA (Touvron et al., 2023a,b) and Galactica (Taylor et al., 2022), which already contain some basic chemistry knowledge.In contrast, pretraining from scratch is cost-prohibitive.Chemistry knowledge is typically encoded in specific languages, such as the Simplified Molecular-Input Line-Entry System (SMILES) (Weininger, 1988), which represents 3D structures as flattened sequences while preserving most structural information.Other representations include molecular formulas, SELFIES (Krenn et al., 2020), International Union of Pure and Applied Chemistry (IUPAC) names, and the Chemical Identifier (InChI) (Heller et al., 2013).To enhance foundation models with domain-specific chemistry knowledge, it is necessary to gather pre-training corpora in these chemical languages and apply continued pre-training.</p>
<p>Chemistry LLMs</p>
<p>Challenge 3: Chemistry Tools ( § 4) Embodied Robots ( § 4.3)</p>
<p>Coscientist (Boiko et al., 2023),CLAIRify (Yoshikawa et al., 2023),OR-GANA (Darvish et al., 2024), ML Models ( § 4.2) ChatChemTS (Ishida et al., 2024), ChemCrow (M.Bran et al., 2024), ChatMOF (Kang andKim, 2024), ChemReasoner (Sprueill et al., 2024) Structured Knowledge Retrieval ( § 4.1) ChemCrow (M.Bran et al., 2024),LLaMP (Chiang et al., 2024), ChatGPT Chemistry Assistant (Zheng et al., 2023), DRAK-K (Liu et al., 2024b), Challenge 2: Multimodal Data: ( § 3) Other Modalites ( § 3.4)</p>
<p>ChemVLM (Li et al., 2024c), ChemDFM-X (Zhao et al., 2024a) 3D Structure ( § 3.3) 3D-MoLM (Li et al., 2024d) 2D Graph ( § 3.2)</p>
<p>InstructMol (Cao et al., 2023), HIGHT (Chen et al., 2024b), MolTC (Fang et al., 2024a), MolCA (Liu et al., 2023b), ReactXT (Liu et al., 2024e), ICMA (Li et al., 2024b), MoleculeGPT (Zhang et al., 2023c), MolX (Le et al., 2024), MM-RCR (Zhang et al., 2024e) 1D Sequence ( § 3.1)</p>
<p>MolX (Le et al., 2024), MoleculeGPT (Zhang et al., 2023c) Challenge 1: Domain Knowledge ( § 2) RLHF ( § 2.3)</p>
<p>MolGen (Fang et al., 2024b), BindGPT (Zholus et al., 2024), MolRL-MGPT (Hu et al., 2024) SFT ( § 2.2)</p>
<p>Task-specific SFT GPTChem (Jablonka et al., 2024), MatChat (Chen et al., 2023), MolecularGPT (Liu et al., 2024d) Multi-task SFT LlaSMol (Yu et al., 2024), Mol-Instructions (Fang et al., 2023), ChemDFM (Zhao et al., 2024b), ChemLLM (Zhang et al., 2024a) Pre-training ( § 2.1) ChemDFM (Zhao et al., 2024b) Figure 2: Taxonomy of currect approachs for transfering general LLMs to specialized chemistry LLMs.</p>
<p>The volume of pre-training data required for chemistry LLMs is immense, making it difficult to obtain and, in some cases, restricted by copyright.To the best of our knowledge, ChemDFM (Zhao et al., 2024b) is the sole chemistry LLM specifically pre-trained on a chemical corpus.ChemDFM's training data comprises 34 billion tokens from 3.9 million chemical papers collected online before January 2022 and 49 million tokens from 1.4 thousand chemistry books sourced from LibreTexts 2 and Gold Books 3 .Through pre-training on this chemical text, ChemDFM can acquire a solid understanding of chemistry and emerge as the top open-source model (Feng et al., 2024).Another T5-based chemistry LM, Nach0 (Livne et al., 2024), collects 13 million abstracts from PubMed, 119K patent descriptions from the USPTO, and incorporates approximately 100 million documents from ZINC.</p>
<p>SFT</p>
<p>Pre-training on large corpus with next token prediction does not align well with users' objective, 2 https://libretexts.org/ 3 https://goldbook.iupac.org/as users expect models to "follow their instructions helpfully and safely" (Zhang et al., 2023b).SFT effectively aligns LLMs with user expectations by training them on datasets consisting of (INSTRUC-TION, OUTPUT) pairs, where INSTRUCTION refers to specific chemistry tasks and OUTPUT represents the desired responses.Given the variety of chemistry tasks in the SFT dataset, it can be further categorized as follows:</p>
<ol>
<li>Multi-task SFT: We categorize commonly used chemistry tasks into four types: SMILES understanding, reaction understanding, notation alignment and chemistry-related QA, as detailed in Appendix B. The most significant distinction among different SFT models (Yu et al., 2024;Fang et al., 2023;Zhao et al., 2024b;Zhang et al., 2024a) lie in their data sources and the volume of data used, and the detailed data distribution is shown in Appendix B. The total dataset volume ranges from 1.5M to 3M, although Zhang et al. (2024a) does not provide exact figures, it is likely of a similar magnitude.The distribution of tasks within the SFT dataset determines the model's chemistry capabilities, as identified by (Feng et al., 2024) (2024d) propose hybrid instruction tuning on more than 1000 property tasks with LLaMA2-7b-chat (Touvron et al., 2023b), reporting up to a 16.6% average improvement over leading LLM baselines across all classification tasks.Additionally, Chen et al. ( 2023) also fine-tune LLaMA2-7B-chat with 13,878 pieces of structured material knowledge data to predict inorganic material synthesis pathways.</li>
</ol>
<p>In addition to these chemistry tasks, chemical text mining is also a crucial foundation in chemical research, as much scientific knowledge is dispersed across the text, tables, and figures in millions of academic papers (Dagdelen et al., 2024).Dagdelen et al. (2024) focus on joint named entity recognition and relation extraction, enabling the generation of simple English sentences or more structured formats, such as JSON object, from individual sentences or entire paragraphs.Zhang et al. (2024c) extend these efforts to more chemical text mining tasks, achieving the best performance across all tasks, with exact accuracy ranging from 69% to 95% using minimal annotated data.</p>
<p>RLHF</p>
<p>While pre-training and SFT provide chemistry LLMs with domain-specific knowledge and enable them to perform specific tasks, these models are still prone to hallucination.RLHF is the most effective method to alleviate hallucinations and build a truthful, helpful and harmless LLM (Ouyang et al., 2022).There are many detail algorithms to utilize human feedback, such as PPO (Schulman et al., 2017), DPO (Rafailov et al., 2024).Beyond human feedback, other methods for collecting preference feedback include AI feedback (Lee et al., 2023;Bai et al., 2022) and environment feedback (Cao et al., 2024;Dong et al., 2024).</p>
<p>Existing research on human alignment for chemistry LLMs primarily focuses on molecular generation tasks.Fang et al. (2024b) first pre-trains LLM on SELFIES (Krenn et al., 2020), enabling the generation of syntactically correct molecules; however, the model also produces undesirable molecules, referred as molecular hallucinations.To mitigate these hallucinations and better align with actual chemical contexts, they apply a rank loss (Liu et al., 2022) by assigning higher probabilities to molecule candidates with desired properties.Zholus et al. ( 2024) finetunes a GPT-based model for 3D molecular design, and utlizes external feedback from docking software using REINFORCE algorithm (Williams, 1992).Hu et al. (2024) further investigates multiple GPT agents to generate desirable molecules in diverse directions, with the reward function estimated by docking software.The objective is to maximize the average reward while simultaneously improving molecular diversity.</p>
<p>AI and environment feedback are the most commonly used rewards for chemistry LLMs, as the more valuable human feedback is often unavailable due to the need for strong domain knowledge and the lack of effective tools to collect chemistryspecific feedback.Hu et al. (2024) design a Pythonbased open-source graphical user interface (GUI) to explore and evaluate molecules, and capture chemist's implicit knowledge and preferences more efficiently.This tool provides a promising approach for collecting chemistry-specific feedback to better align chemistry LLMs with human expertise.</p>
<p>Multi-Modal Data</p>
<p>Domain knowledge training is a standard approach for developing domain-specific LLMs, as demonstrated in fields like geoscience (Deng et al., 2024), law (Zhou et al., 2024), and medicine (Zhang et al., 2023a).However, chemical data is highly fragmented across multiple modalities (Mirza et al., 2024), such as 2D graphs, 3D structures, and spectra, as shown in Figure 3, which cannot be directly processed by vanilla LLMs.Inspired by recent advances in multi-modal and vision LLMs (Liu et al., 2024a;Li et al., 2024a;Huang et al., 2024a), numerous studies have focused on integrating chemical modalities with vanilla LLMs through the design of alignment components.We provide a compre-hensive review of these works based on the modalities they support: 1D Sequences, 2D Graphs, 3D Structures, and Other Modalities.</p>
<p>1D Sequences</p>
<p>SMILES (Weininger, 1988) is a widely used molecular representation, but it is generally processed as text using a byte-pair encoding tokenizer (Sennrich, 2015), which fails to capture its inherent chemical information.To address this limitation, MolX (Le et al., 2024) treats SMILES as a distinct modality and proposes a pre-trained BERTlike (Devlin, 2018) SMILES encoder to extract features, which are then aligned with other modalities through projection.MoleculeGPT (Zhang et al., 2023c) also adapt ChemBerta (Ahmad et al., 2022) for SMILES encoding.However, SMILES lacks robustness and does not fully capture spatial information, leading to the development of other 1D sequence representations, such as SELFIES (Krenn et al., 2020), IUPAC names, molecular fingerprints (Morgan, 1965), and InChI (Heller et al., 2013).These 1D sequences are generally processed similarly to text but can be further refined using specialized encoders, such as SELFormer (Yüksel et al., 2023) for SELFIES and variational autoencoders (VAE, Kingma (2013)) for molecular fingerprints.</p>
<p>2D Graphs</p>
<p>Compared to 1D sequences, 2D graphs offer a more intuitive representation of molecular structures and chemical bonds.To process 2D graphs, an encoder is required to convert them into vector representations, followed by a projector to align these vectors with LLMs.Graph neural networks (GNNs, Hu et al. (2019); Xiao et al. (2022)) are widely used as 2D graph encoders and have been adopted by most multimodal chemistry LLMs (Liu et al., 2024e;Li et al., 2024b;Zhang et al., 2023c;Le et al., 2024;Zhang et al., 2024e).For instance, MolTC (Fang et al., 2024a) train two GNNbased encoders and representation projectors by freezing the LLM and backpropagating the generation loss.InstructMol (Cao et al., 2023) employs MoleculeSTM's graph encoder (Liu et al., 2023a), which is trained through molecular-textual contrastive learning.MolCA (Liu et al., 2023b) utilze a more expressive GNN model -Graph isomorphism network (GIN, Hu et al. (2019)), which pre-trained on 2 million molecules from the ZINC15 (Sterling and Irwin, 2015).HIGHT (Chen et al., 2024b) further introduce a hierarchical graph tokenizer which em Vector Quantized-Variational AutoEncoder (VQVAE, (Zang et al., 2023)) to extract highorder structural information and then feed them into LLMs.</p>
<p>There are various projectors to map graph features into the LLM embedding space, such as crossattention (Alayrac et al., 2022), Q-Former (Li et al., 2023), position-aware vision language adapters (Bai et al., 2023), and light-weight Multi-layer Perceptron (MLP).Q-Former is the most widely adopted projector (Liu et al., 2023b;Fang et al., 2024a;Zhang et al., 2023c), maintaining a set of learnable query tokens to interact with the graph encoder and extract features.However, Instruct-Mol (Cao et al., 2023) argues that Q-Former requires a large number of paired data for pretraining, making alignment inefficient, and instead employs a lightweight MLP for alignment.DeCo (Yao et al., 2024) also find that Q-Former tends to lose finegrained visual attributes and spatial locality in visual LLMs.</p>
<p>3D Structures</p>
<p>The 3D structures of molecules is crucial because it contains spatial information essential for understanding molecular dynamics, protein-ligand interactions, enzymatic functions, and other biomolecular phenomena (Li et al., 2024d).Unlike 1D sequences or 2D graphs, 3D structures provide a complete geometric representation of the molecule, allowing models to take into account the threedimensional arrangement of atoms and the distances between them.MolLM (Tang et al., 2024) and Uni-Mol (Zhou et al., 2023) demotarte performance enhancement in downstream tasks when incorporating 3D information.3D-MoLM (Li et al., 2024d) utilizes Uni-Mol (Zhou et al., 2023) to encode 3D conformations generated from SMILES and employs Q-Former (Li et al., 2023) for crossmodal alignment.This approach outperforms baseline models that rely on 1D or 2D molecular perceptions in tasks such as molecule-text retrieval, molecule captioning, and open-text question answering, particularly when addressing 3Ddependent properties.In contrast, 3D-MolT5 (Pei et al., 2024b) contends that the modality alignment approach employed by 3D-MoLM (Li et al., 2024d) is inefficient and introduces a specialized 3D vocabulary to train 1D, 3D, and text modalities within a unified architecture, demonstrating significant improvements over 3D-MoLM (Li et al., 2024d) in various downstream tasks.</p>
<p>Other Modalities</p>
<p>2D graphs or 3D structures generated by RDKit are often represented as matrices, which are not humanreadable.In contrast, chemical images are more intuitive and frequently used to represent chemical structures in a human-friendly format.At the same time, numerous efficient image algorithms, such as the Vision Transformer (ViT) (Dosovitskiy, 2020) and Swin Transformer (Liu et al., 2021), can be directly employed as modality encoders.GIT-Mol (Liu et al., 2024c) utilizes Swin Transformer (Liu et al., 2021) from SwinOCSR for image ecoding, and adopt cross-attention for modal alignment.ChemVLM (Li et al., 2024c) adopts InternViT-6B (Chen et al., 2024d) as the vision encoder, following the LLaVA (Liu et al., 2024a) architecture in the "ViT-MLP-LLM" style.Additionally, ChemVLM introduces three new chemical image datasets -ChemOCR, MMCR-Bench, and MMChemBench, However, these datasets are not open-source at this time.To facilitate future research on chemical images, we provide a summary of existing chemical image datasets in Appendix C.</p>
<p>Another important chemistry-specific modality is spectral , which can be obtained through simulations (CFMID 4.0, Wang et al. ( 2021)) and experiments.This data is rich in structural information and plays a vital role in determining molecular structures.For example, MSNovelist (Stravs et al., 2022) utilizes an encoder-decoder neural network to generate molecular structures de novo from tan-dem mass spectrometry, but its accuracy is less than 50%.Comprehensive exploration of the diverse information embedded in these spectral modalities is crucial for advancing research in this domain.</p>
<p>Chemistry Tools</p>
<p>Although domian knowledge training and multimodal enhancement can encode a certain amount of domain-specific knowledge into LLMs, it is constrained by scalability and intrinsic memory capacity (Chiang et al., 2024).In this section, We emphasize improving the capability of LLMs to tackle complex chemistry and embodied problems through the use of chemistry tools, such as operating experimental equipment for scientific research.We categorize these chemistry tools into three types: structured knowledge retrieval, machine learning (ML) models, and embodied robots.</p>
<p>Structured Knowledge Retrieval</p>
<p>Structured knowledge retrieval, or retrievalaugmented generation (RAG, (Lewis et al., 2020)), has been proposed to alleviate hallucinations in both chemistry-specific and general LLMs (Xu et al., 2024).The key component of knowledge retrieval is the knowledge source, and the retrieval method is typically determined by the source.We categorize common knowledge sources as follows:</p>
<ol>
<li>
<p>Database: There are many famous chemistry database, such as, Materials Project (MP, Jain et al. ( 2013)), OPTIMADE (Evans et al., 2024).These databases cannot be accessed through direct web searches; instead, data retrieval requires following specific API documentation.LLaMP (Chiang et al., 2024) design hierarchical ReAct (Yao et al., 2022) agents that can dynamically and recursively interact with MP to ground LLMs on highfidelity materials informatics.</p>
</li>
<li>
<p>Scientific Literature: Peer-reviewed research articles are the most accurate and authoritative data source, and there are many Scholarly engines can help us find the related papers.Zheng et al. (2023) propose to use ChatGPT for text mining the synthesis conditions of metal-organic frameworks (MOFs) and develop a ChatGPT Chemistry Assistant (CCA) chatbot base on the systhesis dataset and bibliographic context (such as authors and DOI), to alleviate hallucinatory errors.</p>
</li>
</ol>
<p>Knowledge Graph:</p>
<p>A knowledge graph is a structured representation that allows for complex queries and provides insights that traditional databases cannot easily offer (Ye et al., 2024).Liu et al. (2024b) propose KG-driven Knowledge Injection (DRAK-K) by retrieving the top-k most relevant pieces of knowledge and transforming the related knowledge into structured background context for LLMs.</p>
<p>ML Models</p>
<p>LLMs are prone to worse than existing ML baselines (Guo et al., 2023) in reaction-related tasks, and this tasks are difficult to be solved by knowledge retriveal.On the other hand, LLMs can interact with various tools (APIs) to accomplish complex tasks (Qin et al., 2023) in ReAct (Yao et al., 2022) style , and we can boost chemistry LLMs performance with SOTA ML models.ChemCrow (M.Bran et al., 2024) design reacttion tool set consist of NameRXN, ReactionPredict and Reac-tionPlanner provied by RXN4Chemistry API from IBM Research, and plan the syntheses of an insect repellent and three organocatalysts.ChatChemTS (Ishida et al., 2024) develop a user frendly chatbot named ChatChemTS which utilize AI-based molecule generators such as ChemTSv2 (Ishida et al., 2023) for molecular design.ChatMOF (Kang and Kim, 2024) foucs on generating new metal organic frameworks (MOFs, Kitagawa et al. (2014)) which are useful in many chemical applications due to large porosity, high surface area,and exceptional tunability (Deng et al., 2012), and they also predict the properties of generated MOFs.They adopt MOFTransformer (Kang et al., 2023) for the universal prediction of MOF properties and genetic algorithm (Park et al., 2022) to generate new MOFs, and achieve high accuracy of 95.7% for predicting, and 87.5% for generating tasks with GPT-4.ML models can also help discover new catalyst by just giving feedback, ChemReasoner (Sprueill et al., 2024) use atomistic graph neural networks (GNNs) trained from quantum chemistry simulations for structure-based scoring, the GNNs are used to yeild reward and drive LLM towards catalysts with specific properties.This novel idea suggest that ML models not only can be used as tools aid in specific task, but also can be used as feeback to guide and stimulate the LLMs to fulfill the tasks by themselfs.</p>
<p>Embodied Robots</p>
<p>Chemistry experiments are often resoure-and laborintensive, and automated experiments canattain higher throughput and precision (Tom et al., 2024).However, the discovery of new material requires not only automation but autonomy-the ability of an experimental agent to interpret data and make decisions based on it (Szymanski et al., 2023), where LLMs are excellent at planing and reasoning, showing promise of sought-after system that autonomously designs and executes scientific experiments (Boiko et al., 2023).</p>
<p>Coscientist (Boiko et al., 2023) is a GPT-4 driven AI system which can autonomously designs, plans and performs complex experiments, it demonstrate the versatility and performance across six tasks.CLAIRify (Yoshikawa et al., 2023) also leverage robots and LLM to automate chemistry experiments, and they pay more attention to how to generate syntactically valid programs in a data-scarce domain-specific language that incorporates environmental constraints.ORGANA (Darvish et al., 2024) further extend CLAIRify with visual perception of the environment and support complex experiments between multiple robots.</p>
<p>Benchmarks</p>
<p>Benchmarks are essential for evaluating the performance of chemistry LLMs on chemistry-related tasks and can be broadly categorized into two categories: science benchmarks and molecule-specific benchmarks.Chemistry is a subset of science, and existing science benchmarks evaluate LLMs' ability to solve scientific problems, including those related to chemistry.Existing science benchmarks, such as SciQ (Welbl et al., 2017), Sci-Code (Tian et al., 2024), ScienceQA (Lu et al., 2022), AGIEval (Zhong et al., 2023), SciEval (Sun et al., 2024), SciBench (Wang et al., 2023), and VisScience (Jiang et al., 2024), typically cover a wide range of scientific disciplines, including biology, earth science, physics, chemistry, and even social science.Although these science benchmarks include chemistry-related tasks, they are not specifically designed for chemistry and fail to address many chemistry-specific problems.</p>
<p>In contrast, molecule-specific benchmarks are designed to assess knowledge in molecule-related sciences (e.g., chemistry, materials science, biochemistry).ChemLLMBench (Guo et al., 2023) first adapts traditional chemistry tasks to a language model setting, evaluating the performance of contemporary LLMs in zero-shot and few-shot prompts.SciKnowEval (Feng et al., 2024) expands the chemistry domain to molecules by introducing a large dataset of 50,000 problems that assess various LLM abilities, including knowledge coverage, reflection and reasoning, and application.MassSpecGym (Bushuiev et al., 2024) focuses on characterization techniques, such as Tandem Mass Spectrometry (MS/MS), and evaluates the ability of LLMs to elucidate molecular structures from MS/MS data.Notably, there are several other important chemistry benchmarks, including Schol-arChemQA (Chen et al., 2024a), SCIASSESS (Cai et al., 2024), SciKnowEval (Feng et al., 2024), ChemEVal (Huang et al., 2024b), Alberts et al. (2024), and MolPuzzles (Guo et al., 2024).Due to page limitations, we provide a brief overview of these benchmarks in Table 3.</p>
<p>Future Directions</p>
<p>Although current approaches have made steady progress towards chemistry LLMs, there remains significant room for improvement.Future research directions can be categorized into three main aspects: data, model, and application.</p>
<p>Data</p>
<p>Data Diversity Training data is the foundation of LLMs.However, most existing datasets are built from pre-existing sources, such as MoleculeNet (Wu et al., 2018), and cover a limited range of chemistry tasks.Future work should aim to create more diverse and comprehensive datasets to enhance the training of chemistry LLMs and broaden their capabilities.</p>
<p>CoT Reasoning Chain-of-Thought (CoT, Wei et al. (2022b) ) reasoning is one of the most notable emergent abilities of LLMs, involving the generation of a sequence of intermediate steps leading to the final answer.However, existing chemistry LLMs often lack this critical reasoning capability due to simple training instruction pairs.Developing training data with explicit reasoning paths to effectively elicit the CoT ability in chemistry LLMs is a crucial direction for future research.</p>
<p>Chemical Modality As described in Section 3.4, many chemistry-specific spectra are not yet fully exploited in in chemistry LLMs.However, these spectra contain rich structural information that can be valuable for various chemical tasks.For example, tandem mass spectrometry (MS/MS) can provide detailed insights into the molecular structure, allowing for the identification and characterization of compounds and elucidation of reaction mechanisms.</p>
<p>Model</p>
<p>Multi-Modal Alignment Most works towards multi-modal chemistry LLMs always invole a single pair of modalities, limiting their representations ability.Align multiple N ( ≥ 3) modalities is a promising direction as different modalites are complementary and can provide more comprehensive understanding of chemistry molecules.</p>
<p>RLXF RLHF is a crucial step in training powerful LLMs.Although obtaining human feedback is challenging, especially in chemistry where data annotation requires specialized domain knowledg, we can leverage advanced LLMs as assistants to guide this process.Additionally, we can also utilize results from professional chemistry software as a form of reward to align chemistry LLMs.</p>
<p>Application</p>
<p>Research Assistants Chemistry LLMs have the potential to serve as powerful research assistants, aiding chemists by automating routine tasks such as literature review, data analysis, and hypothesis generation.For future development, these models can be designed to understand complex scien-tific queries, provide insights from vast amounts of chemical literature, suggest experimental protocols, and even propose novel research directions.</p>
<p>Automated Experimentation Automated experimentation is another promising direction for advancing chemistry LLMs.Integrating these models with automated laboratory systems can enable them to not only predict molecular properties or suggest potential chemical reactions but also design, execute, and analyze experiments in real-time.Future research should explore how chemistry LLMs can be trained and aligned to interact with automated experimental setups, ensuring reliability, safety, and compliance with scientific standards.</p>
<p>Conclusion</p>
<p>In this survey, we systematically investigate the current approaches to adapting general LLMs for chemistry LLMs.We highlight key challenges, including domain knowledge, multi-modal data, and the integration of chemistry-specific tools, and review existing efforts to address these challenges.While significant progress has been made, achieving chemical general intelligence remains a distant goal, and we identify promising future directions.We hope this survey will inspire further innovative research in the field.</p>
<p>Limitations</p>
<p>In this paper, a comprehensive review of existing methods for constructing chemistry-focused LLMs is presented, with an emphasis on three key aspects for enhancing general LLMs: domain-specific knowledge, multi-modal data, and chemistry tools.This survey aims to provide researchers with a concise understanding of chemistry LLMs and suggest potential directions for future research.However, certain limitations may be present.</p>
<p>References.</p>
<p>Due to page limitations and the rapid development of the field, we may not include all relevant references and detailed technical information.However, we strive to keep our work up-to-date on our GitHub repository.</p>
<p>A Related Work</p>
<p>The intersection of LLMs and chemistry is an urgent and rapidly growing field.Numerous works and reviews have addressed this topic, which can be broadly categorized into:</p>
<p>A.1 General Science</p>
<p>Several surveys focus on general science, including chemistry.Zhang et al. (2024d) explore LLM applications across mathematics, physics, biology, medicine, geography, geology, environmental science, and chemistry.However, the broad scope limits the depth of discussion on chemistry-specific LLMs.Zhang et al. (2024b) focus more on the chemical domain but still include biological LLMs and BERT-style models, without discussing the emergent applications of chemistry-specific agents.</p>
<p>A</p>
<p>B SFT Tasks Description</p>
<p>The most frequently used chemistry tasks for SFT and their description are shown in Table 1.In accordance with the task division presented in Table 1, we illustrate in Figure 4 the data distribution of the commonly used SFT dataset.</p>
<p>C Molecule Image Dataset</p>
<p>We describe the existing molecule image dataset in Table 2.</p>
<p>D Benchmarks</p>
<p>We briefly introduce the existing benchmarks in Table 3, covering aspects such as subject, task type, dynamics, source, and modality.</p>
<p>Figure 1 :
1
Figure 1: Three common errors in general LLMs arising from the key challenges.</p>
<p>Figure 3 :
3
Figure 3: For example, the compound C 8 H 11 N O can be represented across various modalities.1D sequeues include SMILES, IUPAC name and so on.Molecular structure consist of 2D graphs and 3D structures, 2D graphs encompass three matrices: atomic features, atom connection, chemical bonds features, 3D strutures compromise the coordinate of every atom.Other modalities consist of mass spectra, images, and so on.</p>
<p>Zhang et al. (2024a);Zhang et al. (2024a)focus more on chemistryrelated QA, gathering major data from sources such as chemistry exams and existing datasets, which enhances the model's ability to answer user questions more naturally.
2. Task-specific SFT: Task-specific finetuningof LLMs has demonstrated effective predic-tion performances, often surpassing tradi-tional machine learning models, particularlyin low-data scenarios(Jablonka et al., 2024).Jablonka et al. (2024) finetune GPT-3 for clas-sification, regression, and inverse design tasks,achieving competitive results in three casestudies (polymers, metal-organic frameworks,
and photoswitches).More recently, Liu et al.</p>
<p>WeitongZhang, Xiaoyun Wang, Weili Nie, Joe Eaton,  Brad Rees, and Quanquan Gu. 2023c.Moleculegpt: Instruction following large language models for molecular property prediction.In NeurIPS 2023 Workshop on New Frontiers of AI for Drug Discovery and Development.Zhiling Zheng, Oufan Zhang, Christian Borgs, Jennifer T Chayes, and Omar M Yaghi.2023.Chatgpt chemistry assistant for text mining and the prediction of mof synthesis.Journal of the American Chemical Society, 145(32):18048-18062.Wanjun Zhong, Ruixiang Cui, Yiduo Guo, Yaobo Liang, Shuai Lu, Yanlin Wang, Amin Saied, Weizhu Chen, and Nan Duan.2023.Agieval: A human-centric benchmark for evaluating foundation models.arXiv preprint arXiv:2304.06364.Gengmo Zhou, Zhifeng Gao, Qiankun Ding, Hang Zheng, Hongteng Xu, Zhewei Wei, Linfeng Zhang, and Guolin Ke. 2023.Uni-mol: A universal 3d molecular representation learning framework.Zhi Zhou, Jiang-Xin Shi, Peng-Xiao Song, Xiao-Wen Yang, Yi-Xuan Jin, Lan-Zhe Guo, and Yu-Feng Li. 2024.Lawgpt: A chinese legal knowledgeenhanced large language model.arXiv preprint arXiv:2406.04614.
Yu Zhang, Xiusi Chen, Bowen Jin, Sheng Wang, Shui-wang Ji, Wei Wang, and Jiawei Han. 2024d. A com-prehensive survey of scientific large language modelsand their applications in scientific discovery. arXivpreprint arXiv:2406.10833.Yu Zhang, Ruijie Yu, Kaipeng Zeng, Ding Li, Feng Zhu,Xiaokang Yang, Yaohui Jin, and Yanyan Xu. 2024e.Text-augmented multimodal llms for chemical re-action condition recommendation. arXiv preprintarXiv:2407.15141.Zihan Zhao, Bo Chen, Jingpiao Li, Lu Chen, LiyangWen, Pengyu Wang, Zichen Zhu, Danyang Zhang,Ziping Wan, Yansi Li, et al. 2024a. Chemdfm-x: To-wards large multimodal model for chemistry. arXivpreprint arXiv:2409.13194.Zihan Zhao, Da Ma, Lu Chen, Liangtai Sun, ZihaoLi, Hongshen Xu, Zichen Zhu, Su Zhu, Shuai Fan,Guodong Shen, et al. 2024b. Chemdfm: Dialoguefoundation model for chemistry. arXiv preprintarXiv:2401.14818.Artem Zholus, Maksim Kuznetsov, Roman Schut-ski, Rim Shayakhmetov, Daniil Polykovskiy, SarathChandar, and Alex Zhavoronkov. 2024. Bindgpt: Ascalable framework for 3d molecular design via lan-guage modeling and reinforcement learning. arXivpreprint arXiv:2406.03686.</p>
<p>.2 Chemistry-Specific Surveys Chemistry's significance has drawn considerable attention, leading to various efforts summarizing current trends.Xia et al. (2022) review Chemical Pre-trained Models (CPMs) based on GNNs or Transformers but focus little on LLMs.Janakarajan et al. (2024) emphasize the role of language models in molecular discovery but offer limited insights on training chemistry-specific LLMs.Liao et al. (2024) concentrate on molecule encoding and pretraining objectives, while Pei et al. (2024a) discuss progress from a multi-modal perspective, neglecting LLMs' tool-using potential.Ramos et al. (2024) review chemistry LLM agent applications in literature analysis, experiment planning, and hypothesis generation, but overlook multi-modal capabilities.Notably, these surveys categorize BERTstyle LMs as LLMs, despite their need for taskspecific fine-tuning and lack of emergent abilities.</p>
<p>AcknowledgementsI would like to express my gratitude to the anonymous reviewers for their meticulous and diligent review efforts.This work was supported by National Science and Technology Major Project (Grant No. 2023ZD0120703), National Natural Science Foundation of China (Grant Nos.92370206, U23B2057, 62120106006), and Shanghai Municipal Science and Technology Major Project (Grant No. 2021SHZDZX0102).https: //github.com/OpenDFM/LLM4Chemistry.SMILES and FormulasGiven SMILES, generate formulas, and reverse transformation.Chemistry-Related QA QA Chemical QA extracted from existing dataset or exam.Table1: The most frequently used chemistry tasks for SFT.
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, arXiv:2303.08774Shyamal Anadkat, et al. 2023. Gpt-4 technical report. arXiv preprint</p>
<p>Walid Ahmad, Elana Simon, arXiv:2209.01712Seyone Chithrananda, Gabriel Grand, and Bharath Ramsundar. 2022. Chemberta-2: Towards chemical foundation models. arXiv preprint</p>
<p>Flamingo: a visual language model for few-shot learning. Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc, Arthur Mensch, Katherine Millican, Malcolm Reynolds, Advances in neural information processing systems. 202235</p>
<p>Leveraging infrared spectroscopy for automated structure elucidation. Marvin Alberts, Teodoro Laino, Alain C Vaucher, 2023</p>
<p>Unraveling molecular structure: A multimodal spectroscopic dataset for chemistry. Marvin Alberts, Oliver Schilter, Federico Zipoli, Nina Hartrampf, Teodoro Laino, arXiv:2407.174922024arXiv preprint</p>
<p>. Anthropic, 2024Introducing claude models</p>
<p>Geometric deep learning on molecular representations. Kenneth Atz, Francesca Grisoni, Gisbert Schneider, Nature Machine Intelligence. 3122021</p>
<p>Jinze Bai, Shuai Bai, Shusheng Yang, Shijie Wang, Sinan Tan, Peng Wang, Junyang Lin, Chang Zhou, Jingren Zhou, arXiv:2308.12966Qwen-vl: A frontier large vision-language model with versatile abilities. 2023arXiv preprint</p>
<p>Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron Mckinnon, arXiv:2212.08073Constitutional ai: Harmlessness from ai feedback. 2022arXiv preprint</p>
<p>Autonomous chemical research with large language models. Robert Daniil A Boiko, Ben Macknight, Gabe Kline, Gomes, Nature. 62479922023</p>
<p>Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, arXiv:2303.12712Sparks of artificial general intelligence: Early experiments with gpt-4. 2023arXiv preprint</p>
<p>Roman Bushuiev, Anton Bushuiev, F Niek, Adamo De Jonge, Fleming Young, Raman Kretschmer, Janne Samusevich, Fei Heirman, Luke Wang, Kai Zhang, Dührkop, arXiv:2410.23326Massspecgym: A benchmark for the discovery and identification of molecules. 2024arXiv preprint</p>
<p>Hengxing Cai, Xiaochen Cai, Junhan Chang, Sihang Li, Lin Yao, Changxin Wang, Zhifeng Gao, Yongge Li, Mujie Lin, Shuwen Yang, arXiv:2403.01976Sciassess: Benchmarking llm proficiency in scientific literature analysis. 2024arXiv preprint</p>
<p>Boxi Cao, Keming Lu, Xinyu Lu, Jiawei Chen, Mengjie Ren, Hao Xiang, Peilin Liu, Yaojie Lu, Ben He, Xianpei Han, arXiv:2406.01252Towards scalable automated alignment of llms: A survey. 2024arXiv preprint</p>
<p>Instructmol: Multi-modal integration for building a versatile and reliable molecular assistant in drug discovery. He Cao, Zijing Liu, Xingyu Lu, Yuan Yao, Yu Li, arXiv:2311.162082023arXiv preprint</p>
<p>Do large language models understand chemistry? a conversation with chatgpt. Cayque Monteiro, Castro Nascimento, André Silva Pimentel, Journal of Chemical Information and Modeling. 6362023</p>
<p>Scholarchemqa: Unveiling the power of language models in chemical research question answering. Xiuying Chen, Tairan Wang, Taicheng Guo, Kehan Guo, Juexiao Zhou, Haoyang Li, Mingchen Zhuge, Jürgen Schmidhuber, Xin Gao, Xiangliang Zhang, arXiv:2407.169312024aarXiv preprint</p>
<p>Hight: Hierarchical graph tokenization for graph-language alignment. Yongqiang Chen, Quanming Yao, Juzheng Zhang, James Cheng, Yatao Bian, arXiv:2406.140212024barXiv preprint</p>
<p>Molnextr: A generalized deep learning model for molecular image recognition. Yufan Chen, Ching Ting Leung, Yong Huang, Jianwei Sun, Hao Chen, Hanyu Gao, arXiv:2403.036912024carXiv preprint</p>
<p>Internvl: Scaling up vision foundation models and aligning for generic visual-linguistic tasks. Zhe Chen, Jiannan Wu, Wenhai Wang, Weijie Su, Guo Chen, Sen Xing, Muyan Zhong, Qinglong Zhang, Xizhou Zhu, Lewei Lu, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2024d</p>
<p>Matchat: A large language model and application service platform for materials science. Zi-Yi Chen, Fan-Kai Xie, Meng Wan, Yang Yuan, Miao Liu, Zong-Guo Wang, Sheng Meng, Yan-Gang Wang, Chinese Physics B. 32111181042023</p>
<p>Yuan Chiang, Chia-Hong Chou, Janosh Riebesell, arXiv:2401.17244Llamp: Large language model made powerful for high-fidelity materials knowledge retrieval and distillation. 2024arXiv preprint</p>
<p>Deep reinforcement learning from human preferences. Advances in neural information processing systems. Jan Paul F Christiano, Tom Leike, Miljan Brown, Shane Martic, Dario Legg, Amodei, 201730</p>
<p>Unifying molecular and textual representations via multi-task language modelling. Dimitrios Christofidellis, Giorgio Giannone, Jannis Born, Ole Winther, Teodoro Laino, Matteo Manica, International Conference on Machine Learning. PMLR2023</p>
<p>Img2mol-accurate smiles recognition from molecular graphical depictions. Djork-Arné Clevert, Tuan Le, Robin Winter, Floriane Montanari, Chemical science. 12422021</p>
<p>Structured information extraction from scientific text with large language models. John Dagdelen, Alexander Dunn, Sanghoon Lee, Nicholas Walker, Gerbrand Andrew S Rosen, Kristin A Ceder, Anubhav Persson, Jain, Nature Communications. 15114182024</p>
<p>Organa: A robotic assistant for automated chemistry experimentation and characterization. Kourosh Darvish, Marta Skreta, Yuchi Zhao, Naruki Yoshikawa, Sagnik Som, Miroslav Bogdanovic, Yang Cao, Han Hao, Haoping Xu, Alán Aspuru-Guzik, arXiv:2401.069492024arXiv preprint</p>
<p>K2: A foundation language model for geoscience knowledge understanding and utilization. Cheng Deng, Tianhang Zhang, Zhongmou He, Qiyuan Chen, Yuanyuan Shi, Yi Xu, Luoyi Fu, Weinan Zhang, Xinbing Wang, Chenghu Zhou, Proceedings of the 17th ACM International Conference on Web Search and Data Mining. the 17th ACM International Conference on Web Search and Data Mining2024</p>
<p>Shunsuke Asahina, et al. 2012. Large-pore apertures in a series of metal-organic frameworks. Hexiang Deng, Sergio Grunder, Kyle E Cordova, Cory Valente, Hiroyasu Furukawa, Mohamad Hmadeh, Felipe Gándara, Adam C Whalley, Zheng Liu, science. 3366084</p>
<p>Bert: Pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, arXiv:1810.048052018arXiv preprint</p>
<p>Self-play with execution feedback: Improving instruction-following capabilities of large language models. Guanting Dong, Keming Lu, Chengpeng Li, Tingyu Xia, Bowen Yu, Chang Zhou, Jingren Zhou, arXiv:2406.135422024arXiv preprint</p>
<p>An image is worth 16x16 words: Transformers for image recognition at scale. Alexey Dosovitskiy, arXiv:2010.119292020arXiv preprint</p>
<p>Searching molecular structure databases with tandem mass spectra using csi: Fingerid. Kai Dührkop, Huibin Shen, Marvin Meusel, Juho Rousu, Sebastian Böcker, 2015Proceedings of the National Academy of Sciences112</p>
<p>Convolutional networks on graphs for learning molecular fingerprints. Dougal David K Duvenaud, Jorge Maclaurin, Rafael Iparraguirre, Timothy Bombarell, Alán Hirzel, Ryan P Aspuru-Guzik, Adams, Advances in neural information processing systems. 201528</p>
<p>Carl Edwards, Tuan Lai, Kevin Ros, Garrett Honke, Kyunghyun Cho, Heng Ji, arXiv:2204.11817Translation between molecules and natural language. 2022arXiv preprint</p>
<p>Text2mol: Cross-modal molecule retrieval with natural language queries. Carl Edwards, Chengxiang Zhai, Heng Ji, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language Processing2021</p>
<p>Developments and applications of the optimade api for materials discovery, design, and data exchange. Matthew Evans, Johan Bergsma, Andrius Merkys, Casper Andersen, Daniel Oskar B Andersson, Evgeny Beltrán, Tara M Blokhin, Rubén Castañeda Boland, Kamal Balderas, Choudhary, 2024Digital Discovery</p>
<p>Openchemie: An information extraction toolkit for chemistry literature. Yujie Vincent Fan, Alex Qian, Amber Wang, Connor W Wang, Regina Coley, Barzilay, Journal of Chemical Information and Modeling. 2024</p>
<p>Junfeng Fang, Shuai Zhang, Chang Wu, Zhengyi Yang, Zhiyuan Liu, Sihang Li, Kun Wang, Wenjie Du, Xiang Wang, arXiv:2402.03781Moltc: Towards molecular relational modeling in language models. 2024aarXiv preprint</p>
<p>Yin Fang, Xiaozhuan Liang, Ningyu Zhang, Kangwei Liu, Rui Huang, Zhuo Chen, Xiaohui Fan, Hua , arXiv:2306.08018Mol-instructions: A large-scale biomolecular instruction dataset for large language models. jun Chen. 2023arXiv preprint</p>
<p>Domainagnostic molecular generation with chemical feedback. Yin Fang, Ningyu Zhang, Zhuo Chen, Lingbing Guo, Xiaohui Fan, Huajun Chen, The Twelfth International Conference on Learning Representations. 2024b</p>
<p>Kehua Feng, Keyan Ding, Weijie Wang, Xiang Zhuang, Zeyuan Wang, Ming Qin, Yu Zhao, Jianhua Yao, Qiang Zhang, Huajun Chen, arXiv:2406.09098Sciknoweval: Evaluating multi-level scientific knowledge of large language models. 2024arXiv preprint</p>
<p>Can llms solve molecule puzzles? a multimodal benchmark for molecular structure elucidation. Kehan Guo, Bozhao Nan, Yujun Zhou, Taicheng Guo, Zhichun Guo, Mihir Surve, Zhenwen Liang, V Nitesh, Olaf Chawla, Xiangliang Wiest, Zhang, The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track. 2024</p>
<p>What can large language models do in chemistry? a comprehensive benchmark on eight tasks. Taicheng Guo, Bozhao Nan, Zhenwen Liang, Zhichun Guo, Nitesh Chawla, Olaf Wiest, Xiangliang Zhang, Advances in Neural Information Processing Systems. 202336</p>
<p>Inchi-the worldwide chemical structure identifier standard. Stephen Heller, Alan Mcnaught, Stephen Stein, Dmitrii Tchekhovskoi, Igor Pletnev, Journal of cheminformatics. 52013</p>
<p>Weihua Hu, Bowen Liu, Joseph Gomes, Marinka Zitnik, Percy Liang, Vijay Pande, Jure Leskovec, arXiv:1905.12265Strategies for pre-training graph neural networks. 2019arXiv preprint</p>
<p>De novo drug design using reinforcement learning with multiple gpt agents. Xiuyuan Hu, Guoqing Liu, Yang Zhao, Hao Zhang, Advances in Neural Information Processing Systems. 202436</p>
<p>Language is not all you need: Aligning perception with language models. Shaohan Huang, Li Dong, Wenhui Wang, Yaru Hao, Saksham Singhal, Shuming Ma, Tengchao Lv, Lei Cui, Owais Khan Mohammed, Barun Patra, Advances in Neural Information Processing Systems. 2024a36</p>
<p>Chemeval: A comprehensive multi-level chemical evaluation for large language models. Yuqing Huang, Rongyang Zhang, Xuesong He, Xuyang Zhi, Hao Wang, Xin Li, Feiyang Xu, Deguang Liu, Huadong Liang, Yi Li, arXiv:2409.139892024barXiv preprint</p>
<p>Chemtsv2: Functional molecular design using de novo molecule generator. Shoichi Ishida, Tanuj Aasawat, Masato Sumita, Michio Katouda, Tatsuya Yoshizawa, Kazuki Yoshizoe, Koji Tsuda, Kei Terayama, Wiley Interdisciplinary Reviews: Computational Molecular Science. 136e16802023</p>
<p>Large language models open new way of ai-assisted molecule design for chemists. Shoichi Ishida, Tomohiro Sato, Teruki Honma, Kei Terayama, 2024</p>
<p>Leveraging large language models for predictive chemistry. Kevin Maik, Jablonka , Philippe Schwaller, Andres Ortega-Guerrero, Berend Smit, Nature Machine Intelligence. 622024</p>
<p>Commentary: The materials project: A materials genome approach to accelerating materials innovation. Anubhav Jain, Ping Shyue, Geoffroy Ong, Wei Hautier, William Davidson Chen, Stephen Richards, Shreyas Dacek, Dan Cholia, David Gunter, Gerbrand Skinner, Ceder, APL materials. 112013</p>
<p>Language models in molecular discovery. Nikita Janakarajan, Tim Erdmann, Sarath Swaminathan, Teodoro Laino, Jannis Born, Drug Development Supported by Informatics. Springer2024</p>
<p>Visscience: An extensive benchmark for evaluating k12 educational multi-modal scientific reasoning. Zhihuan Jiang, Zhen Yang, Jinhao Chen, Zhengxiao Du, Weihan Wang, Bin Xu, Yuxiao Dong, Jie Tang, arXiv:2409.137302024arXiv preprint</p>
<p>Chatmof: an artificial intelligence system for predicting and generating metal-organic frameworks using large language models. Yeonghun Kang, Jihan Kim, Nature Communications. 15147052024</p>
<p>A multi-modal pre-training transformer for universal transfer learning in metalorganic frameworks. Yeonghun Kang, Hyunsoo Park, Berend Smit, Jihan Kim, Nature Machine Intelligence. 532023</p>
<p>Pubchem 2019 update: improved access to chemical data. Sunghwan Kim, Jie Chen, Tiejun Cheng, Asta Gindulyte, Jia He, Siqian He, Qingliang Li, Benjamin A Shoemaker, Paul A Thiessen, Bo Yu, Nucleic acids research. 47D12019</p>
<p>P Diederik, Kingma, arXiv:1312.6114Auto-encoding variational bayes. 2013arXiv preprint</p>
<p>Metal-organic frameworks (mofs). Susumu Kitagawa, Chemical Society Reviews. 43162014</p>
<p>Selfreferencing embedded strings (selfies): A 100% robust molecular string representation. Mario Krenn, Florian Häse, Akshatkumar Nigam, Machine Learning: Science and Technology. 14450242020Pascal Friederich, and Alan Aspuru-Guzik</p>
<p>Molx: Enhancing large language models for molecular learning with a multi-modal extension. Khiem Le, Zhichun Guo, Kaiwen Dong, Xiaobao Huang, Bozhao Nan, Roshni Iyer, Xiangliang Zhang, Olaf Wiest, Wei Wang, Nitesh V Chawla, arXiv:2406.067772024arXiv preprint</p>
<p>Rlaif: Scaling reinforcement learning from human feedback with ai feedback. Harrison Lee, Samrat Phatale, Hassan Mansoor, Kellie Lu, Thomas Mesnard, Colton Bishop, Victor Carbune, Abhinav Rastogi, arXiv:2309.002672023arXiv preprint</p>
<p>Retrieval-augmented generation for knowledge-intensive nlp tasks. Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-Tau Yih, Tim Rocktäschel, Advances in Neural Information Processing Systems. 202033</p>
<p>Llava-med: Training a large language-and-vision assistant for biomedicine in one day. Chunyuan Li, Cliff Wong, Sheng Zhang, Naoto Usuyama, Haotian Liu, Jianwei Yang, Tristan Naumann, Hoifung Poon, Jianfeng Gao, Advances in Neural Information Processing Systems. 2024a36</p>
<p>Large language models are in-context molecule learners. Jiatong Li, Wei Liu, Zhihao Ding, Wenqi Fan, Yuqiang Li, Qing Li, arXiv:2403.041972024barXiv preprint</p>
<p>Blip-2: Bootstrapping language-image pretraining with frozen image encoders and large language models. Junnan Li, Dongxu Li, Silvio Savarese, Steven Hoi, International conference on machine learning. PMLR2023</p>
<p>Junxian Li, Di Zhang, Xunzhi Wang, Zeying Hao, Jingdi Lei, Qian Tan, Cai Zhou, Wei Liu, Weiyun Wang, Zhe Chen, arXiv:2408.07246Seeing and understanding: Bridging vision with chemical knowledge via chemvlm. 2024carXiv preprint</p>
<p>Sihang Li, Zhiyuan Liu, Yanchen Luo, Xiang Wang, Xiangnan He, Kenji Kawaguchi, arXiv:2401.13923Tat-Seng Chua, and Qi Tian. 2024d. Towards 3d molecule-text interpretation in language models. arXiv preprint</p>
<p>Chang Liao, Yemin Yu, Yu Mei, Ying Wei, arXiv:2402.01439From words to molecules: A survey of large language models in chemistry. 2024arXiv preprint</p>
<p>An end-to-end deep learning framework for translating mass spectra to de-novo molecules. Eleni E Litsa, Vijil Chenthamarakshan, Payel Das, Lydia E Kavraki, Communications Chemistry. 611322023</p>
<p>Visual instruction tuning. Haotian Liu, Chunyuan Li, Qingyang Wu, Yong Jae Lee, Advances in neural information processing systems. 2024a36</p>
<p>Drak: Unlocking molecular insights with domain-specific retrieval-augmented knowledge in llms. Jinzhe Liu, Xiangsheng Huang, Zhuo Chen, Yin Fang, 2024bAuthorea Preprints</p>
<p>Git-mol: A multi-modal large language model for molecular science with graph, image, and text. Pengfei Liu, Yiming Ren, Computers in biology and medicine. 171108073Jun Tao, and Zhixiang Ren. 2024c</p>
<p>Jian Tang, Chaowei Xiao, and Animashree Anandkumar. 2023a. Multimodal molecule structure-text model for text-based retrieval and editing. Shengchao Liu, Mehmet F Demirel, Yingyu Liang ; Shengchao, Weili Liu, Chengpeng Nie, Jiarui Wang, Zhuoran Lu, Ling Qiao, Liu, Nature Machine Intelligence. 32122019N-gram graph: Simple unsupervised representation for graphs, with applications to molecules</p>
<p>Yixin Liu, Pengfei Liu, Dragomir Radev, Graham Neubig, arXiv:2203.16804Brio: Bringing order to abstractive summarization. 2022arXiv preprint</p>
<p>Moleculargpt: Open large language model (llm) for few-shot molecular property prediction. Yuyan Liu, Sirui Ding, Sheng Zhou, Wenqi Fan, Qiaoyu Tan, arXiv:2406.129502024darXiv preprint</p>
<p>Swin transformer: Hierarchical vision transformer using shifted windows. Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, Baining Guo, Proceedings of the IEEE/CVF international conference on computer vision. the IEEE/CVF international conference on computer vision2021</p>
<p>Molca: Molecular graph-language modeling with cross-modal projector and uni-modal adapter. Zhiyuan Liu, Sihang Li, Yanchen Luo, Hao Fei, Yixin Cao, Kenji Kawaguchi, Xiang Wang, Tat-Seng Chua, arXiv:2310.127982023barXiv preprint</p>
<p>Reactxt: Understanding molecular" reaction-ship" via reaction-contextualized moleculetext pretraining. Zhiyuan Liu, Yaorui Shi, An Zhang, Sihang Li, Enzhi Zhang, Xiang Wang, Kenji Kawaguchi, Tat-Seng Chua, arXiv:2405.142252024earXiv preprint</p>
<p>Alán Aspuru-Guzik, et al. 2024. nach0: Multimodal natural and chemical languages foundation model. Micha Livne, Zulfat Miftahutdinov, Elena Tutubalina, Maksim Kuznetsov, Daniil Polykovskiy, Annika Brundyn, Aastha Jhunjhunwala, Anthony Costa, Alex Aliper, Chemical Science. 1522</p>
<p>Learn to explain: Multimodal reasoning via thought chains for science question answering. Pan Lu, Swaroop Mishra, Tanglin Xia, Liang Qiu, Kai-Wei Chang, Song-Chun Zhu, Oyvind Tafjord, Peter Clark, Ashwin Kalyan, Advances in Neural Information Processing Systems. 202235</p>
<p>Augmenting large language models with chemistry tools. Andres M Bran, Sam Cox, Oliver Schilter, Carlo Baldassari, Andrew D White, Philippe Schwaller, Nature Machine Intelligence. 2024</p>
<p>Bridging chemical modalities by aligning embeddings. Adrian Mirza, Sebastian Starke, Erinc Merdivan, Kevin Maik Jablonka, AI for Accelerated Materials Design. Vienna2024. 2024</p>
<p>The generation of a unique machine description for chemical structures-a technique developed at chemical abstracts service. Harry L Morgan, Journal of chemical documentation. 521965</p>
<p>Molgrapher: Graphbased visual recognition of chemical structures. Lucas Morin, Martin Danelljan, Maria Isabel Agea, Ahmed Nassar, Valery Weber, Ingmar Meijer, Peter Staar, Fisher Yu, Proceedings of the IEEE/CVF International Conference on Computer Vision. the IEEE/CVF International Conference on Computer Vision2023</p>
<p>Training language models to follow instructions with human feedback. Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, Advances in neural information processing systems. 202235</p>
<p>Computational design of metal-organic frameworks with unprecedented high hydrogen working capacity and high synthesizability. Junkil Park, Yunsung Lim, Sangwon Lee, Jihan Kim, Chemistry of Materials. 3512022</p>
<p>Qizhi Pei, Lijun Wu, Kaiyuan Gao, Jinhua Zhu, Yue Wang, Zun Wang, Tao Qin, Rui Yan, arXiv:2403.01528Leveraging biomolecule and natural language through multi-modal learning: A survey. 2024aarXiv preprint</p>
<p>Qizhi Pei, Lijun Wu, Kaiyuan Gao, Jinhua Zhu, Rui Yan, arXiv:2406.057973d-molt5: Towards unified 3d moleculetext modeling with 3d molecular tokenization. 2024barXiv preprint</p>
<p>Transfer learning enables the molecular transformer to predict regioand stereoselective reactions on carbohydrates. Giorgio Pesciullesi, Philippe Schwaller, Teodoro Laino, Jean-Louis Reymond, Nature communications. 11148742020</p>
<p>Rxnscribe: A sequence generation model for reaction diagram parsing. Yujie Qian, Jiang Guo, Zhengkai Tu, Connor W Coley, Regina Barzilay, Journal of Chemical Information and Modeling. 63132023</p>
<p>Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, arXiv:2307.16789Toolllm: Facilitating large language models to master 16000+ real-world apis. 2023arXiv preprint</p>
<p>Language models are unsupervised multitask learners. Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, OpenAI blog. 1892019</p>
<p>Direct preference optimization: Your language model is secretly a reward model. Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher D Manning, Stefano Ermon, Chelsea Finn, Advances in Neural Information Processing Systems. 202436</p>
<p>Exploring the limits of transfer learning with a unified text-to-text transformer. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, Journal of machine learning research. 211402020</p>
<p>Christopher J Mayk Caldas Ramos, Andrew D Collison, White, arXiv:2407.01603A review of large language models and autonomous agents in chemistry. 2024arXiv preprint</p>
<p>E (n) equivariant graph neural networks. Garcia Vıctor, Emiel Satorras, Max Hoogeboom, Welling, International conference on machine learning. PMLR2021</p>
<p>Toolformer: Language models can teach themselves to use tools. Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, Thomas Scialom, Advances in Neural Information Processing Systems. 202436</p>
<p>John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, Oleg Klimov, arXiv:1707.06347Proximal policy optimization algorithms. 2017arXiv preprint</p>
<p>Schnet-a deep learning architecture for molecules and materials. Kristof T Schütt, E Huziel, P-J Sauceda, Alexandre Kindermans, K-R Tkatchenko, Müller, The Journal of Chemical Physics. 241482018</p>
<p>Usage and limitations of liquid chromatography-tandem mass spectrometry (lcms/ms) in clinical routine laboratories. Christoph Seger, Wiener Medizinische Wochenschrift. 16221-222012. 1946</p>
<p>Planning chemical syntheses with deep neural networks and symbolic ai. Marwin Hs Segler, Mike Preuss, Mark P Waller, Nature. 55576982018</p>
<p>Rico Sennrich, arXiv:1508.07909Neural machine translation of rare words with subword units. 2015arXiv preprint</p>
<p>Nuclear magnetic resonance spectroscopy and its key role in environmental research. Myrna J Andre J Simpson, Ronald Simpson, Soong, 2012</p>
<p>Chemreasoner: Heuristic search over a large language model's knowledge space using quantumchemical feedback. Carl Henry W Sprueill, Khushbu Edwards, Agarwal, Udishnu Mariefel V Olarte, Conrad Sanyal, Hongbin Johnston, Heng Liu, Sutanay Ji, Choudhury, Forty-first International Conference on Machine Learning. 2024</p>
<p>Zinc 15-ligand discovery for everyone. Teague Sterling, John J Irwin, Journal of chemical information and modeling. 55112015</p>
<p>Learning to summarize with human feedback. Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford, Dario Amodei, Paul F Christiano, Advances in Neural Information Processing Systems. 202033</p>
<p>Msnovelist: de novo structure generation from mass spectra. Kai Michael A Stravs, Sebastian Dührkop, Nicola Böcker, Zamboni, Nature Methods. 1972022</p>
<p>Bing Su, Dazhao Du, Zhao Yang, Yujie Zhou, Jiangmeng Li, Anyi Rao, Hao Sun, Zhiwu Lu, Ji-Rong Wen, arXiv:2209.05481A molecular multimodal foundation model associating molecule graphs with natural language. 2022arXiv preprint</p>
<p>Scieval: A multi-level large language model evaluation benchmark for scientific research. Liangtai Sun, Yang Han, Zihan Zhao, Da Ma, Zhennan Shen, Baocai Chen, Lu Chen, Kai Yu, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202438</p>
<p>Ekin Dogus Cubuk, Amil Merchant, et al. 2023. An autonomous laboratory for the accelerated synthesis of novel materials. Nathan J Szymanski, Bernardus Rendy, Yuxing Fei, Rishi E Kumar, Tanjin He, David Milsted, Matthew J Mcdermott, Max Gallant, Nature. 6247990</p>
<p>Mollm: a unified language model for integrating biomedical text with 2d and 3d molecular representations. Xiangru Tang, Andrew Tran, Jeffrey Tan, Mark B Gerstein, Bioinformatics. 40Supplement_12024</p>
<p>Ross Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony Hartshorn, Elvis Saravia, Andrew Poulton, Viktor Kerkez, Robert Stojnic, arXiv:2211.09085Galactica: A large language model for science. 2022arXiv preprint</p>
<p>Minyang Tian, Luyu Gao, Dylan Shizhuo, Xinan Zhang, Cunwei Chen, Xuefei Fan, Roland Guo, Pan Haas, Kittithat Ji, Yao Krongchon, Li, arXiv:2407.13168Scicode: A research coding benchmark curated by scientists. 2024arXiv preprint</p>
<p>Self-driving laboratories for chemistry and materials science. Gary Tom, Stefan P Schmid, Sterling G Baird, Yang Cao, Kourosh Darvish, Han Hao, Stanley Lo, Sergio Pablo-García, Ella M Rajaonson, Marta Skreta, Chemical Reviews. 2024</p>
<p>Thibaut Hugo Touvron, Gautier Lavril, Xavier Izacard, Marie-Anne Martinet, Timothée Lachaux, Baptiste Lacroix, Naman Rozière, Eric Goyal, Hambro, arXiv:2302.13971Faisal Azhar, et al. 2023a. Llama: Open and efficient foundation language models. arXiv preprint</p>
<p>Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, arXiv:2307.09288Llama 2: Open foundation and fine-tuned chat models. 2023barXiv preprint</p>
<p>Attention is all you need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, Illia Polosukhin, Advances in neural information processing systems. 201730</p>
<p>Cfmid 4.0: more accurate esi-ms/ms spectral prediction and compound identification. Fei Wang, Jaanus Liigand, Siyang Tian, David Arndt, Russell Greiner, David S Wishart, Analytical chemistry. 93342021</p>
<p>Xiaoxuan Wang, Ziniu Hu, Pan Lu, Yanqiao Zhu, Jieyu Zhang, Satyen Subramaniam, Shichang Arjun R Loomba, Yizhou Zhang, Wei Sun, Wang, arXiv:2307.10635Scibench: Evaluating college-level scientific problem-solving abilities of large language models. 2023arXiv preprint</p>
<p>Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, arXiv:2206.07682Emergent abilities of large language models. 2022aarXiv preprint</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Denny Quoc V Le, Zhou, Advances in neural information processing systems. 2022b35</p>
<p>Smiles, a chemical language and information system. 1. introduction to methodology and encoding rules. David Weininger, Journal of chemical information and computer sciences. 2811988</p>
<p>Crowdsourcing multiple choice science questions. Johannes Welbl, Nelson F Liu, Matt Gardner, arXiv:1707.062092017arXiv preprint</p>
<p>Reactiondataextractor 2.0: A deep learning approach for data extraction from chemical reaction schemes. M Damian, Jacqueline M Wilary, Cole, Journal of Chemical Information and Modeling. 63192023</p>
<p>Simple statistical gradientfollowing algorithms for connectionist reinforcement learning. Williams Ronald, Machine learning. 81992</p>
<p>Moleculenet: a benchmark for molecular machine learning. Zhenqin Wu, Bharath Ramsundar, Evan N Feinberg, Joseph Gomes, Caleb Geniesse, S Aneesh, Karl Pappu, Vijay Leswing, Pande, Chemical science. 922018</p>
<p>A systematic survey of chemical pre-trained models. Jun Xia, Yanqiao Zhu, Yuanqi Du, Stan Z Li, arXiv:2210.164842022arXiv preprint</p>
<p>Decoupled selfsupervised learning for graphs. Teng Xiao, Zhengyu Chen, Zhimeng Guo, Zeyang Zhuang, Suhang Wang, Advances in Neural Information Processing Systems. 202235</p>
<p>Yi Xiao, Xiangxin Zhou, Qiang Liu, Liang Wang, arXiv:2403.13830Bridging text and molecule: A survey on multimodal frameworks for molecule. 2024arXiv preprint</p>
<p>Keyulu Xu, Weihua Hu, Jure Leskovec, Stefanie Jegelka, arXiv:1810.00826How powerful are graph neural networks?. 2018arXiv preprint</p>
<p>Hallucination is inevitable: An innate limitation of large language models. Ziwei Xu, Sanjay Jain, Mohan Kankanhalli, arXiv:2401.118172024arXiv preprint</p>
<p>Deco: Decoupling token compression from semantic abstraction in multimodal large language models. Linli Yao, Lei Li, Shuhuai Ren, Lean Wang, Yuanxin Liu, Xu Sun, Lu Hou, arXiv:2405.209852024arXiv preprint</p>
<p>Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, Yuan Cao, arXiv:2210.03629React: Synergizing reasoning and acting in language models. 2022arXiv preprint</p>
<p>Yanpeng Ye, Jie Ren, Shaozhou Wang, Yuwei Wan, Imran Razzak, Tong Xie, Wenjie Zhang, arXiv:2404.03080Construction of functional materials knowledge graph in multidisciplinary materials science via large language model. 2024arXiv preprint</p>
<p>Large language models for chemistry robotics. Naruki Yoshikawa, Marta Skreta, Kourosh Darvish, Sebastian Arellano-Rubach, Zhi Ji, Lasse Bjørn Kristensen, Andrew Zou Li, Yuchi Zhao, Haoping Xu, Artur Kuramshin, Autonomous Robots. 4782023</p>
<p>Llasmol: Advancing large language models for chemistry with a large-scale, comprehensive, high-quality instruction tuning dataset. Botao Yu, Frazier N Baker, Ziqi Chen, Xia Ning, Huan Sun, arXiv:2402.093912024arXiv preprint</p>
<p>Selformer: molecular representation learning via selfies language models. Atakan Yüksel, Erva Ulusoy, Atabey Ünlü, Tunca Dogan, Machine Learning: Science and Technology. 2023425035</p>
<p>Hierarchical molecular graph self-supervised learning for property prediction. Xuan Zang, Xianbing Zhao, Buzhou Tang, Communications Chemistry. 61342023</p>
<p>Di Zhang, Wei Liu, Qian Tan, Jingdan Chen, Hang Yan, Yuliang Yan, Jiatong Li, Weiran Huang, Xiangyu Yue, Dongzhan Zhou, arXiv:2402.06852Chemllm: A chemical large language model. 2024aarXiv preprint</p>
<p>HuatuoGPT, towards taming language model to be a doctor. Hongbo Zhang, Junying Chen, Feng Jiang, Fei Yu, Zhihong Chen, Guiming Chen, Jianquan Li, Xiangbo Wu, Zhang Zhiyi, Qingying Xiao, Xiang Wan, Benyou Wang, Haizhou Li, 10.18653/v1/2023.findings-emnlp.725Findings of the Association for Computational Linguistics: EMNLP 2023. SingaporeAssociation for Computational Linguistics2023a</p>
<p>Qiang Zhang, Keyang Ding, Tianwen Lyv, Xinda Wang, Qingyu Yin, Yiwen Zhang, Jing Yu, Yuhao Wang, Xiaotong Li, Zhuoyi Xiang, arXiv:2401.14656Scientific large language models: A survey on biological &amp; chemical domains. 2024barXiv preprint</p>
<p>Shengyu Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang, Xiaofei Sun, Shuhe Wang, Jiwei Li, Runyi Hu, Tianwei Zhang, Fei Wu, arXiv:2308.10792Instruction tuning for large language models: A survey. 2023barXiv preprint</p>
<p>Runze Zhang, et al. 2024c. Fine-tuning large language models for chemical text mining. Wei Zhang, Qinggong Wang, Xiangtai Kong, Jiacheng Xiong, Shengkun Ni, Duanhua Cao, Buying Niu, Mingan Chen, Yameng Li, Chemical Science. </p>            </div>
        </div>

    </div>
</body>
</html>