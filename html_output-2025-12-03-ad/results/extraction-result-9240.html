<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9240 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9240</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9240</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-162.html">extraction-schema-162</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-272366479</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2409.01980v2.pdf" target="_blank">Large Language Models for Anomaly and Out-of-Distribution Detection: A Survey</a></p>
                <p><strong>Paper Abstract:</strong> Detecting anomalies or out-of-distribution (OOD) samples is critical for maintaining the reliability and trustworthiness of machine learning systems. Recently, Large Language Models (LLMs) have demonstrated their effectiveness not only in natural language processing but also in broader applications due to their advanced comprehension and generative capabilities. The integration of LLMs into anomaly and OOD detection marks a significant shift from the traditional paradigm in the field. This survey focuses on the problem of anomaly and OOD detection under the context of LLMs. We propose a new taxonomy to categorize existing approaches into two classes based on the role played by LLMs. Following our proposed taxonomy, we further discuss the related work under each of the categories and finally discuss potential challenges and directions for future research in this field. We also provide an up-to-date reading list of relevant papers.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9240.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9240.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SIGLLM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SIGLLM (unnamed pipeline in survey)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Survey-reported prompting pipeline applying large LLMs to time-series anomaly detection using role-play prompts and an LLM-based forecasting-comparison pipeline to identify anomalous elements.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>unspecified large language model (LLM) — survey reports use of large decoder-based LLMs</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>transformer (decoder-style LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>time series (sequential numerical data)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>general monitoring/time-series domains (e.g., system metrics, monitoring signals) as reported in survey</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>point and short-sequence anomalies detected via deviation from forecast / anomalous elements</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Prompting-based detection: (a) direct role-play prompting to label anomalous elements in series; (b) forecasting pipeline where LLM generates forecasts and anomalies are detected by comparing original sequence to LLM forecasts (discrepancy indicates anomaly). No full LLM fine-tuning reported in survey for this pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Not specified in survey for SIGLLM; survey situates these against traditional time-series detectors (e.g., statistical forecasting, reconstruction-based methods) but specific baselines not given.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Survey-level descriptions only; typical metrics used in time-series anomaly work include AUROC, F1, precision/recall but SIGLLM numeric metrics are not provided in the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Survey states SIGLLM explores two pipelines and shows promising detection behavior with forecasting-based discrepancies, but no numerical results are reported in this survey.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Not quantified in survey; described as a promising zero-/few-shot alternative to traditional detectors but direct experimental comparisons are not detailed in the survey text.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Modality gap between numerical sequences and text prompts; token-length and input-size limits when converting long sequences to text; computational cost of running large LLMs for long sequences; survey does not report specific failure-case studies for SIGLLM.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Using an LLM's forecasting ability as an indirect detector (forecast vs actual discrepancy) is a novel prompting-based approach for sequential anomaly detection highlighted by the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Language Models for Anomaly and Out-of-Distribution Detection: A Survey', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9240.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9240.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLMAD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLMAD (Log/Time-series LLM Anomaly Detection, as cited)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prompting-based method for time-series/log anomaly detection that leverages in-context learning (retrieved examples) and chain-of-thought (CoT) prompts to inject domain knowledge and improve zero-/few-shot detection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>unspecified large language model(s) (LLMs used with in-context examples)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>transformer (decoder-style LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>time series and log sequences (sequential textualized or numeric data converted to text)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>system logs, monitoring/time-series data</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>anomalous sequences/entries and contextual anomalies in logs/time series</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Prompting without LLM tuning: retrieve in-context examples from a constructed database and use CoT-style prompts that inject domain knowledge to guide the LLM to classify or highlight anomalies in sequences/logs.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Survey does not enumerate specific baselines used by LLMAD; typical baselines would include rule-based log detectors and statistical time-series detectors but not specified here.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Survey-level only; common metrics for these tasks include AUROC, precision/recall, and F1 but LLMAD numeric values are not reported in the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Survey reports that combining retrieval of examples and CoT prompting improves detection quality compared to simpler prompts, but provides no numeric performance figures.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Survey indicates improvement over simpler prompting strategies (implicit baseline) but does not provide head-to-head comparisons with traditional anomaly detectors in the survey text.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Same general LLM limitations: input token limits for long sequences, potential hallucination when prompts are ambiguous, and computational inefficiency; specific failure cases for LLMAD are not detailed in the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Retrieval-augmented in-context examples plus CoT prompts can inject domain knowledge into zero-shot/few-shot LLM detection for sequences, improving quality without full fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Language Models for Anomaly and Out-of-Distribution Detection: A Survey', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9240.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9240.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LogPrompt</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LogPrompt: Prompt engineering towards zero-shot and interpretable log analysis</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prompt-engineering study that evaluates self-prompting, in-context prompting, and chain-of-thought prompting strategies for log-based anomaly detection, finding CoT prompts perform best among prompting strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Logprompt: Prompt engineering towards zero-shot and interpretable log analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLMs (survey cites application to GPT-style models; original LogPrompt paper targets ChatGPT/GPT-family in zero-shot prompts)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>transformer (decoder-style LLMs such as GPT-family)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>log sequences (textual log entries; sequences of categorical+text fields)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>system logs / software monitoring logs</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>anomalous log entries (errors, abnormal sequences of events)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Prompting-based zero-shot detection: design task-specific prompt templates including CoT instructions and step-by-step rules to classify log entries as normal or abnormal; parse LLM textual response to extract anomaly labels and scores.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Survey does not list the exact baselines LogPrompt compared against; it compares three prompting strategies (self-prompt, CoT, in-context) internally and notes CoT outperforms other prompt strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not enumerated in the survey; typical metrics would be accuracy, F1, AUROC; the survey only reports relative superiority of CoT prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Survey states that CoT prompting outperforms self-prompting and in-context prompting for log anomaly tasks; no numeric values included in the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>CoT prompting > other prompting strategies per the survey; comparisons to classical log-analysis models are not detailed in the survey text.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Potential hallucination in LLM outputs, input token limits for long logs, computational cost; additionally, converting structured logs to textual prompts may lose fine-grained numeric fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Carefully designed CoT prompts with explicit stepwise anomaly rules improve LLM zero-shot detection on logs, giving more interpretable decisions compared to simple prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Language Models for Anomaly and Out-of-Distribution Detection: A Survey', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9240.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9240.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LogGPT / LogFit</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LogGPT (Exploring ChatGPT for log-based anomaly detection) / LogFit (embedding-based log methods)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Works exploring LLMs (ChatGPT) as a tool to perform or assist log-based anomaly detection, either via prompting (LogGPT) or via generation of embeddings/textual features used in downstream detectors (LogFit).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Loggpt: Exploring chatgpt for log-based anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT / ChatGPT-style LLMs (LogGPT); encoder LLMs / embedding models in LogFit</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>transformer (ChatGPT / decoder; encoder-based embedding LMs for LogFit)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>log sequences (textual log entries)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>software/system logs and monitoring domains</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>anomalous log entries and sequences (errors, unexpected events)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>LogGPT: prompting ChatGPT to analyze logs and flag anomalies (zero-shot prompting). LogFit: use LLM-derived embeddings (text embeddings from log entries) as representations for downstream anomaly detectors.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Survey does not specify exact baselines for these works; typical baselines include classical log anomaly detectors and supervised classifiers on log features.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Survey-level only; usual metrics include F1, precision/recall, AUROC but numeric results are not reported in the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Survey cites these works as exploratory studies showing LLMs and LLM-derived embeddings can be effective for log anomaly detection; no numerical performance reported in the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Survey does not provide a granular comparison; these methods are presented as promising alternatives or supplements to classical log detectors.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Hallucination risk from LLM outputs, need to convert structured logs to text which may lose structure, token limits for long log windows, and computational costs for large LLM calls.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>LLMs can be used either directly via prompting for interpretable zero-shot log analysis or indirectly via embeddings to feed conventional detectors; embedding-based use can be more scalable/structured while prompting offers interpretability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Language Models for Anomaly and Out-of-Distribution Detection: A Survey', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9240.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e9240.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Tabular (Li et al., 2024a)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Anomaly detection of tabular data using LLMs</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A study adapting LLMs to tabular anomaly detection by converting tabular rows into prompt templates and using parameter-efficient fine-tuning (LoRA) with a synthetic labeled dataset to teach the LLM to output anomaly labels for batches.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Anomaly detection of tabular data using llms.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>unspecified pre-trained LLM (prompted/fine-tuned with LoRA in the referenced work)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>transformer (decoder-style LLM used as text-based classifier)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>tabular rows (mixed-type lists: categorical + numerical fields converted to text prompts)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>general tabular domains (survey does not restrict to a single domain; Li et al. target tabular anomaly detection broadly)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>outliers in tabular data (anomalous rows / entries)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Convert tabular rows into structured textual prompts and query the LLM to classify rows as anomalous or normal; fine-tune the LLM using parameter-efficient LoRA on a synthetic supervised dataset with ground-truth anomaly labels to adapt to batch-level detection.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Not specified in the survey text for this paper; typical tabular baselines include isolation forest, LOF, autoencoders, and statistical detectors but survey does not list explicit comparisons here.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Survey does not list numerical metrics from this paper; typical metrics would include AUROC, AUPR, precision/recall and F1 for tabular anomaly tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Survey reports that Tabular uses LoRA fine-tuning on a synthetic supervised dataset to adapt LLMs for batch-level anomaly detection but does not provide numeric performance values.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Not detailed in survey; the approach is presented as a way to leverage LLMs for tabular anomalies, with PEFT reducing compute, but direct baseline comparisons are not described in the survey text.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Converting structured numeric/tabular data to text can be inefficient (long prompts), token-limit constraints for large tables, potential loss of numeric precision or relational structure during textualization, and computational cost even with PEFT; survey notes these generic limitations.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Parameter-efficient fine-tuning (LoRA) on synthetic labeled examples enables an LLM to perform batch-level tabular anomaly detection without full model re-training, suggesting a practical adaptation path for LLMs on structured lists.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Language Models for Anomaly and Out-of-Distribution Detection: A Survey', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9240.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e9240.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TimeSeries-LLM (Liu et al., 2024?)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Large language models can deliver accurate and interpretable time series anomaly detection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced work demonstrating that LLMs can perform accurate and interpretable time-series anomaly detection, leveraging LLMs' reasoning and generation capabilities to detect and explain anomalies in sequential data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Large language models can deliver accurate and interpretable time series anomaly detection</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>large decoder-style LLMs (paper referenced in survey; exact model names unspecified in survey summary)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>transformer (decoder LLMs with in-context/few-shot capabilities)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>time series (sequential numerical data)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>monitoring systems / general time-series datasets (YAHOO, ECG, etc., are mentioned elsewhere in survey as common datasets)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>point anomalies and contextual anomalies in time series</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Use LLM prompting (zero- or few-shot) to detect anomalies in time-series by having the LLM reason about sequence behavior and optionally produce explanations; may combine forecasting, CoT, and retrieved in-context examples to improve detection and interpretability.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Survey does not list the baselines used by the referenced time-series paper; general baseline families include statistical forecasting, autoencoders, and modern deep learning detectors.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Survey-level only; common metrics for time-series anomalies include AUROC, precision/recall, F1, false positive rates; the referenced paper is cited as reporting accurate detection but survey does not reproduce numbers.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Survey summarizes that the paper shows accurate and interpretable detection with LLMs for time-series, but provides no numeric performance values in this survey text.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Survey-level claim that LLM methods can be competitive or advantageous in zero-/few-shot settings relative to traditional methods, but detailed comparisons from the original paper are not reproduced in the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Token limits for long sequences, computational overhead, and possible hallucination; converting high-resolution numeric sequences to text can be inefficient and may lose precision—survey highlights these general limitations.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>LLMs provide both detection and human-readable explanations for time-series anomalies; combining forecasting and CoT reasoning leverages LLMs' strengths for sequential anomaly tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Language Models for Anomaly and Out-of-Distribution Detection: A Survey', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Logprompt: Prompt engineering towards zero-shot and interpretable log analysis. <em>(Rating: 2)</em></li>
                <li>Loggpt: Exploring chatgpt for log-based anomaly detection. <em>(Rating: 2)</em></li>
                <li>Anomaly detection of tabular data using llms. <em>(Rating: 2)</em></li>
                <li>Large language models can deliver accurate and interpretable time series anomaly detection <em>(Rating: 2)</em></li>
                <li>Anomaly detection on unstable logs with gpt models. <em>(Rating: 1)</em></li>
                <li>LLM-Monitor (referenced work on using object detectors + LLMs for video anomaly detection) <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9240",
    "paper_id": "paper-272366479",
    "extraction_schema_id": "extraction-schema-162",
    "extracted_data": [
        {
            "name_short": "SIGLLM",
            "name_full": "SIGLLM (unnamed pipeline in survey)",
            "brief_description": "Survey-reported prompting pipeline applying large LLMs to time-series anomaly detection using role-play prompts and an LLM-based forecasting-comparison pipeline to identify anomalous elements.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "unspecified large language model (LLM) — survey reports use of large decoder-based LLMs",
            "model_type": "transformer (decoder-style LLM)",
            "model_size": null,
            "data_type": "time series (sequential numerical data)",
            "data_domain": "general monitoring/time-series domains (e.g., system metrics, monitoring signals) as reported in survey",
            "anomaly_type": "point and short-sequence anomalies detected via deviation from forecast / anomalous elements",
            "method_description": "Prompting-based detection: (a) direct role-play prompting to label anomalous elements in series; (b) forecasting pipeline where LLM generates forecasts and anomalies are detected by comparing original sequence to LLM forecasts (discrepancy indicates anomaly). No full LLM fine-tuning reported in survey for this pipeline.",
            "baseline_methods": "Not specified in survey for SIGLLM; survey situates these against traditional time-series detectors (e.g., statistical forecasting, reconstruction-based methods) but specific baselines not given.",
            "performance_metrics": "Survey-level descriptions only; typical metrics used in time-series anomaly work include AUROC, F1, precision/recall but SIGLLM numeric metrics are not provided in the survey.",
            "performance_results": "Survey states SIGLLM explores two pipelines and shows promising detection behavior with forecasting-based discrepancies, but no numerical results are reported in this survey.",
            "comparison_to_baseline": "Not quantified in survey; described as a promising zero-/few-shot alternative to traditional detectors but direct experimental comparisons are not detailed in the survey text.",
            "limitations_or_failure_cases": "Modality gap between numerical sequences and text prompts; token-length and input-size limits when converting long sequences to text; computational cost of running large LLMs for long sequences; survey does not report specific failure-case studies for SIGLLM.",
            "unique_insights": "Using an LLM's forecasting ability as an indirect detector (forecast vs actual discrepancy) is a novel prompting-based approach for sequential anomaly detection highlighted by the survey.",
            "uuid": "e9240.0",
            "source_info": {
                "paper_title": "Large Language Models for Anomaly and Out-of-Distribution Detection: A Survey",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "LLMAD",
            "name_full": "LLMAD (Log/Time-series LLM Anomaly Detection, as cited)",
            "brief_description": "A prompting-based method for time-series/log anomaly detection that leverages in-context learning (retrieved examples) and chain-of-thought (CoT) prompts to inject domain knowledge and improve zero-/few-shot detection.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "unspecified large language model(s) (LLMs used with in-context examples)",
            "model_type": "transformer (decoder-style LLM)",
            "model_size": null,
            "data_type": "time series and log sequences (sequential textualized or numeric data converted to text)",
            "data_domain": "system logs, monitoring/time-series data",
            "anomaly_type": "anomalous sequences/entries and contextual anomalies in logs/time series",
            "method_description": "Prompting without LLM tuning: retrieve in-context examples from a constructed database and use CoT-style prompts that inject domain knowledge to guide the LLM to classify or highlight anomalies in sequences/logs.",
            "baseline_methods": "Survey does not enumerate specific baselines used by LLMAD; typical baselines would include rule-based log detectors and statistical time-series detectors but not specified here.",
            "performance_metrics": "Survey-level only; common metrics for these tasks include AUROC, precision/recall, and F1 but LLMAD numeric values are not reported in the survey.",
            "performance_results": "Survey reports that combining retrieval of examples and CoT prompting improves detection quality compared to simpler prompts, but provides no numeric performance figures.",
            "comparison_to_baseline": "Survey indicates improvement over simpler prompting strategies (implicit baseline) but does not provide head-to-head comparisons with traditional anomaly detectors in the survey text.",
            "limitations_or_failure_cases": "Same general LLM limitations: input token limits for long sequences, potential hallucination when prompts are ambiguous, and computational inefficiency; specific failure cases for LLMAD are not detailed in the survey.",
            "unique_insights": "Retrieval-augmented in-context examples plus CoT prompts can inject domain knowledge into zero-shot/few-shot LLM detection for sequences, improving quality without full fine-tuning.",
            "uuid": "e9240.1",
            "source_info": {
                "paper_title": "Large Language Models for Anomaly and Out-of-Distribution Detection: A Survey",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "LogPrompt",
            "name_full": "LogPrompt: Prompt engineering towards zero-shot and interpretable log analysis",
            "brief_description": "A prompt-engineering study that evaluates self-prompting, in-context prompting, and chain-of-thought prompting strategies for log-based anomaly detection, finding CoT prompts perform best among prompting strategies.",
            "citation_title": "Logprompt: Prompt engineering towards zero-shot and interpretable log analysis.",
            "mention_or_use": "use",
            "model_name": "LLMs (survey cites application to GPT-style models; original LogPrompt paper targets ChatGPT/GPT-family in zero-shot prompts)",
            "model_type": "transformer (decoder-style LLMs such as GPT-family)",
            "model_size": null,
            "data_type": "log sequences (textual log entries; sequences of categorical+text fields)",
            "data_domain": "system logs / software monitoring logs",
            "anomaly_type": "anomalous log entries (errors, abnormal sequences of events)",
            "method_description": "Prompting-based zero-shot detection: design task-specific prompt templates including CoT instructions and step-by-step rules to classify log entries as normal or abnormal; parse LLM textual response to extract anomaly labels and scores.",
            "baseline_methods": "Survey does not list the exact baselines LogPrompt compared against; it compares three prompting strategies (self-prompt, CoT, in-context) internally and notes CoT outperforms other prompt strategies.",
            "performance_metrics": "Not enumerated in the survey; typical metrics would be accuracy, F1, AUROC; the survey only reports relative superiority of CoT prompts.",
            "performance_results": "Survey states that CoT prompting outperforms self-prompting and in-context prompting for log anomaly tasks; no numeric values included in the survey.",
            "comparison_to_baseline": "CoT prompting &gt; other prompting strategies per the survey; comparisons to classical log-analysis models are not detailed in the survey text.",
            "limitations_or_failure_cases": "Potential hallucination in LLM outputs, input token limits for long logs, computational cost; additionally, converting structured logs to textual prompts may lose fine-grained numeric fidelity.",
            "unique_insights": "Carefully designed CoT prompts with explicit stepwise anomaly rules improve LLM zero-shot detection on logs, giving more interpretable decisions compared to simple prompts.",
            "uuid": "e9240.2",
            "source_info": {
                "paper_title": "Large Language Models for Anomaly and Out-of-Distribution Detection: A Survey",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "LogGPT / LogFit",
            "name_full": "LogGPT (Exploring ChatGPT for log-based anomaly detection) / LogFit (embedding-based log methods)",
            "brief_description": "Works exploring LLMs (ChatGPT) as a tool to perform or assist log-based anomaly detection, either via prompting (LogGPT) or via generation of embeddings/textual features used in downstream detectors (LogFit).",
            "citation_title": "Loggpt: Exploring chatgpt for log-based anomaly detection.",
            "mention_or_use": "use",
            "model_name": "ChatGPT / ChatGPT-style LLMs (LogGPT); encoder LLMs / embedding models in LogFit",
            "model_type": "transformer (ChatGPT / decoder; encoder-based embedding LMs for LogFit)",
            "model_size": null,
            "data_type": "log sequences (textual log entries)",
            "data_domain": "software/system logs and monitoring domains",
            "anomaly_type": "anomalous log entries and sequences (errors, unexpected events)",
            "method_description": "LogGPT: prompting ChatGPT to analyze logs and flag anomalies (zero-shot prompting). LogFit: use LLM-derived embeddings (text embeddings from log entries) as representations for downstream anomaly detectors.",
            "baseline_methods": "Survey does not specify exact baselines for these works; typical baselines include classical log anomaly detectors and supervised classifiers on log features.",
            "performance_metrics": "Survey-level only; usual metrics include F1, precision/recall, AUROC but numeric results are not reported in the survey.",
            "performance_results": "Survey cites these works as exploratory studies showing LLMs and LLM-derived embeddings can be effective for log anomaly detection; no numerical performance reported in the survey.",
            "comparison_to_baseline": "Survey does not provide a granular comparison; these methods are presented as promising alternatives or supplements to classical log detectors.",
            "limitations_or_failure_cases": "Hallucination risk from LLM outputs, need to convert structured logs to text which may lose structure, token limits for long log windows, and computational costs for large LLM calls.",
            "unique_insights": "LLMs can be used either directly via prompting for interpretable zero-shot log analysis or indirectly via embeddings to feed conventional detectors; embedding-based use can be more scalable/structured while prompting offers interpretability.",
            "uuid": "e9240.3",
            "source_info": {
                "paper_title": "Large Language Models for Anomaly and Out-of-Distribution Detection: A Survey",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "Tabular (Li et al., 2024a)",
            "name_full": "Anomaly detection of tabular data using LLMs",
            "brief_description": "A study adapting LLMs to tabular anomaly detection by converting tabular rows into prompt templates and using parameter-efficient fine-tuning (LoRA) with a synthetic labeled dataset to teach the LLM to output anomaly labels for batches.",
            "citation_title": "Anomaly detection of tabular data using llms.",
            "mention_or_use": "use",
            "model_name": "unspecified pre-trained LLM (prompted/fine-tuned with LoRA in the referenced work)",
            "model_type": "transformer (decoder-style LLM used as text-based classifier)",
            "model_size": null,
            "data_type": "tabular rows (mixed-type lists: categorical + numerical fields converted to text prompts)",
            "data_domain": "general tabular domains (survey does not restrict to a single domain; Li et al. target tabular anomaly detection broadly)",
            "anomaly_type": "outliers in tabular data (anomalous rows / entries)",
            "method_description": "Convert tabular rows into structured textual prompts and query the LLM to classify rows as anomalous or normal; fine-tune the LLM using parameter-efficient LoRA on a synthetic supervised dataset with ground-truth anomaly labels to adapt to batch-level detection.",
            "baseline_methods": "Not specified in the survey text for this paper; typical tabular baselines include isolation forest, LOF, autoencoders, and statistical detectors but survey does not list explicit comparisons here.",
            "performance_metrics": "Survey does not list numerical metrics from this paper; typical metrics would include AUROC, AUPR, precision/recall and F1 for tabular anomaly tasks.",
            "performance_results": "Survey reports that Tabular uses LoRA fine-tuning on a synthetic supervised dataset to adapt LLMs for batch-level anomaly detection but does not provide numeric performance values.",
            "comparison_to_baseline": "Not detailed in survey; the approach is presented as a way to leverage LLMs for tabular anomalies, with PEFT reducing compute, but direct baseline comparisons are not described in the survey text.",
            "limitations_or_failure_cases": "Converting structured numeric/tabular data to text can be inefficient (long prompts), token-limit constraints for large tables, potential loss of numeric precision or relational structure during textualization, and computational cost even with PEFT; survey notes these generic limitations.",
            "unique_insights": "Parameter-efficient fine-tuning (LoRA) on synthetic labeled examples enables an LLM to perform batch-level tabular anomaly detection without full model re-training, suggesting a practical adaptation path for LLMs on structured lists.",
            "uuid": "e9240.4",
            "source_info": {
                "paper_title": "Large Language Models for Anomaly and Out-of-Distribution Detection: A Survey",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "TimeSeries-LLM (Liu et al., 2024?)",
            "name_full": "Large language models can deliver accurate and interpretable time series anomaly detection",
            "brief_description": "A referenced work demonstrating that LLMs can perform accurate and interpretable time-series anomaly detection, leveraging LLMs' reasoning and generation capabilities to detect and explain anomalies in sequential data.",
            "citation_title": "Large language models can deliver accurate and interpretable time series anomaly detection",
            "mention_or_use": "use",
            "model_name": "large decoder-style LLMs (paper referenced in survey; exact model names unspecified in survey summary)",
            "model_type": "transformer (decoder LLMs with in-context/few-shot capabilities)",
            "model_size": null,
            "data_type": "time series (sequential numerical data)",
            "data_domain": "monitoring systems / general time-series datasets (YAHOO, ECG, etc., are mentioned elsewhere in survey as common datasets)",
            "anomaly_type": "point anomalies and contextual anomalies in time series",
            "method_description": "Use LLM prompting (zero- or few-shot) to detect anomalies in time-series by having the LLM reason about sequence behavior and optionally produce explanations; may combine forecasting, CoT, and retrieved in-context examples to improve detection and interpretability.",
            "baseline_methods": "Survey does not list the baselines used by the referenced time-series paper; general baseline families include statistical forecasting, autoencoders, and modern deep learning detectors.",
            "performance_metrics": "Survey-level only; common metrics for time-series anomalies include AUROC, precision/recall, F1, false positive rates; the referenced paper is cited as reporting accurate detection but survey does not reproduce numbers.",
            "performance_results": "Survey summarizes that the paper shows accurate and interpretable detection with LLMs for time-series, but provides no numeric performance values in this survey text.",
            "comparison_to_baseline": "Survey-level claim that LLM methods can be competitive or advantageous in zero-/few-shot settings relative to traditional methods, but detailed comparisons from the original paper are not reproduced in the survey.",
            "limitations_or_failure_cases": "Token limits for long sequences, computational overhead, and possible hallucination; converting high-resolution numeric sequences to text can be inefficient and may lose precision—survey highlights these general limitations.",
            "unique_insights": "LLMs provide both detection and human-readable explanations for time-series anomalies; combining forecasting and CoT reasoning leverages LLMs' strengths for sequential anomaly tasks.",
            "uuid": "e9240.5",
            "source_info": {
                "paper_title": "Large Language Models for Anomaly and Out-of-Distribution Detection: A Survey",
                "publication_date_yy_mm": "2024-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Logprompt: Prompt engineering towards zero-shot and interpretable log analysis.",
            "rating": 2,
            "sanitized_title": "logprompt_prompt_engineering_towards_zeroshot_and_interpretable_log_analysis"
        },
        {
            "paper_title": "Loggpt: Exploring chatgpt for log-based anomaly detection.",
            "rating": 2,
            "sanitized_title": "loggpt_exploring_chatgpt_for_logbased_anomaly_detection"
        },
        {
            "paper_title": "Anomaly detection of tabular data using llms.",
            "rating": 2,
            "sanitized_title": "anomaly_detection_of_tabular_data_using_llms"
        },
        {
            "paper_title": "Large language models can deliver accurate and interpretable time series anomaly detection",
            "rating": 2,
            "sanitized_title": "large_language_models_can_deliver_accurate_and_interpretable_time_series_anomaly_detection"
        },
        {
            "paper_title": "Anomaly detection on unstable logs with gpt models.",
            "rating": 1,
            "sanitized_title": "anomaly_detection_on_unstable_logs_with_gpt_models"
        },
        {
            "paper_title": "LLM-Monitor (referenced work on using object detectors + LLMs for video anomaly detection)",
            "rating": 1,
            "sanitized_title": "llmmonitor_referenced_work_on_using_object_detectors_llms_for_video_anomaly_detection"
        }
    ],
    "cost": 0.0155875,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Large Language Models for Anomaly and Out-of-Distribution Detection: A Survey
30 Oct 2024</p>
<p>Ruiyao Xu ruiyaoxu2028@u.northwestern.edu 
Department of Statistics and Data Science
Northwestern University</p>
<p>Kaize Ding kaize.ding@northwestern.edu 
Department of Statistics and Data Science
Northwestern University</p>
<p>Davide Abati 
Department of Statistics and Data Science
Northwestern University</p>
<p>Angelo Porrello 
Department of Statistics and Data Science
Northwestern University</p>
<p>Simone Calderara 
Department of Statistics and Data Science
Northwestern University</p>
<p>Rita 2019 Cucchiara 
Department of Statistics and Data Science
Northwestern University</p>
<p>Latent 
Department of Statistics and Data Science
Northwestern University</p>
<p>Josh Achiam 
Department of Statistics and Data Science
Northwestern University</p>
<p>Steven Adler 
Department of Statistics and Data Science
Northwestern University</p>
<p>Sandhini Agarwal 
Department of Statistics and Data Science
Northwestern University</p>
<p>Lama Ahmad 
Department of Statistics and Data Science
Northwestern University</p>
<p>Ilge Akkaya 
Department of Statistics and Data Science
Northwestern University</p>
<p>Florencia Leoni Aleman 
Department of Statistics and Data Science
Northwestern University</p>
<p>Diogo Almeida 
Department of Statistics and Data Science
Northwestern University</p>
<p>Janko Altenschmidt 
Department of Statistics and Data Science
Northwestern University</p>
<p>Sam Altman 
Department of Statistics and Data Science
Northwestern University</p>
<p>Jean-Baptiste Alayrac 
Department of Statistics and Data Science
Northwestern University</p>
<p>Jeff Donahue 
Department of Statistics and Data Science
Northwestern University</p>
<p>Pauline Luc 
Department of Statistics and Data Science
Northwestern University</p>
<p>Antoine Miech 
Department of Statistics and Data Science
Northwestern University</p>
<p>Iain Barr 
Department of Statistics and Data Science
Northwestern University</p>
<p>Yana Hasson 
Department of Statistics and Data Science
Northwestern University</p>
<p>Karel Lenc 
Department of Statistics and Data Science
Northwestern University</p>
<p>Arthur Mensch 
Department of Statistics and Data Science
Northwestern University</p>
<p>Katherine Millican 
Department of Statistics and Data Science
Northwestern University</p>
<p>Paul Bergmann 
Department of Statistics and Data Science
Northwestern University</p>
<p>Kilian Batzner 
Department of Statistics and Data Science
Northwestern University</p>
<p>Michael Fauser 
Department of Statistics and Data Science
Northwestern University</p>
<p>David Sattlegger 
Department of Statistics and Data Science
Northwestern University</p>
<p>Carsten 2022 Steger 
Department of Statistics and Data Science
Northwestern University</p>
<p>Large Language Models for Anomaly and Out-of-Distribution Detection: A Survey
30 Oct 2024D97F3DE0BF7006D547549223B0331E73arXiv:2409.01980v2[cs.LG]
Detecting anomalies or out-of-distribution (OOD) samples is critical for maintaining the reliability and trustworthiness of machine learning systems.Recently, Large Language Models (LLMs) have demonstrated their effectiveness not only in natural language processing but also in broader applications due to their advanced comprehension and generative capabilities.The integration of LLMs into anomaly and OOD detection marks a significant shift from the traditional paradigm in the field.This survey focuses on the problem of anomaly and OOD detection under the context of LLMs.We propose a new taxonomy to categorize existing approaches into two classes based on the role played by LLMs.Following our proposed taxonomy, we further discuss the related work under each of the categories and finally discuss potential challenges and directions for future research in this field.We also provide an up-todate reading list 1 of relevant papers.</p>
<p>Introduction</p>
<p>Most machine learning models operate under the closed-set assumption (Krizhevsky et al., 2012), where the test data is assumed to be drawn i.i.d.from the same distribution as the training data.However, in real-world applications, this assumption often cannot hold, as test examples can come from distributions not represented in the training data.These instances, known as anomalies or outof-distribution (OOD) samples, can severely degrade the performance and reliability of existing models (Yang et al., 2024a).To build robust AI systems, methods including probabilistic approaches (Lee et al., 2018;Leys et al., 2018) and recent deep learning techniques (Pang et al., 2021;Yang et al., 2024a) have been explored to detect these unknown instances across various domains, such as fraud de- tection in finance and fault detection in industrial systems (Hilal et al., 2022;Liu et al., 2024b).Large Language Models (LLMs), such as GPT-4 (Achiam et al., 2023) and LLaMA (Touvron et al., 2023), have demonstrated remarkable capabilities in language comprehension and generation.To further harness the potential of LLMs beyond text data, there is also a growing interest in extending them to multi-modal tasks such as vision-language understanding and generation (Wang et al., 2024), evolving them into Multimodal LLMs (MLLMs) (Yin et al., 2023).Given the zero-and few-shot reasoning capabilities of LLMs and MLLMs, researchers try to apply these models to anomaly and out-of-distribution (OOD) detection, as illustrated in Figure 1, yielding promising detection results.</p>
<p>Remarkably, the emergence of LLMs has fundamentally changed the learning paradigm in this field, compared to previous statistical and machine learning methods.In the meantime, while leveraging LLMs to solve the problem of anomaly and OOD detection has drawn much attention, this field remains underexplored, highlighting the need for a comprehensive survey to analyze the emerging challenges and systematically review the rapidly expanding works.Recently, Salehi et al. (2021) and Yang et al. (2024a) present unified frameworks for OOD detection but do not delve into the uti-lization of LLMs.While Su et al. (2024) review some small-sized language models for forecasting and anomaly detection, they neither cover the usage of LLMs with emergent abilities nor discuss OOD detection.A recent survey by Miyai et al. (2024a) summarizes works on anomaly and OOD detection in vision using vision-language models but neglects other data modalities.Therefore, we aim to conduct a systematic survey that covers both anomaly and OOD detection tasks across various data domains, concentrating on how LLMs are used in existing works.</p>
<p>In this survey, we propose a novel taxonomy that focuses on how LLMs can profoundly impact anomaly and OOD detection in two fundamental ways, as illustrated in Figure 4: ❶ LLMs for Detection ( §3): We provide a detailed review of existing methods that leverage LLMs as detectors for identifying anomalies and OOD instances, categorizing these methods into distinct pipelines; and ❷LLMs for Generation ( §4): We also review methods that utilize LLMs' emergent abilities, advanced semantic understanding, and vast knowledge to generate augmented data and explanations, thereby enhancing detection models with more robust and interpretable outputs.At the end ( §5), we also outline the challenges and future research directions, in order to provide a better understanding of anomaly and OOD detection in the era of LLMs and shed light on the following research.</p>
<p>Preliminaries</p>
<p>Large Language Models.Large language models (LLMs) generally refer to Transformer-based pre-trained language models with hundreds of billions of parameters or more.Early LLMs like BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) utilize an encoder-only architecture, excelling in text representation learning (Bengio et al., 2013).Recently, the focus has shifted toward models aimed at natural language generation, often using the "next token prediction" objective as their core task.Examples include T5 (Raffel et al., 2020) and BART (Lewis et al., 2019), which employ an encoder-decoder structure, as well as GPT-3 (Brown et al., 2020), PaLM (Chowdhery et al., 2023), andLLaMA (Touvron et al., 2023), which are based on decoder-only architectures.Advancements in these architectures and training methods have led to superior reasoning and emergent abilities, such as in-context learning (Brown et al., 2020) and chain-of-thought reasoning (Wei et al., 2022).Multimodal Large Language Models.The remarkable abilities of Large Language Models (LLMs) have inspired efforts to integrate language with other modalities, with a particular focus on combining language and vision.Notable examples of Multimodal Large Language Models (MLLMs) include CLIP (Radford et al., 2021), BLIP2 (Li et al., 2023a), andFlamingo (Alayrac et al., 2022), which were pre-trained on large-scale cross-modal datasets comprising images and text.Models like GPT-4(V) (OpenAI, 2023) and Gemini (Team et al., 2023) showcase the emergent abilities of Multimodal LLMs, significantly improving the performance of vision-related tasks.</p>
<p>Problem Definition</p>
<p>With LLMs advancing in zero-shot and few-shot learning, the general pipeline of anomaly and outof-distribution (OOD) detection methods shifts to adapt pre-trained LLMs for detection without extensive training.This shift challenges traditional definitions of anomaly and OOD detection, as the conventional train-test paradigm may not always apply.Following previous studies (Miyai et al., 2024a;Yang et al., 2024a), we propose to redefine anomaly and OOD detection under the context of LLMs and highlight the differences between the two problems as follows: Discussions.The distinction between anomaly detection and OOD detection in the context of LLMs highlights the unique challenges posed by covariate and semantic shifts.Anomaly detection aims to identify subtle deviations within the data that may not involve a complete change in the underlying class or concept, such as detecting defects or irregularities in industrial processes.In contrast, OOD detection focuses on identifying instances that do not belong to any of the known ID classes at the object level, such as recognizing a dog when the only provided ID class is cat.This differentiation underscores the need for tailored approaches for each detection task.</p>
<p>LLMs for Detection</p>
<p>The primary objective of this section is to explore existing works that utilize LLMs' inherent knowledge to detect anomalies or OOD samples.Under this line of research, approaches can be categorized into two classes as illustrated in Figure 2: ❶ Prompting-based Detection methods, which involve directly prompting LLMs to generate language responses that include detection results; ❷ Contrasting-based Detection methods, which focus on multimodal scenarios, using MLLMs pretrained with a contrastive objective as detectors.</p>
<p>Prompting-based Detection</p>
<p>The general pipeline for prompting-based detection methods consists of two primary stages: (i) constructing a structured prompt template with instruction prompt P and input data X ; and (ii) feeding the template-based prompt X into LLMs to generate a language response.The function Parse(•) is then applied to extract the detection results.Depending on the scenario, the LLM can either be frozen or fine-tuned, denoted as f ♡ LLM or f ♣ LLM , respectively.This process can be summarized as follows:</p>
<p>Prompt Construction: X = Template(X , P),
Detection: Ỹ = Parse f ♡/♣ LLM ( X)
Note that the prompting-based approach primarily addresses the anomaly detection task.OOD detection research has not yet widely adopted prompting to directly identify OOD samples.</p>
<p>Detection without LLM Tuning</p>
<p>Since some approaches do not require additional tuning, they mainly focus on employing various prompt engineering techniques (Sahoo et al., 2024) to guide LLMs to produce better detection results.To design suitable prompts for anomaly detection, researchers have employed a combination of various prompt techniques, such as role-play prompt-ing (Wu et al., 2023), in-context learning (Brown et al., 2020), and chain-of-thought (CoT) reasoning (Wei et al., 2022), to create effective prompt templates.Studies such as SIGLLM (Alnegheimish et al., 2024), LLMAD (Liu et al., 2024c), and LogPrompt (Liu et al., 2024d) focus on time series and log data.SIGLLM (Alnegheimish et al., 2024) investigates two distinct pipelines for using LLMs in time series anomaly detection: one directly prompts an LLM with specific role-play instructions to identify anomalous elements in given data, and the other uses the LLM's forecasting ability to detect anomalies by comparing original and forecasted signals, where discrepancies indicate anomalies.LLMAD (Liu et al., 2024c) incorporates in-context learning examples retrieved from a constructed database and CoT prompts that inject domain knowledge of time series.LogPrompt (Liu et al., 2024d) explores three prompting strategies for log data: self-prompt, CoT prompt, and in-context prompt, demonstrating that the prompt with CoT techniques outperforms other prompting strategies.The tailored CoT prompt for log data includes a specific task instruction, i.e. "classify the given log entries into normal and abnormal categories", and step-by-step rules for considering given data as anomalies.</p>
<p>Unlike time series and log data which can be directly converted into raw text data, other data modalities, such as videos and images, require additional processing to be transformed into a format that LLMs can understand.For instance, LAVAD (Zanella et al., 2024) first exploits a captioning model to generate a textual description for each video frame and further uses an LLM to summarize captions within a temporal window.This summary is then used to prompt the LLM to provide an anomaly score for each frame.LLM-Monitor (Elhafsi et al., 2023) uses an object detector to identify objects in video clips and then designs specific prompt templates incorporating CoT and in-context examples to query LLMs for anomaly detection.</p>
<p>With the integration of multimodal understanding into LLMs, these models are now capable of comprehending various modalities beyond text, enabling more direct applications for anomaly detection across a wide range of data types.Cao et al. (2023) conduct comprehensive experiments and analyses using GPT-4V(ision) for anomaly detection across various modality datasets and tasks.To enhance GPT-4V's performance, they also incorporate different types of additional cues such as class information, human expertise, and reference images as prompts.Similarly, GPT-4V-AD (Zhang et al., 2023) employs GPT-4V as the backbone, designing a general prompt description for all image categories and injecting specific image category information, resulting in a specific output format for each region with respective anomaly scores.</p>
<p>Detection with LLM Tuning</p>
<p>Directly prompting frozen LLMs for anomaly or OOD detection results across various data types often yields suboptimal performance due to the inherent modality gap between text and other data modalities.As a result, additional training and finetuning on LLMs for downstream detection tasks has become a prevalent research trend.Unfortunately, fine-tuning entire LLMs is often computationally expensive and poses significant challenges.Therefore, parameter-efficient fine-tuning (PEFT) has been extensively employed instead.For example, Tabular (Li et al., 2024a) designs a prompt template to query the LLM to output anomalies based on given converted tabular data.To better adapt the LLM for anomaly detection at the batch level, they apply Low-Rank Adaptation (LoRA), using a synthetic dataset with ground truth labels in a supervised manner.</p>
<p>To enhance LLMs for localization understanding and adapting to industrial tasks, AnomalyGPT (Zhang et al., 2023) first derives localization features from a frozen image encoder and image decoder and these features are then fed to a tunable prompt learner.Without fine-tuning the entire LLM, they fine-tune the prompt learner with LoRA to significantly reduce computational costs.Myriad (Li et al., 2023b) employs Mini-GPT-4 as the backbone and integrates a trainable encoder, referred to as Vision Expert Tokenizer, to embed the vision expert's segmentation output into tokens that the LLM can understand.With expert-driven visual-language extraction, Myriad can generate accurate anomaly detection descriptions.</p>
<p>Contrasting-based Detection</p>
<p>In this section, we focus on MLLMs, such as CLIP, which are pre-trained with an image-text contrastive objective and learn by pulling the paired images and texts close and pushing others far away in the embedding space.The zero-shot classification ability of these models further builds the foundation for contrasting-based anomaly and OOD detection methods: (i) given an image x i and a text prompt f with a target class set C, CLIP extracts image features h ∈ R D using an image encoder f img , and text features e j ∈ R D using a text encoder f text with a prompt template for each class c j ∈ C, and (ii) the similarity between h and each e j is usually used as an important component in the score function f score for deciding whether x i is an anomaly or OOD sample.This process can be summarized as follows:</p>
<p>Feature Extraction: h = f img (x i ), and e j = f text (prompt(c j )),
Detection: Ỹ = f score (cos(h, e j ))
We further categorize contrasting-based detection methods into two main classes depending on whether there exists additional training and finetuning.</p>
<p>Detection without LLM Tuning</p>
<p>Anomaly and OOD detection problems can indeed be understood as classification problems.Therefore, pretrained MLLMs like CLIP, with strong zero-shot classification ability, can serve as detectors themselves.By using only ID or normal prompts, CLIP can be leveraged for both OOD and anomaly detection tasks.Despite the promise, existing CLIP-like models perform zero-shot classification in a closed-world setting.That is, it will match an input into a fixed set of categories, even if it is irrelevant (Ming et al., 2022) For OOD detection, to address the challenges of using only in-distribution (ID) class information while avoiding the matching of OOD inputs to irrelevant ID classes, one notable approach is the Maximum Concept Matching (MCM) framework proposed by (Ming et al., 2022).This method is not limited to CLIP and can be generally applicable to other pre-trained models that promote multi-modal feature alignment.They view the textual embeddings of ID classes as a collection of concept prototypes and define the maximum concept matching (MCM) score based on the cosine similarity between the image feature and the textual feature.Following the idea of MCM, several subsequent works focus on improving OOD detection results by either adding a local MCM score or modifying weights in the original MCM framework, such as (Miyai et al., 2023) and (Li et al., 2024c).</p>
<p>• With Anomaly/OOD Prompts.(Huang et al., 2024b), (Park et al., 2023), and (Xu et al., 2023).</p>
<p>For contrasting-based anomaly detection, following the simple binary zero-shot framework, CLIP-AC (Jeong et al., 2023), which adapts CLIP with two class prompts: "normal [o]" vs. "anomalous [o]", many subsequent research emerge.While using the default prompt has demonstrated promising performance, similar to the prompt engineering discussion around GPT-3 (Brown et al., 2020), researchers have observed that performance can be significantly improved by customizing the prompt text.Models like WinCLIP (Jeong et al., 2023) and AnoCLIP (Deng et al., 2023) use a Prompt Ensemble technique to generate all combinations of pre-defined lists of state words per label and text templates.After generating all combinations of states and templates, they compute the average of text embeddings per label to represent the normal and anomalous classes.In practice, more descriptions in prompts do not always yield better performance.Therefore, CLIP-AD (Chen et al., 2023b) proposes Representative Vector Selection (RVS), from a distributional perspective for the design of the text prompt, broadening research opportunities beyond merely crafting adjectives.</p>
<p>Detection with LLM Tuning</p>
<p>Following the similar detection pipeline of methods without LLM tuning, researchers propose to employ prompt tuning or adapter tuning techniques to eliminate the need for manually crafting prompts and enhance the understanding of local features of images.Additionally, by incorporating a few ID or normal images during training or inference phases, some methods transition into few-shot scenarios.</p>
<p>• LLM Adapter-Tuning.Adapter-tuning methods involve integrating additional components or layers into the model architecture to facilitate better alignment or localization (Hu et al., 2023).This approach is significantly useful for anomaly detection task, because CLIP was originally designed for classifying the semantics of objects in the scene, which does not align well with the sensory anomaly detection task where both normal and abnormal samples are often from the same class of object.To reconcile this, InCTRL (Zhu and Pang, 2024) includes a tunable adapter layer to further adapt the image representations for anomaly detection.To better adapt to medical image anomaly detection, MVFA (Huang et al., 2024a) proposes a multi-level visual feature adaptation architecture to align CLIP's features with the requirements of anomaly detection in medical contexts.This is achieved by integrating multiple residual adapters into the pre-trained visual encoder, guided by multi-level, pixel-wise visual-language feature alignment loss functions.</p>
<p>• LLM Prompt-Tuning.Manually crafting suitable prompts always requires extensive human effort.Therefore, researchers employ the idea of prompt tuning, such as CoOp (Zhou et al., 2022), to learn a soft or differentiable context vector to replace the fixed text prompt.For OOD detection, most approaches rely on using auxiliary prompts to represent potential OOD textual information, and one crucial problem is to identify hard OOD data that is similar to ID samples.</p>
<p>LLMs for Generation</p>
<p>In this section, we review methods that leverage LLMs as generative tools for enhancing anomaly and OOD detection.LLMs use their extensive pre-trained knowledge to generate augmented data, such as embeddings, pseudo labels, and textual descriptions, which improve detection performance.Furthermore, due to their ability to understand and generate human-like text, LLMs have been explored for providing insightful explanations and analyses of detection results, aiding in interpretation, planning, and decision-making.These methods are classified into two main approaches: Augmentation-centric Generation and Explanation-centric Generation.</p>
<p>Augmentation-centric Generation</p>
<p>LLMs serve as effective tools for data augmentation in anomaly and OOD detection tasks by generating textual embeddings, pseudo labels, and descriptive text.For OOD detection in text data, a common approach involves using encoder-only LLMs to generate sentence representations that are used to compute OOD confidence scores (Liu et al., 2024a).These models are typically fine-tuned on ID data, and OOD detectors are applied to the generated representations.Recently, there has been a shift toward leveraging larger language models with decoder architectures, which provide enhanced capabilities in refining textual representations.Liu et al. (2024a) explore the use of decoder-only LLMs, such as LLaMa, incorporating fine-tuning techniques like LoRA to reduce the additional parameters.Their findings demonstrate that fine-tuned LLMs, combined with customized OOD scoring functions, significantly improve OOD detection performance.A key advantage of decoder-based LLMs is their autoregressive ability, which allows for more effective handling of sequential data.Building on this, Zhang et al. (2024a) propose using the likelihood ratio between a pre-trained and fine-tuned LLM as a criterion for OOD detection, leveraging the deep contextual understanding embedded within LLMs for text data.</p>
<p>Pseudo Label-based Augmentation</p>
<p>The emergent capabilities of LLMs provide a promising approach for generating high-quality synthetic datasets, including pseudo labels for OOD samples.A significant challenge in OOD detection is the lack of labeled OOD data, which can limit model performance.Traditionally, obtaining OOD labels requires extensive human effort, but LLMs can mitigate this by generating pseudo-OOD labels through carefully designed prompts.These pseudo labels augment existing ID data and enhance the distinction between ID and OOD samples.</p>
<p>For example, EOE (Cao et al., 2024) and PCC (Huang et al., 2024b) prompt LLMs to generate visually similar OOD class labels, which are then used to define a new scoring function.This approach significantly outperforms methods relying solely on known ID labels.TOE (Park et al., 2023) further evaluates the generation of pseudo-OOD labels at three verbosity levels-word-level, description-level, and caption-level-using BERT, GPT-3, and BLIP-2, respectively.Results indicate that caption-level pseudo-OOD labels generated by BLIP-2, which incorporates both semantic and visual understanding, perform the best.In text data, CoNAL (Xu et al., 2023) prompts LLMs to extend closed-set labels with novel examples and generates a comprehensive set of probable OOD samples.By applying contrastive confidence loss during training, the model achieves high accuracy on the ID training set while maintaining lower confidence on the generated OOD examples.</p>
<p>Textual Description-based Augmentation</p>
<p>In addition to generating pseudo labels, LLMs are also used to generate textual descriptions of both known ID classes and potential OOD samples.For example, TagFog (Chen et al., 2024) employs a Jigsaw strategy to generate fake OOD samples and prompts ChatGPT to create detailed descriptions for each ID class, guiding the training of the image encoder in CLIP for OOD detection.In anomaly detection tasks, it is essential for LLMs to recognize the close correlation between normal images and their respective prompts, while identifying a more distant association with abnormal prompts.This requires detailed and nuanced descriptions of normal and anomalous stages of objects.ALFA (Zhu et al., 2024) formulates prompts for LLMs to describe both normal and abnormal features for each class, and these descriptions are then used to improve the detection of abnormal objects.To avoid LLM hallucination, Dai et al. ( 2023) introduce a consistency-based uncertainty calibration method, where LLMs describe visual features for distinguishing categories in images, and the confidence score of each generation is estimated accordingly.</p>
<p>Prompt</p>
<p>Suggest categories that are not directly related or belong to the same primary group as [dog].</p>
<p>Explanation-centric Generation</p>
<p>Beyond augmentation, LLMs' powerful reasoning and natural language generation abilities allow them to provide insightful explanations for anomaly and OOD detection outcomes.These explanations are especially important in safetycritical domains, such as autonomous driving, where transparency and interpretability are crucial.</p>
<p>For example, Holmes-VAD (Zhang et al., 2024b) trains a lightweight temporal sampler to select frames with high anomaly scores and uses an LLM to generate detailed explanations, providing clear insights into the detected anomalies.VAD-LLaMA (Lv and Sun, 2024) generates instructiontuning data to train the projection layer of Video-LLaMA, enabling more comprehensive explanations of anomalies.AnomalyRuler (Yang et al., 2024b) employs a rule-based reasoning strategy with few-normal-shot prompting, providing interpretable, rule-driven explanations that can quickly adapt to various video anomaly detection scenarios.</p>
<p>Additionally, LLMs are being used in autonomous agents to guide decision-making after anomaly or OOD detection.For instance, AESOP (Sinha et al., 2024) leverages the autoregressive capabilities of an LLM to provide zero-shot assessments on whether interventions are required in robotic systems after an anomaly is detected.By utilizing LLMs' generative reasoning, these systems can plan and respond to anomalies in an efficient and informed manner.</p>
<p>Challenges and Future Directions</p>
<p>In this section, we briefly summarize challenges and future directions within the anomaly and OOD detection research field in the era of LLMs.Explainability and Trustworthiness.In addition to accurately detecting anomalies or OOD samples, there is an increasing trend to utilize LLMs to provide reasonable explanations and serve as agents to plan future actions.Future research should focus on developing methods to enhance the explainability of LLMs for anomaly or OOD detection, increasing the trustworthiness of LLM-based systems and facilitating their adoption in critical domains such as healthcare and finance (Holzinger et al., 2019;Guidotti et al., 2019).Unsolvable Problem Detection.Miyai et al. (2024b) propose Unsolvable Problem Detection (UPD), which evaluates the LLMs' ability to recognize and abstain from answering unexpected or unsolvable input questions, aiding in preventing incorrect or misleading outputs in critical applications where the consequences of errors can be significant.Future work should focus on incorporating the concepts of OOD detection techniques for solving the UPD problems.Handling Multimodal Data.The emergence of MLLMs capable of processing and understanding multiple data modalities offers significant potential in the field of anomaly and OOD detection (Alayrac et al., 2022;Li et al., 2023a).Future research should explore methods to better adapt LLMs to comprehend and integrate various multimodal data, thereby enhancing their ability to detect anomalies and OOD instances across diverse datasets.</p>
<p>Conclusion</p>
<p>In this survey, we examined the use of Large Language Models (LLMs) and multimodal LLMs (MLLMs) in anomaly and out-of-distribution (OOD) detection.We introduced a novel taxonomy categorizing methods into two approaches based on the role of LLMs in the architectures: detection, and generation.This taxonomy clarifies how LLMs can augment data, detect anomalies or OOD, and build explainable systems.We also discussed limitations and future research directions, aiming to highlight advancements and challenges in the field of anomaly or OOD detection and encourage further progress.</p>
<p>Limitations</p>
<p>While this survey provides a comprehensive overview of the utilization of Large Language Models (LLMs) for anomaly and out-of-distribution (OOD) detection, several limitations should be acknowledged:</p>
<p>• Scope of Coverage: Although we endeavored to include the latest research, the rapid pace of advancements in the field means that some recent developments may not be covered.</p>
<p>• Depth of Analysis: Given the broad range of topics discussed, certain methods may not be explored in the depth they deserve.</p>
<p>• Evaluations and Benchmarks: Due to space constraints, we did not include a detailed summary of common evaluation metrics and benchmark datasets used in this area.By acknowledging these limitations, we aim to provide a balanced perspective and encourage further research to address these gaps and build on the foundations laid by this survey.Explainability and Interpretability: LLMs possess strong reasoning abilities that can contribute to building explainable systems for anomaly and OOD detection.Traditional methods often rely on scores that offer little insight into the detection process.In contrast, LLMs can provide detailed, interpretable explanations for their detection results, offering valuable insights for future actions.Furthermore, LLMs can be integrated as agents within a system, assisting in planning the next steps when an anomaly or OOD event is detected.</p>
<p>B.2 Challenges</p>
<p>Computational Efficiency and Token Limits: A major concern when leveraging LLMs for anomaly and OOD detection is computational inefficiency.Applying LLMs in these tasks often requires complex reasoning which can lead to significant computational overhead.Additionally, many LLMs have input token limits, making it impossible to feed large amounts of data directly into the model.To address this, researchers must carefully design architectures that allow LLMs to process the data effectively.For instance, techniques like Retrieval-Augmented Generation have been used to retrieve the most relevant data to avoid token limit issues (Liu et al., 2024c).Moreover, methods such as model pruning and knowledge distillation should be considered to reduce computational costs while maintaining high accuracy.</p>
<p>Domain Knowledge: While LLMs are trained on vast and diverse datasets, they may lack specific domain expertise needed for certain anomaly and OOD detection tasks.To enhance performance in these specialized domains, incorporating domain knowledge into the LLMs is crucial.One strategy is injecting domain knowledge into prompts to guide the LLM's understanding.Another approach involves using adapters or fine-tuning to better tailor the LLMs to domain-specific problems, ensuring they perform well in specialized tasks.</p>
<p>Hallucination and Trustworthiness: LLMs can sometimes produce inaccurate or fabricated information, a phenomenon known as hallucination.In the context of anomaly and OOD detection, hallucinations pose a significant risk, potentially leading to incorrect or misleading results.To mitigate this, researchers need to work on reducing hallucination rates and improving the trustworthiness of the model.Manual checks may still be necessary in critical applications, as LLMs should be seen as assistants rather than sole decision-makers.</p>
<p>C Anomaly Detection Research Roadmap</p>
<p>Anomaly detection has evolved significantly from traditional statistical methods to deep learning approaches and more recently to Large Language Model (LLM)-based methods.These advancements have expanded the range of applications across diverse data modalities and downstream tasks.Following Yang et al. (2024a), traditional methodologies can be grouped into densitybased, reconstruction-based, distance-based, and classification-based methods.Below is an overview of these traditional approaches, followed by a discussion of the advantages and challenges of LLMbased anomaly detection.</p>
<p>C.1 Traditional Methods</p>
<p>Density-based Methods.Density-based methods model the distribution of normal data and detect anomalies by evaluating how well a sample fits this modeled distribution.The underlying assumption is that normal data is more likely to have a higher likelihood under the distribution, while anomalous data will have a lower likelihood.Parametric density estimation assumes a predefined form for the distribution, such as a multivariate Gaussian or Poisson distribution (Danuser and Stricker, 1998;Leys et al., 2018;Turcotte et al., 2016).These methods perform well when the data LLMs for Anomaly and OOD Detection</p>
<p>LLMs for Detection</p>
<p>Prompting w/o Tuning SIGLLM (Alnegheimish et al., 2024), LLMAD (Liu et al., 2024c), LogPrompt (Liu et al., 2024d), LAVAD (Zanella et al., 2024), LLM-Monitor (Elhafsi et al., 2023), GPT-4V-AD (Zhang et al., 2023), (Cao et al., 2023) w/ Tuning Tabular (Li et al., 2024a), Myriad (Li et al., 2023b), AnomalyGPT (Zhang et al., 2023) Contrasting w/o Tuning (Fort et al., 2021), ZOC (Esmaeilpour et al., 2022), NegLabel (Jiang et al., 2024), CLIPScope (Fu et al., 2024), WinCLIP (Jeong et al., 2023), AnoCLIP (Deng et al., 2023), CLIP-AD (Chen et al., 2023b), MCM (Ming et al., 2022), (Miyai et al., 2023), SETAR (Li et al., 2024c) w/ Tuning LoCoOp (Miyai et al., 2024c) AnomalyCLIP (Zhou et al., 2024), InCTRL (Zhu and Pang, 2024), MVFA (Huang et al., 2024a), ID-like (Bai et al., 2024), NegPrompt (Li et al., 2024b), CLIPN (Wang et al., 2023), LSN (Nie et al., 2024), MCM-PEFT (Ming and Li, 2024) LLMs for Generation</p>
<p>Augmentation</p>
<p>Text Embedding LogGPT (Qi et al., 2023), LogFit (Almodovar et al., 2024), (Liu et al., 2024a), (Zhang et al., 2024a) Psuedo Label EOE (Cao et al., 2024), PCC (Huang et al., 2024b), TOE (Park et al., 2023), CoNAL (Xu et al., 2023) Textual Description TagFog (Chen et al., 2024), ALFA (Zhu et al., 2024), (Dai et al., 2023) Explanation Holmes-VAD (Zhang et al., 2024b), AnomalyRuler (Yang et al., 2024b), VAD-LLaMA (Lv and Sun, 2024), AESOP (Sinha et al., 2024) Figure 4: Taxonomy of methods utilizing LLMs for anomaly and OOD detection tasks.</p>
<p>distribution adheres to the parametric assumption but can struggle with more complex cases.Nonparametric density estimation methods, such as histograms and kernel density estimation (KDE), offer more flexibility by not assuming a fixed parametric form, making them suitable for handling more complex distributions (Parzen, 1962;Hu et al., 2018).Modern deep learning techniques enhance density estimation by learning high-quality feature representations.Methods such as autoencoders (AE), variational autoencoders (VAE), and flowbased models are commonly used (Kramer, 1991;Kingma and Welling, 2013;Goodfellow et al., 2014).</p>
<p>Reconstruction-based Methods.Reconstruction-based methods operate on the assumption that models trained on normal data will reconstruct those samples accurately, while anomalous data will result in higher reconstruction errors.This discrepancy in reconstruction performance is used to identify anomalies.Common approaches include sparse reconstruction, where normal samples are represented by a small set of basis functions, while anomalies are not.Autoencoders and variational autoencoders are often employed to capture these differences in reconstruction errors (Kramer, 1991;Kingma and Welling, 2013).Recent advancements have sought to reduce the computational costs associated with reconstructionbased methods, for example by focusing on reconstructing hidden features or masking parts of the input (Pidhorskyi et al., 2018).These improve-ments enhance both the accuracy and efficiency of anomaly detection, without requiring pixel-level reconstruction.</p>
<p>Distance-based Methods.Distance-based methods detect anomalies by measuring the distance between test samples and reference points, such as class prototypes or centroids.Anomalies are expected to be further from these reference points than normal samples (Tian et al., 2014).</p>
<p>Classification-based Methods.Classificationbased methods treat anomaly detection as a supervised learning problem.In one-class classification (OCC) (Tax, 2002), the goal is to learn a decision boundary that encompasses the normal data, with any data points outside this boundary being classified as anomalies.</p>
<p>DeepSVDD (Ruff et al., 2018) is a notable deep learning method for OCC, where a deep network learns a compact representation of the normal class.Semi-supervised approaches, such as positive-unlabeled (PU) learning (Zhang and Zuo, 2008;Bekker and Davis, 2020;Jaskie and Spanias, 2019), are also used when only a subset of the normal data is labeled, with the rest being unlabeled.Self-supervised learning methods have been proposed as well, using pretext tasks such as contrastive learning or future frame prediction to identify anomalies (Tack et al., 2020).</p>
<p>C.2 LLM-based Anomaly Detection</p>
<p>The advent of Large Language Models (LLMs) like GPT, as well as multimodal LLMs, has introduced new possibilities for anomaly detection.LLMs offer zero-shot and few-shot learning capabilities, allowing anomalies to be detected with minimal or no task-specific training.This is particularly valuable in scenarios where labeled data is scarce or unavailable.LLM-based approaches benefit from their pre-trained knowledge and can adapt to various data modalities, including images, and videos.By using natural language processing capabilities, LLMs can provide explainability in anomaly detection, offering reasoning as to why a particular instance is flagged as anomalous.</p>
<p>However, LLM-based methods come with certain challenges, including high computational costs and limitations related to token size.These models are computationally intensive to run and may struggle with long input sequences, which necessitates techniques such as retrieval-augmented generation (RAG) or model pruning to manage these constraints.</p>
<p>C.3 Comparison: Traditional vs. LLM-based Anomaly Detection</p>
<p>When comparing traditional and LLM-based anomaly detection methods, several key differences emerge:</p>
<p>• Assumptions: Traditional methods often rely on predefined assumptions about the data distribution, such as the parametric forms used in density-based methods.In contrast, LLM-based approaches require fewer assumptions and are better equipped to generalize across a variety of tasks.</p>
<p>• Data Requirements: Traditional methods, particularly those based on deep learning, usually require large labeled datasets for training.LLMbased methods excel in zero-shot or few-shot settings, enabling them to detect anomalies with minimal task-specific data.</p>
<p>• Explainability: Traditional methods tend to offer high interpretability but lack the ability to explain their decisions in natural language.LLMbased approaches can not only detect anomalies but also provide natural language explanations, which improves transparency and trustworthiness.</p>
<p>• Computational Efficiency: Traditional methods are generally more computationally efficient compared to LLM-based methods, especially when fine-tuning models.However, LLM-based approaches offer greater flexibility and can handle a wider range of tasks, though at the cost of higher computational resources.Moreover, LLMs do not require extensive data preparation and training from scratch, which can offset the computational overhead in certain scenarios.</p>
<p>• Generalization: LLM-based methods are highly adaptable, capable of processing different types of data and tasks, such as text and images.In contrast, traditional methods often need custom architectures tailored to the specific data modality.</p>
<p>In conclusion, while traditional anomaly detection methods remain effective and computationally efficient, LLM-based methods provide greater flexibility, generalization, and explainability.This makes LLM-based approaches increasingly valuable in modern, complex anomaly detection tasks.</p>
<p>D Out-of-Distribution Detection Research Roadmap</p>
<p>Compared to Anomaly Detection (AD), Out-ofdistribution (OOD) detection emerged in 2017 and has since received increasing attention.OOD detection is critical for ensuring the reliability and safety of machine learning models by identifying samples that fall outside the distribution of the training data.Following Yang et al. (2024a), traditional OOD detection methods can be categorized into classification-based, density-based, distancebased, and reconstruction-based methods.These approaches vary in how they define and detect OOD samples, with each showing strengths depending on data characteristics and the task at hand.</p>
<p>D.1 Traditional Methods</p>
<p>Classification-based Methods.Classificationbased OOD detection methods rely on the outputs of neural networks , typically using the softmax probabilities of a classifier to determine whether a sample is in-distribution (ID) or OOD.The most common baseline is the Maximum Softmax Probability (MSP) method, which flags samples with lower softmax scores as OOD (Hendrycks and Gimpel, 2017).This has led to more advanced techniques that either post-process the classification outputs or modify the training process to improve OOD detection performance (Liu et al., 2020).</p>
<p>Given its alignment with classification tasks, this approach remains one of the most prominent methods for OOD detection.</p>
<p>Density-based Methods.Density-based methods explicitly model the distribution of indistribution (ID) data using probabilistic models, assuming that OOD samples will lie in low-density regions (Zong et al., 2018;Abati et al., 2019;Pidhorskyi et al., 2018;Deecke et al., 2018;Sabokrou et al., 2018).Techniques such as class-conditional Gaussian models allow for probabilistic modeling of ID classes, while flow-based models are also used for density estimation (Kobyzev et al., 2020;Zisselman and Tamar, 2020;Kingma and Dhariwal, 2018;Van Oord et al., 2016).However, densitybased methods sometimes assign higher likelihoods to OOD samples, leading to challenges in reliability.Methods such as likelihood ratio-based approaches and ensembles have been proposed to address these issues, though these approaches tend to be computationally expensive and often fall behind classification-based methods in performance.</p>
<p>Distance-based Methods.Distance-based methods operate under the assumption that OOD samples are farther from the centroids or prototypes of in-distribution classes in feature space.A popular parametric approach is to use Mahalanobis distance to compute the distance between test samples and class centroids (Lee et al., 2018), whereas non-parametric methods are increasingly favored for their flexibility and simplicity (Sun et al., 2022).These methods use various distance metrics-such as Euclidean distance, cosine similarity, and geodesic distance-to detect OOD samples.</p>
<p>Reconstruction-based Methods.Reconstruction-based methods leverage encoder-decoder models to reconstruct input samples and detect OOD samples by measuring reconstruction error.The premise is that models trained on ID data will exhibit lower reconstruction errors for ID samples and higher errors for OOD samples.(Zhou, 2022).</p>
<p>D.2 LLM-based OOD Detection</p>
<p>Large Language Models (LLMs) and Multi-Modal LLMs (MLLMs) have transformed Out-of-Distribution (OOD) detection by leveraging pretrained models like CLIP to perform downstream detection tasks.These models are capable of detecting OOD samples in zero-shot or few-shot settings, meaning they can generalize to unseen data with little to no additional training.This represents a shift from traditional OOD detection methods, which typically rely on training classifiers using the entire in-distribution (ID) dataset.</p>
<p>Incorporating the internal knowledge of pretrained MLLMs, the field is progressing towards even greater computational efficiency, where minimal or no training data is needed.This ability to operate with limited data while maintaining performance makes LLM-based OOD detection especially appealing for real-world applications.</p>
<p>D.3 Comparison of Traditional vs. LLM-based OOD Detection</p>
<p>The shift from traditional OOD detection methods to LLM-based approaches marks a fundamental change in how OOD detection is defined and executed.Traditional methods, such as classificationbased approaches like Maximum Softmax Probability (MSP) or distance-based techniques like Mahalanobis distance, rely heavily on task-specific training and typically require large amounts of indistribution (ID) data.These methods often define OOD detection in the context of post-processing or retraining models on ID data to differentiate between in-and out-of-distribution samples.</p>
<p>In contrast, LLM-based methods redefine OOD detection by leveraging pre-trained models, allowing them to detect OOD samples without extensive task-specific training.This results in a significant shift in the OOD detection paradigm, moving towards zero-shot and few-shot learning, where models can generalize to new tasks with minimal or no additional training.Key differences include: • Performance: LLM-based methods often outperform traditional methods in zero-shot and fewshot scenarios, where limited labeled data is available.Traditional methods struggle without substantial in-distribution data and retraining.</p>
<p>• Flexibility: LLM-based approaches are highly adaptable to new tasks and datasets due to their reliance on vast pre-trained knowledge, while traditional methods require significant retraining for new domains or data types.</p>
<p>• Efficiency: Traditional OOD methods rely on explicitly training models with in-distribution data, while LLM-based methods redefine the problem by leveraging pre-existing knowledge in zeroshot or few-shot settings, minimizing the need for retraining or task-specific data preparation.</p>
<p>In conclusion, the transition from traditional OOD detection methods to LLM-based approaches represents a shift from task-specific training and rigid models to more flexible, generalizable systems that can handle a wider variety of tasks with minimal additional training.As research continues, a hybrid approach combining the efficiency of traditional methods with the flexibility and generalization of LLM-based models may offer the most robust solution for diverse OOD detection challenges.</p>
<p>E Datasets E.1 Anomaly Detection</p>
<p>The field of anomaly detection using Large Language Models (LLMs) is still in its infancy, and as a result, no standardized benchmarks have been established.Nonetheless, several important datasets have emerged for specific applications.In industrial settings, datasets such as MVTec-AD (Bergmann et al., 2019) and VisA (Zou et al., 2022) are widely used for image anomaly detection and localization tasks.Medical image datasets, such as Chest X-ray (Kermany et al., 2018), Head CT (Felipe, 2018), have been applied for detecting and localizing anomalies in medical imaging.Additionally, various other datasets are employed across a range of anomaly detection applications, including logical anomaly detection using MVTec LOCO (Bergmann et al., 2022), video anomaly detection with the UCF-Crime dataset (Sultani et al., 2018).For time series and tabular anomaly detection, datasets like the ODDS dataset (Rayana, 2016) are common, alongside frequently used datasets such as YAHOO, ECG, SVDB, and IOPS, which focus on anomalies in monitoring systems and ECG recordings (Paparrizos et al., 2022).</p>
<p>E.2 OOD Detection</p>
<p>Standard benchmarks use ImageNet (Deng et al., 2009) as the in-distribution (ID) dataset and other datasets as OOD samples (Van Horn et al., 2018;Zhou et al., 2017;Xiao et al., 2010;Cimpoi et al., 2014), but the semantic gap between ID and OOD data can make detection easier.To address this, recent approaches split ImageNet classes into ID and OOD categories, with datasets like ImageNet-20 (Ming et al., 2022) and ImageNet-10 (Ming et al., 2022).</p>
<p>Beyond images, text-based OOD detection is also growing.</p>
<p>F Quantitative Analysis and Comparison</p>
<p>While our primary goal is to conduct a systematic literature review of existing methods for anomaly and out-of-distribution (OOD) detection tasks, we acknowledge that including quantitative analysis and comparisons is valuable for understanding the practical implications of these methods.</p>
<p>F.1 Anomaly Detection</p>
<p>Table 1 presents the quantitative results for imagelevel anomaly detection on two widely used benchmarks, MVTec AD (Bergmann et al., 2019) and VisA (Zou et al., 2022).The results are sourced from the original papers.We ensured that the experiments across different methods used the same dataset and learning settings for a fair comparison.</p>
<p>F.2 OOD Detection</p>
<p>Table 2 provides an overview of out-of-distribution (OOD) detection results using ImageNet-1K as the in-distribution (ID) dataset.The methods are evaluated across multiple OOD datasets, including Texture, iNaturalist, Places, and SUN (Van Horn et al., 2018;Zhou et al., 2017;Xiao et al., 2010;Cimpoi et al., 2014), with performance measured using AUC (Area Under the ROC Curve) and FPR95 (False Positive Rate at 95% True Positive Rate).</p>
<p>G Evaluation Metrics</p>
<p>The primary goal of both anomaly detection and out-of-distribution (OOD) detection is to differentiate between normal/in-distribution (ID) samples and abnormal/out-of-distribution (OOD) samples, framing the problem as a binary classification task.</p>
<p>Several common metrics are used to evaluate the performance of detectors:</p>
<p>AUROC (Area Under the Receiver Operating Characteristic curve): This metric evaluates a detector's overall ability to distinguish between ID or normal and OOD or anomalous samples.</p>
<p>The ROC curve plots the true positive rate (TPR) against the false positive rate (FPR), where:
T P R = T P T P + F N , F P R = F P F P + T N
Here, TP (true positives), TN (true negatives), FP (false positives), and FN (false negatives) correspond to the detector's correct and incorrect classifications.</p>
<p>AUPR (Area Under the Precision-Recall curve):</p>
<p>The AUPR metric is particularly useful for cases where there is class imbalance, as AUROC can be biased in such situations.The Precision-Recall curve plots precision recall, where: P recision = T P T P + F P , Recall = T P T P + F N FPR@N (False Positive Rate at TPR = N%): This metric evaluates the probability of misclassifying an OOD or anomalous sample as ID or normal when the true positive rate (TPR) is set at a specified value, commonly 90% or 95%.This is crucial for real-world deployments where achieving high accuracy on ID samples is important, while also minimizing false positives for OOD or anomaly detection.</p>
<p>F1 Score: The F1 score is a harmonic mean of precision and recall, providing a balanced evaluation of a model's performance across both metrics.It is particularly useful in scenarios where there is an imbalance between the positive and negative classes, as it gives a single metric that reflects both false positives and false negatives.</p>
<p>The F1 score is calculated as: A high F1 score indicates that the model maintains a good balance between precision (minimizing false positives) and recall (minimizing false negatives), which is critical in practical OOD detection and anomaly detection tasks.</p>
<p>H General Guidelines</p>
<p>We provide general guidelines for selecting appropriate approaches for anomaly or out-ofdistribution (OOD) detection, considering key factors such as data modality, efficiency, explanation, and optimization.</p>
<p>Data Modality: The choice of approach is strongly influenced by the type of data being analyzed.For textual data, prompting-based methods may not always offer meaningful interpretations of anomalies or OOD detection, particularly when trying to understand patterns in semantic spaces.In these cases, generating embeddings from large language models (LLMs) and applying specialized post-hoc detection techniques can lead to better results.Fine-tuning LLMs to produce more relevant embeddings may further enhance detection accuracy.In the case of numerical data, such as time series or tabular data, prompting-based methods have been explored, though they often require carefully designed prompts or fine-tuning to capture the underlying structure of the data.For vision data, including images and videos, the development of multimodal LLMs offers greater flexibility.(Wang et al., 2023) and (Miyai et al., 2024c).Others are sourced from their original papers (Wang et al., 2023;Jiang et al., 2024;Cao et al., 2024;Nie et al., 2024) Both prompting-based and contrasting learningbased methods can be highly effective, as they are capable of handling the diverse characteristics of multimodal data.</p>
<p>Efficiency: Efficiency is a crucial consideration when choosing between prompting-based and contrasting-based methods.Prompting-based methods can be inefficient for high-precision numerical tasks, as the conversion of numerical values into text results in excessively long input sequences.This inefficiency can become a bottleneck for tasks involving long-term predictions or large datasets, where the computational overhead of generating long outputs becomes significant.In contrast, contrasting-based methods are more efficient for detection tasks for image.By utilizing contrastive objectives to distinguish between positive and negative samples, these methods excel at zero-shot classification and are computationally more efficient, especially for handling multimodal anomaly and OOD detection.Researchers can also explore the use of contrasting-based approaches to numerical data modalities with their visual representations.</p>
<p>Explanation: In fields where trust, transparency, and interpretability are critical, explanation plays a pivotal role in model selection.LLMs offer a unique advantage by not only detecting anomalies but also generating human-like explanations that provide deeper insights into the nature of the detected anomalies.This capability is especially valuable in domains where actionable insights and interpretable results are essential for decision-making.</p>
<p>Research should focus on enhancing the ability of LLMs to explain their outputs in a way that aligns with domain-specific requirements for clarity and transparency.</p>
<p>Optimization: The optimization strategy is highly dependent on the specific data modality and the nature of the detection task.For promptingbased methods, parameter-efficient tuning techniques-such as Low-Rank Adaptation (LoRA) or adapter tuning-are essential for improving model performance without incurring high computational costs.These techniques enable models to adapt to new tasks efficiently while maintaining their generalization capabilities.Additionally, a hybrid approach where LLMs are used as generation tools alongside specialized anomaly or OOD detection algorithms can strike a balance between performance and efficiency.This allows the broad generalization capabilities of LLMs to be leveraged while optimizing for specific domain-related tasks, leading to improved accuracy and reduced computational overhead.</p>
<p>Figure 1 :
1
Figure 1: A simple illustration of leveraging LLMs for vision anomaly and OOD detection.</p>
<p>Definition 1
1
LLM-based Anomaly Detection: Given a test dataset D test = {x 1 , • • • , x n }, where each sample x i is drawn from distribution P in or P out .The objective of LLM-based Anomaly Detection is to use a pre-trained LLM as the backbone and develop a detection model f LLM (•) to predict whether each sample x ′ ∈ D test belongs to P out , where P out has covariate shift with P in Definition 2 LLM-based OOD Detection: Given a test dataset D test = {x 1 , • • • , x n }, where each sample x i is drawn from distribution P in or P out , and a known ID class set C = {c 1 , • • • , c k }.The objective of LLM-based OOD Detection is to use a pre-trained LLM as backbone and develop detection model f LLM (•) to predict whether each sample x ′ ∈ D test belongs to P out , where P out has semantic shift with P in .If not, x ′ will be classified into one of the classes in C.</p>
<p>Figure 2 :
2
Figure 2: The illustration of two approaches in ( §3): (a) Prompting-based Detection and (b) Contrasting-based Detection.</p>
<p>Figure 3 :
3
Figure 3: The illustration of four approaches in ( §4): (a) Text Embedding-based Augmentation; (b) Pseudo Label-based Augmentation; (c) Textual Descriptionbased Augmentation; and (d) Explanation-centric Generation.</p>
<p>F</p>
<p>Precision measures the proportion of true positive predictions out of all positive predictions made by the model, while recall measures the proportion of actual positives correctly identified by the model.There are two main variations of the F1 score:• Macro F1 Score: This version computes the F1 score independently for each class (ID and OOD, or normal and anomalous) and then takes the average across classes.It treats all classes equally, making it particularly useful when the class distribution is imbalanced.•Micro F1 Score: This version aggregates the contributions of all classes to calculate the F1 score, considering the total number of true positives, false positives, and false negatives across all classes.It is more sensitive to the performance on the larger class.</p>
<p>(Fu et al., 2024)24)e test image with seen and generated unseen labels is used as the OOD score.Instead of training an additional text decoder, NegLabel(Jiang et al., 2024)and CLIPScope(Fu et al., 2024)rely on auxiliary datasets to gather potential OOD labels.CLIPScope gathers nouns from open-world sources as potential OOD labels and uses them in designed prompts to ensure maximal coverage of potential OOD samples.NegLabel employs the NegMining algorithm to select high-quality negative labels with sufficient semantic differences from ID labels.Recent work utilizes the emergent abilities of LLMs to generate reliable OOD labels, such as(Cao et al., 2024),</p>
<p>(Esmaeilpour et al., 2022)vestigate using CLIP for OOD detection and demonstrate encouraging performance.However, in their setup, they include the candidate labels related to the actual OOD classes and utilize this knowledge as a very weak form of outlier exposure, which contradicts the openworld assumption.Therefore, after this work, researchers aim to leverage pseudo-OOD labels in the text prompt instead of using actual OOD labels.The earliest work under this idea is ZOC(Esmaeilpour et al., 2022)which trains a text description generator on top of CLIP's image encoder to dynamically generate candidate unseen labels for each test image.</p>
<p>Table 1 :
1
Common datasets include 20 News-Anomaly detection results for MVTec AD andVisA (image-level).Bold indicates the best performance.The methods marked with † are using MLLMs as backbones.The results are are sourced from(Zhou et al.,
MethodMVTec AD VisAAUC ↑AUC ↑Zero-shotCoOp (Zhou et al., 2022)  †88.862.8CLIP-AC (Radford et al., 2021)  †71.565.0VAND (Chen et al., 2023a)  †86.178.0AnomalyCLIP (Zhou et al., 2024)  †91.582.1CLIP-AD (Liznerski et al., 2022)  †90.979.2FiLo (Gu et al., 2024a)  †91.283.9One-shotSPADE (Park et al., 2019)81.079.5PaDiM (Defard et al., 2021)76.662.8PatchCore (Roth et al., 2022)83.479.9WinCLIP (Jeong et al., 2023)  †93.183.8AnomalyGPT (Gu et al., 2024b)  †94.187.4AnomalyDINO-S (Damm et al., 2024)  †96.687.42024; Gu et al., 2024b)groups (20NG) (Lang, 1995) for topic classifica-tion and SST-2 (Socher et al., 2013) for sentimentanalysis. Typically, 20NG and SST-2 serve as IDdatasets, while the others are used as OOD. In in-tent detection, the CLINC150 dataset (Repository,2020) is commonly used, splitting domains likeBanking and Travel into ID and OOD categories.</p>
<p>Table 2 :
2
FPR95 ↓ AUC ↑ FPR95 ↓ AUC ↑ FPR95 ↓ AUC ↑ FPR95 ↓ AUC ↑ FPR95 ↓ Comprehensive OODdetection results for ImageNet-1K as ID dataset.The black bold indicates the best performance.The results marked with † are sourced from
Texture AUC ↑ Traditional posthoc methods MethodiNaturalistPlacesSUNAvgMSP (Hendrycks et al., 2019)  †74.8473.6677.7474.5772.1879.1273.9776.9574.9876.22MaxLogit (Hendrycks et al., 2019)  † 88.6348.7288.0360.8887.4555.5491.1644.8388.8252.49Energy (Liu et al., 2020)  †88.2250.3987.1864.9887.3357.4091.1746.4288.4854.80ReAct (Sun et al., 2021)  †88.1349.8886.8765.5787.4256.8591.0446.1788.3754.62ODIN (Liang et al., 2018)  †87.8551.6794.6530.2285.5455.0687.1754.0488.8047.75Without Tuning methodsMCM (Ming et al., 2022)  †86.1157.7794.6130.9189.7744.6992.5734.5990.7642.74NegLabel (Jiang et al., 2024)90.2243.599.491.9191.6435.5995.4920.5394.2125.40EOE (Cao et al., 2024)57.5385.6497.5212.2995.7320.4092.9530.1692.9630.09With Tuning methodsCoOp (Zhou et al., 2022)89.4745.0093.7729.8190.5840.1193.2940.8391.7851.68LoCoOp (Miyai et al., 2024c)  †90.1942.2896.8616.0591.9832.8795.0723.4493.5228.66CLIPN (Wang et al., 2023)  †90.9340.8395.2723.9492.2833.4593.9226.1793.1031.10NegPrompt (Nie et al., 2024)91.6035.2198.736.3293.3427.6095.5522.8994.8123.01</p>
<p>Anomalydino: Boosting patch-based few-shot anomaly detection with dinov2. Simon Damm, Mike Laszkiewicz, Johannes Lederer, Asja Fischer, arXiv:2405.145292024arXiv preprint</p>
<p>Parametric model fitting: From inlier characterization to outlier detection. Gaudenz Danuser, Markus Stricker, 1998TPAMI</p>
<p>Image anomaly detection with generative adversarial networks. Lucas Deecke, Robert Vandermeulen, Lukas Ruff, Stephan Mandt, Marius Kloft, ECML&amp;KDD. 2018</p>
<p>Padim: a patch distribution modeling framework for anomaly detection and localization. Thomas Defard, Aleksandr Setkov, Angelique Loesch, Romaric Audigier, International Conference on Pattern Recognition. Springer2021</p>
<p>Anovl: Adapting vision-language models for unified zero-shot anomaly localization. Hanqiu Deng, Zhaoxiang Zhang, Jinan Bao, Xingyu Li, arXiv:2308.159392023arXiv preprint</p>
<p>Imagenet: A large-scale hierarchical image database. Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, Li Fei-Fei, CVPR. 2009</p>
<p>Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, arXiv:1810.04805Pre-training of deep bidirectional transformers for language understanding. Bert2018arXiv preprint</p>
<p>Semantic anomaly detection with large language models. Amine Elhafsi, Rohan Sinha, Christopher Agia, Edward Schmerling, Marco Issa Ad Nesnas, Pavone, 10.1007/s10514-023-10132-6Autonomous Robots. 2023</p>
<p>Zero-shot out-of-distribution detection based on the pre-trained model clip. Sepideh Esmaeilpour, Bing Liu, Eric Robertson, Lei Shu, AAAI. 2022</p>
<p>Head ct -hemorrhage. Felipe Kitamura, 2018</p>
<p>Exploring the limits of out-of-distribution detection. Stanislav Fort, Jie Ren, Balaji Lakshminarayanan, 2021NeurIPS</p>
<p>Clipscope: Enhancing zero-shot ood detection with bayesian scoring. Hao Fu, Naman Patel, Prashanth Krishnamurthy, Farshad Khorrami, arXiv:2405.147372024arXiv preprint</p>
<p>Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio, Generative adversarial nets. NeurIPS2014</p>
<p>Filo: Zero-shot anomaly detection by fine-grained description and high-quality localization. Zhaopeng Gu, Bingke Zhu, Guibo Zhu, Yingying Chen, Hao Li, Ming Tang, Jinqiao Wang, arXiv:2404.136712024aarXiv preprint</p>
<p>Anomalygpt: Detecting industrial anomalies using large visionlanguage models. Zhaopeng Gu, Bingke Zhu, Guibo Zhu, Yingying Chen, Ming Tang, Jinqiao Wang, AAAI. 2024b</p>
<p>A survey of methods for explaining black box models. Riccardo Guidotti, Anna Monreale, Salvatore Ruggieri, Franco Turini, Fosca Giannotti, Dino Pedreschi, 2019ACM computing surveys (CSUR</p>
<p>Anomaly detection on unstable logs with gpt models. Fatemeh Hadadi, Qinghua Xu, Domenico Bianculli, Lionel Briand, arXiv:2406.074672024arXiv preprint</p>
<p>Scaling out-ofdistribution detection for real-world settings. Dan Hendrycks, Steven Basart, Mantas Mazeika, Andy Zou, Joe Kwon, Mohammadreza Mostajabi, Jacob Steinhardt, Dawn Song, arXiv:1911.111322019arXiv preprint</p>
<p>A baseline for detecting misclassified and out-of-distribution examples in neural networks. Dan Hendrycks, Kevin Gimpel, 2017In ICLR</p>
<p>Financial fraud: A review of anomaly detection techniques and recent advances. Waleed Hilal, S Andrew Gadsden, John Yawney, 10.1016/j.eswa.2021.116429Expert Systems with Applications. 2022</p>
<p>Causability and explainability of artificial intelligence in medicine. Andreas Holzinger, Georg Langs, Daniel Denk, Kurt Zatloukal, Henning Müller, 2019Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery</p>
<p>Anomaly detection using local kernel density estimation and contextbased regression. Weiming Hu, Jun Gao, Bing Li, Ou Wu, Junping Du, Stephen Maybank, 2018TKDE</p>
<p>Llm-adapters: An adapter family for parameter-efficient finetuning of large language models. Zhiqiang Hu, Lei Wang, Yihuai Lan, Wanyu Xu, Ee-Peng Lim, Lidong Bing, Xing Xu, Soujanya Poria, Roy Ka-Wei Lee, arXiv:2304.019332023arXiv preprint</p>
<p>Adapting visual-language models for generalizable anomaly detection in medical images. Chaoqin Huang, Aofan Jiang, Jinghao Feng, Ya Zhang, Xinchao Wang, Yanfeng Wang, CVPR. 2024a</p>
<p>Out-of-distribution detection using peer-class generated by large language model. Huang, Hanwen Song, Jiyan Su, Wang, arXiv:2403.133242024barXiv preprint</p>
<p>Positive and unlabeled learning algorithms and applications: A survey. Kristen Jaskie, Andreas Spanias, International Conference on Information, Intelligence, Systems and Applications. 2019</p>
<p>Winclip: Zero-/few-shot anomaly classification and segmentation. Jongheon Jeong, Yang Zou, Taewan Kim, Dongqing Zhang, Avinash Ravichandran, Onkar Dabeer, CVPR. 2023</p>
<p>Anomaly detection of tabular data using llms. Aodong Li, Yunhan Zhao, Chen Qiu, Marius Kloft, Padhraic Smyth, Maja Rudolph, Stephan Mandt, arXiv:2406.163082024aarXiv preprint</p>
<p>Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models. Junnan Li, Dongxu Li, Silvio Savarese, Li Fei-Fei, arXiv:2301.125972023aarXiv preprint</p>
<p>Learning transferable negative prompts for out-of-distribution detection. Tianqi Li, Guansong Pang, Xiao Bai, Wenjun Miao, Jin Zheng, CVPR. 2024b</p>
<p>Setar: Out-of-distribution detection with selective low-rank approximation. Yixia Li, Boya Xiong, Guanhua Chen, Yun Chen, arXiv:2406.126292024carXiv preprint</p>
<p>Myriad: Large multimodal model by applying vision experts for industrial anomaly detection. Yuanze Li, Haolin Wang, Shihao Yuan, Ming Liu, Debin Zhao, Yiwen Guo, Chen Xu, Guangming Shi, Wangmeng Zuo, arXiv:2310.190702023barXiv preprint</p>
<p>Enhancing the reliability of out-of-distribution image detection in neural networks. Shiyu Liang, Yixuan Li, R Srikant, International Conference on Learning Representations. 2018</p>
<p>How good are LLMs at out-of-distribution detection?. Bo Liu, Li-Ming Zhan, Zexin Lu, Yujie Feng, Lei Xue, Xiao-Ming Wu, Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024). the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)Torino, ItaliaELRA and ICCL2024a</p>
<p>Deep industrial image anomaly detection: A survey. Jiaqi Liu, Guoyang Xie, Jinbao Wang, Shangnian Li, Chengjie Wang, Feng Zheng, Yaochu Jin, 2024bMachine Intelligence Research</p>
<p>Large language models can deliver accurate and interpretable time series anomaly detection. Jun Liu, Chaoyun Zhang, Jiaxu Qian, Minghua Ma, Si Qin, Chetan Bansal, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, arXiv:2405.153702024carXiv preprint</p>
<p>Energy-based out-of-distribution detection. Weitang Liu, Xiaoyun Wang, John Owens, Yixuan Li, 2020NeurIPS</p>
<p>Logprompt: Prompt engineering towards zero-shot and interpretable log analysis. Yilun Liu, Shimin Tao, Weibin Meng, Feiyu Yao, Xiaofeng Zhao, Hao Yang, ICSE. 2024d</p>
<p>Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov, arXiv:1907.11692Roberta: A robustly optimized bert pretraining approach. 2019arXiv preprint</p>
<p>Exposing outlier exposure: What can be learned from few, one, and zero outlier images. Philipp Liznerski, Lukas Ruff, Robert A Vandermeulen, Billy Joe Franks, Klaus-Robert Müller, Marius Kloft, arXiv:2205.114742022arXiv preprint</p>
<p>Video anomaly detection and explanation via large language models. Hui Lv, Qianru Sun, arXiv:2401.057022024arXiv preprint</p>
<p>Delving into out-ofdistribution detection with vision-language representations. Yifei Ming, Ziyang Cai, Jiuxiang Gu, Yiyou Sun, Wei Li, Yixuan Li, 2022NeurIPS</p>
<p>How does finetuning impact out-of-distribution detection for visionlanguage models? IJCV. Yifei Ming, Yixuan Li, 2024</p>
<p>Generalized out-of-distribution detection and beyond in vision language model era: A survey. Atsuyuki Miyai, Jingkang Yang, Jingyang Zhang, Yifei Ming, Yueqian Lin, Qing Yu, Go Irie, Shafiq Joty, Yixuan Li, Hai Li, arXiv:2407.217942024aarXiv preprint</p>
<p>Unsolvable problem detection: Evaluating trustworthiness of vision language models. Atsuyuki Miyai, Jingkang Yang, Jingyang Zhang, Yifei Ming, Qing Yu, Go Irie, Yixuan Li, Hai Li, Ziwei Liu, Kiyoharu Aizawa, arXiv:2403.203312024barXiv preprint</p>
<p>Zero-shot in-distribution detection in multi-object settings using vision-language foundation models. Atsuyuki Miyai, Qing Yu, Go Irie, Kiyoharu Aizawa, arXiv:2304.045212023arXiv preprint</p>
<p>Locoop: Few-shot out-ofdistribution detection via prompt learning. Atsuyuki Miyai, Qing Yu, Go Irie, Kiyoharu Aizawa, ICLR. Bo Liu, Xinmei Han, Tian, 2024c. 2024Out-of-distribution detection with negative prompts</p>
<p>arXiv:2303.08774Gpt-4 technical report. 2023OpenAIarXiv preprint</p>
<p>Longbing Cao, and Anton Van Den Hengel. 2021. Deep learning for anomaly detection: A review. Guansong Pang, Chunhua Shen, CSUR</p>
<p>Tsb-uad: an end-to-end benchmark suite for univariate time-series anomaly detection. John Paparrizos, Yuhao Kang, Paul Boniol, Ruey S Tsay, Themis Palpanas, Michael J Franklin, 10.14778/3529337.3529354Proc. VLDB Endow. VLDB Endow2022</p>
<p>On the powerfulness of textual outlier exposure for visual ood detection. Sangha Park, Jisoo Mok, Dahuin Jung, Saehyung Lee, Sungroh Yoon, NeurIPS. 2023</p>
<p>Semantic image synthesis with spatially-adaptive normalization. Taesung Park, Ming-Yu Liu, Ting-Chun Wang, Jun-Yan Zhu, CVPR. 2019</p>
<p>On estimation of a probability density function and mode. The annals of mathematical statistics. Emanuel Parzen, 1962</p>
<p>Generative probabilistic novelty detection with adversarial autoencoders. Stanislav Pidhorskyi, Ranya Almohsen, Donald A Adjeroh, Gianfranco Doretto, NeurIPS. 2018</p>
<p>Loggpt: Exploring chatgpt for log-based anomaly detection. Jiaxing Qi, Shaohan Huang, Zhongzhi Luan, Shu Yang, Carol Fung, Hailong Yang, Depei Qian, Jing Shang, Zhiwen Xiao, Zhihui Wu, 10.1109/HPCC-DSS-SmartCity-DependSys60770.2023.000452023</p>
<p>Learning transferable visual models from natural language supervision. Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, ICML. 2021</p>
<p>Exploring the limits of transfer learning with a unified text-to-text transformer. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, 2020JMLR</p>
<p>Odds library. UCI Machine Learning Repository. Shebuti Rayana, 2016. 2020C150</p>
<p>Towards total recall in industrial anomaly detection. Karsten Roth, Latha Pemula, Joaquin Zepeda, Bernhard Schölkopf, Thomas Brox, Peter Gehler, CVPR. 2022</p>
<p>Deep one-class classification. Lukas Ruff, Robert Vandermeulen, Nico Goernitz, Lucas Deecke, Ahmed Shoaib, Alexander Siddiqui, Emmanuel Binder, Marius Müller, Kloft, ICML. 2018</p>
<p>Adversarially learned one-class classifier for novelty detection. Mohammad Sabokrou, Mohammad Khalooei, Mahmood Fathy, Ehsan Adeli, CVPR. 2018</p>
<p>Pranab Sahoo, Ayush Kumar Singh, Sriparna Saha, Vinija Jain, Samrat Mondal, Aman Chadha, arXiv:2402.07927A systematic survey of prompt engineering in large language models: Techniques and applications. 2024arXiv preprint</p>
<p>Mohammad Hossein Rohban, and Mohammad Sabokrou. 2021. A unified survey on anomaly, novelty, open-set, and out-of-distribution detection: Solutions and future challenges. Mohammadreza Salehi, Hossein Mirzaei, Dan Hendrycks, Yixuan Li, arXiv:2110.14051arXiv preprint</p>
<p>Real-time anomaly detection and reactive planning with large language models. Rohan Sinha, Amine Elhafsi, Christopher Agia, Matthew Foutter, Edward Schmerling, Marco Pavone, arXiv:2407.087352024arXiv preprint</p>
<p>Recursive deep models for semantic compositionality over a sentiment treebank. Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D Manning, Andrew Ng, Christopher Potts, 2013</p>
<p>Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. the 2013 Conference on Empirical Methods in Natural Language ProcessingSeattle, Washington, USAAssociation for Computational Linguistics</p>
<p>Large language models for forecasting and anomaly detection: A systematic literature review. Jing Su, Chufeng Jiang, Xin Jin, Yuxin Qiao, Tingsong Xiao, Hongda Ma, Rong Wei, Zhi Jing, Jiajun Xu, Junhong Lin, arXiv:2402.103502024arXiv preprint</p>
<p>Real-world anomaly detection in surveillance videos. Waqas Sultani, Chen Chen, Mubarak Shah, CVPR. 2018</p>
<p>React: Out-of-distribution detection with rectified activations. Yiyou Sun, Chuan Guo, Yixuan Li, Advances in Neural Information Processing Systems. 2021</p>
<p>Out-of-distribution detection with deep nearest neighbors. Yiyou Sun, Yifei Ming, Xiaojin Zhu, Yixuan Li, ICML. 2022</p>
<p>Csi: Novelty detection via contrastive learning on distributionally shifted instances. Jihoon Tack, Sangwoo Mo, Jongheon Jeong, Jinwoo Shin, NeurIPS. 2020</p>
<p>One-class classification: Concept learning in the absence of counterexamples. David Martinus, Johannes Tax, 2002</p>
<p>Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, arXiv:2312.11805Gemini: a family of highly capable multimodal models. 2023arXiv preprint</p>
<p>Anomaly detection using self-organizing maps-based k-nearest neighbor algorithm. Jing Tian, Michael Michael H Azarian, Pecht, PHM Society European Conference. 2014</p>
<p>Thibaut Hugo Touvron, Gautier Lavril, Xavier Izacard, Marie-Anne Martinet, Thomas Lachaux, Baptiste Lacroix, Naman Rozière, Eric Goyal, Ferhan Hambro, Azhar, arXiv:2302.13971Llama: Open and efficient foundation language models. 2023arXiv preprint</p>
<p>Poisson factorization for peer-based anomaly detection. Melissa Turcotte, Juston Moore, Nick Heard, Aaron Mcphall, IEEE Conference on Intelligence and Security Informatics (ISI). 2016</p>
<p>The inaturalist species classification and detection dataset. Grant Van Horn, Oisin Mac Aodha, Yang Song, Yin Cui, Chen Sun, Alex Shepard, Hartwig Adam, Pietro Perona, Serge Belongie, CVPR. 2018</p>
<p>Pixel recurrent neural networks. Aaron Van Oord, Nal Kalchbrenner, Koray Kavukcuoglu, 2016In ICML</p>
<p>Clipn for zero-shot ood detection: Teaching clip to say no. Hualiang Wang, Yi Li, Huifeng Yao, Xiaomeng Li, ICCV. 2023</p>
<p>Visionllm: Large language model is also an open-ended decoder for vision-centric tasks. Wenhai Wang, Zhe Chen, Xiaokang Chen, Jiannan Wu, Xizhou Zhu, Gang Zeng, Ping Luo, Tong Lu, Jie Zhou, Yu Qiao, 2024NeurIPS</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Denny Quoc V Le, Zhou, 2022NeurIPS</p>
<p>Large language models are diverse role-players for summarization evaluation. Ning Wu, Ming Gong, Linjun Shou, Shining Liang, Daxin Jiang, 2023In NLPCC</p>
<p>Sun database: Large-scale scene recognition from abbey to zoo. Jianxiong Xiao, James Hays, Krista A Ehinger, Aude Oliva, Antonio Torralba, CVPR. 2010</p>
<p>Contrastive novelty-augmented learning: Anticipating outliers with large language models. Albert Xu, Xiang Ren, Robin Jia, 10.18653/v1/2023.acl-long.658Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics. Long Papers. the 61st Annual Meeting of the Association for Computational LinguisticsToronto, CanadaAssociation for Computational Linguistics20231</p>
<p>Generalized out-of-distribution detection: A survey. Jingkang Yang, Kaiyang Zhou, Yixuan Li, Ziwei Liu, 10.1007/s11263-024-02117-42024aIJCV</p>
<p>Follow the rules: Reasoning for video anomaly detection with large language models. Yuchen Yang, Kwonjoon Lee, Behzad Dariush, Yinzhi Cao, Shao-Yuan Lo, arXiv:2407.102992024barXiv preprint</p>
<p>Shukang Yin, Chaoyou Fu, Sirui Zhao, Ke Li, Xing Sun, Tong Xu, Enhong Chen, arXiv:2306.13549A survey on multimodal large language models. 2023arXiv preprint</p>
<p>Harnessing large language models for training-free video anomaly detection. Luca Zanella, Willi Menapace, Massimiliano Mancini, Yiming Wang, Elisa Ricci, CVPR. 2024</p>
<p>Your finetuned large language model is already a powerful out-of-distribution detector. Andi Zhang, Tim Z Xiao, Weiyang Liu, Robert Bamler, Damon Wischik, arXiv:2404.086792024aarXiv preprint</p>
<p>Learning from positive and unlabeled examples: A survey. Bangzuo Zhang, Wanli Zuo, International Symposiums on Information Processing. 2008</p>
<p>Holmes-vad: Towards unbiased and explainable video anomaly detection via multi-modal llm. Huaxin Zhang, Xiaohao Xu, Xiang Wang, Jialong Zuo, Chuchu Han, Xiaonan Huang, Changxin Gao, Yuehuan Wang, Nong Sang, arXiv:2406.122352024barXiv preprint</p>
<p>Exploring grounding potential of vqa-oriented gpt-4v for zero-shot anomaly detection. Jiangning Zhang, Xuhai Chen, Zhucun Xue, Yabiao Wang, Chengjie Wang, Yong Liu, arXiv:2311.026122023arXiv preprint</p>
<p>Places: A 10 million image database for scene recognition. Bolei Zhou, Agata Lapedriza, Aditya Khosla, Aude Oliva, Antonio Torralba, 2017TPAMI</p>
<p>Learning to prompt for visionlanguage models. Kaiyang Zhou, Jingkang Yang, Chen Change Loy, Ziwei Liu, 2022IJCV</p>
<p>AnomalyCLIP: Object-agnostic prompt learning for zero-shot anomaly detection. Qihang Zhou, Guansong Pang, Yu Tian, Shibo He, Jiming Chen, 2024In ICLR</p>
<p>Do llms understand visual anomalies? uncovering llm capabilities in zero-shot anomaly detection. Yibo Zhou, ACM Multimedia. Cvpr Jiaqi Zhu, Shaofeng Cai, Fang Deng, Junran Wu, 2022. 2024. 2024Rethinking reconstruction autoencoder-based out-of-distribution detection</p>
<p>Toward generalist anomaly detection via in-context residual learning with few-shot sample prompts. Jiawen Zhu, Guansong Pang, CVPR. 2024</p>
<p>Deep residual flow for out of distribution detection. Ev Zisselman, Aviv Tamar, CVPR. 2020</p>
<p>Deep autoencoding gaussian mixture model for unsupervised anomaly detection. Bo Zong, Qi Song, Martin Renqiang Min, Wei Cheng, Cristian Lumezanu, Daeki Cho, Haifeng Chen, ICLR. 2018</p>
<p>Spot-the-difference self-supervised pre-training for anomaly detection and segmentation. Yang Zou, Jongheon Jeong, Latha Pemula, Dongqing Zhang, Onkar Dabeer, European Conference on Computer Vision. 2022</p>            </div>
        </div>

    </div>
</body>
</html>