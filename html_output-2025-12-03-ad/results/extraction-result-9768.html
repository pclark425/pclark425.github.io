<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9768 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9768</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9768</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-165.html">extraction-schema-165</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <p><strong>Paper ID:</strong> paper-2012877f69aa01ad5d8c7283154c14a84aeaf7ad</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/2012877f69aa01ad5d8c7283154c14a84aeaf7ad" target="_blank">Large-Scale Knowledge Synthesis and Complex Information Retrieval from Biomedical Documents</a></p>
                <p><strong>Paper Venue:</strong> 2022 IEEE International Conference on Big Data (Big Data)</p>
                <p><strong>Paper TL;DR:</strong> This work offers an all-in-one scalable solution for extracting and exploring complex information from large-scale research documents, which would otherwise be tedious.</p>
                <p><strong>Paper Abstract:</strong> Recent advances in the healthcare industry have led to an abundance of unstructured data, making it challenging to perform tasks such as efficient and accurate information retrieval at scale. Our work offers an all-in-one scalable solution for extracting and exploring complex information from large-scale research documents, which would otherwise be tedious. First, we briefly explain our knowledge synthesis process to extract helpful information from unstructured text data of research documents. Then, on top of the knowledge extracted from the documents, we perform complex information retrieval using three major components- Paragraph Retrieval, Triplet Retrieval from Knowledge Graphs, and Complex Question Answering (QA). These components combine lexical and semantic-based methods to retrieve paragraphs and triplets and perform faceted refinement for filtering these search results. The complexity of biomedical queries and documents necessitates using a QA system capable of handling queries more complex than factoid queries, which we evaluate qualitatively on the COVID-19 Open Research Dataset (CORD-19) to demonstrate the effectiveness and value-add.</p>
                <p><strong>Cost:</strong> 0.003</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9768",
    "paper_id": "paper-2012877f69aa01ad5d8c7283154c14a84aeaf7ad",
    "extraction_schema_id": "extraction-schema-165",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.0032817499999999995,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Large-Scale Knowledge Synthesis and Complex Information Retrieval from Biomedical Documents</h1>
<p>Shreya Saxena<em>, Raj Sangani</em>, Siva Prasad<em>, Shubham Kumar</em><br>Mihir Athale<em>, Rohan Awhad</em>, Vishal Vaddina*<br>Applied Research, Quantiphi<br>{shreya.saxena, siva.prasad, shubham.kumar01, mihir.athale, rohan.awhad, vishal.vaddina}@quantiphi.com<br>rsangani@ucdavis.edu</p>
<h4>Abstract</h4>
<p>Recent advances in the healthcare industry have led to an abundance of unstructured data, making it challenging to perform tasks such as efficient and accurate information retrieval at scale. Our work offers an all-in-one scalable solution for extracting and exploring complex information from large-scale research documents, which would otherwise be tedious. First, we briefly explain our knowledge synthesis process to extract helpful information from unstructured text data of research documents. Then, on top of the knowledge extracted from the documents, we perform complex information retrieval using three major components- Paragraph Retrieval, Triplet Retrieval from Knowledge Graphs, and Complex Question Answering (QA). These components combine lexical and semantic-based methods to retrieve paragraphs and triplets and perform faceted refinement for filtering these search results. The complexity of biomedical queries and documents necessitates using a QA system capable of handling queries more complex than factoid queries, which we evaluate qualitatively on the COVID-19 Open Research Dataset (CORD-19) to demonstrate the effectiveness and valueadd.</p>
<p>Index Terms-Information-Retrieval, Knowledge-Synthesis, Semantic-Retrieval, Question-Answering, CORD-19</p>
<h2>I. INTRODUCTION</h2>
<p>The healthcare sector stands tall with an enormous amount of unstructured text data in documents, articles, biomedical journals, and JSON files, as well as structured data like tables, and electronic health records, often leading to a severe information overload challenge. To researchers and health professionals, extracting relevant information from a huge corpus of biomedical data is a complex and tedious task that delays the research outcome and involves considerable capital. Therefore, there is an increased urgency for an information retrieval system in the biomedical domain to retrieve such complex information.
Information Retrieval (IR) is a core task in many real-world applications, such as digital libraries, expert finding, web search and others. Information retrieval aims at retrieving information relevant to a query from large data collections, which has been an active research area in the healthcare domain [2] [3] [4]. Traditional information retrieval systems rely on lexical retrievers such as Boolean Retrieval, BM25</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>[5], and statistical language models, which aim to find an exact match between the query and documents but fail to handle the problem of vocabulary and semantic mismatch. Earlier studies in neural IR handle the problem of vocabulary mismatch by taking a different approach, such as maximum inner product search (MIPS) between GLoVe [6] or Word2vec [7] embeddings of query and document terms. The problem of semantic mismatch was solved by leveraging contextual embeddings with the introduction of language models [8]. Lexical systems might fail to capture the semantics of the concepts, especially in biomedical data with complex terms that sometimes are quite ambiguous. Semantic systems can handle this ambiguity well, but these systems often have difficulty dealing with longer contexts. Hence, we need a hybrid framework that can accommodate both of these mechanisms. This paper conceptualizes a framework to help users access meaningful information extracted from massive corpora in the biomedical domain. They can explore the information in the form of knowledge graphs (Section III.A), search for specific information, and get answers to complex questions i.e, questions that require multiple contexts to provide an answer (e.g. "What virus was isolated from a patient who died from acute respiratory failure?").
We propose an all-in-one information retrieval framework using lexical and semantic approaches, shown in Fig.1, that combines multiple functionalities like passage retrieval; triplet retrieval from knowledge graphs and complex QA. We also include faceted navigation for filtering the triplet search results, making it easier for the user to explore relevant information through a large amount of data. Our question answering system can answer complex queries by integrating multi-hop dense retriever [9], which uses a dense iterative retrieval method.
The following describes how the paper is structured: Background information is provided in Section-II. The methodology is then discussed in Section-III with distinct subsections for its various components, experiments are discussed in Section-IV, and Section-V concludes the paper.</p>
<h2>II. BACKGROUND</h2>
<p>To researchers and health professionals, extracting relevant information from a huge corpus of medical research documents and texts is a complex, time-consuming, and tedious task that delays the research outcome and involves consid-</p>
<p>erable capital, yet is a necessity. Therefore, there has been an increased urgency for an information retrieval system in the medical domain to retrieve such complex information [10]. Recent years have witnessed an increase in information retrieval systems in the healthcare domain, such as a medical information retrieval system for e-healthcare records [11], retrieval of semantically similar questions in healthcare forums [12], and a system that uses information retrieval with an added component for classifying breast cancer [13].
Due to the pandemic, information extraction around COVID19 data has emerged as an active research area [14], predominantly using knowledge graphs [15] [16]. Complex question answering, especially in the medical domain, has also become prominent [17]. These systems try to solve problems like knowledge graph (KG) generation on structured data, factoid question answering and searching entities in the KG [18]. These systems fail to address these use cases comprehensively. For example, the KG created might be ontology specific and cannot capture facts from open text or might only represent metadata information in the form of a graph; these systems also fail to provide an efficient integrated search [19] [20] and QA functionality such as ours.
Recent transformer-based retrievers mostly rely on the maximum inner product search between the dense representation of the query and the documents, generated using transformer models. These retriever-based systems are often supported by a re-ranker, based on variants of transformer models like SBERT and BERT-based cross-encoders [21].
Previous work on Open Domain Question Answering [22] is mainly based on retriever and reader architecture, Iterative Retriever, Reader, Reranker (IRRR) [23], which captures an initial set of keywords from the query, expands it based on the passages it retrieves from the database and re-ranks them. These re-ranked passages are then passed to the reader to generate answers, and the whole process is iteratively repeated until the answer is found with high confidence. All of this makes the IRRR based systems highly complex due to the large number of components involved, coupled with longer inference time and higher memory consumption. Other retrieval methods use graph-based knowledge along with transformer models to find multi-hop reasoning paths [24] [25].</p>
<h2>III. Methodology</h2>
<p>In this section, we explain the proposed model architecture. We use CORD-19 [26] as an example dataset for explaining the pipeline and process throughout this paper, although the entire framework is flexible and should be translatable to a variety of datasets in biomedical literature.</p>
<h2>A. Knowledge Synthesis</h2>
<p>In the biomedical domain, data may be present in the form of blogs, articles, research papers, clinical documents, etc. We adopt a knowledge synthesis process to extract information in the form of subject-relation-object triplets from such unstructured text documents.
a) Knowledge graph construction: We first clean and preprocess the text from research documents. This data is indexed for further use by the retrievers to retrieve relevant contexts. Then we pass this text through our knowledge graph construction pipeline, which is as follows:-</p>
<p>1) Coreference Resolution on the sentences.
2) Extracting triplets (subject, relation, object pairs) using the Open Information Extraction (OpenIE 6) System [27] from sentences.
3) Canonicalization of the extracted relations.
4) Linking extracted entities to appropriate ontology.</p>
<p>The above pipeline results in the formation of a knowledge graph, which consists of canonicalized and linked triplets, extracted from the biomedical documents. We also include metadata such as Authors, Institutions, Publication Year, etc. along with textual phrases from the original documents.</p>
<h2>B. Complex Information Retrieval</h2>
<p>Our Complex Information Retrieval system consists of three main components:- Paragraph Retrieval, Triplet Retrieval, and Complex Question Answering. We also have a spell checker that corrects spelling errors in the query asked by the user.</p>
<p>Spell correction: Often queries include misspelled terms resulting in irrelevant results. Therefore, a spell correction module trained on biomedical text is deployed to correct the query before handing it over to the retrievers, enabling the system to handle adversarial examples of misspelled terms robustly. The module is based on [28], which uses Levenshtein Distance (edit distance) and the probability of the word appearing in the document.</p>
<p>$$
\operatorname{correction}(w)=\operatorname{argmax}_{c \in \text { candidates }} P(c \mid w)
$$</p>
<p>Out of all possible candidate corrections, having an edit distance of 2 or less, the algorithm finds the correction c that maximizes the probability that c is the intended correction, given the original word w.</p>
<p>1) Paragraph Retrieval: To retrieve the most relevant piece of information from indexed documents, we introduce the paragraph retrieval functionality, where one paragraph is considered a unit of information and indexed. The retrieval combines four different search mechanisms viz, phrase search, bigram search, keyword search and semantic search. For all the mechanisms, we use ElasticSearch for indexing. We employ a cross-encoder to re-rank the results based on their relevance to the given query.
a) Phrase Search: Phrase search finds an exact match for the entire query or a part of the query, which can be specified by encoding the phrase in double quotes, e.g. Human "SARSCoV" infection where we retrieve the relevant documents by matching the exact phrase "SARS-CoV".
b) Bi-gram Search: Bi-gram search splits the query into pairs of words, called bi-grams. These bi-grams are substrings of the query. The system searches the paragraph corpus for exact matches of these bi-grams (e.g. Real-time PCR assay $\dot{i}$ ['Real-time PCR', "PCR assay']).</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Fig. 1. Architecture of Complex Information Retrieval System. The query is passed through all three components of the framework. The paragraph retrieval combines results from the phrase, bigram, and keyword searches and retrieves relevant passages from the indexed data. The triplet retrieval retrieves related subject-object-relation pairs from the constructed knowledge graph. The complex question answering system gives an answer to the query along with the semantically retrieved passages from the Multi-hop Dense Retriever (MDR).</p>
<p><em>c) Keyword Search:</em> This method tokenizes the query and searches through the corpus for matches and retrieves them in order of the count of matches in the specific paragraph. We use an Edge n-gram tokenizer with <em>n</em> being set to a minimum value of 4 and a maximum value of 30. The similarity function we use in this method is Okapi BM25 [5].</p>
<p><em>Re-ranking the results:</em> To re-rank the retrieved results based on relevance to the query, we use a MiniLM cross-encoder [29] trained on MS MARCO [30] is used. This model outputs a relevancy score between 0 and 1 for every paragraph paired with the query. The order is decided based on this score with 1 being the highest.</p>
<p><em>Retrieved Paragraphs:</em> The results list consists of a predefined number of paragraphs (<em>r</em>). The passages are retrieved using phrase, bi-gram, and keyword search, in the respective order. This ordering is based on descending precision for individual mechanisms. We combine these passages with the passages retrieved using semantic search, from the retriever of the complex QA system. The retrieval process continues until the length of the results list is less than <em>r</em> (e.g. <em>r</em>=20).</p>
<p><em>2) Triplet Retrieval:</em> To retrieve the most relevant triplets for the query from our large knowledge graph we need the triplet retrieval system. This methodology retrieves triplets (subject-relation-object) which are constructed using the Knowledge Synthesis pipeline (Section III.A) for all the CORD-19 research papers. An additional feature of faceted refinement is added on top to refine the results further by specifying values for different facets. We consider the subject and object types and subtypes as facets and join multiple such facets using a boolean AND condition to filter the retrieved results.</p>
<p><em>a) Triplet Index Construction:</em> While indexing the data into the ElasticServer we use the following custom settings and analyzer for preprocessing the raw JSON data:-</p>
<p>1) Tokenize the documents using the Edge n_gram method.
2) Filter the tokens to lowercase and ASCII folding.</p>
<p><em>b) Retrieval:</em> The triplet retrieval component consists of the same similarity functions and search mechanisms used before viz. phrase search, bi-gram search, and keyword search. The results here consist of a list of triplets each containing subject, relation, and object. Additionally, we utilize triplet metadata like aliases, types, subtypes, descriptions, etc. Higher weightage is given to the subject, object, and relation triplet as compared to the metadata. Here, the weights can be manually tuned or trained.</p>
<p><em>c) Faceted Refinement:</em> Faceted refinement is employed to assist researchers to refine the information retrieved using the facet fields as shown in Fig.3. Subject and object types and subtypes are considered facets. Multiple facets are joined together using a boolean AND condition filtering the retrieved results.</p>
<p><em>d) Knowledge Graph Querying:</em> We also store our knowledge graph in the Neo4j graph database AuraDB with a particular schema to run structured queries on top of it for retrieving triplets and subgraphs, using CypherQL [31].</p>
<table>
<thead>
<tr>
<th>virus found in rhinolophus bats</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Paragraph Retrieval</td>
<td>Triplet Retrieval</td>
<td></td>
</tr>
<tr>
<td>The discovery of SARS-related CoVs in Kenyan bats adds to the diversity and geographic range of CoVs in Rhinolophus bats.</td>
<td>Subject: rhinolophus bats Relation: harbor Object: wide diversity of covs</td>
<td></td>
</tr>
<tr>
<td>Our long-term surveillances suggest that Rhinolophus bats seem to harbor a wide diversity of CoVs.</td>
<td>Subject: Yan Zhu Relation: Authored Object: Characterization of a New Member of Alphacoronavirus with Unique Genomic Features in Rhinolophus Bats</td>
<td></td>
</tr>
<tr>
<td>Semantic Search</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Global Epidemiology of Bat Coronaviruses</td>
<td></td>
<td></td>
</tr>
<tr>
<td>However, there are not sufficient data to establish the prevalence of SARS-like CoVs in different bat host species, especially the species under the genus Rhinolophus. Interestingly, geographical factor does contribute to the diversity of SARS-like CoVs.</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Bat Coronaviruses in China</td>
<td></td>
<td></td>
</tr>
<tr>
<td>It was strongly suggested that SARS-CoV most likely originated from Yunnan Rhinolophus bats via recombination events among existing SARSr-CoVs. These studies revealed that various SARSr-CoVs capable of using human ACE2 are still circulating among bats.</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Fig. 2. Results from Complex Information Retrieval Framework for phrase. The paragraph retrieval retrieves passages relevant to the detection of rhinolophus bats. The triplet retrieval results subject-relation-object pairs from the knowledge graph. They include entity-relation-entity triplets from the passages and metadata triplets like document-reference-documents. The semantic search results contain passages retrieved from Multihop Dense Retriever (MDR). As the query is a phrase, there is no response from the question-answering pipeline.
3) Complex Question Answering: The Complex Question Answering system can handle factoid questions, e.g. "Where was coronavirus first discovered?" as well as multi-hop questions which require going through multiple passages to answer the question, e.g. "What bats are the main reservoir of the virus which is transmitted to humans via ACE2 receptor?". We split the passages from COVID-19 related documents into a maximum length of 300 tokens. Then, we pass these fixed length passages through a transformer encoder to generate dense embeddings for each passage. We store these embeddings in a dense index for further retrieval.
a) Retriever: The retriever searches through the dense index of CORD-19 documents and retrieves passages relevant to the query. To deal with multi-hop questions, we make use of the Multi-hop Dense Retriever (MDR) [9], which is an iterative retriever that uses a single RoBERTa-base model [32] to encode queries and passages into the same vector space. It is trained to iteratively search and retrieve relevant documents from the database using Facebook AI Similarity Search (FAISS) [33]. We have set the number of iterations to 2 in our system, but it is tunable. MDR retrieves two passages, related to each other based on reasoning paths or information about the entities in question, constituting one chain of retrieved contexts. Top-k such chains are retrieved based on their semantic similarity scores. The chains are then sorted based on the combined similarity score of the hops and further re-rank the retrieved passages using the MiniLM crossencoder. Then we send the passages to the reader models to generate answers. We also merge these semantically retrieved
results from the MDR with the results from paragraph retrieval (Section III.B.1).
b) Reader: The reader is responsible for providing an answer given a context. We use two readers in our framework: Extractive reader and Generative reader. Extractive readers extract continuous answer spans from the retrieved passage. In contrast, generative readers are capable of generating answers even though they may not find them in the context provided. For extractive QA we use the RoBERTa model. This model for question answering takes the question tokens and context tokens as inputs and predicts the answer start and end tokens. For generative reader we use the Fusion-in-decoder (FiD) [34].</p>
<h2>IV. EXPERIMENTS</h2>
<h2>A. Dataset</h2>
<p>CORD-19 is a corpus of academic papers about COVID-19 and related coronavirus research, curated and maintained by the Allen Institute for AI. The dataset has grown to index over 1 M papers and includes full-text content for nearly 370K papers. Documents from CORD-19 are indexed and information retrieval is done on top of this index. The reader models are fine-tuned on the MRQA [35] dataset that contains preprocessed subsets of other domain-related datasets, making it a more generalized and suitable benchmark. The reader is also fine-tuned on Covid-QA [36], a medical question answering dataset around COVID-19.</p>
<p>| How many species exist of the mammals that are the main reservoir of coronaviruses? | | | | :--: | :--: | :--: | :--: | :--: | | Paragraph Retrieval | Triplet Retrieval | | High species diversity (about 1,150 in the world), high mobility and the fact that they represent a source of emerging infections for humans make bats one of the most epidemiologically relevant group of mammals to study disease ecology. | Subject: Isolation and characterization of a bat SARS-like coronavirus that uses the ACE2 receptor Relation: References Object: Detection of Novel SARS Coronaviruses in Bats | | Bats are the second largest order of mammals, comprising more than 1200 different species | Subject: alpha-coronaviruses Relation: may be derived from Object: bat coronaviruses | | Complex Question Answering | | QA Response: 1200 | | Replication of MERS and SARS coronaviruses in bat cells offers insights to their ancestral origins Coronaviruses(CoVs) are important pathogens in animals and humans, responsible for a variety of respiratory, hepatic, and neurological diseases. Bats are an important reservoir of alpha coronaviruses and beta coronaviruses, which may jump to other species. | | | | | New Adenovirus Groups in Western Palaearctic Bats Bats are the second largest order of mammals, comprising more than $\mathbf{1 2 0 0}$ different species. Their high vagility and the organization typically in social groups predispose them to infection and viral dissemination. | | | |</p>
<p>Fig. 3. Results from Complex Information Retrieval Framework for a multi-hop question. The paragraph retrieval retrieves passages relevant to the question. The triplet retrieval results subject-relation-object pairs from the knowledge graph. They include entity-relation-entity triplets from the passages and metadata triplets like document-reference-documents. The complex question answering system first retrieves a passage that talks about the main reservoir of coronavirus i.e bat and then retrieves a passage that talks about the number of species of bats.</p>
<h2>B. Training</h2>
<p>The extractive reader is a RoBERTa-base model, already pre-trained on WikiMultiHop. We initially fine-tune it on a generalized dataset, MRQA, and then fine-tune it further on Covid-QA for two epochs to learn the biomedical context. To avoid losing important information, we split the documents present in the CORD-19 dataset into chunks of size C, such that each chunk contains strides (overlap) of size S with the previous chunk. We make sure that C is less than 512, as most transformer models cannot process tokens more than 512 and S is set as 128 to overlap optimal information. The generative reader is the Fusion-in-Decoder model, with T5-base architecture, already pre-trained on TriviaQA [37]. We fine-tune FiD on MRQA and then on Covid-QA, for a total of 45000 steps with a batch size of 8 .</p>
<h2>C. Results</h2>
<p>We evaluate our framework qualitatively on the CORD-19 dataset. We use two kinds of queries to test the performance of various components in our framework. First, for the phrase" virus found in rhinolophus bats", we get a list of passages from paragraph retriever and multi-hop dense retriever along with multiple triplets that talk about rhinolophus bats (as shown in Fig.2). In case of a complex question like-"How many species exist of the mammals that are the main reservoir of coronaviruses?", the complex QA system reasons over the passages retrieved by our multi-hop retriever and the reader gives us the correct answer. It first retrieves a passage that talks about the main reservoir of coronavirus i.e, bats, followed by a passage that talks about the number of species of bats (1200), which can be seen in Fig.3. We also observe that our passage retrieval mechanism retrieves highly relevant passages. They contain the keywords in the query and are contextually similar to the query asked. The triplet retrieval also retrieves the best set of triplets related to the query. Overall our system can provide the user with the most relevant information to the query asked using lexical as well semantic retrievers unlike similar information extraction systems around COVID19, such as [19] that uses only BM25 for retrieval and not an iterative retriever like ours that also enables our question answering system to reason over more than one document and provide the answer. [20] supports keyword and entity search, it fails to accommodate phrase search, bi-gram search and semantic search like our search system. Both of these systems do not perform triplet retrieval on knowledge graphs.</p>
<h2>D. Evaluation</h2>
<p>We evaluate our framework on related open-source datasets due to the unavailability of labeled data for CORD-19. We evaluate the paragraph retrieval pipeline on another COVID19 related dataset, TREC-COVID [38]. Here we use Precision and NDCG as the metric. NDCG is the ratio of the Discounted Cumulative Gain (DCG) of a recommended and ideal order. It is evident that phrase search with MiniLM-L-6-v-2 re-ranker yields better results when compared to results without reranking, as shown in Fig. 4. We evaluate the performance of the reader models on the MRQA-dev data split by calculating the exact match and the</p>
<p>F1 scores for all subsets of the dataset. We see that the model’s performance varies massively depending on the kind of data as seen in Table.1.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Fig. 4. Evaluation of Paragraph Retrieval on TREC-COVID. Phrase with re- ranker (denoted by blue) outperforms phrase without re-ranker (denoted by red) across different top-k comparisons in both Precision and NDCG metrics.</p>
<p>TABLE I EVALUATION OF READERS ON MRQA-DEV SUBSETS</p>
<table>
<thead>
<tr>
<th>Subset</th>
<th>No. of Questions</th>
<th>Extractive Reader</th>
<th></th>
<th>Generative Reader</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td>Exact Match (%)</td>
<td>F1 score (%)</td>
<td>Exact Match (%)</td>
</tr>
<tr>
<td>SQUAD</td>
<td>10507</td>
<td>83.76</td>
<td>90.48</td>
<td>69.8</td>
</tr>
<tr>
<td>Trivia-QA-web</td>
<td>7785</td>
<td>12.76</td>
<td>14.24</td>
<td>45.7</td>
</tr>
<tr>
<td>Search QA</td>
<td>16980</td>
<td>10.2</td>
<td>10.94</td>
<td>60.4</td>
</tr>
<tr>
<td>Hotpot QA</td>
<td>5901</td>
<td>60.78</td>
<td>76.74</td>
<td>41.5</td>
</tr>
<tr>
<td>NQ Short</td>
<td>12836</td>
<td>64.78</td>
<td>76.74</td>
<td>48.9</td>
</tr>
<tr>
<td>News QA</td>
<td>4212</td>
<td>52.84</td>
<td>66.62</td>
<td>36.2</td>
</tr>
</tbody>
</table>
<p>V. CONCLUSION</p>
<p>In this paper, we presented a complex information retrieval framework built on COVID-19 related biomedical documents that can perform both lexical and semantic search and retrieve paragraphs along with a knowledge graph consisting of triplets extracted from unstructured text. We also use faceted refinement to filter the results. We demonstrate our complex QA system, which gives the researcher a pinpoint answer to the query asked. We find that this framework makes it easier for the researcher to search for specific information from massive corpora. In our future work, we plan to add functionalities like query expansion and query intent classification along with scalable semantic retrieval on top of the knowledge graph.</p>
<p>ACKNOWLEDGMENT</p>
<p>We thank Varun V, Advaith Shankar, Nim Sherpa and Saisubramaniam Gopalakrishnan for their assistance with figures, and useful suggestions that helped improve the manuscript.</p>
<p>REFERENCES</p>
<p>[1] S. Saxena, R. Sangani, S. Prasad, S. Kumar, M. Athale, R. Awhad, and V. Vaddina, “Large-scale knowledge synthesis and complex information retrieval from biomedical documents,” in <em>2022 IEEE International Conference on Big Data (Big Data)</em>, 2022, pp. 2364–2369.</p>
<p>[2] S. Sakji, A. D. Dibad, I. Kergourlay, S. Darmoni, and M. Joubert, “Information retrieval in context using various health terminologies,” in <em>2009 Third International Conference on Research Challenges in Information Science</em>. IEEE, 2009, pp. 453–458.</p>
<p>[3] M. Al-Qahtani, S. Katsigiannis, and N. Ramzan, “Information retrieval from electronic health records,” <em>Engineering and Technology for Healthcare</em>, p. 117, 2020.</p>
<p>[4] W. Wemming, C. Shihong, C. Xi, and Z. Fan, “Knowledge-based document retrieval in medical domain,” in <em>2008 International Symposium on Knowledge Acquisition and Modeling</em>. IEEE, 2008, pp. 226–230.</p>
<p>[5] K. S. Jones, S. Walker, and S. E. Robertson, “A probabilistic model of information retrieval: development and comparative experiments: Part 2,” <em>Information processing &amp; management</em>, vol. 36, no. 6, pp. 809–840, 2000.</p>
<p>[6] J. Pennington, R. Socher, and C. D. Manning, “Glove: Global vectors for word representation,” in <em>Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</em>, 2014, pp. 1532–1543.</p>
<p>[7] T. Mikolov, K. Chen, G. Corrado, and J. Dean, “Efficient estimation of word representations in vector space,” <em>arXiv preprint arXiv:1301.3781</em>, 2013.</p>
<p>[8] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training of deep bidirectional transformers for language understanding,” <em>arXiv preprint arXiv:1810.04805</em>, 2018.</p>
<p>[9] W. Xiong, X. L. Li, S. Iyer, J. Du, P. Lewis, W. Y. Wang, Y. Mehdad, W.-t. Yih, S. Riedel, D. Kiela <em>et al.</em>, “Answering complex open-domain questions with multi-hop dense retrieval,” <em>arXiv preprint arXiv:2009.12756</em>, 2020.</p>
<p>[10] R. Jackson, I. Kartoglu, C. Stringer, G. Gorrell, A. Roberts, X. Song, H. Wu, A. Agrawal, K. Lui, T. Groza, D. Lewsley, D. Northwood, A. Folarin, R. Stewart, and R. Dobson, “Cogstack - experiences of deploying integrated information retrieval and extraction services in a large national health service foundation trust hospital,” <em>BMC Medical Informatics and Decision Making</em>, vol. 18, 06 2018.</p>
<p>[11] S. Sengan, G. Kamalam, J. Vellingiri, J. Gopal, P. Velayutham, V. Subramaniyaswamy <em>et al.</em>, “Medical information retrieval systems for e-health care records using fuzzy based machine learning model,” <em>Microprocessors and Microsystems</em>, p. 103344, 2020.</p>
<p>[12] Y. Wang, S. Mehrabi, M. R. Mojarad, D. Li, and H. Liu, “Retrieval of semantically similar healthcare questions in healthcare forums,” in <em>2015 International Conference on Healthcare Informatics</em>. IEEE, 2015, pp. 517–518.</p>
<p>[13] M. Kumari and P. Ahlawat, “Intelligent information retrieval for reducing missed cancer and improving the healthcare system,” <em>International Journal of Information Retrieval Research (IJIRR)</em>, vol. 12, no. 1, pp. 1–25, 2022.</p>
<p>[14] C. Shorten, T. M. Khoshgoftaar, and B. Furht, “Deep learning applications for covid-19,” <em>Journal of big Data</em>, vol. 8, no. 1, pp. 1–54, 2021.</p>
<p>[15] C. Wise, V. N. Ioannidis, M. R. Calvo, X. Song, G. Price, N. Kulkarni, R. Brand, P. Bhatia, and G. Karypis, “Covid-19 knowledge graph: accelerating information retrieval and discovery for scientific literature,” <em>arXiv preprint arXiv:2007.12731</em>, 2020.</p>
<p>[16] A. Esteva, A. Kale, R. Paulus, K. Hashimoto, W. Yin, D. Radev, and R. Socher, “Covid-19 information retrieval with deep-learning based semantic search, question answering, and abstractive summarization,” <em>NPJ digital medicine</em>, vol. 4, no. 1, pp. 1–9, 2021.</p>
<p>[17] Q. Jin, Z. Yuan, G. Xiong, Q. Yu, H. Ying, C. Tan, M. Chen, S. Huang, X. Liu, and S. Yu, "Biomedical question answering: A survey of approaches and challenges," ACM Computing Surveys (CSUR), vol. 55, no. 2, pp. 1-36, 2022.
[18] Y. Lan, G. He, J. Jiang, J. Jiang, W. X. Zhao, and J.-R. Wen, "Complex knowledge base question answering: A survey," arXiv preprint arXiv:2108.06688, 2021.
[19] D. Su, Y. Xu, T. Yu, F. B. Siddique, E. J. Barezi, and P. Fung, "Caire-covid: A question answering and query-focused multi-document summarization system for covid-19 scholarly information management," arXiv preprint arXiv:2005.03975, 2020.
[20] H. Ambavi, K. Vaishnaw, U. Vyas, A. Tiwari, and M. Singh, "Covidexplorer: A multi-faceted ai-based search and visualization engine for covid-19 information," in Proceedings of the 29th ACM International Conference on Information \&amp; Knowledge Management, 2020, pp. 33653368.
[21] N. Reimers and I. Gurevych, "Sentence-bert: Sentence embeddings using siamese bert-networks," arXiv preprint arXiv:1908.10084, 2019.
[22] F. Zhu, W. Lei, C. Wang, J. Zheng, S. Poria, and T.-S. Chua, "Retrieving and reading: A comprehensive survey on open-domain question answering," arXiv preprint arXiv:2101.00774, 2021.
[23] P. Qi, H. Lee, O. Sido, C. D. Manning et al., "Answering opendomain questions of varying reasoning steps from text," arXiv preprint arXiv:2010.12527, 2020.
[24] A. Saxena, A. Tripathi, and P. Talukdar, "Improving multi-hop question answering over knowledge graphs using knowledge base embeddings," in Proceedings of the 58th annual meeting of the association for computational linguistics, 2020, pp. 4498-4507.
[25] Z. Wang, L. Li, D. D. Zeng, and Y. Chen, "Attention-based multi-hop reasoning for knowledge graph," in 2018 IEEE International Conference on Intelligence and Security Informatics (ISI). IEEE, 2018, pp. 211213.
[26] L. L. Wang, K. Lo, Y. Chandrasekhar, R. Reas, J. Yang, D. Eide, K. Funk, R. Kinney, Z. Liu, W. Merrill et al., "Cord-19: The covid19 open research dataset," ArXiv, 2020.
[27] K. Kolluru, V. Adlakha, S. Aggarwal, S. Chakrabarti et al., "Openie6: Iterative grid labeling and coordination analysis for open information extraction," arXiv preprint arXiv:2010.03147, 2020.
[28] P. Norvig, "How to write a spelling corrector," De: http://norvig. com/spell-correct. html, 2007.
[29] W. Wang, F. Wei, L. Dong, H. Bao, N. Yang, and M. Zhou, "Minilm: Deep self-attention distillation for task-agnostic compression of pretrained transformers," Advances in Neural Information Processing Systems, vol. 33, pp. 5776-5788, 2020.
[30] T. Nguyen, M. Rosenberg, X. Song, J. Gao, S. Tiwary, R. Majumder, and L. Deng, "Ms marco: A human generated machine reading comprehension dataset," in CoCo@ NIPs, 2016.
[31] N. Francis, A. Green, P. Guagliardo, L. Libkin, T. Lindaaker, V. Marsault, S. Plantikow, M. Rydberg, P. Selmer, and A. Taylor, "Cypher: An evolving query language for property graphs," in Proceedings of the 2018 International Conference on Management of Data, ser. SIGMOD '18. New York, NY, USA: Association for Computing Machinery, 2018, p. 1433-1445. [Online]. Available: https://doi.org/10.1145/3183713.3190657
[32] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer, and V. Stoyanov, "Roberta: A robustly optimized bert pretraining approach," arXiv preprint arXiv:1907.11692, 2019.
[33] J. Johnson, M. Douze, and H. Jégou, "Billion-scale similarity search with gpus," IEEE Transactions on Big Data, vol. 7, no. 3, pp. 535-547, 2019.
[34] G. Izacard and E. Grave, "Leveraging passage retrieval with generative models for open domain question answering," arXiv preprint arXiv:2007.01282, 2020.
[35] A. Fisch, A. Talmor, R. Jia, M. Seo, E. Choi, and D. Chen, "Mrqa 2019 shared task: Evaluating generalization in reading comprehension," arXiv preprint arXiv:1910.09753, 2019.
[36] T. Möller, A. Reina, R. Jayakumar, and M. Pietsch, "Covid-qa: A question answering dataset for covid-19," in Proceedings of the 1st Workshop on NLP for COVID-19 at ACL 2020, 2020.
[37] M. Joshi, E. Choi, D. S. Weld, and L. Zettlemoyer, "Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension," arXiv preprint arXiv:1705.03551, 2017.
[38] E. Voorhees, T. Alam, S. Bedrick, D. Demner-Fushman, W. R. Hersh, K. Lo, K. Roberts, I. Soboroff, and L. L. Wang, "Trec-covid: construct-
ing a pandemic information retrieval test collection," in ACM SIGIR Forum, vol. 54, no. 1. ACM New York, NY, USA, 2021, pp. 1-12.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<ul>
<li>Equal contribution, * Corresponding author</li>
</ul>
<p>Shorter version of this work is published at IEEE BigData 2022 Conference, held at Osaka, Japan [1] DOI:10.1109/BigData55660.2022.10020725&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>