<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9295 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9295</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9295</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-162.html">extraction-schema-162</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-270703007</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2406.15781v1.pdf" target="_blank">DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models</a></p>
                <p><strong>Paper Abstract:</strong> Detecting anomalies in business processes is crucial for ensuring operational success. While many existing methods rely on statistical frequency to detect anomalies, it's important to note that infrequent behavior doesn't necessarily imply undesirability. To address this challenge, detecting anomalies from a semantic viewpoint proves to be a more effective approach. However, current semantic anomaly detection methods treat a trace (i.e., process instance) as multiple event pairs, disrupting long-distance dependencies. In this paper, we introduce DABL, a novel approach for detecting semantic anomalies in business processes using large language models (LLMs). We collect 143,137 real-world process models from various domains. By generating normal traces through the playout of these process models and simulating both ordering and exclusion anomalies, we fine-tune Llama 2 using the resulting log. Through extensive experiments, we demonstrate that DABL surpasses existing state-of-the-art semantic anomaly detection methods in terms of both generalization ability and learning of given processes. Users can directly apply DABL to detect semantic anomalies in their own datasets without the need for additional training. Furthermore, DABL offers the capability to interpret the causes of anomalies in natural language, providing valuable insights into the detected anomalies.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9295.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9295.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DABL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Detecting semantic Anomalies in Business processes using Large language models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A fine-tuned conversational LLM that detects semantic anomalies in business process traces (sequences of activity names) and explains causes in natural language; trained on synthetic anomalies generated from 143,137 real-world process models and fine-tuned from Llama 2-Chat 13B via QLoRA.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama 2-Chat 13B (fine-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>transformer-based large language model (chat/decoder+instruction-tuning style)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>13B</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>categorical sequences / ordered lists of activity names (process traces)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>business process event logs spanning many domains (order/request handling, software engineering, healthcare) and real-world logs (travel permit, road traffic fines)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>semantic ordering anomalies (skip, insert, rework, early, late) and exclusion anomalies (mutually exclusive activities executed together)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Generate normal traces by playout of BPMN process models and synthesize ordering/exclusion anomalies; convert traces into Q&A prompt pairs (ask if trace is normal/anomalous and request a natural-language cause) and fine-tune Llama 2-Chat 13B using QLoRA with Adam (2 epochs, lr=5e-5, batch=64) so the LLM learns to (i) classify traces and (ii) provide interpretable explanations.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>SEM (BERT-based semantic method), SENSE-BERT, SENSE-SVM (semantic event-pair methods); statistical and conformance-checking methods noted as inapplicable across many processes in the mixed dataset</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>precision, recall, F1-score, accuracy for anomaly detection; ROUGE-2 and ROUGE-L for quality of natural-language explanations</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Test D1 (unseen processes): Precision 94.06%, Recall 89.79%, F1 91.88%, Accuracy 92.39%. Test D2 (seen processes, unseen anomalies): Precision 98.12%, Recall 95.64%, F1 96.87%, Accuracy 97.03%. Explanation quality: D1 ROUGE-2 F1 ≈ 74.32%, ROUGE-L F1 ≈ 76.02%; D2 ROUGE-2 F1 ≈ 84.54%, ROUGE-L F1 ≈ 86.56%. (Numbers taken directly from paper tables.)</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Outperforms state-of-the-art semantic methods (SEM, SENSE-SVM, SENSE-BERT) on both generalization (D1) and learning given processes (D2). Example: on D2 DABL F1=96.87% vs best comparative SENSE-BERT F1=75.08% (improvement ~21.79 percentage points); accuracy improved from 80.28% to 97.03% (~16.75 points).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Paper notes several caveats: (1) existing off-the-shelf LLMs (GPT-3.5, GPT-4, GLM-3, vanilla Llama 2) lack prior domain knowledge and often give non-definitive answers in zero-shot—hence need for fine-tuning; (2) synthesized anomalies can sometimes coincide with actually allowed traces and must be filtered against the model's allowed trace set; (3) interpretation scoring (ROUGE) may underestimate quality because multiple valid natural-language explanations exist but only a single reference was used; (4) statistical and conformance methods are inapplicable on datasets containing many different processes/variants, limiting cross-comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Incorporating the entire trace into a single prompt lets the LLM capture long-distance dependencies that event-pair methods miss; training on a very large, diverse collection of process models (and synthetic anomalies) yields strong zero-shot generalization to unseen processes; the fine-tuned LLM can both detect anomalies and produce human-readable causes, aiding interpretability and remediation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9295.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9295.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Llama-2-Chat-13B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Llama 2 Chat 13B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source 13-billion-parameter conversational large language model used as the base model for fine-tuning in DABL.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama 2-Chat 13B</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>transformer-based conversational LLM</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>13B</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>categorical sequences of activity names when applied in this work</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>business process traces (synthetic and real-world logs)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>ordering and exclusion semantic anomalies (when fine-tuned as DABL)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Used as the foundation model and fine-tuned via QLoRA on QA-style trace/anomaly data to create DABL.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Performance reported as part of DABL after fine-tuning (see DABL entry).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Vanilla Llama 2 (zero-shot) performed poorly on definitive anomaly classification compared to the fine-tuned DABL; fine-tuning yields large improvements.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Out-of-the-box Llama 2 without domain fine-tuning provides non-definitive answers on process traces, demonstrating limited domain knowledge for this task.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Fine-tuning an open-source LLM on synthetically generated, diverse process traces is an effective way to adapt general LLMs to sequence-anomaly detection tasks in structured categorical lists.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9295.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9295.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>QLoRA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>QLoRA (Efficient fine-tuning of quantized LLMs)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An efficient low-memory fine-tuning method used to fine-tune Llama 2-Chat 13B for DABL, enabling high-capacity model tuning on constrained GPU memory.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>QLoRA (method)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>applied to textual prompts consisting of sequences of activity names and associated QA labels</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>business process traces for fine-tuning DABL</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>ordering/exclusion semantic anomalies (as training signal)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Used to efficiently fine-tune the quantized Llama 2-Chat 13B model on the generated Q&A dataset (trace -> normal/anomalous + natural-language cause).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Enables fine-tuning Llama 2-Chat 13B using a single A6000 48GB GPU with batch size 64; specific ablation vs full precision fine-tuning not reported in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Paper does not report QLoRA-specific failure cases; general caveat: efficient fine-tuning reduces resource needs but requires care with hyperparameters.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>QLoRA allowed practical fine-tuning of a 13B conversational LLM to perform sequence-level anomaly detection and explanation on a standard GPU.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9295.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9295.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Other off-the-shelf LLMs (GPT-3.5/GPT-4/GLM-3/Llama 2)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-3.5, GPT-4, GLM-3, Llama 2 (off-the-shelf, zero-shot/few-shot usage)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Large pretrained LLMs evaluated qualitatively in the paper; they generally provide non-definitive answers on whether a business process trace is anomalous without domain fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5, GPT-4, GLM-3, Llama 2 (vanilla)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>transformer-based LLMs</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>categorical sequences / traces (used in qualitative examples)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>business process traces</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>semantic anomalies in sequences (ordering/exclusion) in zero-shot regime</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Zero-shot/few-shot prompting applied in qualitative comparisons; model responses were compared to DABL's outputs on example traces and anomalies.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>DABL (fine-tuned Llama 2-Chat 13B) used as the improved method in comparison</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>qualitative judgment (no numeric scores reported for these off-the-shelf LLMs in the paper apart from illustrative examples)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Paper reports these off-the-shelf LLMs 'often struggle to provide specific answers' and are less decisive than DABL on whether traces are anomalous and on giving precise causes.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>DABL (fine-tuned) provided more decisive anomaly labels and clear natural-language explanations compared to these zero-shot LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Lack of prior domain knowledge leads to ambiguous or non-definitive outputs in zero-shot settings; they may give plausible but non-authoritative judgments without fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Demonstrates that instruction-following ability alone is insufficient for domain-specific sequence-anomaly detection—domain fine-tuning on structured trace Q&A data markedly improves performance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9295.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e9295.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SENSE-BERT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SENSE (BERT-based variant for semantic anomaly detection)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A semantic anomaly detection approach that extends BERT with a classification layer to decide whether an input event pair (event A eventually follows event B) is anomalous; used as a baseline in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BERT (fine-tuned variant within SENSE)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>transformer encoder (BERT) with classification head</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>event pairs extracted from traces (pairwise relations), i.e., truncated pairs rather than whole sequences</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>business process event logs</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>semantic anomalous event pairs (event-pair level anomalies)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Treat traces as event-pairs in eventually-follow relation, fine-tune BERT for two-class classification (normal vs anomalous pair), classify trace as anomalous if any pair is anomalous.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared against DABL and SENSE-SVM and SEM</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>precision, recall, F1, accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>On D1: Precision 48.17%, Recall 97.74%, F1 64.53%, Accuracy 48.47%. On D2: Precision 93.16%, Recall 62.88%, F1 75.08%, Accuracy 80.28% (values taken from paper tables).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>SENSE-BERT shows very high recall but low precision (on D1) implying many false positives; DABL achieves a better balance and higher overall F1 and accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>By decomposing traces into event pairs, SENSE-BERT breaks long-distance dependencies and can generate many false alarms or miss contextual anomalies that require whole-trace understanding.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Event-pair decomposition yields models sensitive to certain pairwise anomalies but loses global sequence structure; improving long-distance context capture is crucial for semantic anomaly detection in traces.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9295.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e9295.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SENSE-SVM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SENSE (SVM-based variant for semantic anomaly detection)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An SVM-based semantic anomaly detector that vectorizes event pairs using GloVe embeddings and classifies pair anomalies with SVM; used as a baseline in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>SVM with GloVe embeddings (within SENSE-SVM)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>classical SVM classifier on fixed embeddings</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>event pairs from traces (pairwise analysis)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>business process traces</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>semantic anomalous event pairs</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Transform event pair text into GloVe embedding vectors and train an SVM to classify pair as normal or anomalous; a trace is anomalous if any pair is anomalous.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared against DABL, SENSE-BERT, SEM</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>precision, recall, F1, accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>On D1: Precision 87.95%, Recall 51.12%, F1 62.20%, Accuracy 52.50%. On D2: Precision 90.28%, Recall 28.64%, F1 43.49%, Accuracy 64.82% (from paper tables).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>High precision but low recall (misses many anomalies); DABL achieves much higher recall and balanced F1/accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Limited sensitivity to anomalies (low recall) and inability to capture long-range dependencies due to pairwise decomposition.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Classical embedding+SVM pipeline can achieve good precision but suffers from low coverage of anomaly types when global sequence context matters.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9295.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e9295.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SEM (van der Aa et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SEM: Natural language-based detection of semantic execution anomalies (BERT-based parsing + knowledge base)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A semantic anomaly detection approach that fine-tunes BERT to parse activity names into action and business object, then checks assertions (from VerbOcean or abstract model) to detect semantic violations; used as a baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BERT (fine-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>transformer encoder</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>parsed activity names and derived assertions (event-pair / asserted relations)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>business process traces</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>semantic violations (assertion breaches, event-pair related semantic anomalies)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Parse activity names to extract action/object, build a knowledge base of assertions about relations using VerbOcean or abstract model, detect anomalies where traces violate asserted relations.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared against DABL and SENSE approaches</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>precision, recall, F1, accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>On D1: Precision 48.67%, Recall 46.84%, F1 47.72%, Accuracy 50.81%. On D2: Precision 71.91%, Recall 48.63%, F1 58.02%, Accuracy 66.75% (from paper tables).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>DABL substantially outperforms SEM in both generalization and learning given processes.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Relies on extracted assertions and event-pair reasoning, which can break long-distance dependencies and yield limited accuracy where whole-trace context and long-range order matter.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Semantic assertion checking can catch some rule-based semantic anomalies but is limited when assertions are incomplete or when anomalies require whole-trace interpretation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9295.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e9295.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Other LLM-based anomaly works (AnomalyGPT, Myriad, LLMAD, LogGPT, SheepDog, Sarda et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Collection of recent works that apply large language models (or LLM pipelines) to anomaly detection in various modalities</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Related works cited that apply LLMs or LLM-centered pipelines to anomaly detection tasks (industrial image/anomaly detection, time series, system logs, microservices), mentioned in the paper's related work to contextualize DABL.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>AnomalyGPT, Myriad, LLMAD, LogGPT, SheepDog, etc. (various LLM-centered methods)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>varies (vision-language LLMs, LLM + retrieval, LLM prompting pipelines)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>various: images (industrial), time series segments, system logs, microservice metrics, textual descriptions—i.e., sequences or structured logs in different modalities</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>industrial inspection, time-series monitoring, system logs, microservice anomaly detection</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>industrial visual anomalies, time-series anomalies, log anomalies, microservice anomalies (domain-specific)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Examples include combining vision encoders with LLMs for image anomaly detection (AnomalyGPT, Myriad), retrieval-augmented few-shot LLM anomaly detection for time series (LLMAD), prompt engineering / preprocessing pipelines for log anomaly detection (LogGPT, Egersdoerfer et al.), and LLM-driven anomaly remediation pipelines (Sarda et al.).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>These works demonstrate feasibility of LLMs in other anomaly domains; the paper notes that application to business process trace semantic anomalies was unexplored prior to DABL.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Modalities and data structures differ (images vs. sequences); many approaches require modality-specific encoders, retrieval components, or are limited by domain knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Paper places DABL as a complementary direction that focuses specifically on structured categorical sequences (process traces) and on interpretable natural-language causes, an area less explored by existing LLM anomaly works.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Anomalygpt: Detecting industrial anomalies using large vision-language models. <em>(Rating: 2)</em></li>
                <li>Myriad: Large multimodal model by applying vision experts for industrial anomaly detection. <em>(Rating: 2)</em></li>
                <li>Large Language Models can Deliver Accurate and Interpretable Time Series Anomaly Detection. <em>(Rating: 2)</em></li>
                <li>Loggpt: Exploring chatgpt for log-based anomaly detection. <em>(Rating: 2)</em></li>
                <li>Semantic anomaly detection with large language models. <em>(Rating: 1)</em></li>
                <li>Early exploration of using chatgpt for log-based anomaly detection on parallel file systems logs. <em>(Rating: 1)</em></li>
                <li>Adarma auto-detection and auto-remediation of microservice anomalies by leveraging large language models. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9295",
    "paper_id": "paper-270703007",
    "extraction_schema_id": "extraction-schema-162",
    "extracted_data": [
        {
            "name_short": "DABL",
            "name_full": "Detecting semantic Anomalies in Business processes using Large language models",
            "brief_description": "A fine-tuned conversational LLM that detects semantic anomalies in business process traces (sequences of activity names) and explains causes in natural language; trained on synthetic anomalies generated from 143,137 real-world process models and fine-tuned from Llama 2-Chat 13B via QLoRA.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Llama 2-Chat 13B (fine-tuned)",
            "model_type": "transformer-based large language model (chat/decoder+instruction-tuning style)",
            "model_size": "13B",
            "data_type": "categorical sequences / ordered lists of activity names (process traces)",
            "data_domain": "business process event logs spanning many domains (order/request handling, software engineering, healthcare) and real-world logs (travel permit, road traffic fines)",
            "anomaly_type": "semantic ordering anomalies (skip, insert, rework, early, late) and exclusion anomalies (mutually exclusive activities executed together)",
            "method_description": "Generate normal traces by playout of BPMN process models and synthesize ordering/exclusion anomalies; convert traces into Q&A prompt pairs (ask if trace is normal/anomalous and request a natural-language cause) and fine-tune Llama 2-Chat 13B using QLoRA with Adam (2 epochs, lr=5e-5, batch=64) so the LLM learns to (i) classify traces and (ii) provide interpretable explanations.",
            "baseline_methods": "SEM (BERT-based semantic method), SENSE-BERT, SENSE-SVM (semantic event-pair methods); statistical and conformance-checking methods noted as inapplicable across many processes in the mixed dataset",
            "performance_metrics": "precision, recall, F1-score, accuracy for anomaly detection; ROUGE-2 and ROUGE-L for quality of natural-language explanations",
            "performance_results": "Test D1 (unseen processes): Precision 94.06%, Recall 89.79%, F1 91.88%, Accuracy 92.39%. Test D2 (seen processes, unseen anomalies): Precision 98.12%, Recall 95.64%, F1 96.87%, Accuracy 97.03%. Explanation quality: D1 ROUGE-2 F1 ≈ 74.32%, ROUGE-L F1 ≈ 76.02%; D2 ROUGE-2 F1 ≈ 84.54%, ROUGE-L F1 ≈ 86.56%. (Numbers taken directly from paper tables.)",
            "comparison_to_baseline": "Outperforms state-of-the-art semantic methods (SEM, SENSE-SVM, SENSE-BERT) on both generalization (D1) and learning given processes (D2). Example: on D2 DABL F1=96.87% vs best comparative SENSE-BERT F1=75.08% (improvement ~21.79 percentage points); accuracy improved from 80.28% to 97.03% (~16.75 points).",
            "limitations_or_failure_cases": "Paper notes several caveats: (1) existing off-the-shelf LLMs (GPT-3.5, GPT-4, GLM-3, vanilla Llama 2) lack prior domain knowledge and often give non-definitive answers in zero-shot—hence need for fine-tuning; (2) synthesized anomalies can sometimes coincide with actually allowed traces and must be filtered against the model's allowed trace set; (3) interpretation scoring (ROUGE) may underestimate quality because multiple valid natural-language explanations exist but only a single reference was used; (4) statistical and conformance methods are inapplicable on datasets containing many different processes/variants, limiting cross-comparison.",
            "unique_insights": "Incorporating the entire trace into a single prompt lets the LLM capture long-distance dependencies that event-pair methods miss; training on a very large, diverse collection of process models (and synthetic anomalies) yields strong zero-shot generalization to unseen processes; the fine-tuned LLM can both detect anomalies and produce human-readable causes, aiding interpretability and remediation.",
            "uuid": "e9295.0",
            "source_info": {
                "paper_title": "DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Llama-2-Chat-13B",
            "name_full": "Llama 2 Chat 13B",
            "brief_description": "An open-source 13-billion-parameter conversational large language model used as the base model for fine-tuning in DABL.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Llama 2-Chat 13B",
            "model_type": "transformer-based conversational LLM",
            "model_size": "13B",
            "data_type": "categorical sequences of activity names when applied in this work",
            "data_domain": "business process traces (synthetic and real-world logs)",
            "anomaly_type": "ordering and exclusion semantic anomalies (when fine-tuned as DABL)",
            "method_description": "Used as the foundation model and fine-tuned via QLoRA on QA-style trace/anomaly data to create DABL.",
            "baseline_methods": "",
            "performance_metrics": "",
            "performance_results": "Performance reported as part of DABL after fine-tuning (see DABL entry).",
            "comparison_to_baseline": "Vanilla Llama 2 (zero-shot) performed poorly on definitive anomaly classification compared to the fine-tuned DABL; fine-tuning yields large improvements.",
            "limitations_or_failure_cases": "Out-of-the-box Llama 2 without domain fine-tuning provides non-definitive answers on process traces, demonstrating limited domain knowledge for this task.",
            "unique_insights": "Fine-tuning an open-source LLM on synthetically generated, diverse process traces is an effective way to adapt general LLMs to sequence-anomaly detection tasks in structured categorical lists.",
            "uuid": "e9295.1",
            "source_info": {
                "paper_title": "DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "QLoRA",
            "name_full": "QLoRA (Efficient fine-tuning of quantized LLMs)",
            "brief_description": "An efficient low-memory fine-tuning method used to fine-tune Llama 2-Chat 13B for DABL, enabling high-capacity model tuning on constrained GPU memory.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "QLoRA (method)",
            "model_type": null,
            "model_size": null,
            "data_type": "applied to textual prompts consisting of sequences of activity names and associated QA labels",
            "data_domain": "business process traces for fine-tuning DABL",
            "anomaly_type": "ordering/exclusion semantic anomalies (as training signal)",
            "method_description": "Used to efficiently fine-tune the quantized Llama 2-Chat 13B model on the generated Q&A dataset (trace -&gt; normal/anomalous + natural-language cause).",
            "baseline_methods": null,
            "performance_metrics": null,
            "performance_results": "Enables fine-tuning Llama 2-Chat 13B using a single A6000 48GB GPU with batch size 64; specific ablation vs full precision fine-tuning not reported in the paper.",
            "comparison_to_baseline": null,
            "limitations_or_failure_cases": "Paper does not report QLoRA-specific failure cases; general caveat: efficient fine-tuning reduces resource needs but requires care with hyperparameters.",
            "unique_insights": "QLoRA allowed practical fine-tuning of a 13B conversational LLM to perform sequence-level anomaly detection and explanation on a standard GPU.",
            "uuid": "e9295.2",
            "source_info": {
                "paper_title": "DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Other off-the-shelf LLMs (GPT-3.5/GPT-4/GLM-3/Llama 2)",
            "name_full": "GPT-3.5, GPT-4, GLM-3, Llama 2 (off-the-shelf, zero-shot/few-shot usage)",
            "brief_description": "Large pretrained LLMs evaluated qualitatively in the paper; they generally provide non-definitive answers on whether a business process trace is anomalous without domain fine-tuning.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-3.5, GPT-4, GLM-3, Llama 2 (vanilla)",
            "model_type": "transformer-based LLMs",
            "model_size": null,
            "data_type": "categorical sequences / traces (used in qualitative examples)",
            "data_domain": "business process traces",
            "anomaly_type": "semantic anomalies in sequences (ordering/exclusion) in zero-shot regime",
            "method_description": "Zero-shot/few-shot prompting applied in qualitative comparisons; model responses were compared to DABL's outputs on example traces and anomalies.",
            "baseline_methods": "DABL (fine-tuned Llama 2-Chat 13B) used as the improved method in comparison",
            "performance_metrics": "qualitative judgment (no numeric scores reported for these off-the-shelf LLMs in the paper apart from illustrative examples)",
            "performance_results": "Paper reports these off-the-shelf LLMs 'often struggle to provide specific answers' and are less decisive than DABL on whether traces are anomalous and on giving precise causes.",
            "comparison_to_baseline": "DABL (fine-tuned) provided more decisive anomaly labels and clear natural-language explanations compared to these zero-shot LLMs.",
            "limitations_or_failure_cases": "Lack of prior domain knowledge leads to ambiguous or non-definitive outputs in zero-shot settings; they may give plausible but non-authoritative judgments without fine-tuning.",
            "unique_insights": "Demonstrates that instruction-following ability alone is insufficient for domain-specific sequence-anomaly detection—domain fine-tuning on structured trace Q&A data markedly improves performance.",
            "uuid": "e9295.3",
            "source_info": {
                "paper_title": "DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "SENSE-BERT",
            "name_full": "SENSE (BERT-based variant for semantic anomaly detection)",
            "brief_description": "A semantic anomaly detection approach that extends BERT with a classification layer to decide whether an input event pair (event A eventually follows event B) is anomalous; used as a baseline in this paper.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "BERT (fine-tuned variant within SENSE)",
            "model_type": "transformer encoder (BERT) with classification head",
            "model_size": null,
            "data_type": "event pairs extracted from traces (pairwise relations), i.e., truncated pairs rather than whole sequences",
            "data_domain": "business process event logs",
            "anomaly_type": "semantic anomalous event pairs (event-pair level anomalies)",
            "method_description": "Treat traces as event-pairs in eventually-follow relation, fine-tune BERT for two-class classification (normal vs anomalous pair), classify trace as anomalous if any pair is anomalous.",
            "baseline_methods": "Compared against DABL and SENSE-SVM and SEM",
            "performance_metrics": "precision, recall, F1, accuracy",
            "performance_results": "On D1: Precision 48.17%, Recall 97.74%, F1 64.53%, Accuracy 48.47%. On D2: Precision 93.16%, Recall 62.88%, F1 75.08%, Accuracy 80.28% (values taken from paper tables).",
            "comparison_to_baseline": "SENSE-BERT shows very high recall but low precision (on D1) implying many false positives; DABL achieves a better balance and higher overall F1 and accuracy.",
            "limitations_or_failure_cases": "By decomposing traces into event pairs, SENSE-BERT breaks long-distance dependencies and can generate many false alarms or miss contextual anomalies that require whole-trace understanding.",
            "unique_insights": "Event-pair decomposition yields models sensitive to certain pairwise anomalies but loses global sequence structure; improving long-distance context capture is crucial for semantic anomaly detection in traces.",
            "uuid": "e9295.4",
            "source_info": {
                "paper_title": "DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "SENSE-SVM",
            "name_full": "SENSE (SVM-based variant for semantic anomaly detection)",
            "brief_description": "An SVM-based semantic anomaly detector that vectorizes event pairs using GloVe embeddings and classifies pair anomalies with SVM; used as a baseline in this paper.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "SVM with GloVe embeddings (within SENSE-SVM)",
            "model_type": "classical SVM classifier on fixed embeddings",
            "model_size": null,
            "data_type": "event pairs from traces (pairwise analysis)",
            "data_domain": "business process traces",
            "anomaly_type": "semantic anomalous event pairs",
            "method_description": "Transform event pair text into GloVe embedding vectors and train an SVM to classify pair as normal or anomalous; a trace is anomalous if any pair is anomalous.",
            "baseline_methods": "Compared against DABL, SENSE-BERT, SEM",
            "performance_metrics": "precision, recall, F1, accuracy",
            "performance_results": "On D1: Precision 87.95%, Recall 51.12%, F1 62.20%, Accuracy 52.50%. On D2: Precision 90.28%, Recall 28.64%, F1 43.49%, Accuracy 64.82% (from paper tables).",
            "comparison_to_baseline": "High precision but low recall (misses many anomalies); DABL achieves much higher recall and balanced F1/accuracy.",
            "limitations_or_failure_cases": "Limited sensitivity to anomalies (low recall) and inability to capture long-range dependencies due to pairwise decomposition.",
            "unique_insights": "Classical embedding+SVM pipeline can achieve good precision but suffers from low coverage of anomaly types when global sequence context matters.",
            "uuid": "e9295.5",
            "source_info": {
                "paper_title": "DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "SEM (van der Aa et al.)",
            "name_full": "SEM: Natural language-based detection of semantic execution anomalies (BERT-based parsing + knowledge base)",
            "brief_description": "A semantic anomaly detection approach that fine-tunes BERT to parse activity names into action and business object, then checks assertions (from VerbOcean or abstract model) to detect semantic violations; used as a baseline.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "BERT (fine-tuned)",
            "model_type": "transformer encoder",
            "model_size": null,
            "data_type": "parsed activity names and derived assertions (event-pair / asserted relations)",
            "data_domain": "business process traces",
            "anomaly_type": "semantic violations (assertion breaches, event-pair related semantic anomalies)",
            "method_description": "Parse activity names to extract action/object, build a knowledge base of assertions about relations using VerbOcean or abstract model, detect anomalies where traces violate asserted relations.",
            "baseline_methods": "Compared against DABL and SENSE approaches",
            "performance_metrics": "precision, recall, F1, accuracy",
            "performance_results": "On D1: Precision 48.67%, Recall 46.84%, F1 47.72%, Accuracy 50.81%. On D2: Precision 71.91%, Recall 48.63%, F1 58.02%, Accuracy 66.75% (from paper tables).",
            "comparison_to_baseline": "DABL substantially outperforms SEM in both generalization and learning given processes.",
            "limitations_or_failure_cases": "Relies on extracted assertions and event-pair reasoning, which can break long-distance dependencies and yield limited accuracy where whole-trace context and long-range order matter.",
            "unique_insights": "Semantic assertion checking can catch some rule-based semantic anomalies but is limited when assertions are incomplete or when anomalies require whole-trace interpretation.",
            "uuid": "e9295.6",
            "source_info": {
                "paper_title": "DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Other LLM-based anomaly works (AnomalyGPT, Myriad, LLMAD, LogGPT, SheepDog, Sarda et al.)",
            "name_full": "Collection of recent works that apply large language models (or LLM pipelines) to anomaly detection in various modalities",
            "brief_description": "Related works cited that apply LLMs or LLM-centered pipelines to anomaly detection tasks (industrial image/anomaly detection, time series, system logs, microservices), mentioned in the paper's related work to contextualize DABL.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "AnomalyGPT, Myriad, LLMAD, LogGPT, SheepDog, etc. (various LLM-centered methods)",
            "model_type": "varies (vision-language LLMs, LLM + retrieval, LLM prompting pipelines)",
            "model_size": null,
            "data_type": "various: images (industrial), time series segments, system logs, microservice metrics, textual descriptions—i.e., sequences or structured logs in different modalities",
            "data_domain": "industrial inspection, time-series monitoring, system logs, microservice anomaly detection",
            "anomaly_type": "industrial visual anomalies, time-series anomalies, log anomalies, microservice anomalies (domain-specific)",
            "method_description": "Examples include combining vision encoders with LLMs for image anomaly detection (AnomalyGPT, Myriad), retrieval-augmented few-shot LLM anomaly detection for time series (LLMAD), prompt engineering / preprocessing pipelines for log anomaly detection (LogGPT, Egersdoerfer et al.), and LLM-driven anomaly remediation pipelines (Sarda et al.).",
            "baseline_methods": null,
            "performance_metrics": null,
            "performance_results": null,
            "comparison_to_baseline": "These works demonstrate feasibility of LLMs in other anomaly domains; the paper notes that application to business process trace semantic anomalies was unexplored prior to DABL.",
            "limitations_or_failure_cases": "Modalities and data structures differ (images vs. sequences); many approaches require modality-specific encoders, retrieval components, or are limited by domain knowledge.",
            "unique_insights": "Paper places DABL as a complementary direction that focuses specifically on structured categorical sequences (process traces) and on interpretable natural-language causes, an area less explored by existing LLM anomaly works.",
            "uuid": "e9295.7",
            "source_info": {
                "paper_title": "DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models",
                "publication_date_yy_mm": "2024-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Anomalygpt: Detecting industrial anomalies using large vision-language models.",
            "rating": 2,
            "sanitized_title": "anomalygpt_detecting_industrial_anomalies_using_large_visionlanguage_models"
        },
        {
            "paper_title": "Myriad: Large multimodal model by applying vision experts for industrial anomaly detection.",
            "rating": 2,
            "sanitized_title": "myriad_large_multimodal_model_by_applying_vision_experts_for_industrial_anomaly_detection"
        },
        {
            "paper_title": "Large Language Models can Deliver Accurate and Interpretable Time Series Anomaly Detection.",
            "rating": 2,
            "sanitized_title": "large_language_models_can_deliver_accurate_and_interpretable_time_series_anomaly_detection"
        },
        {
            "paper_title": "Loggpt: Exploring chatgpt for log-based anomaly detection.",
            "rating": 2,
            "sanitized_title": "loggpt_exploring_chatgpt_for_logbased_anomaly_detection"
        },
        {
            "paper_title": "Semantic anomaly detection with large language models.",
            "rating": 1,
            "sanitized_title": "semantic_anomaly_detection_with_large_language_models"
        },
        {
            "paper_title": "Early exploration of using chatgpt for log-based anomaly detection on parallel file systems logs.",
            "rating": 1,
            "sanitized_title": "early_exploration_of_using_chatgpt_for_logbased_anomaly_detection_on_parallel_file_systems_logs"
        },
        {
            "paper_title": "Adarma auto-detection and auto-remediation of microservice anomalies by leveraging large language models.",
            "rating": 1,
            "sanitized_title": "adarma_autodetection_and_autoremediation_of_microservice_anomalies_by_leveraging_large_language_models"
        }
    ],
    "cost": 0.018093249999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models
22 Jun 2024</p>
<p>Wei Guan guan-wei@sjtu.edu.cn 
Department of Computer Science and Engineering
Shanghai Jiao Tong University
ShanghaiChina</p>
<p>Jian Cao cao-jian@sjtu.edu.cn 
Department of Computer Science and Engineering
Shanghai Jiao Tong University
ShanghaiChina</p>
<p>Jianqi Gao 
Department of Computer Science and Engineering
Shanghai Jiao Tong University
ShanghaiChina</p>
<p>Haiyan Zhao zhaohaiyan1992@foxmail.com 
Department of Computer Science and Engineering
University of Shanghai for Science and Technology
ShanghaiChina</p>
<p>Shiyou Qian 
Department of Computer Science and Engineering
Shanghai Jiao Tong University
ShanghaiChina</p>
<p>DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models
22 Jun 202432B40218D0D5A8DD2EC658EF59F6849DarXiv:2406.15781v1[cs.CL]
Detecting anomalies in business processes is crucial for ensuring operational success.While many existing methods rely on statistical frequency to detect anomalies, it's important to note that infrequent behavior doesn't necessarily imply undesirability.To address this challenge, detecting anomalies from a semantic viewpoint proves to be a more effective approach.However, current semantic anomaly detection methods treat a trace (i.e., process instance) as multiple event pairs, disrupting long-distance dependencies.In this paper, we introduce DABL, a novel approach for detecting semantic anomalies in business processes using large language models (LLMs).We collect 143,137 real-world process models from various domains.By generating normal traces through the playout of these process models and simulating both ordering and exclusion anomalies, we fine-tune Llama 2 using the resulting log.Through extensive experiments, we demonstrate that DABL surpasses existing state-of-the-art semantic anomaly detection methods in terms of both generalization ability and learning of given processes.Users can directly apply DABL to detect semantic anomalies in their own datasets without the need for additional training.Furthermore, DABL offers the capability to interpret the causes of anomalies in natural language, providing valuable insights into the detected anomalies.</p>
<p>Introduction</p>
<p>Business process anomaly detection is geared towards identifying undesired behavior occurring during process execution, serving as a crucial component in guaranteeing the efficient and dependable operation of businesses.By pinpointing anomalies within business processes, these detection techniques facilitate timely intervention, maintenance, and optimization, consequently bolstering overall well-being.</p>
<p>Over the past few decades, notable advancements have been achieved in business process anomaly detection.Fig. 1 illustrates a comparison of various applicable methods for accomplishing this task.Traditional statistical-based approaches (Lu, Fang, and Fang 2022;Ko and Comuzzi 2022;Nolle et al. 2022;Guan et al. 2024) rely on analyzing statistical frequencies to identify anomalies.However, infrequent behavior is not necessarily anomalous; it may represent rare but acceptable behavior.Conversely, frequent behavior may not always be normal.Furthermore, these methods focus on providing anomaly scores and require manual specification of thresholds to distinguish between normal and anomalous instances, which is not suitable for real-world applications.Alternatively, methods based on conformance checking (Ebrahim and Golpayegani 2022; Sarno, Sinaga, and Sungkono 2020;Sinaga and Sarno 2016) detect anomalies by assessing the alignment between traces and their corresponding process models.Yet, accurately capturing complex processes within a process model remains a challenge, thereby restricting the utility of such approaches.The concept of semantic anomaly detection, recently introduced, addresses these challenges by identifying anomalies from a semantic viewpoint.For example, it can detect irregularities such as a claim being paid after having been rejected.Its grounding in natural language analysis allows for the consideration of typical behavior in standard processes, eliminating the necessity of having a specific process model at hand.However, existing semantic-based anomaly detection methods (van der Aa, Rebmann, and Leopold 2021; Caspary, Rebmann, and van der Aa 2023) treat a trace as multiple event pairs, disrupting long-distance dependencies and thus limiting their accuracy.Additionally, these methods interpret the cause of anomalies by providing anomalous event pairs, which can be confusing.</p>
<p>Recently, there have been significant advancements in large language models (LLMs).Due to their remarkable language comprehension abilities, LLMs such as GPT-3.5 (Ouyang et al. 2022), GPT-4 (Achiam et al. 2023), Llama 2 (Touvron et al. 2023), and GLM-3 (Zeng et al. 2022) have shown proficiency in tasks like summarization, paraphrasing, and instruction following in zero-shot scenarios.However, in the context of semantic anomaly detection in business processes, their performance is limited by a lack of prior domain knowledge.As illustrated in Fig. 1, they often struggle to provide specific answers.</p>
<p>To address the aforementioned issues, we propose DABL, a fine-tuned LLM designed to detect semantic anomalies in business processes.Due to the lack of event logs comprising traces from various domains with rich semantic information, we generated our training dataset by playing out 143,137 real-world process models from three different process model datasets.This resulted in 1,574,381 normal traces.The collected process models cover a broad range of domains, including common processes related to order and request handling, as well as specialized processes in fields such as software engineering and healthcare.Utilizing the generated normal traces, we then created synthetic anomalous traces.We introduced ordering anomalies, where activities should be executed in a different sequence (e.g., "accept request" followed by "check request"), and exclusion anomalies, where certain activities should not occur together within the same trace without an intermediate activity (e.g., "refusing the application" followed by "accepting the application" without "reapplying" in between).These generated normal and anomalous traces collectively form the training dataset.Finally, by incorporating traces into question and answer content, we fine-tune the Llama 2-Chat 13B model (Touvron et al. 2023), an open-source LLM, using QLoRA (Dettmers et al. 2024), to create a generic model capable of detecting semantic anomalies in business processes.Compared to existing anomaly detection methods, DABL offers the capability to interpret the causes of anomalies in natural language, providing valuable insights into the detected anomalies.Extensive experiments show that DABL surpasses state-of-the-art methods in both generalization ability and learning of given processes.Thanks to its strong generalization ability, users can apply our opensource, fine-tuned model directly to their datasets without the need for additional training.</p>
<p>Our contributions are summarized as follows:</p>
<p>• We introduce DABL, an innovative method for finetuning large language models (LLMs) to detect semantic anomalies in business processes.</p>
<p>• We introduce novel techniques for simulating business process anomalies, encompassing ordering anomalies and exclusion anomalies, thereby enabling precise finetuning of LLMs.</p>
<p>• Extensive experiments demonstrate that DABL outperforms state-of-the-art methods in both generalization ability and the learning of given processes.Tests on real-world datasets confirm the practical effectiveness of DABL.</p>
<p>Related Work Business Process Anomaly Detection</p>
<p>Existing business process anomaly detection methods can be divided into three categories: statistical-based, conformance checking-based, and semantic-based.</p>
<p>Statistical-based Methods Some of these methods construct probabilistic models to infer the probability values (i.e., anomaly score) of traces.For example, HPDTMC (Yang et al. 2020) (Rullo et al. 2020).Furthermore, the authors in (Ko andComuzzi 2022, 2021) employ one-hot encoding to convert traces into vector representations and detect anomalies using statistical leverage (Hoaglin and Welsch 1978).Recently, deep learning has been adopted to detect anomalies based on the reconstruction error.Given that traces exhibit sequential data characteristics, the authors in (Guan et al. 2023;Nolle et al. 2022;Krajsic and Franczyk 2021) embed LSTM or GRU within the autoencoder to enhance the model's reconstruction capabilities.The authors in (Huo et al. 2021;Guan et al. 2024; Niro and Werner 2024) transform traces into graphs and utilize graph neural networks (GNNs) to generate graph encodings, identifying anomalies by evaluating the reconstruction error of the graphs or traces.</p>
<p>Statistical-based methods detect anomalies by analyzing statistical frequencies.However, infrequent behavior is not necessarily anomalous, as it may represent rare but acceptable behavior.Conversely, frequent behavior may not always be normal.</p>
<p>Conformance Checking-based Methods The conformance checking-based approaches (Ebrahim and Golpayegani 2022; Sarno, Sinaga, and Sungkono 2020; Sinaga and Sarno 2016) utilize process models, which are either provided by the user or derived from logs using process mining techniques.Anomalies are detected through conformance checking techniques (Leemans, Fahland, and van der Aalst 2018), which assess the alignment between traces and the corresponding process model.When the trace deviates from the process model, it is considered anomalous.</p>
<p>The performance of these methods heavily depends on the quality of the process model.Additionally, complex processes are difficult to accurately represent with a process model, limiting the applicability of these methods.</p>
<p>Semantic-based Methods</p>
<p>The semantic-based methods detect anomalies through natural language analysis, aim-ing to detect process behaviors that deviate from a semantic point of view.</p>
<p>Van der Aa et al. (van der Aa, Rebmann, and Leopold 2021) fine-tune BERT (Devlin et al. 2018), a pre-trained language model, to parse the names of executed activities by extracting the action and business object.Then, a knowledge base capturing assertions about the interrelations that should hold among actions parsed from names of executed activities is applied.The knowledge is extracted either from VerbOcean (Chklovski and Pantel 2004) or from an abstract representation of the process model.Anomalies can be detected by checking if the recorded process behavior violates the assertions captured in the knowledge base.</p>
<p>Caspary et al. (Caspary, Rebmann, and van der Aa 2023) extract event pairs that are in an eventually-follow relation.To detect anomalous event pairs, they propose two approaches: an SVM-based approach and a BERT-based approach.The SVM-based approach transforms an event pair into a vector representation using GloVe embeddings.This vector is then fed into a trained SVM, which classifies whether the event pair is an anomaly.The BERT-based approach extends BERT with an additional output layer for two-class classification, determining whether an input event pair is anomalous or not.Both the SVM and the extended BERT model are trained using normal event pairs extracted from normal traces, along with anomalous event pairs simulated by randomly generating event pairs that are not normal.</p>
<p>However, existing semantic-based methods treat a trace as multiple event pairs, which disrupts long-distance dependencies.Additionally, these methods only identify anomalous event pairs to interpret the causes of anomalies, making them difficult to understand.In contrast, our DABL incorporates the entire trace into a novel prompt, allowing the LLMs to automatically capture long-distance dependencies.DABL also provides insightful interpretations of the causes of anomalies in natural language, making them easy to understand.</p>
<p>Large Language Models for Anomaly Detection</p>
<p>Motivated by the impressive cognitive abilities exhibited by large language models (LLMs) (Ouyang et al. 2022;Zeng et al. 2022;Achiam et al. 2023;Touvron et al. 2023), researchers have begun investigating their application for anomaly detection.</p>
<p>AnomalyGPT (Gu et al. 2024) and Myriad (Li et al. 2023) incorporate novel image encoders with LLMs for industrial anomaly detection (IAD).Elhafsi et al. (Elhafsi et al. 2023) apply an LLM to analyze potential confusion among observed objects in a scene, which could lead to taskrelevant errors in policy implementation.LLMAD (Liu et al. 2024) leverages LLMs for few-shot anomaly detection by retrieving and utilizing both positive and negative similar time series segments.In (Qi et al. 2023) and (Egersdoerfer, Zhang, and Dai 2023), authors devise effective prompts to apply LLMs for zero/few-shot system log anomaly detection.SheepDog (Wu and Hooi 2023) conducts fake news detection by preprocessing data using LLMs to reframe the news, customizing each article to match different writing styles.Sarda et al. (Sarda et al. 2023) propose a pipeline for automatic microservice anomaly detection and remediation based on LLMs.</p>
<p>Yet, the application of LLMs for business process anomaly detection remains unexplored.</p>
<p>Method</p>
<p>DABL is a novel conversational fine-tuned large language model, primarily designed to detect semantic anomalies in business processes and interpret their causes.Fig. 2 details the DABL training procedure, which consists mainly of dataset preparation and fine-tuning.DABL is implemented in Python, and the source code is accessible at https://github.com/guanwei49/DABL.</p>
<p>Dataset Preparation</p>
<p>To effectively fine-tune LLMs for developing a generic model capable of detecting semantic anomalies in business processes, a log meeting the following criteria is imperative: i) it must encompass both normal and anomalous traces, ii) it should contain rich semantic information (i.e., the activities should not be represented by meaningless characters), and iii) the traces within it should stem from diverse processes across various domains.Since such a log is not available in the real world, we generate normal traces by playout of the real-world process models from the BPM Academic Initiative (BPMAI) (Weske et al. 2020), fundamentals of business process management (FBPM) (Dumas et al. 2018), and SAP signavio academic models (SAP-SAM) (Sola et al. 2022).These process models cover a broad range of domains, including common processes related to order and request handling, as well as specialized processes from fields such as software engineering and healthcare.We then generate synthetic anomalies from these normal traces.We detail the dataset preparation in the following subsection.</p>
<p>Generation of Normal Traces</p>
<p>We select process models M from BPMAI, FBPM, and SAP-SAM that meet the following criteria: they are in BPMN notation (Chinosi and Trombetta 2012), described in English, and convertible into a sound workflow net.This results in a total set of 144,137 process models.Among these, 143,137 process models are used for generating training datasets, resulting in 1,574,381 normal traces, while the remaining 1,000 process models are used for generating test datasets.</p>
<p>Next, for each process model m ∈ M, we perform a playout to obtain the set of normal traces, denoted as L m .These traces are allowed by the process model m.To prevent infinite trace lengths, we limit each loop in the process model m to be executed a maximum of twice.</p>
<p>Anomaly Simulation Normal traces can be converted into anomalous ones by disrupting the order of executed activities (ordering anomalies) or by sequencing exclusive activities (exclusion anomalies).</p>
<p>Ordering anomalies: Ordering anomalies arise when activities ought to be executed in a different sequence.Five types of ordering anomalies, as identified in (Nolle et al. 2022), are frequently encountered in real-world business  Below are the causes for these anomaly types, which are currently in the plural form (i.e., 'activities', 'they').During implementation, they may need to be flexibly transformed into the singular form (i.e., 'activity', 'it').</p>
<p>• Skip: The activities ${e i , • • • , e j } are skipped before ${e j+1 }.
• Insert: The activities ${e ′ 1 , • • • , e ′ m }
should not be executed.</p>
<p>• Rework: The activities ${e i , • • • , e j } are reworked after ${e k }. • Early: The activities ${e i , • • • , e j } are executed too early, they should be executed after ${e i−1 }. • Late: The activities ${e i , • • • , e j } are executed too late, they should be executed before ${e j+1 }.</p>
<p>Here, ${e i , . . ., e j } represents converting the trace [e i , • • • , e j ] into a string format by enclosing each executed activity in apostrophes and separating them with commas, while using and before the penultimate and ultimate activities.For example, for the trace [A, B, C, D], the resulting string would be 'A', 'B', 'C' and 'D'.</p>
<p>However, the generated anomalies may actually represent a normal trace.For a process model m, we refine the set of generated ordering anomalies L o m by excluding traces present in L m from it.</p>
<p>Exclusion anomalies: Exclusion anomalies occur when certain activities should not have been executed together within the same trace without an intermediate activity.For instance, in the loan application process illustrated in Fig. 2, it is inappropriate to send an acceptance pack and reject an application within the same trace.</p>
<p>The process tree (Aalst, Buijs, and Dongen 2011), a specialized form of process model, is utilized for analyzing process structure.For instance, the process tree corresponding to the process model depicted in Fig. 2 is illustrated in Fig. 4. We begin by converting the gathered process model m into a process tree using the techniques presented in (van Zelst and Leemans 2020).Then, we replace an exclusive node (represented as ×) in the process tree with a parallel node (represented as ∧), resulting in a modified process model denoted as m ′ .This modification enables certain exclusive activities to be executed within the same trace to simulate exclusion anomalies.It is important to recognize that a single process tree may contain multiple exclusive nodes; therefore, we carry out this modification successively, resulting in multiple modified process models.Subsequently, we playout of all the modified models, restricting each loop to be executed a maximum of twice, to generate the set of traces, denoted as L m ′ .We refine L m ′ by excluding traces present in L m from it, resulting in the set of exclusion anomalies L e m .To extract the causes of exclusion anomalies, we need to identify activities that exhibit exclusion relationships.In a process tree, activities located under different branches of an exclusive node (represented as ×) exhibit such relationships.For example, in the process tree illustrated in Fig. 4, the activity set {'Prepare acceptance pack', 'Send acceptance pack'} and the activity set {'Reject application'} exhibit exclusion relationships.</p>
<p>Formally, consider a modified model m ′ , which results from modifying an exclusive node R in the process tree corresponding to the process model m.An exclusion anomaly t is generated from model m ′ .The node R has N branches, with the activity sets A 1 , • • • , A N under them.Activities within each activity set A i that do not appear in t are filtered out.The cause of this exclusion anomaly t is then:</p>
<p>• The activities ${A 1 } are mutually exclusive with the activities ${ i=2•••N A i }, meaning they should not be executed within the same process instance.</p>
<p>Question and Answer Content</p>
<p>To conduct prompt tuning on the LLM, we generate corresponding textual queries based on simulated anomalous traces.Specifically, each query consists of two components.The first component introduces the traces, such as "In the following business process trace, each executed activity is separated by a comma: [Send acceptance pack, Check credit history, Assess loan risk, Assess eligibility, Prepare acceptance pack]".The second component queries whether the trace is anomalous, asking, for instance, "Is this trace normal or anomalous?".The LLM first responds to whether the given trace is normal or anomalous.If it is anomalous, the LLM is asked about the cause of the anomaly, for example, "What causes this trace to deviate?".The LLM then explains the cause of the anomaly, such as "The activity 'Send acceptance pack' is executed too early, it should be executed after 'Prepare acceptance pack'.".This descriptive content about the anomaly's cause provides valuable insights and facilitates actions to maintain the health of the process execution.</p>
<p>Efficient Fine-Tuning on LLMs We employ the Adam optimizer (Kingma and Ba 2014) to fine-tune the LLMs for two epochs, setting the initial learning rate to 5 × 10 −5 with polynomial learning rate decay.The mini-batch size is set to 64.The fine-tuning is carried out on an NVIDIA A6000 GPU with 48 GB of memory.</p>
<p>Experiments Experimental Setup</p>
<p>Datasets As mentioned in previous section, we allocate 1,000 process models for generating the test dataset D 1 .These models produce 14,387 normal traces, and we randomly simulate anomalies, resulting in 13,694 anomalous traces.In total, the test dataset D 1 comprises 28,081 traces.</p>
<p>From 143,137 process models used for generating the training dataset, we randomly select 1,000 process models to create the test dataset D 2 .These 1,000 process models produce 21,298 normal traces, and we randomly simulate anomalies, resulting in 19,627 anomalous traces.In total, the test dataset D 2 comprises 40,925 traces.Note that, although the normal traces within the test dataset D 2 are identical to those in the training dataset, the simulated anomalies are not.</p>
<p>In summary, the test dataset D 1 is used to evaluate the model's generalization ability, verifying if the model can detect anomalies of unseen processes.The test dataset D 2 aims to validate the model's performance on seen processes but unseen anomalies (i.e., learning of given processes).</p>
<p>Compared Methods Statistical-based and conformance checking methods can only be applied to datasets containing traces from a single process.However, our test datasets include traces from 1000 processes where no two traces are identical (i.e., traces with identical orders of activities are executed).Therefore, these methods cannot be compared.In our evaluation, we compare our DABL to existing semantic business process anomaly detection methods: SENSE (Caspary, Rebmann, and van der Aa 2023) and SEM (van der Aa, Rebmann, and Leopold 2021).SENSE offers both SVM-based and BERT-based models for detecting anomalous event pairs, which we denote as SENSE-SVM and SENSE-BERT, respectively.These methods divide traces into event pairs and determine whether each pair is normal or anomalous.If at least one event pair in a trace is identified as anomalous, the entire trace is classified as anomalous.It is important to note that SEM can only detect anomalous event pairs that share the same business object, automatically classifying pairs with distinct business objects as non-anomalous.Due to the high training costs, we utilize the open-source trained models provided by the authors for the test dataset D 1 .For the test dataset D 2 , we train the comparative models using the 21,298 normal traces available within it.The hyper-parameters of these methods are set to the values that yielded the best results reported in the original paper.</p>
<p>Evaluation Metrics Following existing anomaly detection methods, we employ precision, recall, F 1 -score and accuracy to evaluate the anomaly detection performance.</p>
<p>The recall-oriented understudy for gisting evaluation (ROUGE) (Lin 2004) is a software package and metric set designed to assess the quality of generated text by comparing it with ground truth text.In our evaluation of DABL's ability to interpret the cause of anomalies, we utilize ROUGE-2 and ROUGE-L metrics.</p>
<p>Quantitative Results</p>
<p>Anomaly Detection To evaluate the model's generalization ability, we conduct experiments on the test dataset D 1 .The results are shown in Table 1, with the best outcomes highlighted in bold.Our DBAL achieves the highest precision, F 1 -score, and accuracy, with both the F 1 -score and accuracy exceeding 90%.Although SENSE-BERT attains the best recall, it has the lowest precision and accuracy.Compared to other methods, DBAL maintains a balanced We conduct experiments on dataset D 2 to evaluate if the methods can learn the given processes.The results are presented in Table 2. Compared to the experiments on dataset D 1 , the precision of each method increases.This improvement is due to the incorporation of normal process behavior in the training dataset, thereby reducing false alarms.Consequently, the F 1 -score and accuracy also show significant improvements.Our DABL method stands out, achieving the best performance across all metrics, with the F 1score and accuracy showing improvements of 21.79% and 16.75%, respectively, over the best existing semantic-based anomaly detection method (i.e., SENSE-BERT).These results demonstrate that DABL can learn the given processes effectively, allowing users to further fine-tune DABL on their own processes to obtain a customized model.3 shows the results of DABL in interpreting the causes of anomalies.On dataset D 1 , both ROUGE-2 and ROUGE-L scores are relatively high, indicating that DABL performs well in identifying the causes of anomalies, even for processes not included in the training data.For dataset D 2 , DABL exhibits better performance because the normal behaviors of the processes are well-represented in the training data.Furthermore, the slight difference between recall and precision suggests that the model maintains a good balance.These results demonstrate that DABL is effective at interpreting the causes of anomalies in terms of both bigrams and longest common subsequences.</p>
<p>Interpretation of the Cause of Anomalies Table</p>
<p>However, these result values may be underestimated because the cause of an anomaly can be interpreted in various ways.For example, for a desired trace [A, B, C, D, E], the anomaly [A, B, E, C, D] can be interpreted as "The activities 'C' and 'D' are executed too late, they should be executed after 'B'" and "The activity 'E' is executed too early, it should be executed after 'D'."Nevertheless, we only provide one reference answer to calculate ROUGE-2 and ROUGE-L scores.Without further context or information, it is difficult to determine if the given business process trace is normal or anomalous.GPT-3.5 GPT-4 GLM-3 Llama 2 DABL Without knowing the standard sequence of activities or having additional context, it's difficult to say definitively whether this trace is normal or anomalous.This sequence of activities seems logical and typically follows an onboarding process in many organizations.It would be considered normal if this is the standard procedure for equipping new employees with the necessary tools and access to perform their job.</p>
<p>Qualitative Examples</p>
<p>A business process trace is a sequence of activities that are executed in a business process.Each executed activity is separated by a comma in the trace.</p>
<p>The trace is anomalous.</p>
<p>What's the origin of the anomaly?</p>
<p>机器人学 DABL The activity 'Procure work equipment' is executed too early, it should be executed after 'Select necessary work equipment'.</p>
<p>机器人学</p>
<p>Here is a trace of a business process, with each performed activity separated by a comma: [Sh goods, Contact container port, Contact airlines, Prepare delivery note].Is this trace normal anomalou</p>
<p>Based on the provided business process trace, it is difficult to determine if it is normal or anomalous without further context or information.GPT-3.5 GPT-4 GLM-3 Llama 2 DABL As an AI, I don't have the exact context or knowledge of the specific rules of the business process.However, based on the general order of operations in shipping and logistics, this trace seems norma Without additional context or a definition of what is considered normal in this specific process, we can only say that the given trace is not inherently anomalous based on the activities listed.</p>
<p>What is the difference between a trace and a log?A trace is a record of all the activities performed i a business process.A log is a record of all the activities performed in a business process.</p>
<p>The trace is anomalous.</p>
<p>What makes this trace anomalou</p>
<p>机器人学 DABL The activity 'Contact airlines' is mutually exclusive with the activity 'Contact container port', meaning they should not be executed within the same process instance.Due to the absence of business process-related knowledge, existing LLMs may not offer definitive answers.In contrast, our DABL is proficient in identifying anomalies and interpreting their underlying causes, thanks to the integration of a vast array of process models from diverse domains in the training data.</p>
<p>Real-world Application</p>
<p>Travel Permit We apply our DABL on a real-world permit log from the BPI 2020 challenge (van Dongen 2020), which captures data on work trips conducted by university employees.The process flow involves the request for and approval of a travel permit, the trip itself, a subsequent travel declaration, as well as associated reimbursements.</p>
<p>This log contains 7,065 traces with 1,478 variants (traces with different orders of activities are executed).DABL iden- This sequence of activities seems logical and typically follows an onboarding process in many organizations.It would be considered normal if this is the standard procedure for equipping new employees with the necessary tools and access to perform their job.</p>
<p>A business process trace is a sequence of activities that are executed in a business process.Each executed activity is separated by a comma in the trace.</p>
<p>The trace is anomalous.</p>
<p>What's the origin of the anomaly?
人学 BL
The activity 'Procure work equipment' is executed too early, it should be executed after 'Select necessary work equipment'.</p>
<p>机器人学</p>
<p>Here is a trace of a business process, with each performed activity separated by a comma: [Ship goods, Contact container port, Contact airlines, Prepare delivery note].Is this trace normal or anomalous?</p>
<p>Based on the provided business process trace, it is difficult to determine if it is normal or anomalous without further context or information.GPT-3.5 GPT-4 GLM-3 Llama 2 DABL As an AI, I don't have the exact context or knowledge of the specific rules of the business process.However, based on the general order of operations in shipping and logistics, this trace seems normal.</p>
<p>Without additional context or a definition of what is considered normal in this specific process, we can only say that the given trace is not inherently anomalous based on the activities listed.</p>
<p>What is the difference between a trace and a log?A trace is a record of all the activities performed in a business process.A log is a record of all the activities performed in a business process.</p>
<p>The trace is anomalous.</p>
<p>What makes this trace anomalous?</p>
<p>机器人学 DABL The activity 'Contact airlines' is mutually exclusive with the activity 'Contact container port', meaning they should not be executed within the same process instance.tifies 562 anomalous variants.These detected anomalies reveal some interesting irregularity patterns illustrated in Table 4.These irregularity patterns include: trips starting before a permit is properly handled (A1), approved (A2), or even rejected (A3); the declaration being finally approved by a supervisor and payment handled despite the permit being rejected (A4); and requests for payment being approved before the permit is approved (A5).</p>
<p>Road Traffic Fine Management</p>
<p>We apply our DABL on another real-world event log from an information system managing road traffic fines (de Leoni and Mannhardt 2015), which captures the road traffic fine management process.The process flow involves the creation of a fine, appeal to the prefecture, addition of penalties, and fine payment.</p>
<p>This log contains 150,370 traces with 231 variants.DABL identifies 56 anomalous variants.These detected anomalies reveal some interesting irregularity patterns as detailed in Table 5.The examples illustrate irregularity patterns where the fine is repeatedly paid (A1), the fine is paid before the penalty is added (A2), and the result appeal from the prefecture is received before the appeal is sent to the prefecture (A3).</p>
<p>Conclusion</p>
<p>In this paper, we introduce DABL, a novel semantic business process anomaly detection model leveraging LLMs.Trained on 143,137 real-world process models from various domains, DABL excels at zero-shot detection of semantic anomalies and interprets their causes in natural language.Extensive experiments demonstrate DABL's generalization ability, allowing users to detect anomalies in their own datasets without additional training.</p>
<p>Figure 1 :
1
Figure 1: Comparison between our DABL with existing methods.</p>
<p>Figure 3 :
3
Figure 3: Different anomaly types applied to a normal trace.</p>
<p>Figure 4 :
4
Figure 4: Different anomaly types applied to a normal trace.</p>
<p>Fig. 5
5
Fig. 5 and Fig. 6 illustrate the performance of existing LLMs and DABL on early and exclusion anomalies, respectively.</p>
<p>Figure 5 :
5
Figure 5: Qualitative results of various LLMs on an early anomaly.</p>
<p>人学</p>
<p>Below is a business process trace, with each executed activity separated by a comma: [Add personal data, Procure work equipment, Select necessary work equipment, Set up access rights hardware and software].Is this trace normal or anomalous?Without further context or information, it is difficult to determine if the given business process trace is normal or anomalous.standard sequence of activities or having additional context, it's difficult to say definitively whether this trace is normal or anomalous.</p>
<p>Figure 6 :
6
Figure 6: Qualitative results of various LLMs on an exclusion anomaly.</p>
<p>[Check credit history, Assess loan risk, Assess eligibility, Reject application] [Check credit history, Assess loan risk, Assess eligibility, Prepare acceptance pack, Send acceptance pack] Check credit history, Assess loan risk, Assess eligibility, Prepare acceptance pack, Send acceptance pack]", "label": "normal"} {"trace": "[Send acceptance pack, Check credit history, Assess loan risk, Assess eligibility, Prepare acceptance pack]", "label": "anomalous", "cause": "The activity 'Send acceptance pack' is executed too early, it should be executed after 'Prepare acceptance pack'."}{"trace": "[Check credit history, Assess loan risk, Assess eligibility, Reject application, Prepare acceptance pack, Send acceptance pack]",
Process ModelApplicant Applicantnot eligible not eligibleReject Rejectapplication applicationCheck credit Check creditAssess loan Assess loanAssess Assesshistory historyrisk riskeligibility eligibilityPrepare PrepareSend SendApplicant eligible Applicant eligibleacceptance pack acceptance packacceptance pack acceptance packPlayout of Process ModelNormal TracesAnomaly Simulation{"trace": "[Check credit history, Assess loan risk, Assess eligibility, Reject application]","label": "normal"}Question and Answer Content: In the following business process trace, each executed activity is separated by a comma:{trace}. Is this trace normal or anomalous? \n The trace is {label}.\n What's the cause of the anomaly? \n {cause} Open-source LLM Open-source LLM Efficient Fine-Tuning on Open-Source LLMs {"trace": "[Check credit history Assess loan risk Develop Hypothesis Assess eligibility Reject application Normal Check credit history Assess loan risk Develop Hypothesis Assess eligibility Reject application NormalFine-Tuned LLM for Business Process Anomaly DetectionSkipCheck credit historyAssess loan riskDevelop HypothesisAssess eligibilityReject applicationInsertCheck credit historyAssess loan riskDevelop HypothesisAssess eligibilityExperimentReject applicationReworkCheck credit historyAssess loan riskDevelop HypothesisAssess loan riskAssess eligibilityReject applicationEarlyCheck credit historyAssess eligibilityAssess loan riskDevelop HypothesisReject applicationLateCheck credit history Develop HypothesisAssess eligibilityAssess loan riskReject application
"label": "anomalous", "cause": "The activity 'Reject application' is mutually exclusive with the activities 'Prepare acceptance pack' and 'Send acceptance pack', meaning they should not be executed within the same process instance."}Figure2:Detecting semantic anomalies in business processes using large language models.</p>
<p>Table 1 :
1
Semantic anomaly detection results on dataset D 1 .The best results are indicated using bold typeface.
Prec.(%) Rec.(%) F 1 (%) Acc.(%)SEM48.6746.847.7250.81SENSE-SVM87.951.122.2052.50SENSE-BERT48.1797.7464.5348.47DBAL94.0689.7991.8892.39</p>
<p>Table 2 :
2
Semantic anomaly detection results on dataset D 2 .The best results are indicated using bold typeface.
Prec.(%) Rec.(%) F 1 (%) Acc.(%)SEM71.9148.6358.0266.75SENSE-SVM90.2828.6443.4964.82SENSE-BERT93.1662.8875.0880.28DBAL98.1295.6496.8797.03</p>
<p>Table 3 :
3
The results of DABL in interpreting the causes of anomalies.
DatasetROUGE-2(%)ROUGE-L(%)Prec. Rec.F 1Prec. Rec.F 1D 174.48 74.49 74.32 76.29 76.11 76.02D 284.92 84.61 84.54 86.96 86.66 86.56precision and recall. SENSE-SVM exhibits limited sensi-tivity to anomalies, potentially overlooking many anoma-lies, thereby achieving high precision but markedly low re-call. Conversely, SENSE-BERT demonstrates excessive sen-sitivity, resulting in numerous false alarms, thus yieldinglow precision but high recall. These results demonstrate thatDBAL possesses a superior generalization ability for detect-ing anomalies in unseen processes.</p>
<p>Table 4 :
4
Irregularity patterns identified in the travel permit log.The activities 'Permit APPROVED by BUDGET OWNER' and 'Permit FINAL APPROVED by SUPERVISOR' are executed too late, they should be executed before 'Request For Payment APPROVED by BUDGET OWNER'.Permit SUBMITTED by EMPLOYEE; PAA: Permit APPROVED by ADMINISTRATION; PAB: Permit APPROVED by BUDGET OWNER; PAS: Permit APPROVED by SUPERVISOR; PFAS: Permit FI-NAL APPROVED by SUPERVISOR; PFAD: FINAL APPROVED by DIRECTOR; PRM: Permit REJECTED by MISSING; RSE: Request For Payment SUBMITTED by EMPLOYEE; RRA: Request For Payment REJECTED by ADMINISTRATION; RRE: Request For Payment REJECTED by EMPLOYEE; RAA: Request For Payment APPROVED by ADMINISTRATION; RAB: Request For Payment APPROVED by BUDGET OWNER; RFAS: Request For Payment FINAL APPROVED by SUPERVISOR; DSAE: Declaration SAVED by EMPLOYEE; DSE: Declaration SUBMITTED by EMPLOYEE; DRA: Declaration RE-JECTED by ADMINISTRATION; DRE: Declaration REJECTED by EMPLOYEE; DAA: Declaration APPROVED by ADMINISTRATION; DAB: Declaration APPROVED by BUDGET OWNER; DFAS: Declaration FINAL APPROVED by SUPERVISOR; RP: Request Payment; PH: Payment Handled; SR: Send Reminder; ST: Start trip; ET: End trip.
IDExample Trace
PSE:</p>
<p>Table 5 :
5
Irregularity patterns identified in the road traffic fine management log.Receive Result Appeal from Prefecture' is executed too early, it should be executed after 'Send Appeal to Prefecture'.Create Fine; SF: Send Fine; IFN: Insert Fine Notification; AP: Add penalty; P: Payment; RRAP: Receive Result Appeal from Prefecture; IDAP: Insert Date Appeal to Prefecture; SAP: Send Appeal to Prefecture.Below is a business process trace, with each executed activity separated by a comma: [Add personal data, Procure work equipment, Select necessary work equipment, Set up access rights hardware and software].Is this trace normal or anomalous?
IDExample Trace
CF:机器人学</p>
<p>AcknowledgmentsThis work is supported by China National Science Foundation (Granted No. 62072301).
Towards improving the representational bias of process mining. W V D Aalst, J Buijs, B V Dongen, International Symposium on Data-Driven Process Discovery and Analysis. Springer2011</p>
<p>J Achiam, S Adler, S Agarwal, L Ahmad, I Akkaya, F L Aleman, D Almeida, J Altenschmidt, S Altman, S Anadkat, arXiv:2303.08774Gpt-4 technical report. 2023arXiv preprint</p>
<p>Does this make sense? machine learning-based detection of semantic anomalies in business processes. J Caspary, A Rebmann, H Van Der Aa, A Trombetta, International Conference on Business Process Management. Springer2023. 201234BPMN: An introduction to the standard</p>
<p>Verbocean: Mining the web for fine-grained semantic verb relations. T Chklovski, P , Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing. the 2004 Conference on Empirical Methods in Natural Language Processing2004</p>
<p>Representation Learning for Business Processes. P De Koninck, S Vanden Broucke, J De Weerdt, Business Process Management. M Weske, M Montali, I Weber, J Brocke, ChamSpringer International Publishing2018. act2vec, trace2vec, log2vec, and model2vec</p>
<p>M M De Leoni, F Mannhardt, Road Traffic Fine Management Process. 2015</p>
<p>Qlora: Efficient finetuning of quantized llms. T Dettmers, A Pagnoni, A Holtzman, L Zettlemoyer, Advances in Neural Information Processing Systems. 202436</p>
<p>Bert: Pre-training of deep bidirectional transformers for language understanding. J Devlin, M.-W Chang, K Lee, K Toutanova, M Dumas, L M Rosa, J Mendling, A H Reijers, arXiv:1810.04805J. Comput. Virol. Hacking Tech. Springer. Ebrahim, M.and Golpayegani, S. A. H. 20222018. 2018arXiv preprintAnomaly detection in business processes logs using social network analysis</p>
<p>Early exploration of using chatgpt for log-based anomaly detection on parallel file systems logs. C Egersdoerfer, D Zhang, D Dai, Proceedings of the 32nd International Symposium on High-Performance Parallel and Distributed Computing. the 32nd International Symposium on High-Performance Parallel and Distributed Computing2023</p>
<p>Semantic anomaly detection with large language models. A Elhafsi, R Sinha, C Agia, E Schmerling, I A Nesnas, M Pavone, Autonomous Robots. 4782023</p>
<p>Anomalygpt: Detecting industrial anomalies using large vision-language models. Z Gu, B Zhu, G Zhu, Y Chen, M Tang, J Wang, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202438</p>
<p>GRASPED: A GRU-AE Network Based Multi-Perspective Business Process Anomaly Detection Model. W Guan, J Cao, Y Gu, S Qian, IEEE Transactions on Services Computing. 2023</p>
<p>GAMA: A multi-graph-based anomaly detection framework for business processes via graph neural networks. W Guan, J Cao, Y Gu, S Qian, 2024. 102405Information Systems</p>
<p>The hat matrix in regression and ANOVA. D C Hoaglin, R E Welsch, The American Statistician. 3211978</p>
<p>Graph Autoencoders for Business Process Anomaly Detection. S Huo, H Völzer, P Reddy, P Agarwal, V Isahagian, V Muthusamy, Springer, S B Junior, P Ceravolo, E Damiani, N J Omori, G M Tavares, Business Process Management -19th International Conference, BPM, volume 12875 of Lecture Notes in Computer Science. 2021. 2020. 2020Anomaly Detection on Event Logs with a Scarcity of Labels. 2nd International Conference on Process Mining (ICPM</p>
<p>Detecting anomalies in business process event logs using statistical leverage. D P Kingma, J Ba, J Ko, M Comuzzi, arXiv:1412.6980Adam: A method for stochastic optimization. 2014. 2021549arXiv preprint</p>
<p>Keeping our rivers clean: Information-theoretic online anomaly detection for streaming business process events. Information Systems. J Ko, M Comuzzi, P Krajsic, B Franczyk, Procedia Computer Science. 1042022. 2021Semi-supervised anomaly detection in business process event data using selfattention based classification</p>
<p>Scalable process discovery and conformance checking. S J J Leemans, D Fahland, W M Van Der Aalst, Softw. Syst. Model. 1722018</p>
<p>Y Li, H Wang, S Yuan, M Liu, D Zhao, Y Guo, C Xu, G Shi, W Zuo, arXiv:2310.19070Myriad: Large multimodal model by applying vision experts for industrial anomaly detection. 2023arXiv preprint</p>
<p>Rouge: A package for automatic evaluation of summaries. C.-Y Lin, Text summarization branches out. 2004</p>
<p>Large Language Models can Deliver Accurate and Interpretable Time Series Anomaly Detection. J Liu, C Zhang, J Qian, M Ma, S Qin, C Bansal, Q Lin, S Rajmohan, D Zhang, arXiv:2405.15370Lu, K.; Fang, X.; and Fang, N. 2022. PN-BBN: A Petri Net-Based Bayesian Network for Anomalous Behavior Detection. Mathematics202410arXiv preprint</p>
<p>BINet: Multi-perspective business process anomaly classification. T Mikolov, K Chen, G Corrado, J Dean, T Nolle, S Luettgen, A Seeliger, M Mühlhäuser, arXiv:2403.00775Workshop Track Proceedings. Niro, A.; and Werner, M. 2024. Detecting Anomalous Events in Object-centric Business Processes via Graph Neural Networks. Y Bengio, Y Lecun, Scottsdale, Arizona, USA2013. May 2-4, 2013. 2022103101458arXiv preprintEfficient Estimation of Word Representations in Vector Space</p>
<p>Training language models to follow instructions with human feedback. L Ouyang, J Wu, X Jiang, D Almeida, C Wainwright, P Mishkin, C Zhang, S Agarwal, K Slama, A Ray, Advances in neural information processing systems. 202235</p>
<p>An Anomaly Detection Technique for Business Processes Based on Extended Dynamic Bayesian Networks. S Pauwels, T Calders, Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing, SAC '19. the 34th ACM/SIGAPP Symposium on Applied Computing, SAC '19New York, NY, USAAssociation for Computing Machinery2019aISBN 9781450359337</p>
<p>S Pauwels, T Calders, Detecting Anomalies in Hybrid Business Process Logs. 2019b19</p>
<p>Loggpt: Exploring chatgpt for log-based anomaly detection. J Qi, S Huang, Z Luan, S Yang, C Fung, H Yang, D Qian, J Shang, Z Xiao, Z Wu, 2023 IEEE International Conference on High Performance Computing &amp; Communications, Data Science &amp; Systems, Smart City &amp; Dependability in Sensor, Cloud &amp; Big Data Systems &amp; Application. IEEE2023</p>
<p>A framework for the multi-modal analysis of novel behavior in business processes. A Rullo, A Guzzo, E Serra, E Tirrito, Intelligent Data Engineering and Automated Learning-IDEAL 2020: 21st International Conference. Guimaraes, PortugalSpringer2020. November 4-6, 2020Proceedings, Part I 21</p>
<p>Adarma auto-detection and auto-remediation of microservice anomalies by leveraging large language models. K Sarda, Z Namrud, R Rouf, H Ahuja, M Rasolroveicy, M Litoiu, L Shwartz, I Watts, Proceedings of the 33rd Annual International Conference on Computer Science and Software Engineering. the 33rd Annual International Conference on Computer Science and Software Engineering2023</p>
<p>Anomaly detection in business processes using process mining and fuzzy association rule learning. R Sarno, F Sinaga, K R Sungkono, J. Big Data. 72020</p>
<p>Business process anomali detection using multi-level class association rule learning. F Sinaga, R Sarno, IPTEK Journal of Proceedings Series. 212016</p>
<p>Natural language-based detection of semantic execution anomalies in event logs. D Sola, C Warmuth, B Schäfer, P Badakhshan, J.-R Rehse, T Kampik, Springer, H Touvron, L Martin, K Stone, P Albert, A Almahairi, Y Babaei, N Bashlykov, S Batra, P Bhargava, S Bhosale, arXiv:2307.09288Translating Workflow Nets to Process Trees: An Algorithmic Approach. 2022. 2023. 2021. 2020. 2020. 2020102279arXiv preprintAlgorithms</p>
<p>On the Use of Online Clustering for Anomaly Detection in Trace Streams. R Vertuam Neto, G Tavares, P Ceravolo, S Barbon, G Decker, M Dumas, M L Rosa, J Mendling, H A Reijers, XVII Brazilian Symposium on Information Systems, SBSI 2021. New York, NY, USA2021. 2020Association for Computing Machinery. ISBN 9781450384919. Model Collection of the Business Process Management Academic Initiative</p>
<p>J Wu, B Hooi, arXiv:2310.10830Fake News in Sheep's Clothing: Robust Fake News Detection Against LLM-Empowered Style Attacks. 2023arXiv preprint</p>
<p>Analysing Business Process Anomalies Using Discrete-time Markov chains. L Yang, S Mcclean, M Donnelly, K Khan, K Burke, 2020 IEEE 22nd International Conference on High Performance Computing and Communications; IEEE 18th International Conference on Smart City; IEEE 6th International Conference on Data Science and Systems. HPCC/SmartCity/DSS. 2020</p>
<p>A Zeng, X Liu, Z Du, Z Wang, H Lai, M Ding, Z Yang, Y Xu, W Zheng, X Xia, arXiv:2210.02414Glm-130b: An open bilingual pre-trained model. 2022arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>