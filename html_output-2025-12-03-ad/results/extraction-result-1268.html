<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1268 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1268</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1268</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-27.html">extraction-schema-27</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <p><strong>Paper ID:</strong> paper-255942299</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2301.05832v1.pdf" target="_blank">World Models and Predictive Coding for Cognitive and Developmental Robotics: Frontiers and Challenges</a></p>
                <p><strong>Paper Abstract:</strong> Creating autonomous robots that can actively explore the environment, acquire knowledge and learn skills continuously is the ultimate achievement envisioned in cognitive and developmental robotics. Their learning processes should be based on interactions with their physical and social world in the manner of human learning and cognitive development. Based on this context, in this paper, we focus on the two concepts of world models and predictive coding. Recently, world models have attracted renewed attention as a topic of considerable interest in artificial intelligence. Cognitive systems learn world models to better predict future sensory observations and optimize their policies, i.e., controllers. Alternatively, in neuroscience, predictive coding proposes that the brain continuously predicts its inputs and adapts to model its own dynamics and control behavior in its environment. Both ideas may be considered as underpinning the cognitive development of robots and humans capable of continual or lifelong learning. Although many studies have been conducted on predictive coding in cognitive robotics and neurorobotics, the relationship between world model-based approaches in AI and predictive coding in robotics has rarely been discussed. Therefore, in this paper, we clarify the definitions, relationships, and status of current research on these topics, as well as missing pieces of world models and predictive coding in conjunction with crucially related concepts such as the free-energy principle and active inference in the context of cognitive and developmental robotics. Furthermore, we outline the frontiers and challenges involved in world models and predictive coding toward the further integration of AI and robotics, as well as the creation of robots with real cognitive and developmental capabilities in the future.</p>
                <p><strong>Cost:</strong> 0.027</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1268.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1268.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>WorldModels(Ha)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>World Models (Ha & Schmidhuber)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A seminal latent world-model that separates spatial compression (VAE) and temporal prediction (RNN) to learn a compact latent representation from pixels and use latent 'imagination' to train policies offline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>World models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>World Models</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Two-stage architecture: a VAE encoder/decoder for spatial compression of high-dimensional observations into a low-dimensional latent z, and an RNN (typically an LSTM) modeling temporal transitions in latent space; policies are trained using rollouts ('imagination') produced by the RNN/VAE in latent space.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>latent world model</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>simulated games / Atari-like environments</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>reconstruction loss (VAE ELBO / pixel MSE), next-frame prediction error in pixel space, and environment return when policy is evaluated in the real environment</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>Partially interpretable: latent vectors encode compressed visual features that can be decoded to images, but latents are not explicitly mapped to physical variables; overall model behaves largely as a neural black box</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>visualization of decoded frames and latent traversals; qualitative inspection of generated sequences</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Moderate by modern standards (VAE + RNN training on game data); trained offline on collected trajectories; cost scales with pixel resolution and sequence length but no explicit large-scale GPU training statistics provided</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>Shown to enable policy learning in compact latent imagination; more sample-efficient than naively training policies in pixel space, but the original separation of VAE and RNN limited long-term performance</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Authors report that policies trained on the learned latent model transferred to the real game environments and achieved competent behavior (no numeric scores given in survey)</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>The world model enables sample-efficient policy learning by providing cheap latent rollouts; however, decoupled training (VAE then RNN) can harm long-horizon prediction fidelity and downstream policy quality</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>Separation of spatial and temporal learning simplifies training but sacrifices joint optimization benefits; compression gains efficiency but may omit task-relevant details</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>Separate VAE for spatial compression and RNN for temporal dynamics; low-dimensional latent bottleneck for efficiency and imagination</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared to model-free RL in cited work, enabled policy training using imagined rollouts and reduced environment samples; less integrated than later RSSM/Dreamer approaches</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>Paper suggests compact latent encodings and an imagination-driven policy can be effective, but later work recommends joint training of representation and dynamics for better long-term fidelity</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1268.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1268.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PlaNet/RSSM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PlaNet / Recurrent State Space Model (RSSM) (Hafner et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A latent dynamics model (RSSM) that combines deterministic recurrent units and stochastic latent variables to learn transition dynamics in latent space enabling planning and control from pixels.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Learning latent dynamics for planning from pixels</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>PlaNet / RSSM</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Recurrent State Space Model: an RNN (deterministic path) combined with stochastic latent variables per time-step; a pixel decoder defines the generative model and an encoder/recognition model supports amortized inference; planning is performed in latent space (e.g., CEM).</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>latent world model (recurrent stochastic SSM)</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Atari-like benchmarks, continuous control from pixels, planning tasks</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>ELBO / variational lower bound (reconstruction loss + KL regularization), next-state prediction error, reward prediction error, and task return when planning is applied</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>Latent space is engineered for predictive accuracy rather than direct interpretability; not explicitly interpretable as physical variables</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>Mostly implicit assessment via prediction/rollout fidelity and downstream task performance; no specific symbolic/explainable extraction methods emphasized</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Significant due to joint training of generative/inference networks and planning algorithms; planning in latent space reduces inference-time cost versus pixel-space planning but training involves substantial neural network optimization</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>Reported to be more sample-efficient than many model-free baselines on pixel-based control tasks, because planning/imagined rollouts are cheaper than environment interactions</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Improved planning and control over pixel-space baselines in cited work (no numeric values provided in survey), effective for a range of simulated control tasks</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>High latent prediction fidelity generally translates to improved planning returns; latent dynamics that capture task-relevant features enable efficient planning</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>Autoregressive pixel reconstruction can be costly; balancing reconstruction fidelity and latent compactness is necessary to maintain planning utility</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>Combines deterministic RNN path with stochastic latent variables (RSSM), optimizes ELBO, performs planning in latent space</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Outperforms pixel-based planners and some model-free approaches in sample efficiency; motivates Dreamer-style end-to-end latent policy learning</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>Survey suggests RSSM + latent-space planning is a strong baseline; encourages latent transition models that avoid autoregressive pixel generation for long-horizon efficiency</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1268.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1268.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Dreamer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Dreamer (Hafner et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An actor-critic framework that learns a latent world model (RSSM) and trains policy and value networks by backpropagating through imagined latent trajectories—enabling end-to-end learning in latent imagination.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Dream to control: Learning behaviors by latent imagination</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Dreamer</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Uses an RSSM latent model to imagine trajectories; concurrently trains actor and critic networks inside latent imagination using gradients propagated through the learned dynamics; relies on reconstruction and latent prediction losses for model learning.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>latent world model with integrated policy/value learning</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Atari, continuous control; extended to robot learning in later works</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>ELBO / reconstruction loss, KL regularization, and policy return (cumulative reward) used to evaluate both model fidelity and task success</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>Latent representation remains largely a neural black box; interpretability arises indirectly through the ability to generate realistic imagined sequences</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>Visual inspection of imagined rollouts and decoded frames; diagnostic ablations to assess latent content</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Higher than simple model-free baselines because of simultaneous model and actor-critic training and imagination rollouts, but inference/planning remains cheaper than pixel-level simulation</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>Shown to outperform PlaNet's latent planning baseline and many model-free baselines in sample efficiency on benchmark tasks (survey does not provide numeric comparisons)</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Reported to achieve superior returns on multiple tasks versus baselines in original work, and later shown effective for real-robot online learning pipelines</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>High-fidelity latent dynamics combined with integrated policy learning yields strong task performance; fidelity in dynamics is leveraged directly by policy gradients in imagination</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>End-to-end coupling of model and policy improves performance on trained tasks but can entangle representation with task-specific objectives, potentially reducing task-agnostic reuse</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>Train world model + actor + critic jointly; use latent rollouts for policy/value updates; optimize ELBO and actor-critic objectives</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Demonstrated improved sample efficiency and performance over PlaNet (CEM planning) and many model-free methods on similar benchmarks</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>Survey highlights Dreamer as a strong configuration when joint model-policy optimization and sample efficiency are priorities; suggests trade-offs for generality</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1268.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1268.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DreamerV2</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Dreamer V2 / Discrete World Models (Hafner et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A further development of Dreamer replacing continuous stochastic latents with discrete latent variables and other improvements, achieving state-of-the-art performance on Atari among world-model-based agents.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Mastering Atari with discrete world models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Dreamer V2 (Discrete World Models)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Discrete latent variant of RSSM combined with improvements in representation and training, enabling high-quality latent rollouts and superior performance on Atari benchmarks; still follows latent imagination + policy/value training paradigm.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>latent world model with discrete latent codes</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Atari games; extended to control benchmarks and robotics</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>Prediction/reconstruction losses, discrete-latent ELBO variants, and environment return (game scores)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>Discrete latent codes can improve interpretability (categorical factors easier to inspect) relative to continuous latent vectors, but direct mapping to semantics still limited</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>Inspection of discrete code activations and their decoded rollouts; qualitative analysis of latent structure</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Comparable or higher to continuous latent counterparts due to categorical modeling and potentially larger model capacity; still more efficient than pixel-level planning</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>Reported to significantly outperform many model-free baselines on Atari (survey reports qualitative advantage but no numeric values)</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>State-of-the-art among discrete world-model-based methods on Atari benchmarks at time of publication (exact scores not given in survey)</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>Discrete latents improved downstream policy learning by providing stable, informative latent dynamics; high task performance stems from latent fidelity to task-relevant dynamics</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>Discrete latents improve stability and sometimes interpretability but may sacrifice smooth interpolation properties useful in certain continuous control contexts</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>Switch from continuous to discrete latent representations, adjustments to training losses and model capacity to exploit categorical structure</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Outperformed previous Dreamer and PlaNet instantiations on Atari; suggests discrete latents are advantageous for complex, multi-modal pixel domains</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>Survey implies that discrete latent structures are a strong choice for complex visual tasks where categorical events dominate, but recommends evaluation per task type</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1268.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1268.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Dreaming</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Dreaming (Okada & Taniguchi)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A world-model approach that replaces pixel reconstruction objectives with contrastive training in latent space, aiming to learn latent dynamics useful for control when reconstruction is misleading or infeasible.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Dreaming: Model-based reinforcement learning by latent imagination without reconstruction</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Dreaming</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Latent dynamics model trained with contrastive objectives rather than pixel reconstruction; latent imagination is used to train policies, improving representation of task-relevant features when pixel-level reconstruction is hard or unnecessary.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>latent world model (contrastive/discriminative training)</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>RL from pixels, tasks that are difficult to reconstruct (e.g., sparse or high-variance observations), robotics</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>Contrastive loss (e.g., InfoNCE-like), downstream policy return, and latent prediction accuracy for task-relevant signals</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>Latent focuses on task-relevant discriminative features rather than full observation fidelity, which can improve interpretability in terms of task utility but not full scene reconstruction</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>Evaluate downstream task performance and inspect latent activations for task-relevant correlations; no explicit symbolic extraction reported</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Potentially lower than reconstruction-based models since avoiding image-pixel decoders reduces decoder compute and learning instability; cost still includes dynamics model and contrastive batch processing</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>Reported to outperform reconstruction-based models on tasks that are hard to reconstruct, improving sample-efficiency and downstream returns for those tasks</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Improved performance on tasks where pixel reconstruction is detrimental; survey reports qualitative improvements (no numeric scores)</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>By prioritizing task-relevant predictive features in the latent, Dreaming trades full observation fidelity for greater utility in policy learning</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>Sacrifices full generative fidelity (no pixel reconstruction) to gain better task-relevant representation and downstream policy performance</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>Use contrastive/discriminative objectives for latent learning; perform imagination-based policy updates in latent space</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Performs better than VAE/reconstruction-based world models on tasks with high visual complexity or where reconstruction distracts from task signals</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>Survey recommends contrastive objectives when the goal is control/policy learning rather than accurate image generation, particularly in real-robot settings</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1268.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1268.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NewtonianVAE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>NewtonianVAE (Jaques et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A VAE variant that enforces a physical (Newtonian) structure in latent space — latents correspond to physical quantities (position, velocity) enabling proportional/PD control directly from latent states.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>NewtonianVAE: Proportional control and goal identification from pixels via physical latent spaces</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>NewtonianVAE</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A variational autoencoder with inductive biases enforcing Newtonian dynamics in a low-dimensional latent space, producing latents aligned with interpretable physical state variables used directly for control.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>latent world model with physics prior / structured latent</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Robotic manipulation and industrial tasks (e.g., precise connector/socket insertion)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>Predictive consistency of physical latent variables, control error (position/force), and task success rate (e.g., successful insertion)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>High interpretability: latent dimensions are designed to correspond to physical quantities (position, velocity), which enables direct inspection and use for controllers</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>Impose physics-inspired regularizers and check latent-to-physical variable correlations; evaluate closed-loop control performance using latents</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Lower inference and control complexity due to compact, structured latent; training cost includes enforcing dynamics constraints but decoder complexity is reduced compared to unconstrained pixel reconstructions</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>Enables efficient control (e.g., PD controllers) in latent space and improved sample efficiency for control tasks by encoding physically-relevant variables</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Applied to real robot socket-insertion tasks achieving high-accuracy performance (survey references a successful real-robot experiment though no numeric success rates are given)</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>Physical priors in latent space translate to direct control utility: high interpretability maps to better controller performance for precision tasks</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>Constraining latents to Newtonian form limits flexibility to model non-Newtonian or high-level semantics; good for control but may reduce generality for perception-heavy tasks</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>Low-dimensional latent aligned with physics laws; dynamics regularization to obtain PD-controllable latent states</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>More suitable than generic VAEs for precise control applications because latents map to control-relevant variables, at the cost of modeling general visual variability</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>Survey suggests physics-constrained latent spaces are optimal for tasks requiring precise control; the approach trades representational generality for interpretability and controller compatibility</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1268.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e1268.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Daydreamer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Daydreamer / World models for physical robot learning (Wu et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An extension of Dreamer-style latent world models tailored for physical robot learning, demonstrating an end-to-end pipeline for real-world data collection, online world-model learning, and control.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>World models for physical robot learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Daydreamer (World models for physical robots)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Adaptation of latent world-model architectures (Dreamer family) to physical robot settings, integrating online data acquisition, latent-model updates, and control policies trained with imagined rollouts to enable sample-efficient real-world learning.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>latent world model adapted for real-robot learning</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Physical robot learning and manipulation</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>Sample-efficiency (environment interactions required), task success rate, stability of online model updates, prediction error of latent rollouts</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>Not a primary focus; model prioritized robustness and sample efficiency rather than explicit interpretability</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>Practical evaluation via robot task success and stability of imagined trajectories; no explicit interpretability tools emphasized in survey</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Higher engineering and compute requirements due to real-time/online training on robot-collected data and safety/robustness constraints; inference uses latent rollouts which are cheaper than pixel simulations</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>Reported to enable high sample-efficiency online robot learning compared to naive model-free approaches, enabling fewer real interactions for skill acquisition</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Survey cites high sample efficiency and successful robot tasks in related work (no exact numeric measures provided)</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>World model fidelity in the latent domain directly supports policy learning on the robot; online updating helps adapt to real-world nonstationarity</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>Adapting to noisy real-world data increases engineering complexity and requires robust model updates; balancing model capacity, update frequency, and safety is challenging</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>Pipeline design for online data collection, latent-model updates, and downstream policy learning; attention to robustness over pure generative fidelity</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>More sample-efficient and practical for real robots than many model-free RL methods; requires more engineering and system-level design than pure-simulation approaches</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>Survey emphasizes integrated online learning pipelines and robust latent representations as key for real-robot world models</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1268.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e1268.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ContrastiveModels/CURL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Contrastive world-model approaches (e.g., CURL)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Representation learning approaches that use contrastive/discriminative objectives instead of pixel reconstruction to learn latents that prioritize task-relevant features and improve downstream control.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>CURL: Contrastive unsupervised representations for reinforcement learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Contrastive world-models (contrastive latent learning)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>World models or encoders trained with contrastive objectives (InfoNCE-like) to produce embeddings where temporally/semantically related observations are close and unrelated ones are distant; can be combined with latent dynamics models for planning and control.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>latent world model (contrastive/discriminative training)</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>RL from pixels, robotics, tasks where reconstruction is expensive or misleading</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>Contrastive loss (e.g., InfoNCE), downstream policy return, representation quality measures (e.g., linear probe accuracy), and prediction of task-relevant signals</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>Latents emphasize task-relevant discriminative structure; full observation fidelity is not preserved, so interpretability is limited to task-relevant factors</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>Representation probing and downstream task performance analyses; visualization of nearest neighbors in embedding space</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Often more efficient than full pixel-decode models because they avoid heavy image decoders; contrastive training can require large batch sizes/augmentations</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>Shown to improve sample-efficiency and downstream returns compared to reconstruction-based world models on many control tasks</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Improves policy learning in domains where pixel reconstruction is a poor proxy for task-relevant structure; survey cites qualitative improvements without numeric values</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>By focusing on task-relevant features, contrastive latents often yield better policy performance even when generative fidelity is lower</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>Lose full generative fidelity and interpretability of the full observation, gaining task utility and sometimes compute efficiency</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>Replace reconstruction objectives with contrastive losses; pair with latent dynamics models for latent imagination</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Outperforms reconstruction-based latent models on tasks with reconstruction-irrelevant variability; choice depends on whether task utility or full generative fidelity is required</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>Survey recommends contrastive objectives when downstream control/robustness is prioritized over full image generation fidelity</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1268.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e1268.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PredictiveCoding/ActiveInference</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Predictive Coding / Free-Energy Principle / Active Inference (Friston et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A normative probabilistic framework from neuroscience proposing hierarchical generative models whose top-down predictions are compared with bottom-up inputs; actions and perceptions minimize variational free energy (prediction error), enabling perception, learning, and action selection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Active inference: the free energy principle in mind, brain, and behavior</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Predictive coding / Active inference</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Hierarchical probabilistic generative models (often PGMs) where higher levels predict lower-level activity; variational free energy (ELBO-like) is minimized for inference and action; expected free energy used for planning (epistemic + pragmatic value). Implementations vary from small PGMs to deep amortized networks.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>probabilistic generative framework / model-based inference approach</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Robotics (perception, body estimation, manipulation), cognitive modeling, exploration and active perception</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>Variational free energy / ELBO (prediction error + KL regularization), expected free energy for planning; behavior measured by reduction of prediction error and task success</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>High-level conceptual interpretability (prediction errors, hierarchical signals, precision-weighting) but concrete implementations may remain complex; offers principled mapping between model variables and cognitive constructs</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>Precision-weighting analysis, hierarchical error units, tracing prediction-error signals across levels; mapping to behavioral phenomena</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Potentially high because full Bayesian inversion over complex generative models is costly; practical implementations rely on amortized variational inference, sampling, or approximations to scale</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>Promises data-efficiency via principled epistemic drives and amortized inference, but scaling to high-dimensional inputs (images) is challenging; recent works combine with deep networks to improve scalability</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Applied to robot body perception, manipulation, active perception, and social inference producing adaptive behaviors; concrete performance depends on implementation and task (no universal numeric claims in survey)</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>Unifies perception and action; expected free energy gives an elegant formal solution to exploration-exploitation; model fidelity to sensory dynamics directly supports effective active perception/control</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>Principled normative framework offers interpretability and unified objectives but at the cost of computational scalability and engineering complexity for high-dimensional real-world tasks</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>Hierarchical predictive coding with precision-weighting, expected free energy for planning; use of amortized inference and contrastive/deep methods to scale implementations</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Offers a normative complement to model-based RL and control-as-inference (CaI); strong conceptual advantages for epistemic exploration but requires practical approximations to match performance of deep RL in high-dim domains</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>Survey recommends hybrid solutions: combine active inference principles with amortized deep inference, structural inductive biases (objects, physics), and contrastive objectives for scalability and task utility</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>World models <em>(Rating: 2)</em></li>
                <li>Dream to control: Learning behaviors by latent imagination <em>(Rating: 2)</em></li>
                <li>Learning latent dynamics for planning from pixels <em>(Rating: 2)</em></li>
                <li>Mastering Atari with discrete world models <em>(Rating: 2)</em></li>
                <li>Dreaming: Model-based reinforcement learning by latent imagination without reconstruction <em>(Rating: 2)</em></li>
                <li>NewtonianVAE: Proportional control and goal identification from pixels via physical latent spaces <em>(Rating: 2)</em></li>
                <li>World models for physical robot learning <em>(Rating: 2)</em></li>
                <li>CURL: Contrastive unsupervised representations for reinforcement learning <em>(Rating: 2)</em></li>
                <li>Active inference: the free energy principle in mind, brain, and behavior <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1268",
    "paper_id": "paper-255942299",
    "extraction_schema_id": "extraction-schema-27",
    "extracted_data": [
        {
            "name_short": "WorldModels(Ha)",
            "name_full": "World Models (Ha & Schmidhuber)",
            "brief_description": "A seminal latent world-model that separates spatial compression (VAE) and temporal prediction (RNN) to learn a compact latent representation from pixels and use latent 'imagination' to train policies offline.",
            "citation_title": "World models",
            "mention_or_use": "mention",
            "model_name": "World Models",
            "model_description": "Two-stage architecture: a VAE encoder/decoder for spatial compression of high-dimensional observations into a low-dimensional latent z, and an RNN (typically an LSTM) modeling temporal transitions in latent space; policies are trained using rollouts ('imagination') produced by the RNN/VAE in latent space.",
            "model_type": "latent world model",
            "task_domain": "simulated games / Atari-like environments",
            "fidelity_metric": "reconstruction loss (VAE ELBO / pixel MSE), next-frame prediction error in pixel space, and environment return when policy is evaluated in the real environment",
            "fidelity_performance": null,
            "interpretability_assessment": "Partially interpretable: latent vectors encode compressed visual features that can be decoded to images, but latents are not explicitly mapped to physical variables; overall model behaves largely as a neural black box",
            "interpretability_method": "visualization of decoded frames and latent traversals; qualitative inspection of generated sequences",
            "computational_cost": "Moderate by modern standards (VAE + RNN training on game data); trained offline on collected trajectories; cost scales with pixel resolution and sequence length but no explicit large-scale GPU training statistics provided",
            "efficiency_comparison": "Shown to enable policy learning in compact latent imagination; more sample-efficient than naively training policies in pixel space, but the original separation of VAE and RNN limited long-term performance",
            "task_performance": "Authors report that policies trained on the learned latent model transferred to the real game environments and achieved competent behavior (no numeric scores given in survey)",
            "task_utility_analysis": "The world model enables sample-efficient policy learning by providing cheap latent rollouts; however, decoupled training (VAE then RNN) can harm long-horizon prediction fidelity and downstream policy quality",
            "tradeoffs_observed": "Separation of spatial and temporal learning simplifies training but sacrifices joint optimization benefits; compression gains efficiency but may omit task-relevant details",
            "design_choices": "Separate VAE for spatial compression and RNN for temporal dynamics; low-dimensional latent bottleneck for efficiency and imagination",
            "comparison_to_alternatives": "Compared to model-free RL in cited work, enabled policy training using imagined rollouts and reduced environment samples; less integrated than later RSSM/Dreamer approaches",
            "optimal_configuration": "Paper suggests compact latent encodings and an imagination-driven policy can be effective, but later work recommends joint training of representation and dynamics for better long-term fidelity",
            "uuid": "e1268.0"
        },
        {
            "name_short": "PlaNet/RSSM",
            "name_full": "PlaNet / Recurrent State Space Model (RSSM) (Hafner et al.)",
            "brief_description": "A latent dynamics model (RSSM) that combines deterministic recurrent units and stochastic latent variables to learn transition dynamics in latent space enabling planning and control from pixels.",
            "citation_title": "Learning latent dynamics for planning from pixels",
            "mention_or_use": "mention",
            "model_name": "PlaNet / RSSM",
            "model_description": "Recurrent State Space Model: an RNN (deterministic path) combined with stochastic latent variables per time-step; a pixel decoder defines the generative model and an encoder/recognition model supports amortized inference; planning is performed in latent space (e.g., CEM).",
            "model_type": "latent world model (recurrent stochastic SSM)",
            "task_domain": "Atari-like benchmarks, continuous control from pixels, planning tasks",
            "fidelity_metric": "ELBO / variational lower bound (reconstruction loss + KL regularization), next-state prediction error, reward prediction error, and task return when planning is applied",
            "fidelity_performance": null,
            "interpretability_assessment": "Latent space is engineered for predictive accuracy rather than direct interpretability; not explicitly interpretable as physical variables",
            "interpretability_method": "Mostly implicit assessment via prediction/rollout fidelity and downstream task performance; no specific symbolic/explainable extraction methods emphasized",
            "computational_cost": "Significant due to joint training of generative/inference networks and planning algorithms; planning in latent space reduces inference-time cost versus pixel-space planning but training involves substantial neural network optimization",
            "efficiency_comparison": "Reported to be more sample-efficient than many model-free baselines on pixel-based control tasks, because planning/imagined rollouts are cheaper than environment interactions",
            "task_performance": "Improved planning and control over pixel-space baselines in cited work (no numeric values provided in survey), effective for a range of simulated control tasks",
            "task_utility_analysis": "High latent prediction fidelity generally translates to improved planning returns; latent dynamics that capture task-relevant features enable efficient planning",
            "tradeoffs_observed": "Autoregressive pixel reconstruction can be costly; balancing reconstruction fidelity and latent compactness is necessary to maintain planning utility",
            "design_choices": "Combines deterministic RNN path with stochastic latent variables (RSSM), optimizes ELBO, performs planning in latent space",
            "comparison_to_alternatives": "Outperforms pixel-based planners and some model-free approaches in sample efficiency; motivates Dreamer-style end-to-end latent policy learning",
            "optimal_configuration": "Survey suggests RSSM + latent-space planning is a strong baseline; encourages latent transition models that avoid autoregressive pixel generation for long-horizon efficiency",
            "uuid": "e1268.1"
        },
        {
            "name_short": "Dreamer",
            "name_full": "Dreamer (Hafner et al.)",
            "brief_description": "An actor-critic framework that learns a latent world model (RSSM) and trains policy and value networks by backpropagating through imagined latent trajectories—enabling end-to-end learning in latent imagination.",
            "citation_title": "Dream to control: Learning behaviors by latent imagination",
            "mention_or_use": "mention",
            "model_name": "Dreamer",
            "model_description": "Uses an RSSM latent model to imagine trajectories; concurrently trains actor and critic networks inside latent imagination using gradients propagated through the learned dynamics; relies on reconstruction and latent prediction losses for model learning.",
            "model_type": "latent world model with integrated policy/value learning",
            "task_domain": "Atari, continuous control; extended to robot learning in later works",
            "fidelity_metric": "ELBO / reconstruction loss, KL regularization, and policy return (cumulative reward) used to evaluate both model fidelity and task success",
            "fidelity_performance": null,
            "interpretability_assessment": "Latent representation remains largely a neural black box; interpretability arises indirectly through the ability to generate realistic imagined sequences",
            "interpretability_method": "Visual inspection of imagined rollouts and decoded frames; diagnostic ablations to assess latent content",
            "computational_cost": "Higher than simple model-free baselines because of simultaneous model and actor-critic training and imagination rollouts, but inference/planning remains cheaper than pixel-level simulation",
            "efficiency_comparison": "Shown to outperform PlaNet's latent planning baseline and many model-free baselines in sample efficiency on benchmark tasks (survey does not provide numeric comparisons)",
            "task_performance": "Reported to achieve superior returns on multiple tasks versus baselines in original work, and later shown effective for real-robot online learning pipelines",
            "task_utility_analysis": "High-fidelity latent dynamics combined with integrated policy learning yields strong task performance; fidelity in dynamics is leveraged directly by policy gradients in imagination",
            "tradeoffs_observed": "End-to-end coupling of model and policy improves performance on trained tasks but can entangle representation with task-specific objectives, potentially reducing task-agnostic reuse",
            "design_choices": "Train world model + actor + critic jointly; use latent rollouts for policy/value updates; optimize ELBO and actor-critic objectives",
            "comparison_to_alternatives": "Demonstrated improved sample efficiency and performance over PlaNet (CEM planning) and many model-free methods on similar benchmarks",
            "optimal_configuration": "Survey highlights Dreamer as a strong configuration when joint model-policy optimization and sample efficiency are priorities; suggests trade-offs for generality",
            "uuid": "e1268.2"
        },
        {
            "name_short": "DreamerV2",
            "name_full": "Dreamer V2 / Discrete World Models (Hafner et al.)",
            "brief_description": "A further development of Dreamer replacing continuous stochastic latents with discrete latent variables and other improvements, achieving state-of-the-art performance on Atari among world-model-based agents.",
            "citation_title": "Mastering Atari with discrete world models",
            "mention_or_use": "mention",
            "model_name": "Dreamer V2 (Discrete World Models)",
            "model_description": "Discrete latent variant of RSSM combined with improvements in representation and training, enabling high-quality latent rollouts and superior performance on Atari benchmarks; still follows latent imagination + policy/value training paradigm.",
            "model_type": "latent world model with discrete latent codes",
            "task_domain": "Atari games; extended to control benchmarks and robotics",
            "fidelity_metric": "Prediction/reconstruction losses, discrete-latent ELBO variants, and environment return (game scores)",
            "fidelity_performance": null,
            "interpretability_assessment": "Discrete latent codes can improve interpretability (categorical factors easier to inspect) relative to continuous latent vectors, but direct mapping to semantics still limited",
            "interpretability_method": "Inspection of discrete code activations and their decoded rollouts; qualitative analysis of latent structure",
            "computational_cost": "Comparable or higher to continuous latent counterparts due to categorical modeling and potentially larger model capacity; still more efficient than pixel-level planning",
            "efficiency_comparison": "Reported to significantly outperform many model-free baselines on Atari (survey reports qualitative advantage but no numeric values)",
            "task_performance": "State-of-the-art among discrete world-model-based methods on Atari benchmarks at time of publication (exact scores not given in survey)",
            "task_utility_analysis": "Discrete latents improved downstream policy learning by providing stable, informative latent dynamics; high task performance stems from latent fidelity to task-relevant dynamics",
            "tradeoffs_observed": "Discrete latents improve stability and sometimes interpretability but may sacrifice smooth interpolation properties useful in certain continuous control contexts",
            "design_choices": "Switch from continuous to discrete latent representations, adjustments to training losses and model capacity to exploit categorical structure",
            "comparison_to_alternatives": "Outperformed previous Dreamer and PlaNet instantiations on Atari; suggests discrete latents are advantageous for complex, multi-modal pixel domains",
            "optimal_configuration": "Survey implies that discrete latent structures are a strong choice for complex visual tasks where categorical events dominate, but recommends evaluation per task type",
            "uuid": "e1268.3"
        },
        {
            "name_short": "Dreaming",
            "name_full": "Dreaming (Okada & Taniguchi)",
            "brief_description": "A world-model approach that replaces pixel reconstruction objectives with contrastive training in latent space, aiming to learn latent dynamics useful for control when reconstruction is misleading or infeasible.",
            "citation_title": "Dreaming: Model-based reinforcement learning by latent imagination without reconstruction",
            "mention_or_use": "mention",
            "model_name": "Dreaming",
            "model_description": "Latent dynamics model trained with contrastive objectives rather than pixel reconstruction; latent imagination is used to train policies, improving representation of task-relevant features when pixel-level reconstruction is hard or unnecessary.",
            "model_type": "latent world model (contrastive/discriminative training)",
            "task_domain": "RL from pixels, tasks that are difficult to reconstruct (e.g., sparse or high-variance observations), robotics",
            "fidelity_metric": "Contrastive loss (e.g., InfoNCE-like), downstream policy return, and latent prediction accuracy for task-relevant signals",
            "fidelity_performance": null,
            "interpretability_assessment": "Latent focuses on task-relevant discriminative features rather than full observation fidelity, which can improve interpretability in terms of task utility but not full scene reconstruction",
            "interpretability_method": "Evaluate downstream task performance and inspect latent activations for task-relevant correlations; no explicit symbolic extraction reported",
            "computational_cost": "Potentially lower than reconstruction-based models since avoiding image-pixel decoders reduces decoder compute and learning instability; cost still includes dynamics model and contrastive batch processing",
            "efficiency_comparison": "Reported to outperform reconstruction-based models on tasks that are hard to reconstruct, improving sample-efficiency and downstream returns for those tasks",
            "task_performance": "Improved performance on tasks where pixel reconstruction is detrimental; survey reports qualitative improvements (no numeric scores)",
            "task_utility_analysis": "By prioritizing task-relevant predictive features in the latent, Dreaming trades full observation fidelity for greater utility in policy learning",
            "tradeoffs_observed": "Sacrifices full generative fidelity (no pixel reconstruction) to gain better task-relevant representation and downstream policy performance",
            "design_choices": "Use contrastive/discriminative objectives for latent learning; perform imagination-based policy updates in latent space",
            "comparison_to_alternatives": "Performs better than VAE/reconstruction-based world models on tasks with high visual complexity or where reconstruction distracts from task signals",
            "optimal_configuration": "Survey recommends contrastive objectives when the goal is control/policy learning rather than accurate image generation, particularly in real-robot settings",
            "uuid": "e1268.4"
        },
        {
            "name_short": "NewtonianVAE",
            "name_full": "NewtonianVAE (Jaques et al.)",
            "brief_description": "A VAE variant that enforces a physical (Newtonian) structure in latent space — latents correspond to physical quantities (position, velocity) enabling proportional/PD control directly from latent states.",
            "citation_title": "NewtonianVAE: Proportional control and goal identification from pixels via physical latent spaces",
            "mention_or_use": "mention",
            "model_name": "NewtonianVAE",
            "model_description": "A variational autoencoder with inductive biases enforcing Newtonian dynamics in a low-dimensional latent space, producing latents aligned with interpretable physical state variables used directly for control.",
            "model_type": "latent world model with physics prior / structured latent",
            "task_domain": "Robotic manipulation and industrial tasks (e.g., precise connector/socket insertion)",
            "fidelity_metric": "Predictive consistency of physical latent variables, control error (position/force), and task success rate (e.g., successful insertion)",
            "fidelity_performance": null,
            "interpretability_assessment": "High interpretability: latent dimensions are designed to correspond to physical quantities (position, velocity), which enables direct inspection and use for controllers",
            "interpretability_method": "Impose physics-inspired regularizers and check latent-to-physical variable correlations; evaluate closed-loop control performance using latents",
            "computational_cost": "Lower inference and control complexity due to compact, structured latent; training cost includes enforcing dynamics constraints but decoder complexity is reduced compared to unconstrained pixel reconstructions",
            "efficiency_comparison": "Enables efficient control (e.g., PD controllers) in latent space and improved sample efficiency for control tasks by encoding physically-relevant variables",
            "task_performance": "Applied to real robot socket-insertion tasks achieving high-accuracy performance (survey references a successful real-robot experiment though no numeric success rates are given)",
            "task_utility_analysis": "Physical priors in latent space translate to direct control utility: high interpretability maps to better controller performance for precision tasks",
            "tradeoffs_observed": "Constraining latents to Newtonian form limits flexibility to model non-Newtonian or high-level semantics; good for control but may reduce generality for perception-heavy tasks",
            "design_choices": "Low-dimensional latent aligned with physics laws; dynamics regularization to obtain PD-controllable latent states",
            "comparison_to_alternatives": "More suitable than generic VAEs for precise control applications because latents map to control-relevant variables, at the cost of modeling general visual variability",
            "optimal_configuration": "Survey suggests physics-constrained latent spaces are optimal for tasks requiring precise control; the approach trades representational generality for interpretability and controller compatibility",
            "uuid": "e1268.5"
        },
        {
            "name_short": "Daydreamer",
            "name_full": "Daydreamer / World models for physical robot learning (Wu et al.)",
            "brief_description": "An extension of Dreamer-style latent world models tailored for physical robot learning, demonstrating an end-to-end pipeline for real-world data collection, online world-model learning, and control.",
            "citation_title": "World models for physical robot learning",
            "mention_or_use": "mention",
            "model_name": "Daydreamer (World models for physical robots)",
            "model_description": "Adaptation of latent world-model architectures (Dreamer family) to physical robot settings, integrating online data acquisition, latent-model updates, and control policies trained with imagined rollouts to enable sample-efficient real-world learning.",
            "model_type": "latent world model adapted for real-robot learning",
            "task_domain": "Physical robot learning and manipulation",
            "fidelity_metric": "Sample-efficiency (environment interactions required), task success rate, stability of online model updates, prediction error of latent rollouts",
            "fidelity_performance": null,
            "interpretability_assessment": "Not a primary focus; model prioritized robustness and sample efficiency rather than explicit interpretability",
            "interpretability_method": "Practical evaluation via robot task success and stability of imagined trajectories; no explicit interpretability tools emphasized in survey",
            "computational_cost": "Higher engineering and compute requirements due to real-time/online training on robot-collected data and safety/robustness constraints; inference uses latent rollouts which are cheaper than pixel simulations",
            "efficiency_comparison": "Reported to enable high sample-efficiency online robot learning compared to naive model-free approaches, enabling fewer real interactions for skill acquisition",
            "task_performance": "Survey cites high sample efficiency and successful robot tasks in related work (no exact numeric measures provided)",
            "task_utility_analysis": "World model fidelity in the latent domain directly supports policy learning on the robot; online updating helps adapt to real-world nonstationarity",
            "tradeoffs_observed": "Adapting to noisy real-world data increases engineering complexity and requires robust model updates; balancing model capacity, update frequency, and safety is challenging",
            "design_choices": "Pipeline design for online data collection, latent-model updates, and downstream policy learning; attention to robustness over pure generative fidelity",
            "comparison_to_alternatives": "More sample-efficient and practical for real robots than many model-free RL methods; requires more engineering and system-level design than pure-simulation approaches",
            "optimal_configuration": "Survey emphasizes integrated online learning pipelines and robust latent representations as key for real-robot world models",
            "uuid": "e1268.6"
        },
        {
            "name_short": "ContrastiveModels/CURL",
            "name_full": "Contrastive world-model approaches (e.g., CURL)",
            "brief_description": "Representation learning approaches that use contrastive/discriminative objectives instead of pixel reconstruction to learn latents that prioritize task-relevant features and improve downstream control.",
            "citation_title": "CURL: Contrastive unsupervised representations for reinforcement learning",
            "mention_or_use": "mention",
            "model_name": "Contrastive world-models (contrastive latent learning)",
            "model_description": "World models or encoders trained with contrastive objectives (InfoNCE-like) to produce embeddings where temporally/semantically related observations are close and unrelated ones are distant; can be combined with latent dynamics models for planning and control.",
            "model_type": "latent world model (contrastive/discriminative training)",
            "task_domain": "RL from pixels, robotics, tasks where reconstruction is expensive or misleading",
            "fidelity_metric": "Contrastive loss (e.g., InfoNCE), downstream policy return, representation quality measures (e.g., linear probe accuracy), and prediction of task-relevant signals",
            "fidelity_performance": null,
            "interpretability_assessment": "Latents emphasize task-relevant discriminative structure; full observation fidelity is not preserved, so interpretability is limited to task-relevant factors",
            "interpretability_method": "Representation probing and downstream task performance analyses; visualization of nearest neighbors in embedding space",
            "computational_cost": "Often more efficient than full pixel-decode models because they avoid heavy image decoders; contrastive training can require large batch sizes/augmentations",
            "efficiency_comparison": "Shown to improve sample-efficiency and downstream returns compared to reconstruction-based world models on many control tasks",
            "task_performance": "Improves policy learning in domains where pixel reconstruction is a poor proxy for task-relevant structure; survey cites qualitative improvements without numeric values",
            "task_utility_analysis": "By focusing on task-relevant features, contrastive latents often yield better policy performance even when generative fidelity is lower",
            "tradeoffs_observed": "Lose full generative fidelity and interpretability of the full observation, gaining task utility and sometimes compute efficiency",
            "design_choices": "Replace reconstruction objectives with contrastive losses; pair with latent dynamics models for latent imagination",
            "comparison_to_alternatives": "Outperforms reconstruction-based latent models on tasks with reconstruction-irrelevant variability; choice depends on whether task utility or full generative fidelity is required",
            "optimal_configuration": "Survey recommends contrastive objectives when downstream control/robustness is prioritized over full image generation fidelity",
            "uuid": "e1268.7"
        },
        {
            "name_short": "PredictiveCoding/ActiveInference",
            "name_full": "Predictive Coding / Free-Energy Principle / Active Inference (Friston et al.)",
            "brief_description": "A normative probabilistic framework from neuroscience proposing hierarchical generative models whose top-down predictions are compared with bottom-up inputs; actions and perceptions minimize variational free energy (prediction error), enabling perception, learning, and action selection.",
            "citation_title": "Active inference: the free energy principle in mind, brain, and behavior",
            "mention_or_use": "mention",
            "model_name": "Predictive coding / Active inference",
            "model_description": "Hierarchical probabilistic generative models (often PGMs) where higher levels predict lower-level activity; variational free energy (ELBO-like) is minimized for inference and action; expected free energy used for planning (epistemic + pragmatic value). Implementations vary from small PGMs to deep amortized networks.",
            "model_type": "probabilistic generative framework / model-based inference approach",
            "task_domain": "Robotics (perception, body estimation, manipulation), cognitive modeling, exploration and active perception",
            "fidelity_metric": "Variational free energy / ELBO (prediction error + KL regularization), expected free energy for planning; behavior measured by reduction of prediction error and task success",
            "fidelity_performance": null,
            "interpretability_assessment": "High-level conceptual interpretability (prediction errors, hierarchical signals, precision-weighting) but concrete implementations may remain complex; offers principled mapping between model variables and cognitive constructs",
            "interpretability_method": "Precision-weighting analysis, hierarchical error units, tracing prediction-error signals across levels; mapping to behavioral phenomena",
            "computational_cost": "Potentially high because full Bayesian inversion over complex generative models is costly; practical implementations rely on amortized variational inference, sampling, or approximations to scale",
            "efficiency_comparison": "Promises data-efficiency via principled epistemic drives and amortized inference, but scaling to high-dimensional inputs (images) is challenging; recent works combine with deep networks to improve scalability",
            "task_performance": "Applied to robot body perception, manipulation, active perception, and social inference producing adaptive behaviors; concrete performance depends on implementation and task (no universal numeric claims in survey)",
            "task_utility_analysis": "Unifies perception and action; expected free energy gives an elegant formal solution to exploration-exploitation; model fidelity to sensory dynamics directly supports effective active perception/control",
            "tradeoffs_observed": "Principled normative framework offers interpretability and unified objectives but at the cost of computational scalability and engineering complexity for high-dimensional real-world tasks",
            "design_choices": "Hierarchical predictive coding with precision-weighting, expected free energy for planning; use of amortized inference and contrastive/deep methods to scale implementations",
            "comparison_to_alternatives": "Offers a normative complement to model-based RL and control-as-inference (CaI); strong conceptual advantages for epistemic exploration but requires practical approximations to match performance of deep RL in high-dim domains",
            "optimal_configuration": "Survey recommends hybrid solutions: combine active inference principles with amortized deep inference, structural inductive biases (objects, physics), and contrastive objectives for scalability and task utility",
            "uuid": "e1268.8"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "World models",
            "rating": 2,
            "sanitized_title": "world_models"
        },
        {
            "paper_title": "Dream to control: Learning behaviors by latent imagination",
            "rating": 2,
            "sanitized_title": "dream_to_control_learning_behaviors_by_latent_imagination"
        },
        {
            "paper_title": "Learning latent dynamics for planning from pixels",
            "rating": 2,
            "sanitized_title": "learning_latent_dynamics_for_planning_from_pixels"
        },
        {
            "paper_title": "Mastering Atari with discrete world models",
            "rating": 2,
            "sanitized_title": "mastering_atari_with_discrete_world_models"
        },
        {
            "paper_title": "Dreaming: Model-based reinforcement learning by latent imagination without reconstruction",
            "rating": 2,
            "sanitized_title": "dreaming_modelbased_reinforcement_learning_by_latent_imagination_without_reconstruction"
        },
        {
            "paper_title": "NewtonianVAE: Proportional control and goal identification from pixels via physical latent spaces",
            "rating": 2,
            "sanitized_title": "newtonianvae_proportional_control_and_goal_identification_from_pixels_via_physical_latent_spaces"
        },
        {
            "paper_title": "World models for physical robot learning",
            "rating": 2,
            "sanitized_title": "world_models_for_physical_robot_learning"
        },
        {
            "paper_title": "CURL: Contrastive unsupervised representations for reinforcement learning",
            "rating": 2,
            "sanitized_title": "curl_contrastive_unsupervised_representations_for_reinforcement_learning"
        },
        {
            "paper_title": "Active inference: the free energy principle in mind, brain, and behavior",
            "rating": 2,
            "sanitized_title": "active_inference_the_free_energy_principle_in_mind_brain_and_behavior"
        }
    ],
    "cost": 0.027358249999999997,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Survey Paper World Models and Predictive Coding for Cognitive and Developmental Robotics: Frontiers and Challenges
January 18, 2023 14 Jan 2023 January 18, 2023</p>
<p>Tadahiro Taniguchi 
Department of Information Science and Engineering
Ritsumeikan University
1-1-1 Noji-HigashiKusatsuShigaJapan</p>
<p>Shingo Murata 
Keio University
Japan</p>
<p>Masahiro Suzuki 
The University of Tokyo
Japan</p>
<p>Dimitri Ognibene 
Università Milano-Bicocca
Italy</p>
<p>University of Essex
UK</p>
<p>Pablo Lanillos 
Donders Institute for Brain
Cognition and Behaviour
Netherlands</p>
<p>Cajal International Neuroscience Center
Spanish National Research Council
Spain</p>
<p>Emre Ugur 
Bogazici University
Turkey</p>
<p>Lorenzo Jamone 
Queen Mary University of London
UK</p>
<p>Tomoaki Nakamura 
The University of Electro-Communications
Japan</p>
<p>Alejandra Ciria 
National Autonomous University of Mexico
Mexico</p>
<p>Bruno Lara 
Universidad Autónoma del Estado de Morelos
Mexico</p>
<p>Giovanni Pezzulo 
Institute of Cognitive Sciences and Technologies
National Research Council of Italy
Italy</p>
<p>Survey Paper World Models and Predictive Coding for Cognitive and Developmental Robotics: Frontiers and Challenges</p>
<p>Advanced Robotics
xx,No.xxJanuary 18, 2023 14 Jan 2023 January 18, 2023released April 2021)Advanced Robotics main Advanced Robotics mainWorld modelcognitive roboticspredictive codingfree-energy principleactive inferencedeep generative models *
Creating autonomous robots that can actively explore the environment, acquire knowledge and learn skills continuously is the ultimate achievement envisioned in cognitive and developmental robotics. Importantly, if the aim is to create robots that can continuously develop through interactions with their environment, their learning processes should be based on interactions with their physical and social world in the manner of human learning and cognitive development. Based on this context, in this paper, we focus on the two concepts of world models and predictive coding. Recently, world models have attracted renewed attention as a topic of considerable interest in artificial intelligence. Cognitive systems learn world models to better predict future sensory observations and optimize their policies, i.e., controllers. Alternatively, in neuroscience, predictive coding proposes that the brain continuously predicts its inputs and adapts to model its own dynamics and control behavior in its environment. Both ideas may be considered as underpinning the cognitive development of robots and humans capable of continual or lifelong learning. Although many studies have been conducted on predictive coding in cognitive robotics and neurorobotics, the relationship between world model-based approaches in AI and predictive coding in robotics has rarely been discussed. Therefore, in this paper, we clarify the definitions, relationships, and status of current research on these topics, as well as missing pieces of world models and predictive coding in conjunction with crucially related concepts such as the free-energy principle and active inference in the context of cognitive and developmental robotics. Furthermore, we outline the frontiers and challenges involved in world models and predictive coding toward the further integration of AI and robotics, as well as the creation of robots with real cognitive and developmental capabilities in the future.</p>
<p>Introduction</p>
<p>How can we develop robots that can autonomously explore the environment, acquire knowledge, and learn skills continuously? Creating autonomous cognitive and developmental robots that can co-exist in our society has been considered an ultimate goal of cognitive and developmental robotics and artificial intelligence (AI) since the inception of these fields. Autonomous robots that can develop in the real world and collaborate with us may also be called embodied artificial general intelligence (AGI). The recent success of artificial intelligence depends primarily on large-scale human-annotated data. However, human infants can acquire knowledge and skills from sensorimotor information through physical interactions with their environment and social interactions with others (e.g., their parents or caregivers). Importantly, the aim is to build robots that can continuously develop through embodied interactions, their learning process must be strongly based on their own sensorimotor experiences. This autonomous learning process that occurs throughout development is also referred to as continual or lifelong learning [1][2][3], and is considered the foundation for the emergence of both individual and social abilities necessary for robots with adaptive and collaborative capabilities.</p>
<p>Recently, world models have attracted renewed attention in artificial intelligence [4][5][6][7]. Now, the term "world" does not indicate the objective world but rather refers to a world understood from a robot's point of view 1 . This idea corresponds to that of Umwelt proposed by Uexküll [9]. Umwelt, literally around-world, meaning environment or surroundings, refers to the self-centered world of an organism perceived through its species-specific sensors 2 . Therefore, notably, the world model is different from the bird's-eye model of the world that was aimed to build in good-old-fashioned AI and criticized later [12] 3 . A cognitive system learns a world model to predict its future sensory observations better and optimize its policies, also referred to as controllers. Note that although typically the term "world model" is used to denote the spatiotemporal dynamics of the external environment, it could also equally apply to bodily dynamics (including interoceptive signals from inside the body) and the social environment. This world-model view entails previous ideas and results, such as the effect of behavioral feedback on sensory sampling and perceptual learning [14] and the resulting acquisition of self-centered, yet efficient, representations induced by an active perception strategy on the part of an agent [15].</p>
<p>Predictive coding is another related theory that recently has become more and more influential [16]. It is heavily influenced by Helmholtz's early theories of perception as a process driven by learning, knowledge, and inference [17]. Predictive coding proposes that the brain infers the external causes of sensations by continuously predicting its input through top-down signals and adapts to minimize prediction error [18,19]. This substantiates the idea that the brain might use an adaptive world model to support perception. The free energy principle (FEP) also proposes a similar vision. It argues that our brain supports both perception (perceptual inference) and action (active inference) using a form of variational Bayesian inference; in particular, using (variational) free energy, it assesses the quality of the prediction and its conformity to prior beliefs [20]. These ideas, which are currently influential in neuroscience and cognitive science, are also used in cognitive and developmental robotics, neurorobotics [21][22][23], and artificial intelligence to develop neurodynamics realizing adaptive behaviors and social perception [24].</p>
<p>Although such a learning-driven world model-based approach is promising in cognitive and developmental robotics, the many applications and studies of world models tend to be limited to simulation studies or adopt an offline pretrained world model [25]. Meanwhile, many studies based on predictive coding have been conducted in the field of cognitive robotics and neurorobotics. However, the relationship between the world model-based approach in AI and the predictive coding-based approach in robotics has rarely been discussed in an integrated manner. We believe that clarifying the definition, 1 This viewpoint may be called a robot's subjective point of view of the world. Philosophically, however, whether robots can have a "subjective" point of view remains controversial [8]. Therefore, we describe this point of view simply as "a robot's point of view". 2 Importantly, the relationship between Umwelt and world modeling was suggested in semiotics. Sebeok pointed out that the closest equivalent of Umwelt in English is "model" [10]. An Umwelt is created and constructed through a functional cycle, which includes 1) anticipation of a perceptual cue, 2) perception, 3) working out a relation between the perception and action (either simply executing a habit or using representation, or modeling anew), and 4) action (operation) [11]. 3 Also, notably, the world-model approach is different from behavior-based robotics [13], which does not learn world models. Figure 1. Overview of challenges and relationships between topics described in this survey. A robot, similar to a human, receives sensations x, infers internal states z, exhibits actions a, and affects causes E in the social and physical environment. The initial problem is determining the models and architecture that a robot uses to efficiently and effectively learn latent representations. An approach to this problem uses a neurosymbolic predictive model, which combines neural network and symbolic models. The notion of object affordance highlights the importance of object-centric representation learning and the coupling of action and perception. Social interaction with other agents is also an important area of research. Developing artificial intelligence for cognitive and developmental autonomous robots based on knowledge of neuroscience, i.e., brain-inspiredworld models, is promising. Creating cognitive architecture and developing and sharing software frameworks for this purpose will also be an important frontier. relationship, current state of the art, notable research gaps in work on world models, predictive coding, free-energy principle, and active inference in the context of cognitive and developmental robotics is important for further progress in this field. Based on the current status, we elucidate the frontiers and challenges toward this holy grail in cognitive and developmental robotics.</p>
<p>In this survey paper, we aim to build bridges and clarify the challenges and frontiers of world models and predictive coding in cognitive robotics. The remainder of this paper is structured as follows. Section 2 provides a working definition of each key concept. Section 3 describes prior works related to the concepts and clarifies state of the art. Section 4 describes some notable challenges. Some additional discussion is provided in Section 5, and we conclude the work in Section 6.</p>
<p>Working definition</p>
<p>World model</p>
<p>World models describe the internal models of an agent, which encodes how world states evolve, respond to agents' actions, and relate to a given sensory input [4,26]. The term world model dates back to the beginnings of artificial intelligence and robotics [27]. Early research in machine learning studied how an agent could independently acquire and adapt a world model to [28,29]. Currently, it usually refers to predictive models [30], which are mainly encoded using deep neural networks.</p>
<p>In recent years, advancements in the studies on deep neural networks have enabled self-supervised (or unsupervised) learning 4 of large-scale world models directly from observations (sensory inputs) [26,31,32], and these models have been applied in various areas of artificial intelligence, including reinforcement learning (RL). World models allow agents to perform a sample-efficient prediction of the present state of the world and enable the prediction of future states, which further enables efficient planning (equivalent to model-based reinforcement learning or control). A compact internal representation further enables planning in an efficient low-dimensional space.</p>
<p>The key elements of world models are prediction and inference 5 . Prediction is the probabilistic process of generating the observation x given the state (or representation) z, whereas inference is the process of obtaining a state representation z from an observation x in a probabilistic manner. In real-world settings, observations x are large (high-dimensional, e.g., images) and provide only partial information about the world (partial observability). At the same time, the latent representation z is assumed to represent the internal state of the world. In a static case, these can be summarized as the generative processes of probability distributions as follows.</p>
<p>Prediction:</p>
<p>x ∼ p(x|z)
Inference: z ∼ q(z|x),(1)
where p is a generative model and q is an inference (or recognition) model 6 . These models are considered parameterized in deep neural networks. When these models are trained simultaneously, generative approaches (e.g., variational autoencoders [38]) are employed [26]. There are also cases where only an inference model is trained, in which case a discriminative approach (e.g., contrastive learning [39]) is used 7 .</p>
<p>In the most common conditions, the state of the environment (and agent body) and the observations evolve over time in response to the agent's actions. In such cases, the state z is often assumed to satisfy Markov conditions. In turn, due to typical sensory limitations such as limited field of view or occlusions, the environment is assumed to follow a partially observable Markov decision process (POMDP) [34]. That is, when the current internal state of the environment is z t (where the subscript represents a discrete time step), performing an action a t causes the internal state to transition to z t+1 and the corresponding x t+1 is observed. In the POMDP case, the prediction and inference models are given as follows.
Prediction (transition): z t ∼ p(z t |z t−1 , a t−1 ) Prediction (generation): x t ∼ p(x t |z t ) Inference: z t ∼ q(z t |x 1:t , a 1:t−1 ),(2)
where x 1:t denotes the set of observations from the first step (x 1 ) to step t (x t ). To learn a state space model (SSM) on the time interval 1 to T , a variational approach can be adopted that maximizes the following objective [6,30,41]: 5 The use of these terms is sometimes incongruent in the literature on statistics and machine learning; the word inference is also used to describe prediction or substituted by other concepts, such as encoding and decoding in the literature on (variational) autoencoders. 6 In classical formulations of control theory [33], AI [34], and probabilistic robotics [35], the inference step is performed by exactly inverting the prediction probability p using the Bayes theorem. However, this poses several computational challenges and is often intractable. For dealing with such complexity, sampling-based approximate inference can be performed using Monte Carlo methods [36,37]. In the context of world models and predictive coding, variational Bayes approaches are often preferred [20]. Variational Bayes involves the definition of an approximate inference distributionq. Amortized inference allows us to approximate the q(x) using a neural network, which is called an inference network, and obtain an inference model q(x|a) [38]. 7 However, recently, studies have also shown that contrastive learning can be interpreted as a generative approach [40]. Therefore, the boundary between generative and discriminative approaches is, to a certain extent, blurred.
log p(x 1:T |a 1:T −1 ) ≥ T ∑ t=1 E q(z t |x 1:t ,a 1:t−1 ) [log p(x t |z t )] (Negative) prediction error − E q(z t−1 |x 1:t−1 ,a 1:t−2 ) [D KL [q(z t |x 1:t , a 1:t−1 )||p(z t |z t−1 , a t−1 )]] Regularization ≡ T ∑ t=1 L t ,(3)
where the first term in Eq. (3) represents the prediction error (or reconstruction error) of the observation, and the second term represents the regularization for the state representation (so that the transition model and the inference model yield the same state representation).</p>
<p>Predictive coding and the free-energy principle</p>
<p>The original predictive coding model provided by Rao and Ballard [18] was proposed as a model of visual processing in the brain. The model assumes a hierarchically organized neural network, and topdown and bottom-up interactions at each hierarchical level are considered. In the top-down process, higher levels generate predictions about lower-level neural activities, and the lowest level generates sensory predictions. In the bottom-up process, residual errors between the predictions and actual activities (or sensory inputs) are computed and used to correct the originally generated predictions at each level. Predictive coding models learn spatial and temporal statistical regularities at each level for efficient coding and to reduce the redundancy of the predicted activity of lower levels [42,43]. The main principle behind this hierarchical predictive coding cortical organization in the brain is prediction error minimization (PEM) [19,44,45]. This idea based on the principle of PEM has been extended to various cognitive processes, and this framework is usually referred to as predictive processing [16,46,47]. This approach is being recently used also in machine learning to learn robust generative models of data [48]. The principle of PEM can be situated within a more general principle of free-energy minimization because the amount of variational free energy, the core information measure used in the FEP, can be understood, under simplifying assumptions, as the amount of prediction error [19,45,49]. The variational free energy F t , which is an upper bound on the surprise − log p(x t |x 1:t−1 , a 1:t−1 ), is the negative value of the evidence lower bound (ELBO) L t introduced in Eq. (3) as follows.
−L t = F t = −E q(z t |x 1:t ,a 1:t−1 ) [log p(x t |z t )] Prediction error + E q(z t−1 |x 1:t−1 ,a 1:t−2 ) [D KL [q(z t |x 1:t , a 1:t−1 )||p(z t |z t−1 , a t−1 )] Regularization = D KL [q(z t |x 1:t , a 1:t−1 )||p(z t |x 1:t , a 1:t−1 )] Divergence − log p(x t |x 1:t−1 , a 1:t−1 ) Evidence ≥ − log p(x t |x 1:t−1 , a 1:t−1 ) Surprise .(4)
From the second line of Eq. (4), when observations are assumed to follow a Gaussian distribution with a fixed variance, minimizing the variational free energy is equivalent to minimizing the sum of mean squared errors and a regularization term. The FEP is a mathematical formulation of how self-organizing systems, such as biological agents, brains, and cells, are able to maintain an equilibrium with their environment by means of minimizing variational free energy, or the surprise associated with sensations 8 [44,50,51]. In the FEP, different cognitive processes such as perception and action can be understood as different ways to minimize the variational free energy in terms of probabilistic inference called active inference [52][53][54] as detailed in the next subsection.</p>
<p>Active inference and exploration</p>
<p>Active inference is a normative framework that derives from the FEP and provides a unifying account for perception, control, and learning in terms of minimization of the variational free energy in the past, present, and future. This unification is important in neuroscience as it reflects neural mechanisms and on a computational level because it offers new perspectives and the possibility of sharing algorithmic solutions between all these functions and transforming them into sophisticated robotic behaviors [23]. For example, perception aims to minimize the variational free energy in the past and present by inferring the latent representations of observed sensory inputs 9 , e.g., when an orange appears in the field of view instead of the apple as currently encoded in the internal representation, the representation state can change toward that of an orange [19]. Conversely, actions try to minimize the variational free energy in the present by actively sampling sensory inputs, e.g., by moving the gaze away from the orange toward an apple. In addition to selecting an action in the present, agents can infer a sequence of future actions (or policy) that elicit the most plausible future states [53][54][55][56] by considering the minimization of expected free energy, as detailed below.</p>
<p>While active inference introduces an important perspective towards an understanding of adaptive and autonomous behaviors, an obvious behavioral imperative, the exploration-exploitation dilemma, seems in conflict with this idea because exploration, i.e., observing an uncertain aspect of the environment, would result in obtaining an unpredictable outcome [57,58]. Indeed exploration and active perception have a central role in robot control and learning. Several tasks focus on robots' ability to explore an unknown environment [59][60][61]. Furthermore, in social contexts, unobservable factors such as others' intentions must be actively considered to allow for efficient human-robot collaboration [62][63][64][65].</p>
<p>However, in [20,54,66], the authors showed that active inference can easily support exploratory behaviors and that it can provide an elegant formal solution for the exploration-exploitation dilemma.</p>
<p>In fact, we must consider that planning behaviors for an extended period of time require anticipating future data. More specifically, to infer the best action sequences (policies), one must also predict the future observations they would produce. This is realized in the active inference framework by minimizing the expected free energy over a time interval T . We can express this as the sum of two terms, including i) the variational information gain term [62,[67][68][69], or epistemic value [54], defined as the expected KL divergence between the distribution of the latent states conditioned on the expected observations q(z t+1:T |x t+1:T , a t:T −1 ) and the prior distribution on the latent states q(z t+1:T |a t:T −1 ) that represents the reduction in uncertainty on the latent states z t+1:T provided by the expected observations x t+1:T , and ii) the extrinsic or pragmatic value log p(x t+1:T |C), where C denotes the agent's preferences. This results in the following expression 10 .
G(a t:T −1 ) = − E q(z t+1:T ,x t+1:T |a t:T −1 ) [D KL [q(z t+1:T |x t+1:T , a t:T −1 )||q(z t+1:T |a t:T −1 )]] E pistemic value − E q(x t+1:T |a t:T −1 ) [log p(x t+1:T |C)] Pragmatic value .(5)
The epistemic value term favors obtaining observations that disambiguate the world state such as obtaining the address for the best apple shop in town, versus observations that correspond to multiple (aliased) state such as corridors in a mall. Without the factor of variational information gain, asking the address of the shop would not be preferred to any other action that would not immediately result in obtaining an apple. Thus, minimizing expected free energy corresponds to maximizing the sum of epistemic and pragmatic values over an extended period and defines the optimal trade-off between exploration and exploitation. The similarity between the epistemic value term in Eq. (5) and the divergence term in Eq. (4) with an inverted sign may be noted. This is due to the different role that observations play in expected free-energy formulation, where they comprise not observed data but expected observations. Finally, the 9 This perception can be regarded as a variational Bayesian version of the original predictive coding that employs a maximum a posteriori (MAP) estimation [44]. 10 Note that in the literature on active inference, a sequence of actions a t:T −1 is referred to as a policy π. This policy is different from a policy in reinforcement learning, where it represents a statistical mapping from states to actions (π(a t |s t )). Using this notation of the policy π and mean-field approximation, the general formulation of the expected free energy can be described by the following more practical formulation.
G(π) = − ∑ T τ=t+1 E q(xτ |π) [D KL [q(z τ |x τ , π)||q(z τ |π)]] − E q(xτ |π) [log p(x τ |C)],
where the time step τ &gt; t used here is a future time step. Figure 2. Researches of world models. Left: Dreamer [30] and Dreaming [78]. Right: robot control system using NewtonianVAE [79].</p>
<p>close connection between variational free energy (Eq. (4)), expected free energy (Eq. (5)), used in this context to define behaviors with exploration capabilities, and ELBO (Eq. (3)), used to model learning processes objectives, shows the versatility of this type of formulation, the extension and refinement of which currently a promising field of research that aims to develop an autonomous system with the ability to efficiently acquire and execute complex skills [69]. For a more advanced and detailed presentation, we refer to [20,54,69,70]. Another important framework that considers behaviors as inference is planning or control as inference (CaI) [71][72][73][74][75]. The main difference between CaI and active inference is that CaI introduces a binary optimality variable O t that represents whether an action a t in state z t is optimal (or preferred) [75,76]. If the reward for taking action a t in state z t is r (z t , a t ), the conditional distribution of the optimality variable is defined as follows.
p (O t = 1 | z t , a t ) ≡ exp (r (z t , a t )) .(6)
Thus, unlike active inference, CaI can introduce the value of the reward at each time explicitly and independently of the observation's generative model 11 . CaI aims to obtain the optimal policy p(a t |z t ) for inference. If the variational inference is chosen as a solution to the intractability of exact inference (as with active inference), we seek the policy that maximizes the following ELBO 12 .
log p(O 1:T ) ≥ E ∏ T t=1 p(a t |z t )p(z t |z t−1 ,a t−1 ) T ∑ t=1 r (z t , a t ) + H (p (a t | z t )) ,(7)
where H represents the entropy. This corresponds to the entropy-regularized expected reward, and reinforcement learning with this as the objective is called entropy-regularized reinforcement learning [77].</p>
<p>Prior works</p>
<p>World models and model-based reinforcement learning in AI and robotics</p>
<p>In this section, we describe world models used in model-based reinforcement learning in the context of artificial intelligence and robotics. Time-series world models conditioned on behavior have been studied for policy learning for some time. Schmidhuber proposed learning an agent's policy (utility) via an RNN-based world model obtained by self-supervised learning [28]. Based on this idea, Ha et al. introduced a large-scale world model consisting of a VAE and an RNN that learned directly from observations (time-series images) from the external world [5]. They showed that the policies of agents trained only on this world model, which learns a game environment, can work properly in real game environments. Since this study, research has been conducted on self-supervised learning of models of an environment directly from observations, along with ideas referred to as "world models". However, the authors trained spatial compression (VAE) and temporal transitions (RNN) separately; thus, the perspective of learning state representations was not considered.</p>
<p>Subsequently, VAE-based models that simultaneously learn time transitions and spatial compression have been proposed. Kaiser et al. proposed a VAE-based world model with discrete latent variables designed to predict the next frame and reward from the stacked frames of the previous four steps and the current action and showed that model-based reinforcement learning using this model performed adequately in an Atari video game environment with high sample efficiency [80]. One limitation of this model is that it does not include RNNs and cannot account for long-term prediction. Moreover, the measures are learned from the observation space, so the learned representation is not fully exploited. Ke et al. showed that learning long-term transitions using a stochastic RNN-based world model contributes to high performance on tasks that require long-term prediction [81]. All of these models, however, are autoregressive, requiring the generation of a high-dimensional observation space every step for long-term prediction, and are unable to transition within the latent space.</p>
<p>Recently, models that learn transitions in latent space without requiring autoregressive generation have been widely used. Hafner et al. introduced a recurrent state space model (RSSM) that includes RNNs in SSM and showed that it could be used for long-term prediction and model-based reinforcement learning with higher performance than model-free learning [41].</p>
<p>While PlaNet [41], the first study using RSSM, used an existing model-based planning method (crossentropy method) for planning in the latent space 13 , Dreamer [30], a subsequent method, explicitly modeled the policy and value function in neural networks and learned a world model through gradients in an actor-critic framework, resulting in a better performance than PlaNet. This model has been further developed by replacing the latent variables with discrete values, which significantly outperformed model-free performance in Atari game environments (Dreamer V2 [6]), and by using contrastive learning instead of reconstruction, which resulted in higher performance on tasks that were difficult to reconstruct (Dreaming [78], see the left side of Fig. 2). They were also combined and compared (Dreaming V2 [83]).</p>
<p>In terms of obtaining a good state representation for control, enforcing explicit constraints on transitions is preferable. For example, NewtonianVAE was able to form PD-controllable state space [84]. However, to develop such a model, what kind of state representation the world model should acquire (as a good representation for control) should be considered, which remains as yet relatively unclear (see section 4.1 for details).</p>
<p>These world models have been shown to be effective in learning using real robots. Okumura et al. successfully applied the NewtonianVAE to a robot and enabled it to perform a precise socket insertion task <a href="see the right side of Fig. 2">79</a>. Wu et al. showed that Dreamer V2 enabled real robots to perform online learning with very high sample efficiency and performance, which includes a pipeline of acquiring data through interaction with the external world, learning a world model, and controlling the robot using the model [7]. However, all of these results are for a single environment and task, and what kinds of world models should be acquired for robot control in diverse environments and tasks remains unclear.</p>
<p>Predictive coding and active inference in cognitive and developmental robotics</p>
<p>In recent years, an increasing body of research has considered predictive coding models for perception and action in robotics. Recent comprehensive reviews on active inference and predictive processing in robotics can be found in [21,23], respectively. These ideas aim to provide a general mathematical Figure 3. Research on predictive coding and active inference in cognitive robotics. Left: adaptation to environmental changes by prediction error minimization [89]. Right: body perception and action by pixel-based deep active inference [99]. account of behavior. Importantly, they incorporate adaptation and robustness to current methods in cognitive and developmental robotics.</p>
<p>Since the early works of Tani et al. using hierarchically organized RNNs [85], a variety of methods have been proposed to exploit this idea of prediction-error-minimization or propagation. "Higher levels" (internal representation) generate predictions about the dynamics of the "lower levels" up to the sensorimotor level. Prediction errors at the sensorimotor level, given the observations, are then propagated "upwards" in the hierarchy correcting the internal state and thus minimizing the errors. Extensions of Tani's approach allow multiple time scales [86][87][88][89] (see the left side of Fig. 3), stochasticity [90,91] and stochastic latent representations [92]. In particular, a precision-weighting mechanism for the PEM enabled robots to extract stochastic or fluctuating structures of temporal sensorimotor sequences and utilize the extracted structures for their action generation [91]. Interestingly, this mechanism is related to the precision account in psychiatric disorders [93] (especially autism spectrum disorder [94,95]) and several works have proposed cognitive robot models based on aberrant-precision to model unusual perception and action [96][97][98].</p>
<p>Aside from hierarchical RNNs, active inference controllers for robotic manipulators [100,101] and humanoid robots [22,99] have also been developed based on Lanillos's initial work on predictive coding adaptive perception and learning [102,103] for both low-dimensional and high-dimensional inputs (see the right side of Fig. 3). These methods have widespread applications such as object manipulation [104], imitation [104], language acquisition [105], social interaction [106] and navigation [107].</p>
<p>Cognitive robots benefit from predictive coding mechanisms to infer others' actions [108]. The reuse of common circuits for both movement generation and action estimation seems to be a key principle in the sensorimotor organization. Recently, the authors of [109] proposed deep modality blending networks (DMBN) designed to create a common latent space from the multi-modal experience of a robot by blending multi-modal signals with a stochastic weighting mechanism. Using a state-of-the-art skill-encoding system referred to as Conditional Neural Movement Primitives (CNMPs) [110], they showed that deep learning could facilitate action recognition and produce structures to sustain anatomical (mirror-like) and effect-based imitation capabilities when combined with a novel modality-blending scheme.</p>
<p>Current state-of-the-art research is focusing on scaling active inference in planning tasks [51] with high-dimensional inputs [32,111] and improving representation learning through multimodal common latent space [109] or introducing structural inductive biases, such as objects [112]. Whilst active inference is a promising framework for robotics [113], current works are still limited to a particular aspect of cognitive and developmental processes. Therefore, in addition to extending the scalability of computational frameworks, continual or lifelong learning for developing abilities from low-level sensorimotor skills to higher-order cognitive functions should also be considered.</p>
<p>Frontiers and Challenges</p>
<p>Latent representations for action planning</p>
<p>One of the most important challenges in world-model approaches of any kind is that of efficiently performing planning, in the sense of generating meaningful actions to solve a sequential task [114]. Working in the high-dimensional space of the sensorimotor manifold is very computationally expensive and provides local optima solutions [99]. In fact, current approaches in planning use a compressed encoded representation of the world dynamics, which aids in the process of predicting future states and in action generation [26]. In reinforcement learning, state representation learning is tied to learned tasks to achieve high performance because it depends on the actions needed to obtain the maximum expected reward [30]. However, this sometimes prevents generalization across tasks. Decoupled actionrepresentation world models are an interesting work-around [39]. In deep active inference [23] amortized methods have also been considered [32,115], in addition to contrastive [116] and iterative amortized inference approaches [112].</p>
<p>However, the key question cannot be narrowed down to that what type of architecture or method should be used. Rather, what type of information should be encoded in the latent representation and how this information is processed must be a key focus so that information is not uncoupled from the sensorimotor process, particularly from motor control, which is a key limitation of existing endeavors in robotics. There has been considerable discussion as to what would comprise an appropriate state representation of a world model; that is, what inductive bias or prior knowledge should be given [117][118][119]. Here, we list the properties of this prior knowledge we consider important.</p>
<p>• Low dimensionality. Observations obtained from the environment are high-dimensional, and compressing this information into a low-dimensional space is critical for efficient data handling, abstraction, and planning. This approach is the most frequently considered in state representation learning. The challenge is how best to represent observations in a low-dimensional encoding while retaining the necessary task-dependant information. Recent literature focused on generative and discriminative approaches to tackle this. • Meaningful abstraction and disentanglement. Low-dimensional representations should have scene-understanding and task meaning, such as objects [112], locations [120] and temporal events [121]. Representation disentanglement proposes that factors of variation with different semantics should be separated, contributing to the requirements for sufficiency and efficiency in state representation. Object-centric representation learning is related to this hypothesis, [112,122], in which every observed object is encoded independently. • Compositionality. Although disentanglement aims to separate independent factors, the agent should also acquire their relationships and hierarchy. In the case of object representations, there should also be relations or implication relations among objects. Currently, methods such as those using graph neural networks are being considered, but they do not provide an essential solution. This idea of the compositionality of representation is also relevant to the neuro-symbolic approach. • Dynamics prediction. These three properties are important not only for learning representations in static environments but in dynamic worlds, e.g., they consider a transition model that depends on external factors and agent actions. The best latent representation is one that allows transitions to be easily predictable for given actions. Many recent models use RNNs to learn transitions, which incorporate information on long-term dependence [30,41]. One way to make transitions more predictable is to incorporate prior knowledge of the physical world (e.g., dynamics following Newton's laws of motion [84]). Furthermore, by learning to separate representations that are not related to control from state representations, representations that are easier to control can be acquired [123]. • Values are sufficiently encoded. To perform reinforcement learning on the state representation of the world model, the value of the state representative to the agent must be known. For example, a recurrent state representation learns to predict the reward from the state so that the reward is embedded in the representation [30]. However, because the value of the state changes depending on the task, it remains unclear whether this hypothesis should be introduced in a world model that should acquire a prediction model that is as task-independent as possible. Alternatively, in active inference approaches, the agent value function cannot be modified, and it is defined by expected free energy. Here, the challenge becomes learning the state preferences and being able to predict the transitions that may yield those preferences. • Task-agnostic. Representations should be informative to solve narrow problems where the agent is trained but also sufficiently general to be reused in tasks with different kinds of variability or new tasks that the agent has never encountered. • Fusion of multiple-types multimodal information. Robots inevitably face a variety of events with their multimodal sensorimotor systems. Observations given to world models are from multiple sources (e.g., social non-social, sensorimotor purely sensorial, and linguistic and nonlinguistic). They can have different reliability and volatility and represent various aspects of the world. Therefore, the world models must properly encode the internal representation in a stable and efficient manner.</p>
<p>These are some of the elements that we identified that a latent representation should be fulfilled to provide a smooth connection with real-world interaction and provide power for solving cognitive tasks. Importantly, abstract representation and disentanglement, such as objects or events encoding, may be important to achieve efficient planning, reducing the gap for neuro-symbolic solutions. However, the connection between the low-dimensional (and hierarchical) encoding and the synchronization with the sensorimotor control remains a major challenge.</p>
<p>Neuro-symbolic predictive models</p>
<p>In this section, we provide an overview of state-of-the-art techniques in which symbols and rules are discovered and used by robots through neuro-symbolic approaches. The term symbols, here, refers to manipulative discrete representations used in symbolic AI and cognitive science. The neuro-symbolic approach attempts to integrate conventional symbolic and modern neural network-based AIs. Both biological and artificial agents benefit from predictive coding mechanisms for reasoning, decision-making, and planning. Predictive forward models are used to generate plans that involve a sequence of actions. For example, chimpanzees are known to generate multi-step plans that include stacking a number of boxes on top of each other, grabbing a long stick, climbing on top of a stack of boxes, and using the stick to reach the object that was initially out of reach [124,125]. While the underlying cognitive mechanisms for high-level planning remain unknown, different specific brain regions have been shown to become active in inductive and deductive reasoning in humans [126] while predicting the effects of actions [127]. In artificial agents, on the other hand, standard search and planning rely heavily on manually coded or learned state transitions and prediction models [128,[10][11].</p>
<p>The seminal work of [129] addressed the learning of discrete representations of predictive models, i.e., dynamic Bayesian networks, by discretizing the continuous features of the environment to plan goal-directed arm/hand control. [130] showed the units generated by slow feature analysis with the lowest eigenvalues resemble symbolic representations that highly correlate with high-level features, which might be considered precursors for fully symbolic systems. [131,132] studied methods to discover useful symbols that can be directly utilized in problem and domain definition language (PDDL) for various agent settings. In simulation and the real world, the discovered symbols were directly used as predicates in the action descriptions to generate deterministic and probabilistic symbolic plans. [133] learned symbols in the ego-centric frame of the agent to transfer the learned symbols into novel settings. [134,135] discovered symbols in the continuous perceptual space of the robots for PDDL-based manipulation planning via combining several machine learning algorithms such as X-means clustering and support vector machine (SVM) classification. Although the symbols were discovered by the robot without any human intervention, the continuous perceptual features were manually encoded by the authors. Towards an endto-end framework, [136] used directly raw camera image and pixel values to discover symbols via a novel deep predictive coding neural architecture. In detail, they proposed a deep encoder-decoder network with a binary bottleneck layer designed to take a camera image and an action as input and output the action effects in pixel coordinates. The binary activations in the bottleneck layer encode object symbols that not only depend on the visual input but are also shaped based on action and effect. In other words, the objects that provide the same affordances [137] were automatically grouped together as object symbols. To distill the knowledge represented by the neural network into rules useful for symbolic reasoning, a decision tree was trained to reproduce its decoder function. Probabilistic rules were extracted from the effect predictor / neural decoder and encoded in the probabilistic PDDL, which can be directly used by the off-the-shelf AI planners. In follow-up work, [138] used a multi-head attention mechanism to learn symbols to encode affordances of a varying number of objects.</p>
<p>Asai et al. implemented a neural framework where a state autoencoder with a discrete bottleneck layer was trained first, and preconditions and effects of actions were learned next [139]. In follow-up work, [140] combined the previous two systems and discovered action preconditions and effects together with visual symbols. These works were realized in visual environments such as 2-D puzzles and achieved visualized plan executions. An important aspect of pure visual neuro-symbolic systems and studies on neuro-symbolic robotics is that in robotics, predictive coding over object symbols takes actions and effects into account in addition to the features of objects and the environment, which facilitates the formation of symbols that are likely to capture object affordances [141][142][143][144].</p>
<p>However, in the context of world models, methods to integrate prior symbolic knowledge into VAE and SSM-based world models are still being explored. The bottom-up formation of symbolic representations is closely related to disentanglement and compositionality discussed in Section 4.1. Moreover, leveraging linguistic knowledge in world modeling is a challenge in relation to neuro-symbolic predictive models.</p>
<p>Affordance perception</p>
<p>Affordance perception has often been discussed independently of world models, but in fact, it is closely related. According to the original definition provided by Gibson [141,145,146], an affordance is an action possibility offered to the agent by the environment. A stable surface may afford to be traversed; a stone may afford the possibility of being used as a hammer; a door handle may afford the possibility of being opened. The concept of affordances and affordance perception has then been further analyzed and revisited in psychology, neuroscience, cognitive science, artificial intelligence, and robotics (see [143] for a recent survey). The ability to perceive affordances is crucial for any biological or artificial agent to interact successfully with the environment.</p>
<p>Central to the idea of affordances is that the action possibilities depend on both the agent and the environment; the same environment would offer different action possibilities to different agents, depending on their sensorimotor capabilities. A stable surface affords the possibility of traversal to an agent that is able to locomote and whose body dimensions fit the size of the surface borders; a stone affords the possibility of being used as a hammer to an agent who is able to pick it and who has enough force to lift it; a door handle affords to open to an agent who knows how to open doors, assuming it is well-designed [147]. Therefore, those affordances must be learned autonomously by the agent. In fact, the agent must learn how to perceive them. The means by which agents perceive affordances are those of ecological perception, powerfully illustrated by Eleanor Jack Gibson [148][149][150]: "narrowing down from a vast manifold of (perceptual) information to the minimal, optimal information that specifies the affordance of an event, object, or layout" [150, p.284]. The agent must learn what minimal information is to be picked; this happens both through evolution and development, leveraging the sensorimotor exploration of the environment by physical interaction.</p>
<p>Interestingly, while exploring the action possibilities, the agent can learn the effects of those actions as well. This is crucial for biological agents and turns out to be extremely useful for artificial systems as well. In fact, most computational models of affordances in robotics rely on representations that include not only the action but also the effects (or in other terms, the goal) of the action [108,110,[151][152][153][154][155][156][157][158][159][160][161][162]; therefore, the perceived possibilities for actions (and for achieving certain effects) can be used for action planning, leading to problem-solving [163]. Such comprehensive models of affordances are, in fact, world models; they are internal models of how the world behaves "in the eyes" of the learning agent, and they can be used by the agent to make predictions about how the world will change if certain actions are performed. Therefore, it is not surprising that the computational techniques used for learning affordance models often overlap with those used for learning world models [164]. It is worth noting that, in world model approaches, a robot only receives raw sensory information and needs to extract the relevant semantics from such data flow; therefore, to successfully integrate affordance perception in these systems, the challenges of meaningful abstraction/disentanglement and object-centric representation learning, described in Section 4.1, are particularly relevant.</p>
<p>Social interaction</p>
<p>Robots' "worlds" do not consist of physical objects alone but also of social entities, i.e., people who give them social guidance and try to cooperate with them. World models should model and predict social dynamics involving people's behaviors, and infer their latent variables, e.g., intentions and emotions, to cooperate with them, that is, to control social phenomena.</p>
<p>Efficient and safe human-robot collaboration and interaction are some of the main research objectives of robotics and have important practical applications [165][166][167][168][169][170][171]. Associating beliefs, intentions, or mental states to other agents, theory of mind, or, in other words, trying to predict the internal state of another agent's world model to understand its activities and context [172], is an essential aspect of human interaction [173][174][175] and has attracted attention in robotics [176].</p>
<p>Mutual understanding using a world model in social interaction can play an important role when complex interactions are challenging the perceptual systems of the agents, inducing a mismatch between their interpretation of the current context [177,178]. It is also crucial when different levels of knowledge and expertise induce different representations of a domain, as well as different points of view, which may induce conflictual interactions [179] or different support strategies [180]. For example, the perspective of an automotive mechanic and that of an ordinary user differ considerably, so collaboration may be difficult if one cannot properly infer the internal state of others. A robots' world model can play a crucial role in its operation and functionality [181].</p>
<p>The recent progress in machine learning methods has resulted in substantial improvement in action recognition methodologies [65,[182][183][184]. However, this approach has often focused on shallow and purely perceptual representations of the observed activities resulting in limited flexibility in terms of contexts, tasks, and observed actors demanding a substantial amount of difficult-to-collect data and retraining time to apply the system in relatively similar conditions [185]. Approaches such as goal recognition as planning or inverse planning [166,[186][187][188], that, given a model of the environment, understand others' activities by computing plans that would result in the observed actions have shown the flexibility advantage delivered in intention recognition by a world model. Several works have extended this approach. The problem of dealing with behaviors generated under partial observability, which may require inferring both the plan and the beliefs, the mental state [176,178], of the observed actor, was studied with both classical planning [189] and Bayesian approaches [177,190]. The impact of missing observations for the observer agent has also been analyzed [189]. A further step has been proposed by active methods for activity recognition [62,191,192] that use the same world model both to interpret others' actions as well as selecting actions that would improve the recognition process, e.g., by giving access to the most informative observations [63] and allow the completion of a joint task [180]. While even the initial formulations of this approach were computationally aware [186], their efficiency is often affected by the length of the observed behavior and the environment complexity, resulting in methods that can seldom be applied online on a robot. Several models proposed a pre-compile approach that transformed the world into a form that would allow efficient plan recognition [185]. The adoption of hierarchical world model representations has also been considered to constrain the computational and modeling costs of the process [193][194][195]. Precomputed and robust local plans, in the form of the same motor controllers that the robot uses to perform its own actions, have also been adopted to allow active perception for action recognition and prediction on humanoid robots [62,172]. One of the main issues of the approach, also related to computational efficiency considerations, is relying on specific algorithms for planning that aiming for the optimal plan may misinterpret the bounded rational behaviors that collaborators may perform. This problem was faced by using online Bayesian inference in [196].</p>
<p>The additional flexibility provided by world models in social interaction skills is likely relevant beyond activity recognition. It is easy to imagine that purely supervised models may be limited in terms of perspective-taking and the ability to reason based on the world structure may help to adapt to partners with different sensory systems [176,[197][198][199]. Similarly, world models are likely to help with imitation learning by dealing with embodiment mismatch between the observed actor and the learner [200]. Finally, physical cooperation [201,202] and signaling [203,204] would also be more flexible when integrating world and partner models in the equation, for example, to account for the trust of the human cooperator towards the robot [205]. Finally, a world model may also be learned through socially rich experiences and sources of information (e.g., imitation [200] or verbal instructions) in addition to the results of autonomous exploration. However, developing a robust, efficient, and flexible enough representation may prove to be one of the main challenges in this effort.</p>
<p>Brain-inspired world models</p>
<p>In cognitive science, it has long been postulated that the brain learns small-scale models of the world and uses these models for various cognitive functions, such as perception, planning, and imagination [206]. For example, theories of perception-as-inference described perception as an inferential process, which works by "inverting" a generative model of how the percepts are generated [207,208]. As discussed above, these ideas (and others) have been recently formalized under the label of the Bayesian Brain [209] and extended by Active Inference from the domain of perception to other domains, such as action planning and interoception [20].</p>
<p>In parallel, there have been many attempts to describe mathematically and to assess the neuronal underpinnings of world models and of inference processes empirically (e.g., [210]). One question that has received a great deal of attention is how the brain might encode internal world models in the neuronal substrate. Given that the brain models are often assumed to be probabilistic, various formal schemes have been proposed that describe plausible neuronal implementations of probabilistic variables and of Bayesian inference over these variables, such as, for example, probabilistic population codes [211] and sampling schemes [212]. These attempts show that (probabilistic, generative) world models could be at least potentially implemented in neuronal substrate [213,214] -and even updated after statistical learning [215] -but the specific scheme(s) that the brain might use for this remain to be fully assessed.</p>
<p>Another relevant question is what algorithms the brain might use to perform inference over world models. A strong candidate in neuroscience is predictive coding [18,19]. Several studies have aimed to validate its key empirical predictions, showing that under the appropriate conditions, it is possible to observe predictions [216], prediction errors [217] and other signatures of inference in brain signals [218] and that neural activity in lower visual areas in the absence of bottom-up inputs could be explained by the top-down, feedback dynamics postulated by predictive coding [219]. These and other studies (see [220] for a recent review) lend some support for predictive coding, but the theory remains under development.</p>
<p>At yet another level, one may ask what the systems-level architecture that supports world models and whether different parts of the brain might model different aspects of the world is. Anatomical considerations suggest that the brain is not a monolithic entity but rather is composed of several areas and networks [221]; however, the extent to which these areas or networks are modularized and how they exactly influence each other are heavily discussed [222]. One interesting consideration is that cortical brain areas in humans and monkeys appear to be organized along principal gradients (defined by functional connectivity); in one of these gradients, heteromodal areas (e.g., prefrontal cortex) are placed at the top, and unimodal areas (e.g., primary visual area) at the bottom, recapitulating the structure of a putative hierarchical generative model [223]. Another interesting consideration is that there seems to be a "division of labor" between brain pathways that perform complementary computations, such as the two visual pathways for processing "what" and "where" information [224]. These anatomical and functional separations might be potentially interpreted as useful factorizations of the brain generative models. A whole-brain probabilistic generative model (WB-PGM) approach attempts to build a cognitive architecture for cognitive and developmental robots integrating probabilistic generative model (PGM)-based modules referring comprehensive knowledge of human and animal brain architectures and their anatomy [225].</p>
<p>The above studies indicate that at a general level, both neuroscience and machine learning / AI conceive world models and inference in similar ways. However, at a more detailed level, there might be profound differences between the ways these two disciplines use the same concepts. Predictive coding and other biological schemes proposed in neuroscience exploit top-down dynamics (and recurrences) in ways that are rarely used in machine learning. Furthermore, brain information processing is heavily based on spontaneous brain dynamics, which are largely absent in machine learning systems; see [226][227][228] for a detailed discussion of putative computational roles of spontaneous dynamics. Moreover, it is plausible to assume that different parts of the brain might be specialized (or might have different inductive biases) to process different statistical regularities, rendering them able to learn and model (for example) slower or faster dynamics of the visual scenes, one's own body, the actions of other agents, or extended temporal events [229]. It is worth highlighting here that, although prediction errors have a central role in learning, there are other forms of statistical learning, such as those based on Hebbian associative learning [230]. It remains to be understood how to best endow our more advanced machine learning systems with the ability of the brain to perform (apparently) specialized computations but also orchestrate them coherently. Finally, it is important to remember that the brain is an evolved system, and our more advanced cognitive abilities are grounded in (the neuronal mechanisms supporting) simpler sensorimotor skills [231,232]. Trying to develop advanced cognitive systems without the necessary requirements for embodied interaction and "phylogenetic refinement" might lead to solutions that differ completely from how the brain works -or that fail altogether.</p>
<p>Cognitive architectures</p>
<p>Truly cognitive and developmental robots, i.e., embodied AGI, that behave autonomously and flexibly in the real environment would have a wide range of sensors and exhibit multiple functions. That requires a large-scale world model that deals with multimodal sensory observations and multilayered state representations. Considering the discussion in Section 4.5, such word models may be factorized in a proper manner from engineering and biological viewpoints. To realize embodied AGIs, further frameworks and architectures to factorize a total world model into cognitive modules and to integrate individual cognitive capabilities into a cognitive system are required. The idea is related to cognitive architectures, which have been studied in cognitive science, artificial intelligence, and robotics [233,234].</p>
<p>In cognitive science, cognitive functionalities such as memory, perception, and decision-making are implemented as modules in the cognitive architectures studied, and the specific task can be solved by activating these modules coordinately. ACT-R [235] and Soar [236] are representatives of cognitive architectures. It has been shown that the model implemented by ACT-R can explain the time to solve the task by humans, and activation patterns of the brain can be predicted by activation patterns of the modules [237]. Furthermore, Soar has been used for controlling robots [238] and learning games [239]. However, complex machine learning methods that have rapidly advanced in a decade are not introduced yet. Sigma [240,241] is a newer cognitive architecture that introduces the generative flow graph, a generalized probabilistic graphical model. Therefore, the model can be implemented using probabilistic programming techniques [242][243][244]. Furthermore, the concept of the standard model of the mind is discussed through a synthesis across these three cognitive architectures [222]. Particularly, cognitive architectures based on first principles, e.g., with a general computation scheme, such as free energy minimization [19], are especially attractive. The architecture for social cognition has also been proposed [245]. The authors point out that these architectures explained above are incomplete in dealing with the social aspect of cognition and describe the elements of architecture for social cognition. Clarion [246] is another cognitive architecture based on dual process theory [247]. In this architecture, each subsystem is composed of explicit and implicit processes, and it is shown that the interaction between implicit-explicit processes can explain psychological phenomena.</p>
<p>In robotics, several types of cognitive architecture have been proposed. One of them is ArmarX [248], which has three layers, including a middleware layer, a robot framework layer, and an application layer. This three-layered structure simplifies the development robotics software easier. (Neuro-)Serket [249,250] is another approach to integrating cognitive modules 14 . In (Neuro-)Serket, modules are described by the (deep) PGM and trained mutually by exchanging messages between modules. To make it easy to develop large-scale models, the modules in Neuro-Serket are weakly connected through the Serket interface. (Neuro-)SERKET is closely related to the world model-based approach because SER-KET requires each module to be a PGM, i.e., a model based on prediction and inference as Eq. (1), and integrate modules into a large PGM. This architecture does not provide any restrictions regarding the functionalities of modules. Therefore, it has high flexibility but brings high dimensional design space at the same time. To reduce the large degree of freedom in the design space, a brain-inspired approach, WBA-PGM, was proposed [225]. In this approach, a cognitive model was constructed by connecting PGM-based modules utilizing knowledge from neuroscience. By referring to the brain studies, WBA-PGM constrains the function of modules and their connection and reduces the design space of the cognitive model.</p>
<p>There are two crucial requirements for cognitive architecture for cognitive and developmental robots, which can be used along with the approach based on world models and predictive coding. The first is the engineering aspect which is seen in (Neuro-)Serket and ArmarX. The scale of cognitive models that enables the robots to behave flexibly in the real environment is very large, and many modules must be connected and work collaboratively. Furthermore, the model needs to introduce machine learning techniques that are not only existing as well as those will be developed in rapid progress. The development of such a model would require a massive engineering effort, and this is considered a notable obstacle to realizing such robots. Therefore, architecture is needed to simplify development. Another requirement is that of the scientific aspect seen in ACT-R, Soar, WBA-PGM, and Clarion. Developing AGI, which is human-like intelligence, referring to the knowledge regarding humans obtained in cognitive science and neuroscience, can accelerate its development. However, meeting these two aspects completely is very challenging. All machine learning techniques and module connections might necessarily be not reasonable from the point of view of cognitive science and neuroscience. On the other hand, entire humans are not understood yet. Therefore, finding common ground between engineering and science aspects and developing a novel cognitive architecture is a current challenge. Developing a large-scale cognitive architecture and overcoming the problems described in the previous subsections is also a challenge.</p>
<p>Discussion</p>
<p>As we described, world models and predictive coding are promising approaches in cognitive and developmental robotics. Before closing this paper, we will mention some remaining issues which have not been addressed in the main body sufficiently.</p>
<p>Language and world models: Umwelts, i.e., worlds from first-person views, of biological systems are not monolithic but have some sort of structure. Notably, language and symbolic systems have syntactic structures. The interaction between high-level cognitive capabilities, e.g., language and reasoning, and low-level cognitive capabilities, e.g., perception and action, is essential in world modeling. Recently, large-scale language models (LLMs) have been replacing many natural language processing methods [251,252], including reasoning tasks, which have been conducted solely by symbolic AI by the end of 2010s [253,254]. Recently, the use of LLMs in robotics has been attempted, e.g., [255]. It is clear that language learning and understanding by robots is itself a frontier [256]. To leverage the symbolic knowledge in LLMs, integration of LLMs and world models will be an important challenge.</p>
<p>This shift from models of artificial symbols in conventional AI to models of natural language, i.e., a human symbol system, is resonating with the discussion in symbol emergence in cognitive and developmental systems [257][258][259]. An important topic is then considering not only the integration of human language into robots' world models in a top-down manner but also the bottom-up formation of symbol systems, including language in relation to world models.</p>
<p>Policy representations: How should the policies of robots be represented? Conventionally, policies are described as feedback controllers π(z t , a t ) = p(a t |z t ) in reinforcement and imitation learning. Even though one direction of world model approaches is to explore task agnostic representations (Section 4.1), the decomposition of world modeling and policy learning can be controversial. In a conventional approach of world models, policies (π = p(a t |z t ) or a t:T ) and world models (p(z t+1 |z t , a t ) and p(o t |z t )) are decoupled. In contrast, a series of studies about predictive coding in neuro-robotics have been intentionally entangling policies and world models and making robots directly learn p(o t+1 , a t+1 |o 1:t , a 1:t ) and exhibiting many successful results in robotics, e.g., [24,260,261]. As the notion of affordance also suggests, actions and perceptions are not independent and entangled, generally. The question "to what extent should we decouple world model and policy representations?" should be investigated.</p>
<p>From artificial cognition to human cognition: Cognitive and developmental robotics are also constructive approaches to human developmental cognition. Not only learning from neuro-, cognitive and developmental sciences but also provide with scientific feedback to them is also an important mission. Building a virtuous circle between studies on human and artificial studies is a challenge.</p>
<p>The constructive approach may give us a novel approach to scientific and philosophical hard problems like self-awareness [262] and consciousness. The relationship between the multimodal world model and global workspace theory was suggested [263]. Extending the discussion between world models and consciousness using robots may be an exciting challenge. Moreover, the relationship between predictive coding and emotion is worth exploring to build emotional robots and understand the emotions of biological systems [264][265][266].</p>
<p>Software frameworks for implementation: To accelerate the studies on world models and predictive coding in robotics, the development framework for cognitive and developmental robotics is crucially important. In robotics, not only AI "software" frameworks but also middle-ware are important. Recently, ROS has been widely used in the robotics community for bridging hardware and AI software layers. Developing and sharing such software frameworks as a community will be important, e.g., [267]. Moreover, the world model involves many types of knowledge, and the knowledge can be used for achieving multiple functions via active inference. The software framework should allow the world model to efficiently organize the knowledge and to perform (cross-modal) active inference. A great initiative is the discrete state-space active inference python library [268]. However, it can only be used for toy examples due to scalability issues and to be useful in cognitive and developmental robotics. It needs further development. For instance, the support for high-dimensional input observations and the possibility of combining discrete and continuous action and state representations are something that has been addressed in robotic approaches [23].</p>
<p>Data-efficient and autonomous learning: A generalist agent called GATO was developed based on Transformers and shown to be able to solve various tasks with one neural network [269]. Although the approach is superficially different, the approach is really related to the world models and the predictive coding approach. However, the learning system is hugely data-hungry. It is very questionable if the model can be regarded as a model of human intelligence. Moreover, to train the generalist agent, researchers need to prepare a large dataset and simulation environment. Human children can autonomously explore their environment and acquire data through active exploration. Moreover, they use heuristics and biases in their developmental process. Learning and considering the human developmental process will give us the inspiration to build real generalist agents. Developing a data-efficient autonomous learning architecture with world models and predictive coding at its core is the key to a truly cognitive and developmental system.</p>
<p>Emergence of behaviors: Should an agent have a completely internal model of its world? Lastly, we raise fundamental speculation about the world model-based approach. Behaviors are not externalization of internally designed trajectories but something to emerge through the interaction between the body and the environment. For example, it has been proven by passive walking machines that the behavior of walking emerges only from the interaction between the body and the environment, without any computation by the brain [270]. About three decades ago, Brooks famously advocated the physical grounding hypothesis together with subsumption architecture, saying the world is its own best model [271]. The robots behaved smoothly and flexibly without any explicit world models. This is also referred to as morphological computation, which means the body itself implicitly processes information dynamically [272,273]. Soft robotics emphasizes these points nowadays. Combining the viewpoints of the emergence of behaviors with complex physical dynamics and the world model-based approach is another important challenge.</p>
<p>Conclusion</p>
<p>In this survey paper, we have aimed to clarify the frontiers and challenges of world models and predictive coding in cognitive and developmental robotics. Creating an autonomous robot that can actively explore the real environment, acquire knowledge, and learn skills continuously is the ultimate goal of cognitive and developmental robotics. To make the robot continuously develop through active exploration, the robot's learning process should be based on sensorimotor information obtained through physical and social interactions with the physical and social environment. Following the motivation, this paper reviewed studies related to world models and predictive coding in cognitive and developmental robotics and related AI studies. We clarified the definition of world model and predictive coding in robotics, in conjunction with those of FEP and active inference, and discussed the relationship between them. We also introduced state-of-the-art and research gaps of studies on world models and predictive in robotics. We described six frontiers and challenges, i.e., latent representations for action planning, neuro-symbolic predictive models, affordance perception, social interaction, brain-inspired world models, and cognitive architecture. Through the survey and clarification of challenges, we provided future directions for developing cognitive and developmental robots based on world models and predictive coding.
 Self-supervised learning is a type of unsupervised learning that aims to accomplish a task by learning to predict or classify any part of unsupervised data from any other part. In contrast to self-supervised learning, unsupervised learning includes clustering.
In contrast to states of surprise, free-energy can be measured because it is a function of sensory input and the inferred state[45] 
Therefore, unlike active inference, CaI does not require the assumption of POMDP.12 Here, MDP is assumed, i.e., state z t is an observed variable rather than a latent variable; if POMDP is assumed, inference and generative models for observations are added to this ELBO.
PlaNet was extended to be uncertainty-aware on the basis of Bayesian inference[82].
Neuro-SERKET is an updated version of SERKET.</p>
<p>Developmental robotics: a survey. Connection science. M Lungarella, G Metta, R Pfeifer, G Sandini, 15Lungarella M, Metta G, Pfeifer R, Sandini G. Developmental robotics: a survey. Connection science. 2003; 15(4):151-190.</p>
<p>Continual learning for robotics: Definition, framework, learning strategies, opportunities and challenges. Information fusion. T Lesort, V Lomonaco, A Stoian, D Maltoni, D Filliat, N Díaz-Rodríguez, 58Lesort T, Lomonaco V, Stoian A, Maltoni D, Filliat D, Díaz-Rodríguez N. Continual learning for robotics: Definition, framework, learning strategies, opportunities and challenges. Information fusion. 2020;58:52- 68.</p>
<p>A continual learning survey: Defying forgetting in classification tasks. M De Lange, R Aljundi, M Masana, S Parisot, X Jia, A Leonardis, G Slabaugh, T Tuytelaars, IEEE transactions. 447De Lange M, Aljundi R, Masana M, Parisot S, Jia X, Leonardis A, Slabaugh G, Tuytelaars T. A contin- ual learning survey: Defying forgetting in classification tasks. IEEE transactions on pattern analysis and machine intelligence. 2021;44(7):3366-3385.</p>
<p>World model learning and inference. K Friston, R J Moran, Y Nagai, T Taniguchi, H Gomi, J Tenenbaum, Neural Networks. 144Friston K, Moran RJ, Nagai Y, Taniguchi T, Gomi H, Tenenbaum J. World model learning and inference. Neural Networks. 2021;144:573-590.</p>
<p>. D Ha, J Schmidhuber, arXiv:180310122World models. arXiv preprintHa D, Schmidhuber J. World models. arXiv preprint arXiv:180310122. 2018;.</p>
<p>Mastering Atari with discrete world models. D Hafner, T Lillicrap, M Norouzi, J Ba, arXiv:201002193. 2020arXiv preprintHafner D, Lillicrap T, Norouzi M, Ba J. Mastering Atari with discrete world models. arXiv preprint arXiv:201002193. 2020;.</p>
<p>P Wu, A Escontrela, D Hafner, K Goldberg, Abbeel P Daydreamer, arXiv:220614176. 2022World models for physical robot learning. arXiv preprintWu P, Escontrela A, Hafner D, Goldberg K, Abbeel P. Daydreamer: World models for physical robot learn- ing. arXiv preprint arXiv:220614176. 2022;.</p>
<p>Could a robot have a subjective point of view. J Kiverstein, Journal of Consciousness Studies. 147Kiverstein J. Could a robot have a subjective point of view? Journal of Consciousness Studies. 2007; 14(7):127-139.</p>
<p>A stroll through the worlds of animals and men: A picture book of invisible worlds. Semiotica. Von Uexküll, J , 89Von Uexküll J. A stroll through the worlds of animals and men: A picture book of invisible worlds. Semiot- ica. 1992;89(4):319-391.</p>
<p>Biosemiotics: Its roots, proliferation, and prospects. T A Sebeok, Semiotica. Sebeok TA. Biosemiotics: Its roots, proliferation, and prospects. Semiotica. 2001;:61-78.</p>
<p>Umwelt and modelling. In: The routledge companion to semiotics. Routledge. K Kull, Kull K. Umwelt and modelling. In: The routledge companion to semiotics. Routledge. 2009. p. 65-78.</p>
<p>. R Brooks, Intelligence without representation. Artificial Intelligence. 471-3Brooks R. Intelligence without representation. Artificial Intelligence. 1991;47(1-3):139-159.</p>
<p>Behavior-based robotics. R C Arkin, R C Arkin, MIT pressArkin RC, Arkin RC, et al.. Behavior-based robotics. MIT press. 1998.</p>
<p>Environmentally mediated synergy between perception and behaviour in mobile robots. P F Verschure, T Voegtlin, R J Douglas, Nature. 4256958Verschure PF, Voegtlin T, Douglas RJ. Environmentally mediated synergy between perception and behaviour in mobile robots. Nature. 2003;425(6958):620-624.</p>
<p>Ecological active vision: four bioinspired principles to integrate bottom-up and adaptive top-down attention tested with a simple camera-arm robot. D Ognibene, G Baldassare, IEEE transactions on autonomous mental development. 71Ognibene D, Baldassare G. Ecological active vision: four bioinspired principles to integrate bottom-up and adaptive top-down attention tested with a simple camera-arm robot. IEEE transactions on autonomous mental development. 2014;7(1):3-25.</p>
<p>Whatever next? Predictive brains, situated agents, and the future of cognitive science. A Clark, Behavioral and Brain Sciences. 363Clark A. Whatever next? Predictive brains, situated agents, and the future of cognitive science. Behavioral and Brain Sciences. 2013;36(3):181-204.</p>
<p>Helmholtz Hv, Handbuch der physiologischen optik. Leipzig: Leopold VossIIIHelmholtz Hv. Handbuch der physiologischen optik, vol. III. Allgemeine Encyklopädie der Physik, Leipzig: Leopold Voss. 1867;.</p>
<p>Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. R P Rao, D H Ballard, Nature Neuroscience. 21Rao RP, Ballard DH. Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nature Neuroscience. 1999;2(1):79-87.</p>
<p>A theory of cortical responses. K Friston, Philosophical transactions of the Royal Society B: Biological sciences. 360Friston K. A theory of cortical responses. Philosophical transactions of the Royal Society B: Biological sciences. 2005;360(1456):815-836.</p>
<p>Active inference: the free energy principle in mind, brain, and behavior. T Parr, G Pezzulo, K J Friston, MIT PressParr T, Pezzulo G, Friston KJ. Active inference: the free energy principle in mind, brain, and behavior. MIT Press. 2022.</p>
<p>Predictive processing in cognitive robotics: a review. A Ciria, G Schillaci, G Pezzulo, V V Hafner, B Lara, Neural Computation. 335Ciria A, Schillaci G, Pezzulo G, Hafner VV, Lara B. Predictive processing in cognitive robotics: a review. Neural Computation. 2021;33(5):1402-1432.</p>
<p>An empirical study of active inference on a humanoid robot. G Oliver, P Lanillos, G Cheng, IEEE Transactions on Cognitive and Developmental Systems. Oliver G, Lanillos P, Cheng G. An empirical study of active inference on a humanoid robot. IEEE Transac- tions on Cognitive and Developmental Systems. 2021;.</p>
<p>P Lanillos, C Meo, C Pezzato, A A Meera, M Baioumy, W Ohata, A Tschantz, B Millidge, M Wisse, C L Buckley, arXiv:211201871Active inference in robotics and artificial agents: Survey and challenges. arXiv preprintLanillos P, Meo C, Pezzato C, Meera AA, Baioumy M, Ohata W, Tschantz A, Millidge B, Wisse M, Buck- ley CL, et al.. Active inference in robotics and artificial agents: Survey and challenges. arXiv preprint arXiv:211201871. 2021;.</p>
<p>Exploring robotic minds: actions, symbols, and consciousness as self-organizing dynamic phenomena. J Tani, Oxford University PressTani J. Exploring robotic minds: actions, symbols, and consciousness as self-organizing dynamic phenom- ena. Oxford University Press. 2016.</p>
<p>How to train your robot with deep reinforcement learning: lessons we have learned. J Ibarz, J Tan, C Finn, M Kalakrishnan, P Pastor, S Levine, The International Journal of Robotics Research. 404-5Ibarz J, Tan J, Finn C, Kalakrishnan M, Pastor P, Levine S. How to train your robot with deep reinforcement learning: lessons we have learned. The International Journal of Robotics Research. 2021;40(4-5):698-721.</p>
<p>Recurrent world models facilitate policy evolution. D Ha, J Schmidhuber, 31Advances in neural information processing systemsHa D, Schmidhuber J. Recurrent world models facilitate policy evolution. Advances in neural information processing systems. 2018;31.</p>
<p>Shakey the robot. N J Nilsson, Tech RepNilsson NJ, et al.. Shakey the robot. 1984. Tech Rep.</p>
<p>Making the world differentiable: On using self-supervised fully recurrent neural networks for dynamic reinforcement learning and planning in non-stationary environments. Inst. für Informatik. J Schmidhuber, Schmidhuber J. Making the world differentiable: On using self-supervised fully recurrent neural networks for dynamic reinforcement learning and planning in non-stationary environments. Inst. für Informatik. 1990.</p>
<p>Integrated architectures for learning, planning, and reacting based on approximating dynamic programming. R S Sutton, Machine learning proceedings. ElsevierSutton RS. Integrated architectures for learning, planning, and reacting based on approximating dynamic programming. In: Machine learning proceedings 1990. Elsevier. 1990. p. 216-224.</p>
<p>Dream to control: Learning behaviors by latent imagination. D Hafner, T Lillicrap, J Ba, M Norouzi, arXiv:191201603arXiv preprintHafner D, Lillicrap T, Ba J, Norouzi M. Dream to control: Learning behaviors by latent imagination. arXiv preprint arXiv:191201603. 2019;.</p>
<p>End-to-end training of deep visuomotor policies. S Levine, C Finn, T Darrell, P Abbeel, The Journal of Machine Learning Research. 171Levine S, Finn C, Darrell T, Abbeel P. End-to-end training of deep visuomotor policies. The Journal of Machine Learning Research. 2016;17(1):1334-1373.</p>
<p>Deep active inference for partially observable mdps. O Van Der Himst, P Lanillos, Active inference. Verbelen T, Lanillos P, Buckley CL, De Boom CChamSpringer International Publishingvan der Himst O, Lanillos P. Deep active inference for partially observable mdps. In: Verbelen T, Lanillos P, Buckley CL, De Boom C, editors. Active inference. Cham: Springer International Publishing. 2020. p. 61-71.</p>
<p>A new approach to linear filtering and prediction problems. R E Kalman, Journal of Basic Engineering (Transactions of the American Society of Mechanical Engineers). Kalman RE. A new approach to linear filtering and prediction problems. Journal of Basic Engineering (Transactions of the American Society of Mechanical Engineers). 1960;:35-45.</p>
<p>Acting optimally in partially observable stochastic domains. A R Cassandra, L P Kaelbling, M L Littman, In: Aaai. 94Cassandra AR, Kaelbling LP, Littman ML. Acting optimally in partially observable stochastic domains. In: Aaai. Vol. 94. 1994. p. 1023-1028.</p>
<p>Probabilistic robotics. S Thrun, W Burgard, D Fox, MIT PressThrun S, Burgard W, Fox D. Probabilistic robotics. MIT Press. 2005.</p>
<p>Bayesian filtering: From kalman filters to particle filters, and beyond. Z Chen, Statistics. 1821Chen Z, et al.. Bayesian filtering: From kalman filters to particle filters, and beyond. Statistics. 2003; 182(1):1-69.</p>
<p>Particle filters in robotics. S Thrun, Proceedings of the eighteenth conference on uncertainty in artificial intelligence. the eighteenth conference on uncertainty in artificial intelligenceThrun S. Particle filters in robotics. In: Proceedings of the eighteenth conference on uncertainty in artificial intelligence. 2002. p. 511-518.</p>
<p>Auto-encoding variational bayes. D P Kingma, M Welling, arXiv:13126114arXiv preprintKingma DP, Welling M. Auto-encoding variational bayes. arXiv preprint arXiv:13126114. 2013;.</p>
<p>CURL: Contrastive unsupervised representations for reinforcement learning. M Laskin, A Srinivas, P Abbeel, International Conference on Machine Learning (ICML). Laskin M, Srinivas A, Abbeel P. CURL: Contrastive unsupervised representations for reinforcement learn- ing. In: International Conference on Machine Learning (ICML). 2020. p. 5639-5650.</p>
<p>Self-supervised representation learning as multimodal variational inference. H Nakamura, M Okada, T Taniguchi, arXiv:220311437. 2022arXiv preprintNakamura H, Okada M, Taniguchi T. Self-supervised representation learning as multimodal variational inference. arXiv preprint arXiv:220311437. 2022;.</p>
<p>Learning latent dynamics for planning from pixels. D Hafner, T Lillicrap, I Fischer, R Villegas, D Ha, H Lee, J Davidson, International conference on machine learning (ICML). Hafner D, Lillicrap T, Fischer I, Villegas R, Ha D, Lee H, Davidson J. Learning latent dynamics for planning from pixels. In: International conference on machine learning (ICML). 2019. p. 2555-2565.</p>
<p>Predictive coding. Y Huang, R P Rao, Wiley Interdisciplinary Reviews: Cognitive Science. 25Huang Y, Rao RP. Predictive coding. Wiley Interdisciplinary Reviews: Cognitive Science. 2011;2(5):580- 593.</p>
<p>Predictive coding with neural transmission delays: a real-time temporal alignment hypothesis. H Hogendoorn, A N Burkitt, Eneuro. 62Hogendoorn H, Burkitt AN. Predictive coding with neural transmission delays: a real-time temporal align- ment hypothesis. Eneuro. 2019;6(2).</p>
<p>Predictive coding under the free-energy principle. K Friston, S Kiebel, Philosophical Transactions of the Royal Society B: Biological Sciences. 364Friston K, Kiebel S. Predictive coding under the free-energy principle. Philosophical Transactions of the Royal Society B: Biological Sciences. 2009;364(1521):1211-1221.</p>
<p>The free-energy principle: a unified brain theory?. K Friston, Nature Reviews Neuroscience. 112Friston K. The free-energy principle: a unified brain theory? Nature Reviews Neuroscience. 2010;11(2):127- 138.</p>
<p>Surfing uncertainty: Prediction, action, and the embodied mind. A Clark, Oxford University PressClark A. Surfing uncertainty: Prediction, action, and the embodied mind. Oxford University Press. 2015.</p>
<p>New directions in predictive processing. J Hohwy, Mind &amp; Language. 352Hohwy J. New directions in predictive processing. Mind &amp; Language. 2020;35(2):209-223.</p>
<p>The neural coding framework for learning generative models. A Ororbia, D Kifer, Nature communications. 131Ororbia A, Kifer D. The neural coding framework for learning generative models. Nature communications. 2022;13(1):1-14.</p>
<p>A free energy principle for the brain. K Friston, J Kilner, L Harrison, Journal of Physiology-Paris. 1001-3Friston K, Kilner J, Harrison L. A free energy principle for the brain. Journal of Physiology-Paris. 2006; 100(1-3):70-87.</p>
<p>Action understanding and active inference. K Friston, J Mattout, J Kilner, Biological cybernetics. 1041Friston K, Mattout J, Kilner J. Action understanding and active inference. Biological cybernetics. 2011; 104(1):137-160.</p>
<p>The free energy principle for action and perception: A mathematical review. C Buckley, C Kim, S Mcgregor, A Seth, Journal of Mathematical Psychology. 81Buckley C, Kim C, McGregor S, Seth A. The free energy principle for action and perception: A mathemat- ical review. Journal of Mathematical Psychology. 2017;81:55-79.</p>
<p>Action and behavior: a free-energy formulation. K J Friston, J Daunizeau, J Kilner, S J Kiebel, Biological Cybernetics. 1023Friston KJ, Daunizeau J, Kilner J, Kiebel SJ. Action and behavior: a free-energy formulation. Biological Cybernetics. 2010;102(3):227-260.</p>
<p>Perceptions as Hypotheses: Saccades as Experiments. K Friston, R A Adams, L Perrinet, M Breakspear, Frontiers in Psychology. 3151Friston K, Adams RA, Perrinet L, Breakspear M. Perceptions as Hypotheses: Saccades as Experiments. Frontiers in Psychology. 2012;3(May):151.</p>
<p>Active inference and epistemic value. K Friston, F Rigoli, D Ognibene, C Mathys, T Fitzgerald, G Pezzulo, Cognitive neuroscience. 64Friston K, Rigoli F, Ognibene D, Mathys C, Fitzgerald T, Pezzulo G. Active inference and epistemic value. Cognitive neuroscience. 2015;6(4):187-214.</p>
<p>All thinking is "wishful"thinking. A Kruglanski, K Jasko, K Friston, Trends in Cognitive Sciences. Kruglanski A, Jasko K, Friston K. All thinking is "wishful"thinking. Trends in Cognitive Sciences. 2020;.</p>
<p>Active inference and agency: optimal control without cost functions. K Friston, S Samothrakis, R Montague, Biological Cybernetics. 1068-9Friston K, Samothrakis S, Montague R. Active inference and agency: optimal control without cost functions. Biological Cybernetics. 2012;106(8-9):523-541.</p>
<p>Free-energy minimization and the dark-room problem. Frontiers in psychology. K Friston, C Thornton, A Clark, 130Friston K, Thornton C, Clark A. Free-energy minimization and the dark-room problem. Frontiers in psy- chology. 2012;:130.</p>
<p>The dark room problem. Z Sun, C Firestone, Trends in Cognitive Sciences. 245Sun Z, Firestone C. The dark room problem. Trends in Cognitive Sciences. 2020;24(5):346-348.</p>
<p>Learning to explore using active neural slam. D S Chaplot, D Gandhi, S Gupta, A Gupta, R Salakhutdinov, International Conference on Learning Representations (ICLR). Chaplot DS, Gandhi D, Gupta S, Gupta A, Salakhutdinov R. Learning to explore using active neural slam. In: International Conference on Learning Representations (ICLR). 2020.</p>
<p>Emergence of exploratory look-around behaviors through active observation completion. S K Ramakrishnan, D Jayaraman, K Grauman, Science Robotics. 4306326Ramakrishnan SK, Jayaraman D, Grauman K. Emergence of exploratory look-around behaviors through active observation completion. Science Robotics. 2019;4(30):eaaw6326.</p>
<p>A dataset for developing and benchmarking active vision. P Ammirato, P Poirson, E Park, J Košecká, A C Berg, IEEE International Conference on Robotics and Automation (ICRA. Ammirato P, Poirson P, Park E, Košecká J, Berg AC. A dataset for developing and benchmarking active vision. In: IEEE International Conference on Robotics and Automation (ICRA). 2017. p. 1378-1385.</p>
<p>Towards active event recognition. D Ognibene, Y Demiris, Ijcai. 2013. Ognibene D, Demiris Y. Towards active event recognition. In: Ijcai. 2013. p. 2495-2501.</p>
<p>Stare: Spatio-temporal attention relocation for multiple structured activities detection. K Lee, D Ognibene, H J Chang, T K Kim, Y Demiris, IEEE Transactions on Image Processing. 2412Lee K, Ognibene D, Chang HJ, Kim TK, Demiris Y. Stare: Spatio-temporal attention relocation for multiple structured activities detection. IEEE Transactions on Image Processing. 2015;24(12):5916-5927.</p>
<p>Action perception as hypothesis testing. F Donnarumma, M Costantini, E Ambrosini, K Friston, G Pezzulo, Cortex. 89Donnarumma F, Costantini M, Ambrosini E, Friston K, Pezzulo G. Action perception as hypothesis testing. Cortex. 2017;89:45-60.</p>
<p>Active vision for early recognition of human actions. B Wang, L Huang, M Hoai, IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Wang B, Huang L, Hoai M. Active vision for early recognition of human actions. In: IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). 2020.</p>
<p>Computational mechanisms of curiosity and goal-directed exploration. P Schwartenbeck, J Passecker, T U Hauser, T H Fitzgerald, M Kronbichler, K J Friston, Elife. 8Schwartenbeck P, Passecker J, Hauser TU, FitzGerald TH, Kronbichler M, Friston KJ. Computational mech- anisms of curiosity and goal-directed exploration. Elife. 2019;8.</p>
<p>Information theoretic sensor data selection for active object recognition and state estimation. J Denzler, C Brown, IEEE Transactions on Pattern Analysis and Machine Intelligence. 242Denzler J, Brown C. Information theoretic sensor data selection for active object recognition and state esti- mation. IEEE Transactions on Pattern Analysis and Machine Intelligence. 2002;24(2):145-157.</p>
<p>Information-theoretic active scene exploration. E Sommerlade, I Reid, IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Sommerlade E, Reid I. Information-theoretic active scene exploration. In: IEEE Conference on Computer Vision and Pattern Recognition (CVPR). 2008. p. 1-7.</p>
<p>Action and perception as divergence minimization. D Hafner, P A Ortega, J Ba, T Parr, K Friston, N Heess, arXiv:200901791. 2020arXiv preprintHafner D, Ortega PA, Ba J, Parr T, Friston K, Heess N. Action and perception as divergence minimization. arXiv preprint arXiv:200901791. 2020;.</p>
<p>Generalised free energy and active inference. T Parr, K J Friston, Biological cybernetics. 1135Parr T, Friston KJ. Generalised free energy and active inference. Biological cybernetics. 2019;113(5):495- 513.</p>
<p>Planning by probabilistic inference. H Attias, International workshop on artificial intelligence and statistics. Attias H. Planning by probabilistic inference. In: International workshop on artificial intelligence and statis- tics. 2003. p. 9-16.</p>
<p>Robot trajectory optimization using approximate inference. M Toussaint, International conference on machine learning (ICML). Toussaint M. Robot trajectory optimization using approximate inference. In: International conference on machine learning (ICML). 2009. p. 1049-1056.</p>
<p>Optimal control as a graphical model inference problem. Machine learning. H J Kappen, V Gómez, M Opper, 87Kappen HJ, Gómez V, Opper M. Optimal control as a graphical model inference problem. Machine learning. 2012;87(2):159-182.</p>
<p>Planning as inference. M Botvinick, M Toussaint, Trends in cognitive sciences. 1610Botvinick M, Toussaint M. Planning as inference. Trends in cognitive sciences. 2012;16(10):485-488.</p>
<p>On the relationship between active inference and control as inference. B Millidge, A Tschantz, A K Seth, C L Buckley, International workshop on active inference. SpringerMillidge B, Tschantz A, Seth AK, Buckley CL. On the relationship between active inference and control as inference. In: International workshop on active inference. Springer. 2020. p. 3-11.</p>
<p>Controlled optimism: Reply to sun and firestone on the dark room problem. S Van De Cruys, K Friston, A Clark, Trends in Cognitive Sciences. 249Van de Cruys S, Friston K, Clark A. Controlled optimism: Reply to sun and firestone on the dark room problem. Trends in Cognitive Sciences. 2020;24(9):1-2.</p>
<p>Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor. T Haarnoja, A Zhou, P Abbeel, S Levine, International Conference on Machine Learning (ICML). Haarnoja T, Zhou A, Abbeel P, Levine S. Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor. In: International Conference on Machine Learning (ICML). 2018. p. 1861- 1870.</p>
<p>Dreaming: Model-based reinforcement learning by latent imagination without reconstruction. M Okada, T Taniguchi, IEEE International Conference on Robotics and Automation (ICRA). 2021. Okada M, Taniguchi T. Dreaming: Model-based reinforcement learning by latent imagination without re- construction. In: IEEE International Conference on Robotics and Automation (ICRA). 2021. p. 4209-4215.</p>
<p>Tactile-sensitive NewtonianVAE for high-accuracy industrial connectorsocket insertion. R Okumura, N Nishio, T Taniguchi, IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). Okumura R, Nishio N, Taniguchi T. Tactile-sensitive NewtonianVAE for high-accuracy industrial connector- socket insertion. In: IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). 2022.</p>
<p>Model-based reinforcement learning for atari. L Kaiser, M Babaeizadeh, P Milos, B Osinski, R H Campbell, K Czechowski, D Erhan, C Finn, P Kozakowski, S Levine, arXiv:190300374arXiv preprintKaiser L, Babaeizadeh M, Milos P, Osinski B, Campbell RH, Czechowski K, Erhan D, Finn C, Kozakowski P, Levine S, et al.. Model-based reinforcement learning for atari. arXiv preprint arXiv:190300374. 2019;.</p>
<p>Learning dynamics model in reinforcement learning by incorporating the long term future. N R Ke, A Singh, A Touati, A Goyal, Y Bengio, D Parikh, D Batra, arXiv:190301599arXiv preprintKe NR, Singh A, Touati A, Goyal A, Bengio Y, Parikh D, Batra D. Learning dynamics model in reinforce- ment learning by incorporating the long term future. arXiv preprint arXiv:190301599. 2019;.</p>
<p>Planet of the Bayesians: Reconsidering and improving deep planning network by incorporating bayesian inference. M Okada, N Kosaka, T Taniguchi, Ieee/rsj international conference on intelligent robots and systems (IROS). 2020. Okada M, Kosaka N, Taniguchi T. Planet of the Bayesians: Reconsidering and improving deep planning network by incorporating bayesian inference. In: Ieee/rsj international conference on intelligent robots and systems (IROS). 2020. p. 5611-5618.</p>
<p>DreamingV2: Reinforcement learning with discrete world models without reconstruction. M Okada, T Taniguchi, IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). Okada M, Taniguchi T. DreamingV2: Reinforcement learning with discrete world models without recon- struction. In: IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). 2022.</p>
<p>NewtonianVAE: Proportional control and goal identification from pixels via physical latent spaces. M Jaques, M Burke, T M Hospedales, IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). 2021. Jaques M, Burke M, Hospedales TM. NewtonianVAE: Proportional control and goal identification from pixels via physical latent spaces. In: IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). 2021. p. 4454-4463.</p>
<p>Learning to generate articulated behavior through the bottom-up and the top-down interaction processes. J Tani, Neural Networks. 161Tani J. Learning to generate articulated behavior through the bottom-up and the top-down interaction pro- cesses. Neural Networks. 2003;16(1):11-23.</p>
<p>Emergence of functional hierarchy in a multiple timescale neural network model: A humanoid robot experiment. Y Yamashita, J Tani, PLoS Computational Biology. 4111000220Yamashita Y, Tani J. Emergence of functional hierarchy in a multiple timescale neural network model: A humanoid robot experiment. PLoS Computational Biology. 2008;4(11):e1000220.</p>
<p>Development of hierarchical structures for actions and motor imagery: A constructivist view from synthetic neuro-robotics study. R Nishimoto, J Tani, Psychological Research. 734Nishimoto R, Tani J. Development of hierarchical structures for actions and motor imagery: A constructivist view from synthetic neuro-robotics study. Psychological Research. 2009;73(4):545-558.</p>
<p>A neurodynamic account of spontaneous behaviour. J Namikawa, R Nishimoto, J Tani, PLoS Computational Biology. 7101002221Namikawa J, Nishimoto R, Tani J. A neurodynamic account of spontaneous behaviour. PLoS Computational Biology. 2011;7(10):e1002221.</p>
<p>Spontaneous prediction error generation in schizophrenia. Y Yamashita, J Tani, PloS One. 7537843Yamashita Y, Tani J. Spontaneous prediction error generation in schizophrenia. PloS One. 2012;7(5):e37843.</p>
<p>Learning to Reproduce Fluctuating Time Series by Inferring Their Time-Dependent Stochastic Properties: Application in Robot Learning Via Tutoring. S Murata, J Namikawa, Arie H Sugano, S Tani, J , IEEE Transactions on Autonomous Mental Development. 54Murata S, Namikawa J, Arie H, Sugano S, Tani J. Learning to Reproduce Fluctuating Time Series by In- ferring Their Time-Dependent Stochastic Properties: Application in Robot Learning Via Tutoring. IEEE Transactions on Autonomous Mental Development. 2013;5(4):298-310.</p>
<p>Learning to Perceive the World as Probabilistic or Deterministic via Interaction With Others: A Neuro-Robotics Experiment. S Murata, Y Yamashita, Arie H Ogata, T Sugano, S Tani, J , IEEE Transactions on Neural Networks and Learning Systems. 284Murata S, Yamashita Y, Arie H, Ogata T, Sugano S, Tani J. Learning to Perceive the World as Probabilistic or Deterministic via Interaction With Others: A Neuro-Robotics Experiment. IEEE Transactions on Neural Networks and Learning Systems. 2017;28(4):830-848.</p>
<p>A Novel Predictive-Coding-Inspired Variational RNN Model for Online Prediction and Recognition. A Ahmadi, J Tani, Neural Computation. 3111Ahmadi A, Tani J. A Novel Predictive-Coding-Inspired Variational RNN Model for Online Prediction and Recognition. Neural Computation. 2019;31(11):2025-2074.</p>
<p>A review on neural network models of schizophrenia and autism spectrum disorder. P Lanillos, D Oliva, A Philippsen, Y Yamashita, Y Nagai, G Cheng, Neural Networks. 122Lanillos P, Oliva D, Philippsen A, Yamashita Y, Nagai Y, Cheng G. A review on neural network models of schizophrenia and autism spectrum disorder. Neural Networks. 2020;122:338-363.</p>
<p>Precise minds in uncertain worlds: predictive coding in autism. S Van De Cruys, K Evers, R Van Der Hallen, L Van Eylen, B Boets, L De-Wit, J Wagemans, Psychological review. 1214Van de Cruys S, Evers K, Van der Hallen R, Van Eylen L, Boets B, De-Wit L, Wagemans J. Precise minds in uncertain worlds: predictive coding in autism. Psychological review. 2014;121(4):649-75.</p>
<p>An aberrant precision account of autism. R P Lawson, G Rees, K J Friston, Frontiers in Human Neuroscience. 8Lawson RP, Rees G, Friston KJ. An aberrant precision account of autism. Frontiers in Human Neuroscience. 2014;8(May):1-10.</p>
<p>A Neurorobotics Simulation of Autistic Behavior Induced by Unusual Sensory Precision. H Idei, S Murata, Y Chen, Y Yamashita, J Tani, T Ogata, Computational Psychiatry. 2Idei H, Murata S, Chen Y, Yamashita Y, Tani J, Ogata T. A Neurorobotics Simulation of Autistic Behavior Induced by Unusual Sensory Precision. Computational Psychiatry. 2018;2:164-182.</p>
<p>Homogeneous Intrinsic Neuronal Excitability Induces Overfitting to Sensory Noise: A Robot Model of Neurodevelopmental Disorder. H Idei, S Murata, Y Yamashita, T Ogata, Frontiers in Psychiatry. 11Idei H, Murata S, Yamashita Y, Ogata T. Homogeneous Intrinsic Neuronal Excitability Induces Overfit- ting to Sensory Noise: A Robot Model of Neurodevelopmental Disorder. Frontiers in Psychiatry. 2020; 11(August):1-15.</p>
<p>Paradoxical sensory reactivity induced by functional disconnection in a robot model of neurodevelopmental disorder. H Idei, S Murata, Y Yamashita, T Ogata, Neural Networks. 138Idei H, Murata S, Yamashita Y, Ogata T. Paradoxical sensory reactivity induced by functional disconnection in a robot model of neurodevelopmental disorder. Neural Networks. 2021;138:150-163.</p>
<p>End-to-end pixel-based deep active inference for body perception and action. C Sancaktar, M Van Gerven, P Lanillos, Joint IEEE International Conference on Development and Learning and Epigenetic Robotics. 2020ICDL-EpiRobSancaktar C, van Gerven M, Lanillos P. End-to-end pixel-based deep active inference for body perception and action. In: Joint IEEE International Conference on Development and Learning and Epigenetic Robotics (ICDL-EpiRob). 2020.</p>
<p>Active inference for fault tolerant control of robot manipulators with sensory faults. C Pezzato, M Baioumy, C H Corbato, N Hawes, M Wisse, R Ferrari, International workshop on active inference. SpringerPezzato C, Baioumy M, Corbato CH, Hawes N, Wisse M, Ferrari R. Active inference for fault tolerant control of robot manipulators with sensory faults. In: International workshop on active inference. Springer. 2020. p. 20-27.</p>
<p>Multimodal vae active inference controller. C Meo, P Lanillos, IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEEMeo C, Lanillos P. Multimodal vae active inference controller. In: IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE. 2021.</p>
<p>Active inference with function learning for robot body perception. International Workshop on Continual Unsupervised Sensorimotor Learning. P Lanillos, G Cheng, IEEE Developmental Learning and Epigenetic Robotics (ICDL-Epirob). Lanillos P, Cheng G. Active inference with function learning for robot body perception. International Work- shop on Continual Unsupervised Sensorimotor Learning, IEEE Developmental Learning and Epigenetic Robotics (ICDL-Epirob). 2018;.</p>
<p>Adaptive robot body learning and estimation through predictive coding. P Lanillos, G Cheng, IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE. Lanillos P, Cheng G. Adaptive robot body learning and estimation through predictive coding. In: IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE. 2018. p. 4083-4090.</p>
<p>Dynamic and interactive generation of object handling behaviors by a small humanoid robot using a dynamic neural network model. M Ito, K Noda, Y Hoshino, J Tani, Neural Networks. 193Ito M, Noda K, Hoshino Y, Tani J. Dynamic and interactive generation of object handling behaviors by a small humanoid robot using a dynamic neural network model. Neural Networks. 2006;19(3):323-337.</p>
<p>Learning Semantic Combinatoriality from the Interaction between Linguistic and Behavioral Processes. Y Sugita, J Tani, Adaptive Behavior. 131Sugita Y, Tani J. Learning Semantic Combinatoriality from the Interaction between Linguistic and Behav- ioral Processes. Adaptive Behavior. 2005;13(1):33-52.</p>
<p>Emergence of interactive behaviors between two robots by prediction error minimization mechanism. Y Chen, S Murata, Arie H Ogata, T Tani, J Sugano, S , Joint IEEE International Conference on Development and Learning and Epigenetic Robotics. ICDL-EpiRobChen Y, Murata S, Arie H, Ogata T, Tani J, Sugano S. Emergence of interactive behaviors between two robots by prediction error minimization mechanism. In: Joint IEEE International Conference on Development and Learning and Epigenetic Robotics (ICDL-EpiRob). 2016. p. 302-307.</p>
<p>Robot navigation as hierarchical active inference. O Verbelen, T Van De Maele, T Dhoedt, B Safron, A , Neural Networks. 142Ç atal O, Verbelen T, Van de Maele T, Dhoedt B, Safron A. Robot navigation as hierarchical active inference. Neural Networks. 2021;142:192-204.</p>
<p>Affordance-based altruistic robotic architecture for human-robot collaboration. M Imre, E Oztop, Y Nagai, E Ugur, Adaptive Behavior. 274Imre M, Oztop E, Nagai Y, Ugur E. Affordance-based altruistic robotic architecture for human-robot col- laboration. Adaptive Behavior. 2019;27(4):223-241.</p>
<p>Imitation and mirror systems in robots through deep modality blending networks. M Y Seker, A Ahmetoglu, Y Nagai, M Asada, E Oztop, E Ugur, Neural Networks. 146Seker MY, Ahmetoglu A, Nagai Y, Asada M, Oztop E, Ugur E. Imitation and mirror systems in robots through deep modality blending networks. Neural Networks. 2022;146:22-35.</p>
<p>Conditional neural movement primitives. M Y Seker, M Imre, J Piater, E Ugur, Robotics Science and Systems (RSS). Seker MY, Imre M, Piater J, Ugur E. Conditional neural movement primitives. In: Robotics Science and Systems (RSS). 2019.</p>
<p>Scaling active inference. A Tschantz, M Baltieri, A K Seth, C L Buckley, international joint conference on neural networks (IJCNN). 2020. Tschantz A, Baltieri M, Seth AK, Buckley CL. Scaling active inference. In: international joint conference on neural networks (IJCNN). 2020. p. 1-8.</p>
<p>Object-based active inference. R S Van Bergen, P L Lanillos, arXiv:220901258. 2022arXiv preprintvan Bergen RS, Lanillos PL. Object-based active inference. arXiv preprint arXiv:220901258. 2022;.</p>
<p>How active inference could help revolutionise robotics. Da Costa, L Lanillos, P Sajid, N Friston, K Khan, S , Entropy. 243361Da Costa L, Lanillos P, Sajid N, Friston K, Khan S. How active inference could help revolutionise robotics. Entropy. 2022;24(3):361.</p>
<p>Grounding context in embodied cognitive robotics. D Valenzo, A Ciria, G Schillaci, B Lara, Frontiers in Neurorobotics. 16Valenzo D, Ciria A, Schillaci G, Lara B. Grounding context in embodied cognitive robotics. Frontiers in Neurorobotics. 2022;16.</p>
<p>Deep active inference agents using monte-carlo methods. Advances in neural information processing systems. Z Fountas, N Sajid, P Mediano, K Friston, 33Fountas Z, Sajid N, Mediano P, Friston K. Deep active inference agents using monte-carlo methods. Ad- vances in neural information processing systems. 2020;33:11662-11675.</p>
<p>Contrastive active inference. P Mazzaglia, T Verbelen, B Dhoedt, Advances in Neural Information Processing Systems. 34Mazzaglia P, Verbelen T, Dhoedt B. Contrastive active inference. Advances in Neural Information Process- ing Systems. 2021;34:13870-13882.</p>
<p>Autonomous learning of state representations for control: An emerging field aims to autonomously learn state representations for reinforcement learning agents from their real-world sensor observations. KI-Künstliche Intelligenz. W Böhmer, J T Springenberg, J Boedecker, M Riedmiller, K Obermayer, 29Böhmer W, Springenberg JT, Boedecker J, Riedmiller M, Obermayer K. Autonomous learning of state repre- sentations for control: An emerging field aims to autonomously learn state representations for reinforcement learning agents from their real-world sensor observations. KI-Künstliche Intelligenz. 2015;29(4):353-362.</p>
<p>A separation principle for control in the age of deep learning. A Achille, S Soatto, Robotics, and Autonomous Systems. 1Annual Review of ControlAchille A, Soatto S. A separation principle for control in the age of deep learning. Annual Review of Control, Robotics, and Autonomous Systems. 2018;1:287-307.</p>
<p>State representation learning for control: An overview. T Lesort, N Díaz-Rodríguez, J F Goudou, D Filliat, Neural Networks. 108Lesort T, Díaz-Rodríguez N, Goudou JF, Filliat D. State representation learning for control: An overview. Neural Networks. 2018;108:379-392.</p>
<p>The hippocampal formation as a hierarchical generative model supporting generative replay and continual learning. I Stoianov, D Maisto, G Pezzulo, Progress in Neurobiology. 217102329Stoianov I, Maisto D, Pezzulo G. The hippocampal formation as a hierarchical generative model supporting generative replay and continual learning. Progress in Neurobiology. 2022;217:102329.</p>
<p>Sparsely changing latent states for prediction and planning in partially observable domains. C Gumbsch, M V Butz, G Martius, Advances in Neural Information Processing Systems. 34Gumbsch C, Butz MV, Martius G. Sparsely changing latent states for prediction and planning in partially observable domains. Advances in Neural Information Processing Systems. 2021;34:17518-17531.</p>
<p>. K Greff, R L Kaufman, R Kabra, N Watters, C Burgess, D Zoran, L Matthey, M Botvinick, A Lerchner, Greff K, Kaufman RL, Kabra R, Watters N, Burgess C, Zoran D, Matthey L, Botvinick M, Lerchner A.</p>
<p>Multi-object representation learning with iterative variational inference. International Conference on Machine Learning (ICML). Multi-object representation learning with iterative variational inference. In: International Conference on Machine Learning (ICML). 2019. p. 2424-2433.</p>
<p>T Wang, S S Du, A Torralba, P Isola, A Zhang, Y Tian, Denoised Mdps, arXiv:220615477. 2022Learning world models better than the world itself. arXiv preprintWang T, Du SS, Torralba A, Isola P, Zhang A, Tian Y. Denoised MDPs: Learning world models better than the world itself. arXiv preprint arXiv:220615477. 2022;.</p>
<p>The mentality of apes. International library of psychology, philosophy, and scientific method. K. Paul, Trench, Trubner &amp; Company, Limited. W Köhler, E Winter, Köhler W, Winter E. The mentality of apes. International library of psychology, philosophy, and scientific method. K. Paul, Trench, Trubner &amp; Company, Limited. 1925.</p>
<p>Plans, affordances, and combinatory grammar. M Steedman, Linguistics and Philosophy. 255-6Steedman M. Plans, affordances, and combinatory grammar. Linguistics and Philosophy. 2002;25(5-6):723- 753.</p>
<p>Neuroanatomical correlates of human reasoning. V Goel, B Gold, S Kapur, S Houle, Journal of cognitive neuroscience. 103Goel V, Gold B, Kapur S, Houle S. Neuroanatomical correlates of human reasoning. Journal of cognitive neuroscience. 1998;10(3):293-302.</p>
<p>Atkinson and hilgard's introduction to psychology. Cengage Learning. N Al, S Nolen-Hoeksema, Al N, Nolen-Hoeksema S. Atkinson and hilgard's introduction to psychology. Cengage Learning. 2014.</p>
<p>Artificial intelligence: a modern approach. S J Russell, P Norvig, Pearson Education LimitedRussell SJ, Norvig P. Artificial intelligence: a modern approach. Pearson Education Limited,. 2016.</p>
<p>Autonomous learning of high-level states and actions in continuous environments. J Mugan, B Kuipers, IEEE Transactions on Autonomous Mental Development. 41Mugan J, Kuipers B. Autonomous learning of high-level states and actions in continuous environments. IEEE Transactions on Autonomous Mental Development. 2012;4(1):70-86.</p>
<p>High-level features for resource economy and fast learning in skill transfer. A Ahmetoglu, E Ugur, M Asada, E Oztop, Advanced Robotics. 365-6Ahmetoglu A, Ugur E, Asada M, Oztop E. High-level features for resource economy and fast learning in skill transfer. Advanced Robotics. 2022;36(5-6):291-303.</p>
<p>Constructing symbolic representations for high-level planning. G Konidaris, L P Kaelbling, T Lozano-Perez, AAAI Conference on Artificial Intelligence (AAAI). Konidaris G, Kaelbling LP, Lozano-Perez T. Constructing symbolic representations for high-level planning. In: AAAI Conference on Artificial Intelligence (AAAI). 2014.</p>
<p>Symbol acquisition for probabilistic high-level planning. G Konidaris, L Kaelbling, T Lozano-Perez, International Joint Conference on Artificial Intelligence (IJCAI). Konidaris G, Kaelbling L, Lozano-Perez T. Symbol acquisition for probabilistic high-level planning. In: International Joint Conference on Artificial Intelligence (IJCAI). 2015.</p>
<p>Learning portable representations for high-level planning. S James, B Rosman, G Konidaris, arXiv:190512006arXiv preprintJames S, Rosman B, Konidaris G. Learning portable representations for high-level planning. arXiv preprint arXiv:190512006. 2019;.</p>
<p>Bottom-up learning of object categories, action effects and logical rules: From continuous manipulative exploration to symbolic planning. E Ugur, J Piater, IEEE International Conference on Robotics and Automation (ICRA). Ugur E, Piater J. Bottom-up learning of object categories, action effects and logical rules: From contin- uous manipulative exploration to symbolic planning. In: IEEE International Conference on Robotics and Automation (ICRA). 2015. p. 2627-2633.</p>
<p>Refining discovered symbols with multi-step interaction experience. E Ugur, J Piater, ieee-ras 15th international conference on humanoid robots (humanoids). Ugur E, Piater J. Refining discovered symbols with multi-step interaction experience. In: 2015 ieee-ras 15th international conference on humanoid robots (humanoids). 2015. p. 1007-1012.</p>
<p>Deepsym: Deep symbol generation and rule learning from unsupervised continuous robot interaction for planning. A Ahmetoglu, M Y Seker, J Piater, E Oztop, E Ugur, Journal of Artificial Intelligence Research. Ahmetoglu A, Seker MY, Piater J, Oztop E, Ugur E. Deepsym: Deep symbol generation and rule learning from unsupervised continuous robot interaction for planning. Journal of Artificial Intelligence Research. 2022;.</p>
<p>To afford or not to afford: A new formalization of affordances toward affordance-based robot control. E Ş Ahin, M Cakmak, M R Dogar, E Ugur, G Üçoluk, Adaptive Behavior. 154Ş ahin E, Cakmak M, Dogar MR, Ugur E,Üçoluk G. To afford or not to afford: A new formalization of affordances toward affordance-based robot control. Adaptive Behavior. 2007;15(4):447-472.</p>
<p>Learning multi-object symbols for manipulation with attentive deep effect predictors. A Ahmetoglu, E Oztop, E Ugur, arXiv:220801021. 2022arXiv preprintAhmetoglu A, Oztop E, Ugur E. Learning multi-object symbols for manipulation with attentive deep effect predictors. arXiv preprint arXiv:220801021. 2022;.</p>
<p>Classical planning in deep latent space: Bridging the subsymbolic-symbolic boundary. M Asai, A Fukunaga, arXiv:170500154arXiv preprintAsai M, Fukunaga A. Classical planning in deep latent space: Bridging the subsymbolic-symbolic boundary. arXiv preprint arXiv:170500154. 2017;.</p>
<p>Learning neural-symbolic descriptive planning models via cube-space priors: The voyage home (to strips). M Asai, C Muise, arXiv:200412850. 2020arXiv preprintAsai M, Muise C. Learning neural-symbolic descriptive planning models via cube-space priors: The voyage home (to strips). arXiv preprint arXiv:200412850. 2020;.</p>
<p>The ecological approach to visual perception. J J Gibson, Boston: Houghton MifflinGibson JJ. The ecological approach to visual perception. Boston: Houghton Mifflin. 1979.</p>
<p>Computational models of affordance in robotics: a taxonomy and systematic classification. P Zech, S Haller, S R Lakani, B Ridge, E Ugur, J Piater, Adaptive Behavior. 255Zech P, Haller S, Lakani SR, Ridge B, Ugur E, Piater J. Computational models of affordance in robotics: a taxonomy and systematic classification. Adaptive Behavior. 2017;25(5):235-271.</p>
<p>Affordances in psychology, neuroscience and robotics: a survey. L Jamone, E Ugur, A Cangelosi, L Fadiga, A Bernardino, J Piater, J Santos-Victor, IEEE Transactions on Cognitive and Developmental Systems. 101Jamone L, Ugur E, Cangelosi A, Fadiga L, Bernardino A, Piater J, Santos-Victor J. Affordances in psy- chology, neuroscience and robotics: a survey. IEEE Transactions on Cognitive and Developmental Systems. 2016;10(1):4-25.</p>
<p>Computational models of affordance for robotics. E Renaudo, P Zech, R Chatila, M Khamassi, Frontiers in Neurorobotics. 161045355Renaudo E, Zech P, Chatila R, Khamassi M. Computational models of affordance for robotics. Frontiers in Neurorobotics. 2022;16:1045355.</p>
<p>The senses considered as perceptual systems. J J Gibson, Boston: Houghton MifflinGibson JJ. The senses considered as perceptual systems. Boston: Houghton Mifflin. 1966.</p>
<p>The theory of affordances. Perceiving, Acting, and Knowing: Toward an ecological psychology. J J Gibson, Lawrence Erlbaum AssociatesGibson JJ. The theory of affordances. Perceiving, Acting, and Knowing: Toward an ecological psychology. Eds. Lawrence Erlbaum Associates. 1977.</p>
<p>Affordance, conventions, and design. D A Norman, Interactions. 63Norman DA. Affordance, conventions, and design. Interactions. 1999;6(3):38-42.</p>
<p>An odyssey in learning and perception. E J Gibson, MIT PressGibson EJ. An odyssey in learning and perception. MIT Press. 1994.</p>
<p>Perceptual learning in development: Some basic concepts. E J Gibson, Ecological Psychology. 124Gibson EJ. Perceptual learning in development: Some basic concepts. Ecological Psychology. 2000; 12(4):295-302.</p>
<p>The world is so full of a number of things: On specification and perceptual learning. E J Gibson, Ecological Psychology. 154Gibson EJ. The world is so full of a number of things: On specification and perceptual learning. Ecological Psychology. 2003;15(4):283-288.</p>
<p>To afford or not to afford: A new formalization of affordances toward affordance-based robot control. E Ş Ahin, M Cakmak, M R Dogar, E Ugur, G Üçoluk, Adaptive Behavior. 154Ş ahin E, Cakmak M, Dogar MR, Ugur E,Üçoluk G. To afford or not to afford: A new formalization of affordances toward affordance-based robot control. Adaptive Behavior. 2007;15(4):447-472.</p>
<p>Learning object affordances: From sensory-motor coordination to imitation. L Montesano, M Lopes, A Bernardino, J Santos-Victor, IEEE Transactions on Robotics. 241Montesano L, Lopes M, Bernardino A, Santos-Victor J. Learning object affordances: From sensory-motor coordination to imitation. IEEE Transactions on Robotics. 2008;24(1):15-26.</p>
<p>Unsupervised learning of object affordances for planning in a mobile manipulation platform. E Ugur, E Oztop, E , IEEE International Conference on Robotics and Automation (ICRA). Ugur E, Ş ahin E, Oztop E. Unsupervised learning of object affordances for planning in a mobile manipula- tion platform. In: IEEE International Conference on Robotics and Automation (ICRA). 2011. p. 4312-4317.</p>
<p>Object-action complexes: Grounded abstractions of sensory-motor processes. N Krueger, C Geib, J Piater, R Petrick, M Steedman, F Worgotter, A Ude, T Asfour, D Kraft, D Omrcen, A Agostini, R Dillmann, Robotics and Autonomous Systems. 5910Krueger N, Geib C, Piater J, Petrick R, Steedman M, Worgotter F, Ude A, Asfour T, Kraft D, Omrcen D, Agostini A, Dillmann R. Object-action complexes: Grounded abstractions of sensory-motor processes. Robotics and Autonomous Systems. 2011;59(10):740-757.</p>
<p>Knowledge propagation and relation learning for predicting action effects. S Szedmak, E Ugur, J Piater, Ieee/rsj international conference on intelligent robots and systems (IROS). Szedmak S, Ugur E, Piater J. Knowledge propagation and relation learning for predicting action effects. In: Ieee/rsj international conference on intelligent robots and systems (IROS). 2014. p. 623-629.</p>
<p>Learning intermediate object affordances: Towards the development of a tool concept. A Gonçalves, J Abrantes, G Saponaro, L Jamone, A Bernardino, 4th international conference on development and learning and on epigenetic robotics. Gonçalves A, Abrantes J, Saponaro G, Jamone L, Bernardino A. Learning intermediate object affordances: Towards the development of a tool concept. In: 4th international conference on development and learning and on epigenetic robotics. 2014. p. 482-488.</p>
<p>Denoising auto-encoders for learning of objects and tools affordances in continuous space. A Dehban, L Jamone, A R Kampff, J Santos-Victor, IEEE International Conference on Robotics and Automation (ICRA). Dehban A, Jamone L, Kampff AR, Santos-Victor J. Denoising auto-encoders for learning of objects and tools affordances in continuous space. In: IEEE International Conference on Robotics and Automation (ICRA). 2016. p. 4866-4871.</p>
<p>A deep probabilistic framework for heterogeneous selfsupervised learning of affordances. A Dehban, L Jamone, A R Kampff, J Santos-Victor, IEEE-RAS 17th International Conference on Humanoid Robotics (Humanoids. Dehban A, Jamone L, Kampff AR, Santos-Victor J. A deep probabilistic framework for heterogeneous self- supervised learning of affordances. In: IEEE-RAS 17th International Conference on Humanoid Robotics (Humanoids). 2017. p. 476-483.</p>
<p>Emergent structuring of interdependent affordance learning tasks using intrinsic motivation and empirical feature selection. E Ugur, J Piater, IEEE Transactions on Cognitive and Developmental Systems. 94Ugur E, Piater J. Emergent structuring of interdependent affordance learning tasks using intrinsic motiva- tion and empirical feature selection. IEEE Transactions on Cognitive and Developmental Systems. 2017; 9(4):328-340.</p>
<p>A logic-based computational framework for inferring cognitive affordances. V Sarathy, M Scheutz, IEEE Transactions on Cognitive and Developmental Systems. 101Sarathy V, Scheutz M. A logic-based computational framework for inferring cognitive affordances. IEEE Transactions on Cognitive and Developmental Systems. 2018;10(1):26-43.</p>
<p>Heteroscedastic regression and active learning for modeling affordances in humanoids. F Stramandinoli, V Tikhanoff, U Pattacini, F Nori, IEEE Transactions on Cognitive and Developmental Systems. 102Stramandinoli F, Tikhanoff V, Pattacini U, Nori F. Heteroscedastic regression and active learning for modeling affordances in humanoids. IEEE Transactions on Cognitive and Developmental Systems. 2018; 10(2):455-468.</p>
<p>Belief regulated dual propagation nets for learning action effects on groups of articulated objects. A E Tekden, A Erdem, E Erdem, M Imre, M Y Seker, E Ugur, IEEE International Conference on Robotics and Automation (ICRA). 2020. Tekden AE, Erdem A, Erdem E, Imre M, Seker MY, Ugur E. Belief regulated dual propagation nets for learning action effects on groups of articulated objects. In: IEEE International Conference on Robotics and Automation (ICRA). 2020. p. 10556-10562.</p>
<p>From human instructions to robot actions: Formulation of goals, affordances and probabilistic planning. A Antunes, L Jamone, G Saponaro, A Bernardino, R Ventura, Ieee icra. Antunes A, Jamone L, Saponaro G, Bernardino A, Ventura R. From human instructions to robot actions: Formulation of goals, affordances and probabilistic planning. In: Ieee icra. 2016.</p>
<p>Learning deep features for robotic inference from physical interactions. A Dehban, S Zhang, N Cauli, L Jamone, J Santos-Victor, IEEE Transactions on Cognitive and Developmental Systems. Dehban A, Zhang S, Cauli N, Jamone L, Santos-Victor J. Learning deep features for robotic inference from physical interactions. IEEE Transactions on Cognitive and Developmental Systems. 2022;:1-1.</p>
<p>Investigation of practical use of humanoid robots in elderly care centres. Z Shen, Y Wu, Proceedings of the fourth international conference on human agent interaction. the fourth international conference on human agent interactionShen Z, Wu Y. Investigation of practical use of humanoid robots in elderly care centres. In: Proceedings of the fourth international conference on human agent interaction. 2016. p. 63-66.</p>
<p>Autonomous agents modelling other agents: A comprehensive survey and open problems. S V Albrecht, P Stone, Artificial Intelligence. 258Albrecht SV, Stone P. Autonomous agents modelling other agents: A comprehensive survey and open prob- lems. Artificial Intelligence. 2018;258:66-95.</p>
<p>Cobot programming for collaborative industrial tasks: An overview. S El Zaatari, M Marei, W Li, Z Usman, Robotics and Autonomous Systems. 116El Zaatari S, Marei M, Li W, Usman Z. Cobot programming for collaborative industrial tasks: An overview. Robotics and Autonomous Systems. 2019;116:162-180.</p>
<p>Human-robot interaction in industrial collaborative robotics: a literature review of the decade. A Hentout, M Aouache, A Maoudj, I Akli, Advanced Robotics. 33Hentout A, Aouache M, Maoudj A, Akli I. Human-robot interaction in industrial collaborative robotics: a literature review of the decade 2008-2017. Advanced Robotics. 2019;33(15-16):764-799.</p>
<p>Human-robot coexistence and interaction in open industrial cells. E Magrini, F Ferraguti, A J Ronga, F Pini, De Luca, A Leali, F , Robotics and Computer-Integrated Manufacturing. 61101846Magrini E, Ferraguti F, Ronga AJ, Pini F, De Luca A, Leali F. Human-robot coexistence and interaction in open industrial cells. Robotics and Computer-Integrated Manufacturing. 2020;61:101846.</p>
<p>Active vision and perception in human-robot collaboration. D Ognibene, T Foulsham, L Marchegiani, G M Farinella, Frontiers in Neurorobotics. 16Ognibene D, Foulsham T, Marchegiani L, Farinella GM. Active vision and perception in human-robot col- laboration. Frontiers in Neurorobotics. 2022;16.</p>
<p>Human-robot collaboration and machine learning: A systematic review of recent research. F Semeraro, A Griffiths, A Cangelosi, Robotics and Computer-Integrated Manufacturing. 79102432Semeraro F, Griffiths A, Cangelosi A. Human-robot collaboration and machine learning: A systematic re- view of recent research. Robotics and Computer-Integrated Manufacturing. 2023;79:102432.</p>
<p>Contextual action recognition and target localization with an active allocation of attention on a humanoid robot. D Ognibene, E Chinellato, M Sarabia, Y Demiris, Bioinspiration &amp; biomimetics. 8335002Ognibene D, Chinellato E, Sarabia M, Demiris Y. Contextual action recognition and target localization with an active allocation of attention on a humanoid robot. Bioinspiration &amp; biomimetics. 2013;8(3):035002.</p>
<p>Mentalizing homeostasis: The social origins of interoceptive inference. Neuropsychoanalysis. A Fotopoulou, M Tsakiris, 19Fotopoulou A, Tsakiris M. Mentalizing homeostasis: The social origins of interoceptive inference. Neu- ropsychoanalysis. 2017;19(1):3-28.</p>
<p>Thinking through other minds: A variational approach to cognition and culture. S P Veissière, A Constant, M J Ramstead, K J Friston, L J Kirmayer, Behavioral and brain sciences. 43Veissière SP, Constant A, Ramstead MJ, Friston KJ, Kirmayer LJ. Thinking through other minds: A varia- tional approach to cognition and culture. Behavioral and brain sciences. 2020;43.</p>
<p>Uniquely human social cognition. Current opinion in neurobiology. R Saxe, 16Saxe R. Uniquely human social cognition. Current opinion in neurobiology. 2006;16(2):235-239.</p>
<p>Functional advantages of an adaptive theory of mind for robotics: a review of current architectures. F Bianco, D Ognibene, Computer Science and Electronic Engineering (CEEC). Bianco F, Ognibene D. Functional advantages of an adaptive theory of mind for robotics: a review of current architectures. Computer Science and Electronic Engineering (CEEC). 2019;:139-143.</p>
<p>Rational quantitative attribution of beliefs, desires and percepts in human mentalizing. C L Baker, J Jara-Ettinger, Saxe R Tenenbaum, J B , Nature Human Behaviour. 14Baker CL, Jara-Ettinger J, Saxe R, Tenenbaum JB. Rational quantitative attribution of beliefs, desires and percepts in human mentalizing. Nature Human Behaviour. 2017;1(4):1-10.</p>
<p>Robot learning theory of mind through self-observation: Exploiting the intentionsbeliefs synergy. F Bianco, D Ognibene, arXiv:221009435. 2022arXiv preprintBianco F, Ognibene D. Robot learning theory of mind through self-observation: Exploiting the intentions- beliefs synergy. arXiv preprint arXiv:221009435. 2022;.</p>
<p>F Bianchi, M Marelli, Nicoli P , Palmonari M Sweat, arXiv:210907231Scoring polarization of topics across different corpora. arXiv preprintBianchi F, Marelli M, Nicoli P, Palmonari M. Sweat: Scoring polarization of topics across different corpora. arXiv preprint arXiv:210907231. 2021;.</p>
<p>Proactive intention recognition for joint human-robot search and rescue missions through monte-carlo planning in POMDP environments. D Ognibene, L Mirante, L Marchegiani, International conference on social robotics. SpringerOgnibene D, Mirante L, Marchegiani L. Proactive intention recognition for joint human-robot search and rescue missions through monte-carlo planning in POMDP environments. In: International conference on social robotics. Springer. 2019. p. 332-343.</p>
<p>Modelling intention recognition for intelligent agent systems. C Heinze, DEFENCE SCIENCE AND TECHNOLOGY ORGANISATION. Tech RepHeinze C. Modelling intention recognition for intelligent agent systems. DEFENCE SCIENCE AND TECHNOLOGY ORGANISATION. 2004. Tech Rep. Available from: http://www.dsto.defence. gov.au/corporate/reports/DSTO-RR-0286.pdf.</p>
<p>Collecting complex activity datasets in highly rich networked sensor environments. D Roggen, A Calatroni, M Rossi, T Holleczek, K Förster, G Tröster, P Lukowicz, D Bannach, G Pirkl, A Ferscha, International conference on networked sensing systems (INSS). Roggen D, Calatroni A, Rossi M, Holleczek T, Förster K, Tröster G, Lukowicz P, Bannach D, Pirkl G, Ferscha A, et al.. Collecting complex activity datasets in highly rich networked sensor environments. In: International conference on networked sensing systems (INSS). 2010. p. 233-240.</p>
<p>Convolutional neural networks for human activity recognition using mobile sensors. M Zeng, L T Nguyen, B Yu, O J Mengshoel, J Zhu, P Wu, J Zhang, 6th international conference on mobile computing, applications and services. IEEEZeng M, Nguyen LT, Yu B, Mengshoel OJ, Zhu J, Wu P, Zhang J. Convolutional neural networks for human activity recognition using mobile sensors. In: 6th international conference on mobile computing, applica- tions and services. IEEE. 2014. p. 197-205.</p>
<p>Deep convolutional neural networks on multichannel time series for human activity recognition. J Yang, M N Nguyen, P P San, X L Li, S Krishnaswamy, Twenty-fourth international joint conference on artificial intelligence. Yang J, Nguyen MN, San PP, Li XL, Krishnaswamy S. Deep convolutional neural networks on multichannel time series for human activity recognition. In: Twenty-fourth international joint conference on artificial intelligence. 2015.</p>
<p>A model-based human activity recognition for human-robot collaboration. S U Lee, A Hofmann, B Williams, IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE. 2019. Lee SU, Hofmann A, Williams B. A model-based human activity recognition for human-robot collabo- ration. In: IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE. 2019. p. 736-743.</p>
<p>Plan recognition as planning. M Ramírez, H Geffner, International joint conference on artificial intelligence (IJCAI). Ramírez M, Geffner H. Plan recognition as planning. In: International joint conference on artificial intelli- gence (IJCAI). 2009.</p>
<p>Action understanding as inverse planning. C L Baker, R Saxe, J B Tenenbaum, Cognition. 1133Baker CL, Saxe R, Tenenbaum JB. Action understanding as inverse planning. Cognition. 2009;113(3):329- 349.</p>
<p>Plan recognition as planning revisited. S Sohrabi, A V Riabov, O Udrea, International joint conference on artificial intelligence (IJCAI). New York, NYSohrabi S, Riabov AV, Udrea O. Plan recognition as planning revisited. In: International joint conference on artificial intelligence (IJCAI). New York, NY. 2016. p. 3258-3264.</p>
<p>Goal recognition over POMDPs: Inferring the intention of a pomdp agent. M Ramirez, H Geffner, International joint conference on artificial intelligence (IJCAI). Ramirez M, Geffner H. Goal recognition over POMDPs: Inferring the intention of a pomdp agent. In: Inter- national joint conference on artificial intelligence (IJCAI). 2011.</p>
<p>Bayesian theory of mind: Modeling joint belief-desire attribution. C Baker, R Saxe, J Tenenbaum, Proceedings of the annual meeting of the cognitive science society. the annual meeting of the cognitive science society33Baker C, Saxe R, Tenenbaum J. Bayesian theory of mind: Modeling joint belief-desire attribution. In: Pro- ceedings of the annual meeting of the cognitive science society. Vol. 33. 2011.</p>
<p>Active goal recognition. M Shvo, S A Mcilraith, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence34Shvo M, McIlraith SA. Active goal recognition. In: Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 34. 2020. p. 9957-9966.</p>
<p>Active goal recognition. C Amato, A Baisero, arXiv:190911173arXiv preprintAmato C, Baisero A. Active goal recognition. arXiv preprint arXiv:190911173. 2019;.</p>
<p>Perceiving the unusual: Temporal properties of hierarchical motor representations for action perception. Y Demiris, G Simmons, Neural Networks. 193Demiris Y, Simmons G. Perceiving the unusual: Temporal properties of hierarchical motor representations for action perception. Neural Networks. 2006;19(3):272-284.</p>
<p>Toward combining domain theory and recipes in plan recognition. R E Cardona-Rivera, R M Young, Workshops at the thirty-first aaai conference on artificial intelligence. Cardona-Rivera RE, Young RM. Toward combining domain theory and recipes in plan recognition. In: Workshops at the thirty-first aaai conference on artificial intelligence. 2017.</p>
<p>An active inference model of hierarchical action understanding, learning and imitation. R Proietti, G Pezzulo, A Tessari, PsyArXiv. Proietti R, Pezzulo G, Tessari A. An active inference model of hierarchical action understanding, learning and imitation. PsyArXiv. 2021;.</p>
<p>Online bayesian goal inference for boundedly rational planning agents. T Zhi-Xuan, J Mann, T Silver, J Tenenbaum, V Mansinghka, H Larochelle, M Ranzato, R Hadsell, M Balcan, H Lin, Advances in neural information processing systems. Curran Associates, Inc33Zhi-Xuan T, Mann J, Silver T, Tenenbaum J, Mansinghka V. Online bayesian goal inference for boundedly rational planning agents. In: Larochelle H, Ranzato M, Hadsell R, Balcan M, Lin H, ed- itors. Advances in neural information processing systems. Vol. 33. Curran Associates, Inc.. 2020. p. 19238-19250. Available from: https://proceedings.neurips.cc/paper/2020/file/ df3aebc649f9e3b674eeb790a4da224e-Paper.pdf.</p>
<p>Perceptual perspective taking and action recognition. M Johnson, Y Demiris, International Journal of Advanced Robotic Systems. 2432Johnson M, Demiris Y. Perceptual perspective taking and action recognition. International Journal of Ad- vanced Robotic Systems. 2005;2(4):32.</p>
<p>Towards a task-aware proactive sociable robot based on multi-state perspective-taking. A K Pandey, M Ali, R Alami, International Journal of Social Robotics. 52Pandey AK, Ali M, Alami R. Towards a task-aware proactive sociable robot based on multi-state perspective-taking. International Journal of Social Robotics. 2013;5(2):215-236.</p>
<p>Computational modeling of embodied visual perspective taking. T Fischer, Y Demiris, IEEE Transactions on Cognitive and Developmental Systems. 124Fischer T, Demiris Y. Computational modeling of embodied visual perspective taking. IEEE Transactions on Cognitive and Developmental Systems. 2019;12(4):723-732.</p>
<p>. F Torabi, G Warnell, P Stone, 1905Recent advances in imitation learning from observation. arXiv e-printsTorabi F, Warnell G, Stone P. Recent advances in imitation learning from observation. arXiv e-prints. 2019; :arXiv-1905.</p>
<p>The role of roles: Physical cooperation between humans and robots. A Mörtl, M Lawitzky, A Kucukyilmaz, M Sezgin, C Basdogan, S Hirche, The International Journal of Robotics Research. 3113Mörtl A, Lawitzky M, Kucukyilmaz A, Sezgin M, Basdogan C, Hirche S. The role of roles: Physical cooper- ation between humans and robots. The International Journal of Robotics Research. 2012;31(13):1656-1674.</p>
<p>A framework of human-robot coordination based on game theory and policy iteration. Y Li, K P Tee, R Yan, W L Chan, Y Wu, IEEE Transactions on Robotics. 326Li Y, Tee KP, Yan R, Chan WL, Wu Y. A framework of human-robot coordination based on game theory and policy iteration. IEEE Transactions on Robotics. 2016;32(6):1408-1418.</p>
<p>The body talks: Sensorimotor communication and its brain and kinematic signatures. G Pezzulo, F Donnarumma, H Dindo, D &apos;ausilio, A Konvalinka, I Castelfranchi, C , Physics of life reviews. 28Pezzulo G, Donnarumma F, Dindo H, D'Ausilio A, Konvalinka I, Castelfranchi C. The body talks: Sensori- motor communication and its brain and kinematic signatures. Physics of life reviews. 2019;28:1-21.</p>
<p>Implicit perception simplicity and explicit perception complexity in sensorimotor comunication. D Ognibene, G Giglia, L Marchegiani, D Rudrauf, Physics of life reviews. 28Ognibene D, Giglia G, Marchegiani L, Rudrauf D. Implicit perception simplicity and explicit perception complexity in sensorimotor comunication. Physics of life reviews. 2019;28:36-38.</p>
<p>Trust in robots: Challenges and opportunities. B C Kok, H Soh, Current Robotics Reports. 14Kok BC, Soh H. Trust in robots: Challenges and opportunities. Current Robotics Reports. 2020;1(4):297- 309.</p>
<p>The nature of explanation. K Craik, Cambridge University PressCambridgeCraik K. The nature of explanation. Cambridge: Cambridge University Press. 1943.</p>
<p>H Von Helmholtz, Handbuch der physiologischen optik. Leipzig: L. Voss. 1867. von Helmholtz H. Handbuch der physiologischen optik. Leipzig: L. Voss. 1867.</p>
<p>Knowledge in perception and illusion. R L Gregory, Philosophical Transactions of the Royal Society B: Biological Sciences. 352Gregory RL. Knowledge in perception and illusion. Philosophical Transactions of the Royal Society B: Biological Sciences. 1997;352:1121-1128.</p>
<p>K Doya, S Ishii, A Pouget, Rpn Rao, Bayesian brain: Probabilistic approaches to neural coding. MIT Press1st ed. TheDoya K, Ishii S, Pouget A, Rao RPN, editors. Bayesian brain: Probabilistic approaches to neural coding. 1st ed. The MIT Press. 2007.</p>
<p>The brain produces mind by modeling. Proceedings of the National Academy of Sciences. R M Shiffrin, D S Bassett, N Kriegeskorte, J B Tenenbaum, 117Shiffrin RM, Bassett DS, Kriegeskorte N, Tenenbaum JB. The brain produces mind by modeling. Proceed- ings of the National Academy of Sciences. 2020;117(47):29299-29301.</p>
<p>Bayesian inference with probabilistic population codes. W J Ma, J M Beck, P E Latham, A Pouget, 10.1038/nn1790Nat Neurosci. 911Ma WJ, Beck JM, Latham PE, Pouget A. Bayesian inference with probabilistic population codes. Nat Neu- rosci. 2006;9(11):1432-1438. Available from: http://dx.doi.org/10.1038/nn1790.</p>
<p>Neural dynamics as sampling: a model for stochastic computation in recurrent networks of spiking neurons. L Buesing, J Bill, B Nessler, W Maass, PLoS Comput Biol. 7111002211Buesing L, Bill J, Nessler B, Maass W. Neural dynamics as sampling: a model for stochastic computation in recurrent networks of spiking neurons. PLoS Comput Biol. 2011;7(11):e1002211.</p>
<p>Local reliability weighting explains identification of partially masked objects in natural images. S Sebastian, E S Seemiller, W S Geisler, Proceedings of the National Academy of Sciences. 11747Sebastian S, Seemiller ES, Geisler WS. Local reliability weighting explains identification of partially masked objects in natural images. Proceedings of the National Academy of Sciences. 2020;117(47):29363- 29370.</p>
<p>How humans learn and represent networks. C W Lynn, D S Bassett, Proceedings of the National Academy of Sciences. 11747Lynn CW, Bassett DS. How humans learn and represent networks. Proceedings of the National Academy of Sciences. 2020;117(47):29407-29415.</p>
<p>Spontaneous cortical activity reveals hallmarks of an optimal internal model of the environment. P Berkes, G Orban, M Lengyel, J Fiser, Science. 3316013Berkes P, Orban G, Lengyel M, Fiser J. Spontaneous cortical activity reveals hallmarks of an optimal internal model of the environment. Science. 2011;331(6013):83-87.</p>
<p>Time-compressed preplay of anticipated events in human primary visual cortex. M Ekman, P Kok, F P De Lange, Nature Communications. 81Ekman M, Kok P, de Lange FP. Time-compressed preplay of anticipated events in human primary visual cortex. Nature Communications. 2017;8(1):1-9.</p>
<p>Model-based influences on humans' choices and striatal prediction errors. N D Daw, S J Gershman, B Seymour, P Dayan, R J Dolan, Neuron. 696Daw ND, Gershman SJ, Seymour B, Dayan P, Dolan RJ. Model-based influences on humans' choices and striatal prediction errors. Neuron. 2011;69(6):1204-1215.</p>
<p>Tracking the time course of bayesian inference with event related potentials: a study using the central cue posner paradigm. C M Gómez, A Arjona, F Donnarumma, D Maisto, Rodríguez Martínez, E I Pezzulo, G , Frontiers in Psychology. 101424Gómez CM, Arjona A, Donnarumma F, Maisto D, Rodríguez Martínez EI, Pezzulo G. Tracking the time course of bayesian inference with event related potentials: a study using the central cue posner paradigm. Frontiers in Psychology. 2019;10:1424.</p>
<p>Contextual feedback to superficial layers of v1. L Muckli, De Martino, F Vizioli, L Petro, L S Smith, F W Ugurbil, K Goebel, R Yacoub, E , Current Biology. 2520Muckli L, De Martino F, Vizioli L, Petro LS, Smith FW, Ugurbil K, Goebel R, Yacoub E. Contextual feedback to superficial layers of v1. Current Biology. 2015;25(20):2690-2695.</p>
<p>Evaluating the neurophysiological evidence for predictive processing as a model of perception. K S Walsh, D P Mcgovern, A Clark, R G O&apos;connell, Annals of the new York Academy of Sciences. 14641Walsh KS, McGovern DP, Clark A, O'Connell RG. Evaluating the neurophysiological evidence for predic- tive processing as a model of perception. Annals of the new York Academy of Sciences. 2020;1464(1):242- 268.</p>
<p>Complex brain networks: graph theoretical analysis of structural and functional systems. E Bullmore, O Sporns, Nature reviews neuroscience. 103Bullmore E, Sporns O. Complex brain networks: graph theoretical analysis of structural and functional systems. Nature reviews neuroscience. 2009;10(3):186-198.</p>
<p>A standard model of the mind: Toward a common computational framework across artificial intelligence, cognitive science, neuroscience, and robotics. AI Magazine. J E Laird, C Lebiere, P S Rosenbloom, 38Laird JE, Lebiere C, Rosenbloom PS. A standard model of the mind: Toward a common computational framework across artificial intelligence, cognitive science, neuroscience, and robotics. AI Magazine. 2017; 38(4):13-26.</p>
<p>Situating the default-mode network along a principal gradient of macroscale cortical organization. D S Margulies, S S Ghosh, A Goulas, M Falkiewicz, J M Huntenburg, G Langs, G Bezgin, S B Eickhoff, F X Castellanos, M Petrides, Proceedings of the National Academy of Sciences. 11344Margulies DS, Ghosh SS, Goulas A, Falkiewicz M, Huntenburg JM, Langs G, Bezgin G, Eickhoff SB, Castellanos FX, Petrides M, et al.. Situating the default-mode network along a principal gradient of macroscale cortical organization. Proceedings of the National Academy of Sciences. 2016;113(44):12574- 12579.</p>
<p>what" and "where" in the human brain. L Ungerleider, J Haxby, Current Opinion in Neurobiology. 42Ungerleider L, Haxby J. "what" and "where" in the human brain. Current Opinion in Neurobiology. 1994; 4(2):157-65.</p>
<p>A whole brain probabilistic generative model: Toward realizing cognitive architectures for developmental robots. T Taniguchi, H Yamakawa, T Nagai, K Doya, M Sakagami, M Suzuki, T Nakamura, A Taniguchi, Neural Networks. 150Taniguchi T, Yamakawa H, Nagai T, Doya K, Sakagami M, Suzuki M, Nakamura T, Taniguchi A. A whole brain probabilistic generative model: Toward realizing cognitive architectures for developmental robots. Neural Networks. 2022;150:293-312.</p>
<p>Recurrent dynamics in the cerebral cortex: Integration of sensory evidence with stored knowledge. W Singer, Proceedings of the National Academy of Sciences. 118332101043118Singer W. Recurrent dynamics in the cerebral cortex: Integration of sensory evidence with stored knowledge. Proceedings of the National Academy of Sciences. 2021;118(33):e2101043118.</p>
<p>The secret life of predictive brains: what's spontaneous activity for? Trends in Cognitive Sciences. G Pezzulo, M Zorzi, M Corbetta, Pezzulo G, Zorzi M, Corbetta M. The secret life of predictive brains: what's spontaneous activity for? Trends in Cognitive Sciences. 2021;.</p>
<p>The brain from inside out. György Buzsáki, M , Oxford University PressGyörgy Buzsáki M. The brain from inside out. Oxford University Press. 2019.</p>
<p>Internally generated hippocampal sequences as a vantage point to probe future-oriented cognition. G Pezzulo, C Kemere, M Van Der Meer, Annals of the New York Academy of Sciences. 1396Pezzulo G, Kemere C, van der Meer M. Internally generated hippocampal sequences as a vantage point to probe future-oriented cognition. Annals of the New York Academy of Sciences. 2017;1396:144-165.</p>
<p>Statistical learning is not error-driven. bioRxiv. I Nazli, A Ferrari, C Huber-Huber, F P De Lange, Nazli I, Ferrari A, Huber-Huber C, de Lange FP. Statistical learning is not error-driven. bioRxiv. 2022;.</p>
<p>Navigating the affordance landscape: Feedback control as a process model of behavior and cognition. G Pezzulo, P Cisek, Trends in Cognitive Sciences. 206Pezzulo G, Cisek P. Navigating the affordance landscape: Feedback control as a process model of behavior and cognition. Trends in Cognitive Sciences. 2016;20(6):414-424.</p>
<p>Resynthesizing behavior through phylogenetic refinement. Attention, Perception, &amp; Psychophysics. P Cisek, 81Cisek P. Resynthesizing behavior through phylogenetic refinement. Attention, Perception, &amp; Psychophysics. 2019;81(7):2265-2287.</p>
<p>The role of cognitive architectures in general artificial intelligence. A Lieto, M Bhatt, A Oltramari, D Vernon, Lieto A, Bhatt M, Oltramari A, Vernon D. The role of cognitive architectures in general artificial intelligence. 2018.</p>
<p>40 years of cognitive architectures: core cognitive abilities and practical applications. I Kotseruba, J K Tsotsos, Artificial Intelligence Review. 531Kotseruba I, Tsotsos JK. 40 years of cognitive architectures: core cognitive abilities and practical applica- tions. Artificial Intelligence Review. 2020;53(1):17-94.</p>
<p>How can the human mind occur in the physical universe?. J R Anderson, Oxford University PressAnderson JR. How can the human mind occur in the physical universe? Oxford University Press. 2009.</p>
<p>Extending the soar cognitive architecture. J E Laird, Frontiers in Artificial Intelligence and Applications. 171224Laird JE. Extending the soar cognitive architecture. Frontiers in Artificial Intelligence and Applications. 2008;171:224.</p>
<p>Human symbol manipulation within an integrated cognitive architecture. In: Cognitive science. Routledge. J R Anderson, Anderson JR. Human symbol manipulation within an integrated cognitive architecture. In: Cognitive sci- ence. Routledge. 2005. p. 313-341.</p>
<p>Controlling a general purpose service robot by means of a cognitive architecture. J Y Puigbo, A Pumarola, R A Téllez, Ceur workshop proceedings. Puigbo JY, Pumarola A, Téllez RA. Controlling a general purpose service robot by means of a cognitive architecture. In: Ceur workshop proceedings. 2013. p. 45-55.</p>
<p>Learning to play mario. S Mohan, J E Laird, CCA-TR-2009-03Tech RepMohan S, Laird JE. Learning to play mario. Tech Rep CCA-TR-2009-03. 2009;.</p>
<p>The sigma cognitive architecture and system: Towards functionally elegant grand unification. P S Rosenbloom, A Demski, V Ustun, Journal of Artificial General Intelligence. 71Rosenbloom PS, Demski A, Ustun V. The sigma cognitive architecture and system: Towards functionally elegant grand unification. Journal of Artificial General Intelligence. 2016;7(1):1-103.</p>
<p>Toward an idiomatic framework for cognitive robotics. M R Damgaard, R Pedersen, T Bak, Patterns. 37100533Damgaard MR, Pedersen R, Bak T. Toward an idiomatic framework for cognitive robotics. Patterns. 2022; 3(7):100533.</p>
<p>Pyro: Deep universal probabilistic programming. E Bingham, J P Chen, M Jankowiak, F Obermeyer, N Pradhan, T Karaletsos, R Singh, P Szerlip, P Horsfall, N D Goodman, The Journal of Machine Learning Research. 201Bingham E, Chen JP, Jankowiak M, Obermeyer F, Pradhan N, Karaletsos T, Singh R, Szerlip P, Horsfall P, Goodman ND. Pyro: Deep universal probabilistic programming. The Journal of Machine Learning Research. 2019;20(1):973-978.</p>
<p>Learning disentangled representations with semi-supervised deep generative models. Advances in neural information processing systems. B Paige, J W Van De Meent, A Desmaison, N Goodman, P Kohli, F Wood, P Torr, 30Paige B, van de Meent JW, Desmaison A, Goodman N, Kohli P, Wood F, Torr P, et al.. Learning disentangled representations with semi-supervised deep generative models. Advances in neural information processing systems. 2017;30.</p>
<p>D Tran, A Kucukelbir, A B Dieng, M Rudolph, D Liang, D M Blei, Edward, arXiv:161009787A library for probabilistic modeling, inference, and criticism. arXiv preprintTran D, Kucukelbir A, Dieng AB, Rudolph M, Liang D, Blei DM. Edward: A library for probabilistic modeling, inference, and criticism. arXiv preprint arXiv:161009787. 2016;.</p>
<p>Social cognition for human-robot symbiosis-challenges and building blocks. G Sandini, V Mohan, A Sciutti, P Morasso, Frontiers in neurorobotics. 1234Sandini G, Mohan V, Sciutti A, Morasso P. Social cognition for human-robot symbiosis-challenges and building blocks. Frontiers in neurorobotics. 2018;12:34.</p>
<p>Anatomy of the Mind: Exploring Psychological Mechanisms and Processes with the Clarion Cognitive Architecture. R Sun, Oxford University PressSun R. Anatomy of the Mind: Exploring Psychological Mechanisms and Processes with the Clarion Cogni- tive Architecture. Oxford University Press. 2016.</p>
<p>A perspective on judgment and choice: mapping bounded rationality. D Kahneman, American psychologist. 589697Kahneman D. A perspective on judgment and choice: mapping bounded rationality. American psychologist. 2003;58(9):697.</p>
<p>The robot software framework armarx. it-Information Technology. N Vahrenkamp, M Wächter, M Kröhnert, K Welke, T Asfour, 57Vahrenkamp N, Wächter M, Kröhnert M, Welke K, Asfour T. The robot software framework armarx. it- Information Technology. 2015;57(2):99-111.</p>
<p>Serket: An architecture for connecting stochastic models to realize a large-scale cognitive model. T Nakamura, T Nagai, T Taniguchi, Frontiers in Neurorobotics. 12Nakamura T, Nagai T, Taniguchi T. Serket: An architecture for connecting stochastic models to realize a large-scale cognitive model. Frontiers in Neurorobotics. 2018;12:1-16.</p>
<p>Neuro-serket: development of integrative cognitive system through the composition of deep probabilistic generative models. T Taniguchi, T Nakamura, M Suzuki, R Kuniyasu, K Hayashi, A Taniguchi, T Horii, T Nagai, New Generation Computing. Taniguchi T, Nakamura T, Suzuki M, Kuniyasu R, Hayashi K, Taniguchi A, Horii T, Nagai T. Neuro-serket: development of integrative cognitive system through the composition of deep probabilistic generative mod- els. New Generation Computing. 2020;:1-26.</p>
<p>J Devlin, M W Chang, K Lee, Toutanova K Bert, arXiv:181004805Pre-training of deep bidirectional transformers for language understanding. arXiv preprintDevlin J, Chang MW, Lee K, Toutanova K. BERT: Pre-training of deep bidirectional transformers for lan- guage understanding. arXiv preprint arXiv:181004805. 2019;.</p>
<p>Language models are few-shot learners. Advances in neural information processing systems. T Brown, B Mann, N Ryder, M Subbiah, J D Kaplan, P Dhariwal, A Neelakantan, P Shyam, G Sastry, A Askell, 33Brown T, Mann B, Ryder N, Subbiah M, Kaplan JD, Dhariwal P, Neelakantan A, Shyam P, Sastry G, Askell A, et al.. Language models are few-shot learners. Advances in neural information processing systems. 2020; 33:1877-1901.</p>
<p>Self-consistency improves chain of thought reasoning in language models. X Wang, J Wei, D Schuurmans, Q Le, Chi E Zhou, D , arXiv:220311171. 2022arXiv preprintWang X, Wei J, Schuurmans D, Le Q, Chi E, Zhou D. Self-consistency improves chain of thought reasoning in language models. arXiv preprint arXiv:220311171. 2022;.</p>
<p>Large language models are zero-shot reasoners. T Kojima, S S Gu, M Reid, Y Matsuo, Y Iwasawa, arXiv:220511916. 2022arXiv preprintKojima T, Gu SS, Reid M, Matsuo Y, Iwasawa Y. Large language models are zero-shot reasoners. arXiv preprint arXiv:220511916. 2022;.</p>
<p>Do as i can and not as i say: Grounding language in robotic affordances. M Ahn, A Brohan, N Brown, Y Chebotar, O Cortes, B David, C Finn, C Fu, K Gopalakrishnan, K Hausman, A Herzog, D Ho, J Hsu, J Ibarz, B Ichter, A Irpan, E Jang, R J Ruano, K Jeffrey, S Jesmonth, N Joshi, R Julian, D Kalashnikov, Y Kuang, K H Lee, S Levine, Y Lu, L Luu, C Parada, P Pastor, J Quiambao, K Rao, J Rettinghouse, D Reyes, P Sermanet, N Sievers, C Tan, A Toshev, V Vanhoucke, F Xia, T Xiao, P Xu, S Xu, M Yan, A Zeng, In: arxiv preprint arxiv:2204.01691. 2022Ahn M, Brohan A, Brown N, Chebotar Y, Cortes O, David B, Finn C, Fu C, Gopalakrishnan K, Hausman K, Herzog A, Ho D, Hsu J, Ibarz J, Ichter B, Irpan A, Jang E, Ruano RJ, Jeffrey K, Jesmonth S, Joshi N, Julian R, Kalashnikov D, Kuang Y, Lee KH, Levine S, Lu Y, Luu L, Parada C, Pastor P, Quiambao J, Rao K, Rettinghouse J, Reyes D, Sermanet P, Sievers N, Tan C, Toshev A, Vanhoucke V, Xia F, Xiao T, Xu P, Xu S, Yan M, Zeng A. Do as i can and not as i say: Grounding language in robotic affordances. In: arxiv preprint arxiv:2204.01691. 2022.</p>
<p>Survey on frontiers of language and robotics. T Tangiuchi, D Mochihashi, T Nagai, S Uchida, N Inoue, I Kobayashi, T Nakamura, Y Hagiwara, N Iwahashi, T Inamura, Advanced Robotics. 33Tangiuchi T, Mochihashi D, Nagai T, Uchida S, Inoue N, Kobayashi I, Nakamura T, Hagiwara Y, Iwahashi N, Inamura T. Survey on frontiers of language and robotics. Advanced Robotics. 2019;33(15-16):700-730.</p>
<p>The symbol grounding problem has been solved, so what's next ? In: Symbols and embodiment: Debates on meaning and cognition. L Steels, Oxford University PressSteels L. The symbol grounding problem has been solved, so what's next ? In: Symbols and embodiment: Debates on meaning and cognition. Oxford University Press. 2008. p. 223-244.</p>
<p>Symbol emergence in cognitive developmental systems: a survey. T Taniguchi, E Ugur, M Hoffmann, L Jamone, T Nagai, B Rosman, T Matsuka, N Iwahashi, E Oztop, J Piater, IEEE transactions on Cognitive and Developmental Systems. 114Taniguchi T, Ugur E, Hoffmann M, Jamone L, Nagai T, Rosman B, Matsuka T, Iwahashi N, Oztop E, Piater J, et al.. Symbol emergence in cognitive developmental systems: a survey. IEEE transactions on Cognitive and Developmental Systems. 2018;11(4):494-516.</p>
<p>Symbol emergence in robotics: A survey. T Taniguchi, T Nagai, T Nakamura, N Iwahashi, T Ogata, H Asoh, Advanced Robotics. 30Taniguchi T, Nagai T, Nakamura T, Iwahashi N, Ogata T, Asoh H. Symbol emergence in robotics: A survey. Advanced Robotics. 2016;30(11-12):706-728.</p>
<p>Goal-directed behavior under variational predictive coding: Dynamic organization of visual attention and working memory. M Jung, T Matsumoto, J Tani, IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). Jung M, Matsumoto T, Tani J. Goal-directed behavior under variational predictive coding: Dynamic organi- zation of visual attention and working memory. In: IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). 2019. p. 1040-1047.</p>
<p>Efficient multitask learning with an embodied predictive model for door opening and entry with whole-body control. H Ito, K Yamamoto, H Mori, T Ogata, Science Robotics. 7658177Ito H, Yamamoto K, Mori H, Ogata T. Efficient multitask learning with an embodied predictive model for door opening and entry with whole-body control. Science Robotics. 2022;7(65):eaax8177.</p>
<p>Robot in the mirror: toward an embodied computational model of mirror self-recognition. KI-Künstliche Intelligenz. M Hoffmann, S Wang, V Outrata, E Alzueta, P Lanillos, 35Hoffmann M, Wang S, Outrata V, Alzueta E, Lanillos P. Robot in the mirror: toward an embodied computa- tional model of mirror self-recognition. KI-Künstliche Intelligenz. 2021;35(1):37-51.</p>
<p>On the link between conscious function and general intelligence in humans and machines. A Juliani, K Arulkumaran, S Sasai, R Kanai, arXiv:220405133. 2022arXiv preprintJuliani A, Arulkumaran K, Sasai S, Kanai R. On the link between conscious function and general intelligence in humans and machines. arXiv preprint arXiv:220405133. 2022;.</p>
<p>Interoceptive inference, emotion, and the embodied self. A K Seth, Trends in cognitive sciences. 1711Seth AK. Interoceptive inference, emotion, and the embodied self. Trends in cognitive sciences. 2013; 17(11):565-573.</p>
<p>The role of valence and meta-awareness in mirror self-recognition using hierarchical active inference. J Bauermeister, P Lanillos, arXiv:220813213. 2022arXiv preprintBauermeister J, Lanillos P. The role of valence and meta-awareness in mirror self-recognition using hierar- chical active inference. arXiv preprint arXiv:220813213. 2022;.</p>
<p>Survey and perspective on social emotions in robotics. C Hieida, T Nagai, Advanced Robotics. 361-2Hieida C, Nagai T. Survey and perspective on social emotions in robotics. Advanced Robotics. 2022;36(1- 2):17-32.</p>
<p>Serket-SDE: A Containerized Software Development Environment for the Symbol Emergence in Robotics Toolkit. L El Hafi, Y Zheng, H Shirouzu, T Nakamura, T Taniguchi, IEEE/SICE International Symposium on System Integration (SII). El Hafi L, Zheng Y, Shirouzu H, Nakamura T, Taniguchi T. Serket-SDE: A Containerized Software Develop- ment Environment for the Symbol Emergence in Robotics Toolkit. In: IEEE/SICE International Symposium on System Integration (SII). 2023.</p>
<p>pymdp: A python library for active inference in discrete state spaces. C Heins, B Millidge, D Demekas, B Klein, K Friston, I Couzin, A Tschantz, arXiv:220103904. 2022arXiv preprintHeins C, Millidge B, Demekas D, Klein B, Friston K, Couzin I, Tschantz A. pymdp: A python library for active inference in discrete state spaces. arXiv preprint arXiv:220103904. 2022;.</p>
<p>. S Reed, K Zolna, E Parisotto, S G Colmenarejo, A Novikov, G Barth-Maron, M Gimenez, Y Sulsky, J Kay, J T Springenberg, arXiv:220506175. 2022A generalist agent. arXiv preprintReed S, Zolna K, Parisotto E, Colmenarejo SG, Novikov A, Barth-Maron G, Gimenez M, Sulsky Y, Kay J, Springenberg JT, et al.. A generalist agent. arXiv preprint arXiv:220506175. 2022;.</p>
<p>Passive dynamic walking. T Mcgeer, Int J Robotics Res. 92McGeer T, et al.. Passive dynamic walking. Int J Robotics Res. 1990;9(2):62-82.</p>
<p>Elephants don't play chess. Robotics and autonomous systems. R A Brooks, 6Brooks RA. Elephants don't play chess. Robotics and autonomous systems. 1990;6(1-2):3-15.</p>
<p>Self-organization, embodiment, and biologically inspired robotics. science. R Pfeifer, M Lungarella, F Iida, 318Pfeifer R, Lungarella M, Iida F. Self-organization, embodiment, and biologically inspired robotics. science. 2007;318(5853):1088-1093.</p>
<p>Morphological computation-connecting brain, body, and environment. In: Creating brain-like intelligence. R Pfeifer, G Gómez, SpringerPfeifer R, Gómez G. Morphological computation-connecting brain, body, and environment. In: Creating brain-like intelligence. Springer. 2009. p. 66-83.</p>            </div>
        </div>

    </div>
</body>
</html>