<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-842 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-842</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-842</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-23.html">extraction-schema-23</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that use probabilistic symbolic world models (such as PPDDL, PDDL, or belief states) for planning in text-based environments, especially those that integrate uncertainty from large language models.</div>
                <p><strong>Paper ID:</strong> paper-272832315</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2409.15865v2.pdf" target="_blank">BeSimulator: A Large Language Model Powered Text-based Behavior Simulator</a></p>
                <p><strong>Paper Abstract:</strong> —Traditional robot simulators focus on physical process modeling and realistic rendering, often suffering from high computational costs, inefficiencies, and limited adaptability. To handle this issue, we propose Behavior Simulation in robotics to emphasize checking the behavior logic of robots and achieving sufficient alignment between the outcome of robot actions and real scenarios. In this paper, we introduce BeSimulator, a modular and novel LLM-powered framework, as an attempt towards behavior simulation in the context of text-based environments. By constructing text-based virtual environments and performing semantic-level simulation, BeSimulator can generalize across scenarios and achieve long-horizon complex simulation. Inspired by human cognition processes, it employs a “consider-decide-capture-transfer” methodology, termed Chain of Behavior Simulation, which excels at analyzing action feasibility and state transitions. Additionally, BeSimulator incorporates code-driven reasoning to enable arithmetic operations and enhance reliability, as well as integrates reflective feedback to refine simulation. Based on our manually constructed behavior-tree-based simulation benchmark BTSIMBENCH, our experiments show a significant performance improvement in behavior simulation compared to baselines, ranging from 14.7% to 26.6%.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e842.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e842.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that use probabilistic symbolic world models (such as PPDDL, PDDL, or belief states) for planning in text-based environments, especially those that integrate uncertainty from large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BeSimulator</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BeSimulator: A Large Language Model Powered Text-based Behavior Simulator</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An LLM-powered, modular framework that simulates robot behavior-planning solutions in text-based virtual environments using a structured world-state manager and a four-phase Chain of Behavior Simulation (CBS) to analyze action feasibility and state transitions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>BeSimulator</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>BeSimulator constructs text-based simulation cases from robot task descriptions, maintains a structured textual world state manager, and simulates Behavior Planning Solutions (BPS, studied with Behavior Trees) step-by-step. For each action it runs a four-phase Chain of Behavior Simulation (consider → decide → capture → transfer) that (1) extracts preconditions and critical states, (2) evaluates precondition satisfaction (using semantic reasoning or code-driven numeric checks), (3) captures which states will change, and (4) generates precise state updates. It integrates code-driven reasoning (generates Python and executes it to handle numerical computations) and a reflective feedback loop (syntactic and semantic checking of LLM outputs) to iteratively correct LLM errors. Evaluation uses a dedicated benchmark (BTSIMBENCH) and py_trees for BT execution control.</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_type</strong></td>
                            <td>Structured textual/symbolic state manager (task-specific symbolic dictionaries); deterministic state-transition simulation driven by LLM reasoning (not PPDDL/PPDDL-like belief states)</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_description</strong></td>
                            <td>World state is represented as structured dictionaries of entities, entity properties, and hierarchical state keys (A-B-C naming). Actions are represented semantically (action descriptions / BT nodes). State transitions are predicted by the LLM via the CBS pipeline and applied to the textual world-state manager. Transitions are treated deterministically in the simulator (LLM produces the next state); numerical computations are delegated to generated code for precision. There is no explicit probabilistic transition model (no PPDDL, explicit belief states, or distributional transition representation reported).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_llm</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>llm_role</strong></td>
                            <td>world model construction and simulation (state estimation, precondition inference, state-transition prediction), case generation, and evaluation/analysis of BPS; also used as judge/baseline in comparisons</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td>Claude-3.5-Sonnet; DeepSeek-V3; Qwen2-72B-Instruct; Llama3.1-70B-Instruct (these LLMs were used as base models in experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_modeling</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_method</strong></td>
                            <td>Reflective feedback loop (syntactic/semantic checking and iterative re-query to LLM) and selection strategies (Best-of-N baseline used for comparison); no explicit probabilistic representation (no belief-state, PPDDL, or probability distributions reported)</td>
                        </tr>
                        <tr>
                            <td><strong>planning_algorithm</strong></td>
                            <td>Behavior Trees (BT) execution controlled by py_trees; the system simulates the BT control flow (leaf action/condition nodes handled by CBS).</td>
                        </tr>
                        <tr>
                            <td><strong>planning_integrates_uncertainty</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_name</strong></td>
                            <td>BTSIMBENCH (text-based BT simulation cases constructed from BEHAVIOR-1K tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_description</strong></td>
                            <td>A text-based benchmark of 75 Behavior Trees (BTs) derived from 25 long-horizon, manipulation-heavy tasks in BEHAVIOR-1K; each case is a textual simulation case containing entities, relationships, and environment information used to exercise BT control logic in simulation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Delivery rate (successful production of valid simulation output within reflective-feedback budget) and Accuracy (proportion of BTs correctly classified into Good / Counterfactuals / Unreachable). Also measured: accuracy extracting action preconditions (Acc_AP) and accuracy updating world states (Acc_WS).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>BeSimulator improves average accuracy vs baselines by 13.60%–24.80% absolute across base LLMs (example: DeepSeek-V3 saw a +24.80% absolute improvement, a 37.80% relative improvement over CoT). Example per-LM quantitative metrics (Table 5): Claude-3.5-Sonnet Acc_AP=94.67%, Acc_WS=98.67%; DeepSeek-V3 Acc_AP=96.00%, Acc_WS=97.33%; Qwen2-72B-Instruct Acc_AP=78.67%, Acc_WS=94.67%; Llama3.1-70B-Instruct Acc_AP=85.33%, Acc_WS=88.00%. Example category result: on Qwen2-72B-Instruct BeSimulator achieves 90.40% accuracy on Counterfactuals BTs while the BoN baseline yielded 1.60% on that category.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Baselines: Chain of Thought (CoT) and Best-of-N with an LLM judge (BoN). BoN generally outperforms CoT; both baselines show comparatively poor performance detecting Counterfactuals and Unreachable BTs (e.g., BoN on Qwen2 Counterfactuals reported as 1.6%). Exact baseline numbers vary per LLM and category in the paper's tables.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_uncertainty</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td>Ablations remove components of BeSimulator: (1) Replacing CBS four-phase with single-phase reduces accuracy (CBS gives large gains in detecting indirectly caused state changes), (2) Removing code-driven reasoning ('w/o Code') decreases performance especially on Good and Unreachable categories because LLMs hallucinate on arithmetic/comparison tasks, (3) Removing reflective feedback reduces delivery rate by 5.33% (LLMs more often fail to produce syntactically/semantically valid outputs). No explicit ablation on probabilistic uncertainty modeling because none was implemented.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>LLMs can act as effective textual world models for behavior-level simulation, especially when supported by structured decomposition (CBS), code-driven numeric checks, and reflective feedback; however, this work does not implement formal probabilistic symbolic world models (e.g., PPDDL or belief-state planning) nor explicitly propagate LLM uncertainty into a probabilistic planner. Instead, the paper addresses LLM unreliability with iterative checking and code execution rather than probability distributions or belief-state planning. The approach is effective at detecting logic defects in BTs and improving simulation accuracy versus scenario-agnostic CoT baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'BeSimulator: A Large Language Model Powered Text-based Behavior Simulator', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e842.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e842.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that use probabilistic symbolic world models (such as PPDDL, PDDL, or belief states) for planning in text-based environments, especially those that integrate uncertainty from large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CBS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chain of Behavior Simulation (consider-decide-capture-transfer)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A four-phase atomic action simulation procedure that decomposes action simulation into: (1) consider: infer preconditions and crucial states; (2) decide: evaluate precondition satisfaction (semantic or code-driven checks); (3) capture: identify states that will be affected; (4) transfer: generate concrete state updates applied to the world-state manager.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Chain of Behavior Simulation (CBS)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>CBS is the core per-action reasoning pipeline inside BeSimulator. For each action node CBS: (1) extracts and lists preconditions and their critical state variables; (2) checks each precondition with semantic reasoning or by running generated code for numeric checks; (3) enumerates which state keys in the world-state manager will change (including indirectly affected states); (4) outputs specific state updates in JSON that the world-state manager applies. Condition nodes use the first two phases (consider & decide). CBS is used to reduce hallucination and capture indirect state effects that single-phase LLM prompting misses.</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_type</strong></td>
                            <td>Structured textual/symbolic state manager (hierarchical key names), deterministic stepwise transition produced by LLM and applied by the manager</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_description</strong></td>
                            <td>CBS operates over the textual symbolic representation (entity dictionaries and hierarchical A-B-C keys). It treats transitions as deterministic transformations decided by the LLM (with numeric steps delegated to code execution). CBS explicitly identifies dependencies and ordering of state updates but does not represent transitions probabilistically.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_llm</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>llm_role</strong></td>
                            <td>per-action reasoning: precondition extraction, precondition evaluation, identification of affected states, and generation of state-update descriptions and code for numeric checks</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td>Used with the same LLMs as BeSimulator (Claude-3.5-Sonnet; DeepSeek-V3; Qwen2-72B-Instruct; Llama3.1-70B-Instruct) in experiments</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_modeling</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_method</strong></td>
                            <td>No explicit probabilistic representation; uncertainty handled operationally by reflective feedback and re-querying LLM outputs rather than by belief states or probability distributions.</td>
                        </tr>
                        <tr>
                            <td><strong>planning_algorithm</strong></td>
                            <td>Applied within Behavior Tree (BT) node simulation; CBS itself is a per-action simulator rather than a global planner algorithm.</td>
                        </tr>
                        <tr>
                            <td><strong>planning_integrates_uncertainty</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_name</strong></td>
                            <td>BTSIMBENCH (used for evaluating CBS inside BeSimulator)</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_description</strong></td>
                            <td>Same as BeSimulator: text-based BT cases derived from BEHAVIOR-1K, long-horizon tasks requiring complex manipulation and multi-step reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Contribution measured by accuracy improvements in BT category classification and by ablation comparisons (accuracy and delivery rate).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Ablation shows four-phase CBS materially improves accuracy versus single-phase prompting: single-phase still beats CoT by ~13.07% on average, but full CBS further increases detection of indirect state changes and yields the highest accuracy gains reported (part of the +13.6%–24.8% total improvements).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to single-phase LLM prompting (one-shot analysis) and CoT baselines; CBS substantially outperforms single-phase in detecting indirect transitions and faulty BTs.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_uncertainty</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td>Removing CBS (replacing with single-phase simulation) reduces accuracy; CBS is particularly important for recovering indirect state transitions and improving Counterfactuals/Unreachable detection.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Decomposing action simulation into consider/decide/capture/transfer significantly improves LLM reliability at simulating state transitions and revealing logic defects; CBS improves detection of indirectly induced state changes that naive prompting misses. CBS, however, remains a deterministic reasoning pipeline and does not implement probabilistic belief tracking.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'BeSimulator: A Large Language Model Powered Text-based Behavior Simulator', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e842.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e842.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods that use probabilistic symbolic world models (such as PPDDL, PDDL, or belief states) for planning in text-based environments, especially those that integrate uncertainty from large language models.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BTSIMBENCH</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BTSIMBENCH (Behavior Tree Simulation Benchmark)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A text-based benchmark created for evaluating behavior-level simulation systems, consisting of 75 Behavior Trees for 25 tasks taken from BEHAVIOR-1K, including Good, Counterfactuals, and Unreachable BT variants for systematic evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>BTSIMBENCH</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Benchmark of 75 textual BT instances derived from BEHAVIOR-1K tasks; each task includes a Good BT and two defective variants (Counterfactuals and Unreachable) to test simulators' ability to detect logic defects. Cases include full textual scene descriptions (entities, relationships, environment info) and BT node descriptions, used to evaluate simulators' accuracy and delivery rate.</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_type</strong></td>
                            <td>Textual symbolic simulation cases (structured dictionaries of states) used as inputs for simulation systems; benchmark does not itself prescribe probabilistic models.</td>
                        </tr>
                        <tr>
                            <td><strong>world_model_description</strong></td>
                            <td>Each case encodes entity lists, hierarchical state keys, and relationships (A-B-C style keys) as the symbolic textual world representation that simulators consume; transitions are produced by the simulator/LLM under test.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_llm</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>llm_role</strong></td>
                            <td>BTSIMBENCH was created using LLMs to convert BEHAVIOR Domain Definition Language cases into textual descriptions and to construct BT variants; used as evaluation input for LLM-based simulators.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td>LLMs were used to convert BDDL to textual cases during dataset construction (paper does not fix a single model for construction)</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_modeling</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>planning_algorithm</strong></td>
                            <td>Designed to evaluate Behavior Tree based control logic; not a planner itself.</td>
                        </tr>
                        <tr>
                            <td><strong>planning_integrates_uncertainty</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_name</strong></td>
                            <td>BTSIMBENCH (constructed from BEHAVIOR-1K)</td>
                        </tr>
                        <tr>
                            <td><strong>text_environment_description</strong></td>
                            <td>Text-only BT simulation cases intended to test long-horizon manipulation tasks' control logic (Good and broken BT variants) with structured scene/state information; designed to expose indirect state changes and logical defects.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Accuracy (Good/Counterfactuals/Unreachable classification), Delivery Rate, Acc_AP (action precondition extraction accuracy), Acc_WS (world state update accuracy).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Used to produce the numbers reported for BeSimulator and baselines: e.g., Acc_AP and Acc_WS values in Table 5 (Claude-3.5-Sonnet Acc_AP=94.67% Acc_WS=98.67%; DeepSeek-V3 Acc_AP=96.00% Acc_WS=97.33%; Qwen2-72B-Instruct Acc_AP=78.67% Acc_WS=94.67%; Llama3.1-70B-Instruct Acc_AP=85.33% Acc_WS=88.00%). Overall BeSimulator yielded 13.60%–24.80% absolute accuracy gains over baselines across LM choices.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Benchmark used to compare BeSimulator vs CoT and Best-of-N (LLM judge). Baselines perform relatively well on Good BTs but poorly on Counterfactuals/Unreachable categories.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_uncertainty</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_results</strong></td>
                            <td>Benchmark was used to demonstrate ablation impacts of CBS, code-driven reasoning, and reflective feedback in BeSimulator; results show each component contributes materially to final performance (CBS largest for Counterfactuals, code-driven for numerical correctness, reflective feedback for delivery rate).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>BTSIMBENCH exposes that LLM-based text simulators can accurately update world states (high Acc_WS) but struggle more at reliably extracting correct action preconditions (lower Acc_AP); experiments on BTSIMBENCH show structured per-action reasoning (CBS) plus code execution and feedback significantly improves simulator reliability, but the benchmark and BeSimulator do not implement formal probabilistic symbolic planners or belief-state tracking.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'BeSimulator: A Large Language Model Powered Text-based Behavior Simulator', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Reasoning with language model is planning with world model <em>(Rating: 2)</em></li>
                <li>Can language models serve as text-based world simulators? <em>(Rating: 2)</em></li>
                <li>Large language models as commonsense knowledge for large-scale task planning <em>(Rating: 2)</em></li>
                <li>Recurrent world models facilitate policy evolution <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-842",
    "paper_id": "paper-272832315",
    "extraction_schema_id": "extraction-schema-23",
    "extracted_data": [
        {
            "name_short": "BeSimulator",
            "name_full": "BeSimulator: A Large Language Model Powered Text-based Behavior Simulator",
            "brief_description": "An LLM-powered, modular framework that simulates robot behavior-planning solutions in text-based virtual environments using a structured world-state manager and a four-phase Chain of Behavior Simulation (CBS) to analyze action feasibility and state transitions.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "BeSimulator",
            "system_description": "BeSimulator constructs text-based simulation cases from robot task descriptions, maintains a structured textual world state manager, and simulates Behavior Planning Solutions (BPS, studied with Behavior Trees) step-by-step. For each action it runs a four-phase Chain of Behavior Simulation (consider → decide → capture → transfer) that (1) extracts preconditions and critical states, (2) evaluates precondition satisfaction (using semantic reasoning or code-driven numeric checks), (3) captures which states will change, and (4) generates precise state updates. It integrates code-driven reasoning (generates Python and executes it to handle numerical computations) and a reflective feedback loop (syntactic and semantic checking of LLM outputs) to iteratively correct LLM errors. Evaluation uses a dedicated benchmark (BTSIMBENCH) and py_trees for BT execution control.",
            "world_model_type": "Structured textual/symbolic state manager (task-specific symbolic dictionaries); deterministic state-transition simulation driven by LLM reasoning (not PPDDL/PPDDL-like belief states)",
            "world_model_description": "World state is represented as structured dictionaries of entities, entity properties, and hierarchical state keys (A-B-C naming). Actions are represented semantically (action descriptions / BT nodes). State transitions are predicted by the LLM via the CBS pipeline and applied to the textual world-state manager. Transitions are treated deterministically in the simulator (LLM produces the next state); numerical computations are delegated to generated code for precision. There is no explicit probabilistic transition model (no PPDDL, explicit belief states, or distributional transition representation reported).",
            "uses_llm": true,
            "llm_role": "world model construction and simulation (state estimation, precondition inference, state-transition prediction), case generation, and evaluation/analysis of BPS; also used as judge/baseline in comparisons",
            "llm_model_name": "Claude-3.5-Sonnet; DeepSeek-V3; Qwen2-72B-Instruct; Llama3.1-70B-Instruct (these LLMs were used as base models in experiments)",
            "uncertainty_modeling": false,
            "uncertainty_type": null,
            "uncertainty_method": "Reflective feedback loop (syntactic/semantic checking and iterative re-query to LLM) and selection strategies (Best-of-N baseline used for comparison); no explicit probabilistic representation (no belief-state, PPDDL, or probability distributions reported)",
            "planning_algorithm": "Behavior Trees (BT) execution controlled by py_trees; the system simulates the BT control flow (leaf action/condition nodes handled by CBS).",
            "planning_integrates_uncertainty": false,
            "text_environment_name": "BTSIMBENCH (text-based BT simulation cases constructed from BEHAVIOR-1K tasks)",
            "text_environment_description": "A text-based benchmark of 75 Behavior Trees (BTs) derived from 25 long-horizon, manipulation-heavy tasks in BEHAVIOR-1K; each case is a textual simulation case containing entities, relationships, and environment information used to exercise BT control logic in simulation.",
            "performance_metric": "Delivery rate (successful production of valid simulation output within reflective-feedback budget) and Accuracy (proportion of BTs correctly classified into Good / Counterfactuals / Unreachable). Also measured: accuracy extracting action preconditions (Acc_AP) and accuracy updating world states (Acc_WS).",
            "performance_value": "BeSimulator improves average accuracy vs baselines by 13.60%–24.80% absolute across base LLMs (example: DeepSeek-V3 saw a +24.80% absolute improvement, a 37.80% relative improvement over CoT). Example per-LM quantitative metrics (Table 5): Claude-3.5-Sonnet Acc_AP=94.67%, Acc_WS=98.67%; DeepSeek-V3 Acc_AP=96.00%, Acc_WS=97.33%; Qwen2-72B-Instruct Acc_AP=78.67%, Acc_WS=94.67%; Llama3.1-70B-Instruct Acc_AP=85.33%, Acc_WS=88.00%. Example category result: on Qwen2-72B-Instruct BeSimulator achieves 90.40% accuracy on Counterfactuals BTs while the BoN baseline yielded 1.60% on that category.",
            "baseline_comparison": "Baselines: Chain of Thought (CoT) and Best-of-N with an LLM judge (BoN). BoN generally outperforms CoT; both baselines show comparatively poor performance detecting Counterfactuals and Unreachable BTs (e.g., BoN on Qwen2 Counterfactuals reported as 1.6%). Exact baseline numbers vary per LLM and category in the paper's tables.",
            "has_ablation_uncertainty": false,
            "ablation_results": "Ablations remove components of BeSimulator: (1) Replacing CBS four-phase with single-phase reduces accuracy (CBS gives large gains in detecting indirectly caused state changes), (2) Removing code-driven reasoning ('w/o Code') decreases performance especially on Good and Unreachable categories because LLMs hallucinate on arithmetic/comparison tasks, (3) Removing reflective feedback reduces delivery rate by 5.33% (LLMs more often fail to produce syntactically/semantically valid outputs). No explicit ablation on probabilistic uncertainty modeling because none was implemented.",
            "key_findings": "LLMs can act as effective textual world models for behavior-level simulation, especially when supported by structured decomposition (CBS), code-driven numeric checks, and reflective feedback; however, this work does not implement formal probabilistic symbolic world models (e.g., PPDDL or belief-state planning) nor explicitly propagate LLM uncertainty into a probabilistic planner. Instead, the paper addresses LLM unreliability with iterative checking and code execution rather than probability distributions or belief-state planning. The approach is effective at detecting logic defects in BTs and improving simulation accuracy versus scenario-agnostic CoT baselines.",
            "uuid": "e842.0",
            "source_info": {
                "paper_title": "BeSimulator: A Large Language Model Powered Text-based Behavior Simulator",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "CBS",
            "name_full": "Chain of Behavior Simulation (consider-decide-capture-transfer)",
            "brief_description": "A four-phase atomic action simulation procedure that decomposes action simulation into: (1) consider: infer preconditions and crucial states; (2) decide: evaluate precondition satisfaction (semantic or code-driven checks); (3) capture: identify states that will be affected; (4) transfer: generate concrete state updates applied to the world-state manager.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Chain of Behavior Simulation (CBS)",
            "system_description": "CBS is the core per-action reasoning pipeline inside BeSimulator. For each action node CBS: (1) extracts and lists preconditions and their critical state variables; (2) checks each precondition with semantic reasoning or by running generated code for numeric checks; (3) enumerates which state keys in the world-state manager will change (including indirectly affected states); (4) outputs specific state updates in JSON that the world-state manager applies. Condition nodes use the first two phases (consider & decide). CBS is used to reduce hallucination and capture indirect state effects that single-phase LLM prompting misses.",
            "world_model_type": "Structured textual/symbolic state manager (hierarchical key names), deterministic stepwise transition produced by LLM and applied by the manager",
            "world_model_description": "CBS operates over the textual symbolic representation (entity dictionaries and hierarchical A-B-C keys). It treats transitions as deterministic transformations decided by the LLM (with numeric steps delegated to code execution). CBS explicitly identifies dependencies and ordering of state updates but does not represent transitions probabilistically.",
            "uses_llm": true,
            "llm_role": "per-action reasoning: precondition extraction, precondition evaluation, identification of affected states, and generation of state-update descriptions and code for numeric checks",
            "llm_model_name": "Used with the same LLMs as BeSimulator (Claude-3.5-Sonnet; DeepSeek-V3; Qwen2-72B-Instruct; Llama3.1-70B-Instruct) in experiments",
            "uncertainty_modeling": false,
            "uncertainty_type": null,
            "uncertainty_method": "No explicit probabilistic representation; uncertainty handled operationally by reflective feedback and re-querying LLM outputs rather than by belief states or probability distributions.",
            "planning_algorithm": "Applied within Behavior Tree (BT) node simulation; CBS itself is a per-action simulator rather than a global planner algorithm.",
            "planning_integrates_uncertainty": false,
            "text_environment_name": "BTSIMBENCH (used for evaluating CBS inside BeSimulator)",
            "text_environment_description": "Same as BeSimulator: text-based BT cases derived from BEHAVIOR-1K, long-horizon tasks requiring complex manipulation and multi-step reasoning.",
            "performance_metric": "Contribution measured by accuracy improvements in BT category classification and by ablation comparisons (accuracy and delivery rate).",
            "performance_value": "Ablation shows four-phase CBS materially improves accuracy versus single-phase prompting: single-phase still beats CoT by ~13.07% on average, but full CBS further increases detection of indirect state changes and yields the highest accuracy gains reported (part of the +13.6%–24.8% total improvements).",
            "baseline_comparison": "Compared to single-phase LLM prompting (one-shot analysis) and CoT baselines; CBS substantially outperforms single-phase in detecting indirect transitions and faulty BTs.",
            "has_ablation_uncertainty": false,
            "ablation_results": "Removing CBS (replacing with single-phase simulation) reduces accuracy; CBS is particularly important for recovering indirect state transitions and improving Counterfactuals/Unreachable detection.",
            "key_findings": "Decomposing action simulation into consider/decide/capture/transfer significantly improves LLM reliability at simulating state transitions and revealing logic defects; CBS improves detection of indirectly induced state changes that naive prompting misses. CBS, however, remains a deterministic reasoning pipeline and does not implement probabilistic belief tracking.",
            "uuid": "e842.1",
            "source_info": {
                "paper_title": "BeSimulator: A Large Language Model Powered Text-based Behavior Simulator",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "BTSIMBENCH",
            "name_full": "BTSIMBENCH (Behavior Tree Simulation Benchmark)",
            "brief_description": "A text-based benchmark created for evaluating behavior-level simulation systems, consisting of 75 Behavior Trees for 25 tasks taken from BEHAVIOR-1K, including Good, Counterfactuals, and Unreachable BT variants for systematic evaluation.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "BTSIMBENCH",
            "system_description": "Benchmark of 75 textual BT instances derived from BEHAVIOR-1K tasks; each task includes a Good BT and two defective variants (Counterfactuals and Unreachable) to test simulators' ability to detect logic defects. Cases include full textual scene descriptions (entities, relationships, environment info) and BT node descriptions, used to evaluate simulators' accuracy and delivery rate.",
            "world_model_type": "Textual symbolic simulation cases (structured dictionaries of states) used as inputs for simulation systems; benchmark does not itself prescribe probabilistic models.",
            "world_model_description": "Each case encodes entity lists, hierarchical state keys, and relationships (A-B-C style keys) as the symbolic textual world representation that simulators consume; transitions are produced by the simulator/LLM under test.",
            "uses_llm": true,
            "llm_role": "BTSIMBENCH was created using LLMs to convert BEHAVIOR Domain Definition Language cases into textual descriptions and to construct BT variants; used as evaluation input for LLM-based simulators.",
            "llm_model_name": "LLMs were used to convert BDDL to textual cases during dataset construction (paper does not fix a single model for construction)",
            "uncertainty_modeling": false,
            "uncertainty_type": null,
            "uncertainty_method": null,
            "planning_algorithm": "Designed to evaluate Behavior Tree based control logic; not a planner itself.",
            "planning_integrates_uncertainty": false,
            "text_environment_name": "BTSIMBENCH (constructed from BEHAVIOR-1K)",
            "text_environment_description": "Text-only BT simulation cases intended to test long-horizon manipulation tasks' control logic (Good and broken BT variants) with structured scene/state information; designed to expose indirect state changes and logical defects.",
            "performance_metric": "Accuracy (Good/Counterfactuals/Unreachable classification), Delivery Rate, Acc_AP (action precondition extraction accuracy), Acc_WS (world state update accuracy).",
            "performance_value": "Used to produce the numbers reported for BeSimulator and baselines: e.g., Acc_AP and Acc_WS values in Table 5 (Claude-3.5-Sonnet Acc_AP=94.67% Acc_WS=98.67%; DeepSeek-V3 Acc_AP=96.00% Acc_WS=97.33%; Qwen2-72B-Instruct Acc_AP=78.67% Acc_WS=94.67%; Llama3.1-70B-Instruct Acc_AP=85.33% Acc_WS=88.00%). Overall BeSimulator yielded 13.60%–24.80% absolute accuracy gains over baselines across LM choices.",
            "baseline_comparison": "Benchmark used to compare BeSimulator vs CoT and Best-of-N (LLM judge). Baselines perform relatively well on Good BTs but poorly on Counterfactuals/Unreachable categories.",
            "has_ablation_uncertainty": false,
            "ablation_results": "Benchmark was used to demonstrate ablation impacts of CBS, code-driven reasoning, and reflective feedback in BeSimulator; results show each component contributes materially to final performance (CBS largest for Counterfactuals, code-driven for numerical correctness, reflective feedback for delivery rate).",
            "key_findings": "BTSIMBENCH exposes that LLM-based text simulators can accurately update world states (high Acc_WS) but struggle more at reliably extracting correct action preconditions (lower Acc_AP); experiments on BTSIMBENCH show structured per-action reasoning (CBS) plus code execution and feedback significantly improves simulator reliability, but the benchmark and BeSimulator do not implement formal probabilistic symbolic planners or belief-state tracking.",
            "uuid": "e842.2",
            "source_info": {
                "paper_title": "BeSimulator: A Large Language Model Powered Text-based Behavior Simulator",
                "publication_date_yy_mm": "2024-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Reasoning with language model is planning with world model",
            "rating": 2,
            "sanitized_title": "reasoning_with_language_model_is_planning_with_world_model"
        },
        {
            "paper_title": "Can language models serve as text-based world simulators?",
            "rating": 2,
            "sanitized_title": "can_language_models_serve_as_textbased_world_simulators"
        },
        {
            "paper_title": "Large language models as commonsense knowledge for large-scale task planning",
            "rating": 2,
            "sanitized_title": "large_language_models_as_commonsense_knowledge_for_largescale_task_planning"
        },
        {
            "paper_title": "Recurrent world models facilitate policy evolution",
            "rating": 1,
            "sanitized_title": "recurrent_world_models_facilitate_policy_evolution"
        }
    ],
    "cost": 0.014721749999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>BeSimulator: A Large Language Model Powered Text-based Behavior Simulator
8 Sep 2025</p>
<p>Jianan Wang wangjianan@nudt.edu.cn 
College of Computer Science and Technology
National University of Defense Technology</p>
<p>Intelligent Game and Decision Lab (IGDL)</p>
<p>Bin Li 
Intelligent Game and Decision Lab (IGDL)</p>
<p>Jingtao Qi 
Intelligent Game and Decision Lab (IGDL)</p>
<p>Xueying Wang 
Fu Li 
Intelligent Game and Decision Lab (IGDL)</p>
<p>Hanxun Li 
College of Computer Science and Technology
National University of Defense Technology</p>
<p>Intelligent Game and Decision Lab (IGDL)</p>
<p>B Btsimbench 
Intelligent Game and Decision Lab (IGDL)</p>
<p>BeSimulator: A Large Language Model Powered Text-based Behavior Simulator
8 Sep 2025BFEEAFBE47F5FBD0053198AFF38DF03BarXiv:2409.15865v2[cs.RO]BPS Evaluation Example Actionpick_up_toy_from_table BPS Simulation ReasoningAccording to the initial states and executed actions …… Evaluation ResultUnreachable * Current States <em CURRENT_STATE_DESCRIPTION="CURRENT_STATE_DESCRIPTION">{CURRENT_STATES} * Current States Description </em> * Action <em PRECONDITION="PRECONDITION">{ACTION_DESCRIPTION} * Condition </em> * Core States <em>{CORESTATES} * Output </em>A.3 Capture of CBS * Current States <em CURRENT_STATE_DESCRIPTION="CURRENT_STATE_DESCRIPTION">{CURRENT_STATES} * Current States Description </em> * Action <em CURRENT_STATES="CURRENT_STATES">{ACTION_DESCRIPTION} * Output ** Current States </em> * Current States Description <em ACTION_DESCRIPTION="ACTION_DESCRIPTION">{CURRENT_STATE_DESCRIPTION} * Action </em> * Thought <em STATE_TO_TRANSFER="STATE_TO_TRANSFER">{THOUGHT} * States to be Transferred </em> * Output *
Traditional robot simulators focus on physical process modeling and realistic rendering, often suffering from high computational costs, inefficiencies, and limited adaptability.To handle this issue, we concentrate on behavior simulation in robotics to analyze and validate the logic behind robot behaviors, aiming to achieve preliminary evaluation before deploying resource-intensive simulators and thus enhance simulation efficiency.In this paper, we propose BeSimulator, a modular and novel LLM-powered framework, as an attempt towards behavior simulation in the context of text-based environments.By constructing text-based virtual environments and performing semantic-level simulation, BeSimulator can generalize across scenarios and achieve long-horizon complex simulation.Inspired by human cognition paradigm, it employs a "consider-decide-capture-transfer" four-phase simulation process, termed Chain of Behavior Simulation (CBS), which excels at analyzing action feasibility and state transition.Additionally, BeSimulator incorporates code-driven reasoning to enable arithmetic operations and enhance reliability, and reflective feedback to refine simulation.Based on our manually constructed behavior-tree-based simulation benchmark, BTSIMBENCH, our experiments show a significant performance improvement in behavior simulation compared to baselines, ranging from 13.60% to 24.80%.Code and data are available at https://github.com/Dawn888888/BeSimulator.</p>
<p>Introduction</p>
<p>Simulation plays a pivotal role in robotics, providing a controlled platform for testing, enabling researchers to iteratively optimize robotic systems while circumventing the risks and costs associated with physical prototyping (Koenig and Howard, 2004).Conventional simulation tools, such as [{"name": robot, "position": [0.0, 1.0, 0.6], "contact_range": 0.6, …}]</p>
<p>[{"name": table, "position": [2.5, 1.0, 0.5], "clean_state": dirty, …}, {"name": chair, …}, …]</p>
<p>Present state</p>
<p>Because …, action "move_to_table" can be executed.After executing, state … will transfer to … [{"name": robot, "position": [2.0, 1.0, 0.6], "contact_range": 0.6, …}] [{"name": table, "position": [2.5, 1.0, 0.5], "clean_state": dirty, …}, {"name": chair, …}, …] Gazebo (Koenig N) and Unreal Engine (Epic), have been extensively utilized for tasks involving navigation and human-robot interaction (Takaya et al., 2016;Chandan et al., 2021).However, these platforms are predominantly domain specific and focus on modeling physical processes as well as pursuing realistic rendering, which struggle with high computational demands, inefficiencies, and restricted adaptability to the dynamic and diverse nature of environments (Staranowicz and Mariottini, 2011).Additionally, they rely on domain experts to design initial simulation scenes and evaluate the results.</p>
<p>To alleviate this problem, we focus on behaviorlevel simulation, which abstracts complex physical interactions between robots and environments while maintaining action outcomes consistent with real-world scenarios.It emphasizes the control logic of robotic behavior planning solutions (BPS), such as Finite State Machine (FSM) (Lee and Yannakakis, 1996), Hierarchical Task Network (HTN) (Hayes and Scassellati, 2016), and Behavior Tree (BT) (Colledanchise and Ögren, 2018), aiming to detect the potential conflicts with reality and task logic.Compared to conventional simulators, behavior-level simulation offers greater computa-tional efficiency and broader generalizability, enabling early detection of behavior logic defects before deploying conventional simulators, thus reducing robotic development time and cost.</p>
<p>World model, which originates from the mental models of humans, can predict the next state after executing an action in the present state (Ha and Schmidhuber, 2018;Matsuo et al., 2022).Trained on large-scale datasets, Large Language Models (LLMs) encapsulate rich world knowledge and have exhibited potential as sophisticated world models for reasoning and planning (Hao et al., 2023;Zhao et al., 2024).This raises a pivotal research question: can the intrinsic world modeling capacity of LLMs be utilized for robotic behavior simulation?Existing research (Wang et al., 2024) has demonstrated its feasibility in text-based environments.However, experiments show that while the direct simulation performance of LLMs is impressive, their reliability remains limited.The limitation mainly stems from two factors: the inability to capture state transitions that are indirectly related to actions and challenges in arithmetic reasoning.</p>
<p>To bridge this gap, we propose BeSimulator, a LLM-powered framework designed to efficiently simulate BPS, as an effort towards behavior simulation in text-based environments, as shown in Figure 1.BeSimulator consists of three key modules: 1) Case Generation, to generate the text-based simulation environment from the robot task, which includes diverse world states; 2) BPS Simulation, to perform step-by-step behavior simulation according to the control logic of the solution, which means conducting state transitions on the generated case states; 3) BPS Evaluation, to evaluate the effectiveness of the solution and think about potential defects if ineffective.In contrast to conventional simulation tools, it integrates environment design and result evaluation, thus alleviating the costly need for expert involvement.To improve the LLMs reliability, BeSimulator adopts Chain of Behavior Simulation (CBS)-a four-phase simulation process inspired by human cognitive reasoning paradigm-to deeply analyze the action feasibility and state transitions, especially those indirectly associated with actions.It also incorporates a codedriven reasoning mechanism to tackle arithmetic reasoning challenges.Moreover, a reflective feedback mechanism is utilized to enhance the LLMs' error recovery capability, thus refining simulation.</p>
<p>Given the modularity and popularity of BTs in robotic control, we construct a BT simulation benchmark, BTSIMBENCH, to evaluate our approach's performance.This benchmark provides 75 BTs based on the 25 robot tasks from BEHAVIOR-1K (Li et al., 2024a), which are long-horizon and rely on complex manipulation skills.Experimental results indicate that BeSimulator enhances the reliability of LLMs in behavior simulation, achieving higher accuracy in identifying defective behavior planning compared to the baselines.</p>
<p>Overall, we make the following contributions: 2 Related Works</p>
<p>Robotics Simulators</p>
<p>Common robot simulators include general simulators like Gazebo (Koenig N), Isaac Sim (NVIDIA), V-REP (Rohmer et al., 2013), and some game engines like Unreal Engine (Epic).Robot simulators have been widely used for tasks related to navigation (Takaya et al., 2016), human-robot interaction (Chandan et al., 2021), vehicle driving (Dosovitskiy et al., 2017), etc.Their performance is primarily determined by the physics and rendering engine.The physics engine is used to mathematically model complex physical processes like motion, collisions, etc.The rendering engine provides a visual interface to enhance simulation realism.However, these simulators suffer from low efficiency, high computational costs, poor generalization capability (Staranowicz and Mariottini, 2011;Iovino et al., 2021), and reliance on manual scene construction and expert evaluation.Based on this, we focus on behavior-level simulation to examine logical defects behind robotic behaviors, thereby achieving preliminary validation before deploying resourceintensive simulators.This can significantly reduce cycles and associated costs in robotic system development.</p>
<p>Conventional Behavior Simulation</p>
<p>Traditionally, behavioral simulation refers to simulating the behavior patterns of specific subjects.</p>
<p>Most researches focus on user-behavior simulation to evaluate the effectiveness of evacuation systems (Kountouriotis et al., 2016;Harada et al., 2015).Moreover, some researchers focus on behavior simulation of various subjects, like infants (Nishida et al., 2004), humans living in atypical buildings (Lee, 2019), etc.There are also research efforts (Zhang et al., 2023;Hassouni et al., 2018) that utilize behavior simulators to provide a simulation environment for reinforcement learning (RL).These are fundamentally different from the behavior simulation expounded in this paper.</p>
<p>LLMs for Logical Reasoning</p>
<p>Trained on the large-scale corpus, LLMs exhibit remarkable reasoning capability.LLMs are typically prompted to decompose complex problems and engage in step-by-step thinking and reasoning, exemplified by CoT (Wei et al., 2022), Zero-shot-CoT (Kojima et al., 2022), self-consistency (Wang et al., 2022), etc.Some methods combine reasoning problems with search algorithms like ToT (Yao et al., 2024), RAP (Hao et al., 2023), etc.Moreover, some researchers focus on supervised fine-tuning of LLMs to improve reasoning, such as WOMD-Reasoning (Li et al., 2024b), CPO (Zhang et al., 2024b), etc. Methods like CoC (Li et al., 2023) and ToRA (Gou et al., 2023) apply external tools such as code interpreters, computation libraries, etc., aiming to reduce computational hallucination and enhance reasoning.Reflect (Liu et al., 2023) utilizes generated failure explanations to rectify reasoning and planning errors.In this paper, we propose Chain of Behavior Simulation containing four phases from shallow to deep, which conforms to the human cognition process further.</p>
<p>Problem Formalization</p>
<p>Based on research (Colledanchise and Ögren, 2018;Cai et al., 2021), a behavior planning problem can be formalized as a quintet: <S, A, T , s initial , g>, where S is state space, A is action space, T : S × A → S is the state transition rules, s initial is the initial scene state and g is goal condition.After executing action a in the state s t , the next state s t+1 = T (s t , a).The target of the behavior planning problem is to produce a solution π capable of transferring s initial to g in finite steps.In this paper, we aim to determine whether one behavior planning solution is effective through behavior simulation.Our main idea is that based on the initial scene states s initial and the control logic of the solution π, step by step perform state transitions and finally determine whether the goal condition g is achieved, as is shown in Eq 1.In this paper, we integrate LLMs to implement this process to achieve automated and long-horizon behavior simulation.
g ⊆ T (s initial , π)(1</p>
<p>Case Generation</p>
<p>Given a robot task, BeSimulator first initiates the corresponding simulation case.Leveraging the scene comprehension and generation capabilities of LLMs, the case generation exhibits strong generalization and is conducive to constructing complex scenes.The three parts of a case are as follows.</p>
<p>• Entity Information is composed of robot entities and object entities.The robot entities are autonomous and capable of action, e.g., sweeping robots, quadruped robots.The object entities are static, e.g., tables, chairs.For each entity, the generated states include basic properties: id, type, position, size, and taskrelated properties.E.g., if the task requires the robot to turn on lamp, the on_off_state property of the lamp is considered task-related.• Relationship Information defines interactions between entities, including spatial relationships (e.g., on, in, distance), holding relationships, manipulable relationships, etc.</p>
<p>• Environment Information describes taskspecific settings, e.g., locale, weather, object target poses.</p>
<p>BPS Simulation</p>
<p>Building upon the initial scene case, BeSimulator dynamically simulates action sequences based on the control logic of the BPS.Our approach leverages the reasoning capability and embedded knowledge of LLMs to support behavior-level simulation while significantly improving efficiency.To address the reliability limitations of direct LLMbased simulation, we propose CBS, an atomic action simulation process inspired by the human cognition processes.Additionally, we incorporate code-driven reasoning to ensure precise numerical computation and employ reflective feedback mechanism to iteratively refine simulation.</p>
<p>Chain of Behavior Simulation</p>
<p>For each action, BeSimulator employs chain of behavior simulation to model its execution via a structured four-phase process: consider-decide-capturetransfer.Through CBS, BeSimulator first analyzes the action's feasibility (phase 1-2) and, if feasible, predicts the resulting state transitions (phase 3-4).</p>
<p>The prompt designs for CBS are detailed in Appendix A.</p>
<p>During the first two phases, BeSimulator analyzes whether the action execution adheres to the real-world logic.Specifically, in the consider phase, BeSimulator ponders the preconditions required for successful action execution and identifies the crucial states affecting each precondition.Subsequently, in the decide phase, BeSimulator assesses the satisfaction of each precondition by examining the corresponding crucial states.Then it aggregates these assessment results to determine the action's feasibility within the current scene.For instance, when simulating the action "pick_up_toy", BeSimulator summarizes two preconditions: "can_robot_touch_toy?=true" and "whether_robot_has_free_gripper?=true".For the first precondition, the crucial states inferred include robot-position, toy-position and robot-gripper_contact_range, which determine whether the precondition is satisfied.</p>
<p>Upon confirming an action's executability, BeSimulator predicts the state transitions through the last two phases.Detailedly, in the capture phase, it identifies which scene states will be affected by the action.Then, BeSimulator determines the precise transition rules for each impacted state in the transfer phase.For example, for action "move_to_bed", the states to be updated may include robot-position, the positions of held objects, the involved spatial relationships -with the latter two are indirectly related to the action.Moreover, BeSimulator utilizes a world states manager to implement state transitions.This manager, which maintains all scene states in a structured representation and supports the state querying and updating functionalities, serves as a textual virtual environment and effectively reduces LLMs' hallucinations regarding the diverse scene states.</p>
<p>Compared to behavior simulation with just one phase, our four-phase reasoning paradigm decomposes the complex simulation problem through sequential, human-like cognitive processes.This significantly improves the analysis of action feasibility and state transitions (especially indirectly induced transitions), and enhances the LLMs simulation reliability, which is the core goal of our approach.We further investigate its effectiveness through ablation study in Section 5.4.1.</p>
<p>Code-driven Reasoning</p>
<p>While LLMs demonstrate strong capabilities in semantic reasoning, their performance often degrades when handling tasks requiring numerical reasoning.To address this limitation, BeSimulator employs a code-driven reasoning mechanism for arithmetic operations involving numerical states.This mechanism, applied during the decide and transfer phases, integrates code generation and code execution via a code interpreter to ensure computational precision and improve simulation fidelity.Taking decide phase as an example, BeSimulator dynamically selects its reasoning mode based on data types of critical states.If these states involve numerical types, it activates code-driven reasoning; otherwise, it defaults to semantic reasoning.Ablation experiment in Section 5.4.2 validates its efficacy.</p>
<p>Reflective Feedback</p>
<p>Required to respond in JSON format, LLMs occasionally produce errors in syntactic accuracy and semantic consistency.Therefore, BeSimulator incorporates a reflective feedback mechanism.After LLMs generate an output, an automated content checker evaluates its validity from two aspects.First, the checker performs syntactic validation by examining four key aspects: (1) adherence to JSON format, (2) completeness of JSON keys, (3) accu-racy of JSON values, and (4) executability of the generated codes.Second, the checker conducts semantic validation by assessing whether the reasoning process aligns logically with the final output, identifying potential inconsistencies.If errors are detected, BeSimulator provides feedback to the LLM, guiding it to reflect and re-output.The process iterates until either all errors are resolved or a predefined feedback limit is reached.In Section 5.4.3, we demonstrate the effectiveness of the mechanism through ablation.</p>
<p>Category</p>
<p>Reality logic Task logic
Good ✓ ✓ Counterfactuals N/A Unreachable ✓</p>
<p>BPS Evaluation</p>
<p>Based on the simulation results, hSimulator classifies BPS into three distinct categories: Good, Counterfactuals, and Unreachable, as presented in Table 1.The latter two categories indicate inherent logic defects in the solution.Specifically, during the step-by-step simulation process, if any action is infeasible-indicating conflicts between the solution's execution logic and reality logic-the solution is classified as Counterfactuals.Moreover, for solutions that maintain logical consistency with reality, BeSimulator performs rigorous evaluation based on four key elements: task objectives, initial scene states, executed action sequences, and terminal states.The evaluation yields either Good or Unreachable classification.The Good category indicates that the solution achieves the task goal at the behavior level, while Unreachable indicates fundamental incompatibility between the solution and task requirements.Consider the example of "Clean book with rag" task, which presents two defective solutions, namely Solution A and Solution B. Solution A, which controls the robot to perform the action "move_to_book" followed by "clean_book", exhibits Counterfactuals because it omits the crucial step of picking up the rag before cleaning.In contrast, Solution B is classified as Unreachable because the robot only picks up the rag and the book after executing the complete solution, thereby failing to achieve the intended task goal.</p>
<p>Our approach is versatile and can be adapted across different BPS.In this section, we use behavior tree (BT) as a case study and perform experiments to evaluate the effectiveness of our approach.We first propose a novel BT simulation benchmark and then conduct comprehensive experiments to address two research questions:</p>
<p>• To what degree of accuracy does BeSimulator conduct behavior simulation?(Section 5.3)</p>
<p>• To what extent do our designed mechanisms contribute to the simulation, including chain of behavior simulation, code-driven reasoning, and reflective feedback?(Section 5.4)</p>
<p>BTs Simulation</p>
<p>A BT is a directed tree structure where leaf nodes (Condition and Action nodes) control the robot's perception and actions, while internal nodes (e.g., Fallback and Sequence nodes) manage the execution logic of leaf nodes (Colledanchise and Ögren, 2018), as is shown in Table 2. BT execution begins at the root node, which ticks its descendant nodes at each time step through Depth First Search (DFS).</p>
<p>Based on the current scene, the tick creates a control flow that determines the robot's perception and action sequence.</p>
<p>In our experiments, we utilize py_trees 1 as BTs engineer that sends tick signal and controls nodes execution.Internal nodes follow the execution rules defined in py_trees, while leaf nodes are handled by the the CBS mechanism.Specifically, BeSimulator implements the four-phase CBS process for action node simulation and employs a twophase variant for condition nodes.This variant adopts the first two CBS phases, "consider-decide":</p>
<p>1 https://py-trees.readthedocs.io/en/devel/it first identifies relevant scene states for the condition node, then determines its output (Success/Failure) based on their values.For example, for the condition node "is_near_book?", BeSimulator infers critical states (e.g., robot-position, book-position, and robot-contact_range) and generates code to determine whether the node succeeds or fails.</p>
<p>Experimental Setup</p>
<p>Benchmarks</p>
<p>Based on BEHAVIOR-1K (Li et al., 2024a) which is a comprehensive benchmark for human-centered robots, we construct BTSIMBENCH, a novel BT simulation benchmark comprising 75 BTs across three categories.BEHAVIOR-1K includes the definitions of 1000 daily tasks, which are long-horizon and depend on complex manipulation skills.These tasks have been experimentally verified to be extremely challenging for current AI algorithms and are widely applied in research on behavior planning (Zhang et al., 2024a), motion control (Jiang et al., 2025), etc.We select 25 tasks from them while keeping diversity in both task categories and  behavior types, then we utilize LLMs to convert them from BEHAVIOR Domain Definition Language (BDDL) into textual descriptions.For each task, we first construct a Good BT and provide the corresponding node descriptions, as illustrated in Figure 3. Additionally, by altering some nodes in the Good BT, we construct a Counterfactuals BT and an Unreachable BT to simultaneously measure the simulation capability of BeSimulator for both good and bad BTs, as shown in Figure 4.For each BT, we conduct multiple rounds of manual verification and adjustment to ensure its availability.See Appendix B for more BTSIMBENCH info.</p>
<p>Baselines and Adopted LLMs</p>
<p>Currently there is no specific framework designed for performing behavior simulation based on LLMs.Thus, we compare our method with the scenarioagnostic methods including Chain of Thought (Wei et al., 2022) and Best of N with LLM Judge.Our method and all baselines employ few-shot examples to ensure a fair comparison.</p>
<p>• Chain of Thought (CoT): This method takes the robot task description and the BT with node descriptions as input.Specifically, we instruct LLMs to generate intermediate reasoning steps to analyze the BT's control logic, evaluate its effectiveness, and identify potential reasons if ineffective.• Best of N with LLM Judge (BoN): According to the CoT method, we sample three candidate answers and then use LLM as a judge to select the best answer based on the correctness of the answers.To assess our method's generalization across LLMs, we select four well-known LLMs in the field of closed source and open source as our base LLMs, including Claude-3.5-Sonnet(Anthropic), DeepSeek-V3 (DeepSeek-AI, 2025), Qwen2-72B-Instruct (Yang et al., 2024) and Llama3.1-70B-Instruct(Dubey et al., 2024).</p>
<p>Metrics</p>
<p>To evaluate the simulation performance of BeSimulator, we use the following metrics:</p>
<p>• Delivery Rate: This metric assesses whether an LLM-based simulator can successfully deliver a simulation result within finite reflection times of LLMs.Exceeding the predefined feedback limit (5 times in our experiment settings) will result in delivery failure.• Accuracy: This metric represents the proportion of BTs that are correctly evaluated for the corresponding categories.As the key evaluation criterion, it reflects the simulator's effectiveness for behavior simulation.</p>
<p>Simulation Performance</p>
<p>In our experiments, we employ BTSIMBENCH to evaluate the efficacy of BeSimulator across four LLMs.Table 3 presents the performance comparison between our method and baselines.</p>
<p>The results demonstrate that BeSimulator achieves significant performance improvements across all base LLMs, showing its capability for behavior-level simulation.Specifically, for DeepSeek-V3, we observe a maximum increase of 24.80% in average accuracy, corresponding to a 37.80% relative improvement over the CoT baseline.Other LLMs exhibit enhancements ranging from 13.60% to 24.53%, further validating the efficacy of our approach.Moreover, the results show that the BoN baseline outperforms CoT in general.This demonstrates that LLMs are better at making choices based on candidate answers than directly generating answers.Furthermore, the baselines' strong performance on Good BTs belies a superficial understanding of robot behavior control, as it struggles to detect hidden conflicts with reality and task logic.For instance, in the Counterfactuals BT shown in Figure 4, the baselines often fail to recognize that one precondition for the "clean_book" action is "hold_rag?=true".Consequently, it tends to classify BTs as Good, resulting in degraded performance on faulty BTs.In contrast, our method outperforms the baselines in the Counterfactuals and Unreachable categories.For instance, on the Qwen2-72B-Instruct model, our method achieves 90.40% accuracy in simulating and evaluating Counterfactuals BTs, while the BoN baseline yields 1.60% accuracy.These results indicate that BeSimulator effectively improves action execution analysis and identifies potential defects, thus facilitating iterative optimization of robot systems.Additional evaluation results for BeSimulator are provided in Appendix C.</p>
<p>Ablation Study</p>
<p>In the ablation experiments, we choose DeepSeek-V3 as the base LLM.Subsequently, we systematically remove each mechanism from our method, enabling us to pinpoint and comprehend the specific efficacy of each mechanism.The ablation experiment results are detailed in Table 4.</p>
<p>Effectiveness of Chain of Behavior Simulation</p>
<p>To implement the ablation analysis on the thought mode of behavior simulation, we compare the "consider-decide-capture-transfer" four-phase mode of CBS with the single-phase mode, which prompts LLMs to analyze the action feasibility and state transitions in only a single phase.We observe that, despite using the single-phase thought mode, the average accuracy across three categories increases by 13.07%compared to the CoT baseline.This confirms that the approach, which constructs the text-based simulation environment and performs state transitions according to the control logic of BPS, can effectively simulate BPS and enhance evaluation accuracy.However, our analysis of LLM outputs reveals that the single-phase thought mode, constrained by the problem's complexity, fails to sufficiently analyze action feasibility and effects, which explains its inferior performance compared to BeSimulator.This underscores the importance of CBS in enhancing action feasibility analysis and capturing state transitions, particularly those indirectly connected to actions, which improves LLMs' reliability in behavior simulation.</p>
<p>Effectiveness of Code-driven Reasoning</p>
<p>We conduct the ablation analysis on the effects of code-driven reasoning.We remove the code-driven reasoning in CBS, transforming it into semantic reasoning.The result indicates that three category accuracy rates decrease, particularly for the Good and Unreachable categories.We find that, in the absence of code generation and execution, LLMs consistently struggle with arithmetic calculations and comparisons.For instance, LLMs are stuck in comparing the numerical values of 1.414 and 1.0.This highlights the efficacy of the code-driven reasoning mechanism in addressing the numerical hallucination of LLMs.Furthermore, compared to the single-phase mode, "w/o Code" performs excellently in the Counterfactuals category due to the human-like thought paradigm of CBS.</p>
<p>Effectiveness of Reflective Feedback</p>
<p>The results of the ablation experiment on reflective feedback reveal a significant 5.33% decline in delivery rate when reflective feedback is removed.</p>
<p>The result shows that LLMs face challenges in providing outputs that satisfy syntax requirements and semantic consistency in one response.This phenomenon substantiates the significance of reflective feedback, which narrows the gap between LLMs and idea outputs and refines simulation.</p>
<p>Conclusion</p>
<p>We formalize the simulation problems for behavior planning solutions to evolve the real-world simulation challenges.</p>
<p>Limitations</p>
<p>To prove the efficacy of our work, we perform adequate experiments based on BTs.We adopt BTs due to their popularity as a robot control architecture in recent years.Although our results substantiate the effectiveness and efficiency of the proposed approach on BTs simulation, the performance has not been evaluated on other robot control architectures, such as FSMs, HTNs.An important direction for future research is to extend the application of this work to a broader range of robot control architectures.</p>
<p>In this work, we propose BeSimulator, a behavior-level simulator in the context of textbased environments, which has a different scope from the existing physics-based and visual simulation tools.These tools are still essential for achieving high-fidelity physical simulations, as well as in scenarios where visual information is crucial.While the primary goal of this work is to realize efficient and versatile simulation.By leveraging this work, robotic system developers can conduct preliminary evaluations and optimizations prior to employing computationally intensive, resource-demanding, and costly conventional simulation tools, thereby significantly reducing development costs and expediting the overall robotics development cycle.</p>
<p>A PROMPT</p>
<p>The complete prompt templates of CBS's four phases are provided in the following.</p>
<p>A.1 Think of CBS</p>
<p>Think Phase Prompt</p>
<p>You are a world model that can recognize and understand various scenes in the real world well, and can determine whether the action could be executed successfully.</p>
<h3>Task Description Based on your understanding of the current world state, and semantics of the given action, your task is to determine whether this provided action could be executed successfully based on the current states and action description, and gives your reason process.</h3>
<h3>Input Description I will give you (1) the current world state in dictionary (denoted as * Current States * ).</h3>
<p>(2) the detailed description of current world states in dictionary ( denoted as * Current States Description * ) (3) the action description (denoted as * Action * ) ### Output Rules 1.Your output must be a dictionary.Just Three keys are included: ' thought', 'corecondition', and 'corecondition_successtag'.Please do not output irrelevant content.2. In the 'thought' key, you should first summarize the conditions that need to be met and the corresponding boolean value, based on the current world states, for the action to be executed successfully.Then, identify which states in the current world states are crucial for influencing each condition.Boolean value is true, indicating that these conditions should be met for the action execution; Boolean value is false, indicating that these conditions should not be met for the action execution.You should express it as 'condition?=true' or 'condition?=false'.3.In the 'corecondition' key, the value is a dictionary.The dictionary includes all preconditions that affect the execution of the action.The keys of the dictionary should be expressed as complete question sentences, representing each precondition.The corresponding values should be the core states from the current world states that are necessary to check each precondition.The state names should be represented as A−B−C.Keys from different levels are connected with hyphen.Each condition corresponds to several states in a list.4. In the 'corecondition_successtag' key, it shows the boolean value that each precondition in the 'corecondition' dictionary should return for the action to be executed successfully.Ensure that information in 'corecondition_successtag' should be consisted with the meaning in 'thought'.5.The response should be output in the JSON format as shown in the example below, which should begins with <code>json and ends with</code>.You are a world model that can recognize and understand various scenes in the real world well, and can determine whether the action could be executed successfully.</p>
<h3>Task Description</h3>
<p>Based on your understanding of the current world state, the semantics of the given action, and a condition related to whether the action can be executed.Your task is to determine whether the condition is true based on the current states and the provided core states, and gives your reason process.### Input Description I will give you (1) the current world state in dictionary (denoted as * Current States * ).</p>
<p>(2) the detailed description of current world states in dictionary ( denoted as * Current States Description * ) (3) the action description (denoted as * Action * ) (4) one condition related to whether the action can be executed successfully (denoted as * Condition * ).</p>
<p>(5) the core states which are key basis for you to determine whether this condition is true or false (denoted as * Core States * ) ### Output Rules 1.Your output must be a dictionary.Just Two keys are included: " thought" and "code".Please do not output irrelevant content.2. In the 'thought' key, you should give your reasoning process to make the decision based on the current world states and the core states.3.In the 'code' key, you must generate python codes to calculate, according to these values of core states.Specifically, the codes should be between with '###python' and ends with '###'.And lastly must get a boolean variable "resp" in final.</p>
<p>Capture Phase Prompt</p>
<p>You are a world model that can recognize and understand various scenes in the real world well, and can predict future situations.### Task Description Based on your understanding of the current world state, and semantics of the given action, your task is to output all states needed to be changed after the action is executed, and gives your reason process.You need to consider the attributes of agent, objects, world environment, as well as the complex intersections of their relationships.</p>
<h3>Input Description I will give you (1) the current world state in dictionary (denoted as * Current States * ).</h3>
<p>(2) the detailed description of current world states in dictionary ( denoted as * Current States Description * ) (3) the action description (denoted as * Action * ) ### Output Rules 1.Your output must be a dictionary.Just Two keys are included: " states_transfer" and "thought".Please do not output irrelevant content.2. For "thought" key, please output your thought and reason process about which states needed to be changed.3.For "states_transfer" key, its value is a list of all states from the current world states that are changed by this action, with considering of the world common knowledge and the affliation relationship provided in the current states.The state name should be represented as A−B−C.Keys from different levels are connected with short lines.Considering the dependency relationship between the states needed to be changed, these states should be output sequentially in the order in which they are updated.If there are no states needed to be changed, please output You are a world model that can recognize and understand various scenes in the real world well, and can predict future situations.### Task Description Based on your understanding of the current world state, and semantics of the given action, your task is to simulate the execution of the given action and predict the transition of the designated world state after the action happens.You need to consider the attributes of agent, objects, world environment, as well as the complex intersections of their relationships.Consider the immediate and potential future consequences of each action iteratively, which must be realistic and meet real−world physical laws.</p>
<p>C Detailed Quantitative Results</p>
<p>This section presents a detailed quantitative analysis of our framework, evaluating its performance on two key dimensions: (1) the accuracy of extracting action preconditions and (2) the accuracy of updating world states after action execution.The results are summarized in Table 5.</p>
<p>The results reveal a consistent trend across four LLMs: the framework demonstrates substantially higher performance in updating world states than in extracting action preconditions.Through in-depth analysis, we find that LLMs are prone to hallucinations about real-world physical rules and generate physically implausible statements when reasoning about preconditions.This issue manifests in three categories: missing preconditions, redundant preconditions and incorrect preconditions.For example, for the action "open_box", one of the preconditions should be "is_box_inside_robot_gripper_contact?=true", but the LLM generates the precondition "is_box_inside_robot_gripper_contact?=false", which does not conform to the physical rules.In the context of world state updating, we identify two main types of errors: missing state transitions and incorrect state transitions.A representative failure case is shown in Appendix D.</p>
<p>D FAILURE CASE STUDY</p>
<p>Due to the inherent biases and hallucinations of LLMs, the simulation may occasionally exhibit unreliability, resulting in failure cases.Specifically, the failures primarily stem from LLMs considering redundant/irrelevant action preconditions and incorrect state transitions.This highlights the need for further improvement in the LLM's understanding of real-world physical commonsense.We select one representative case for detailed demonstration, where the DeepSeek-V3 misclassifies a "Good" BT as the "Counterfactuals" category, as illustrated in Figure 5 and Table 8.</p>
<p>Figure 1 :
1
Figure 1: Workflow of BeSimulator.Based on the task description and robot behavior planning (e.g., BTs), BeSimulator employs LLMs to conduct text-based simulations for identifying behavior logic defects.This serves as a preliminary evaluation before using conventional simulators, enhancing simulation efficiency.</p>
<p>Figure 2 :
2
Figure 2: Overview of BeSimulator.Module 1: Case Generation generates simulation cases from task descriptions.The cases contain diverse world states, which are subsequently maintained by a world state manager.Module 2: BPS Simulation dynamically simulates action sequences according to the execution logic of BPS.Using single action pick_up_toy_from_table as an example, the schematic illustrates the four-phase "consider-decide-capturetransfer" process, which first checks the action feasibility and performs state transitions to update the manager.BeSimulator integrates code-driven reasoning and reflective feedback into the process.Module 3: BPS Evaluation conducts evaluation based on the simulation results.</p>
<p>Figure 4 :
4
Figure 4: Bad BT examples.Left: BT of the Counterfactuals category.Right: BT of the Unreachable category.</p>
<ol>
<li>The response should be output in the JSON format as shown in the example below, which should begins with <code>json and ends with</code>.<strong><em>*</em> Example </strong><strong><em> {SHOTS} </em></strong><strong> Example Ends </strong>***</li>
</ol>
<p>['None'].4. The response should be output in the standard JSON format as shown in the example below.<strong><em>*</em> Example </strong><strong><em> {SHOTS} </em></strong><strong> Example Ends </strong>*<em><em> A.4 Transfer of CBS Note that the </em>Thought</em> part of the following prompt is from the output of the capture phase.Transfer Phase Prompt (Semantic reasoning mode)</p>
<h1></h1>
<p>the current world state (denoted as * Current States * ) (2) the detailed description of the current world state (denoted as * Current States Description * ) (3) the action description (denoted as * Action * ) (4) the complete thought about the action and its effects on the current states (denoted as * Thought * ) (5) the state you need to change after this action is executed ( denoted as * States To Be Transferred * ) ### Output Rules 1.You need to output the new state of '{STATE_TO_TRANSFER}' based on the information in * Thought * .2. The response should be output in the standard JSON format as shown in the example below.<strong><em>*</em> Example </strong><strong><em> {SHOTS} </em></strong><strong> Example Ends </strong>***</p>
<p>Clean the table if it's dirty.
Fallbacktable_is_clean?Sequencemove_to_tableclean_table
*Corresponding authorsRobot task:</p>
<p>Table 1 :
1
The three categories of the evaluation results.</p>
<p>✓ Consistent with logic.Inconsistent with logic.</p>
<p>Table 2 :
2
Typical nodes in BTs and the execution rules they follow.
NodeDescriptionsExecutionSequenceticks its child nodes from left to right until one returns FailureFallbackticks its child nodes from left to right until one returns Successpy_trees rulesParallelticks its child nodes in parallel and returns based on the settingActionperforms an actionCBSCondition checks if a condition is metCBS</p>
<p>Table 3 :
3
The comparative experiment results of BeSimulator on BTSIMBENCH across four LLMs (mean ± standard deviation from five repeated experiments).</p>
<p>Table 5 :
5
The quantitative results in two dimensions."Acc_AP" refers to the accuracy of extracting action preconditions."Acc_WS" refers to the accuracy of updating world states.
ModelAcc_AP(%) Acc_WS(%)Claude-3.5-Sonnet94.6798.67DeepSeek-V396.0097.33Qwen2-72B-Instruct78.6794.67Llama3.1-70B-Instruct85.3388.00
We recognize and ensure that our study aligns with the established Code of Ethics. The focus of this article is on a novel LLM-powered framework that conducts behavior simulation in text-based environments. However, we acknowledge that as an LLM application, it may be exploited by malicious individuals. For example, if someone uses our work to simulate criminal methods, ethical concerns will arise. Therefore, we urge that such applications undergo security checks on user instructions when put into use, to identify malicious attempts.
Task NameCleanPool Task DesciptionThe robot task is to clean a stained pool with a brush and detergent.The behavior logic of a robot should be as follows.The brush and detergent are on the floor.Robot need to use a brush and detergent to scrub the pool and then rinses the pool to make it clean.The goal is to make the pool clean.The robot has two grippers, which one gripper can hold one object at a time.Action NodesMove_to_brush: Robot moves to the location of the brush.Pick_up_brush: Robot grasps and lifts the brush with it one gripper.Move_to_detergent: Robot moves to the location of detergent.Pick_up_detergent: Robot picks up the detergent with its one gripper.Move_to_pool: Robot moves to the location of the pool.ApplyDetergent: Robot applies detergent which is in its gripper to the pool surface.ScrubPoolWithBrush: Robot extends the gripper which holds a brush to the pool which has been applied with detergent, and uses the brush to scrub the pool.Place_brush_detergent: Robot releases its gripper and places the brush and detergent on the floor.RinsePool: Robot turns on the faucet, rinses the pool which has been applied with detergent and has been scrubbed, to make the pool clean.Condition NodesBrush_in_gripper?: Check if the brush is in the robot's gripper.Detergent_in_gripper?: Check if the detergent is in the robot's gripper.IsNearBrush?: Check if the robot is near the brush.Require a distance less than the gripper contact range of the robot to be considered near.IsNearDetergent?: Check if the robot is near the detergent.Require a distance less than the gripper contact range of the robot to be considered near.IsNearPool?: Check if the robot is near the pool.Require a distance less than the gripper contact range of the robot to be considered near.IsfaucetOpen?: Check if the faucet is open.BT (Good)<Sequence class="SequenceNode" instance_name="clean_pool_sequence"> <Fallback class="FallbackNode" instance_name="hold_brush"> <Condition class="Brush_in_gripper?" instance_name="Brush_in_gripper?"></Condition> <Sequence class="SequenceNode" instance_name="hold_brush"> <Fallback class="FallbackNode" instance_name="move_to_brush"> <Condition class="IsNearBrush?" instance_name="IsNearBrush?"></Condition> <Action class="move_to_brush" instance_name="move_to_brush"></Action> </Fallback> <Action class="pick_up_brush" instance_name="pick_up_brush"></Action> </Sequence> </Fallback> <Fallback class="FallbackNode" instance_name="hold_detergent"> <Condition class="Detergent_in_gripper?" instance_name="Detergent_in_gripper?"></Condition> <Sequence class="SequenceNode" instance_name="hold_detergent"> <Fallback class="FallbackNode" instance_name="move_to_detergent"> <Condition class="IsNearDetergent?" instance_name="IsNearDetergent?"></Condition> <Action class="move_to_detergent" instance_name="move_to_detergent"></Action> </Fallback> <Action class="pick_up_detergent" instance_name="pick_up_detergent"></Action> </Sequence> </Fallback> <Fallback class="FallbackNode" instance_name="move_to_pool"> <Condition class="IsNearPool?" instance_name="IsNearPool?"></Condition> <Action class="move_to_pool" instance_name="move_to_pool"></Action> </Fallback> <Sequence class="SequenceNode" instance_name="clean_pool_sequence"> <Action class="ApplyDetergent" instance_name="ApplyDetergent"></Action> <Action class="ScrubPoolWithBrush" instance_name="ScrubPoolWithBrush"></Action> <Action class="Place_brush_detergent" instance_name="Place_brush_detergent"></Action> <Fallback class="FallbackNode" instance_name="turn_on_faucet"> <Condition class="IsfaucetOpen?" instance_name="IsfaucetOpen?"></Condition> <Action class="RinsePool" instance_name="RinsePool"></Action> </Fallback> </Sequence> </Sequence> BT (Counterfactuals) <Sequence class="SequenceNode" instance_name="clean_pool_sequence"> <Fallback class="FallbackNode" instance_name="hold_brush"> <Condition class="Brush_in_gripper?" instance_name="Brush_in_gripper?"></Condition> <Action class="pick_up_brush" instance_name="pick_up_brush"></Action> </Fallback> <Fallback class="FallbackNode" instance_name="hold_detergent"> <Condition class="Detergent_in_gripper?" instance_name="Detergent_in_gripper?"></Condition> <Action class="pick_up_detergent" instance_name="pick_up_detergent"></Action> </Fallback> <Fallback class="FallbackNode" instance_name="move_to_pool"> <Condition class="IsNearPool?" instance_name="IsNearPool?"></Condition> <Action class="move_to_pool" instance_name="move_to_pool"></Action> </Fallback> <Sequence class="SequenceNode" instance_name="clean_pool_sequence"> <Action class="ApplyDetergent" instance_name="ApplyDetergent"></Action> <Action class="ScrubPoolWithBrush" instance_name="ScrubPoolWithBrush"></Action> <Action class="Place_brush_detergent" instance_name="Place_brush_detergent"></Action> <Fallback class="FallbackNode" instance_name="turn_on_faucet"> <Condition class="IsfaucetOpen?" instance_name="IsfaucetOpen?"></Condition> <Action class="RinsePool" instance_name="RinsePool"></Action> </Fallback> </Sequence> </Sequence> BT (Unreachable) <Sequence class="SequenceNode" instance_name="clean_pool_sequence"> <Fallback class="FallbackNode" instance_name="hold_brush"> <Condition class="Brush_in_gripper?" instance_name="Brush_in_gripper?"></Condition> <Sequence class="SequenceNode" instance_name="hold_brush"> <Fallback class="FallbackNode" instance_name="move_to_brush"> <Condition class="IsNearBrush?" instance_name="IsNearBrush?"></Condition> <Action class="move_to_brush" instance_name="move_to_brush"></Action> </Fallback> <Action class="pick_up_brush" instance_name="pick_up_brush"></Action> </Sequence> </Fallback> <Fallback class="FallbackNode" instance_name="hold_detergent"> <Condition class="Detergent_in_gripper?" instance_name="Detergent_in_gripper?"></Condition> <Sequence class="SequenceNode" instance_name="hold_detergent"> <Fallback class="FallbackNode" instance_name="move_to_detergent"> <Condition class="IsNearDetergent?" instance_name="IsNearDetergent?"></Condition> <Action class="move_to_detergent" instance_name="move_to_detergent"></Action> </Fallback> <Action class="pick_up_detergent" instance_name="pick_up_detergent"></Action> </Sequence> </Fallback> <Fallback class="FallbackNode" instance_name="move_to_pool"> <Condition class="IsNearPool?" instance_name="IsNearPool?"></Condition> <Action class="move_to_pool" instance_name="move_to_pool"></Action> </Fallback> <Sequence class="SequenceNode" instance_name="clean_pool_sequence"> <Action class="ApplyDetergent" instance_name="ApplyDetergent"></Action> <Action class="ScrubPoolWithBrush" instance_name="ScrubPoolWithBrush"></Action> </Sequence> </Sequence> Table6: Example 1 CleanPool in BTSIMBENCH.Fault of the Counterfactuals BT: robot does not move near the brush and detergent before picking up them, which may be out of the robot's contact range.Fault of the Unreachable BT: robot does not rinse the pool in the end while the task goal is to make the pool clean.Task NameBrewCoffee Task DesciptionThe robot task is to brew coffee.The behavior logic of a robot should be as follows.The coffee beans are stored in a open jar on the countertop, and the water source is the sink in the kitchen.An clean and empty bottle is near the sink.A coffee machine and a mug are also on the countertop.The robot needs to use the coffee machine to brew the coffee using the coffee beans and water, and then pour the brewed coffee into the mug.The goal is to ensure that the coffee is brewed and contained in the mug.The robot has two grippers, which one gripper can hold one object at a time.Action NodesMove_to_sink: The robot moves to the location of the sink.Grasp_water_bottle: The robot grasps and lifts the water bottle with its one gripper.Fill_water_bottle: The robot turns on the sink switch, fills the bottle which is in its gripper with the flowing water until the bottle is full, and then turns off the sink switch.Move_to_beans_jar: The robot moves to the location of the coffee beans jar.Grasp_coffee_beans: The robot grasps a sufficient amount of coffee beans from the jar with its one gripper.Move_to_machine: The robot moves to the location of the coffee machine.Pour_coffee_beans: The robot pours the coffee beans which are in its gripper into the coffee machine.Pour_water_to_mach: The robot pours the water from the bottle which is in its gripper into the coffee machine.Start_coffee_brewing: The robot turns on the coffee machine power switch.Wait_for_coffee_brew: The robot waits for until the coffee machine gets the brewed coffee.Move_to_mug: The robot moves to the location of the mug.Grasp_mug: The robot grasps and lifts the mug.Pour_coffee_into_mug: The robot pours the brewed coffee from the coffee machine into the mug.Condition Nodesis_near_beans_jar?: Check if the robot is near the coffee beans jar.Require a distance less than the gripper contact range of the robot to be considered near.beans_in_gripper?: Check if the coffee beans is in the robot's gripper.is_near_sink?: Check if the robot is near the sink.Require a distance less than the gripper contact range of the robot to be considered near.water_in_bottle?: Check if the bottle is filled with water.is_near_machine?: Check if the robot is near the coffee machine.Require a distance less than the gripper contact range of the robot to be considered near.beans_in_machine?: Check if the coffee beans have been poured into the coffee machine.water_in_machine?: Check if the water has been poured into the coffee machine.brewing_started?: Check if the power state of the coffee machine is on and start brewing coffee based on ingredients such as coffee beans and water.brewing_completed?: Check if the coffee brewing process of coffee machine has completed and the content of the coffee machine is brewed coffee.mug_in_gripper?: Check if the mug is in the robot's gripper.coffee_in_mug?: Check if the brewed coffee has been into the mug.BT (Good)<Sequence class="SequenceNode" instance_name="Brew_Coffee_Complete_Mug"> <Sequence class="SequenceNode" instance_name="Prepare_Coffee_Brewing"> <Sequence class="SequenceNode" instance_name="Gather_Coffee_Ingredients"> <Fallback class="FallbackNode" instance_name="Move_to_sink"> <Condition class="is_near_sink?" instance_name="is_near_sink?"></Condition> <Action class="Move_to_sink" instance_name="Move_to_sink"></Action> </Fallback> <Action class="Grasp_water_bottle" instance_name="Grasp_water_bottle"></Action> <Fallback class="FallbackNode" instance_name="Fill_water_bottle"> <Condition class="water_in_bottle?" instance_name="water_in_bottle?"></Condition> <Action class="Fill_water_bottle" instance_name="Fill_water_bottle"></Action> </Fallback> <Fallback class="FallbackNode" instance_name="Move_to_coffee_beans"> <Condition class="is_near_beans_jar?" instance_name="is_near_beans_jar?"></Condition> <Action class="Move_to_beans_jar" instance_name="Move_to_beans_jar"></Action> </Fallback> <Fallback class="FallbackNode" instance_name="Grasp_coffee_beans"> <Condition class="beans_in_gripper?" instance_name="beans_in_gripper?"></Condition> <Action class="Grasp_coffee_beans" instance_name="Grasp_coffee_beans"></Action> </Fallback> </Sequence> <Sequence class="SequenceNode" instance_name="Setup_Coffee_Machine"> <Fallback class="FallbackNode" instance_name="Move_to_machine"> <Condition class="is_near_machine?" instance_name="is_near_machine?"></Condition> <Action class="Move_to_machine" instance_name="Move_to_machine"></Action> </Fallback> ...(continued on next page) BT (Good) ... <Fallback class="FallbackNode" instance_name="Pour_coffee_beans"> <Condition class="beans_in_machine?" instance_name="beans_in_machine?"></Condition> <Action class="Pour_coffee_beans" instance_name="Pour_coffee_beans"></Action> </Fallback> <Fallback class="FallbackNode" instance_name="Pour_water_to_mach"> <Condition class="water_in_machine?" instance_name="water_in_machine?"></Condition> <Action class="Pour_water_to_mach" instance_name="Pour_water_to_mach"></Action> </Fallback> </Sequence> </Sequence> <Sequence class="SequenceNode" instance_name="Brew_Pour_Coffee_Mug"> <Fallback class="FallbackNode" instance_name="Start_coffee_brewing"> <Condition class="brewing_started?" instance_name="brewing_started?"></Condition> <Action class="Start_coffee_brewing" instance_name="Start_coffee_brewing"></Action> </Fallback> <Fallback class="FallbackNode" instance_name="Wait_for_coffee_brew"> <Condition class="brewing_completed?" instance_name="brewing_completed?"></Condition> <Action class="Wait_for_coffee_brew" instance_name="Wait_for_coffee_brew"></Action> </Fallback> <Fallback class="FallbackNode" instance_name="Move_to_mug"> <Condition class="mug_in_gripper?" instance_name="mug_in_gripper?"></Condition> <Sequence class="SequenceNode" instance_name="hold_mug"> <Action class="Move_to_mug" instance_name="Move_to_mug"></Action> <Action class="Grasp_mug" instance_name="Grasp_mug"></Action> <Action class="Move_to_machine" instance_name="Move_to_machine"></Action> </Sequence> </Fallback> <Fallback class="FallbackNode" instance_name="Pour_coffee_into_mug"> <Condition class="coffee_in_mug?" instance_name="coffee_in_mug?"></Condition> <Action class="Pour_coffee_into_mug" instance_name="Pour_coffee_into_mug"></Action> </Fallback> </Sequence> </Sequence> BT (Counterfactuals) <Sequence class="SequenceNode" instance_name="Brew_Coffee_Complete_Mug"> <Sequence class="SequenceNode" instance_name="Prepare_Coffee_Brewing"> <Sequence class="SequenceNode" instance_name="Gather_Coffee_Ingredients"> <Fallback class="FallbackNode" instance_name="Move_to_sink"> <Condition class="is_near_sink?" instance_name="is_near_sink?"></Condition> <Action class="Move_to_sink" instance_name="Move_to_sink"></Action> </Fallback> <Action class="Grasp_water_bottle" instance_name="Grasp_water_bottle"></Action> <Fallback class="FallbackNode" instance_name="Fill_water_bottle"> <Condition class="water_in_bottle?" instance_name="water_in_bottle?"></Condition> <Action class="Fill_water_bottle" instance_name="Fill_water_bottle"></Action> </Fallback> <Fallback class="FallbackNode" instance_name="Move_to_coffee_beans"> <Condition class="is_near_beans_jar?" instance_name="is_near_beans_jar?"></Condition> <Action class="Move_to_beans_jar" instance_name="Move_to_beans_jar"></Action> </Fallback> </Sequence> <Sequence class="SequenceNode" instance_name="Setup_Coffee_Machine"> ... (same to the above Good BT) </Sequence> </Sequence> <Sequence class="SequenceNode" instance_name="Brew_Pour_Coffee_Mug"> ... (same to the above Good BT) </Sequence> </Sequence> BT (Unreachable) <Sequence class="SequenceNode" instance_name="Brew_Coffee_Complete_Mug"> <Sequence class="SequenceNode" instance_name="Prepare_Coffee_Brewing"> ... (same to the above Good BT) </Sequence> <Sequence class="SequenceNode" instance_name="Brew_Pour_Coffee_Mug"> <Fallback class="FallbackNode" instance_name="Start_coffee_brewing"> <Condition class="brewing_started?" instance_name="brewing_started?"></Condition> ...(continued on next page) BT (Unreachable) ... <Action class="Start_coffee_brewing" instance_name="Start_coffee_brewing"></Action> </Fallback> <Fallback class="FallbackNode" instance_name="Move_to_mug"> <Condition class="mug_in_gripper?" instance_name="mug_in_gripper?"></Condition> <Sequence class="SequenceNode" instance_name="hold_mug"> <Action class="Move_to_mug" instance_name="Move_to_mug"></Action> <Action class="Grasp_mug" instance_name="Grasp_mug"></Action> <Action class="Move_to_machine" instance_name="Move_to_machine"></Action> </Sequence> </Fallback> <Fallback class="FallbackNode" instance_name="Wait_for_coffee_brew"> <Condition class="brewing_completed?" instance_name="brewing_completed?"></Condition> <Action class="Wait_for_coffee_brew" instance_name="Wait_for_coffee_brew"></Action> </Fallback> </Sequence> </Sequence> Table7: Example 2 BrewCoffee in BTSIMBENCH.Fault of the Counterfactuals BT: robot does not get coffee beans before try to pour some into the coffee machine.Fault of Unreachable BT: robot does not pour the brewed coffee into the mug while the task goal is to ensure that the coffee is brewed and contained in the mug.Task NameGetDrink Task DesciptionThe robot task is to prepare a drink.The behavior logic of a robot should be as follows.The water glass and a straw are inside a cabinet.The pitcher filled with orange juice is inside an electric refrigerator.And an ice cube is inside a bowl which is also in the refrigerator.The robot needs to retrieve the water glass, pitcher, ice cube from their respective locations in the kitchen, then place them on the table.Then robot should fill the water glass with orange juice, add an ice cube to the glass, and place the straw inside the glass.The goal is to obtain a glass of orange juice with ice cube.Action NodesMove_to_table: The robot moves to the location of the table.Move_to_cabinet: The robot moves to the location of the cabinet.Open_cabinet: The robot opens the cabinet door with one gripper.Retrieve_water_glass_from_cabinet: The robot extends its an gripper into the cabinet, holds the water glass and takes it out of the cabinet.Retrieve_straw_from_cabinet: The robot extends its an gripper into the cabinet, holds a straw and takes it out of the cabinet.Place_glass_straw_to_table: The robot extends the gripper that holds the water glass and the straw, places the water glass and straw on the table, and then retracts the grippers.Move_to_refrigerator: The robot moves to the location of the refrigerator.Open_refrigerator: The robot opens the refrigerator door with one gripper.Retrieve_pitcher_from_refrigerator: The robot extends its an gripper into the refrigerator, holds the pitcher, and takes the pitcher out of the refrigerator.Retrieve_ice_cube_from_refrigerator: The robot extends its an gripper into the refrigerator, holds the ice cube, and takes ice cube out of the refrigerator.
Claude 3.5 sonnet. Anthropic, </p>
<p>Bt expansion: a sound and complete algorithm for behavior planning of intelligent robots with behavior trees. Zhongxuan Cai, Minglong Li, Wanrong Huang, Wenjing Yang, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202135</p>
<p>Arroch: Augmented reality for robots collaborating with a human. Kishan Chandan, Vidisha Kudalkar, Xiang Li, Shiqi Zhang, 2021 IEEE International Conference on Robotics and Automation (ICRA). IEEE2021</p>
<p>Behavior trees in robotics and AI: An introduction. Michele Colledanchise, Petter Ögren, 2018CRC PressDeepSeek-AI. 2025. Introducing deepseek-v3</p>
<p>Carla: An open urban driving simulator. Alexey Dosovitskiy, German Ros, Felipe Codevilla, Antonio Lopez, Vladlen Koltun, Conference on robot learning. PMLR2017</p>
<p>Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, arXiv:2407.21783The llama 3 herd of models. 2024arXiv preprint</p>
<p>Tora: A tool-integrated reasoning agent for mathematical problem solving. Zhibin Gou, Zhihong Shao, Yeyun Gong, Yujiu Yang, Minlie Huang, Nan Duan, Weizhu Chen, arXiv:2309.174522023arXiv preprint</p>
<p>Recurrent world models facilitate policy evolution. David Ha, Jürgen Schmidhuber, Advances in neural information processing systems. 201831</p>
<p>Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, Zhiting Hu, arXiv:2305.14992Reasoning with language model is planning with world model. 2023arXiv preprint</p>
<p>A switching action model for dem-based multi-agent crowded behavior simulator. Eiji Harada, Hitoshi Gotoh, Noorhazlinda Binti, Abd Rahman, Safety science. 792015</p>
<p>Using generative adversarial networks to develop a realistic human behavior simulator. Ali El Hassouni, Mark Hoogendoorn, Vesa Muhonen, PRIMA 2018: Principles and Practice of Multi-Agent Systems: 21st International Conference. Tokyo, JapanSpringer2018. October 29-November 2, 201821</p>
<p>Autonomously constructing hierarchical task networks for planning and human-robot collaboration. Bradley Hayes, Brian Scassellati, 2016 IEEE International Conference on Robotics and Automation (ICRA). IEEE2016</p>
<p>Learning behavior trees with genetic programming in unpredictable environments. Matteo Iovino, Jonathan Styrud, Pietro Falco, Christian Smith, 2021 IEEE International Conference on Robotics and Automation (ICRA). IEEE2021</p>
<p>Yunfan Jiang, Ruohan Zhang, Josiah Wong, Chen Wang, Yanjie Ze, Hang Yin, Cem Gokmen, Shuran Song, Jiajun Wu, Li Fei-Fei, arXiv:2503.05652Behavior robot suite: Streamlining real-world whole-body manipulation for everyday household activities. 2025arXiv preprint</p>
<p>Design and use paradigms for gazebo, an open-source multi-robot simulator. Nathan Koenig, Andrew Howard, 2004 IEEE/RSJ international conference on intelligent robots and systems (IROS). Ieee20043IEEE Cat</p>
<p>Gazebo-3d multiple robot simulator with dynamics. Howard A Koenig, N , </p>
<p>Large language models are zero-shot reasoners. Takeshi Kojima, Shane Shixiang, Machel Gu, Yutaka Reid, Yusuke Matsuo, Iwasawa, Advances in neural information processing systems. 202235</p>
<p>icrowd: agent-based behavior modeling and crowd simulator. Manolis Vassilios I Kountouriotis, Stelios Ca Paterakis, Thomopoulos, Sensor/Information Fusion, and Target Recognition XXV. SPIE20169842Signal Processing</p>
<p>Principles and methods of testing finite state machines-a survey. David Lee, Mihalis Yannakakis, Proceedings of the IEEE. 8481996</p>
<p>Actoviz: a human behavior simulator for the evaluation of the dwelling performance of an atypical architectural space. Yun Gil, Lee , HCI International 2019-Posters: 21st International Conference. Orlando, FL, USASpringer2019. July 26-31, 20192019Proceedings, Part III 21</p>
<p>Chengshu Li, Jacky Liang, Andy Zeng, Xinyun Chen, Karol Hausman, Dorsa Sadigh, Sergey Levine, Li Fei-Fei, Fei Xia, Brian Ichter, arXiv:2312.04474Chain of code: Reasoning with a language model-augmented code emulator. 2023arXiv preprint</p>
<p>Behavior-1k: A humancentered, embodied ai benchmark with 1,000 everyday activities and realistic simulation. Chengshu Li, Ruohan Zhang, Josiah Wong, Cem Gokmen, Sanjana Srivastava, Roberto Martín-Martín, Chen Wang, Gabrael Levine, Wensi Ai, Benjamin Martinez, arXiv:2403.092272024aarXiv preprint</p>
<p>Yiheng Li, Chongjian Ge, Chenran Li, Chenfeng Xu, Masayoshi Tomizuka, Chen Tang, Mingyu Ding, Wei Zhan, arXiv:2407.04281Womd-reasoning: A large-scale language dataset for interaction and driving intentions reasoning. 2024barXiv preprint</p>
<p>Reflect: Summarizing robot experiences for failure explanation and correction. Zeyi Liu, Arpit Bahety, Shuran Song, arXiv:2306.157242023arXiv preprint</p>
<p>Deep learning, reinforcement learning, and world models. Yutaka Matsuo, Yann Lecun, Maneesh Sahani, Doina Precup, David Silver, Masashi Sugiyama, Eiji Uchibe, Neural Networks. 152Jun Morimoto. 2022</p>
<p>Infant behavior simulation based on an environmental model and a developmental behavior model. Yoshifumi Nishida, Yoichi Motomura, Koji Kitamura, Hiroshi Mizoguchi, 2004 IEEE International Conference on Systems, Man and Cybernetics. IEEE20042</p>
<p>NVIDIA. Nvidia isaac sim. </p>
<p>V-rep: A versatile and scalable robot simulation framework. Eric Rohmer, P N Surya, Marc Singh, Freese, 2013 IEEE/RSJ international conference on intelligent robots and systems. IEEE2013</p>
<p>A survey and comparison of commercial and opensource robotic simulator software. Aaron Staranowicz, Gian Luca Mariottini, Proceedings of the 4th International Conference on PErvasive Technologies Related to Assistive Environments. the 4th International Conference on PErvasive Technologies Related to Assistive Environments2011</p>
<p>Simulation environment for mobile robots testing using ros and gazebo. Kenta Takaya, Toshinori Asai, Valeri Kroumov, Florentin Smarandache, 2016 20th International Conference on System Theory, Control and Computing (ICSTCC). IEEE2016</p>
<p>Ruoyao Wang, Graham Todd, Ziang Xiao, Xingdi Yuan, Marc-Alexandre Côté, Peter Clark, Peter Jansen, arXiv:2406.06485Can language models serve as text-based world simulators?. 2024arXiv preprint</p>
<p>Self-consistency improves chain of thought reasoning in language models. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, Denny Zhou, arXiv:2203.111712022arXiv preprint</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Denny Quoc V Le, Zhou, Advances in neural information processing systems. 202235</p>
<p>An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, arXiv:2407.10671Qwen2 technical report. 2024arXiv preprint</p>
<p>Tree of thoughts: Deliberate problem solving with large language models. Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, Karthik Narasimhan, Advances in Neural Information Processing Systems. 202436</p>
<p>User behavior simulation for search result re-ranking. Junqi Zhang, Yiqun Liu, Jiaxin Mao, Weizhi Ma, Jiazheng Xu, Shaoping Ma, Qi Tian, ACM Transactions on Information Systems. 4112023</p>
<p>Dkprompt: Domain knowledge prompting vision-language models for open-world planning. Xiaohan Zhang, Zainab Altaweel, Yohei Hayamizu, Yan Ding, Saeid Amiri, Hao Yang, Andy Kaminski, Chad Esselink, Shiqi Zhang, arXiv:2406.176592024aarXiv preprint</p>
<p>Chain of preference optimization: Improving chain-of-thought reasoning in llms. Xuan Zhang, Chao Du, Tianyu Pang, Qian Liu, Wei Gao, Min Lin, arXiv:2406.091362024barXiv preprint</p>
<p>Large language models as commonsense knowledge for large-scale task planning. Zirui Zhao, Wee Sun Lee, David Hsu, Advances in Neural Information Processing Systems. 202436</p>            </div>
        </div>

    </div>
</body>
</html>