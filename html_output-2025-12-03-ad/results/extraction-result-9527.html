<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9527 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9527</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9527</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-165.html">extraction-schema-165</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <p><strong>Paper ID:</strong> paper-270371924</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2406.06009v1.pdf" target="_blank">The Impact of AI on Academic Research and Publishing</a></p>
                <p><strong>Paper Abstract:</strong> Generative artificial intelligence (AI) technologies like ChatGPT, have significantly impacted academic writing and publishing through their ability to generate content at levels comparable to or surpassing human writers. Through a review of recent interdisciplinary literature, this paper examines ethical considerations surrounding the integration of AI into academia, focusing on the potential for this technology to be used for scholarly misconduct and necessary oversight when using it for writing, editing, and reviewing of scholarly papers. The findings highlight the need for collaborative approaches to AI usage among publishers, editors, reviewers, and authors to ensure that this technology is used ethically and productively.</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9527.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9527.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-QualitativeAnalysis</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Large Language Models for Qualitative Analysis and Thematic Synthesis</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper mentions that LLMs can assist qualitative content analysis across bodies of scholarly literature by proposing initial coding schemes, extracting general themes, and helping organize systematic or scoping literature reviews (e.g., suggesting section headings and classifying papers under headings).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td>unspecified large language model(s) (e.g., ChatGPT / general LLMs)</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_description</strong></td>
                            <td>Generic transformer-based large language models (paper does not specify architecture size or fine-tuning for this task; examples named include ChatGPT and other LLMs), described as able to understand and generate human language and to assist in content analysis and synthesis when provided with summaries or text inputs.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>scholarship / interdisciplinary literature reviews and qualitative research (social sciences, humanities, and potentially other fields that use qualitative synthesis)</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Not specified quantitatively in the paper; described conceptually as collections of publication summaries, abstracts, or full-text excerpts assembled for a literature review or qualitative dataset (no number of papers, sources, or preprocessing steps are reported).</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_type</strong></td>
                            <td>thematic patterns / coding schema / general themes across literature (i.e., high-level qualitative rules or patterns that recur across papers)</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_example</strong></td>
                            <td>No concrete empirical example of an extracted 'law' is reported; suggested outputs include an initial set of codes, identification of general themes, suggested section headings for a literature review, and classification of papers under headings.</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_methodology</strong></td>
                            <td>Described qualitatively: prompt-based use of LLMs on researcher-provided summaries or textual excerpts to propose codes and themes; using LLM outputs to guide human coders or to structure systematic/scoping reviews (no formal chain-of-thought, RAG, or fine-tuning workflows are specified).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Not empirically evaluated in this paper; authors recommend comparing LLM outputs to human coding and expert review and note the need for transparency, consistency checks, and further examination of accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>No experimental results presented — the paper presents LLMs' use as a promising, assistive approach for generating initial codes and themes and for organizing literature reviews, but emphasizes these are supportive suggestions requiring human validation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>No quantitative comparison to human coders or traditional meta-synthesis methods is provided; the narrative suggests LLMs should be used to augment rather than replace human-led qualitative synthesis.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td>Quality, consistency, and transparency of LLM-driven qualitative analysis are flagged as primary limitations; LLMs do not yet provide consistent coding processes comparable to human coders, and outputs require human vetting.</td>
                        </tr>
                        <tr>
                            <td><strong>bias_or_hallucination_issues</strong></td>
                            <td>The paper explicitly warns about 'hallucinations' (e.g., fabricated references) and general concerns about black-box behavior; also notes broader concerns about bias in AI-assisted processes (e.g., potential bias in automated peer-review favoring high-impact countries).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Impact of AI on Academic Research and Publishing', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9527.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9527.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-LitReviewOrganizer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLMs for Organizing and Synthesizing Literature Reviews</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper states LLMs can take researcher-supplied summaries of publications and revise them into coherent narratives, propose subheadings for literature reviews, and identify which articles fit under each subheading, thereby assisting synthesis across many scholarly inputs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td>ChatGPT / generic LLMs (unspecified)</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_description</strong></td>
                            <td>Web-based LLMs (e.g., ChatGPT) with typical sequence-to-sequence/decoder-only transformer architectures; no task-specific fine-tuning or size details for literature-synthesis tasks are provided in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>literature synthesis across academic disciplines (used for writing literature reviews and organizing bodies of scholarly work)</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Described as researcher-collected summaries of publications or tables of findings; the paper does not specify corpus size, exact sources, or preprocessing steps.</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_type</strong></td>
                            <td>organizational and thematic synthesis (rules for grouping papers and for narrative structuring rather than domain scientific 'laws')</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_example</strong></td>
                            <td>No domain-specific rule reported; suggested outputs include coherent narrative synthesis from summaries, proposed literature-review subheadings, and mapping of articles to subheadings.</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_methodology</strong></td>
                            <td>Prompt engineering on researcher-supplied summaries or tables (e.g., asking LLM to 'revise summaries into a coherent narrative' or 'determine subheadings and classify articles'); no retrieval augmentation or fine-tuning described.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>No formal evaluation reported; the authors advise human verification of LLM outputs and caution against accepting outputs without checking for meaning changes and hallucinated references.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Claimed as a useful time-saving and organizational tool (particularly helpful for non-native English authors), but with caveats about occasional inaccuracies and the need for manual verification.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>No empirical baseline comparison; qualitatively contrasted with human editing and organization — LLMs can speed and assist but not fully replace human judgment.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td>Risk of changing sentence meaning, replacing key terms inappropriately, and introducing hallucinated citations; output quality may require multiple prompt iterations and manual checking.</td>
                        </tr>
                        <tr>
                            <td><strong>bias_or_hallucination_issues</strong></td>
                            <td>Explicitly warns of hallucinations (including fake references) and the black-box nature of LLMs that complicates trust and attribution.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Impact of AI on Academic Research and Publishing', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9527.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9527.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AI-ManuscriptMgmt</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AI-based Manuscript Management Tools (LLM-enabled) for Multi-paper Screening and Evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper cites AI manuscript management tools (and LLMs more generally) as able to perform initial quality control across many submitted manuscripts — tasks include plagiarism and robot-author detection, statistical checking, reproducibility checks, manuscript-structure checking, and multipurpose manuscript evaluation — which could support large-scale screening and classification of scholarly inputs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td>unspecified AI manuscript management tools and LLM-backed systems (references to work by Kousha & Thelwall, Checco et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_description</strong></td>
                            <td>Described as AI manuscript management tools that may incorporate multiple algorithms (including LLMs) for automated checks; specific architectures, sizes, or fine-tuning details are not given in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>scholarly publishing workflow / editorial screening across journal submissions (multi-document corpus: many submitted manuscripts)</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Incoming sets of submitted manuscripts to journals/conferences; the paper does not provide counts or precise sources, but implies application at scale within editorial systems.</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_type</strong></td>
                            <td>classification and evaluation heuristics (i.e., rules for relevance, structure, reproducibility flags) rather than scientific domain laws</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_example</strong></td>
                            <td>No extracted domain law provided; cited capabilities include automated detection of scope fit, plagiarism, robot authorship, and structural or statistical anomalies across submitted manuscripts.</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_methodology</strong></td>
                            <td>Described as automated initial screening using AI tools (likely pipeline combining detectors and possibly LLM summarization/classification); the paper cites prior work but gives no implementation details such as prompt strategies or model fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Paper states the accuracy of these tools 'needs to be further examined' and does not report systematic evaluation results; prior cited works (Kousha & Thelwall; Checco et al.) are referenced for more detail.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Presented as promising for speeding initial editorial triage and performing complex checks, but with the caveat that accuracy, fairness, and reliability require more study.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>No empirical performance numbers or direct comparisons to human editorial triage are given in this paper; authors emphasize need for further examination of accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td>Unclear accuracy, potential for bias in automated decision-making, and legal/ethical concerns about training data; also the paper notes that LLMs lack domain-expert judgment required for full peer review.</td>
                        </tr>
                        <tr>
                            <td><strong>bias_or_hallucination_issues</strong></td>
                            <td>General concerns about bias and the black-box nature of tools; earlier in the paper concerns are raised that automation may bias peer review in favor of authors from high-impact countries.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Impact of AI on Academic Research and Publishing', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9527.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9527.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Galactica-mention</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Galactica (LLM trained on scientific data) — Mention</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Table 1 lists Galactica (120B parameters) as a model trained predominantly on scientific data and noted as publicly available; the paper includes this model in a list of LLMs that could be relevant to scientific synthesis tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td>Galactica</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_description</strong></td>
                            <td>Galactica, cited here with ~120B parameters and training data composition noted as 86% scientific data, 8% webpages, and 7% code (as per the paper's Table 1); no task-specific fine-tuning or experiments are reported in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>science-specific knowledge work and potential synthesis of scientific literature</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Not applicable in this paper — Galactica's training corpus is summarized in Table 1 (predominantly scientific data) but no downstream task corpus or number of papers used for synthesis is reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_type</strong></td>
                            <td>potentially domain scientific summarization and synthesis (implied) but no concrete law extraction is documented in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_example</strong></td>
                            <td>No example of a qualitative law extracted by Galactica is provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_methodology</strong></td>
                            <td>No methodology described here; Galactica is listed among LLMs that could be used for scientific tasks but the authors do not report using it for law extraction or synthesis in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>No evaluation reported in this paper for Galactica on law extraction or synthesis tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Only listed in an LLM model table; the paper does not present empirical results using Galactica for synthesis or law extraction.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Not provided.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td>No model-specific limitations beyond general limitations of LLMs discussed elsewhere in the paper (e.g., hallucinations, black-box concerns).</td>
                        </tr>
                        <tr>
                            <td><strong>bias_or_hallucination_issues</strong></td>
                            <td>General warnings about LLM hallucinations and copyright/training-data legal concerns apply; no Galactica-specific issues are analyzed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The Impact of AI on Academic Research and Publishing', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Supporting serendipity: Opportunities and challenges for Human-AI Collaboration in qualitative analysis <em>(Rating: 2)</em></li>
                <li>Artificial intelligence to support publishing and peer review: A summary and review <em>(Rating: 2)</em></li>
                <li>AI-assisted peer review <em>(Rating: 2)</em></li>
                <li>Galactica: A large language model for science <em>(Rating: 1)</em></li>
                <li>ChatGPT and a new academic reality: Artificial Intelligence-written research papers and the ethics of the large language models in scholarly publishing <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9527",
    "paper_id": "paper-270371924",
    "extraction_schema_id": "extraction-schema-165",
    "extracted_data": [
        {
            "name_short": "LLM-QualitativeAnalysis",
            "name_full": "Large Language Models for Qualitative Analysis and Thematic Synthesis",
            "brief_description": "The paper mentions that LLMs can assist qualitative content analysis across bodies of scholarly literature by proposing initial coding schemes, extracting general themes, and helping organize systematic or scoping literature reviews (e.g., suggesting section headings and classifying papers under headings).",
            "citation_title": "here",
            "mention_or_use": "mention",
            "llm_model_name": "unspecified large language model(s) (e.g., ChatGPT / general LLMs)",
            "llm_model_description": "Generic transformer-based large language models (paper does not specify architecture size or fine-tuning for this task; examples named include ChatGPT and other LLMs), described as able to understand and generate human language and to assist in content analysis and synthesis when provided with summaries or text inputs.",
            "application_domain": "scholarship / interdisciplinary literature reviews and qualitative research (social sciences, humanities, and potentially other fields that use qualitative synthesis)",
            "input_corpus_description": "Not specified quantitatively in the paper; described conceptually as collections of publication summaries, abstracts, or full-text excerpts assembled for a literature review or qualitative dataset (no number of papers, sources, or preprocessing steps are reported).",
            "qualitative_law_type": "thematic patterns / coding schema / general themes across literature (i.e., high-level qualitative rules or patterns that recur across papers)",
            "qualitative_law_example": "No concrete empirical example of an extracted 'law' is reported; suggested outputs include an initial set of codes, identification of general themes, suggested section headings for a literature review, and classification of papers under headings.",
            "extraction_methodology": "Described qualitatively: prompt-based use of LLMs on researcher-provided summaries or textual excerpts to propose codes and themes; using LLM outputs to guide human coders or to structure systematic/scoping reviews (no formal chain-of-thought, RAG, or fine-tuning workflows are specified).",
            "evaluation_method": "Not empirically evaluated in this paper; authors recommend comparing LLM outputs to human coding and expert review and note the need for transparency, consistency checks, and further examination of accuracy.",
            "results_summary": "No experimental results presented — the paper presents LLMs' use as a promising, assistive approach for generating initial codes and themes and for organizing literature reviews, but emphasizes these are supportive suggestions requiring human validation.",
            "comparison_to_baseline": "No quantitative comparison to human coders or traditional meta-synthesis methods is provided; the narrative suggests LLMs should be used to augment rather than replace human-led qualitative synthesis.",
            "reported_limitations": "Quality, consistency, and transparency of LLM-driven qualitative analysis are flagged as primary limitations; LLMs do not yet provide consistent coding processes comparable to human coders, and outputs require human vetting.",
            "bias_or_hallucination_issues": "The paper explicitly warns about 'hallucinations' (e.g., fabricated references) and general concerns about black-box behavior; also notes broader concerns about bias in AI-assisted processes (e.g., potential bias in automated peer-review favoring high-impact countries).",
            "uuid": "e9527.0",
            "source_info": {
                "paper_title": "The Impact of AI on Academic Research and Publishing",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "LLM-LitReviewOrganizer",
            "name_full": "LLMs for Organizing and Synthesizing Literature Reviews",
            "brief_description": "The paper states LLMs can take researcher-supplied summaries of publications and revise them into coherent narratives, propose subheadings for literature reviews, and identify which articles fit under each subheading, thereby assisting synthesis across many scholarly inputs.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "llm_model_name": "ChatGPT / generic LLMs (unspecified)",
            "llm_model_description": "Web-based LLMs (e.g., ChatGPT) with typical sequence-to-sequence/decoder-only transformer architectures; no task-specific fine-tuning or size details for literature-synthesis tasks are provided in the paper.",
            "application_domain": "literature synthesis across academic disciplines (used for writing literature reviews and organizing bodies of scholarly work)",
            "input_corpus_description": "Described as researcher-collected summaries of publications or tables of findings; the paper does not specify corpus size, exact sources, or preprocessing steps.",
            "qualitative_law_type": "organizational and thematic synthesis (rules for grouping papers and for narrative structuring rather than domain scientific 'laws')",
            "qualitative_law_example": "No domain-specific rule reported; suggested outputs include coherent narrative synthesis from summaries, proposed literature-review subheadings, and mapping of articles to subheadings.",
            "extraction_methodology": "Prompt engineering on researcher-supplied summaries or tables (e.g., asking LLM to 'revise summaries into a coherent narrative' or 'determine subheadings and classify articles'); no retrieval augmentation or fine-tuning described.",
            "evaluation_method": "No formal evaluation reported; the authors advise human verification of LLM outputs and caution against accepting outputs without checking for meaning changes and hallucinated references.",
            "results_summary": "Claimed as a useful time-saving and organizational tool (particularly helpful for non-native English authors), but with caveats about occasional inaccuracies and the need for manual verification.",
            "comparison_to_baseline": "No empirical baseline comparison; qualitatively contrasted with human editing and organization — LLMs can speed and assist but not fully replace human judgment.",
            "reported_limitations": "Risk of changing sentence meaning, replacing key terms inappropriately, and introducing hallucinated citations; output quality may require multiple prompt iterations and manual checking.",
            "bias_or_hallucination_issues": "Explicitly warns of hallucinations (including fake references) and the black-box nature of LLMs that complicates trust and attribution.",
            "uuid": "e9527.1",
            "source_info": {
                "paper_title": "The Impact of AI on Academic Research and Publishing",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "AI-ManuscriptMgmt",
            "name_full": "AI-based Manuscript Management Tools (LLM-enabled) for Multi-paper Screening and Evaluation",
            "brief_description": "The paper cites AI manuscript management tools (and LLMs more generally) as able to perform initial quality control across many submitted manuscripts — tasks include plagiarism and robot-author detection, statistical checking, reproducibility checks, manuscript-structure checking, and multipurpose manuscript evaluation — which could support large-scale screening and classification of scholarly inputs.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "llm_model_name": "unspecified AI manuscript management tools and LLM-backed systems (references to work by Kousha & Thelwall, Checco et al.)",
            "llm_model_description": "Described as AI manuscript management tools that may incorporate multiple algorithms (including LLMs) for automated checks; specific architectures, sizes, or fine-tuning details are not given in this paper.",
            "application_domain": "scholarly publishing workflow / editorial screening across journal submissions (multi-document corpus: many submitted manuscripts)",
            "input_corpus_description": "Incoming sets of submitted manuscripts to journals/conferences; the paper does not provide counts or precise sources, but implies application at scale within editorial systems.",
            "qualitative_law_type": "classification and evaluation heuristics (i.e., rules for relevance, structure, reproducibility flags) rather than scientific domain laws",
            "qualitative_law_example": "No extracted domain law provided; cited capabilities include automated detection of scope fit, plagiarism, robot authorship, and structural or statistical anomalies across submitted manuscripts.",
            "extraction_methodology": "Described as automated initial screening using AI tools (likely pipeline combining detectors and possibly LLM summarization/classification); the paper cites prior work but gives no implementation details such as prompt strategies or model fine-tuning.",
            "evaluation_method": "Paper states the accuracy of these tools 'needs to be further examined' and does not report systematic evaluation results; prior cited works (Kousha & Thelwall; Checco et al.) are referenced for more detail.",
            "results_summary": "Presented as promising for speeding initial editorial triage and performing complex checks, but with the caveat that accuracy, fairness, and reliability require more study.",
            "comparison_to_baseline": "No empirical performance numbers or direct comparisons to human editorial triage are given in this paper; authors emphasize need for further examination of accuracy.",
            "reported_limitations": "Unclear accuracy, potential for bias in automated decision-making, and legal/ethical concerns about training data; also the paper notes that LLMs lack domain-expert judgment required for full peer review.",
            "bias_or_hallucination_issues": "General concerns about bias and the black-box nature of tools; earlier in the paper concerns are raised that automation may bias peer review in favor of authors from high-impact countries.",
            "uuid": "e9527.2",
            "source_info": {
                "paper_title": "The Impact of AI on Academic Research and Publishing",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Galactica-mention",
            "name_full": "Galactica (LLM trained on scientific data) — Mention",
            "brief_description": "Table 1 lists Galactica (120B parameters) as a model trained predominantly on scientific data and noted as publicly available; the paper includes this model in a list of LLMs that could be relevant to scientific synthesis tasks.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "llm_model_name": "Galactica",
            "llm_model_description": "Galactica, cited here with ~120B parameters and training data composition noted as 86% scientific data, 8% webpages, and 7% code (as per the paper's Table 1); no task-specific fine-tuning or experiments are reported in this paper.",
            "application_domain": "science-specific knowledge work and potential synthesis of scientific literature",
            "input_corpus_description": "Not applicable in this paper — Galactica's training corpus is summarized in Table 1 (predominantly scientific data) but no downstream task corpus or number of papers used for synthesis is reported here.",
            "qualitative_law_type": "potentially domain scientific summarization and synthesis (implied) but no concrete law extraction is documented in this paper",
            "qualitative_law_example": "No example of a qualitative law extracted by Galactica is provided in this paper.",
            "extraction_methodology": "No methodology described here; Galactica is listed among LLMs that could be used for scientific tasks but the authors do not report using it for law extraction or synthesis in this paper.",
            "evaluation_method": "No evaluation reported in this paper for Galactica on law extraction or synthesis tasks.",
            "results_summary": "Only listed in an LLM model table; the paper does not present empirical results using Galactica for synthesis or law extraction.",
            "comparison_to_baseline": "Not provided.",
            "reported_limitations": "No model-specific limitations beyond general limitations of LLMs discussed elsewhere in the paper (e.g., hallucinations, black-box concerns).",
            "bias_or_hallucination_issues": "General warnings about LLM hallucinations and copyright/training-data legal concerns apply; no Galactica-specific issues are analyzed in this paper.",
            "uuid": "e9527.3",
            "source_info": {
                "paper_title": "The Impact of AI on Academic Research and Publishing",
                "publication_date_yy_mm": "2024-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Supporting serendipity: Opportunities and challenges for Human-AI Collaboration in qualitative analysis",
            "rating": 2,
            "sanitized_title": "supporting_serendipity_opportunities_and_challenges_for_humanai_collaboration_in_qualitative_analysis"
        },
        {
            "paper_title": "Artificial intelligence to support publishing and peer review: A summary and review",
            "rating": 2,
            "sanitized_title": "artificial_intelligence_to_support_publishing_and_peer_review_a_summary_and_review"
        },
        {
            "paper_title": "AI-assisted peer review",
            "rating": 2,
            "sanitized_title": "aiassisted_peer_review"
        },
        {
            "paper_title": "Galactica: A large language model for science",
            "rating": 1,
            "sanitized_title": "galactica_a_large_language_model_for_science"
        },
        {
            "paper_title": "ChatGPT and a new academic reality: Artificial Intelligence-written research papers and the ethics of the large language models in scholarly publishing",
            "rating": 1,
            "sanitized_title": "chatgpt_and_a_new_academic_reality_artificial_intelligencewritten_research_papers_and_the_ethics_of_the_large_language_models_in_scholarly_publishing"
        }
    ],
    "cost": 0.01121675,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>The Impact of AI on Academic Research and Publishing</p>
<p>Brady Lund 
University of North Texas</p>
<p>Manika Lamba 
University of Illinois at Urbana-Champaign</p>
<p>Sang Hoo Oh 
University of Illinois at Urbana-Champaign</p>
<p>The Impact of AI on Academic Research and Publishing
28C77BDB089CAFB6CDE413C080156C02Artificial IntelligenceLarge Language ModelsAcademic ResearchPublishing EthicsScholarly Publishing
Generative artificial intelligence (AI) technologies like ChatGPT, have significantly impacted academic writing and publishing through their ability to generate content at levels comparable to or surpassing human writers.Through a review of recent interdisciplinary literature, this paper examines ethical considerations surrounding the integration of AI into academia, focusing on the potential for this technology to be used for scholarly misconduct and necessary oversight when using it for writing, editing, and reviewing of scholarly papers.The findings highlight the need for collaborative approaches to AI usage among publishers, editors, reviewers, and authors to ensure that this technology is used ethically and productively.</p>
<p>Introduction</p>
<p>Generative artificial intelligence technologies have rapidly transformed our daily lives, with one of the most profound impacts observed in the realm of writing.These models can produce content at a level that either matches or surpasses the quality of an average human writer.This transformation holds particular significance in academia, where faculty members are traditionally expected to engage in extensive scholarly writing.The increasing prevalence of generative artificial intelligence in academia raises substantial ethical concerns.Reports of scholarly misconduct, spanning a spectrum of issues, have surged in recent years.The implications of integrating such technology into the academic landscape prompt a careful examination of the ethical considerations associated with its use.</p>
<p>The impact of AI on academic research and publishing is multifaceted.Shevlane (2019) highlights the potential for both misuse and protection in AI research, emphasizing the need for a balanced approach.Upshall (2019) discusses the application of AI in scholarly publishing, particularly in identifying suitable peer reviewers.Cheng (2012) provides a quantitative analysis of recent AI research publications, identifying influential journals, languages, and authors.Thelwall (2019) raises concerns about the potential for bias in the peer review process due to AI automation, particularly favoring authors from high-impact countries.These studies collectively underscore the need for careful consideration of the ethical and practical implications of AI in academic research and publishing.</p>
<p>Definitions of Terms</p>
<p>• Generative Artificial Intelligence (Gen AI, GAI, also called "generative models" in this chapter) is a type of artificial intelligence that generates new data/content rather than only classifying or predicting outcomes based on input data (Lund &amp; Wang, 2023).</p>
<p>• Machine Learning (ML) is the process of predicting features of past/trained data on new/test data (Lamba and Madhusudhan, 2022).</p>
<p>• Large Language Models (LLMs, also called "language models" and "AI models" in this chapter) "refer to transformer language models that contain hundreds of billions (or more) of parameters, which are trained on massive text data, such as GPT-3, PaLM, Galactica, and LLaMA" (Zhao et al., 2023).</p>
<p>• Generative Pre-Trained Transformer (GPT, also referred to when referencing the technology ChatGPT) is the underlying large language model behind the popular platform, ChatGPT.It is characterized by its pattern of training, which consists of unsupervised learning followed by supervised fine-tuning (Alt et al., 2019).</p>
<p>Selecting a Model</p>
<p>If using a generative model for academic purposes, it is important to determine which one is the best for your needs.ChatGPT stands out for its ubiquity, but it is a general model.Many models have been trained using training data related to specific topics or purposes (Table 1).</p>
<p>Ethics of AI for Writing Papers</p>
<p>Idea Generation</p>
<p>AI models are adept at idea generation.The better the prompts that you can provide, the better the ideas that you can receive.Yet, it is important to use these AI-generated ideas with care.</p>
<p>Considering these models reference their training data, the ideas may not be entirely original.Thus, the models should be used in conjunction with other information sources.If the generation of ideas also involves the inclusion of scholarly references, authors must also be aware of "hallucinations,"</p>
<p>or fake references created by the model (Sanchez-Ramos et al., 2023).</p>
<p>A good prompt for idea generation will provide specific details.A prompt like "generate topic ideas for a paper relating to developmental psychology" is so broad that it is unlikely to produce particularly meaningful or original ideas.This prompt can be narrowed significantly to read something like "generate topic ideas for a research paper relating to the symptomatology of autism spectrum disorder among Hispanic young adults."This prompt is specific and should be rewarded with specific, new ideas from the AI model.</p>
<p>Another means for generating research ideas would be, instead of focusing on a topic, to provide information about your past research, such as titles and abstracts, and have the model use this information to generate ideas for related studies.This could be a particularly fruitful approach, as it leverages your own past ideas and interests, rather than ideas that may have initially come from another source.Of course, a concern is relevancy and feasibility.A model may present an idea that is unrealistic and it is the role of the researcher to determine which ideas are actually worthwhile.</p>
<p>An AI model is a brainstorming tool, not an excuse to go on "auto-pilot" in terms of critical evaluation of ideas.</p>
<p>Creation of Sample Datasets</p>
<p>When developing new algorithms or approaches to extracting knowledge from data, a challenge can be finding appropriate datasets with which to test them.This is a challenge that AI models are particularly adept at solving.By providing information about the approach you have created and any data requirements, an AI model can produce a dataset that will work for testing.It can even generate various datasets designed to produce vastly different results or flawed datasets designed to produce an error message.This development is groundbreaking for data scientists and researchers.AI models will work especially well for creating sample datasets when they are provided with a few examples.</p>
<p>Data Analysis</p>
<p>Large language models can be used to support both quantitative and qualitative analysis, but this should be done with care.Machine learning models excel with statistical analysis.However, the amount of detail in most research datasets makes it difficult to analyze using web-based models like ChatGPT.Feeding only partial data into a model will significantly impact most analyses a researcher would want to perform.These models, however, can be quite adept at producing Python or R scripts that can then be used to analyze data.For instance, Figure 1 shows a ChatGPTgenerated Python script for performing a logistical regression analysis on a dataset with one dependent variable and five explanatory variables.The script, when run in Python, works perfectly.</p>
<p>Figure 1. ChatGPT-Generated Python Script for Logistical Regression</p>
<p>Large language models that do not have the same character restrictions as web-based models like</p>
<p>ChatGPT may be able to perform the analyses directly.Additionally, these models can clean and transform data to perform analysis.They can even recommend the best statistical analyses to perform, based on the type and amount of data collected.Many of the popular models can provide a data table and distinguish categorical, nominal, and scalar data.</p>
<p>Large language models can also assist with qualitative analysis.These models have been designed</p>
<p>to "understand" human language through computational methods, so tasks like content analysis can be performed quite easily.This is more or less the model's main purpose.However, the issue with qualitative analysis is quality, consistency, and transparency (Jiang et al., 2021).When human researchers perform content analysis, they can agree upon a set of codes and describe a common process of identifying these codes in the data.As of yet, this is not a strength of language models.</p>
<p>So how could LLMs be used to support qualitative analysis, if a researcher was interested in using them for this purpose?They could be used to help identify an initial set of codes that can then be compared to the work of human coders.They could also be used to identify general themes that could then be explored further by human researchers.This could also be helpful for guiding systematic or scoping literature reviews.For instance, it could be used to determine section headings or classify papers underneath existing headings.</p>
<p>Writing Manuscripts</p>
<p>Large language models can help to organize a literature review.If you collect your own summaries of publications to be cited, the language model can revise and edit the summaries into a coherent narrative.Conversely, it can determine subheadings for a literature review and identify which articles could fit under each one.This does not replace the work of reading and summarizing papers for a literature review, but it can help to ensure quality of the reviews and perhaps save some time.</p>
<p>Additionally, LLMs can compose analyses for the results section of a paper quite well based just on the tables that you create to display findings.However, LLMs are not particularly good at writing entire manuscripts from scratch and submitting papers written by LLMs as your own creates significant ethical questions and issues.</p>
<p>Editing Manuscripts</p>
<p>Perhaps the task for which large language models are best suited within academia is revising and editing existing content within manuscripts.By providing a simple prompt like "please revise the following content to improve its quality and clarity," a model like ChatGPT can rework lengthy sections of a paper to read at a level virtually indistinguishable from a professional writer or editor.This is a potentially democratizing power.Authors for whom English is not their primary language now have a tool with which they can work to improve their scholarly writing to a level expected by higher-level academic journals.</p>
<p>However, there are considerable pitfalls that authors must avoid when using LLMs for this purpose.These models are by no means perfect and can produce less than satisfactory outputs on occasion, due to changing the meaning of sentences or inappropriately replacing key terms.Thus, it is critical to check the model's output before replacing any of the text in the original paper.The query may also need to be run through the model multiple times before a suitable output is procured.</p>
<p>AI Policies Among Publishers</p>
<p>AI Authorship Attribution.The matter of authorship attribution with artificial intelligence is a challenging one.In the early months following the release of ChatGPT, many writers included the language model as an additional author in their publications (King &amp; ChatGPT, 2023).However, by late spring, many journal publishers had posted a policy on their sites indicating that the use of language models should be acknowledged within the paper but these models should not be listed as authors (Lund &amp; Naheem, 2023).The rationale for not including AI as an author is due to the common criteria used to determine authorship for scholarly articles: that the author must contribute to the writing of the article, that the author must be able to understand all that is written, and that the author must be able to take responsibility for what is written.The final two points are a barrier to including AI as an author, as it is not clear that an AI model can understand, consent, and take responsibility for the content that it produces (Titus, 2024).</p>
<p>Additionally, existing AI authorship policies note that the AI models should be used for improving the quality of written works, rather than to generate new content from scratch.When asked to generate new content, language models rely on their training data, which means generated content is not necessarily original and is subject to copyright infringement.</p>
<p>There is some debate as to whether attribution of a large language model is actually necessary if that model is simply used as a tool to enhance writing and grammar, rather than to generate altogether new content.Suppose the model is not assimilating new knowledge into the existing writing, per se.In that case, its role is not significantly different from the use of tools embedded into Microsoft Word, like spell and grammar check, to improve writing.However, given the "black box" nature of AI, where users cannot tell how the tool actually works, concerns about the technology persist.The policy of acknowledging AI use may be a stop-gap measure until the nature of these models can be better understood.</p>
<p>AI Policies.</p>
<p>Ultimately, the extent to which AI usage is allowed or barred is likely to remain at the discretion of individual publishers.Like with individual people, some publishing companies may be eager adopters and allow and integrate AI into many aspects of the academic publishing process.</p>
<p>One thing that seems clear is that each publisher needs to provide a clear policy on whether AI is allowed and, if so, in which aspects of manuscript preparation and review.Without these policies in place, it is a veritable "wild west" for authors, reviewers, and editors (Lund et al., 2023).The following is an example of a policy a publisher might use:</p>
<p>The use of artificial intelligence tools, including large language models like ChatGPT, is permitted only for the purposes of enhancing the quality of writing in a completed manuscript.Authors are encouraged to retain a copy of their paper before AI was sued to make revisions and should be prepared to supply this copy to the editors if any questions about the originality of a manuscript arises.Peer reviewers for this journal may not use AI tools when preparing their reviews.</p>
<p>Authors who utilize AI should also acknowledge its usage (including the model and date(s) used) in the acknowledgements of their paper.</p>
<p>The above policy outlines how authors and reviewers may (or may not) use AI tools.This would likely limit some negative press should it be found that some authors have used AI without acknowledgement.Additionally, it gives authors clarity about journal practices before they submit.</p>
<p>Whatever the policy, editors should practice caution with AI, in order to protect themselves and their publications.If lawsuits surrounding the use of copyrighted materials to train AI progress, then the products of that model may also be challenged (Grynbaum &amp; Mac, 2023).By having a policy that disallows the use of AI to write substantial paper content, publishers can hopefully mitigate this potential issue.</p>
<p>AI in Editorial Processes</p>
<p>AI for Determining Value of Manuscripts</p>
<p>Could AI be used to provide a preliminary review of a paper to determine if it fits the scope and quality requirements for an academic journal?</p>
<p>Previous research has shown that different AI tools can be used to provide a preliminary review of submitted manuscripts (Checco et al, 2021;Kousha &amp; Thelwall, 2023).With the advent of large language models, AI manuscript management tools are now able to automate initial quality control of submitted manuscripts to determine if they fit the scope and quality requirements of an academic journal.Initial quality control-related tasks that these AI manuscript management tools can perform include the following: plagiarism detection, robot author detection, methods and automated statistical checking, transparency and reproducibility checking, manuscript structure checking, and multipurpose manuscript evaluation (Kousha &amp; Thelwall, 2023).It is evident that AI manuscript management tools can go beyond basic editorial tasks such as plagiarism and robot author detection.They are now capable of performing more complex tasks such as statistical checking and multipurpose manuscript evaluation.While the accuracy of these AI manuscript management tools needs to be further examined, it is clear that they hold significant promise for the future application of AI in the preliminary review process of a journal paper.</p>
<p>AI for Peer Review</p>
<p>There is evidence that large language models have already been used in some cases to either supplement or replace the duties of peer reviewers.Anecdotally, among the authors of this chapter, evidence of an AI-generated peer review for one of their papers was found on five occasions in 2023 alone.Some aspects of AI-generated reviews can be useful.For instance, suggestions to improve the writing and grammar of a paper can be useful.However, suggestions related to the actual content of a paper are often severely lacking.Most LLMs are trained in large stores of general knowledge but are not experts in specific subject areas.Existing language models lack the judgment of the human expert whose feedback has been requested by a journal or conference.One day, such models may exist -models that are trained to be experts in a specific subject area and assess the quality of new contributions -but a model like ChatGPT does not satisfy this objective.</p>
<p>LLMs could be used to help organize peer reviews and better articulate the reviewers' concerns.</p>
<p>They could make suggestions as to the structure and grammar of the paper.They could also be used for the initial screening of papers to ensure relevance to the journal and for the identification of relevant peer reviewers (Checco et al., 2021;Kousha &amp; Thelwall, 2023).However, these models should not be used to complete an entire review.The journal/conference has requested a review from a human reviewer, based on that individual's expertise, not ChatGPT.Furthermore, if the journal wanted a review from ChatGPT, they could simply ask ChatGPT directly, rather than ask a reviewer to use the model to generate a review for them.</p>
<p>AI for Editing Tasks</p>
<p>AI-assisted decision support systems for editors, reviewers, and authors may aid in decisionmaking and speed up the overall process (Ghosal, 2019).Further, AI-based manuscript writing support may allow the researcher to perform creative work in a more refined fashion (Nakazawa, 2022).</p>
<p>As opposed to peer reviewers using large language models to support peer review, it makes considerably more sense for journal or proceedings editors to utilize it in order to suggest potential edits to improve the quality of a manuscript.This is the flip side of encouraging authors to use AI directly to improve their papers.If editors do not believe that authors should be given the authority to use AI, but believe that they can use it more judiciously to make suggestions for the authors, then this may be an approach that they could take.Still, some publishers will likely be opposed to any use of AI at all, considering it to be unfair to talented writers who do not require AI assistance.</p>
<p>Conclusion</p>
<p>AI has already dramatically transformed academia and scholarly publishing in recent years, with the launch of ChatGPT representing an acceleration of this trend.It is critical for publishers to consider the entire research and publishing process when developing policy.A complete ban on AI use is likely not prudent, given a society that is increasingly adopting it in order to gain a competitive edge, but some restrictions on how AI can be used are necessary.Likely, a collaboration between publishers and their editors and authors would produce the most fruitful results.</p>
<p>As for researchers, it is advisable to use AI with care.These AI models are new and there are many ethical and legal issues yet to be sorted out.Recent years have shown a spike in article retractions, which can ruin promising academic careers.Avoidance of AI usage unless explicitly permitted in a publisher's policy is likely the best approach.Undoubtedly, more issues will emerge as AI technology matures and becomes more sophisticated.Authors, editors, and publishers have an opportunity to lead discussions on these issues and communicate clearly with one another in order to mitigate disruption.</p>
<p>Table 1 : Selected LLM Models (adapted from Zhao et al., 2023) Model (size) Release Time
1Data SourceAvailability PaperT5 (11B)Oct 2019Webpages (100%)PubliclyRaffel et al.Available(2020)LLaMA (65B)Feb 2023Webpages (87%), Books &amp;PubliclyTouvron et al.News (5%), Code (5%),Available(2023)Scientific Data (3%),Conversational Data (2%)GPT-3 (175B)May 2020Webpages (84%), Books &amp;ClosedBrown et al.News (16%)Source(2020)GoPHER (280B)Webpages (60%), Books &amp;ClosedRae et al.News (37%), Code (3%)Source(2021)GLaM (1200B) Dec 2021Webpages (48%),ClosedDu et al. (2021)Conversational Data (30%),SourceBooks &amp; News (22%)LaMDA (137B) Jan 2022Conversation Data (50%),ClosedThoppilan et al.Webpages (38%), Code (13%)Source(2022)Galactica (120B) Nov 2022Scientific Data (86%),PubliclyTaylor et al.Webpages (8%), Code (7%)Available(2022)GPT-NeoXApr 2022Scientific Data (38%),PubliclyBlack et al.(20B)Webpages (30%), Books &amp;Available(2022)News (15%), ConversationalData (10%), Code (8%)</p>
<p>Fine-tuning pre-trained transformer language models to distantly supervised relation extraction. Christoph Alt, Marc Hübner, Leonhard Hennig, arXiv:1906.086462019arXiv preprint</p>
<p>Gpt-neox-20b: An open-source autoregressive language model. Sid Black, Stella Biderman, Eric Hallahan, Quentin Anthony, Leo Gao, Laurence Golding, Horace He, arXiv:2204.067452022arXiv preprint</p>
<p>Language models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Advances in neural information processing systems. 332020</p>
<p>AI-assisted peer review. A Checco, L Bracciale, P Loreti, S Pinfield, G Bianchi, Humanities and Social Sciences Communications. 812021</p>
<p>An Overview of Publications on Artificial Intelligence Research: A Quantitative Analysis on Recent Papers. Saiyan Cheng, Bin Wang, 2012 Fifth International Joint Conference on Computational Sciences and Optimization. IEEE2012</p>
<p>Glam: Efficient scaling of language models with mixture-of-experts. Nan Du, Yanping Huang, Andrew M Dai, Simon Tong, Dmitry Lepikhin, Yuanzhong Xu, Maxim Krikun, International Conference on Machine Learning. PMLR2022</p>
<p>Exploring the implications of artificial intelligence in various aspects of scholarly peer review. Tirthankar Ghosal, Bull. IEEE Tech. Comm. Digit. Libr. 1512019</p>
<p>The Times Sues OpenAI and Microsoft over AI Use of Copyrighted Work. Michael M Grynbaum, Ryan Mac, New York Times. December 27, 2023</p>
<p>Supporting serendipity: Opportunities and challenges for Human-AI Collaboration in qualitative analysis. Jialun Jiang, Kandrea Aaron, Casey Wade, Jed R Fiesler, Brubaker, Proceedings of the ACM on Human-Computer Interaction. 5CSCW12021</p>
<p>A conversation on artificial intelligence, chatbots, and plagiarism in higher education. Michael R King, Chatgpt , Cellular and Molecular Bioengineering. 1612023</p>
<p>Artificial intelligence to support publishing and peer review: A summary and review. Kayvan Kousha, Mike Thelwall, Learned Publishing. 2023</p>
<p>Text Mining for Information Professionals. Manika Lamba, Margam Madhusudhan, 10.1007/978-3-030-85085-22022Springer</p>
<p>Competition-level code generation with alphacode. Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Rémi Leblond, Tom Eccles, Science. 37866242022</p>
<p>Can ChatGPT be an author? A study of artificial intelligence authorship policies in top academic journals. Brady D Lund, K T Naheem, Learned Publishing. 2023</p>
<p>Chatting about ChatGPT: how may AI and GPT impact academia and libraries?. Brady D Lund, Ting Wang, Library Hi Tech News. 4032023</p>
<p>ChatGPT and a new academic reality: Artificial Intelligence-written research papers and the ethics of the large language models in scholarly publishing. Brady D Lund, Ting Wang, Nishith Reddy Mannuru, Bing Nie, Somipam Shimray, Ziang Wang, Journal of the Association for Information Science and Technology. 7452023</p>
<p>Does the Use of AI to Create Academic Research Papers Undermine Researcher Originality?. Eisuke Nakazawa, Makoto Udagawa, Akira Akabayashi, AI. 332022</p>
<p>Codegen2: Lessons for training llms on programming and natural languages. Erik Nijkamp, Hiroaki Hayashi, Caiming Xiong, Silvio Savarese, Yingbo Zhou, arXiv:2305.023092023arXiv preprint</p>
<p>Beware of references when using ChatGPT as a source of information to write scientific articles. Luis Sanchez-Ramos, Lifeng Lin, Roberto Romero, American Journal of Obstetrics &amp; Gynecology. 2023</p>
<p>The Offense-Defense Balance of Scientific Knowledge: Does Publishing AI Research Reduce Misuse?. Toby Shevlane, Allan Dafoe, Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society. the AAAI/ACM Conference on AI, Ethics, and Society2020</p>
<p>Scaling language models: Methods, analysis &amp; insights from training gopher. Jack W Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John Aslanides, arXiv:2112.114462021arXiv preprint</p>
<p>Exploring the limits of transfer learning with a unified textto-text transformer. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, The Journal of Machine Learning Research. 2112020</p>
<p>Ross Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony Hartshorn, Elvis Saravia, Andrew Poulton, Viktor Kerkez, Robert Stojnic, arXiv:2211.09085Galactica: A large language model for science. 2022arXiv preprint</p>
<p>Does ChatGPT have semantic understanding? A problem with the statisticsof-occurrence strategy. Lisa Titus, Miracchi, Cognitive Systems Research. 831011742024</p>
<p>Artificial intelligence, automation and peer review. Mike Thelwall, Bristol. JISC. 2019</p>
<p>Lamda: Language models for dialog applications. Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze, Alicia Cheng, Jin, arXiv:2201.082392022arXiv preprint</p>
<p>Llama: Open and efficient foundation language models. Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, arXiv:2302.139712023arXiv preprint</p>
<p>Using AI to solve business problems in scholarly publishing. Michael Upshall, Insights. 3212019</p>
<p>A survey of large language models. Wayne Zhao, Kun Xin, Junyi Zhou, Tianyi Li, Xiaolei Tang, Yupeng Wang, Yingqian Hou, Min, arXiv:2303.182232023arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>