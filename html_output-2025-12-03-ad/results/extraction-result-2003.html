<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2003 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2003</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2003</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-48.html">extraction-schema-48</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of compositional generalization, systematic generalization, or out-of-distribution generalization experiments, including model architectures, task characteristics, performance metrics, and comparisons across different conditions.</div>
                <p><strong>Paper ID:</strong> paper-280422475</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2508.01948v2.pdf" target="_blank">Navigating High Dimensional Concept Space with Metalearning</a></p>
                <p><strong>Paper Abstract:</strong> Rapidly learning abstract concepts from limited examples is a hallmark of human intelligence. This work investigates whether gradient-based meta-learning can equip neural networks with inductive biases for efficient few-shot acquisition of discrete concepts. I compare meta-learning methods against a supervised learning baseline on Boolean concepts (logical statements) generated by a probabilistic context-free grammar (PCFG). By systematically varying concept dimensionality (number of features) and recursive compositionality (depth of grammar recursion), I delineate between complexity regimes in which meta-learning robustly improves few-shot concept learning and regimes in which it does not. Meta-learners are much better able to handle compositional complexity than featural complexity. I highlight some reasons for this with a representational analysis of the weights of meta-learners and a loss landscape analysis demonstrating how featural complexity increases the roughness of loss trajectories, allowing curvature-aware optimization to be more effective than first-order methods. I find improvements in out-of-distribution generalization on complex concepts by increasing the number of adaptation steps in meta-SGD, where adaptation acts as a way of encouraging exploration of rougher loss basins. Overall, this work highlights the intricacies of learning compositional versus featural complexity in high dimensional concept spaces and provides a road to understanding the role of 2nd order methods and extended gradient adaptation in few-shot concept learning.</p>
                <p><strong>Cost:</strong> 0.01</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2003.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2003.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of compositional generalization, systematic generalization, or out-of-distribution generalization experiments, including model architectures, task characteristics, performance metrics, and comparisons across different conditions.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Meta-SGD vs SGD on PCFG Boolean concepts</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Gradient-based Meta-SGD (1st- and 2nd-order) compared to supervised SGD on PCFG-generated Boolean concept classification</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>This paper evaluates gradient-based meta-learning (Meta-SGD, both first-order and second-order variants, with varying inner-loop adaptation steps) against a supervised SGD baseline on few-shot Boolean concept learning tasks generated by a PCFG that independently varies featural dimensionality and compositional depth.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>5-layer MLP (trained with Meta-SGD or SGD)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Fully-connected feedforward MLP with 5 hidden layers, 128 units per layer, ReLU activations, and a sigmoid output; trained end-to-end for few-shot Boolean classification using either Meta-SGD (meta-trained initialization and per-parameter step sizes) or standard SGD/Adam from scratch per task.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>is_pretrained</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>architectural_features</strong></td>
                            <td>standard MLP (no explicit modularity or symbolic modules); Meta-SGD augments training with learned per-parameter step sizes and second-order/backprop-through-inner-loop when used</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>logical / Boolean concept learning</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>PCFG Boolean concept classification (custom PCFG generator)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Few-shot binary classification of Boolean concepts (logical formulas) over F binary input features; concepts are sampled from a probabilistic context-free grammar (PCFG) that produces literals, negations, conjunctions, and disjunctions. For each sampled concept C, a K-shot support set (positive and negative examples) and a query set are drawn from {0,1}^F; the model must adapt to the sampled concept from few labeled examples and generalize to held-out query examples.</td>
                        </tr>
                        <tr>
                            <td><strong>compositional_depth</strong></td>
                            <td>D ∈ {3, 5, 7} (explicitly varied recursion depth of PCFG parse trees)</td>
                        </tr>
                        <tr>
                            <td><strong>composition_type</strong></td>
                            <td>nested logical operations (negation, conjunction, disjunction) — nested / recursive logical composition</td>
                        </tr>
                        <tr>
                            <td><strong>split_type</strong></td>
                            <td>Unseen-task evaluation: tasks (concepts) sampled from the same PCFG family for meta-evaluation (held-out concepts). OOD-style stress tests performed by systematically increasing feature dimensionality (F) and compositional depth (D); limited out-of-distribution grammar tests noted as future work.</td>
                        </tr>
                        <tr>
                            <td><strong>training_strategy</strong></td>
                            <td>Gradient-based meta-learning (Meta-SGD: 1st-order and 2nd-order variants) with inner-loop adaptation (K adapt steps = 1 or 10) vs standard supervised training (SGD/Adam from scratch on each task). Meta-training: 10,000 episodes; evaluation averaged over 5 seeds on 1,000 unseen tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>curriculum_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inoculation_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>iid_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compositional_performance</strong></td>
                            <td>Meta-SGD is highly robust to increased compositional depth (D): moving from D=3 to D=7 yields minimal performance degradation for Meta-SGD while SGD degrades substantially; reported relative improvements of Meta-SGD over SGD in final accuracy: +15.5% (simple concepts), +34.1% (medium concepts), +11.1% (complex concepts). First-order Meta-SGD with more adaptation steps (K=10) often matches or exceeds second-order Meta-SGD, especially at higher featural dimensionality.</td>
                        </tr>
                        <tr>
                            <td><strong>generalization_gap</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_by_depth</strong></td>
                            <td>Paper reports minimal degradation for Meta-SGD across depths D={3,5,7}; SGD shows substantial drops as D increases. Exact per-depth absolute accuracies not provided in text, only relative descriptions (Meta-SGD stable, SGD degrades).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_by_composition_type</strong></td>
                            <td>All composition types are logical/nested operations from the PCFG; compositional (deeper recursion) cases are handled well by Meta-SGD (robust), whereas featural complexity (more literals/features) is the primary failure mode. No fine-grained breakdown by specific operators provided.</td>
                        </tr>
                        <tr>
                            <td><strong>has_baseline_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparisons</strong></td>
                            <td>Baselines: (1) Vanilla supervised training (SGD/Adam) from scratch per task on the K-shot support set; (2) Meta-SGD first-order (no Hessian/backprop through inner loop) and second-order (full backprop through inner loop) variants, each tested with K=1 and K=10 inner-loop adaptation steps. Findings: Meta-SGD variants learn faster and converge to higher accuracies than SGD for low-to-moderate featural dimensionality (F=8,16). At F=32, most methods collapse; only 1st-order Meta-SGD with K=10 generalized above 60% in the reported experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>architectural_comparison</strong></td>
                            <td>Architectures held constant (5-layer MLP). Comparisons are algorithmic: 1st-order Meta-SGD vs 2nd-order Meta-SGD vs SGD; also inner-loop adaptation length K=1 vs K=10. Second-order methods outperform in low-featural-complexity settings (F=8), while first-order with extended adaptation (K=10) matches or exceeds second-order in higher-featural regimes (F=16 and F=32).</td>
                        </tr>
                        <tr>
                            <td><strong>scale_effects</strong></td>
                            <td>Scale here refers to input feature dimensionality F ∈ {8,16,32}. Performance collapses at F=32 for all methods except 1st-order Meta-SGD with K=10 (the only method to exceed 60% in that case). Increasing F dramatically increases loss landscape roughness and difficulty; meta-learning relative gains persist but absolute performance degrades.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>1) Meta-learning (Meta-SGD) provides substantial compositional generalization advantages: robust to increased compositional depth (D up to 7) while SGD degrades; 2) Featural/dimensional complexity (F) is the dominant failure mode — performance collapses at F=32 for most methods; 3) Inner-loop adaptation length matters: increasing adaptation steps (K=1→K=10) yields larger relative gains as landscape complexity increases (simple: +5–8%; medium: +10–12%; complex: +15–20%); 4) First-order Meta-SGD with more adaptation steps can match/exceed second-order Meta-SGD in high-featural regimes, while curvature-aware second-order updates are advantageous in low-featural (smoother) regimes; 5) Meta-SGD reshapes optimization trajectories (90–99% reduction in trajectory/geodesic length vs SGD) and reduces curvature metrics (Hessian trace reductions: ~92.6% for F=8,D=3; ~95.8% for F=8,D=5; ~88.5% for F=32,D=3), correlating landscape geometry with meta-learning benefit.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_analysis</strong></td>
                            <td>Primary failure: featural (high-dimensional) complexity creates highly rugged loss landscapes with many local minima (reported averages: simple ~0.3±0.1 minima, medium ~1.2±0.4, complex ~2.8±0.6) and large increases in roughness (simple roughness = 0.0002; medium ~4× increase; complex ~12× increase), causing all methods to suffer and meta-learning to lose absolute performance. The paper attributes meta-learning failures in high-F regimes to exponentially large input spaces (2^F) under data sparsity and resultant rough loss geometry.</td>
                        </tr>
                        <tr>
                            <td><strong>success_conditions</strong></td>
                            <td>Meta-learning succeeds when complexity arises primarily from compositional (recursive) structure rather than raw feature dimensionality; it benefits from second-order (curvature-aware) updates in smoother/low-dimensional regimes and from increased inner-loop adaptation (K up to 10) in rugged/high-dimensional regimes. Meta-SGD's learned initialization and per-parameter step sizes plus extended adaptation improve navigation of rugged basins and yield better few-shot generalization for compositionally complex concepts.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Meta-learning to compositionally generalize <em>(Rating: 2)</em></li>
                <li>Human-like systematic generalization through a meta-learning neural network <em>(Rating: 2)</em></li>
                <li>Toward a theoretical understanding of compositional generalization in neural networks <em>(Rating: 2)</em></li>
                <li>Human-level concept learning through probabilistic program induction <em>(Rating: 2)</em></li>
                <li>Model-agnostic meta-learning for fast adaptation of deep networks <em>(Rating: 1)</em></li>
                <li>Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2003",
    "paper_id": "paper-280422475",
    "extraction_schema_id": "extraction-schema-48",
    "extracted_data": [
        {
            "name_short": "Meta-SGD vs SGD on PCFG Boolean concepts",
            "name_full": "Gradient-based Meta-SGD (1st- and 2nd-order) compared to supervised SGD on PCFG-generated Boolean concept classification",
            "brief_description": "This paper evaluates gradient-based meta-learning (Meta-SGD, both first-order and second-order variants, with varying inner-loop adaptation steps) against a supervised SGD baseline on few-shot Boolean concept learning tasks generated by a PCFG that independently varies featural dimensionality and compositional depth.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "5-layer MLP (trained with Meta-SGD or SGD)",
            "model_description": "Fully-connected feedforward MLP with 5 hidden layers, 128 units per layer, ReLU activations, and a sigmoid output; trained end-to-end for few-shot Boolean classification using either Meta-SGD (meta-trained initialization and per-parameter step sizes) or standard SGD/Adam from scratch per task.",
            "model_size": null,
            "is_pretrained": false,
            "architectural_features": "standard MLP (no explicit modularity or symbolic modules); Meta-SGD augments training with learned per-parameter step sizes and second-order/backprop-through-inner-loop when used",
            "task_domain": "logical / Boolean concept learning",
            "task_name": "PCFG Boolean concept classification (custom PCFG generator)",
            "task_description": "Few-shot binary classification of Boolean concepts (logical formulas) over F binary input features; concepts are sampled from a probabilistic context-free grammar (PCFG) that produces literals, negations, conjunctions, and disjunctions. For each sampled concept C, a K-shot support set (positive and negative examples) and a query set are drawn from {0,1}^F; the model must adapt to the sampled concept from few labeled examples and generalize to held-out query examples.",
            "compositional_depth": "D ∈ {3, 5, 7} (explicitly varied recursion depth of PCFG parse trees)",
            "composition_type": "nested logical operations (negation, conjunction, disjunction) — nested / recursive logical composition",
            "split_type": "Unseen-task evaluation: tasks (concepts) sampled from the same PCFG family for meta-evaluation (held-out concepts). OOD-style stress tests performed by systematically increasing feature dimensionality (F) and compositional depth (D); limited out-of-distribution grammar tests noted as future work.",
            "training_strategy": "Gradient-based meta-learning (Meta-SGD: 1st-order and 2nd-order variants) with inner-loop adaptation (K adapt steps = 1 or 10) vs standard supervised training (SGD/Adam from scratch on each task). Meta-training: 10,000 episodes; evaluation averaged over 5 seeds on 1,000 unseen tasks.",
            "curriculum_details": null,
            "inoculation_details": null,
            "iid_performance": null,
            "compositional_performance": "Meta-SGD is highly robust to increased compositional depth (D): moving from D=3 to D=7 yields minimal performance degradation for Meta-SGD while SGD degrades substantially; reported relative improvements of Meta-SGD over SGD in final accuracy: +15.5% (simple concepts), +34.1% (medium concepts), +11.1% (complex concepts). First-order Meta-SGD with more adaptation steps (K=10) often matches or exceeds second-order Meta-SGD, especially at higher featural dimensionality.",
            "generalization_gap": null,
            "performance_by_depth": "Paper reports minimal degradation for Meta-SGD across depths D={3,5,7}; SGD shows substantial drops as D increases. Exact per-depth absolute accuracies not provided in text, only relative descriptions (Meta-SGD stable, SGD degrades).",
            "performance_by_composition_type": "All composition types are logical/nested operations from the PCFG; compositional (deeper recursion) cases are handled well by Meta-SGD (robust), whereas featural complexity (more literals/features) is the primary failure mode. No fine-grained breakdown by specific operators provided.",
            "has_baseline_comparison": true,
            "baseline_comparisons": "Baselines: (1) Vanilla supervised training (SGD/Adam) from scratch per task on the K-shot support set; (2) Meta-SGD first-order (no Hessian/backprop through inner loop) and second-order (full backprop through inner loop) variants, each tested with K=1 and K=10 inner-loop adaptation steps. Findings: Meta-SGD variants learn faster and converge to higher accuracies than SGD for low-to-moderate featural dimensionality (F=8,16). At F=32, most methods collapse; only 1st-order Meta-SGD with K=10 generalized above 60% in the reported experiments.",
            "architectural_comparison": "Architectures held constant (5-layer MLP). Comparisons are algorithmic: 1st-order Meta-SGD vs 2nd-order Meta-SGD vs SGD; also inner-loop adaptation length K=1 vs K=10. Second-order methods outperform in low-featural-complexity settings (F=8), while first-order with extended adaptation (K=10) matches or exceeds second-order in higher-featural regimes (F=16 and F=32).",
            "scale_effects": "Scale here refers to input feature dimensionality F ∈ {8,16,32}. Performance collapses at F=32 for all methods except 1st-order Meta-SGD with K=10 (the only method to exceed 60% in that case). Increasing F dramatically increases loss landscape roughness and difficulty; meta-learning relative gains persist but absolute performance degrades.",
            "transfer_results": null,
            "key_findings": "1) Meta-learning (Meta-SGD) provides substantial compositional generalization advantages: robust to increased compositional depth (D up to 7) while SGD degrades; 2) Featural/dimensional complexity (F) is the dominant failure mode — performance collapses at F=32 for most methods; 3) Inner-loop adaptation length matters: increasing adaptation steps (K=1→K=10) yields larger relative gains as landscape complexity increases (simple: +5–8%; medium: +10–12%; complex: +15–20%); 4) First-order Meta-SGD with more adaptation steps can match/exceed second-order Meta-SGD in high-featural regimes, while curvature-aware second-order updates are advantageous in low-featural (smoother) regimes; 5) Meta-SGD reshapes optimization trajectories (90–99% reduction in trajectory/geodesic length vs SGD) and reduces curvature metrics (Hessian trace reductions: ~92.6% for F=8,D=3; ~95.8% for F=8,D=5; ~88.5% for F=32,D=3), correlating landscape geometry with meta-learning benefit.",
            "failure_analysis": "Primary failure: featural (high-dimensional) complexity creates highly rugged loss landscapes with many local minima (reported averages: simple ~0.3±0.1 minima, medium ~1.2±0.4, complex ~2.8±0.6) and large increases in roughness (simple roughness = 0.0002; medium ~4× increase; complex ~12× increase), causing all methods to suffer and meta-learning to lose absolute performance. The paper attributes meta-learning failures in high-F regimes to exponentially large input spaces (2^F) under data sparsity and resultant rough loss geometry.",
            "success_conditions": "Meta-learning succeeds when complexity arises primarily from compositional (recursive) structure rather than raw feature dimensionality; it benefits from second-order (curvature-aware) updates in smoother/low-dimensional regimes and from increased inner-loop adaptation (K up to 10) in rugged/high-dimensional regimes. Meta-SGD's learned initialization and per-parameter step sizes plus extended adaptation improve navigation of rugged basins and yield better few-shot generalization for compositionally complex concepts.",
            "uuid": "e2003.0"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Meta-learning to compositionally generalize",
            "rating": 2
        },
        {
            "paper_title": "Human-like systematic generalization through a meta-learning neural network",
            "rating": 2
        },
        {
            "paper_title": "Toward a theoretical understanding of compositional generalization in neural networks",
            "rating": 2
        },
        {
            "paper_title": "Human-level concept learning through probabilistic program induction",
            "rating": 2
        },
        {
            "paper_title": "Model-agnostic meta-learning for fast adaptation of deep networks",
            "rating": 1
        },
        {
            "paper_title": "Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks",
            "rating": 1
        }
    ],
    "cost": 0.0096365,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Adapting to High Dimensional Concept Space with Metalearning
9 Sep 2025</p>
<p>Max Gupta mg7411@princeton.edu 
Department of Computer Science
Princeton University</p>
<p>Adapting to High Dimensional Concept Space with Metalearning
9 Sep 202573371889266E30450189B13B0422F209arXiv:2508.01948v2[cs.LG]
Rapidly learning abstract concepts from limited examples is a hallmark of human intelligence.This work investigates whether gradient-based meta-learning can equip neural networks with inductive biases for efficient few-shot acquisition of discrete concepts.I compare meta-learning methods against a supervised learning baseline on Boolean concepts (logical statements) generated by a probabilistic context-free grammar (PCFG).By systematically varying concept dimensionality (number of features) and recursive compositionality (depth of grammar recursion), I delineat between complexity regimes in which meta-learning robustly improves few-shot concept learning and regimes in which it does not.Meta-learners are much better able to handle compositional complexity than featural complexity.I highlight some reasons for this with a representational analysis of the weights of meta-learners and a loss landscape analysis demonstrating how featural complexity increases the roughness of loss trajectories, allowing curvature-aware optimization to be more effective than first-order methods.I find improvements in out-of-distribution generalization on complex concepts by increasing the number of adaptation steps in meta-SGD, where adaptation acts as a way of encouraging exploration of rougher loss basins.Overall, this work highlights the intricacies of learning compositional versus featural complexity in high dimensional concept spaces and provides a road to understanding the role of 2nd order methods and extended gradient adaptation in few-shot concept learning.© .</p>
<p>Introduction</p>
<p>Human learners are able to learn concepts from remarkably little data [10].Early models of concept learning that were able to match human performance leveraged Bayesian inference and symbolic modeling [3,5,14], explaining human performance as an approximation of rational inference.However, these methods often suffered from computational intractability.Recent approaches have combined Bayesian modeling with neural networks through metalearning, allowing models to match Bayesian performance with a fraction of the data [9], thus providing a more plausible mechanism to explain the remarkable sample efficiency of human concept learning.Few approaches have tested the opposite end of the spectrum and explored entirely gradient-based meta-learning methods and effects on sample efficiency and generalization in the concept learning domain.Furthermore, while meta-learning has achieved impressive results across domains including perception, control, and reasoning, existing evaluations often focus on performance within fixed datasets, leaving underexplored how meta-learning behaves as task complexity systematically increases to higher dimensionalities.</p>
<p>In this work, I study the limits of end-to-end, gradient-based meta-learning in a Boolean concept learning task, in a setting that allows precise control over compositional and featural complexity via a probabilistic context free grammar (PCFG).By extending a PCFG-based concept generator developed initially by Goodman et al. 2008 [5], I independently vary featural dimensionality (number of binary input features) and compositional depth (logical recursion) to create a distribution of tasks with increasing structural complexity.This setting enables a study of how out-of-distribution (OOD) generalization from meta-learning scales with the complexity of the underlying concept space.I compare gradient-based meta-learning (Meta-SGD) against standard supervised learning (SGD) on few-shot Boolean classification tasks.Results show that meta-learning is incredibly robust at handling increased compositional recursions, in line with previous work [2,9], but suffers with increased featural dimensionality.To explain this, I show how increasing dimensionality results in an increase in the roughness of the loss landscape of the 'concept basin'.As a potential remedy, I find empirical evidence that increasing the number of adaptation steps can reliably help a meta-learner navigate these rougher loss landscapes, to find generalization-friendly weight initializations.I also present early evidence of how curvature awareness (the second-order gradient term) helps meta-learning effectively navigate different concept complexities by analyzing the Hessian trace of increasingly difficult concept losses.An analysis of loss landscape roughness reveals a strong correlation between landscape curvature and relative gains from meta-learning, proposing a mechanistic account of when and why meta-learning is effective in higher dimensions.</p>
<p>Related Work</p>
<p>Gradient-based meta-learning.MAML [4] introduced a framework for learning model initializations that adapt quickly via gradient descent.Meta-SGD [11] extends this by learning per-parameter step sizes, enabling one-step adaptation.First-order approximations such as FOMAML and Reptile [12] omit Hessian terms to reduce cost, yet their performance often matches full MAML on vision tasks.Theoretical analyses highlight that second-order updates embed an implicit contrastive objective, which can improve generalization on harder tasks [6].</p>
<p>Compositional generalization and concept learning.Symbolic rule induction methods, such as Bayesian Program Learning (BPL) [10] and the Rational Rules model [5], achieve human-level one-shot learning by leveraging explicit grammars.However, they require handcrafted generative models and search.Neural sequence-to-sequence models struggle with systematic generalization on tasks like SCAN [8], and neural meta-learners underperform on benchmarks like CURI [15].Meta-learning has recently been used to improve compositional generalization in NLP [2] and neuro-symbolic reasoning systems [16], but its role in Boolean concept induction remains underexplored.A theoretical framework for compositional generalization in neural networks was recently proposed [1], and surveys highlight the challenges and opportunities for compositional AI [13].Few studies have explicitly engaged in a recursive I study this in a controlled discrete (Boolean) setting to isolate logical structure.</p>
<p>Experimental Setup</p>
<p>The experimental setup starts by modifying the concept-generating PCFG from Goodman et al. 2008 [5] to explicitly control compositionality (recursion depth D ∈ {3, 5, 7}) and feature dimensionality (the number of literals F ∈ {8, 16, 32}).The grammar's production rules and their sampling probabilities are given by :
C → L p = 0.30 C → ¬C p = 0.20 C → (C ∧ C) p = 0.25 C → (C ∨ C) p = 0.25 L → x i , where x i ∈ X = {x 1 , . . . , x F }
For each concept C, I generate a K shot -sized support set S C (with K shot = 5 positive and 5 negative labeled examples (x, C(x))), and a query set Q C , both sampled from the Boolean input space {0, 1} F .</p>
<p>Each meta-learning episode samples a concept C ∼ PCFG(F, D) and creates support/query sets S C , Q C from {0, 1} F (K shot = 10, K qry = 20).Inner-loop adaptation performs K adapt gradient updates:
θ (k+1) = θ (k) − α ⊙ ∇ θ (k) L S C (θ (k)
), yielding θ adapt .The outer-loop updates L meta (C) = L Q C (θ adapt ) and backpropagates through the inner loop to update (θ init , α) with the Adam optimizer [7].</p>
<p>Episodes contain both K-shot training examples (S C ) and held-out evaluation examples (Q C ), ensuring meta-learners are rewarded only for configurations that generalize within tasks.This systematic complexity manipulation enables controlled study of how logical structure affects meta-learning performance.</p>
<p>All methods use a 5-layer MLP (128 hidden units/layer, ReLU, sigmoid output).I compare models trained with three stochastic gradient descent (SGD) learning algorithms, varying the order of the gradients and adaptation steps: 1st-Order and 2nd-Order Meta-SGD with both 1 and 10 adaptation (gradient) steps and regular SGD: training from scratch per task using Adam (learning rate 0.001) on S C .Increasing K adapt allows more extensive search in the task-specific loss landscape, incrementally adjusting the MLP's decision boundaries to correctly classify support set examples.Meta-SGD models were meta-trained for 10,000 episodes.All evaluations were averaged over 5 random seeds on 1,000 unseen tasks (like those shown in Figure 1).For trajectory comparisons, SGD is trained for steps equivalent to processing a fixed total number of samples.Performance is assessed using final mean accuracy (Appendix ??) and data efficiency (samples required to reach 60% accuracy, Appendix A.1).</p>
<p>Results</p>
<p>Figure 2 shows learning trajectories across a sweep of feature dimensionalities (F ) and concept depths (D), averaged for noise over 5 seeds.Meta-SGD methods demonstrate clear advantages over SGD, learning faster and converging to higher accuracies, particularly for F = 8 and F = 16.First-order meta-SGD with increased adaptation steps (K=10) matches or exceeds second-order performance.</p>
<p>Meta-learning demonstrates substantial data efficiency advantages (Appendix A.1), with 1st-order Meta-SGD using K=10 adaptation steps requiring orders of magnitude fewer samples than SGD to reach 60% accuracy, particularly at F = 8, D = 3.</p>
<p>At F = 32, all methods show significant performance drops as featural complexity peaks (bottom row).While second-order methods outperform in low-complexity settings (top row, F = 8), first order methods with added gradient steps outperform in the higher featural dimension settings (middle and bottom rows), suggesting that curvature-awareness is relatively advantageous for simpler concepts only (as we will see in the next section, simpler concepts encode smoother loss landscapes).Even in high-dimensional regimes, increased adaptation (K=10) yields the largest relative improvements, suggesting extensive adaptation becomes crucial when feature space grows.</p>
<p>Loss Landscape Analysis</p>
<p>Representational analysis is but one angle through which to explain the effectiveness of meta-learning.Learned representations are formed as a result of the meta-training process, which involves explicitly calculating second-order gradients at each step of the training process (stochastic gradient descent).In this section, I take a closer look at how the learning process diverges between meta-SGD and SGD over the concept classes tested above by visualizing the loss landscapes during the training process, as opposed to after training has completed (as before).</p>
<p>Methodology</p>
<p>I define roughness as optimization instability: trajectory variation during training.Equation (1) defines a metric of roughness that extracts loss sequences L = [l 1 , l 2 , . . ., l T ], normalized over 200 episodes of training, applies Gaussian smoothing (σ = 1), computes discrete second derivatives ∇ 2 L i = l i+1 −2l i +l i−1 , and calculates:
Roughness = std(∇ 2 L) mean(|∇ 2 L|) + ϵ(1)
where ϵ = 10 −8 prevents division by zero.This normalized measure captures optimization instability, with higher values indicating more erratic training behavior characteristic of rugged loss landscapes, and lower values representing smoother convergence on more navigable terrain.</p>
<p>The goal is to measure how introducing meta-learning (2nd order gradients) changes the loss function across increasingly complex concepts, each define by their own loss landscapes (Figure 3).</p>
<p>Complexity-Dependent Landscape Topology</p>
<p>I analyzed loss landscapes by sampling random directions in parameter space to approximately visualize the optimization challenge posed by each class of boolean concept difficulty.Boolean concept complexity increases roguhness of landscape topology, creating different optimization challenges (Figure 3).3: Meta-SGD and SGD operate on the same concept loss landscapes (determined by task structure and architecture), but meta-learning learns more efficient navigation strategies (shorter paths to the solution point -the bottom-most point in each loss 'basin').Top row: 2D loss landscapes for simple, medium, and complex Boolean concepts show identical topology regardless of optimization method.Middle row: 3D visualizations reveal the terrain both algorithms must navigate, with complexity-dependent roughness.Note: due to computational intractability, loss landscapes are local approximations.</p>
<p>A quantitative analysis reveals systematic patterns: simple concepts (2-3 literals) exhibit smooth, quasiconvex landscapes with few local minima (on average 0.3±0.1,roughness = 0.0002); medium concepts (4-6 literals) show moderately rugged topology (1.2±0.4 minima, 4x roughness increase); complex concepts (7+ literals) display highly rugged landscapes with multiple local minima (2.8±0.6,12x roughness increase).In other words, featural complexity creates characteristic landscape patterns, which map to optimization difficulties -the number and distribution of local minima.This partially explains the failures of meta-SGD to learn featurally dense concepts (</p>
<p>Meta-SGD Learns Shorter Optimization Paths</p>
<p>Our analysis reveals that meta-learning learns efficient navigation strategies for rugged landscapes comparared to vanilla SGD.</p>
<p>As documented in Appendix A, Meta-SGD achieves a 90-99% reduction in trajectory length (the geodesic length) compared to SGD baseline across all concept complexities.This dramatic improvement in navigation efficiency directly translates to performance improvements: +15.5% for simple concepts, +34.1% for medium concepts, and +11.1% for complex concepts.</p>
<p>The largest improvement occurs at medium complexity, where Meta-SGD balances exploration and convergence.Meta-SGD consistently produces trajectories with lower variance in second derivatives, indicating more stable convergence that translates to better performance.Detailed curvature and Hessian trace analysis (see Appendix A.3) confirms that meta-learning learns more efficient pathways through identical loss surfaces, establishing a quantitative framework for predicting meta-learning utility from landscape properties.</p>
<p>Relative use of additional adaptation steps (K=10 vs K=1) scales with concept complexity (see Appendix A.2). Simple concepts show modest 5-8% improvement from K=10 steps, while complex concepts demonstrate 15-20% gains, supporting the intuitive argument that rugged landscapes require multiple steps to escape local minima.</p>
<p>Discussion</p>
<p>Our systematic manipulation of two orthogonal complexity dimensions-featural dimensionality (F ∈ {8, 16, 32}) and compositional depth (D ∈ {3, 5, 7})-reveals fundamentally different challenges for metalearning in Boolean concept acquisition.This controlled experimental design illuminates how different aspects of problem structure interact with optimization landscapes and meta-learning effectiveness.</p>
<p>Compositional Complexity Across all experiments, meta-learning demonstrates remarkable robustness to increasing compositional depth.Moving from D = 3 to D = 7 (simple to deeply nested logical structures) shows minimal performance degradation for Meta-SGD, while SGD suffers substantially.Our loss landscape analysis reveals why: compositional complexity primarily affects the logical structure within concept space but preserves relatively navigable optimization surfaces.The PCFG's recursive depth creates more intricate Boolean relationships without fundamentally altering the smoothness of parameter space traversal.Meta-learning's learned initialization and adaptive step sizes prove particularly effective at discovering these hierarchical patterns within reasonable adaptation budgets.</p>
<p>Featural Complexity In stark contrast, increasing featural dimensionality poses severe challenges for all methods, with performance collapsing dramatically at F = 32.This reveals a deeper truth about the nature of concept learning: while logical complexity (compositionality) can be handled through better optimization strategies, dimensional complexity fundamentally alters the search space structure.The explosion from 2 8 to 2 32 possible input configurations under high data sparsity creates loss landscapes so rugged and high-dimensional that meta-learning alone cannot overcome the curse of dimensionality.Our roughness analysis confirms that featural complexity creates exponentially more challenging optimization terrain than compositional complexity and provides insight for future concept learning work.</p>
<p>Landscape Implications.This dual-axis analysis reveals that not all forms of "complexity" are equivalent from an optimization perspective.Compositional depth affects the logical relationships that must be learned but preserves loss surface properties.The extent to which this is true in higher dimensional setting and with more complex models deserves further investigation.Furthermore, these loss trajectories were randomly sampled in a small, locally convex area of the total loss landscape, but further probing with more compute could reveal more complex topologies than the approximations provided.</p>
<p>These findings suggest that meta-learning is particularly well-suited for domains where complexity arises from structural relationships rather than raw dimensionality, explaining its success in few-shot learning across compositionally rich but feature-constrained domains [6,12].</p>
<p>Future Work</p>
<p>An unanswered and intriguing question in the study of compositionality is how compositional concepts are embedded in the high-dimensional vector space parametrized by the hidden units of a sufficiently deep neural network.In this case, we have already seen that simple MLP's can accurately classify boolean concepts of low to medium compositional depth.I would be very curious to examine the learned representations of the MLP's to explore if any regular structure emerges.Given that the concept space itself is regular and well-defined hierarchically, I would suggest a simple Principal Component Analysis (PCA) on the hidden units of the MLP's trained in the above experiments.In a separate vein of inquiry, the extent to which I tested out of distrbution grammars was very limited -concept length generalization to out-of-distribution grammars would allow us to test the effectiveness and range of the inductive bias endowed by metalearning.</p>
<p>Conclusion</p>
<p>This investigation across featural dimensionality and compositional depth reveals when and why metalearning succeeds in boolean concept acquisition.</p>
<p>Meta-learning exhibits asymmetric robustness across complexity dimensions.While compositional complexity poses minimal challenges for Meta-SGD, featural complexity creates challenging optimization problems.A loss landscape analysis highlights a potential explanation: compositional depth affects logical structure while preserving navigable parameter spaces, whereas featural dimensionality fundamentally transforms loss landscapes, creating "rougher" basins in which second-order methods become relatively more effective than first-order methods.</p>
<p>This dual-axis framework provides both theoretical insight and practical guidance.Meta-learning's strength lies in discovering structural patterns within reasonable dimensional constraints-similar to the regime where human-like few-shot learning excels.These findings suggest that the path toward human-level concept learning requires a hybrid approach: leveraging meta-learning's proven effectiveness for compositional reasoning while developing specialized architectures for high-dimensional feature processing, which could be met with added model complexity not evaluated in this work.Simple concepts show modest 5-8% accuracy improvement from K=10 over K=1 (efficiency ratio 1.4×), medium concepts show substantial 10-12% improvement (efficiency ratio 1.8×), and complex concepts show large 15-20% improvement (efficiency ratio 2.5×).Simple concepts have smooth landscapes navigable with single adaptation steps, while complex concepts have rugged landscapes requiring multiple steps to escape local minima and find better solutions.</p>
<p>A.3. Curvature Analysis</p>
<p>I compute four curvature-related metrics to characterize landscape geometry: roughness (variance of loss gradients along random directions), Hessian trace (tr(H) = i λ i indicating local curvature), spectral norm (∥H∥ 2 = max i |λ i | measuring maximum curvature), and condition number (κ(H) = λ max /λ min quantifying eigenvalue ratios).</p>
<p>There are more systematic patterns in how curvature properties scale with concept complexities.For simple concepts (F8D3), Meta-SGD reduces the Hessian trace by 92.6% compared to SGD (∆tr(H) = −0.926).Medium concepts (F8D5) show 95.8% trace reduction with 50.9% roughness improvement (∆tr(H) = −0.958,∆σ 2 ∇ = −0.509).Complex concepts (F32D3) maintain 88.5% trace reduction despite landscape complexity (∆tr(H) = −0.885).This is a first step towards beginning to explain how meta-SGD finds better solutions by smoothening the geometry of the optimization trajectory (Figure 3), enabling efficient few-shot learning.This connects to recent theoretical work on meta-learning optimization landscapes [6,12].These initial metrics suggest that meta-learning's effectiveness stems from its ability to reduce local curvature (creating smoother gradient flows), improve conditioning (reducing eigenvalue ratios κ(H) for better convergence), and minimize roughness (eliminating sharp local minima that trap gradient descent).This offers a new lens for understanding meta-learning: rather than simply providing better initializations, Meta-SGD actively reshapes the optimization trajectory to enable efficient navigation and adaptation.</p>
<p>Figure 1 :
1
Figure 1: The PCFG parse trees of concepts with increasing complexity.Here compositional depth is visualized as the depth of the parse tree on the vertical axis, feature dimensionality is visualized as the width of the parse tree on the horizontal axis.Examples show how PCFG-generated concepts scale from simple to complex logical structures.Left: Simple concept with 2 features and depth 3. Center: Medium complexity with 3 features and depth 4. Right: Complex concept with 5 features and depth 5. Neural networks see only the bit-string input of features and ideally learn to infer the logical structure of the underlying concept over successive trials.</p>
<p>Figure 2 :
2
Figure 2: First order meta-SGD (blue lines) versus second order meta-SGD (green lines) and vanilla SGD (red line) performance over increasingly complex Boolean concepts.Featural complexity (number of literals) increases along (rows) and concept depths (columns) over normalized training episodes.</p>
<p>Figure</p>
<p>Figure3: Meta-SGD and SGD operate on the same concept loss landscapes (determined by task structure and architecture), but meta-learning learns more efficient navigation strategies (shorter paths to the solution point -the bottom-most point in each loss 'basin').Top row: 2D loss landscapes for simple, medium, and complex Boolean concepts show identical topology regardless of optimization method.Middle row: 3D visualizations reveal the terrain both algorithms must navigate, with complexity-dependent roughness.Note: due to computational intractability, loss landscapes are local approximations.</p>
<p>Figure 5 :
5
Figure 5: K=1 vs K=10 Adaptation Steps Scale with Landscape Complexity.Top:Accuracy improvements from K=1to K=10 scale predictably with landscape complexity, showing modest gains for smooth landscapes but substantial for rough.Bottom: Sample efficiency analysis reveals that additional adaptation steps provide increasingly large benefits as optimization landscapes become rougher.</p>
<p>Appendix A. Appendix A.1. Data EfficiencyThis analysis quantifies the number of training samples required for each method to reach 60% validation accuracy across Boolean concept complexities.Meta-learning methods achieve substantially better sample efficiency than SGD baselines, with 1st-order Meta-SGD with increased adaptation (K=10) consistently demonstrating the highest efficiency, requiring orders of magnitude fewer samples than SGD from scratch.FOr example, while first order Meta-SGD outperforms in high depth settings with a low number of features, second order greatly outperforms when increasing featural complexity.The 32-feature case (bottom panel) has only data for first order Meta-SGD with k=10 steps because it was the only method to generalize to above 60 percent accuracy.The efficiency gains are most pronounced for simpler concept configurations where optimization landscapes remain navigable.For complex concepts (F = 32), while absolute performance degrades for all methods, the relative advantage of meta-learning persists, suggesting that superior navigation strategies provide benefits even in challenging high-dimensional regimes.A.2. Adaptation Steps Scale with Landscape ComplexityA tricky question in meta-learning is how many gradient steps to use during adaptation.Our analysis reveals that the benefit of additional gradient steps (K=10 vs K=1) scales directly with concept complexity.Figure5demonstrates this linear relationship across the spectrum of concept categories I tested above.
Toward a theoretical understanding of compositional generalization in neural networks. Sanjeev Arora, Ying Li, Abhishek Panigrahi, Journal of Machine Learning Research. 2512024</p>
<p>Meta-learning to compositionally generalize. Henry Conklin, Bailin Wang, Kenny Smith, Ivan Titov, 10.18653/v1/2021.acllong.258Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing. Long Papers. the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language ProcessingAssociation for Computational LinguisticsAugust 20211</p>
<p>Minimization of boolean complexity in human concept learning. Jacob Feldman, Nature. 40768042000</p>
<p>Model-agnostic meta-learning for fast adaptation of deep networks. Chelsea Finn, Pieter Abbeel, Sergey Levine, Proceedings of the 34th International Conference on Machine Learning (ICML). the 34th International Conference on Machine Learning (ICML)2017</p>
<p>A rational analysis of rule-based concept learning. Noah D Goodman, Joshua B Tenenbaum, Jacob Feldman, Thomas L Griffiths, Proc. Cognitive Science Society. Cognitive Science Society2008</p>
<p>Maml is a noisy contrastive learner in classification. Chia-Hsiang Kao, Wei-Chen Chiu, Pin-Yu Chen, International Conference on Learning Representations (ICLR). 2022</p>
<p>Adam: A method for stochastic optimization. P Diederik, Jimmy Kingma, Ba, arXivpreprintGarXiv:1412.69802014</p>
<p>Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks. M Brenden, Marco Lake, Baroni, Proceedings of the 35th International Conference on Machine Learning (ICML). the 35th International Conference on Machine Learning (ICML)2018</p>
<p>Human-like systematic generalization through a meta-learning neural network. M Brenden, Marco Lake, Baroni, 10.1038/s41586-023-06668-3Nature. 62379852023</p>
<p>Human-level concept learning through probabilistic program induction. M Brenden, Ruslan Lake, Joshua B Salakhutdinov, Tenenbaum, Science. 35062662015</p>
<p>Meta-sgd: Learning to learn quickly for few-shot learning. Zhenguo Li, Fengwei Zhou, Fei Chen, Hang Li, arXiv:1707.098352017arXiv preprint</p>
<p>On first-order meta-learning algorithms. Alex Nichol, Joshua Achiam, John Schulman, arXiv:1803.029992018arXiv preprint</p>
<p>Compositionality in artificial intelligence: A survey. Yiding Shen, Keith Bonawitz, Michael Lewis, ACM Computing Surveys. 5622024</p>
<p>Generalization, similarity, and bayesian inference. Joshua B Tenenbaum, Thomas L Griffiths, 10.1017/S0140525X01000061Behavioral and Brain Sciences. 2442001</p>
<p>Curi: A benchmark for productive concept learning under uncertainty. Ramakrishna Vedantam, Ari Morcos, arXiv:2301.XXXXX2023arXiv preprint</p>
<p>Nemesys: Neural meta-symbolic synergy for compositional reasoning. Dingding Ye, Bin Zhou, Shih-Chieh Chang, Jian Chen, Advances in Neural Information Processing Systems (NeurIPS). 202235</p>            </div>
        </div>

    </div>
</body>
</html>