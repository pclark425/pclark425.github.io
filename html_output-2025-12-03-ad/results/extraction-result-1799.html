<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1799 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1799</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1799</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-32.html">extraction-schema-32</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of sim-to-real transfer for robotic agents, scientific discovery agents, or laboratory automation systems, including details about simulation fidelity, transfer success, and the conditions that enable or hinder skill transfer from virtual to real environments.</div>
                <p><strong>Paper ID:</strong> paper-33eb00ccc80b3f8a40c0261437b13604069de963</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/33eb00ccc80b3f8a40c0261437b13604069de963" target="_blank">Augmenting Physical Simulators with Stochastic Neural Networks: Case Study of Planar Pushing and Bouncing</a></p>
                <p><strong>Paper Venue:</strong> IEEE/RJS International Conference on Intelligent RObots and Systems</p>
                <p><strong>Paper TL;DR:</strong> This paper builds an efficient, generalizable physical simulator with universal uncertainty estimates for two scenarios, planar pushing and ball bouncing, by augmenting an analytical rigid-body simulator with a neural network that learns to model uncertainty as residuals.</p>
                <p><strong>Paper Abstract:</strong> An efficient, generalizable physical simulator with universal uncertainty estimates has wide applications in robot state estimation, planning, and control. In this paper, we build such a simulator for two scenarios, planar pushing and ball bouncing, by augmenting an analytical rigid-body simulator with a neural network that learns to model uncertainty as residuals. Combining symbolic, deterministic simulators with learnable, stochastic neural nets provides us with expressiveness, efficiency, and generalizability simultaneously. Our model outperforms both purely analytical and purely learned simulators consistently on real, standard benchmarks. Compared with methods that model uncertainty using Gaussian processes, our model runs much faster, generalizes better to new object shapes, and is able to characterize the complex distribution of object trajectories.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1799.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1799.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of sim-to-real transfer for robotic agents, scientific discovery agents, or laboratory automation systems, including details about simulation fidelity, transfer success, and the conditions that enable or hinder skill transfer from virtual to real environments.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hybrid data-augmented residual simulator</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Stochastic Recurrent Data-Augmented Residual Simulator (Decoupled Conditional VRNN + Analytical Physics Engine)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid simulation framework that combines a coarse analytical physics engine (ellipsoidal limit-surface pushing model) with a stochastic recurrent neural residual model (decoupled conditional VRNN) to learn and model residual errors and uncertainty in contact-rich tasks, demonstrated on planar pushing and ball bouncing.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_system_name</strong></td>
                            <td>Pusher-slider planar manipulation system (single-point pusher)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_system_description</strong></td>
                            <td>A robot pusher that executes straight-line pushes on planar objects (rectangular blocks) to move them across a horizontal surface; instrumented in experiments with Vicon markers and force sensing for dataset collection.</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>general robotics manipulation (planar pushing)</td>
                        </tr>
                        <tr>
                            <td><strong>virtual_environment_name</strong></td>
                            <td>Analytical physics engine (ellipsoidal Limit Surface model) + Conditional VRNN; PyBullet used for synthetic bouncing experiments</td>
                        </tr>
                        <tr>
                            <td><strong>virtual_environment_description</strong></td>
                            <td>The analytical physics engine implements a quasistatic ellipsoidal limit-surface pushing model that predicts object motion from pusher motion (stick/slide classification and resulting pose updates). For the illustrative bouncing-ball experiments the PyBullet simulator was used to generate synthetic datasets with configurable restitution.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity_level</strong></td>
                            <td>coarse analytical physics model (approximate contact/limit-surface) augmented with learned stochastic residuals; PyBullet used as medium-fidelity rigid-body simulator for synthetic experiments</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_aspects_modeled</strong></td>
                            <td>Contact classification (sticking vs sliding), quasistatic limit-surface-based frictional wrench→motion mapping (ellipsoidal approximation), pusher kinematics; PyBullet simulated rigid-body collisions and restitution in bouncing experiment.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_aspects_simplified</strong></td>
                            <td>Local contact deformations, micro-surface interactions, spatially varying friction coefficients, anisotropic friction, high-frequency vibrations, exact contact impulse dynamics and non-quasistatic effects were approximated or not modeled; analytic model uses ellipsoidal approximation and fixed parameter choices (e.g., fixed coefficient of restitution in the physics engine for bouncing baseline).</td>
                        </tr>
                        <tr>
                            <td><strong>real_environment_description</strong></td>
                            <td>MIT Push dataset: high-fidelity real-robot repeated straight-line pushes (2,000 repeats) on instrumented objects with Vicon tracking (≈1 mm accuracy), across multiple object shapes and surface materials (ABS, plywood, delrin, polyurethane).</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_skill_transferred</strong></td>
                            <td>Accurate long-horizon prediction of object poses under pushing (planning-relevant belief over outcomes); capturing multimodal uncertainty of push outcomes to inform planning/control.</td>
                        </tr>
                        <tr>
                            <td><strong>training_method</strong></td>
                            <td>Supervised sequence modeling: conditional stochastic recurrent neural network (Decoupled Conditional VRNN / GRU) trained to predict residual corrections to the analytical model using real (or synthetic) trajectory data and maximum-likelihood loss (KL + reconstruction), optimized with ADAM.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success_metric</strong></td>
                            <td>Prediction error metrics on held-out real data: translation error (trans %, relative to initial pose), absolute position error (pos, mm or m), rotation error (rot, degrees), and distributional match via Chamfer distance between sampled outcome clouds and ground-truth repeated-push distribution.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance_sim</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance_real</strong></td>
                            <td>Hybrid test-set metrics (rect1 on ABS): trans 0.60%, pos 2.04 mm, rot 2.03 deg (Hybrid outperforms Physics-only and Neural-only baselines); for materials: plywood pos 2.16 mm, delrin pos 2.09 mm. Distributional Chamfer distance lower than GP-SUM baseline (quantitative value not tabulated in paper body).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sim_to_real_gap_factors</strong></td>
                            <td>Primary factors: deficiencies in contact models (ellipsoidal LS approximations), unmodeled spatial variability in friction coefficients, micro-surface interactions and stick/slip transitions, anisotropic frictional effects, sensitivity to initial conditions, and residual measurement noise; these contribute to simulator/analytic-model vs real-world mismatch.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_enabling_conditions</strong></td>
                            <td>Using an analytical physics model as a structured prior (good initial guess) and learning a stochastic residual model to correct its outputs; training on real repeated-push trajectories with a conditional VRNN that models multimodal outcome distributions; high-quality real data (Vicon) reducing measurement noise focus on dynamics; sample-efficient residual learning (needs fewer examples than full data-driven learning).</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_requirements_identified</strong></td>
                            <td>Contact dynamics fidelity is critical: coarse analytic model must provide a reasonable initial guess (i.e., capture main quasistatic behavior); when the physics model quality degrades, residual-learning generalization suffers. The authors emphasize that modeling contact-related effects (friction variability, stick/slip) is essential for accurate transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuning_in_real_world</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuning_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_fidelity_levels</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>Compared three modeling regimes: Physics-only (analytic), Neural-only (pure data-driven), and Hybrid (analytic + stochastic residuals). Hybrid consistently outperformed both: lower position/rotation errors and better sample efficiency (converges with ~2,500 examples vs Neural requiring more), and produced better distributional matches (lower Chamfer distance vs GP-SUM).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Augmenting a coarse analytical simulator with a stochastic recurrent residual model significantly reduces the sim-to-real gap for contact-rich planar pushing: the hybrid approach is more accurate, captures multimodal uncertainty, generalizes better across shapes and materials, and is more sample-efficient than purely data-driven models; however, the approach depends on the analytic model providing a reasonable initial guess and can predict physically implausible outcomes if insufficiently trained.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Augmenting Physical Simulators with Stochastic Neural Networks: Case Study of Planar Pushing and Bouncing', 'publication_date_yy_mm': '2018-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1799.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1799.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of sim-to-real transfer for robotic agents, scientific discovery agents, or laboratory automation systems, including details about simulation fidelity, transfer success, and the conditions that enable or hinder skill transfer from virtual to real environments.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PyBullet bouncing baseline</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PyBullet synthetic bouncing-ball experiments for illustration of residual learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A synthetic experiment using the PyBullet rigid-body simulator to generate bouncing-ball trajectories with variable restitution, used to illustrate that a physics engine with incorrect fixed restitution can be augmented by a stochastic residual model to better match observed trajectory distributions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_system_name</strong></td>
                            <td>Simulated bouncing ball (no active robot agent)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_system_description</strong></td>
                            <td>A passive object (ball) dropped from randomized heights and restitution coefficients in PyBullet to generate stochastic outcome trajectories (height and vertical velocity) over time; used as a toy problem to illustrate residual learning.</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>robotics physics simulation / dynamical systems illustration</td>
                        </tr>
                        <tr>
                            <td><strong>virtual_environment_name</strong></td>
                            <td>PyBullet</td>
                        </tr>
                        <tr>
                            <td><strong>virtual_environment_description</strong></td>
                            <td>Rigid-body physics simulator modelling collision dynamics and restitution, gravity, and rigid contact; used to synthesize trajectories with stochastic restitution sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity_level</strong></td>
                            <td>medium-fidelity rigid-body simulation (configurable restitutions) but used intentionally mismatched (physics engine fixed restitution vs generated data with variable restitution) to create a controlled sim-to-sim gap.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_aspects_modeled</strong></td>
                            <td>Rigid-body dynamics, gravity, collisions, coefficient of restitution between ball and ground, sampling of initial heights, time-stepped trajectories (60 Hz sampling).</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_aspects_simplified</strong></td>
                            <td>Subtle surface irregularities, microscale deformation, complex contact impulse variability beyond a per-trial restitution parameter were not modeled as continuous stochastic processes; analytical engine for baseline used fixed restitution (0.65) whereas data-generating simulator sampled restitution from N(0.5,0.1).</td>
                        </tr>
                        <tr>
                            <td><strong>real_environment_description</strong></td>
                            <td>Not applicable (synthetic illustration); goal is to study residual learning on simulated data before real experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_skill_transferred</strong></td>
                            <td>Not a skill transfer to real robot; demonstrates ability of residual model to correct a mismatched simulator and to model outcome uncertainty for long-horizon trajectory prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>training_method</strong></td>
                            <td>Supervised training of conditional stochastic recurrent network (DCVRNN) on synthetic trajectories, optimizing log-likelihood with KL regularization (ADAM optimizer).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success_metric</strong></td>
                            <td>Average trajectory errors: translation percent error, absolute position (meters / mm), and velocity error (m/s); compared Neural-only, Physics-only, and Hybrid models on held-out synthetic test set.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance_sim</strong></td>
                            <td>Hybrid model test errors (bouncing): trans 2.42%, pos 0.016 m (16 mm), velocity 0.14 m/s (see Table II).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance_real</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_details</strong></td>
                            <td>No explicit domain randomization; stochasticity introduced in synthetic data generation via sampling restitution and initial heights.</td>
                        </tr>
                        <tr>
                            <td><strong>sim_to_real_gap_factors</strong></td>
                            <td>Illustrated conceptually by intentional mismatch in restitution parameter between data generator and physics-engine baseline; highlights that incorrect fixed physical parameters (restitution) cause significant predictive error.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_enabling_conditions</strong></td>
                            <td>Providing a physics engine that captures core dynamics (even with mismatched parameters) plus a learned stochastic residual yields improved long-horizon prediction accuracy over physics-only or neural-only approaches in the illustrative setting.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_requirements_identified</strong></td>
                            <td>Even modest simulator inaccuracies (e.g., incorrect restitution) can be compensated by learning residuals; however, accurate modeling of dominant physical parameters (e.g., restitution distribution) improves baseline predictions and simplifies residual learning.</td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuning_in_real_world</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuning_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_fidelity_levels</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>Hybrid < Neural < Physics in performance on the synthetic bouncing task (Hybrid lowest error); quantitative results: Hybrid pos 0.016 m vs Neural 0.058 m vs Physics 0.16 m (see Table II).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Residual learning can correct systematic simulator parameter mismatches and produce accurate, uncertainty-aware long-horizon trajectories in contact-rich dynamics even when the underlying physics engine has simplified or incorrect parameters; this supports the hybrid approach as a means to reduce sim-to-real (or sim-to-target) gaps.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Augmenting Physical Simulators with Stochastic Neural Networks: Case Study of Planar Pushing and Bouncing', 'publication_date_yy_mm': '2018-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>More than a million ways to be pushed. a high-fidelity experimental dataset of planar pushing <em>(Rating: 2)</em></li>
                <li>Fundamental limitations in performance and interpretability of common planar rigid-body contact models <em>(Rating: 2)</em></li>
                <li>Learning data-efficient rigid-body contact models: Case study of planar impact <em>(Rating: 2)</em></li>
                <li>GP-SUM. gaussian processes filtering of non-gaussian beliefs <em>(Rating: 2)</em></li>
                <li>A fast stochastic contact model for planar pushing and grasping: Theory and experimental validation <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1799",
    "paper_id": "paper-33eb00ccc80b3f8a40c0261437b13604069de963",
    "extraction_schema_id": "extraction-schema-32",
    "extracted_data": [
        {
            "name_short": "Hybrid data-augmented residual simulator",
            "name_full": "Stochastic Recurrent Data-Augmented Residual Simulator (Decoupled Conditional VRNN + Analytical Physics Engine)",
            "brief_description": "A hybrid simulation framework that combines a coarse analytical physics engine (ellipsoidal limit-surface pushing model) with a stochastic recurrent neural residual model (decoupled conditional VRNN) to learn and model residual errors and uncertainty in contact-rich tasks, demonstrated on planar pushing and ball bouncing.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_system_name": "Pusher-slider planar manipulation system (single-point pusher)",
            "agent_system_description": "A robot pusher that executes straight-line pushes on planar objects (rectangular blocks) to move them across a horizontal surface; instrumented in experiments with Vicon markers and force sensing for dataset collection.",
            "domain": "general robotics manipulation (planar pushing)",
            "virtual_environment_name": "Analytical physics engine (ellipsoidal Limit Surface model) + Conditional VRNN; PyBullet used for synthetic bouncing experiments",
            "virtual_environment_description": "The analytical physics engine implements a quasistatic ellipsoidal limit-surface pushing model that predicts object motion from pusher motion (stick/slide classification and resulting pose updates). For the illustrative bouncing-ball experiments the PyBullet simulator was used to generate synthetic datasets with configurable restitution.",
            "simulation_fidelity_level": "coarse analytical physics model (approximate contact/limit-surface) augmented with learned stochastic residuals; PyBullet used as medium-fidelity rigid-body simulator for synthetic experiments",
            "fidelity_aspects_modeled": "Contact classification (sticking vs sliding), quasistatic limit-surface-based frictional wrench→motion mapping (ellipsoidal approximation), pusher kinematics; PyBullet simulated rigid-body collisions and restitution in bouncing experiment.",
            "fidelity_aspects_simplified": "Local contact deformations, micro-surface interactions, spatially varying friction coefficients, anisotropic friction, high-frequency vibrations, exact contact impulse dynamics and non-quasistatic effects were approximated or not modeled; analytic model uses ellipsoidal approximation and fixed parameter choices (e.g., fixed coefficient of restitution in the physics engine for bouncing baseline).",
            "real_environment_description": "MIT Push dataset: high-fidelity real-robot repeated straight-line pushes (2,000 repeats) on instrumented objects with Vicon tracking (≈1 mm accuracy), across multiple object shapes and surface materials (ABS, plywood, delrin, polyurethane).",
            "task_or_skill_transferred": "Accurate long-horizon prediction of object poses under pushing (planning-relevant belief over outcomes); capturing multimodal uncertainty of push outcomes to inform planning/control.",
            "training_method": "Supervised sequence modeling: conditional stochastic recurrent neural network (Decoupled Conditional VRNN / GRU) trained to predict residual corrections to the analytical model using real (or synthetic) trajectory data and maximum-likelihood loss (KL + reconstruction), optimized with ADAM.",
            "transfer_success_metric": "Prediction error metrics on held-out real data: translation error (trans %, relative to initial pose), absolute position error (pos, mm or m), rotation error (rot, degrees), and distributional match via Chamfer distance between sampled outcome clouds and ground-truth repeated-push distribution.",
            "transfer_performance_sim": null,
            "transfer_performance_real": "Hybrid test-set metrics (rect1 on ABS): trans 0.60%, pos 2.04 mm, rot 2.03 deg (Hybrid outperforms Physics-only and Neural-only baselines); for materials: plywood pos 2.16 mm, delrin pos 2.09 mm. Distributional Chamfer distance lower than GP-SUM baseline (quantitative value not tabulated in paper body).",
            "transfer_success": true,
            "domain_randomization_used": false,
            "domain_randomization_details": null,
            "sim_to_real_gap_factors": "Primary factors: deficiencies in contact models (ellipsoidal LS approximations), unmodeled spatial variability in friction coefficients, micro-surface interactions and stick/slip transitions, anisotropic frictional effects, sensitivity to initial conditions, and residual measurement noise; these contribute to simulator/analytic-model vs real-world mismatch.",
            "transfer_enabling_conditions": "Using an analytical physics model as a structured prior (good initial guess) and learning a stochastic residual model to correct its outputs; training on real repeated-push trajectories with a conditional VRNN that models multimodal outcome distributions; high-quality real data (Vicon) reducing measurement noise focus on dynamics; sample-efficient residual learning (needs fewer examples than full data-driven learning).",
            "fidelity_requirements_identified": "Contact dynamics fidelity is critical: coarse analytic model must provide a reasonable initial guess (i.e., capture main quasistatic behavior); when the physics model quality degrades, residual-learning generalization suffers. The authors emphasize that modeling contact-related effects (friction variability, stick/slip) is essential for accurate transfer.",
            "fine_tuning_in_real_world": null,
            "fine_tuning_details": null,
            "comparison_across_fidelity_levels": true,
            "fidelity_comparison_results": "Compared three modeling regimes: Physics-only (analytic), Neural-only (pure data-driven), and Hybrid (analytic + stochastic residuals). Hybrid consistently outperformed both: lower position/rotation errors and better sample efficiency (converges with ~2,500 examples vs Neural requiring more), and produced better distributional matches (lower Chamfer distance vs GP-SUM).",
            "key_findings": "Augmenting a coarse analytical simulator with a stochastic recurrent residual model significantly reduces the sim-to-real gap for contact-rich planar pushing: the hybrid approach is more accurate, captures multimodal uncertainty, generalizes better across shapes and materials, and is more sample-efficient than purely data-driven models; however, the approach depends on the analytic model providing a reasonable initial guess and can predict physically implausible outcomes if insufficiently trained.",
            "uuid": "e1799.0",
            "source_info": {
                "paper_title": "Augmenting Physical Simulators with Stochastic Neural Networks: Case Study of Planar Pushing and Bouncing",
                "publication_date_yy_mm": "2018-08"
            }
        },
        {
            "name_short": "PyBullet bouncing baseline",
            "name_full": "PyBullet synthetic bouncing-ball experiments for illustration of residual learning",
            "brief_description": "A synthetic experiment using the PyBullet rigid-body simulator to generate bouncing-ball trajectories with variable restitution, used to illustrate that a physics engine with incorrect fixed restitution can be augmented by a stochastic residual model to better match observed trajectory distributions.",
            "citation_title": "",
            "mention_or_use": "use",
            "agent_system_name": "Simulated bouncing ball (no active robot agent)",
            "agent_system_description": "A passive object (ball) dropped from randomized heights and restitution coefficients in PyBullet to generate stochastic outcome trajectories (height and vertical velocity) over time; used as a toy problem to illustrate residual learning.",
            "domain": "robotics physics simulation / dynamical systems illustration",
            "virtual_environment_name": "PyBullet",
            "virtual_environment_description": "Rigid-body physics simulator modelling collision dynamics and restitution, gravity, and rigid contact; used to synthesize trajectories with stochastic restitution sampling.",
            "simulation_fidelity_level": "medium-fidelity rigid-body simulation (configurable restitutions) but used intentionally mismatched (physics engine fixed restitution vs generated data with variable restitution) to create a controlled sim-to-sim gap.",
            "fidelity_aspects_modeled": "Rigid-body dynamics, gravity, collisions, coefficient of restitution between ball and ground, sampling of initial heights, time-stepped trajectories (60 Hz sampling).",
            "fidelity_aspects_simplified": "Subtle surface irregularities, microscale deformation, complex contact impulse variability beyond a per-trial restitution parameter were not modeled as continuous stochastic processes; analytical engine for baseline used fixed restitution (0.65) whereas data-generating simulator sampled restitution from N(0.5,0.1).",
            "real_environment_description": "Not applicable (synthetic illustration); goal is to study residual learning on simulated data before real experiments.",
            "task_or_skill_transferred": "Not a skill transfer to real robot; demonstrates ability of residual model to correct a mismatched simulator and to model outcome uncertainty for long-horizon trajectory prediction.",
            "training_method": "Supervised training of conditional stochastic recurrent network (DCVRNN) on synthetic trajectories, optimizing log-likelihood with KL regularization (ADAM optimizer).",
            "transfer_success_metric": "Average trajectory errors: translation percent error, absolute position (meters / mm), and velocity error (m/s); compared Neural-only, Physics-only, and Hybrid models on held-out synthetic test set.",
            "transfer_performance_sim": "Hybrid model test errors (bouncing): trans 2.42%, pos 0.016 m (16 mm), velocity 0.14 m/s (see Table II).",
            "transfer_performance_real": null,
            "transfer_success": null,
            "domain_randomization_used": false,
            "domain_randomization_details": "No explicit domain randomization; stochasticity introduced in synthetic data generation via sampling restitution and initial heights.",
            "sim_to_real_gap_factors": "Illustrated conceptually by intentional mismatch in restitution parameter between data generator and physics-engine baseline; highlights that incorrect fixed physical parameters (restitution) cause significant predictive error.",
            "transfer_enabling_conditions": "Providing a physics engine that captures core dynamics (even with mismatched parameters) plus a learned stochastic residual yields improved long-horizon prediction accuracy over physics-only or neural-only approaches in the illustrative setting.",
            "fidelity_requirements_identified": "Even modest simulator inaccuracies (e.g., incorrect restitution) can be compensated by learning residuals; however, accurate modeling of dominant physical parameters (e.g., restitution distribution) improves baseline predictions and simplifies residual learning.",
            "fine_tuning_in_real_world": false,
            "fine_tuning_details": null,
            "comparison_across_fidelity_levels": true,
            "fidelity_comparison_results": "Hybrid &lt; Neural &lt; Physics in performance on the synthetic bouncing task (Hybrid lowest error); quantitative results: Hybrid pos 0.016 m vs Neural 0.058 m vs Physics 0.16 m (see Table II).",
            "key_findings": "Residual learning can correct systematic simulator parameter mismatches and produce accurate, uncertainty-aware long-horizon trajectories in contact-rich dynamics even when the underlying physics engine has simplified or incorrect parameters; this supports the hybrid approach as a means to reduce sim-to-real (or sim-to-target) gaps.",
            "uuid": "e1799.1",
            "source_info": {
                "paper_title": "Augmenting Physical Simulators with Stochastic Neural Networks: Case Study of Planar Pushing and Bouncing",
                "publication_date_yy_mm": "2018-08"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "More than a million ways to be pushed. a high-fidelity experimental dataset of planar pushing",
            "rating": 2
        },
        {
            "paper_title": "Fundamental limitations in performance and interpretability of common planar rigid-body contact models",
            "rating": 2
        },
        {
            "paper_title": "Learning data-efficient rigid-body contact models: Case study of planar impact",
            "rating": 2
        },
        {
            "paper_title": "GP-SUM. gaussian processes filtering of non-gaussian beliefs",
            "rating": 2
        },
        {
            "paper_title": "A fast stochastic contact model for planar pushing and grasping: Theory and experimental validation",
            "rating": 1
        }
    ],
    "cost": 0.01180275,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>MIT <br> Libraries</h1>
<h2>DSpace@MIT</h2>
<h2>MIT Open Access Articles</h2>
<h2>Augmenting Physical Simulators with Stochastic Neural Networks: Case Study of Planar Pushing and Bouncing</h2>
<p>The MIT Faculty has made this article openly available. Please share how this access benefits you. Your story matters.</p>
<p>Citation: Ajay, Anurag, Wu, Jiajun, Fazeli, Nima, Bauza, Maria, Kaelbling, Leslie P. et al. 2018. "Augmenting Physical Simulators with Stochastic Neural Networks: Case Study of Planar Pushing and Bouncing."</p>
<p>As Published: 10.1109/iros.2018.8593995
Publisher: IEEE
Persistent URL: https://hdl.handle.net/1721.1/137711
Version: Author's final manuscript: final author's manuscript post peer review, without publisher's formatting or copy editing</p>
<p>Terms of use: Creative Commons Attribution-Noncommercial-Share Alike</p>
<h1>Augmenting Physical Simulators with Stochastic Neural Networks: Case Study of Planar Pushing and Bouncing</h1>
<p>Anurag Ajay ${ }^{1}$, Jiajun $\mathrm{Wu}^{1}$, Nima Fazeli ${ }^{2}$, Maria Bauza ${ }^{2}$, Leslie P. Kaelbling ${ }^{1}$, Joshua B. Tenenbaum ${ }^{1}$, Alberto Rodriguez ${ }^{2}$</p>
<h4>Abstract</h4>
<p>An efficient, generalizable physical simulator with universal uncertainty estimates has wide applications in robot state estimation, planning, and control. In this paper, we build such a simulator for two scenarios, planar pushing and ball bouncing, by augmenting an analytical rigid-body simulator with a neural network that learns to model uncertainty as residuals. Combining symbolic, deterministic simulators with learnable, stochastic neural nets provides us with expressiveness, efficiency, and generalizability simultaneously. Our model outperforms both purely analytical and purely learned simulators consistently on real, standard benchmarks. Compared with methods that model uncertainty using Gaussian processes, our model runs much faster, generalizes better to new object shapes, and is able to characterize the complex distribution of object trajectories.</p>
<h2>I. INTRODUCTION</h2>
<p>Simulators are an essential for the development of robot systems. An important class of systems in robotics is well approximated by rigid-body dynamics; relatively mature, fast, and general-purpose simulators have been developed for these systems. These simulators (e.g., ODE [1], Bullet [2], MuJoco [3]) rely on approximate and efficient dynamics models and do not reason about uncertainty explicitly.</p>
<p>These simulators are an important tool, yet their practicality has been limited due to discrepancies between their predictions and real-world observations. A major source of mismatches is the contact models used in these simulators. Contact is a complex physical interaction with near impulsive forces over a small duration of time that involves local deformations and vibrations. Matters are complicated by the sensitivity of contact outcomes to initial conditions. These models are coarse approximations to contact, and recent studies ([4], [5], [6]) have shown the discrepancies between their predictions and real-world data. Further, Fazeli et al. [6] showed that there exist real-world contact outcomes which the models are unable to predict for any choice of their parameters. This suggests that generating uncertainty by defining distributions over contact parameters does not yield a sufficiently rich and descriptive distribution over outcomes.</p>
<p>In this study, we provide a framework for augmenting analytical motion models with empirical data that has higher accuracy while capturing uncertainty in predictions. We achieve this by using a novel type of recurrent neural networks,</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Fig. 1: The motion of an object being pushed appears stochastic and possibly multi-modal due to imperfections in contact surfaces, non-uniform coefficient of friction, stick/slip transitions, and micro surface interactions. In this study, we propose to augment analytical models to more accurately predict such outcomes while reasoning about uncertainty.
namely decoupled conditional variational recurrent neural nets, to learn the residual errors made by the analytical models. Once the neural networks are trained, they can correct model predictions and provide distributions over possible outcomes.</p>
<p>We demonstrate the efficacy of the data-augmented stochastic simulation framework in two cases: 1) a toy bouncing ball problem, and 2) planar pushing with a single point pusher using the empirical dataset from Yu et al. [5]. First, we use the toy problem to illustrate the implementation and details of the proposed model in simulation. We then move to the experimental planar pushing dataset to demonstrate the ability of the approaches to capture real-world data. We show that the data-augmented model outperforms its purely analytical and purely data-driven counterparts. Further, we demonstrate that this approach is data-efficient, as learning residuals is an easier and better formulated problem than learning full motion models. Experiments also suggest that the learned residual model generalizes better to different shapes than the pure learning-based dynamics model. The data-augmented residual model can reason about uncertainty, which plays an important role in planning and control.</p>
<h2>II. Related Work</h2>
<h2>A. Models for Planar Pushing</h2>
<p>Planar pushing is an important instance of planar manipulation, in which the robot moves objects on a horizontal surface through a set of pushes, in particular for objects that are too heavy or too large to be picked up by the robot. To model planar pushing, Goyal et al. [7] proposed the notion of "Limit Surfaces" (LS) as an invertible mapping between</p>
<p>a push and a consistent set of friction forces and object motions. Given the object’s current pose and force applied to it, the LS predicts the subsequent motion assuming quasistatic motion. The LS assumes a pressure distribution over the contact patch and Coloumb friction law; it integrates over all possible instantaneous centers of rotation for the object to yield the mapping.</p>
<p>In general, the LS does not have a closed form solution; however, Howe and Cutkosky [8] showed that the LS can be approximated by an ellipsoid for uniform pressure distributions, constant friction coefficient, and quasi-static motions. Lynch et al. [9] used the ellipsoidal LS to develop a motion model to predict object motion given pusher motion. The ellipsoidal LS has been used for planar push control by Hogan and Rodriguez [10] and for shape reconstruction by Yu et al. [11]. In this study we also use the model proposed by Lynch et al. [9] as our analytical motion model.</p>
<h2>B. Learning Contact Dynamics</h2>
<p>Recently, researchers have looked towards data-driven techniques to complement existing analytical models and/or learn dynamics directly from data. The work by Kloss et al. [12] is the closest to ours, where the authors trained a neural network that provides input to an analytical model. In this framework, the output of the analytical model is used as the prediction; the neural network learns the best input parameters to maximize the performance of the analytical model. A benefit of this approach is that the model predictions are always feasible because of the analytical model, but the approach is deterministic, and relies on the expressiveness of the analytical model.</p>
<p>In the planar pushing case, these models may be sufficiently expressive to span the full range of outcomes, but this is not always the case in other contact interactions as shown by Fazeli et al. [6]. Further, the models in [12] only make singlestep predictions—an approach that may not work well for long-horizon predictions due to compounding errors at each time step. In our paper, we use the analytical model as an approximation to the push outcomes, and learn a residual model that makes corrections to its output. We are thus not limited by the model’s expressivity, as the neural network can make corrections outside the predictive range of the models. Further, we learn a stochastic recurrent network that makes long-horizon predictions in the form of a distribution over possible outcomes. We believe reasoning about the degree of confidence in outcome prediction can be used effectively in planning and control.</p>
<p>Fazeli et al. [13] also proposed to learn a residual model for prediction of empirical planar impacts. The residual learner in their paper is a Gaussian process and achieves significant improvement over the analytical contact models in terms of its prediction accuracy. Gaussian processes are however limited to Gaussian predictive distributions and are computationally slower, compared with neural networks. Further, the authors also did not study the effect of making long-term predictions, as their focus is on individual impact prediction accuracy. Zhou et al. [14] supplied a data-efficient approach to model the frictional interaction between an object and a support surface, by directly approximating the mapping between frictional wrench and slipping twist. Later, Zhou et al. [15] extended the model to simulate parametric variability in planar pushing and grasping.</p>
<p>Byravan and Fox [16] showed how to design a neural network to predict rigid-body motions in a planar pushing scenario. In this study, as a robot pushes an object, the neural network differentiates between the object and the table. The neural network makes predictions by explicitly predicting $S E(3)$ transformations and jointly learning the full motion model and the observation model. This approach is still deterministic and does not use any more physics knowledge.</p>
<h2>C. Uncertainty Modeling</h2>
<p>Reasoning about the uncertainty in actions and motions is a powerful tool in planning and control [17], [18], [19], [20]. In the context of planar manipulation, Bauza and Rodriguez [20] used Gaussian processes to learn the motion model of planar shapes and to propagate uncertainty using the GP-SUM algorithm. The GP-SUM algorithm is a hybrid Bayes and particle filter; it exploits the Gaussian structure of the motion model to efficiently approximate the distribution over outcomes as a mixture of Gaussians. Bauza and Rodriguez [20] showed that pushing can exhibit multimodality and their approach is able to capture it. We use the model and algorithm from [20] as benchmarks for our approach and compare the two on the MIT push dataset [5].</p>
<p>A practical example of using the knowledge of uncertainty in planar manipulation was introduced by Zhou et al. [21]. They proposed a probabilistic algorithm that generates sequential actions to iteratively reduce uncertainty of objects in the plane, before grasping it with a parallel jaw gripper.</p>
<h2>III. FORMULATION</h2>
<p>In this section we provide the details of our proposed dataaugmented stochastic simulation framework. The simulation framework has two components: an analytical model and a data-driven residual model. We first define each component; we then provide a detailed exposition of the data-driven residual model and its role as a method to improve simulation accuracy and to maintain a belief over states.</p>
<p>Let $S$ represent the state space, $A$ represent the action space, and $(s, a, s^{\prime})$ represent a state-action-state tuple, where $s, s^{\prime} \in S, a \in A$, and $s^{\prime}$ is the state obtained after applying action $a$ in state $s$. A dynamics model is a function $f$ : $S \times A \rightarrow S$ that predicts the next state given the current action and state: $f(s, a) \approx s^{\prime}, s, s^{\prime} \in S, a \in A$.</p>
<p>We distinguish between two classes of dynamic models: physics-based analytical models and data-driven models.</p>
<h2>A. Physics-Based Analytical Models</h2>
<p>These models are constructed from the laws of physics, domain knowledge, and convenient approximations often made for mathematical tractability. In this paper, we also refer to them as Physics Engines and use the terms interchangeably, though in practice physics engines may not be faithfully implementing the mathematical models. Generally, these</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Fig. 2: Model classes: (a) physics-based analytical models; (b) data-driven models; (c) data-augmented residual models; (d) recurrent data-augmented residual models; and (e) stochastic recurrent data-augmented residual models.</p>
<p>models work well close to their assumptions and in structured environments, but their performance degrades as we move away from their nominal working conditions. Further, finding tractable models for complex tasks is difficult and requires extensive domain specific expertise. For the rest of this paper, let $f_p : S \times A \rightarrow S$ represent the analytical model.</p>
<h3><em>B. Data-Driven Models</em></h3>
<p>Rather than being hand engineered, these models are learned using data collected from the real world. They can be either parametric (<em>e.g.</em>, neural networks) or non-parametric (<em>e.g.</em>, Gaussian processes). For the purpose of discussion, let's assume a parametric model represented by $f_\theta : S \times A \rightarrow S$, where $\theta$ is the parameter vector. The model is learned using data collected from the real world; for example, the robot may take actions according to a fixed pushing policy and collect $(s, a, s')$ tuples that represent the states of the object being pushed and the motion of the pusher. After collecting data ${(s_t, a_t, s_{t+1})}_{t=0}^{T-1}$, we solve the following optimization problem to obtain optimal parameters for the model:</p>
<p>$$
\theta^* = \arg\min_{\theta} \sum_{t=0}^{T-1} |f_\theta(s_t, a_t) - s_{t+1} |<em 2="2">2^2 + \lambda | \theta |</em> \qquad (1)
$$}^{2</p>
<p>where $\lambda$ is a constant for regularization. After obtaining $\theta^*$, we use $f_\theta^+$ as the representation of our motion model. While this approach requires no hand-engineering and directly learns from the data without making any assumptions, it does not make use of any domain knowledge, and consequently may require many examples to learn.</p>
<h3><em>C. Data-Augmented Residual Models</em></h3>
<p>We leverage advantages of both model classes and develop a new hybrid class of models, which we call <em>data-augmented residual models</em>, by combining a physics engine with a data-driven model. In this modeling framework, the data-driven part of the model takes the current state-action pairs and the predictions made by the physics engine as input, and effectively learns the discrepancy between analytical model predictions and real-world data (<em>i.e.</em> the residual). If $f_r$ represents the data-augmented residual model, $f_p$ represents its physics engine, and $f_\theta$ represents its residual component, we have $f_r(s, a) = f_\theta(f_p(s, a), s, a) \approx s'$. Intuitively, the residual model refines the physics engine's guess using the current state and action.</p>
<h3><em>D. Recurrent Data-Augmented Residual Models</em></h3>
<p>Planning and control require long-horizon predictions of future states of the world, given actions taken by an agent using dynamic models. No matter how accurate the model is, it will have some error which will compound over a sequence of time steps. Moreover, the data-driven and data-augmented models are trained using data from real world trajectories. While simulating the future, these dynamics models will recursively use their own prediction as input for the next time step. As there will be error in their predictions at each time step, the input data given during simulation phase will have a different distribution than the input data during the training phase. This creates data distribution mismatch between training and test (or simulation) phases for both data-augmented residual models and purely data-driven models.</p>
<p>To address this problem, we propose to use a recurrent data-augmented residual model, trained to predict the entire trajectory based on an initial state and an action sequence. The <em>recurrent data-augmented residual model</em> consists of two components: a physics engine and a recurrent data-augmented residual model. The physics engine takes in the initial state and a sequence of actions at every time step; it generates an entire trajectory which serves as a good initial guess for the recurrent residual model. The residual model takes the initial state, a sequence of actions, and the trajectory predicted by the physics engine; it then predicts the next state. If $f_r^R$ represents the data-augmented recurrent residual model, $f_p$ represents its physics engine, and $f_\theta^R$ represents its residual component, we have</p>
<p>$$
\begin{gathered}
f_r^R(\bar{s}<em>t, \bar{s}_t, a_t) = f</em>\theta^R(f_p(\bar{s}<em t_1="t+1">t, a_t), \bar{s}_t, a_t) = \bar{s}</em>, \
f_p(\bar{s}} \approx s_{t+1<em t_1="t+1">t, a_t) = \bar{s}</em>_0 = s_0,
\end{gathered} \tag{2}
$$}, \quad \bar{s}_0 = \bar{s</p>
<p>where $(\bar{s}<em t="0">t)</em>}^{T-1}$ is the predicted trajectory. The model is fully differentiable and can be trained by minimizing $\min_\theta \sum_{t=0}^{T-1} | \bar{s<em 2="2">t - s_t |</em>$.}^{2} + \lambda | \theta |_{2}^{2</p>
<h3><em>E. Stochastic Recurrent Data-Augmented Residual Models</em></h3>
<p>No model is perfect, therefore the ability to provide a measure of uncertainty over possible future states is an</p>
<p>important capability, allowing better informed planning and control. To this end, we formulate a stochastic model. Let $f_{r}^{R}$ represents stochastic data-augmented recurrent residual model, we have</p>
<p>$f_{r}^{R}(\bar{s}<em t="t">{t},\hat{s}</em>},a_{t})=f_{\theta}^{R}(f_{p}(\bar{s<em t="t">{t},a</em>}),\hat{s<em t="t">{t},a</em>})=\hat{P<em t_1="t+1">{s</em>(\cdot),$ (4)
$f_{p}(\bar{s}}<em t="t">{t},a</em>})=\bar{s<em 0="0">{t+1}, \quad \bar{s}</em>}=\hat{s<em 0="0">{0}=s</em>,$ (5)</p>
<p>where ${\hat{P}<em t="t">{s</em>(\cdot)}}<em _theta="\theta">{t=0}^{T-1}$ is the predicted trajectory distribution. The model is also differentiable and can be trained by minimizing $\min </em>} \sum_{t=0}^{T-1} \log \hat{P<em t="t">{s</em>$.}}\left(s_{t} \mid \theta\right)+\lambda|\theta|_{2}^{2</p>
<h2>IV. METHODS</h2>
<p>We now present how we realize the stochastic recurrent data-augmented residual model by providing an overview of the components and the way they are connected.</p>
<h2>A. The Analytical Push Motion Model</h2>
<p>As mentioned in Sec. II, we use the model proposed in [9] as our analytical pushing motion model (physics engine). The motion model takes the current configuration of the object and the pusher motion, and returns the predicted object motion at each time step. To make predictions, the motion model first computes a motion cone for the current pusher velocity and object configuration. Next, depending on whether the pusher velocity lies inside or outside of the cone, the model identifies the contact as sticking or sliding respectively. Finally the model computes the object motion using the sticking/sliding classification and the ellipsoidal LS.</p>
<p>In the experimental setup of the planar push dataset [5], the time history of object and robot pusher motion are recorded. We can compute the analytical model predictions using the current configuration of the object and robot pusher motion. In doing this, we observe discrepancies between the model prediction and the measured data. The discrepancy is due in part to the ellipsoidal approximation, and in part to variations in coefficients of friction across the surface, micro-interactions between the object and surface, and potentially anisotropic frictional properties. The latter effects are impractical to model analytically and difficult to predict ahead of time.</p>
<h2>B. Stochastic Neural Networks</h2>
<p>We implement our recurrent data-augmented residual model as a GRU [22], a widely used recurrent network for modeling long-term correlations. The model is however deterministic. The simplest way to incorporate stochasticity is to model $P_{s_{t}}(.)$ in Eqn. 4 as a Gaussian distribution, i.e., $\hat{P}<em t="t">{s</em>}}(.)=$ $\mathcal{N}\left(\hat{\mu<em t="t">{s</em>}}, \hat{\sigma<em t="t">{s</em>\right)$. However, this limits our model's ability to characterize complex distributions in real world.}</p>
<p>Chung et al. [23] proposed to incorporate variational autoencoders [24] into recurrent nets and named their model variational RNNs (VRNNs). A VRNN supports modeling highly complex distributions over time. Their model however cannot be conditioned on additional inputs such as control variables (e.g. push forces). We instead embed a conditional variational autoencoder into our GRU. It therefore becomes a variant of VRNNs, namely Conditional VRNNs.</p>
<p>1) Variational Recurrent Neural Networks: VRNNs are recurrent generative models used for modeling multi-modal trajectories. It has three interconnected components: priors, an encoder, and a decoder. Suppose we represent a given trajectory as $\left{x_{t}\right}<em t="t">{t=0}^{T}$. During training, the encoder takes the trajectory as input and infers latent random variables $\left{z</em>\right}$ as</p>
<p>$$
\begin{aligned}
P\left(z_{t} \mid x_{t}\right) &amp; \sim \mathcal{N}\left(\mu_{z, t}, \sigma_{z, t}\right) \
\left[\mu_{z, t}, \sigma_{z, t}\right] &amp; =\varphi^{\mathrm{enc}}\left(\varphi^{x}\left(x_{t}\right), h_{t-1}\right)
\end{aligned}
$$</p>
<p>where $\varphi^{\text {enc }}$ represents the encoder, $\varphi^{x}$ is a function that extracts features of $x_{t}$, and $h$ is the hidden vector in the GRU. We then sample the latent random variable from the above distribution using a reparameterization trick [24], formulated as $z_{t}=\mu_{z, t}+\epsilon_{t} \times \sigma_{z, t}, \quad \epsilon_{t} \sim \mathcal{N}(0, I)$. After that, the decoder uses the sampled latent variable $z_{t}$ to reconstruct the trajectory, following $P\left(x_{t} \mid z_{t}\right) \sim \mathcal{N}\left(\mu_{x, t}, \sigma_{x, t}\right)$, where</p>
<p>$$
\left[\mu_{x, t}, \sigma_{x, t}\right]=\varphi^{\mathrm{dec}}\left(\varphi^{z}\left(z_{t}\right), h_{t-1}\right)
$$</p>
<p>Here, $\varphi^{\text {dec }}$ is the decoder and $\varphi^{z}$ is a feature extractor for $z_{t}$.
In a VAE, we enforce the distribution of the latent vector $\left{z_{t}\right}$ to be close to a prior distribution [24]. In VRNN, the prior $\varphi^{\text {prior }}$ is learned and follows the distribution</p>
<p>$$
P\left(z_{t}\right) \sim \mathcal{N}\left(\mu_{0, t}, \sigma_{0, t}\right), \quad \text { where }\left[\mu_{0, t}, \sigma_{0, t}\right]=\varphi^{\text {prior }}\left(h_{t-1}\right)
$$</p>
<p>Finally, the RNN $f^{\mathrm{RNN}}$ updates its state as</p>
<p>$$
h_{t}=f^{\mathrm{RNN}}\left(\varphi^{x}\left(x_{t}\right), \varphi^{z}\left(z_{t}\right), h_{t-1}\right)
$$</p>
<p>VRNN is trained by minimizing</p>
<p>$$
\begin{aligned}
&amp; \sum_{t=1}^{T} D_{\mathrm{KL}}\left(\mathcal{N}\left(\mu_{z, t}, \sigma_{z, t} \mid \mathcal{N}\left(\mu_{0, t}, \sigma_{0, t}\right)\right)\right. \
&amp; \quad-\frac{1}{L} \sum_{t=1}^{T} \sum_{i=1}^{L} P\left(x_{t} \mid \mu_{z, t}+\epsilon_{i, t} \times \sigma_{z, t}\right)+\lambda|\theta|_{2}^{2}
\end{aligned}
$$</p>
<p>where $\epsilon_{i, t} \sim \mathcal{N}(0, I), \lambda$ is a regularization constant, and $\theta$ is a vector containing all the parameters in our model. Once the VRNN is trained, we use the prior to sample latent random variables and use them to generate trajectories.
2) Conditional VRNNs: We want a VRNN to be conditioned on a sequence $\left{u_{t}\right}<em t="t">{t=0}^{T}$ (e.g., the control inputs). To this end, the posterior distribution of $z</em>\right)$, where}$ (Eqn. 6) is now $P\left(z_{t} \mid x_{t}, u_{t}\right) \sim \mathcal{N}\left(\mu_{z, t}, \sigma_{z, t</p>
<p>$$
\left[\mu_{z, t}, \sigma_{z, t}\right]=\varphi^{\mathrm{enc}}\left(\varphi^{x}\left(x_{t}\right), \varphi^{u}\left(u_{t}\right), h_{t-1}\right)
$$</p>
<p>The prior distribution (Eqn. 9) also becomes conditional $P\left(z_{t} \mid u_{t}\right) \sim \mathcal{N}\left(\mu_{0, t}, \sigma_{0, t}\right)$, where</p>
<p>$$
\left[\mu_{0, t}, \sigma_{0, t}\right]=\varphi^{\text {prior }}\left(\varphi^{u}\left(u_{t}\right), h_{t-1}\right)
$$</p>
<p>And the state update equation (Eqn. 10) becomes</p>
<p>$$
h_{t}=f^{\mathrm{RNN}}\left(\varphi^{x}\left(x_{t}\right), \varphi^{z}\left(z_{t}\right), \varphi^{u}\left(u_{t}\right), h_{t-1}\right)
$$</p>
<p>Here, the decoder (Eqn. 8) does not depend on $\left{u_{t}\right}<em t="t">{t=0}^{T}$ because the latent vectors $\left{z</em>\right}<em t="t">{t=0}^{T}$ already have the capacity to contain all information about the control sequence $\left{u</em>$.}\right}_{t=0}^{T</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Fig. 3: Illustrations for conditional VRNNs: (a) the prior model of the latent representation $z_t$; (b) the generation model for $x_t$; (c) the recurrence model for $h_t$; (d) the inference model for $z_t$; and (e) the overall conditional VRNN design.</p>
<h3>3) Decoupled Conditional VRNNs</h3>
<p>In our experiments, we predict trajectories whose length varies from 100 to 1000. Because training and evaluating a VRNN becomes slower with these long trajectories, we propose an approximation to conditional VRNNs, which we call <em>Decoupled Conditional VRNNs</em>. A conditional VRNN is slow, because updates in a RNN have temporal dependence. However, we observe that the encoding, decoding, and prior networks are not interdependent: for example, the encoder only needs $\epsilon_t$ to sample $z_t$ internally; it does not take signals from the decoding and the prior networks. Thus, in DCVRNNs, we disentangle the model into three recurrent neural nets, one each for priors, the encoder, and the decoder. Specifically, we first have the Gaussian noises sampled as $\epsilon_t \sim \mathcal{N}(0, I)$. Then the equation for the encoder becomes $P(z_t|x_t, u_t) \sim \mathcal{N}(\mu_{z,t}, \sigma_{z,t})$, where</p>
<p>$$h_t, [\mu_{z,t}, \sigma_{z,t}] = f_{\text{enc}}^{\text{RNN}}(e^{\epsilon(t)}), \varphi^u(u_t), \epsilon_t, h_{t-1}).\tag{15}$$</p>
<p>The decoder is now $P(x_t|z_t) \sim \mathcal{N}(\mu_{x,t}, \sigma_{x,t})$, where</p>
<p>$$h_t, [\mu_{x,t}, \sigma_{x,t}] = f_{\text{dec}}^{\text{RNN}}(e^{\epsilon(t)}), h_{t-1}).\tag{16}$$</p>
<p>The prior is now $P(z_t|u_t) \sim \mathcal{N}(\mu_{0,t}, \sigma_{0,t})$, where</p>
<p>$$h_t, [\mu_{0,t}, \sigma_{0,t}] = f_{\text{prior}}^{\text{RNN}}(e^{\mu(t)}), \epsilon_t, h_{t-1}).\tag{17}$$</p>
<p>The loss function remains unchanged.</p>
<p>We use a DCVRNN as our stochastic data-augmented residual model by having</p>
<p>$$x_t = s_t, \quad u_t = [s_0, a_t, s_{t+1}], \quad \hat{s}_{t+1} = f_p(\hat{s}_t, a_t),\tag{18}$$</p>
<p>where $s_t$ represents the state at time $t$, $a_t$ represents the action at time $t$, $f_p$ represents the physics engine, and $\hat{s}_t$ represents the state predicted by the physics engine.</p>
<h3>V. EXPERIMENTS</h3>
<p>We study two scenarios: ball bouncing and planar pushing. We first generate synthetic data of ball bouncing and use them as an illustrative example to demonstrate the efficacy of our model. We then evaluate our model on the MIT Push dataset [5] and compare it with baselines and state-of-the-art motion models. We further present analyses on how well our model generalizes across shapes and materials.</p>
<h4>A. Experiments with Bouncing Balls</h4>
<p><strong>Data.</strong> When a ball bounces against the ground, it may reach different heights due to the irregularities in the ground surface</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Fig. 4: The two scenarios: ball bouncing and planar pushing.</p>
<p>which leads to different coefficients of restitution. Here we simulate the process using PyBullet. Specifically, we choose a height randomly from [4m, 5m] and a coefficient of restitution for ball-ground interaction from $\mathcal{N}(0.5, 0.1)$. We then drop a ball of radius 0.5m from the sampled height, and record its height and vertical velocity for 400 time steps with a sampling frequency of 60Hz. For our physics engine, we create another PyBullet environment but fix the coefficient of restitution to 0.65. We want our physics engine to produce trajectories that are different from our training data, but serve as a good initial guess.</p>
<p><strong>Metrics.</strong> We use three metrics for evaluation. The first two are the average error in object height reported as a percentage (trans) and in absolute values with meters as unit (pos). The third is the average error on the object's vertical velocity (vel) in metres per second.</p>
<p><strong>Methods.</strong> We compare with three baselines. The first is just the average translation and rotation over the dataset. This is equal to the error of always predicting zero movement, and we therefore name it Zero. The second (Physics) is the full deterministic, analytical model described above. The third (Neural) is to use the stochastic neural network alone without the simulator. Our full model (Hybrid) combines the simulator's and the network's predictions. For the stochastic Hybrid and Neural models, we sample 10 trajectories for each input and take their mean as our prediction.</p>
<p><strong>Setup.</strong> We implement our network in PyTorch. We train our network using the loss function in Eqn. 11. We use the ADAM optimizer [25] with a learning rate of 10^-3, a decay of 0.5 every 2,500 iteration for a total of 10,000 iteration, and a batch size of 100. Our training set contains 800 trajectories, while our test set has 100. For this experiment, $\varphi^u$, $\varphi^u$, $\varphi^u$ are all identity functions. $f_{\text{enc}}^{\text{RNN}}$ and $f_{\text{prior}}^{\text{RNN}}$ are both GRUs with 2 hidden layers and a hidden size of 16, followed by a linear layer of hidden size 4 for mean, and another parallel</p>
<p>|  | Train |  |  |  | Test |  |  |  |
| Models | loss $\left(\times 10^{-2}\right)$ | trans $(\%)$ | pos (mm) | rot (deg) | loss $\left(\times 10^{-2}\right)$ | trans $(\%)$ | pos (mm) | rot (deg) |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Zero | N/A | N/A | N/A | N/A | N/A | 99.99 | 359.44 | 49.46 |
| Physics | N/A | N/A | N/A | N/A | N/A | 1.93 | 6.91 | 7.71 |
| Neural | 0.41 | 0.72 | 2.42 | 1.85 | 0.68 | 0.84 | 2.81 | 2.48 |
| Hybrid | 0.36 | 0.54 | 1.86 | 1.73 | 0.47 | 0.60 | 2.04 | 2.03 |</p>
<p>TABLE I: Our hybrid model achieves the best performance in both position and rotation estimation for rect1, compared with methods that rely on physics engines or neural nets alone. Here we show results on both training and test sets, as well as the optimization losses. These numbers suggest that our Hybrid model is overfitting to the training set less than the pure Neural model. As we focus on long-term prediction, we include the Zero baseline to show the scale and the challenging nature of the problem.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Models</th>
<th style="text-align: center;">trans $(\%)$</th>
<th style="text-align: center;">pos $(\mathrm{m})$</th>
<th style="text-align: center;">velocity $\left(\mathrm{m} / \mathrm{s}^{2}\right)$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Zero</td>
<td style="text-align: center;">100.00</td>
<td style="text-align: center;">0.64</td>
<td style="text-align: center;">1.60</td>
</tr>
<tr>
<td style="text-align: left;">Physics</td>
<td style="text-align: center;">27.41</td>
<td style="text-align: center;">0.16</td>
<td style="text-align: center;">1.06</td>
</tr>
<tr>
<td style="text-align: left;">Neural</td>
<td style="text-align: center;">9.16</td>
<td style="text-align: center;">0.058</td>
<td style="text-align: center;">0.43</td>
</tr>
<tr>
<td style="text-align: left;">Hybrid</td>
<td style="text-align: center;">2.42</td>
<td style="text-align: center;">0.016</td>
<td style="text-align: center;">0.14</td>
</tr>
</tbody>
</table>
<p>TABLE II: Our hybrid model achieves the best performance in both position and velocity estimation of the ball, compared with methods that rely on physics engines or neural nets alone.
linear layer of hidden size 4 with softplus activation for standard deviation. $f_{\text {dec }}^{\text {RNN }}$ is a GRU with 2 hidden layers and a hidden size of 16 , followed by a linear layer of hidden size 2 for mean, and another parallel linear layer of hidden size 2 with softplus activation for standard deviation. The decoder's standard deviation is kept fixed to identity.
Results. Table II suggests that our model is able to outperform the baselines on the synthetic dataset. The Physics baseline, designed to be deterministic, is not performing very well as expected. However, with the help of the physics engine, our Hybrid model achieves much better performance compared to the Neural model, which learns everything from scratch. The intuition is that learning from a good guess makes the learning problem significantly easier.</p>
<h2>B. Experiments on Planar Pushing</h2>
<p>Data. We use the MIT Push dataset [5] for the scenario of planar pushing, which contains object pose and force recordings from real robot experiments. For uncertainty modeling in particular, we use the straight-line push experiment which was repeated 2,000 times. In this experiment, the object shape is a rectangle, the contact location is half way in between the block's center and edge, the contact is made perpendicular to the edge, the speed of the pusher is set to $20 \mathrm{~mm} / \mathrm{s}$ with no acceleration, and the total pusher displacement is 15 cm .</p>
<p>Part of the uncertainty comes of measurement noise, which we want to minimize. The object in the experiments is instrumented with reflective markers and tracked with Vicon motion tracking system. Vicon, when correctly calibrated, has 1 mm or better accuracy with a unimodal distribution of noise, well approximated by a Gaussian. Because of its high fidelity, our model can focus on learning the uncertain in dynamics. Metrics and methods. We use three metrics for evaluation, following Kloss et al. [12]. The first two are the average Euclidean distance between the predicted and the ground truth object reported as a percentage relative to the initial pose (trans) and as absolute values (pos) in millimeters. The third is the average error of object rotation (rot) in degree. We</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Materials</th>
<th style="text-align: left;">Models</th>
<th style="text-align: center;">trans (\%)</th>
<th style="text-align: center;">pos (mm)</th>
<th style="text-align: center;">rot (deg)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">plywood</td>
<td style="text-align: left;">Zero</td>
<td style="text-align: center;">99.99</td>
<td style="text-align: center;">339.12</td>
<td style="text-align: center;">48.36</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Physics</td>
<td style="text-align: center;">2.51</td>
<td style="text-align: center;">5.49</td>
<td style="text-align: center;">10.38</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Neural</td>
<td style="text-align: center;">0.92</td>
<td style="text-align: center;">3.43</td>
<td style="text-align: center;">2.16</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Hybrid</td>
<td style="text-align: center;">0.77</td>
<td style="text-align: center;">2.16</td>
<td style="text-align: center;">1.65</td>
</tr>
<tr>
<td style="text-align: left;">delrin</td>
<td style="text-align: left;">Zero</td>
<td style="text-align: center;">99.99</td>
<td style="text-align: center;">357.98</td>
<td style="text-align: center;">52.67</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Physics</td>
<td style="text-align: center;">1.89</td>
<td style="text-align: center;">5.78</td>
<td style="text-align: center;">12.07</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Neural</td>
<td style="text-align: center;">0.81</td>
<td style="text-align: center;">2.81</td>
<td style="text-align: center;">2.50</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Hybrid</td>
<td style="text-align: center;">0.62</td>
<td style="text-align: center;">2.09</td>
<td style="text-align: center;">2.19</td>
</tr>
</tbody>
</table>
<p>TABLE III: Our Hybrid model performs well consistently across object materials. Here for the rectangle made of plywood and delrin, our model again outperforms all other baseline models.
compare with the same baselines as in the ball experiment, except that the physics engine is now the analytical model described in Sec. IV-A.
Setup. For experiments on MIT push dataset, $\varphi^{x}$ and $\varphi^{u}$ consist of two bilinear layers with hidden sizes as 32 and 16 respectively and both followed by $\tan H$ activation. $\varphi^{z}$ is a single linear layer with hidden size 16 followed by $\tan H$ activation. $f_{\text {enc }}^{\text {RNN }}$ and $f_{\text {pose }}^{\text {RNN }}$ are both GRUs with 2 hidden layers and a hidden size of 16 , followed by a linear layer of hidden size 16 for mean, and another parallel linear layer of hidden size 16 with softplus activation for standard deviation. $f_{\text {dec }}^{\text {RNN }}$ is a GRU with 2 hidden layers and a hidden size of 16 , followed by a linear layer of hidden size 4 for mean, and another parallel linear layer of hidden size 4 with softplus activation for standard deviation. We again use ADAM optimizer [25] with a learning rate of $10^{-3}$ and a weight decay of 0.5 every 5,000 iteration for a total of 50,000 iteration. Our training set contains 6,500 trajectories, while our test set contains 628 trajectories.
Results. Table I shows the main results on the MIT Push data-set, using the rect1 object, a 837 g square with a side length of 9 cm , on the ABS surface. Our full model (Hybrid) significantly outperforms the baseline methods that rely only on physics engines or neural nets. Here we list results on both training and test sets. A pure neural net-based approach achieves a relatively low error on the training set, close to our Hybrid model. However, it generalizes much worse to the test set. Its prediction errors are much higher for both position estimation ( 2.81 vs. 2.04) and rotation estimation (2.48 vs. 2.03).</p>
<p>Our formulation is not constrained by the object's material. Table III shows results on objects made of two other materials: plywood and delrin. Our Hybrid model consistently outperforms the baselines.</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Fig. 5: Prediction errors <em>vs.</em> training data size. Our hybrid model not only performs better, but also requires much less data to achieve a given level of performance. In contrast, purely using purely data-driven models requires a larger training set and is not performing as well.</p>
<p>Our hybrid model is also more sample-efficient. As shown in Fig. 5, compared with the Neural model, our Hybrid model not only has higher prediction accuracies, but also achieves such accuracies much faster. Our model converges with as little as 2,500 training examples; in contrast, even with 6,500 training examples, purely data-driven models are not able to achieve performance comparable to ours.</p>
<p>Our model captures the uncertainty of the object motion well. To evaluate this, from the repeated pushes, we collect the ground truth distribution of the position of the object (<em>rect1</em>) after being pushed for one second. We then sample 2,000 points from the state-of-the-art stochastic motion modeling approach—GP-SUM [20]. We also sample 2,000 trajectories from our Hybrid model. We present qualitative and quantitative results in Fig. 6. Compared with GP-SUM, our model can better capture the underlying uncertainty. Quantitatively, we compute the Chamfer distance [26] between each model's output distribution <em>S</em> and the ground truth distribution <em>T</em>, defined as</p>
<p>$$
\text{CD}(S, T) = \frac{1}{|S|} \sum_{p \in S} \min_{q \in T} |p - q|<em T="T" _in="\in" q="q">2 + \frac{1}{|T|} \sum</em>
$$} \min_{p \in S} |p - q|_2. \tag{19</p>
<p>Our model achieves a lower error compared to GP-SUM.</p>
<h3><em>C. Generalization Power</em></h3>
<p>We want our prediction models to generalize to real-world objects, which can be of any shape and material. In this section, we evaluate how our model and the baselines generalize to new object materials and shapes.</p>
<p>For materials, we evaluate our model's predictive abilities on different surfaces. We consider the push data-set on plywood, polyurethane, and delrin. Figs. 7a and 7b summarize the results of our Hybrid model and of the Physics and Neural baselines. Our model has lower generalization errors in both position and rotation prediction.</p>
<p>For shapes, we evaluate our model's predictions on a new object—<em>rect2</em>, a 1045g rectangle with side lengths of 9cm and 11.26cm. Fig. 7c suggests that our model also generalizes better than the Physics and the Neural baselines on both position and rotation estimation.</p>
<p>We hypothesize that our model generalizes better across shapes and materials because it learns residuals—errors of the physics models that are supposed to be similar across various regimes. This assumption critically depends on the</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Fig. 6: Our Hybrid model captures the distribution of possible push outcomes. Measured in Chamfer distance, our model achieves a lower error compared with GP-SUM [20].</p>
<p>quality of the physics model; when it no longer holds, our model's generalization power may be limited.</p>
<h3>VI. DISCUSSION AND CONCLUSION</h3>
<p>We have proposed a simulation framework using a data-augmented residual motion model. Our underlying philosophy is to first exploit analytical models to model real-world data as much as possible, and then to learn the remaining residuals. This residual learning formulation adapts the model to specific real-world scenarios, with little need for domain-specific knowledge or hand-crafting. In this study, we have demonstrated its efficacy in predicting real-world planar pushing and its generalization power across shapes and materials. The particular choice of our residual learner enables accurate long-term predictions and generates complex posterior distributions over future states. The improved accuracy may be attributed to the model's implicitly learning of the details in object-surface frictional interactions, so that it can account for variations in the coefficient of friction and potentially anisotropic friction.</p>
<p>One may be tempted to do away with the analytic model entirely and rely on a purely data-driven approach. This approach results in learning the full motion model from scratch with no priors. Aside from being more data-hungry, this approach does not generalize well to other shapes and materials. Starting from a good initial guess to the trajectory,</p>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Fig. 7: Our method generalizes well to different materials and to a new shape (<em>rect2</em> in the push dataset). The error bars show our hybrid model achieves a consistently lower generalization error for both position and rotation prediction, compared with baseline methods.</p>
<p>the residual model has less to learn and generalizes better.</p>
<p>No model will ever be perfect; therefore, our model's ability in reasoning about possible outcomes can be a powerful tool in planning and control. For example, in the context of the planar pushing task, identifying a predictable push can lead the planner to exploit this property.</p>
<p>While the data-augmented residual model is more accurate and reasons about uncertainty, it does have certain drawbacks. Given that the residual model is data-driven, it can predict outcomes that are physically impossible, because there is no mechanism to enforce basic physics principles (<em>e.g.,</em> the conservation of energy) at the output level. In practice, however, these implausible outcomes would not appear if we can have the model sufficiently trained.</p>
<p>The simulation framework only requires a coarse domain-specific analytical motion model to be applied to other robotic tasks. For future work, we plan on applying the framework to more difficult modeling tasks. In this paper's experimental setup, we have assumed access to the noisy full state space; an interesting extension would be to learn an observation model along with the residual model to simultaneously perform state estimation and prediction.</p>
<p><em>Acknowledgement</em> This work is supported by NSF #1420316, #1523767, and #1723381, AFOSR grant FA9550-17-1-0165, ONR MURI N00014-16-1-2007, Toyota Research Institute, Honda Research, Facebook, and Draper Laboratory. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of our sponsors.</p>
<h2>REFERENCES</h2>
<ul>
<li>[1] R. Smith, "Open Dynamics Engine (ODE)," 2006.</li>
<li>[2] E. Coumans, "Bullet physics engine," <em>Open Source Software: http://bulletphysics.org</em>, 2010.</li>
<li>[3] E. Todorov, T. Erez, and Y. Tassa, "Mujoco: A physics engine for model-based control," in <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>. IEEE, 2012, pp. 5026–5033.</li>
<li>[4] R. Kolbert, N. Chavan Dafle, and A. Rodriguez, "Experimental Validation of Contact Dynamics for In-Hand Manipulation," in <em>International Symposium on Experimental Robotics (ISER)</em>, 2016.</li>
<li>[5] K.-T. Yu, M. Bauza, N. Fazeli, and A. Rodriguez, "More than a million ways to be pushed. a high-fidelity experimental dataset of planar pushing," in <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 2016.</li>
<li>[6] N. Fazeli, S. Zapolsky, E. Drumwright, and A. Rodriguez, "Fundamental limitations in performance and interpretability of common planar rigid-body contact models," in <em>International Symposium on Robotics Research (ISRR)</em>, 2017.</li>
<li>[7] S. Goyal, A. Ruina, and J. Papadopoulos, "Planar Sliding with Dry Friction Part 1 . Limit Surface and Moment Function," <em>Wear</em>, vol. 143, pp. 307–330, 1991.</li>
<li>[8] R. D. Howe and M. R. Cutkosky, "Practical force-motion models for sliding manipulation," <em>Int. J. Robotics Res.</em>, vol. 15, no. 6, pp. 557–572, 1996.</li>
<li>[9] K. M. Lynch, H. Maekawa, and K. Tanie, "Manipulation and active sensing by pushing using tactile feedback." in <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 1992.</li>
<li>[10] F. Hogan and A. Rodriguez, "Feedback Control of the Pusher-Slider System: A Story of Hybrid and Underactuated Contact Dynamics," in <em>Workshop on Algorithmic Foundation of Robotics (WAFR)</em>, 2016.</li>
<li>[11] K.-T. Yu, J. Leonard, and A. Rodriguez, "Shape and pose recovery from planar pushing," in <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>. IEEE, 2015, pp. 1208–1215.</li>
<li>[12] A. Kloss, S. Schaal, and J. Bohg, "Combining learned and analytical models for predicting action effects," <em>arXiv:1710.04102</em>, 2017.</li>
<li>[13] N. Fazeli, S. Zapolsky, E. Drumwright, and A. Rodriguez, "Learning data-efficient rigid-body contact models: Case study of planar impact," in <em>Conference on Robot Learning (CoRL)</em>, 2017, pp. 388–397.</li>
<li>[14] J. Zhou, R. Paolini, A. Bagnell, and M. T. Mason, "A convex polynomial force-motion model for planar sliding: Identification and application," in <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2016, pp. 372–377.</li>
<li>[15] J. Zhou, A. Bagnell, and M. T. Mason, "A fast stochastic contact model for planar pushing and grasping: Theory and experimental validation," in <em>Robotics: Science and Systems (RSS)</em>, 2017.</li>
<li>[16] A. Byravan and D. Fox, "Se3-nets: Learning rigid body motion using deep neural networks," in <em>IEEE International Conference on Robotics and Automation (ICRA)</em>. IEEE, 2017, pp. 173–180.</li>
<li>[17] M. Bauza and A. Rodriguez, "A probabilistic data-driven model for planar pushing," in <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2017.</li>
<li>[18] M. Babaeizadeh, C. Finn, D. Erhan, R. H. Campbell, and S. Levine, "Stochastic variational video prediction," <em>arXiv:1710.11252</em>, 2017.</li>
<li>[19] T. Xue, J. Wu, K. Bouman, and B. Freeman, "Visual dynamics: Probabilistic future frame synthesis via cross convolutional networks," in <em>Neural Information Processing Systems (NIPS)</em>, 2016, pp. 91–99.</li>
<li>[20] M. Bauza and A. Rodriguez, "GP-SUM. gaussian processes filtering of non-gaussian beliefs," <em>arXiv preprint arXiv:1709.08120</em>, 2017.</li>
<li>[21] J. Zhou, R. Paolini, A. M. Johnson, J. A. Bagnell, and M. T. Mason, "A probabilistic planning framework for planar grasping under uncertainty," <em>IEEE Robotics and Automation Letters</em>, vol. 2, no. 4, pp. 2111–2118, 2017.</li>
<li>[22] K. Cho, B. V. Merriënboer, D. Bahdanau, and Y. Bengio, "On the properties of neural machine translation: Encoder-decoder approaches," <em>arXiv:1409.1259</em>, 2014.</li>
<li>[23] J. Chung, K. Kastner, L. Dinh, K. Goel, A. C. Courville, and Y. Bengio, "A recurrent latent variable model for sequential data," in <em>Neural Information Processing Systems (NIPS)</em>, 2015.</li>
<li>[24] D. P. Kingma and M. Welling, "Auto-encoding variational bayes," in <em>International Conference on Learning Representations (ICLR)</em>, 2014.</li>
<li>[25] D. P. Kingma and J. Ba, "Adam: A method for stochastic optimization," in <em>International Conference on Learning Representations (ICLR)</em>, 2015.</li>
<li>[26] H. G. Barrow, J. M. Tenenbaum, R. C. Bolles, and H. C. Wolf, "Parametric correspondence and chamfer matching: Two new techniques for image matching," in <em>International Joint Conference on Artificial Intelligence (IJCAI)</em>, 1977.</li>
</ul>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{1}$ A. Ajay, J. Wu, L. P. Kaelbling, and J. B. Tenenbaum are with the Computer Science and Artificial Intelligence Laboratory at Massachusetts Institute of Technology, Cambridge, MA, USA
${ }^{2}$ N. Fazeli, M. Bauza, and A. Rodriguez are with the Department of Mechanical Engineering at Massachusetts Institute of Technology, Cambridge, MA, USA&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>