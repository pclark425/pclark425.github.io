<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8393 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8393</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8393</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-149.html">extraction-schema-149</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, representations, probing results, interventions, performance, and error analysis.</div>
                <p><strong>Paper ID:</strong> paper-27f7aa77bf343fefd3984c6b23265af672bcc0a3</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/27f7aa77bf343fefd3984c6b23265af672bcc0a3" target="_blank">Attribution Patching Outperforms Automated Circuit Discovery</a></p>
                <p><strong>Paper Venue:</strong> BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP</p>
                <p><strong>Paper TL;DR:</strong> This work shows that a simple method based on attribution patching outperforms all existing methods while requiring just two forward passes and a backward pass, and averages over all tasks finds that this method has greater AUC from circuit recovery than other methods.</p>
                <p><strong>Paper Abstract:</strong> Automated interpretability research has recently attracted attention as a potential research direction that could scale explanations of neural network behavior to large models. Existing automated circuit discovery work applies activation patching to identify subnetworks responsible for solving specific tasks (circuits). In this work, we show that a simple method based on attribution patching outperforms all existing methods while requiring just two forward passes and a backward pass. We apply a linear approximation to activation patching to estimate the importance of each edge in the computational subgraph. Using this approximation, we prune the least important edges of the network. We survey the performance and limitations of this method, finding that averaged over all tasks our method has greater AUC from circuit recovery than other methods.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8393.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8393.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, representations, probing results, interventions, performance, and error analysis.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EAP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Edge Attribution Patching</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A gradient-based, efficient approximation to activation patching that computes absolute attribution scores for every edge in a transformer's computational graph using two forward passes and one backward pass, then prunes lowest-scoring edges to recover task-relevant subnetworks (circuits).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-2 small</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Transformer (GPT-2 small) used in experiments; exact parameter count not specified beyond 'small'; analysis considers attention heads and MLPs as nodes writing to a residual stream.</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>Numerical comparison (Greater-Than) — also evaluated on IOI and Docstring tasks; modular arithmetic is only mentioned as prior work but not evaluated here.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_representation</strong></td>
                            <td>Does not itself posit a detailed algorithmic representation for arithmetic; instead EAP identifies subnetworks (collections of attention heads / MLP edges) that correlate with the model performing the task (i.e., circuits responsible for outputs such as numerical comparison).</td>
                        </tr>
                        <tr>
                            <td><strong>probing_or_intervention_method</strong></td>
                            <td>Attribution patching (linear Taylor approximation) implemented as Edge Attribution Patching: compute Δ_e L = (e_corr - e_clean)^T ∂L/∂e_clean for each edge using two forwards and one backwards; compared against activation patching (direct intervention) and ACDC.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>EAP is more efficient (2 forward + 1 backward) and attained higher ROC AUC than ACDC on the Greater-Than and IOI tasks (per paper's ROC figures). In the Docstring task EAP was competitive but ACDC with KL divergence outperformed EAP in that case. Additional numeric diagnostics: correlation between EAP attribution scores and activation-patching scores in the Docstring task was low (R^2 = 0.27); best-fit slope 0.531 indicating EAP tended to overestimate effects (≈2x).</td>
                        </tr>
                        <tr>
                            <td><strong>error_types_or_failure_modes</strong></td>
                            <td>Approximation failures where the metric-response to interpolation between clean and corrupted activations is concave (linear first-order Taylor overestimates effect); edges originating from embeddings (token/positional) particularly show concave activation-patching curves; attribution patching fails when the gradient of the chosen metric is the zero vector (e.g., KL divergence at the model's natural output).</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>Benchmarked against previously-identified ground-truth circuits for IOI, Docstring, and Greater-Than: ROC/AUC comparisons show EAP recovers meaningful subnetworks; distributions of attribution scores show circuit edges tend to have larger absolute scores; role-stratified IOI analyses (e.g., name-mover edges) yield attribution sign and magnitude consistent with expected functional roles.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexamples_or_challenges</strong></td>
                            <td>EAP's linear approximation has limited fidelity in many cases (low R^2 vs activation patching), overestimates effects when metric-vs-activation curves are concave, and can be misled by particular edge types (embeddings); combining EAP pre-pruning with ACDC (activation-patching-based refinement) improves recovery, indicating EAP alone is not always sufficient.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Attribution Patching Outperforms Automated Circuit Discovery', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8393.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8393.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, representations, probing results, interventions, performance, and error analysis.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Activation Patching</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Activation Patching (causal intervention via replacement of activations)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A causal-intervention analysis that replaces a component's activation from one forward pass with another (do(E = e_corr)) and measures change in a model metric (e.g., loss or logit difference); accurate but computationally expensive because each intervention requires additional forward passes.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-2 small</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Transformer (GPT-2 small) used for experiments/comparisons in this work.</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>Applied to Greater-Than and Docstring tasks here (used as a more exact ground-truth measurement for circuit importance where computational cost allows).</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_representation</strong></td>
                            <td>Used to identify causal importance of edges (parts of circuits) rather than to propose a specific arithmetic algorithm; when applied historically it has revealed subnetworks responsible for behaviors including arithmetic-like tasks in prior work.</td>
                        </tr>
                        <tr>
                            <td><strong>probing_or_intervention_method</strong></td>
                            <td>Direct activation replacement interventions (do-notation) comparing metric L(x_clean | do(E=e_corr)) vs L(x_clean).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Considered the more exact measurement of edge causal importance; in the Docstring task repeated activation patching (used within circuit discovery) could outperform EAP in some settings; however it is much slower because each measurement requires a new forward pass.</td>
                        </tr>
                        <tr>
                            <td><strong>error_types_or_failure_modes</strong></td>
                            <td>Scales poorly: too expensive to exhaustively apply on large numbers of edges or in larger models; practical limits prevented using activation patching for IOI and Greater-Than in this paper except where computationally feasible.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>Activation-patching scores were treated as a higher-fidelity reference for evaluating attribution-patching approximations; discrepancies between activation- and attribution-patching reveal approximation failure modes.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexamples_or_challenges</strong></td>
                            <td>Computational cost limits for large-scale circuit discovery; leads to preference for approximate methods (EAP) despite approximation error.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Attribution Patching Outperforms Automated Circuit Discovery', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8393.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8393.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, representations, probing results, interventions, performance, and error analysis.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Attribution Patching</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Attribution Patching (gradient-based linear approximation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method that approximates the causal effect of corrupting an internal activation by a first-order (linear) Taylor expansion: Δ_e L ≈ (e_corr - e_clean)^T ∂L/∂e_clean, enabling estimation of many edges' importance with only two forward passes and one backward pass.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Attribution patching: Activation patching at industrial scale</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-2 small</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Transformer (GPT-2 small) used for experiments; attribution-patching gradients are obtained from a single backward pass over clean inputs.</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>Used to analyze Greater-Than (numerical comparison) and other tasks (IOI, Docstring) in the paper; not directly applied to modular arithmetic here.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_representation</strong></td>
                            <td>Method for attributing importance to edges that can reveal circuits (groups of edges) implicated in tasks, but does not by itself describe low-level arithmetic algorithms implemented by the model.</td>
                        </tr>
                        <tr>
                            <td><strong>probing_or_intervention_method</strong></td>
                            <td>Two clean/corrupt forward passes to collect e_clean and e_corr, then one backward pass to compute ∂L/∂e_clean and compute attribution scores for all edges.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Computationally efficient and enabled exhaustive ranking of edges; produced attribution-score distributions where circuit edges typically have larger absolute values; however fidelity vs activation patching is imperfect (R^2 = 0.27 in Docstring comparison) and slope of best-fit line was 0.531 (systematic overestimation).</td>
                        </tr>
                        <tr>
                            <td><strong>error_types_or_failure_modes</strong></td>
                            <td>Poor fidelity when the metric response is non-linear (concave) along the interpolation between clean and corrupted activations, leading to overestimation; embedding-derived edges more likely to show such non-linear behavior; fails when gradients are zero under chosen metric (e.g., KL divergence at model baseline).</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>Attribution scores correlate with known circuit membership and functional roles in IOI (e.g., name-mover edges receiving large-magnitude negative scores consistent with their causal role), and EAP-based pruning recovers subnetworks that overlap with previously reported circuits.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexamples_or_challenges</strong></td>
                            <td>Low correlation with activation-patching ground truth in some cases; systematic bias (overestimation) and edge-type sensitivity mean attribution patching should be combined with activation-patching refinement for best results.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Attribution Patching Outperforms Automated Circuit Discovery', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8393.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8393.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, representations, probing results, interventions, performance, and error analysis.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Greater-Than task</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Greater-Than task (numerical comparison)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A benchmark where the model must determine which of two numbers is greater; previously studied mechanistically (cited Hanna et al., 2023) and used here as one of the ground-truth tasks to evaluate circuit discovery methods.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>How does gpt-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-2 small</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Transformer (GPT-2 small) used to evaluate circuit discovery methods on the Greater-Than task; exact model size unspecified beyond 'small'.</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>Numerical comparison (which number is greater).</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_representation</strong></td>
                            <td>This paper does not propose a novel arithmetic algorithm for Greater-Than; it treats previously-identified subgraphs (circuits) for Greater-Than as ground truth and evaluates EAP's ability to recover those subnetworks (i.e., mechanism localization rather than proposing representation).</td>
                        </tr>
                        <tr>
                            <td><strong>probing_or_intervention_method</strong></td>
                            <td>Benchmarking used attribution patching (EAP), activation patching where feasible, and ACDC; logit-difference task metric was used for measuring effect.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>EAP attained maximal ROC AUC on the Greater-Than task compared to ACDC in the paper's figures (no numeric AUC values reported in text).</td>
                        </tr>
                        <tr>
                            <td><strong>error_types_or_failure_modes</strong></td>
                            <td>Specific failure modes for Greater-Than are not detailed beyond the general approximation issues of attribution patching noted in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>Overlap of EAP-recovered subgraphs with previously-identified Greater-Than circuits and superior ROC AUC indicate EAP successfully localizes the circuit responsible for Greater-Than behavior in GPT-2 small.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexamples_or_challenges</strong></td>
                            <td>Because activation-patching is expensive, in some settings EAP's approximation errors could mis-rank edges relevant to Greater-Than; refinement with activation-patching (ACDC) can improve results.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Attribution Patching Outperforms Automated Circuit Discovery', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8393.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e8393.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, representations, probing results, interventions, performance, and error analysis.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Modular arithmetic (prior mention)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Modular arithmetic tasks (prior mechanistic findings)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Mentioned in the introduction as an example of tasks where prior mechanistic interpretability work found subnetworks or partial explanations (i.e., models solving modular arithmetic via identifiable circuits), but not studied directly in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>Modular arithmetic (mentioned as a class of tasks addressed in prior work).</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_representation</strong></td>
                            <td>Paper only cites prior work that found networks of attention heads/MLPs partially or fully explaining modular-arithmetic-like behaviors; no mechanism details are provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>probing_or_intervention_method</strong></td>
                            <td>Not studied in this paper; prior referenced works used mechanistic tools (activation patching, circuit analysis), but specifics are not described here.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>error_types_or_failure_modes</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>Only a literature mention that prior interpretability work has located circuits for modular arithmetic in small models.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexamples_or_challenges</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Attribution Patching Outperforms Automated Circuit Discovery', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>How does gpt-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model. <em>(Rating: 2)</em></li>
                <li>Attribution patching: Activation patching at industrial scale <em>(Rating: 2)</em></li>
                <li>Towards automated circuit discovery for mechanistic interpretability <em>(Rating: 2)</em></li>
                <li>Interpretability in the wild: a circuit for indirect object identification in GPT-2 small <em>(Rating: 1)</em></li>
                <li>A circuit for Python docstrings in a 4-layer attention-only transformer <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8393",
    "paper_id": "paper-27f7aa77bf343fefd3984c6b23265af672bcc0a3",
    "extraction_schema_id": "extraction-schema-149",
    "extracted_data": [
        {
            "name_short": "EAP",
            "name_full": "Edge Attribution Patching",
            "brief_description": "A gradient-based, efficient approximation to activation patching that computes absolute attribution scores for every edge in a transformer's computational graph using two forward passes and one backward pass, then prunes lowest-scoring edges to recover task-relevant subnetworks (circuits).",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-2 small",
            "model_description": "Transformer (GPT-2 small) used in experiments; exact parameter count not specified beyond 'small'; analysis considers attention heads and MLPs as nodes writing to a residual stream.",
            "arithmetic_task_type": "Numerical comparison (Greater-Than) — also evaluated on IOI and Docstring tasks; modular arithmetic is only mentioned as prior work but not evaluated here.",
            "mechanism_or_representation": "Does not itself posit a detailed algorithmic representation for arithmetic; instead EAP identifies subnetworks (collections of attention heads / MLP edges) that correlate with the model performing the task (i.e., circuits responsible for outputs such as numerical comparison).",
            "probing_or_intervention_method": "Attribution patching (linear Taylor approximation) implemented as Edge Attribution Patching: compute Δ_e L = (e_corr - e_clean)^T ∂L/∂e_clean for each edge using two forwards and one backwards; compared against activation patching (direct intervention) and ACDC.",
            "performance_metrics": "EAP is more efficient (2 forward + 1 backward) and attained higher ROC AUC than ACDC on the Greater-Than and IOI tasks (per paper's ROC figures). In the Docstring task EAP was competitive but ACDC with KL divergence outperformed EAP in that case. Additional numeric diagnostics: correlation between EAP attribution scores and activation-patching scores in the Docstring task was low (R^2 = 0.27); best-fit slope 0.531 indicating EAP tended to overestimate effects (≈2x).",
            "error_types_or_failure_modes": "Approximation failures where the metric-response to interpolation between clean and corrupted activations is concave (linear first-order Taylor overestimates effect); edges originating from embeddings (token/positional) particularly show concave activation-patching curves; attribution patching fails when the gradient of the chosen metric is the zero vector (e.g., KL divergence at the model's natural output).",
            "evidence_for_mechanism": "Benchmarked against previously-identified ground-truth circuits for IOI, Docstring, and Greater-Than: ROC/AUC comparisons show EAP recovers meaningful subnetworks; distributions of attribution scores show circuit edges tend to have larger absolute scores; role-stratified IOI analyses (e.g., name-mover edges) yield attribution sign and magnitude consistent with expected functional roles.",
            "counterexamples_or_challenges": "EAP's linear approximation has limited fidelity in many cases (low R^2 vs activation patching), overestimates effects when metric-vs-activation curves are concave, and can be misled by particular edge types (embeddings); combining EAP pre-pruning with ACDC (activation-patching-based refinement) improves recovery, indicating EAP alone is not always sufficient.",
            "uuid": "e8393.0",
            "source_info": {
                "paper_title": "Attribution Patching Outperforms Automated Circuit Discovery",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "Activation Patching",
            "name_full": "Activation Patching (causal intervention via replacement of activations)",
            "brief_description": "A causal-intervention analysis that replaces a component's activation from one forward pass with another (do(E = e_corr)) and measures change in a model metric (e.g., loss or logit difference); accurate but computationally expensive because each intervention requires additional forward passes.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-2 small",
            "model_description": "Transformer (GPT-2 small) used for experiments/comparisons in this work.",
            "arithmetic_task_type": "Applied to Greater-Than and Docstring tasks here (used as a more exact ground-truth measurement for circuit importance where computational cost allows).",
            "mechanism_or_representation": "Used to identify causal importance of edges (parts of circuits) rather than to propose a specific arithmetic algorithm; when applied historically it has revealed subnetworks responsible for behaviors including arithmetic-like tasks in prior work.",
            "probing_or_intervention_method": "Direct activation replacement interventions (do-notation) comparing metric L(x_clean | do(E=e_corr)) vs L(x_clean).",
            "performance_metrics": "Considered the more exact measurement of edge causal importance; in the Docstring task repeated activation patching (used within circuit discovery) could outperform EAP in some settings; however it is much slower because each measurement requires a new forward pass.",
            "error_types_or_failure_modes": "Scales poorly: too expensive to exhaustively apply on large numbers of edges or in larger models; practical limits prevented using activation patching for IOI and Greater-Than in this paper except where computationally feasible.",
            "evidence_for_mechanism": "Activation-patching scores were treated as a higher-fidelity reference for evaluating attribution-patching approximations; discrepancies between activation- and attribution-patching reveal approximation failure modes.",
            "counterexamples_or_challenges": "Computational cost limits for large-scale circuit discovery; leads to preference for approximate methods (EAP) despite approximation error.",
            "uuid": "e8393.1",
            "source_info": {
                "paper_title": "Attribution Patching Outperforms Automated Circuit Discovery",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "Attribution Patching",
            "name_full": "Attribution Patching (gradient-based linear approximation)",
            "brief_description": "A method that approximates the causal effect of corrupting an internal activation by a first-order (linear) Taylor expansion: Δ_e L ≈ (e_corr - e_clean)^T ∂L/∂e_clean, enabling estimation of many edges' importance with only two forward passes and one backward pass.",
            "citation_title": "Attribution patching: Activation patching at industrial scale",
            "mention_or_use": "use",
            "model_name": "GPT-2 small",
            "model_description": "Transformer (GPT-2 small) used for experiments; attribution-patching gradients are obtained from a single backward pass over clean inputs.",
            "arithmetic_task_type": "Used to analyze Greater-Than (numerical comparison) and other tasks (IOI, Docstring) in the paper; not directly applied to modular arithmetic here.",
            "mechanism_or_representation": "Method for attributing importance to edges that can reveal circuits (groups of edges) implicated in tasks, but does not by itself describe low-level arithmetic algorithms implemented by the model.",
            "probing_or_intervention_method": "Two clean/corrupt forward passes to collect e_clean and e_corr, then one backward pass to compute ∂L/∂e_clean and compute attribution scores for all edges.",
            "performance_metrics": "Computationally efficient and enabled exhaustive ranking of edges; produced attribution-score distributions where circuit edges typically have larger absolute values; however fidelity vs activation patching is imperfect (R^2 = 0.27 in Docstring comparison) and slope of best-fit line was 0.531 (systematic overestimation).",
            "error_types_or_failure_modes": "Poor fidelity when the metric response is non-linear (concave) along the interpolation between clean and corrupted activations, leading to overestimation; embedding-derived edges more likely to show such non-linear behavior; fails when gradients are zero under chosen metric (e.g., KL divergence at model baseline).",
            "evidence_for_mechanism": "Attribution scores correlate with known circuit membership and functional roles in IOI (e.g., name-mover edges receiving large-magnitude negative scores consistent with their causal role), and EAP-based pruning recovers subnetworks that overlap with previously reported circuits.",
            "counterexamples_or_challenges": "Low correlation with activation-patching ground truth in some cases; systematic bias (overestimation) and edge-type sensitivity mean attribution patching should be combined with activation-patching refinement for best results.",
            "uuid": "e8393.2",
            "source_info": {
                "paper_title": "Attribution Patching Outperforms Automated Circuit Discovery",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "Greater-Than task",
            "name_full": "Greater-Than task (numerical comparison)",
            "brief_description": "A benchmark where the model must determine which of two numbers is greater; previously studied mechanistically (cited Hanna et al., 2023) and used here as one of the ground-truth tasks to evaluate circuit discovery methods.",
            "citation_title": "How does gpt-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model.",
            "mention_or_use": "use",
            "model_name": "GPT-2 small",
            "model_description": "Transformer (GPT-2 small) used to evaluate circuit discovery methods on the Greater-Than task; exact model size unspecified beyond 'small'.",
            "arithmetic_task_type": "Numerical comparison (which number is greater).",
            "mechanism_or_representation": "This paper does not propose a novel arithmetic algorithm for Greater-Than; it treats previously-identified subgraphs (circuits) for Greater-Than as ground truth and evaluates EAP's ability to recover those subnetworks (i.e., mechanism localization rather than proposing representation).",
            "probing_or_intervention_method": "Benchmarking used attribution patching (EAP), activation patching where feasible, and ACDC; logit-difference task metric was used for measuring effect.",
            "performance_metrics": "EAP attained maximal ROC AUC on the Greater-Than task compared to ACDC in the paper's figures (no numeric AUC values reported in text).",
            "error_types_or_failure_modes": "Specific failure modes for Greater-Than are not detailed beyond the general approximation issues of attribution patching noted in the paper.",
            "evidence_for_mechanism": "Overlap of EAP-recovered subgraphs with previously-identified Greater-Than circuits and superior ROC AUC indicate EAP successfully localizes the circuit responsible for Greater-Than behavior in GPT-2 small.",
            "counterexamples_or_challenges": "Because activation-patching is expensive, in some settings EAP's approximation errors could mis-rank edges relevant to Greater-Than; refinement with activation-patching (ACDC) can improve results.",
            "uuid": "e8393.3",
            "source_info": {
                "paper_title": "Attribution Patching Outperforms Automated Circuit Discovery",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "Modular arithmetic (prior mention)",
            "name_full": "Modular arithmetic tasks (prior mechanistic findings)",
            "brief_description": "Mentioned in the introduction as an example of tasks where prior mechanistic interpretability work found subnetworks or partial explanations (i.e., models solving modular arithmetic via identifiable circuits), but not studied directly in this paper.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": null,
            "model_description": null,
            "arithmetic_task_type": "Modular arithmetic (mentioned as a class of tasks addressed in prior work).",
            "mechanism_or_representation": "Paper only cites prior work that found networks of attention heads/MLPs partially or fully explaining modular-arithmetic-like behaviors; no mechanism details are provided here.",
            "probing_or_intervention_method": "Not studied in this paper; prior referenced works used mechanistic tools (activation patching, circuit analysis), but specifics are not described here.",
            "performance_metrics": null,
            "error_types_or_failure_modes": null,
            "evidence_for_mechanism": "Only a literature mention that prior interpretability work has located circuits for modular arithmetic in small models.",
            "counterexamples_or_challenges": null,
            "uuid": "e8393.4",
            "source_info": {
                "paper_title": "Attribution Patching Outperforms Automated Circuit Discovery",
                "publication_date_yy_mm": "2023-10"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "How does gpt-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model.",
            "rating": 2
        },
        {
            "paper_title": "Attribution patching: Activation patching at industrial scale",
            "rating": 2
        },
        {
            "paper_title": "Towards automated circuit discovery for mechanistic interpretability",
            "rating": 2
        },
        {
            "paper_title": "Interpretability in the wild: a circuit for indirect object identification in GPT-2 small",
            "rating": 1
        },
        {
            "paper_title": "A circuit for Python docstrings in a 4-layer attention-only transformer",
            "rating": 1
        }
    ],
    "cost": 0.015155499999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Attribution Patching Outperforms Automated Circuit Discovery</h1>
<p>Aaquib Syed*<br>asyed04@umd.edu<br>Can Rager ${ }^{\dagger}$<br>canrager@gmail.com<br>Arthur Conmy ${ }^{\dagger}$<br>arthurconmy@gmail.com</p>
<h4>Abstract</h4>
<p>Automated interpretability research has recently attracted attention as a potential research direction that could scale explanations of neural network behavior to large models. Existing automated circuit discovery work applies activation patching to identify subnetworks responsible for solving specific tasks (circuits). In this work, we show that a simple method based on attribution patching outperforms all existing methods while requiring just two forward passes and a backward pass. We apply a linear approximation to activation patching to estimate the importance of each edge in the computational subgraph. Using this approximation, we prune the least important edges of the network. We survey the performance and limitations of this method, finding that averaged over all tasks our method has greater AUC from circuit recovery than other methods.</p>
<h2>1 Introduction</h2>
<p>Mechanistic interpretability is a subfield of AI interpretability that focuses on attributing model behaviors to its components, thus reverse engineering the network (Olah, 2022). This field aims to identify subnetworks (circuits) within the model which are responsible for solving specific tasks (Olah et al., 2020). Prior attempts at finding circuits in language models have led to finding networks of attention heads and multi-layer perceptrons (MLPs) that partially or fully explain model behaviors at tasks such as indirect object identification, modular arithmetic, completion of docstrings, and predicting successive dates (Wang et al., 2023; Nanda et al., 2023; Heimersheim and Janiak, 2023; Hanna et al., 2023). However, almost all previous work has been limited to relatively small models since manually applying mechanistic interpretability methods has not currently scaled to end-to-end circuits in larger models (Lieberum et al., 2023).</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>It may be important to scale interpretability to large models as these are the neural networks most widely deployed and used by a wide range of people. Currently, we have little understanding into how these models work and failure modes are not always found ahead of deployment. If successful, scaled interpretability could address a wide variety of concerns about the lack of transparency of language models (Vig et al., 2020), in addition to speculative risks about the alignment of machine learning systems (Hubinger, 2020).</p>
<p>Automated Circuit Discovery (ACDC; Conmy et al. (2023)) attempts to automate a large portion of the mechanistic interpretability workflow - the pruning of edges between attention heads and MLPs that do not affect the task being studied. ACDC begins with a computational graph, and recursively calculates the importance of an edge in the graph for a specific task. In our work, we use edges to refer to activations inside models between two components (Section 2 describes this motivation further). ACDC's pruning algorithm applies activation patching. (Note that activation patching is not attribution patching. Both are defined in full in Section 3.3.) At a high level, activation patching edits a specific activation in a model forward pass and measures a model statistic (e.g loss) under this intervention. Activation patching is inefficient for circuit discovery because getting each statistic about model activations requires another forward pass. Our work uses attribution patching to recover circuits more efficiently (Section 3.3).</p>
<p>Our main contributions are:</p>
<ol>
<li>Introducing a method for using attribution patching on all computational graph edges for automated circuit discovery (Edge Attribution Patching, Section 3.3).</li>
<li>Benchmarking Edge Attribution Patching vs existing circuit discovery methods (Section 4).</li>
<li>Finding and explaining some limitations with Edge Attribution Patching (Section 5).</li>
</ol>
<h2>2 Related Work</h2>
<p>Automated Circuit Discovery refers to finding the important subgraph of models' computational graphs for performance on particular tasks (Conmy et al., 2023). Existing algorithms include efficient heuristics (Michel et al., 2019) and gradientdescent based methods (Louizos et al., 2018; Cao et al., 2021). ACDC is related to pruning (Blalock et al., 2020) and other compression techniques (Zhu et al., 2023), but differs in how the compressed networks are reflective of the circuits that the model uses to compute outputs to certain tasks and the goal of ACDC is not to speed up forward passes (all techniques studied in this work use slow forward passes). Concurrent work has further established attribution-based circuit discovery (Ferrando and Voita, 2024; Hanna et al., 2024; Kramár et al., 2024).</p>
<p>Activation Patching is a technique for analyzing the role of individual components in a model. It involves targeted manipulations of activations during a forward pass (further explained in Section 3.1). Previous works applied this technique under various names, such as interchange interventions (Geiger et al., 2021), causal mediation analysis (Vig et al., 2020) and causal tracing (Meng et al., 2022). We adapt the terminology used by Conmy et al. (2023).</p>
<p>Transformer Circuits. Our work builds upon the framework for understanding transformers for interpretability as introduced by Elhage et al. (2021). Individual attention heads and MLPs (collectively called nodes) read and write information to a central communication channel, also called the residual stream. In these terms we can examine dependencies of nodes with the output of earlier nodes, i.e we can measure the effect of attention heads in layer 0 on the attention heads in layer 2. In the following, we view these dependencies as edges between nodes, building on existing work using this perspective (Heimersheim and Janiak, 2023; Hanna et al., 2023; Wang et al., 2023).</p>
<h2>3 Edge Attribution Patching</h2>
<p>We present Edge Attribution Patching (EAP) as a technique to identify relevant model components for solving a specific task. In the following, we view language models as directed, acyclic graphs. In these terms, we aim to find small subgraphs that retain good performance on narrow tasks. We determine the importance of a specific edge through
targeted manipulation of activations during a forward pass. We compare two approaches, Attribution Patching and Activation Patching, in order to motivate EAP.</p>
<h3>3.1 Activation Patching</h3>
<p>Activation patching refers to replacing the activations from one model forward pass with the activations from a different forward pass. This method is typically applied to measure the counterfactual importance of model components, i.e. to measure a statistic $L(x)$ from model outputs under the activation patching, where $x$ is an input prompt. For example, $L$ often represents loss or logit difference (Wang et al., 2023).</p>
<p>Following existing work (Section 2), we study the effect of activation patching on specific model edges by setting these equal to activations from different forward passes. Concretely, suppose that an edge $E$ in the computational graph has activation $e_{\text {corr }}$ on some corrupted prompt. In this work, we use the change in metric under activation patching</p>
<p>$$
\left|L\left(x_{\text {clean }} \mid \operatorname{do}\left(E=e_{\text {corr }}\right)\right)-L\left(x_{\text {clean }}\right)\right|
$$</p>
<p>to measure the impact of edge $E$. We use donotation from causality (Pearl, 1995) to emphasise that activation patching is a causal intervention.</p>
<h3>3.2 Attribution Patching</h3>
<p>Activation patching slows ACDC since each measurement (like Equation (1)) requires another forward pass. Attribution patching (Nanda, 2023) is a technique for estimating Equation (1) for many different edges $E$ using only two forward passes and one backward pass. ${ }^{1}$ It linearly approximates the metric difference after corrupting a single edge in the computational graph (Figure 1) by expanding $L$ as a function of the edge activation as a Taylor series with terms up to the first order: ${ }^{2}$</p>
<p>$$
\begin{aligned}
&amp; L\left(x_{\text {clean }} \mid \operatorname{do}\left(E=e_{\text {corr }}\right)\right) \approx L\left(x_{\text {clean }}\right)+ \
&amp; \underbrace{\left(e_{\text {corr }}-e_{\text {clean }}\right)^{\top} \frac{\partial}{\partial e_{\text {clean }}} L\left(x_{\text {clean }} \mid \operatorname{do}\left(E=e_{\text {clean }}\right)\right)}<em e="e">{\text {Call this } \Delta</em>
\end{aligned}
$$} L, \text { the attribution score. }</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>A simple rearrangement implies that Equation (1) is approximately equal to $\left|\Delta_{c} L\right|$ (3) which we call the absolute attribution score for the rest of this paper. In this work we always compute this score across a set of $\left(x_{\text {clean }}, x_{\text {corr }}\right)$ pairs and take the mean.
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Attribution Patching approximates the difference in metric $L$ caused by corrupting edges.</p>
<h3>3.3 Edge Attribution Patching</h3>
<p>We can use the insights from Section 3.2 to build an automated circuit discovery algorithm. This takes two steps:</p>
<ol>
<li>Obtain absolute attribution scores for the importance of all edges in the computational graph with Equation (2).</li>
<li>Sort these scores and keep the top $k$ edges in a circuit.</li>
</ol>
<p>We use Edge Attribution Patching (EAP) to refer to this algorithm. In the rest of the work we report results for all $k$ values when we evaluate EAP (similar to HISP in Conmy et al. (2023)).</p>
<p>Note that in Edge Attribution Patching, the partial derivative $\left(\partial / \partial e_{\text {clean }}\right) L(x) \quad$ in Equation (??) reduces to a partial derivative w.r.t the endpoint of the edge, as discussed in Appendix F.</p>
<p>In practice, all gradients needed to calculate the attribution scores come from intermediate terms computed in one ordinary backwards pass ${ }^{3}$ in PyTorch (Paszke</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Removing the least important edges.
et al., 2019), hence attribution patching is extremely efficient.</p>
<p>One limitation of attribution patching is that it will not work when the gradient of the metric is the zero vector. Conmy et al. (2023) recommended the use of KL divergence as a metric, which is i) equal to 0 when we run the model without ablations and ii) a non-negative metric. Therefore the zero point is a global minimum and hence all gradients are the zero vector at this point. In this work we use the task-specific metrics' (not KL divergence) from Conmy et al. (2023) so avoid this issue.</p>
<h2>4 Results</h2>
<h3>4.1 Edge Attribution Patching vs Activation Patching vs ACDC</h3>
<p>We compare Edge Attribution Patching (EAP) and ACDC on the Indirect Object Identification (IOI), Docstring, and Greater-Than tasks. For each of these tasks, previous studies identified a subgraph (circuit) relevant for solving the task. We use their results as a ground truth for benchmarking both methods. We also compare using ACDC with the task-specific metrics (e.g logit difference) and KL Divergence (which was originally recommended). For the docstring task, we also include repeated activation patching as another point of reference for performance comparisons. We applied repeated activation patching by running the same circuit discovery method described in Section 3.3 but using Equation (1) rather than absolute attribution scores. Activation patching was not included in the other tasks as it was too computationally expensive to run on the GPT-2 small models used by IOI and Greater-Than. Subnetworks found using EAP for all three tasks are shown in Appendix A.</p>
<p>The ROC curves in Figure 3 suggest the performance of EAP is better than ACDC overall: it has the maximal AUC when applied to the IOI and greater than tasks, while ACDC used with the KL Divergence metric outperforms EAP in the docstring task.</p>
<h3>4.2 Validating EAP Attribution Scores</h3>
<p>In this section, we look at the approximate metric change (attribution score) EAP assigns to each edge in the model. We aim to understand the relation between the attribution score and the function of the edge in the task being studied. First, we look at the distribution of scores for edges in the circuit compared to edges not in the circuit for each of the</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: ROC Curves comparing EAP, ACDC with task metric, and ACDC with KL Divergence for the Greater-Than (left), IOI (right), and Docstring task (bottom). The Docstring plot also compares to Activation Patching.
three tasks.
Figure 4 shows the distribution of attribution scores for the IOI task. The distributions for the remaining tasks can be found in Appendix B. Qualitatively, attribution scores for edges in the circuit tend to be spread further from zero. Furthermore, there are only 6 edges outside of the interval $[-0.25,0.25]$ that aren't part of the IOI circuit. We further explore the attribution scores for the IOI circuit's classes of heads in Appendix E.
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Distribution of Attribution Scores for the IOI Task (Logit difference metric)</p>
<h2>5 Limitations</h2>
<p>We introduced edge attribution patching as an approximation to activation patching. However, we found that edge activation patching outperformed ACDC, a technique based on activation patching (Section 4). In this section, we investigate whether attribution patching's success is due to extremely accurate approximations (in Section 5.1 we find that the answer is no), and whether there is any further use for ACDC (in Section 5.2 we find that the answer is yes). We use the docstring task as a case study due to the small model size used.</p>
<h3>5.1 How faithful are Attribution Patching's approximations?</h3>
<p>To study how faithful the approximation ?? is, we plot the attribution patching scores (Equation (2)) against the activation patching scores (Equation (1)) in Figure 5a. Surprisingly, we find a fairly weak correlation between activation and attribution patching scores $\left(R^{2}=0.27\right)$. Further, the line of best fit has gradient 0.531 , suggesting that attribution patching estimates the effect of activation patching as twice as important as it really is.</p>
<p>Moreover, we can gain some sense for the discrepancy between activation and attribution patching by studying the continuous transition between clean ( $e_{\text {clean }}$ ) and corrupted ( $e_{\text {corr }}$ ) activations in Equation (1), i.e studying the values $\left|L\left(x_{\text {clean }}\right|\right.$ do $\left(E=\lambda e_{\text {corr }}+(1-\lambda) e_{\text {clean }}\right))-$ $L\left(x_{\text {clean }}\right) \mid$ for $0 \leq \lambda \leq 1$. We can compare this to the linear approximations of Attribution Patching $\lambda \Delta_{e} L$. Figure 5 b shows the result for one edge in the docstring circuit where the linear approximation to activation patching is not accurate.</p>
<p>We find that interpolating towards the corrupted input creates a concave curve (Figure 5b) such that the linear approximation at $\lambda=0$ overestimates the effect of activation patching this edge. In Appendix D we show that this also holds for the other outlier edges in the ellipse in Figure 5a.</p>
<h3>5.2 Is there any further use for ACDC?</h3>
<p>In Section 5.1 above, we found that EAP overestimates activation patching in cases where the task specific metric is concave. This suggests the potential to refine the result by running ACDC on the pruned subgraph returned by EAP. We ran EAP first, then ACDC on the resulting subgraph for the Docstring task, varying pruning thresholds for EAP and ACDC independently. Figure 6 compares the</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" />
(a) Distribution of attribution scores for edges from activation patching and attribution patching. Circled: outlier EAP point studied in Figure 5b.
<img alt="img-5.jpeg" src="img-5.jpeg" />
(b) Visualizing the rightmost point in Figure 5a. Note that corrupting this edge (surprisingly) slightly increases the logit difference on the Docstring task (higher logit difference is better). However, EAP overestimates how large this increase is.</p>
<p>Figure 5: Visualizing Edge Attribution Patching.</p>
<p>TPR and FPR for the combined methods with the ROC curve of EAP only. The combined methods show increased performance compared to EAP only.</p>
<p>Finally, one further limitation of this research is that the metrics used for interpretability do not precisely capture meaningful human understanding. Recovering a subgraph that humans previously recovered is limited because i) we can't evaluate this metric for interpretability tasks that we don't yet understand and ii) human-found circuits are imperfect, increasing the noise in this measurement.</p>
<h2>6 Conclusion</h2>
<p>We provide evidence that Edge Attribution Patching (EAP) outperforms ACDC in identifying circuits while being substantially faster to compute. This result is surprising, as EAP is an approximation for activation patching, the method applied by
<img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 6: Comparing statistics of the combined EAP + ACDC methods with EAP only. The inset shows a zoom to the significant area of the statistics of the combined method.</p>
<p>ACDC. However, running ACDC on the prepruned subnetwork found by EAP can improve the identification of relevant edges. Therefore, we suggest future circuit discovery experiments to run EAP first and then apply ACDC.</p>
<h2>References</h2>
<p>Davis W. Blalock, Jose Javier Gonzalez Ortiz, Jonathan Frankle, and John V. Guttag. 2020. What is the state of neural network pruning? In Proceedings of Machine Learning and Systems 2020, MLSys 2020, Austin, TX, USA, March 2-4, 2020. mlsys.org.</p>
<p>Steven Cao, Victor Sanh, and Alexander Rush. 2021. Low-complexity probing via finding subnetworks. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 960-966. Association for Computational Linguistics.</p>
<p>Arthur Conmy, Augustine N. Mavor-Parker, Aengus Lynch, Stefan Heimersheim, and Adrià GarrigaAlonso. 2023. Towards automated circuit discovery for mechanistic interpretability. In Thirty-seventh Conference on Neural Information Processing Systems.</p>
<p>Nelson Elhage, Neel Nanda, Catherine Olsson, Tom Henighan, Nicholas Joseph, Ben Mann, Amanda Askell, Yuntao Bai, Anna Chen, Tom Conerly, Nova DasSarma, Dawn Drain, Deep Ganguli, Zac Hatfield-Dodds, Danny Hernandez, Andy Jones, Jackson Kernion, Liane Lovitt, Kamal Ndousse, Dario Amodei, Tom Brown, Jack Clark, Jared Kaplan, Sam McCandlish, and Chris Olah. 2021. A mathematical framework for transformer circuits. Transformer Circuits Thread.</p>
<p>Javier Ferrando and Elena Voita. 2024. Information flow routes: Automatically interpreting language models at scale. Preprint, arXiv:2403.00824.</p>
<p>Atticus Geiger, Hanson Lu, Thomas Icard, and Christopher Potts. 2021. Causal abstractions of neural networks. arXiv preprint.</p>
<p>Michael Hanna, Ollie Liu, and Alexandre Variengien. 2023. How does gpt-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model. Preprint, arXiv:2305.00586.</p>
<p>Michael Hanna, Sandro Pezzelle, and Yonatan Belinkov. 2024. Have faith in faithfulness: Going beyond circuit overlap when finding model mechanisms. arXiv preprint arXiv:2403.17806.</p>
<p>Stefan Heimersheim and Jett Janiak. 2023. A circuit for Python docstrings in a 4-layer attention-only transformer.</p>
<p>Evan Hubinger. 2020. An overview of 11 proposals for building safe advanced ai. Preprint, arXiv:2012.07532.</p>
<p>János Kramár, Tom Lieberum, Rohin Shah, and Neel Nanda. 2024. Atp*: An efficient and scalable method for localizing llm behaviour to components. arXiv preprint arXiv:2403.00745.</p>
<p>Tom Lieberum, Matthew Rahtz, János Kramár, Neel Nanda, Geoffrey Irving, Rohin Shah, and Vladimir Mikulik. 2023. Does circuit analysis interpretability scale? evidence from multiple choice capabilities in chinchilla. Preprint, arXiv:2307.09458.</p>
<p>Christos Louizos, Max Welling, and Diederik P. Kingma. 2018. Learning sparse neural networks through $l_{0}$ regularization. In 6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings. OpenReview.net.</p>
<p>Kevin Meng, David Bau, Alex J Andonian, and Yonatan Belinkov. 2022. Locating and editing factual associations in GPT. In Advances in Neural Information Processing Systems.</p>
<p>Paul Michel, Omer Levy, and Graham Neubig. 2019. Are sixteen heads really better than one? In Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada, pages 14014-14024.</p>
<p>Neel Nanda. 2023. Attribution patching: Activation patching at industrial scale.</p>
<p>Neel Nanda, Lawrence Chan, Tom Lieberum, Jess Smith, and Jacob Steinhardt. 2023. Progress measures for grokking via mechanistic interpretability. In The Eleventh International Conference on Learning Representations.</p>
<p>Chris Olah. 2022. Mechanistic interpretability, variables, and the importance of interpretable bases.</p>
<p>Chris Olah, Nick Cammarata, Ludwig Schubert, Gabriel Goh, Michael Petrov, and Shan Carter. 2020. Zoom in: An introduction to circuits. Distill.</p>
<p>Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. 2019. Pytorch: An imperative style, high-performance deep learning library. In Advances in Neural Information Processing Systems 32, pages 8024-8035. Curran Associates, Inc.</p>
<p>Judea Pearl. 1995. Causal diagrams for empirical research. Biometrika, 82(4):669-688.</p>
<p>Jesse Vig, Sebastian Gehrmann, Yonatan Belinkov, Sharon Qian, Daniel Nevo, Simas Sakenis, Jason Huang, Yaron Singer, and Stuart Shieber. 2020. Causal mediation analysis for interpreting neural nlp: The case of gender bias. Preprint, arXiv:2004.12265.</p>
<p>Kevin Ro Wang, Alexandre Variengien, Arthur Conmy, Buck Shlegeris, and Jacob Steinhardt. 2023. Interpretability in the wild: a circuit for indirect object identification in GPT-2 small. In The Eleventh International Conference on Learning Representations.</p>
<p>Xunyu Zhu, Jian Li, Yong Liu, Can Ma, and Weiping Wang. 2023. A survey on model compression for large language models. Preprint, arXiv:2308.07633.</p>
<h1>A EAP Subnetworks</h1>
<p><img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 7: Resulting subnetworks after EAP at the given thresholds: (Top) IOI Subnetwork, Threshold=0.077; (Middle) Docstring Subnetwork, Threshold=0.244; (Bottom) Greater-Than Subnetwork, Threshold=0.009.</p>
<h1>B Distribution of EAP Attribution Scores</h1>
<p><img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<p>Figure 8: Distribution of Attribution Scores for the Docstring and Greater-Than tasks</p>
<h2>C Further investigation into combining EAP with ACDC</h2>
<p><img alt="img-9.jpeg" src="img-9.jpeg" /></p>
<p>Figure 9: Youdens-J statistic (maximum TPR minus FPR value) for combining EAP and ACDC methods on the docstring task. We applied ACDC to the pruned subgraph returned by EAP.</p>
<h2>D Further failures of attribution patching approximation</h2>
<p>In Figure 10 we show further cases where in the docstring task attribution patching can be misleading. These cases all involve an edge that comes from the model's embeddings (positional and tokens). Our interpretation is that weighted averages of embeddings are anomalous inputs to the model and cause the concave change in docstring logit diff which doesn't occur when edges ae between non-embedding model components.</p>
<p><img alt="img-10.jpeg" src="img-10.jpeg" /></p>
<p>Figure 10: Visualizing Edge Attribution Patching in two further cases where the concave activation patching curve means the linear fit is poor.</p>
<h1>E Edges Roles in IOI</h1>
<p>We further explore the attribution scores for the IOI circuit. The IOI circuit is comprised of different attention head classes such as Induction heads, S-Inhibition heads, etc. (Wang et al., 2023). Figure 11 shows the distributions of scores stratified by the roles of the edges. The edge roles are defined according to the role of their origin node. While edge roles such as Previous Token, Duplicate Token, Induction, and S-Inhibition edges have attribution scores centered around zero, we see a bias in edge scores given to name mover and negative name mover edges. As the name mover edges are directly responsible for the model outputting the indirect object, the attribution scores are largely negative since ablating these edges removes the model's ability to output the indirect object, lowering the logit difference. Similarly, the negative name movers have attribution scores that are largely positive since ablating these edges improves the logit difference. This matches the intuitive function of the edges.
<img alt="img-11.jpeg" src="img-11.jpeg" /></p>
<p>Figure 11: Distribution of Attribution Scores for each Edge Role in the IOI Task.</p>
<h1>F Only one backwards pass is required for EAP</h1>
<p>Note: it may be easier to understand our implementation https://github.com/Aaquib111/ edge-attribution-patching/blob/3702573/utils/prune_utils.py#L249 rather than read this explanation. Alternatively, this derivation uses essentially the same arguments as Nanda (2023) ${ }^{4}$ though with an updated codebase.</p>
<p>There are only two types of edges iterated over in ACDC: i) residual edges where the result is added at its endpoint, and ii) edges between the residual stream and the query, key and value calculations. Clearly for all edges like ii) we can compute the gradient terms in ?? in one backwards pass.</p>
<p>Interestingly, for all $\Delta_{e} L$ terms where $e$ is a type i) edge (i.e added at the endpoint), we only need calculate the gradient with respect to the endpoint of the edge! For example, suppose we're calculating the effect of L0H0 on L1H0Q. If we represent the input to L1H0Q as a node $V$ in the computational graph then</p>
<p>$$
\frac{\partial}{\partial e_{\text {clean }}} L\left(x_{\text {clean }} \mid \operatorname{do}\left(E=e_{\text {clean }}\right)\right)=\frac{\partial}{\partial v_{\text {clean }}} L\left(x_{\text {clean }} \mid \operatorname{do}\left(V=v_{\text {clean }}\right)\right)
$$</p>
<p>due to how $V$ is just the sum of all the edges entering $V$. This allows efficient calculation of all the $\Delta_{e} L$ values since gradients with respect to nodes in computational graphs are calculated by default in backwards passes.</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{4}$ Specifically, this section: https://www.neelnanda.io/mechanistic-interpretability/attribution-patching# how-to-think-about-activation-patching=:-:text=axes\%20of\%20variation.-, Path\%20patching, -The\%20core\% 20intuition&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>