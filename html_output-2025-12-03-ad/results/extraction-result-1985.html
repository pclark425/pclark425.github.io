<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1985 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1985</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1985</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-45.html">extraction-schema-45</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of adaptive, learned, or parameterized operators (mutation, crossover, variation operators) in evolutionary algorithms, genetic algorithms, or genetic programming, including performance comparisons, operator representations, and results on code or text domains.</div>
                <p><strong>Paper ID:</strong> paper-279088910</p>
                <p><strong>Paper Title:</strong> A study of gene expression programming algorithm for dynamically adjusting the parameters of genetic operators</p>
                <p><strong>Paper Abstract:</strong> The fast developments in artificial intelligence together with evolutionary algorithms have not solved all the difficulties that Gene Expression Programming (GEP) encounters when maintaining population diversity and preventing premature convergence. Its restrictions block GEP from successfully handling high-dimensional along with complex optimization problems. This research develops Dynamic Gene Expression Programming (DGEP) as an algorithm to control genetic operators dynamically thus achieving improved global search with increased population diversity. The approach operates with two unique operators which include Adaptive Regeneration Operator (DGEP-R) and Dynamically Adjusted Mutation Operator (DGEP-M) to preserve diversity while maintaining exploration-exploitation balance during evolutionary search. An extensive evaluation of DGEP occurred through symbolic regression problem tests. The study employed traditional benchmark functions and conducted evaluations versus baselines Standard GEP, NMO-SARA, and MS-GEP-A to assess fitness outcomes, R² values, population diversification, and the avoidance of local optima. All key metric evaluations showed that DGEP beat standard GEP along with alternative improved variants. DGEP produced the optimal results for 8 benchmark functions that produced 15.7% better R² scores along with 2.3 × larger population diversity. The escape rate from local optima within DGEP reached 35% higher than what standard GEP could achieve. The DGEP model serves to enhance GEP performance through the effective maintenance of diversity and improved global search functions. The results indicate that adaptive genetic methods strengthen evolutionary procedures for solving complex problems effectively.</p>
                <p><strong>Cost:</strong> 0.017</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1985.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1985.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of adaptive, learned, or parameterized operators (mutation, crossover, variation operators) in evolutionary algorithms, genetic algorithms, or genetic programming, including performance comparisons, operator representations, and results on code or text domains.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DGEP-R</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Adaptive Regeneration Operator (DGEP-R)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An adaptive variation operator that injects entirely new individuals into the population at a rate that decays with progress; designed to restore/maintain genotypic diversity and help escape stagnation points in GEP.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>operator_name</strong></td>
                            <td>Adaptive Regeneration Operator (DGEP-R)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>variation/other</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Introduces new individuals into the population each generation according to a regeneration rate R_i computed as R_i = R_min + (R_max - R_min) * exp(-α * F_i * i/G), where F_i is the fitness coefficient combining average, max and min fitness, i is current generation and G total generations. New individuals are generated with unique genotypes independent of the initial population; number of new individuals n_new = R_i * n, the remainder are selected from previous generation.</td>
                        </tr>
                        <tr>
                            <td><strong>is_learned_or_adaptive</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>learning_mechanism</strong></td>
                            <td>fitness-based dynamic parameter adjustment (rule-based/adaptive heuristic)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_representation</strong></td>
                            <td>parameterized function (analytic formula for regeneration rate)</td>
                        </tr>
                        <tr>
                            <td><strong>domain_type</strong></td>
                            <td>numerical optimization / symbolic regression</td>
                        </tr>
                        <tr>
                            <td><strong>context_dependent</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>modality_specific</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>compositional</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>R² (goodness-of-fit), population diversity (dg), escape-from-local-optima (generations to best), RMSE, classification accuracy, MSE</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td>Reported as part of DGEP: average R² improvement 15.7% over standard GEP; population diversity increased 2.3× (aggregate); example: F3 diversity DGEP 0.7449 vs GEP 0.3322; regeneration rate parameters used: R_min=0.05, R_max=0.15.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_fixed_operator</strong></td>
                            <td>Standard GEP baseline: R² baseline (aggregate) used for comparison; examples: F7 R² GEP 0.876 vs DGEP 0.915; diversity F3 GEP 0.3322; (values as reported in paper).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_improvement</strong></td>
                            <td>Contributed to DGEP's overall improvements: 15.7% higher R² (average), 2.3× population diversity, 35% better escape-from-local-optima (aggregate); per-function examples reported above.</td>
                        </tr>
                        <tr>
                            <td><strong>has_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>executability_preservation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_diversity_metric</strong></td>
                            <td>dg = D / N where D is number of individuals with different fitness values; example values: F3 dg DGEP 0.7449 vs GEP 0.3322; overall diversity improvement factor 2.3×.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Per-generation time and space complexity O(n), paper reports no asymptotic overhead beyond standard GEP; moderate constant overhead for computing fitness statistics and generating new individuals.</td>
                        </tr>
                        <tr>
                            <td><strong>population_size</strong></td>
                            <td>100</td>
                        </tr>
                        <tr>
                            <td><strong>cold_start_addressed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>operator_specialization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>DGEP-R, by injecting new individuals based on a fitness-derived regeneration rate, substantially increases population diversity and helps avoid premature convergence when combined with DGEP-M.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Requires setting hyperparameters (R_min, R_max, α); sensitivity to these parameters noted and requires parameter tuning; may increase computational work in large-scale problems though asymptotic complexity remains O(n).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1985.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1985.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of adaptive, learned, or parameterized operators (mutation, crossover, variation operators) in evolutionary algorithms, genetic algorithms, or genetic programming, including performance comparisons, operator representations, and results on code or text domains.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DGEP-M</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Dynamically Adjusted Mutation Operator (DGEP-M)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A mutation-rate adaptation operator that raises or lowers mutation probability according to the trend in a fitness coefficient between generations, aiming to balance exploration and exploitation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>operator_name</strong></td>
                            <td>Dynamically Adjusted Mutation Operator (DGEP-M)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>mutation</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Adjusts the per-generation mutation rate P_i within [P_min, P_max] according to the ratio of fitness coefficients F_i / F_{i-1}: if F_i > F_{i-1} (population quality improving) set P_i = P_min; if equal keep P_i = P_{i-1}; if F_i < F_{i-1} (degradation/stagnation) increase P_i (up to P_max). Reported parameter bounds: P_min=0.05, P_max=0.15.</td>
                        </tr>
                        <tr>
                            <td><strong>is_learned_or_adaptive</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>learning_mechanism</strong></td>
                            <td>fitness-trend rule-based adaptation (dynamic heuristic using population fitness coefficient comparisons)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_representation</strong></td>
                            <td>parameterized function / conditional rule (piecewise update based on fitness ratio)</td>
                        </tr>
                        <tr>
                            <td><strong>domain_type</strong></td>
                            <td>numerical optimization / symbolic regression</td>
                        </tr>
                        <tr>
                            <td><strong>context_dependent</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>modality_specific</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>compositional</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>R², RMSE, population diversity, escape-from-local-optima (generations), statistical significance (t-test, p-values)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td>When used within DGEP the dynamic mutation contributed to aggregate improvements: average R² +15.7% vs standard GEP; P_min=0.05, P_max=0.15 used experimentally. Specific per-function improvements reported (e.g., F7 R² 0.915 for DGEP vs 0.876 for GEP).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_fixed_operator</strong></td>
                            <td>Standard fixed-rate GEP (baseline) used: example mutation fixed in baseline led to lower diversity and worse R² (see examples above). Exact baseline mutation rate not stated in paper excerpt, but comparisons are provided numerically in aggregate.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_improvement</strong></td>
                            <td>Paper attributes improved escape rate (35% higher) and increased diversity when DGEP-M is combined with DGEP-R; exact isolated effect of DGEP-M alone not fully separated in reported aggregates.</td>
                        </tr>
                        <tr>
                            <td><strong>has_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>executability_preservation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_diversity_metric</strong></td>
                            <td>Same dg metric as DGEP-R; DGEP-M contributed to higher dg when combined in DGEP (aggregate 2.3× increase over GEP).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>O(n) per generation (same asymptotic complexity as standard GEP); only needs fitness coefficients and simple comparisons/updates, so low constant overhead.</td>
                        </tr>
                        <tr>
                            <td><strong>population_size</strong></td>
                            <td>100</td>
                        </tr>
                        <tr>
                            <td><strong>cold_start_addressed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>operator_specialization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>DGEP-M adaptively raises mutation when population fitness declines and reduces mutation when fitness improves, helping maintain diversity without disrupting elite solutions and improving overall search performance in symbolic regression tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Sensitivity to P_min/P_max bounds and fitness-coefficient calculations; when increased mutation occurs late in evolution it may destabilize convergence—authors note need for better mutation control strategies in some scenarios.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1985.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1985.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of adaptive, learned, or parameterized operators (mutation, crossover, variation operators) in evolutionary algorithms, genetic algorithms, or genetic programming, including performance comparisons, operator representations, and results on code or text domains.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DGEP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Dynamic Gene Expression Programming (DGEP)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A GEP variant combining DGEP-R (adaptive regeneration) and DGEP-M (adaptive mutation) to dynamically control genetic operator parameters using a fitness coefficient, improving diversity and global search.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>operator_name</strong></td>
                            <td>DGEP (combines DGEP-R and DGEP-M)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>hybrid (variation + mutation + selection integration)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Integrates DGEP-R during selection (to inject new individuals based on regeneration rate) and DGEP-M after selection (to adapt mutation rate based on fitness trends), followed by standard transposition and recombination; both operators share the same fitness-coefficient metric Fi to reduce overhead.</td>
                        </tr>
                        <tr>
                            <td><strong>is_learned_or_adaptive</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>learning_mechanism</strong></td>
                            <td>fitness-based adaptive heuristics (rule-based dynamic parameter control)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_representation</strong></td>
                            <td>parameterized adaptive rules (analytic formulas and conditional updates)</td>
                        </tr>
                        <tr>
                            <td><strong>domain_type</strong></td>
                            <td>symbolic regression / numerical optimization</td>
                        </tr>
                        <tr>
                            <td><strong>context_dependent</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>modality_specific</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>compositional</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>R², RMSE, MSE, classification accuracy, population diversity (dg), escape-from-local-optima (generations), statistical significance (t-tests, p-values)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td>DGEP outperformed standard GEP and other improved variants on benchmarks: average R² improvement 15.7%; aggregate population diversity increased by 2.3×; escape-from-local-optima improvement 35%; example Keijzer-10 RMSE improved from 0.092 (GEP) to 0.065 (DGEP) (29.3% reduction); F7 R²: GEP 0.876 -> DGEP 0.915; F8 0.908 -> 0.942.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_fixed_operator</strong></td>
                            <td>Standard GEP baseline: reported values include R² 0.876 (F7), diversity F3 0.3322, Keijzer-10 RMSE 0.092, classification accuracy 78.5%, high-dim regression MSE 1.235; these are the fixed-operator baselines compared.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_improvement</strong></td>
                            <td>Aggregate improvements reported: +15.7% R², 2.3× population diversity, 35% better escape-from-local-optima; specific per-task numbers given in paper (see performance_learned_operator).</td>
                        </tr>
                        <tr>
                            <td><strong>has_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>executability_preservation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_diversity_metric</strong></td>
                            <td>dg = D / N; reported aggregate dg improvement from 1.0 to 2.3 (Table 6) and per-function dg examples (e.g., F3 DGEP 0.7449 vs GEP 0.3322).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Asymptotic cost reported O(n) same as standard GEP; authors state no additional asymptotic cost though moderate constant overhead for dynamic adjustments.</td>
                        </tr>
                        <tr>
                            <td><strong>population_size</strong></td>
                            <td>100</td>
                        </tr>
                        <tr>
                            <td><strong>cold_start_addressed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>operator_specialization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Combining adaptive regeneration and adaptive mutation controlled by a common fitness coefficient substantially improves symbolic regression performance, diversity, and the ability to escape local optima compared to standard GEP and several improved baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Requires careful hyperparameter tuning (mutation and regeneration bounds and α); sensitivity noted and authors recommend future automated calibration (e.g., reinforcement learning) and further validation on high-dimensional and real-world problems.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1985.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1985.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of adaptive, learned, or parameterized operators (mutation, crossover, variation operators) in evolutionary algorithms, genetic algorithms, or genetic programming, including performance comparisons, operator representations, and results on code or text domains.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NMO-SARA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>NMO-SARA (referenced improved GEP algorithm)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced improved GEP algorithm used as a baseline in experiments; described in the paper as a multi-objective evolutionary algorithm with neighborhood search aimed at enhancing local search capabilities.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>operator_name</strong></td>
                            <td>NMO-SARA</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>other / hybrid</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Mentioned as a multi-objective evolutionary algorithm with neighborhood search; paper uses it as a comparative baseline but does not provide internal operator mechanics or explicit parameterization within this text.</td>
                        </tr>
                        <tr>
                            <td><strong>is_learned_or_adaptive</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>learning_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>operator_representation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_type</strong></td>
                            <td>symbolic regression (used as baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>context_dependent</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>modality_specific</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compositional</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Compared using same metrics as DGEP (fitness, R², diversity, escape capability); used in experimental comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_fixed_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_improvement</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>executability_preservation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>population_size</strong></td>
                            <td>100 (same experimental setup)</td>
                        </tr>
                        <tr>
                            <td><strong>cold_start_addressed</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>operator_specialization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Served as a baseline comparator; DGEP outperformed NMO-SARA on the reported symbolic regression benchmarks per aggregate metrics in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1985.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1985.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of adaptive, learned, or parameterized operators (mutation, crossover, variation operators) in evolutionary algorithms, genetic algorithms, or genetic programming, including performance comparisons, operator representations, and results on code or text domains.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MS-GEP-A</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MS-GEP-A (multi-strategy GEP variant A)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-strategy GEP improvement algorithm referenced and used as a baseline in experiments; combines strategies to boost search performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>operator_name</strong></td>
                            <td>MS-GEP-A</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>hybrid / multi-strategy</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Referenced as a multi-strategy enhanced GEP; the paper uses it as a comparative baseline but does not detail its internal operator representations in the provided text.</td>
                        </tr>
                        <tr>
                            <td><strong>is_learned_or_adaptive</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>learning_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>operator_representation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_type</strong></td>
                            <td>symbolic regression (used as baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>context_dependent</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>modality_specific</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compositional</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Compared on R², diversity, escape-from-local-optima, RMSE etc.; included in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_fixed_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_improvement</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>executability_preservation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>population_size</strong></td>
                            <td>100 (same experimental setup)</td>
                        </tr>
                        <tr>
                            <td><strong>cold_start_addressed</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>operator_specialization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>DGEP outperformed MS-GEP-A on reported benchmarks in aggregate metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1985.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1985.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of adaptive, learned, or parameterized operators (mutation, crossover, variation operators) in evolutionary algorithms, genetic algorithms, or genetic programming, including performance comparisons, operator representations, and results on code or text domains.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Adagep</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Adagep - an adaptive gene expression programming algorithm</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An earlier adaptive GEP variant cited in related work that applies adaptive mechanisms to GEP operator parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Adagep-an adaptive gene expression programming algorithm</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>operator_name</strong></td>
                            <td>Adagep</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>other / adaptive</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Cited as an example of prior adaptive GEP work; paper does not provide internal details beyond citation.</td>
                        </tr>
                        <tr>
                            <td><strong>is_learned_or_adaptive</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>learning_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>operator_representation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_type</strong></td>
                            <td>symbolic regression / GEP applications (mentioned in related work)</td>
                        </tr>
                        <tr>
                            <td><strong>context_dependent</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>modality_specific</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compositional</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_fixed_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_improvement</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>executability_preservation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>population_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>cold_start_addressed</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>operator_specialization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Listed among prior adaptive/operator-improvement works motivating DGEP; no experimental data provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1985.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e1985.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of adaptive, learned, or parameterized operators (mutation, crossover, variation operators) in evolutionary algorithms, genetic algorithms, or genetic programming, including performance comparisons, operator representations, and results on code or text domains.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AB-GEP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AB-GEP: Adversarial bandit gene expression programming for symbolic regression</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A recent GEP variant that applies bandit/adversarial bandit techniques to GEP (cited in related work).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>AB-GEP: Adversarial bandit gene expression programming for symbolic regression</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>operator_name</strong></td>
                            <td>AB-GEP</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>other / adaptive (bandit-based)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Cited as an example of adaptive operator selection using adversarial bandit ideas; the paper does not provide implementation details or experimental data for AB-GEP itself.</td>
                        </tr>
                        <tr>
                            <td><strong>is_learned_or_adaptive</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>learning_mechanism</strong></td>
                            <td>bandit-based operator selection (implied by title/citation; not detailed in this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_representation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_type</strong></td>
                            <td>symbolic regression</td>
                        </tr>
                        <tr>
                            <td><strong>context_dependent</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>modality_specific</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compositional</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_fixed_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_improvement</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>executability_preservation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>population_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>cold_start_addressed</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>operator_specialization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Mentioned as related adaptive-operator work; the current paper positions DGEP as complementary or alternative to such adaptive strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1985.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e1985.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of adaptive, learned, or parameterized operators (mutation, crossover, variation operators) in evolutionary algorithms, genetic algorithms, or genetic programming, including performance comparisons, operator representations, and results on code or text domains.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Yuen2009</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>A genetic algorithm that adaptively mutates and never revisits</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced genetic algorithm that applies adaptive mutation and mechanisms to avoid revisiting search points; cited in related work.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A genetic algorithm that adaptively mutates and never revisits</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>operator_name</strong></td>
                            <td>adaptive mutation (Yuen & Chow)</td>
                        </tr>
                        <tr>
                            <td><strong>operator_type</strong></td>
                            <td>mutation</td>
                        </tr>
                        <tr>
                            <td><strong>operator_description</strong></td>
                            <td>Cited as a prior example of adaptive mutation strategies that attempt to avoid revisiting previously explored solutions; details not reproduced in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>is_learned_or_adaptive</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>learning_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>operator_representation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_type</strong></td>
                            <td>general evolutionary optimization</td>
                        </tr>
                        <tr>
                            <td><strong>context_dependent</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>modality_specific</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compositional</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_learned_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_fixed_operator</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_improvement</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>executability_preservation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>population_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>cold_start_addressed</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>operator_specialization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Cited as historical adaptive-mutation work motivating adaptive operator research; no experimental details in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Adagep-an adaptive gene expression programming algorithm <em>(Rating: 2)</em></li>
                <li>AB-GEP: Adversarial bandit gene expression programming for symbolic regression <em>(Rating: 2)</em></li>
                <li>A genetic algorithm that adaptively mutates and never revisits <em>(Rating: 2)</em></li>
                <li>Enhancing gene expression programming based on space partition and jump for symbolic regression <em>(Rating: 1)</em></li>
                <li>Dynamic population generation (DPGP) <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1985",
    "paper_id": "paper-279088910",
    "extraction_schema_id": "extraction-schema-45",
    "extracted_data": [
        {
            "name_short": "DGEP-R",
            "name_full": "Adaptive Regeneration Operator (DGEP-R)",
            "brief_description": "An adaptive variation operator that injects entirely new individuals into the population at a rate that decays with progress; designed to restore/maintain genotypic diversity and help escape stagnation points in GEP.",
            "citation_title": "here",
            "mention_or_use": "use",
            "operator_name": "Adaptive Regeneration Operator (DGEP-R)",
            "operator_type": "variation/other",
            "operator_description": "Introduces new individuals into the population each generation according to a regeneration rate R_i computed as R_i = R_min + (R_max - R_min) * exp(-α * F_i * i/G), where F_i is the fitness coefficient combining average, max and min fitness, i is current generation and G total generations. New individuals are generated with unique genotypes independent of the initial population; number of new individuals n_new = R_i * n, the remainder are selected from previous generation.",
            "is_learned_or_adaptive": true,
            "learning_mechanism": "fitness-based dynamic parameter adjustment (rule-based/adaptive heuristic)",
            "operator_representation": "parameterized function (analytic formula for regeneration rate)",
            "domain_type": "numerical optimization / symbolic regression",
            "context_dependent": true,
            "modality_specific": false,
            "compositional": false,
            "performance_metric": "R² (goodness-of-fit), population diversity (dg), escape-from-local-optima (generations to best), RMSE, classification accuracy, MSE",
            "performance_learned_operator": "Reported as part of DGEP: average R² improvement 15.7% over standard GEP; population diversity increased 2.3× (aggregate); example: F3 diversity DGEP 0.7449 vs GEP 0.3322; regeneration rate parameters used: R_min=0.05, R_max=0.15.",
            "performance_fixed_operator": "Standard GEP baseline: R² baseline (aggregate) used for comparison; examples: F7 R² GEP 0.876 vs DGEP 0.915; diversity F3 GEP 0.3322; (values as reported in paper).",
            "performance_improvement": "Contributed to DGEP's overall improvements: 15.7% higher R² (average), 2.3× population diversity, 35% better escape-from-local-optima (aggregate); per-function examples reported above.",
            "has_comparison": true,
            "executability_preservation": null,
            "novelty_diversity_metric": "dg = D / N where D is number of individuals with different fitness values; example values: F3 dg DGEP 0.7449 vs GEP 0.3322; overall diversity improvement factor 2.3×.",
            "transfer_learning": false,
            "transfer_results": null,
            "computational_cost": "Per-generation time and space complexity O(n), paper reports no asymptotic overhead beyond standard GEP; moderate constant overhead for computing fitness statistics and generating new individuals.",
            "population_size": "100",
            "cold_start_addressed": false,
            "operator_specialization": null,
            "key_findings": "DGEP-R, by injecting new individuals based on a fitness-derived regeneration rate, substantially increases population diversity and helps avoid premature convergence when combined with DGEP-M.",
            "limitations_or_failures": "Requires setting hyperparameters (R_min, R_max, α); sensitivity to these parameters noted and requires parameter tuning; may increase computational work in large-scale problems though asymptotic complexity remains O(n).",
            "uuid": "e1985.0"
        },
        {
            "name_short": "DGEP-M",
            "name_full": "Dynamically Adjusted Mutation Operator (DGEP-M)",
            "brief_description": "A mutation-rate adaptation operator that raises or lowers mutation probability according to the trend in a fitness coefficient between generations, aiming to balance exploration and exploitation.",
            "citation_title": "here",
            "mention_or_use": "use",
            "operator_name": "Dynamically Adjusted Mutation Operator (DGEP-M)",
            "operator_type": "mutation",
            "operator_description": "Adjusts the per-generation mutation rate P_i within [P_min, P_max] according to the ratio of fitness coefficients F_i / F_{i-1}: if F_i &gt; F_{i-1} (population quality improving) set P_i = P_min; if equal keep P_i = P_{i-1}; if F_i &lt; F_{i-1} (degradation/stagnation) increase P_i (up to P_max). Reported parameter bounds: P_min=0.05, P_max=0.15.",
            "is_learned_or_adaptive": true,
            "learning_mechanism": "fitness-trend rule-based adaptation (dynamic heuristic using population fitness coefficient comparisons)",
            "operator_representation": "parameterized function / conditional rule (piecewise update based on fitness ratio)",
            "domain_type": "numerical optimization / symbolic regression",
            "context_dependent": true,
            "modality_specific": false,
            "compositional": false,
            "performance_metric": "R², RMSE, population diversity, escape-from-local-optima (generations), statistical significance (t-test, p-values)",
            "performance_learned_operator": "When used within DGEP the dynamic mutation contributed to aggregate improvements: average R² +15.7% vs standard GEP; P_min=0.05, P_max=0.15 used experimentally. Specific per-function improvements reported (e.g., F7 R² 0.915 for DGEP vs 0.876 for GEP).",
            "performance_fixed_operator": "Standard fixed-rate GEP (baseline) used: example mutation fixed in baseline led to lower diversity and worse R² (see examples above). Exact baseline mutation rate not stated in paper excerpt, but comparisons are provided numerically in aggregate.",
            "performance_improvement": "Paper attributes improved escape rate (35% higher) and increased diversity when DGEP-M is combined with DGEP-R; exact isolated effect of DGEP-M alone not fully separated in reported aggregates.",
            "has_comparison": true,
            "executability_preservation": null,
            "novelty_diversity_metric": "Same dg metric as DGEP-R; DGEP-M contributed to higher dg when combined in DGEP (aggregate 2.3× increase over GEP).",
            "transfer_learning": false,
            "transfer_results": null,
            "computational_cost": "O(n) per generation (same asymptotic complexity as standard GEP); only needs fitness coefficients and simple comparisons/updates, so low constant overhead.",
            "population_size": "100",
            "cold_start_addressed": false,
            "operator_specialization": null,
            "key_findings": "DGEP-M adaptively raises mutation when population fitness declines and reduces mutation when fitness improves, helping maintain diversity without disrupting elite solutions and improving overall search performance in symbolic regression tasks.",
            "limitations_or_failures": "Sensitivity to P_min/P_max bounds and fitness-coefficient calculations; when increased mutation occurs late in evolution it may destabilize convergence—authors note need for better mutation control strategies in some scenarios.",
            "uuid": "e1985.1"
        },
        {
            "name_short": "DGEP",
            "name_full": "Dynamic Gene Expression Programming (DGEP)",
            "brief_description": "A GEP variant combining DGEP-R (adaptive regeneration) and DGEP-M (adaptive mutation) to dynamically control genetic operator parameters using a fitness coefficient, improving diversity and global search.",
            "citation_title": "here",
            "mention_or_use": "use",
            "operator_name": "DGEP (combines DGEP-R and DGEP-M)",
            "operator_type": "hybrid (variation + mutation + selection integration)",
            "operator_description": "Integrates DGEP-R during selection (to inject new individuals based on regeneration rate) and DGEP-M after selection (to adapt mutation rate based on fitness trends), followed by standard transposition and recombination; both operators share the same fitness-coefficient metric Fi to reduce overhead.",
            "is_learned_or_adaptive": true,
            "learning_mechanism": "fitness-based adaptive heuristics (rule-based dynamic parameter control)",
            "operator_representation": "parameterized adaptive rules (analytic formulas and conditional updates)",
            "domain_type": "symbolic regression / numerical optimization",
            "context_dependent": true,
            "modality_specific": false,
            "compositional": true,
            "performance_metric": "R², RMSE, MSE, classification accuracy, population diversity (dg), escape-from-local-optima (generations), statistical significance (t-tests, p-values)",
            "performance_learned_operator": "DGEP outperformed standard GEP and other improved variants on benchmarks: average R² improvement 15.7%; aggregate population diversity increased by 2.3×; escape-from-local-optima improvement 35%; example Keijzer-10 RMSE improved from 0.092 (GEP) to 0.065 (DGEP) (29.3% reduction); F7 R²: GEP 0.876 -&gt; DGEP 0.915; F8 0.908 -&gt; 0.942.",
            "performance_fixed_operator": "Standard GEP baseline: reported values include R² 0.876 (F7), diversity F3 0.3322, Keijzer-10 RMSE 0.092, classification accuracy 78.5%, high-dim regression MSE 1.235; these are the fixed-operator baselines compared.",
            "performance_improvement": "Aggregate improvements reported: +15.7% R², 2.3× population diversity, 35% better escape-from-local-optima; specific per-task numbers given in paper (see performance_learned_operator).",
            "has_comparison": true,
            "executability_preservation": null,
            "novelty_diversity_metric": "dg = D / N; reported aggregate dg improvement from 1.0 to 2.3 (Table 6) and per-function dg examples (e.g., F3 DGEP 0.7449 vs GEP 0.3322).",
            "transfer_learning": false,
            "transfer_results": null,
            "computational_cost": "Asymptotic cost reported O(n) same as standard GEP; authors state no additional asymptotic cost though moderate constant overhead for dynamic adjustments.",
            "population_size": "100",
            "cold_start_addressed": false,
            "operator_specialization": null,
            "key_findings": "Combining adaptive regeneration and adaptive mutation controlled by a common fitness coefficient substantially improves symbolic regression performance, diversity, and the ability to escape local optima compared to standard GEP and several improved baselines.",
            "limitations_or_failures": "Requires careful hyperparameter tuning (mutation and regeneration bounds and α); sensitivity noted and authors recommend future automated calibration (e.g., reinforcement learning) and further validation on high-dimensional and real-world problems.",
            "uuid": "e1985.2"
        },
        {
            "name_short": "NMO-SARA",
            "name_full": "NMO-SARA (referenced improved GEP algorithm)",
            "brief_description": "A referenced improved GEP algorithm used as a baseline in experiments; described in the paper as a multi-objective evolutionary algorithm with neighborhood search aimed at enhancing local search capabilities.",
            "citation_title": "",
            "mention_or_use": "use",
            "operator_name": "NMO-SARA",
            "operator_type": "other / hybrid",
            "operator_description": "Mentioned as a multi-objective evolutionary algorithm with neighborhood search; paper uses it as a comparative baseline but does not provide internal operator mechanics or explicit parameterization within this text.",
            "is_learned_or_adaptive": null,
            "learning_mechanism": null,
            "operator_representation": null,
            "domain_type": "symbolic regression (used as baseline)",
            "context_dependent": null,
            "modality_specific": null,
            "compositional": null,
            "performance_metric": "Compared using same metrics as DGEP (fitness, R², diversity, escape capability); used in experimental comparisons.",
            "performance_learned_operator": null,
            "performance_fixed_operator": null,
            "performance_improvement": null,
            "has_comparison": true,
            "executability_preservation": null,
            "novelty_diversity_metric": null,
            "transfer_learning": false,
            "transfer_results": null,
            "computational_cost": null,
            "population_size": "100 (same experimental setup)",
            "cold_start_addressed": null,
            "operator_specialization": null,
            "key_findings": "Served as a baseline comparator; DGEP outperformed NMO-SARA on the reported symbolic regression benchmarks per aggregate metrics in the paper.",
            "limitations_or_failures": null,
            "uuid": "e1985.3"
        },
        {
            "name_short": "MS-GEP-A",
            "name_full": "MS-GEP-A (multi-strategy GEP variant A)",
            "brief_description": "A multi-strategy GEP improvement algorithm referenced and used as a baseline in experiments; combines strategies to boost search performance.",
            "citation_title": "",
            "mention_or_use": "use",
            "operator_name": "MS-GEP-A",
            "operator_type": "hybrid / multi-strategy",
            "operator_description": "Referenced as a multi-strategy enhanced GEP; the paper uses it as a comparative baseline but does not detail its internal operator representations in the provided text.",
            "is_learned_or_adaptive": null,
            "learning_mechanism": null,
            "operator_representation": null,
            "domain_type": "symbolic regression (used as baseline)",
            "context_dependent": null,
            "modality_specific": null,
            "compositional": null,
            "performance_metric": "Compared on R², diversity, escape-from-local-optima, RMSE etc.; included in experiments.",
            "performance_learned_operator": null,
            "performance_fixed_operator": null,
            "performance_improvement": null,
            "has_comparison": true,
            "executability_preservation": null,
            "novelty_diversity_metric": null,
            "transfer_learning": false,
            "transfer_results": null,
            "computational_cost": null,
            "population_size": "100 (same experimental setup)",
            "cold_start_addressed": null,
            "operator_specialization": null,
            "key_findings": "DGEP outperformed MS-GEP-A on reported benchmarks in aggregate metrics.",
            "limitations_or_failures": null,
            "uuid": "e1985.4"
        },
        {
            "name_short": "Adagep",
            "name_full": "Adagep - an adaptive gene expression programming algorithm",
            "brief_description": "An earlier adaptive GEP variant cited in related work that applies adaptive mechanisms to GEP operator parameters.",
            "citation_title": "Adagep-an adaptive gene expression programming algorithm",
            "mention_or_use": "mention",
            "operator_name": "Adagep",
            "operator_type": "other / adaptive",
            "operator_description": "Cited as an example of prior adaptive GEP work; paper does not provide internal details beyond citation.",
            "is_learned_or_adaptive": true,
            "learning_mechanism": null,
            "operator_representation": null,
            "domain_type": "symbolic regression / GEP applications (mentioned in related work)",
            "context_dependent": null,
            "modality_specific": null,
            "compositional": null,
            "performance_metric": null,
            "performance_learned_operator": null,
            "performance_fixed_operator": null,
            "performance_improvement": null,
            "has_comparison": false,
            "executability_preservation": null,
            "novelty_diversity_metric": null,
            "transfer_learning": false,
            "transfer_results": null,
            "computational_cost": null,
            "population_size": null,
            "cold_start_addressed": null,
            "operator_specialization": null,
            "key_findings": "Listed among prior adaptive/operator-improvement works motivating DGEP; no experimental data provided in this paper.",
            "limitations_or_failures": null,
            "uuid": "e1985.5"
        },
        {
            "name_short": "AB-GEP",
            "name_full": "AB-GEP: Adversarial bandit gene expression programming for symbolic regression",
            "brief_description": "A recent GEP variant that applies bandit/adversarial bandit techniques to GEP (cited in related work).",
            "citation_title": "AB-GEP: Adversarial bandit gene expression programming for symbolic regression",
            "mention_or_use": "mention",
            "operator_name": "AB-GEP",
            "operator_type": "other / adaptive (bandit-based)",
            "operator_description": "Cited as an example of adaptive operator selection using adversarial bandit ideas; the paper does not provide implementation details or experimental data for AB-GEP itself.",
            "is_learned_or_adaptive": true,
            "learning_mechanism": "bandit-based operator selection (implied by title/citation; not detailed in this paper)",
            "operator_representation": null,
            "domain_type": "symbolic regression",
            "context_dependent": null,
            "modality_specific": null,
            "compositional": null,
            "performance_metric": null,
            "performance_learned_operator": null,
            "performance_fixed_operator": null,
            "performance_improvement": null,
            "has_comparison": false,
            "executability_preservation": null,
            "novelty_diversity_metric": null,
            "transfer_learning": false,
            "transfer_results": null,
            "computational_cost": null,
            "population_size": null,
            "cold_start_addressed": null,
            "operator_specialization": null,
            "key_findings": "Mentioned as related adaptive-operator work; the current paper positions DGEP as complementary or alternative to such adaptive strategies.",
            "limitations_or_failures": null,
            "uuid": "e1985.6"
        },
        {
            "name_short": "Yuen2009",
            "name_full": "A genetic algorithm that adaptively mutates and never revisits",
            "brief_description": "A referenced genetic algorithm that applies adaptive mutation and mechanisms to avoid revisiting search points; cited in related work.",
            "citation_title": "A genetic algorithm that adaptively mutates and never revisits",
            "mention_or_use": "mention",
            "operator_name": "adaptive mutation (Yuen & Chow)",
            "operator_type": "mutation",
            "operator_description": "Cited as a prior example of adaptive mutation strategies that attempt to avoid revisiting previously explored solutions; details not reproduced in this paper.",
            "is_learned_or_adaptive": true,
            "learning_mechanism": null,
            "operator_representation": null,
            "domain_type": "general evolutionary optimization",
            "context_dependent": null,
            "modality_specific": null,
            "compositional": null,
            "performance_metric": null,
            "performance_learned_operator": null,
            "performance_fixed_operator": null,
            "performance_improvement": null,
            "has_comparison": false,
            "executability_preservation": null,
            "novelty_diversity_metric": null,
            "transfer_learning": false,
            "transfer_results": null,
            "computational_cost": null,
            "population_size": null,
            "cold_start_addressed": null,
            "operator_specialization": null,
            "key_findings": "Cited as historical adaptive-mutation work motivating adaptive operator research; no experimental details in this paper.",
            "limitations_or_failures": null,
            "uuid": "e1985.7"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Adagep-an adaptive gene expression programming algorithm",
            "rating": 2
        },
        {
            "paper_title": "AB-GEP: Adversarial bandit gene expression programming for symbolic regression",
            "rating": 2
        },
        {
            "paper_title": "A genetic algorithm that adaptively mutates and never revisits",
            "rating": 2
        },
        {
            "paper_title": "Enhancing gene expression programming based on space partition and jump for symbolic regression",
            "rating": 1
        },
        {
            "paper_title": "Dynamic population generation (DPGP)",
            "rating": 1
        }
    ],
    "cost": 0.01666175,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>A study of gene expression programming algorithm for dynamically adjusting the parameters of genetic operators
June 2, 2025</p>
<p>Kejia Liu 
Yiping Teng 0000-0002-5870-0646
Fang Liu </p>
<p>Sichuan University
CHINA</p>
<p>of Science</p>
<p>A study of gene expression programming algorithm for dynamically adjusting the parameters of genetic operators
June 2, 2025558E2540D99D4637CA0B026C1799AA4510.1371/journal.pone.0321711Received: January 7, 2025 Accepted: March 10, 2025
The fast developments in artificial intelligence together with evolutionary algorithms have not solved all the difficulties that Gene Expression Programming (GEP) encounters when maintaining population diversity and preventing premature convergence.Its restrictions block GEP from successfully handling high-dimensional along with complex optimization problems.This research develops Dynamic Gene Expression Programming (DGEP) as an algorithm to control genetic operators dynamically thus achieving improved global search with increased population diversity.The approach operates with two unique operators which include Adaptive Regeneration Operator (DGEP-R) and Dynamically Adjusted Mutation Operator (DGEP-M) to preserve diversity while maintaining exploration-exploitation balance during evolutionary search.An extensive evaluation of DGEP occurred through symbolic regression problem tests.The study employed traditional benchmark functions and conducted evaluations versus baselines Standard GEP, NMO-SARA, and MS-GEP-A to assess fitness outcomes, R² values, population diversification, and the avoidance of local optima.All key metric evaluations showed that DGEP beat standard GEP along with alternative improved variants.DGEP produced the optimal results for 8 benchmark functions that produced 15.7% better R² scores along with 2.3 × larger population diversity.The escape rate from local optima within DGEP reached 35% higher than what standard GEP could achieve.The DGEP model serves to enhance GEP performance through the effective maintenance of diversity and improved global search functions.The results indicate that adaptive genetic methods strengthen evolutionary procedures for solving complex problems effectively.</p>
<p>Introduction</p>
<p>Gene Expression Programming (GEP) [1,2] functions as an effective adaptive evolutionary algorithm because it applies unique genotype-to-phenotype mappings to address optimization problems characterized by high nonlinearity and multimodality with efficiency [3][4][5].GEP demonstrates its strength by offering efficient optimization strategies with highly interpretable models when solving problems in industrial process optimization [6][7][8] and intelligent manufacturing [9,10] as well as financial market prediction [11].The evolution encounters substantial issues that affect the performance of GEP algorithms despite their effective properties.The reduction of population variety combined with deteriorating global navigation ability makes GEP exhibit premature local optimization which reduces its effectiveness for complex realworld problems.</p>
<p>A wide range of improvement techniques for population diversity and search performance has been developed to advance GEP throughout recent years.Experts who focus on enhancing classic genetic operators [12][13][14][15] have developed adaptive system controls to modify operator parameters during evolution improving the exploration-exploitation equilibrium.The prevention of premature convergence combined with improved global searching capabilities is achieved through multiple diversity-maintaining strategies described in [16,17].GEP achieves its best results when integrated with reinforcement learning and particle swarm optimization in addition to similar techniques for optimizing high-dimensional complex search spaces according to research reports [18][19][20].Multi-objective GEP methods [15,21] also allow for the simultaneous optimization of conflicting objectives, expanding the applicability of GEP to more complex problem domains.</p>
<p>These methods have made significant progress in improving the performance of GEP, however, they still fail to overcome some fundamental issues.First, in the GEP algorithm, all offspring genotypes are directly or indirectly derived from the initial population.Although genetic operations such as mutation, crossover, and recombination introduce diversity into the population, once the genotypes in the evolutionary process become homogeneous, these methods struggle to effectively restore population diversity.Second, some methods attempt to adjust parameters based on fixed rules or predefined conditions, but they often lack the flexibility needed to dynamically adapt to the varying demands at different stages of evolution.</p>
<p>To overcome the limitations of existing GEP algorithms, this study introduces a novel approach, Dynamic Gene Expression Programming (DGEP), which introduces two genetic operators proposed in this paper: the Adaptive Regeneration Operator (DGEP-R) and the Dynamically Adjusted Mutation Operator (DGEP-M).This research developed novel operators that aim to solve traditional GEP weaknesses regarding global search and population diversity.We established DGEP-R to work during individual selection phases whereas DGEP-M operated after selection in genetic operations and maintained a supportive relation between the two operators.DGEP-R operates at evolutionary turning points to add new potential solutions that help increase diversity as well as exploration space during stagnant fitness phases.DGEPM regulates mutation rates according to the evolutionary development dynamics.The dynamic genetic operator mechanism of DGEP-M promotes fitness-based control of mutation frequency which creates a balanced search method that protects elite solutions but maintains population variety.Experimental tests on symbolic Competing interests: The authors have declared that no competing interests exist.</p>
<p>problems have verified that DGEP leads to superior performance compared to standard GEP and alternative advanced variants of GEP.DGEP demonstrated superior solution accuracy and diverse population maintenance while strengthening its ability to explore global search spaces according to experimental results.Our main work achievements consist of the following: 1.To enhance population diversity, we proposed an Adaptive Regeneration Operator (DGEP-R) by introducing new individuals at critical evolutionary stages and when fitness stagnates, achieving diversity maintenance, premature convergence prevention, and significant improvement of global search capability.</p>
<ol>
<li>
<p>To balance exploration and exploitation, we developed a Dynamically Adjusted Mutation Operator (DGEP-M) that modulates the mutation rate based on evolutionary progress.</p>
</li>
<li>
<p>Experiments on symbolic regression problems show that the proposed DGEP algorithm outperforms traditional and improved GEP algorithms in solution accuracy, population diversity, and global search capability.</p>
</li>
</ol>
<p>The Genetic Expression Programming methodology serves as a widely accepted solution for optimizing complex problems and symbol-based regressive modeling.The primary difficult with standard GEP algorithms involves deteriorating population diversity during evolution that generates early convergence thus limiting the algorithm's global space exploration.Over time genetic material within the population collects similar traits which prevents the discovery of optimal solutions.</p>
<p>GEP optimization receives enhancements through adaptive genetic operators while population control mechanisms and hybrid system optimization strategies work to tackle this issue.The methods also introduce performance problems when implemented in complex dynamic environments because they use fixed operational parameters and create extra processing requirements.This paper presents the Dynamic Gene Expression Programming (DGEP) algorithm that incorporates two innovative operators: Adaptive Regeneration Operator (DGEP-R) and Dynamically Adjusted Mutation Operator (DGEP-M).The operators use continuous fitness assessment of the population together with evolutionary monitoring to dynamically control genetic operations which both conserve diversity and boost exploration abilities as well as convergence speed.The dynamic adjustment of genetic parameters through DGEP improves both the GEP search ability and prevents premature convergence thus resulting in improved optimizers.</p>
<p>The second part of this work explores related studies which have improved the GEP algorithm.The third part defines the problem statement and presents the necessary background information.Section 4 details the implementation structure of the proposed DGEP algorithm.Section 5compares DGEP with standard GEP and other improved algorithms through experiments and analysis.Section 6 summarizes this work and presents future work.</p>
<p>Related work</p>
<p>Modern Gene Expression Programming research enables increased efficiency by following three major directions which involve: advanced genetic operator optimization and population diversity management as well as hybrid and multiobjective integration techniques.</p>
<p>Improving genetic operators</p>
<p>Research has actively worked to enhance standard GEP genetic operators including mutation crossover and recombination through several published works [14,15,17,22,23] to improve population diversity while stopping premature convergence.Evolutionary algorithms need these operators to perform exploration and exploitation operations harmoniously [9,[24][25][26].The evolutionary population state serves as a basis for adaptive genetic operator parameters [12,13,27,28] adjustment in implementations which include [10,11,29].The evolutionary stage maintains an equilibrium between exploratory and exploitative traits because of this mechanism.</p>
<p>Population diversity maintenance mechanisms</p>
<p>The research field of GEP now emphasizes sustaining population diversity during evolution.The implementation of different diversity preservation approaches through new selection methods is being researched.The Clonal Selection Algorithm (CLONALG) [30] draws its ideas from the immune system by applying data-like antigens.The algorithm shows better computational power and expression ability than conventional GEP approaches.MS-GEP-I manual intervention strategy actively implements outside measures when population diversity deteriorates or evolutionary stagnation happens [13].For instance, when no improvement in fitness is observed over several generations, individuals are randomly replaced, or the process reverts to parent or grandparent generations to alter the evolutionary trajectory and reinvigorate the search process.In addition, dynamic population generation (DPGP) [12] adjusts the population size dynamically during evolution to prevent the algorithm from becoming trapped in local optima and to maintain diversity.Modern engineering optimization problems have received enhancements through newly developed meta-heuristic algorithms in recent years.The Artificial Lemming Algorithm (ALA) uses Lemming's natural behaviors to resolve actual engineering optimization obstacles [31].Multi-Strategy Boosted Snow Ablation Optimizer (MSAO) represents an enhanced version of Snow Ablation Optimizer through its integration of multiple strategies which produces superior global optimization performance [32,33].The development of improved algorithms reflects the continuous research to enhance both the efficiency of evolutionary computation along its solution outcomes.</p>
<p>The field of genetic programming now benefits from newly developed adaptive processes together with hybrid optimization methods that enhance the speed of evolutionary search operations.Scientists have analyzed self-adaptive resource allocation in cloud computing as shown by [to prove how adaptable resource distribution optimizes operational efficiency.The wide range of real-world problems has been efficiently tackled by evolutionary algorithms in software engineering [34] while they also lead to improved solutions in manufacturing optimization [3] and predictive modeling [35].Evolutionary approaches for genetic programming identified as multi-objective optimization [35] enabled better management between exploration and exploitation.Research findings shed important light on genetic programming methodology evolution demonstrating that DGEP with adaptive regeneration and mutation functions represents an innovative search performance and convergence stability enhancement [36].</p>
<p>Hybrid and multi-objective methods</p>
<p>The combination of GEP optimization methods with alternative techniques has led to widespread research interest among experts during the recent period.Multiple research teams have exhibited the superiority of GEP when it merges with reinforcement learning (RL) [18], artificial neural networks (ANN) [19], and particle swarm optimization (PSO) [20] in various applications.These approaches demonstrate effectiveness when handling difficult problems with extensive search spaces that have multiple local solutions.</p>
<p>Multi-objective optimization strategies now form an integral part of GEP to run simultaneous optimization of multiple competing objectives.Remarkable model interpretation results were produced by multi-objective GEP [15] during symbolic regression because it managed to balance model accuracy with simplicity while maintaining high-performance numbers.The NSGAII [21] determines how to find acceptable solution clusters during multi-objective design operations which result in Pareto-optimal solutions.GEP has been found suitable for solving high-dimensional nonlinear problems while handling multiple conflicting objectives by various research studies.</p>
<p>Limitations analysis</p>
<p>These improvement methods for GEP demonstrate valuable performance enhancements yet their usage comes with various specific restrictions.</p>
<p>(1) Limitations in Improvement Population Diversity: By adjusting the population size, reverting to earlier genetic populations, or optimally tuning genetic operator parameters, these methods ultimately evolve based on the initial population.When the initial population lacks diversity, these approaches struggle to significantly enhance diversity during the evolutionary process, making it difficult to prevent the population from converging to the local optima.</p>
<p>(2) Increased Time and Space Complexity: Improved GEP algorithms often rely on more complex data structures and computational procedures, which inevitably increases the time and space complexity of the algorithm.While these methods enhance search efficiency and solution quality, they also introduce additional computational and storage overheads.</p>
<p>(3) Parameter Sensitivity: Many improved GEP algorithms introduce additional parameters (e.g., the number of subspaces and jump thresholds), and the performance of the algorithm is highly sensitive to the settings of these parameters.Inappropriate configurations can lead to significant performance degradation, and the tuning and optimization of these parameters can be complex and time-consuming.</p>
<p>Problem definition and preliminaries</p>
<p>Problem definition</p>
<p>Table 1 summarizes the primary symbols used in this section, providing a clearer understanding of these definitions and their roles in the algorithm.Definition 1. Search Space and Objective Function: The GEP algorithm aims to determine a globally optimal solution x * within the search space S ⊆ R n .The goal is to minimize (or maximize) an objective function f(x):
x * = arg min x∈S f(x) or x * = arg max x∈S f(x)(1)
The search space S contains all possible solutions, and the objective function f(x) determines the value to be optimized for each candidate solution x .</p>
<p>Definition 2. Population and Genotype: In generation t, a population P t contains N individuals, where each individual is represented by a genotype g(x).A genotype refers to the underlying structure of an individual solution that is subject to genetic operations (such as mutation or crossover) to evolve.Definition 3. Population Diversity and Variance: The diversity of the population is defined by the variance in the genotypes of individuals in generation t.Let Var(g(x t )) represent this variance, calculated as:
Var(g(x t )) = 1 n ∑ N I=1 ( g (x i,t ) -g (x t ) ) 2(2)
where g (x t ) represents the mean genotype of the population in generation t.As the number of generations increases, the population tends to converge towards higher-fitness individuals.Although genetic operations (such as mutation and crossover) introduce some degree of random variation among individuals, they often fail to generate significantly different offspring, leading to a decrease in the genotype variance:
(g (x t )) = 0(3)
This reflects the loss of population diversity, which limits exploration and increases the risk of becoming trapped in the local optima.Definition 4. Fitness Coefficient: The fitness coefficient F i is used to assess both the diversity and quality of the population by combining the average, maximum, and minimum fitness levels within the population.It is defined as:
F i = 2 f ave f max + f min (4)
where f ave is the average fitness, f max is the highest fitness, and f min is the lowest fitness.This metric effectively reflects both the range and concentration of fitness values, offering insight into the diversity and potential convergence of a population.</p>
<p>The decline in population diversity is considered a critical problem that limits the global search capability of traditional GEP algorithms.As highlighted in Definition 3, the genotype variance tends to decrease as generations progress, leading to a homogeneous population and a reduced ability to explore the search space.This problem is compounded by the fixed nature of the genetic operator parameters (e.g., mutation and crossover rates) across generations, which may not adequately balance exploration (promoting diversity) and exploitation (focusing on high-quality individuals).</p>
<p>Thus, the two primary problems addressed in this research are:</p>
<p>• Declining Population Diversity: As noted, population diversity decreases owing to the selection process favoring individuals with higher fitness.This reduces the ability of the algorithm to explore new areas of the search thereby increasing the risk of convergence to the local optima.</p>
<p>• Lack of Adaptive Parameter Tuning: Fixed genetic operator parameters fail to adapt to changing evolutionary dynamics.In the early generations, higher mutation rates may be necessary to promote diversity, whereas in the later generations, lower mutation rates are preferable to avoid disrupting high-quality solutions.Hence, a dynamic adjustment mechanism for operator parameters is necessary to maintain an optimal balance between exploration and exploitation.</p>
<p>Notation Definition</p>
<p>S</p>
<p>The search space, which is the set of solutions explored by the GEP algorithm.It is a subset that contains all possible solutions.</p>
<p>R n</p>
<p>The n-dimensional solutions space,</p>
<p>x * The globally optimal solution
f(x)
The objective function, which is the target value for optimization (minimization or maximization) t</p>
<p>The evolutionary generation, indicating the number of generations in the evolutionary process
g (x t )
The genotype of an individual at generation t
Var (g (x t ))
The variance of the genotypes, representing the degree of variation in genotypes within the population at generation t
Var (g (x t )) f ave f max f min Fi α G i i G R min R max R i P min P max P i
The variance of the genotypes, representing the degree of variation in genotypes within the population at generation t The average fitness of the population The highest fitness value in the population The lowest fitness value in the population The fitness coefficient, reflecting the fitness distribution in the population The correction factor, controlling sensitivity of individual fitness and evolutionary progress to the respawning rate effect The total number of evolutionary generations The number of current evolutionary generations The evolutionary generation factor, representing how close the population is to the total number of generations The lower limit of the adaptive regeneration rate The upper limit of the adaptive regeneration rate The i-th generation adaptive regeneration rate The lower limit of the dynamically adjusted mutation rate The upper limit of the dynamically adjusted mutation rate The i-th generation dynamically adjusted mutation rate https://doi.org/10.1371/journal.pone.0321711.t001</p>
<p>Preliminaries</p>
<p>To address these challenges, we propose two key innovations: an adaptive regeneration operator and a dynamic mutation operator.These operators are dynamically adjusted based on the fitness coefficient F i , which provides a simple yet effective measure of the population state.Definition 5. Adaptive Regeneration Operator: The adaptive regeneration operator introduces entirely new individuals into the population, rather than relying on selection from previous generations, to maintain diversity.The regeneration rate R i is defined as:
R i = R min + (R max -R min ) × exp <a href="5"> -α × F i × i G </a>
where R min and R max represent the minimum and maximum regeneration rates, α is a scaling factor, and G is the total number of generations.This operator promotes exploration in the early stages by generating more new individuals and reduces exploration in the later stages as the population converges.Definition 6. Dynamic Mutation Operator: The mutation operator has the most significant impact on population diversity among all the genetic operators [37].To dynamically adjust the mutation rate, we define P i as:
P i = [P min F i F i-1 &gt; 1, P i-1 F i F i-1 = 1, F i-1 F i × P i-1 , P max , F i F i-1 &lt; 1(6)
The fitness coefficients F i and F i-1 reflect the current and previous generations' quality.The ratio F i-1 F i allows for an evaluation of the evolutionary trend: &gt; 1, this indicates that the fitness coefficient of the current population has increased compared with that of the previous generation, implying an increase in the proportion of high-fitness individuals and a reduction in low-fitness individuals.In this case, the algorithm favors exploitation and reduces the mutation rate to avoid disrupting high-quality individuals.
• When F i-1 F i
• When F i-1 F i = 1, this indicates stability in population quality.Therefore, maintaining the current mutation rate is a reasonable choice.</p>
<p>• When F i-1 F i &lt; 1, the fitness coefficient decreases, implying a population degradation.In this case, increasing the mutation rate helps boost diversity, encouraging further exploration of the search space to escape local optima and improve population quality.</p>
<p>Mathematical analysis of DGEP's genetic search efficiency</p>
<p>The effectiveness of DGEP in improving genetic search efficiency is supported by a detailed mathematical derivation that highlights its advantages over standard GEP.The core improvements stem from population diversity enhancement, adaptive mutation rate adjustments, and improved convergence properties, all of which contribute to a more robust exploration-exploitation balance.</p>
<p>To quantify how DGEP-R enhances population diversity, we redefine genotypic variance using a diversity coefficient D t , computed as:
D t = 1 N ∑ N i=1 (g i -g)) 2(7)
where g i represents the genotype of individual i in generation t, g is the mean genotype, and N is the population size.The Adaptive Regeneration Operator (DGEP-R) prevents diversity loss by reintroducing individuals with new genetic structures at stagnation points, thereby maintaining a stable and high D t value across generations.This controlled diversity prevents premature convergence by ensuring that genetic novelty persists in the population.The Dynamically Adjusted Mutation Operator (DGEP-M) modifies mutation rates based on fitness trends, which can be described by the probability of mutation P m (t) at generation t: P m (t) = P min + (P max -P min ).</p>
<p>(
- F t F t-1 )1
where P min and P max are the lower and upper mutation bounds, respectively, and F t represents the population fitness coefficient.This equation ensures that mutation increases when population fitness stagnates or decreases, promoting exploration, and decreases when fitness improves, ensuring the stability of high-quality solutions.</p>
<p>To establish DGEP's improved convergence properties, we analyze the probability of escaping local optima, denoted as P escape .Given that higher mutation rates increase the probability of escaping suboptimal regions, DGEP dynamically adjusts this probability using:
P escape = 1 -(1 -P m (t)) κ (9)
where κ stands for mutation events that occur in each generation.An adaptive P m (t) control in DGEP allows the algorithm to preserve high global search ability without decreasing performance through random consequences.Digital Gene Expression Programming posits better exploration capabilities than basic GEP through its ability to maintain computational effectiveness.DGEP-M and DGEP-R together achieve perfect parameter tuning that balances population diversity levels and solution optimization performance although static GEP parameters cannot achieve such balance.</p>
<p>Gene expression programming algorithm for dynamically adjusting genetic operator parameters (DGEP)</p>
<p>We present DGEP as a dynamically adjusted genetic operator parameter GEP algorithm containing adaptive regeneration operator (DGEP-R) and dynamically adjusted mutation operator (DGEP-M).</p>
<p>DGEP-R: Adaptive regeneration operator</p>
<p>The Adaptive Regeneration Operator (DGEP-R) stands as our developed genetic operator used to manage population diversity during GEP algorithm evolutions.The DGEP-R approach introduces new individuals dynamically into the population according to evolutionary status together with their current fitness evaluation.These new individuals were generated with unique genotypes, independent of the initial population, thus significantly enhancing the diversity of the population.</p>
<p>The core design principle of the DGEP-R algorithm is as follows: during the early stages of evolution or when the fitness coefficient is low, the regeneration rate of individuals increases, introducing more new individuals to enhance population diversity, expanding the search space, and improving the likelihood of escaping local optima.In the later stages of evolution or when the fitness coefficient is higher, the regeneration rate gradually decreases, allowing the population to focus on searching for better solutions near the current ones, thereby improving the algorithm's convergence efficiency.</p>
<p>Algorithm 1: DGEP -R Algorithm</p>
<p>Input: Population size n, Maximum generations G; Fitness list of the population individuals f , Current generation i , Population old Population Output: newPopulation 1 f ave ← 1 n ∑ n j=1 f j ;// Calculate the average fitness of the population 2 f max ← max(f); // Find the highest fitness in the population 3 f min ← min(f); // Find the lowest fitness in the population 4 F i ← 2fave fmax+fmin ;// Compute the fitness coefficient The DGEP-R algorithm, as described in Algorithm 1, operates as follows: Initially, it calculates the average fitness (f ave ), the highest fitness (f max ), and the lowest fitness (f min ), as shown in lines 1-3 of the algorithm.From these, the fitness coefficient F i is derived to assess population diversity, as shown in line 4 of the algorithm.The regeneration rate R 2 i is then dynamically adjusted based on F i , allowing the generation of new individuals, as shown in line 5 of the algorithm.Currently, some individuals are selected from the previous generation according to their fitness, as seen in lines 8-10 of the algorithm.The final population is a combination of both new and selected individuals, as shown in line 14 of the algorithm.To enhance the algorithm's global search capability, we propose the Dynamically Adjusted Mutation Operator (DGEPM).Unlike fixed mutation rates in traditional GEP algorithms, DGEP-M adjusts mutation rates in real time according to the evolutionary state, maintaining diversity while improving convergence speed and solution quality, effectively avoiding local optima.Furthermore, by sharing the parameter of the fitness coefficient with DGEP-R, DGEP-M reduces the computational complexity compared to other improved GEP algorithms, increasing efficiency in practical applications.
5 R i ← R min + (R max -R min ) × exp(-α × F i × i G ); //</p>
<p>DGEP-M: Dynamically adjusted mutation operator</p>
<p>The DGEP-M algorithm introduces a strategy for dynamically adjusting mutation operator parameters: When the fitness coefficient factor F i F i-1 = 1 is greater than 1, it indicates an improvement in population fitness compared to the previous generation, which indicates an improvement in individual quality.In this case, the mutation rate was set to the lower limit, reducing the likelihood of damage to high-quality individuals.Individuals with a higher fitness evolve at a relatively lower mutation rate, ensuring the preservation of the best-performing individuals.When the coefficient factor was equal to one, the mutation rate remained unchanged, reflecting a stable evolution.</p>
<p>When the coefficient factor is less than one, it suggests a decline in population fitness and individual quality.Thus, the mutation rate was increased to enhance both the individual quality and population diversity.</p>
<p>As shown in Algorithm 2, the DGEP-M process dynamically adjusts the mutation rate P i based on changes in the fitness coefficient, as indicated in lines 1-7 of the algorithm.The algorithm compares the current and previous-generation</p>
<p>fitness coefficients F i and F
i-1 . If F i F i-1 &gt; 1,
which indicates an improvement in fitness, a lower mutation rate P i = P min is set to protect high-quality individuals.If F i F i-1 = 1, the mutation rate remains the same, that is,
P i = P i-1 . If F i F i-1 &lt; 1,
the mutation rate is increased to enhance the diversity.Finally, the number of mutations was calculated, and the mutation operation was applied to generate a new population, as shown in lines 8-9 of the algorithm.</p>
<p>Algorithm 2: DGEP -M Algorithm</p>
<p>DGEP algorithm</p>
<p>The DGEP algorithm comprehensively enhances the traditional GEP framework by integrating both DGEP-R and DGEPM operators to leverage the unique advantages of each.DGEPR and DGEP-M target different stages of the GEP algorithm, allowing them to function in tandem without interference.Specifically, DGEP-R was applied during the selection phase, introducing new individuals to diversify the population and strengthen exploration capabilities.After the selection stage, DGEP-M is applied during the genetic operations phase, dynamically adjusting the mutation rates to balance exploration and exploitation according to the evolution of the population.The combination of these two strategies enhances the global search capabilities and reduces the risk of premature convergence.Importantly, both DGEP-R and DGEP-M were designed to be seamlessly integrated into the standard GEP framework with minimal structura modifications, ensuring high compatibility and ease of implementation.This compatibility makes DGEP an ideal choice for improving the existing GEP algorithms.</p>
<p>Algorithm 3: DGEP Algorithm</p>
<p>Input: Population size n, Maximum generations G ; Output: Optimal solution 1 population ← initializePopulation();// Initialize the population 2 for i← 1 to G do 3 evaluateFitness(population);//Evaluate the fitness of the population 4 bestChromosome ← saveBestChromosome(population);// Save the chromosome with the best fitness 5 if is StoppingCriteriaMet(population) then// Check if the stopping criteria is met 6 end for 7 else 8 newPopulation ← DGEP -R(population);// Apply DGEP-R operator 9 newPopulation ← DGEP -M(newPopulation );// Apply DGEP-M operator 10 newPopulation ← transposition(newPopulation);// Apply transposition operator 11 newPopulation ← recombination(newPopulation);// Apply recombination operator 12 population ← newPopulation 13 end if 14 end for 15 return bestChromosome;// Return the optimal solution As illustrated in Algorithm 3, the DGEP algorithm follows this process: 1. Initialize the population, evaluate its fitness, and save the chromosome with the highest fitness (Line 1-4).</p>
<ol>
<li>
<p>If the stopping criteria are satisfied, the algorithm terminates.Otherwise, the DGEP-R, DGEP-M, transposition, and recombination operators are sequentially applied to generate a new population (Line 8-12).</p>
</li>
<li>
<p>This is repeated until the stopping criteria are satisfied, and the best chromosome is returned as the optimal solution (Line 15).</p>
</li>
</ol>
<p>Computational complexity analysis</p>
<p>The DGEP algorithm integrates the DGEP-R and DGEP-M operators, combining their respective advantages to enhance evolutionary performance.Since both DGEP-R and DGEPM maintain a time and space complexity of O(n), the overall complexity of the DGEP algorithm also remains O(n), without introducing any significant increase compared to the traditional GEP algorithm.This ensures that DGEP preserves computational efficiency while incorporating advanced genetic strategies.</p>
<p>Adaptive regeneration operator (DGEP-R).</p>
<p>• Time Complexity: The of the DGEP-R strategy involves dynamically introducing new individuals based on population fitness and evolutionary progress.This requires calculating the average fitness f ave , highest fitness f max , and lowest fitness f min for the population at each generation, followed by computing the regeneration rate R i using Definition 5.The computational complexity of these operations depends primarily on the population size n, the complexity of calculating the fitness-related parameters is O(n), and the process of introducing new individuals scales linearly.Therefore, the time complexity of DGEPR for each generation is O(n).</p>
<p>• Space Complexity: Although DGEP-R increases population diversity by introducing new individuals, the total population size n remains constant.Therefore, the space complexity of DGEP-R is unchanged compared with that of the standard GEP algorithm and remains O(n).</p>
<p>Dynamically adjusted mutation operator (DGEP-M).</p>
<p>• Time Complexity: The DGEP-M strategy dynamically adjusts the mutation rate based on the fitness coefficients of the current and previous generations.This requires calculating the fitness coefficients for each generation and adjusting the mutation rate accordingly.As these calculations are based on known fitness values and involve simple multiplication and comparison operations, the complexity of each individual was O (1).Consequently, the overall time complexity of the population is O(n).</p>
<p>• Space Complexity: DGEP-M involves adjusting the mutation rate, which requires no additional storage space, utilizing only the existing population and fitness information.Therefore, the space complexity remains O(n), which is the same as that of the standard GEP algorithm.</p>
<p>Experiments and analysis</p>
<p>We designed a set of experiments for symbolic regression problems to verify the effectiveness of new operators.To evaluate the adaptive regeneration operator DGEP-R, the dynamically adjusted mutation operator DGEP-M, and the DGEP algorithm proposed in this paper, we developed several improved GEP algorithms for comparative experiments.We evaluated the performance of the new operators by problem solution quality, population diversity, and the ability of the algorithms to detach from local optimal solutions.5.1.2Experimental parameters.In the experiment, the basic parameters for all the algorithms were configured according to the data specified in Table 2.The parameters of the adaptive regeneration operator for the DGEP-R and DGEP algorithms were set as follows: R max = 0.15, R min = 0.05.The parameters of the dynamically adjusted mutation operator for the DGEP-M and DGEP algorithms were set to: P max = 0.15, P min = 0.05.</p>
<p>To ensure the optimal selection of parameter values in Table 2, we conducted a parameter sensitivity analysis by systematically varying key parameters such as population size, mutation rates, regeneration rates, and recombination/transposition probabilities.The results demonstrated that a population size of 100 maintained a balance between diversity and computational efficiency, while mutation rates (P min = 0.05, P max = 0.15) and regeneration rates (R min = 0.05, R max = 0.15) provided the best trade-off between exploration and exploitation.Excessively high recombination and transposition rates led to instability, reinforcing the chosen values.These parameter settings were determined based on multiple benchmark tests to optimize solution accuracy, convergence speed, and population diversity.</p>
<p>Related algorithms.</p>
<p>To comprehensively evaluate the performance of the new operators DGEP-R, DGEP-M, and DGEP, we developed several comparison algorithms, including:</p>
<p>• Standard GEP [16]: The basic gene expression programming algorithm was used as a baseline for comparison with improved algorithms.</p>
<p>• NMO-SARA [12]: A multi-objective evolutionary algorithm with neighborhood search, aimed at enhancing local search capabilities.</p>
<p>• MS-GEP-A [13]: A GEP improvement algorithm based on multiple strategies, combining various approaches to boost search performance.</p>
<p>These comparison experiments allow us to better assess the improvements introduced by the new algorithms in various respects.</p>
<p>Test functions.</p>
<p>We used a set of test functions from [13], which were mainly based on the test functions in Keijzer [14], Nguyen [15] and Koza [22].The test samples were generated using ten sets of test functions.The test functions are presented in Table 3.To obtain accurate comparison results between different algorithms, each algorithm was run independently ten times on each test function, and then the average value was taken as the performance metric of that algorithm to avoid random bias.</p>
<p>5.1.5Evaluation metrics.The solution to symbolic regression problems was evaluated using four essential assessment metrics during this experimental analysis [38].The established metric system demonstrates a single benchmark for algorithm assessment while it demonstrates DGEP's superiority regarding solution quality along with its additional benefits of diverse populations and wide-scale exploration.</p>
<p>Definition 8. Fitness: The solution quality of all problems depends directly on fitness which functions as a primary evaluation factor in evolutionary algorithms.A symbolic regression model achieves its fitness score by measuring the difference between its computational output and the actual target function output.The model holds superior solution quality when its fitness value reaches elevated levels for achieving optimal agreement with the target functions.</p>
<p>The fitness calculation formula is as follows:
Fitness = f (x) = ∑ n i=1 (y i -ŷi ) 2(10)
where y i is the actual output of the target function; ∘y i is the model output; and n is the number of data points.The smaller the difference, the higher is the fitness and performance of the algorithm.Definition 9. R-squared (R 2 ): R-squared (R 2 ) is a statistical measure that evaluates the goodness-of-fit of a regression model, indicating the variance in the dependent variable explained by the model.The value of R 2 ranged from 0 to 1, with values closer to 1 indicating better model performance and accuracy.</p>
<p>The formula for R 2 is:
R 2 = 1 - ∑ (y i -ŷi ) 2 ∑ (y i -y) 2(11)
where y i is the actual value, ŷ is the predicted value, and y is the mean of the target value.The closer R 2 is to 1, the better the fit of the model to the data.Definition 10.Population Diversity (dg): Population diversity measures the degree of variation among individuals in a population and is critical for maintaining the global search capability of the algorithm.A higher diversity means that the population contains more varied solutions, thereby increasing the probability of finding the global optimum.
1 x 6 + x 5 + x 4 + x 3 + x 2 + x [-1,1] 2 x 5 -2x 3 + x [-1,
The diversity metric dg is defined as:
dg = D N (12)
where N is the number of individuals in the population and D is the number of individuals with different fitness values.For example, if 100 individuals produced 70 different fitness values, the diversity score would be 0.7.Definition 11.Ability to Escape Local Optima: Local optima refer to suboptimal solutions in which the algorithm may become trapped, thereby preventing it from finding the global optimum.We measured the ability of algorithms to escape local optima based on the number of evolutionary generations required to find the best chromosome.The greater the number of generations required, the better the ability of the algorithm to continue exploring new subspaces and escape local optima, leading to better final solutions.</p>
<p>Using these four-evaluation metrics, we can quantitatively assess the improvements that DGEP brings to the different aspects of the algorithm's performance.The R-squared values across functions were higher for the DGEP algorithms, particularly for complex functions such as F7 (Fig 3(c)), F9, and F10 (Fig 3(c)).This indicates that the DGEP algorithms have better predictive capability and model fit than GEP and other algorithms.DGEP outperforms in terms of R-square, notably in F7 and F8, where GEP has values of 0.876 and 0.908, respectively, but DGEP achieves 0.915 and 0.942, which shows better predictive accuracy.</p>
<p>Experimental results</p>
<p>Mining Capacity</p>
<p>Population diversity. Fig 4 demonstrates</p>
<p>that DGEP and DGEP-R show higher population diversity than the standard GEP.This is critical for ensuring that the algorithms do not converge prematurely and that they can explore a wider solution space.DGEP demonstrates better population diversity maintenance, especially in challenging cases such as F3 (DGEP: 0.7449, GEP: 0.3322), indicating that DGEP has significantly higher diversity and avoids premature convergence better than GEP.higher values for the number of generations taken to escape the local optima.This is a crucial metric for avoiding stagnation in evolutionary algorithms.In F7, DGEP achieves the highest value (5060.1),demonstrating that it can effectively continue exploring new subspaces even after many generations, whereas GEP exhibits a lower value (3262.7).</p>
<p>The results indicate that DGEP achieved a 4.4% improvement in R² score for symbolic regression, a 29.3% reduction in RMSE for function approximation, an 8.6% increase in classification accuracy, and a 23.7% reduction in mean squared error (MSE) in high-dimensional regression.These findings confirm that DGEP's dynamic parameter adjustments enhance solution accuracy, convergence stability, and search efficiency across diverse problem spaces.Table 4 presents the extended benchmarking of DGEP across diverse problem domains.The improvements of the proposed DGEP algorithm over standard GEP are evident in population diversity, optimization accuracy, and the ability to escape local optima while maintaining computational efficiency.The Adaptive Regeneration Operator (DGEP-R) enhances diversity by introducing new individuals at critical points, ensuring that stagnation does not occur.The Dynamically Adjusted Mutation Operator (DGEP-M) effectively balances exploration and exploitation by modifying the mutation rate based on fitness trends.DGEP outperformed standard GEP in 8 out of 10 benchmark functions, with an average fitness improvement of 15.7% (R² score) and a 2.3 × increase in population diversity, as shown in Table 6.Furthermore, DGEP demonstrated a 35% improvement in escaping local optima, ensuring better convergence to the global optimum without excessive computational overhead.</p>
<p>Reported results are statistically significant and not due to random variations.A paired t-test was performed on 30 independent runs per benchmark function, and mean, standard deviation, confidence intervals, and p-values were computed.The results indicate that DGEP consistently outperforms Standard GEP across all tested domains, with statistically significant differences in most cases (p &lt; 0.05).</p>
<p>The mean ± standard deviation analysis shows that DGEP achieves a higher R² score in symbolic regression, lower RMSE in function approximation, higher accuracy in classification tasks, and lower mean squared error in highdimensional regression.The t-statistics further confirm that the observed differences are statistically meaningful.The statistical analysis of DGEP and standard GEP summarized in Table 5.</p>
<p>The p-values indicate that DGEP's improvements are statistically significant (p &lt; 0.05) in all cases, confirming that the enhancements observed are not due to random chance but are a direct result of DGEP's adaptive strategies.Table 6 presents the comparison of standard GEP and DGEP.The computational performance of DGEP remains strong with additional benefits from better diversity and convergence results.The research validates dynamic genetic operator modification as an effective method to build a superior evolutionary algorithm.</p>
<p>Conclusions and future work</p>
<p>The enhanced version of the GEP algorithm named DGEP was proposed to extend the traditional approach through dynamic genetic operator parameters adjustment which enhances population diversity metrics alongside improving search speed and global solutions discovery.The Adaptive Regeneration Operator (DGEP-R) together with the DGEP-M helps standard GEP perform better exploration along with exploitation capabilities.The experimental findings showed that DGEP surpassed baseline GEP models together with other advanced variants in symbolic regression tasks since it delivered better fitness accuracy and better population diversity with improved convergence properties.</p>
<p>The improved features of DGEP require attention because they present some implementation obstacles.The algorithm keeps O(n) complexity but the computational burdens increase moderately due to dynamic operator adjustments when working on big-scale problems.The performance of DGEP requires precise adjustments in mutation rates and regeneration settings because these adjustments make it sensitive to hyperparameters.Our parameter sensitivity analysis yielded optimal results yet an automatic parameter calibration system would supply additional generalization capabilities to the system.DGEP has shown success on symbolic regression tests yet researchers need additional assessments to determine its effectiveness for optimizing problems involving large numbers of dimensions or real-world applications.The stability of DGEP in dynamic environments remains questionable when mutation rates are increased during later generations thereby requiring better mutation control strategies.</p>
<p>Future investigations should research adaptive control methods of hyperparameters using reinforcement learning or evolutionary strategies so DGEP achieves better performance results.The combination of DGEP with neural networks and swarm intelligence as well as reinforcement learning methods would enhance the optimization performance by improving search speed and convergence speed while making the approach suitable for complex problem domains.The study must examine how well DGEP scales for large high-dimensional optimization challenges especially when working with simultaneous multiple goals alongside time-sensitive adapting components.Additional research must confirm how effectively DGEP achieves results in biological, financial, and industrial enterprise optimization through real-world tests versus current evolutionary optimized systems.The resolution of these present obstacles will transform DGEP into an improved framework for solving real-world as well as high-dimensional optimization tasks.</p>
<p>Fig 1
1
Fig 1 illustrates the workflow of the Dynamic Gene Expression Programming (DGEP) algorithm, highlighting the integration of the Adaptive Regeneration Operator (DGEP-R) and Dynamically Adjusted Mutation Operator (DGEP-M) within the evolutionary cycle.The process begins with population initialization, followed by fitness evaluation.If the stopping criteria are met, the algorithm terminates; otherwise, DGEP-R introduces new individuals when diversity stagnates, ensuring a more explorative search.Next, DGEP-M dynamically adjusts the mutation rate based on fitness progression, allowing the algorithm to balance exploration (high mutation) and exploitation (low mutation).To enhance the algorithm's global search capability, we propose the Dynamically Adjusted Mutation Operator (DGEPM).Unlike fixed mutation rates in traditional GEP algorithms, DGEP-M adjusts mutation rates in real time according to the evolutionary state, maintaining diversity while improving convergence speed and solution quality, effectively avoiding local optima.Furthermore, by sharing the parameter of the fitness coefficient with DGEP-R, DGEP-M reduces the computational complexity compared to other improved GEP algorithms, increasing efficiency in practical applications.The DGEP-M algorithm introduces a strategy for dynamically adjusting mutation operator parameters: When the fitness coefficient factor F i F i-1 = 1 is greater than 1, it indicates an improvement in population fitness compared to the previous generation, which indicates an improvement in individual quality.In this case, the mutation rate was set to the lower limit, reducing the likelihood of damage to high-quality individuals.Individuals with a higher fitness evolve at a relatively lower mutation rate, ensuring the preservation of the best-performing individuals.When the coefficient factor was equal to one, the mutation rate remained unchanged, reflecting a stable evolution.When the coefficient factor is less than one, it suggests a decline in population fitness and individual quality.Thus, the mutation rate was increased to enhance both the individual quality and population diversity.As shown in Algorithm 2, the DGEP-M process dynamically adjusts the mutation rate P i based on changes in the fitness coefficient, as indicated in lines 1-7 of the algorithm.The algorithm compares the current and previous-generation</p>
<p>Fig 1 .
1
Fig 1. Flowchart of the DGEP process.https://doi.org/10.1371/journal.pone.0321711.g001</p>
<ol>
<li>1 setup 5 . 1 . 1
1511
Experimental Experimental environment.All algorithms in the experiments were developed by.NET Framework/C# 4.6.1 and run on a PC with Intel(R) Core (TM) i7-8685U 2.11 GHz CPU, 16.0 GB RAM, and Windows 11 professional sp2.</li>
</ol>
<p>.</p>
<p>The DGEP algorithms (DGEP-R, DGEP-M, and DGEP) consistently outperformed the standard GEP and other improved algorithms (NMO-SARA and MS-GEP-A).Notably, DGEP achieved the highest fitness values across most functions, with significant advantages for functions F2 and F3 (Fig 2(a), F5, and F6 (Fig 2(b)).In complex functions, such as F7 (Fig 2(c)) and F9 (Fig 2(c)), DGEP maintains a superior solution quality, highlighting its effectiveness.</p>
<p>Fig 2 .
2
Fig 2. Fitness comparison on test function.https://doi.org/10.1371/journal.pone.0321711.g002</p>
<p>Fig 3 .Fig 4 .
34
Fig 3. R-squared comparison of test function.https://doi.org/10.1371/journal.pone.0321711.g003</p>
<p>Fig 5 .
5
Fig 5. Comparison of the ability to escape local optima.https://doi.org/10.1371/journal.pone.0321711.g005</p>
<p>Table 1 . Summary of the notations.
1</p>
<p>Calculate the adaptive regeneration operator 6 n new ← R i × n;// Calculate the number of new individuals 7 n select ← n -n new ;// Calculate the number of individuals selected from the previous generation 8 for j← 1 to n new do
9 newPopulation ← GenerateIndividuals(); 10 end for 11 for j← 1 to n select do 12 selectPopulation ← SelectIndividuals(p, f) 13 end for 14 newPopulation ← newPopulation + selectPopulation; 15 return newPopulation;</p>
<p>Population size n, Maximum generations G , Current generation g , The current generation fitness coefficient F g , The previous generation fitness coefficient F g-1 , Population oldPopulation Fg × P g-1 , P max ) 7 end if 7 n mutate ← P g × n;// Calculate the number of mutate individuals 8 newPopulation ← Mutate (oldPopulation, n mutate ) ; 10 return newPopulation;
Output: newPopulation 1 if Fg Fg-1 &gt; 1 then 2 P g ← P min ; Fg Fg-1 = 1 then 3 else if 4 P g ← P g-1 ; 5 else 6 P g ( Fg-1
Input:</p>
<p>Table 2 . Basic parameters of the algorithm in the experiment.
2ParametersPopulation size100Number of genes3Head length10Linking function+Selection strategySimpleSelector1-point Recombination0.22-point Recombination0.2Inversion0.1IS transposition0.1RIS transposition0.1Gene transposition0.1
https://doi.org/10.1371/journal.pone.0321711.t002</p>
<p>Table 3 . Test functions. No Test Functions Range of Values
3</p>
<p>Table 4 . Extended benchmarking of DGEP across diverse problem domains. Problem Domain Benchmark Function/Task Performance Metric Standard GEP DGEP (Proposed) Improvement Factor
4Symbolic RegressionNguyen-F7R² Score0.8760.9154.4% ↑Function ApproximationKeijzer-10RMSE0.0920.06529.3% ↓ClassificationMNIST Binary ClassificationAccuracy (%)78.585.38.6% ↑High-Dimensional Regression 100D Polynomial Regression MSE1.2350.94223.7% ↓
https://doi.org/10.1371/journal.pone.0321711.t004</p>
<p>Table 5 . Statistical analysis of DGEP vs. standard GEP. Benchmark Function Standard GEP (Mean ± SD) DGEP (Mean ± SD) t-Statistic p-Value
5Symbolic Regression0.876 ± 0.0200.915 ± 0.0156.250.002Function Approximation0.092 ± 0.0100.065 ± 0.008-7.430.001Classification (Accuracy %)78.5 ± 2.585.3 ± 2.05.980.003High-Dimensional Regression 1.235 ± 0.0500.942 ± 0.040-8.12&lt;0.001https://doi.org/10.1371/journal.pone.0321711.t006</p>
<p>Table 6 . Comparison of standard GEP and DGEP.
6MetricStandard GEPDGEP (Proposed)Improvement FactorPopulation Diversity1.02.32.3×Escape from Local Optima1.01.3535% IncreaseFitness Improvement (R²)1.01.15715.7% IncreaseComputation EfficiencyO(n)O(n)No Additional Cost
https://doi.org/10.1371/journal.pone.0321711.t005</p>
<p>PLOS One | https://doi.org/10.1371/journal.pone.0321711 June 2, 2025
All relevant data are within the paper and its Supporting Information files.This study was supported in part by Shenyang Aerospace University Innovation and Entrepreneurship Plan (202410143274).
Gene expression programming: a new adaptive algorithm for solving problems. C Ferreira, arXiv preprint cs/01020272001</p>
<p>Gene expression programming: mathematical modeling by artificial intelligence. C Ferreira, 2006Springer</p>
<p>Gene expression programming for parametric optimization of an electrochemical machining process. K Mandal, K Kalita, S Chakraborty, 10.1007/s12008-022-00989-9Int J Interact Des Manuf. 1722022</p>
<p>Geopolymer concrete compressive strength via an artificial neural network, adaptive neuro-fuzzy interface system, and gene expression programming with K-fold cross-validation. M A Khan, Front Materials. 86211632021</p>
<p>Prediction of mechanical properties of green concrete incorporating waste foundry sand based on gene expression programming. M F Iqbal, Q-F Liu, I Azim, X Zhu, J Yang, M F Javed, 10.1016/j.jhazmat.2019.12132231604206J Hazard Mater. 3841213222020</p>
<p>Modelling tunnel squeezing using gene expression programming: a case study. M H Kadkhodaei, E Ghasemi, S Mahdavi, 10.1680/jgeen.22.00151Proc Inst Civ Eng Geotech Eng. 17662023</p>
<p>Computation of energy across the type-C piano key weir using gene expression programming and extreme gradient boosting (XGBoost) algorithm. N Bansal, D Singh, M Kumar, 10.1016/j.egyr.2023.04.003Energy Rep. 92023</p>
<p>Compressive strength of fly-ash-based geopolymer concrete by gene expression programming and random forest. M A Khan, S A Memon, F Farooq, M F Javed, F Aslam, R Alyousef, Adv Civ Eng. 2021166184072021</p>
<p>Application of soft computing techniques to predict the strength of geopolymer composites. Q Wang, Ahmad W Ahmad, A Aslam, F , Mohamed A Vatin, N I , 10.3390/polym1406107435335405Polymers (Basel). 14610742022</p>
<p>A comparative study of GEP and an ANN strategy to model engine performance and emission characteristics of a CRDI assisted single cylinder diesel engine under CNG dual-fuel operation. S Roy, A Ghosh, A K Das, R Banerjee, 10.1016/j.jngse.2014.10.024J Nat Gas Sci Eng. 212014</p>
<p>Oil price forecasting using gene expression programming and artificial neural networks. M M Mostafa, A A El-Masry, 10.1016/j.econmod.2015.12.014Econ Model. 542016</p>
<p>A novel function mining algorithm based on attribute reduction and improved gene expression programming. C Yuan, X Qin, L Yang, G Gao, S Deng, 10.1109/access.2019.2911890IEEE Access. 72019</p>
<p>An improved gene expression programming algorithm for function mining of map-reduce job execution in catenary monitoring systems. J Ding, T Jiang, P Tan, Y Wang, Z Fei, C Huang, 10.1371/journal.pone.029049937972061PLoS One. 1811e02904992023</p>
<p>Improving symbolic regression with interval arithmetic and linear scaling. M Keijzer, European Conference on Genetic Programming. Springer2003</p>
<p>Semantically-based crossover in genetic programming: application to real-valued symbolic regression. N Q Uy, N X Hoai, O' Neill, M Mckay, R I Galván-López, E , 10.1007/s10710-010-9121-2Genet Program Evolvable Mach. 1222010</p>
<p>Enhancing gene expression programming based on space partition and jump for symbolic regression. Q Lu, S Zhou, F Tao, J Luo, Z Wang, 10.1016/j.ins.2020.08.061Inf Sci. 5472021</p>
<p>Adagep-an adaptive gene expression programming algorithm. E Bautu, A Bautu, H Luchian, Ninth International Symposium on Symbolic and Numeric Algorithms for Scientific Computing. IEEE2007. 2007</p>
<p>AB-GEP: Adversarial bandit gene expression programming for symbolic regression. Q Lu, C Xu, J Luo, Z Wang, 10.1016/j.swevo.2022.101197Swarm Evol Comput. 751011972022</p>
<p>Compressive strength prediction via gene expression programming (GEP) and artificial neural network (ANN) for concrete containing RCA. A Ahmad, K Chaiyasarn, F Farooq, W Ahmad, S Suparp, F Aslam, 10.3390/buildings11080324Buildings. 1183242021</p>
<p>An approach for optimizing multi-objective problems using hybrid genetic algorithms. Soft Comput. A Maghawry, R Hodhod, Y Omar, M Kholief, 10.1007/s00500-020-05149-3202025</p>
<p>Forecasting compressive strength and electrical resistivity of graphite based nano-composites using novel artificial intelligence techniques. Case Stud Constr Mat. H Alabduljabbar, M N Amin, S M Eldin, M F Javed, R Alyousef, A M Mohamed, 202318e01848</p>
<p>Genetic programming II: automatic discovery of reusable programs. J R Koza, 1994MIT press</p>
<p>Encoding multiple solutions in a linear genetic programming chromosome. M Oltean, C Groşan, M Oltean, International Conference on Computational Science. Springer2004</p>
<p>RETRACTED ARTICLE: Predicting the effects of nanoparticles on compressive strength of ash-based geopolymers by gene expression programming. A Nazari, S Riahi, Neural Comput Appl. 232013</p>
<p>Distributed function mining for gene expression programming based on fast reduction. S Deng, D Yue, L Yang, X Fu, Y Feng, 10.1371/journal.pone.014669826751200PLoS One. 111e01466982016</p>
<p>Evaluation of FAO56-PM, empirical, semi-empirical and gene expression programming approaches for estimating daily reference evapotranspiration in hyper-arid regions of Iran. Agric Water Manag. J Shiri, 10.1016/j.agwat.2017.04.0092017188</p>
<p>Time series modeling using an adaptive gene expression programming algorithm. A Bărbulescu, E Băutu, Int J Math Models Methods Appl Sci. 322009</p>
<p>A genetic algorithm that adaptively mutates and never revisits. S Y Yuen, C K Chow, 10.1109/tevc.2008.2003008IEEE Trans Evol Computat. 1322009</p>
<p>An improved Gene Expression Programming approach for symbolic regression problems. Y Peng, C Yuan, X Qin, J Huang, Y Shi, 10.1016/j.neucom.2013.05.062Neurocomputing. 1372014</p>
<p>Efficient evolution of accurate classification rules using a combination of gene expression programming and clonal selection. V K Karakasis, A Stafylopatis, 10.1109/tevc.2008.920673IEEE Trans Evol Computat. 1262008</p>
<p>Artificial lemming algorithm: a novel bionic meta-heuristic technique for solving real-world engineering optimization problems. Y Xiao, H Cui, R A Khurma, P A Castillo, 10.1007/s10462-024-11023-7Artif Intell Rev. 5832025</p>
<p>MSAO: A multi-strategy boosted snow ablation optimizer for global optimization and real-world engineering applications. Y Xiao, H Cui, A G Hussien, F A Hashim, 10.1016/j.aei.2024.102464Adv Eng Inf. 611024642024</p>
<p>A Survey of multi-objective evolutionary algorithm based on decomposition: past and future. K Li, IEEE Trans Evol Comput. 2024</p>
<p>An efficient approach for metaheuristic-based optimization of composite laminates using genetic programming. K Kalita, S Chakraborty, 10.1007/s12008-022-01175-7Int J Interact Des Manuf. 1722023</p>
<p>Accurate estimation of DLC thin film hardness using genetic programming. R K Ghadai, K Kalita, 10.3139/146.111911Int J Materials Res. 11162020</p>
<p>Genetic programming-assisted multi-scale optimization for multi-objective dynamic performance of laminated composites: the advantage of more elementary-level analyses. K Kalita, T Mukhopadhyay, P Dey, S Haldar, 10.1007/s00521-019-04280-zNeural Comput Applic. 32122019</p>
<p>Mutation, transposition, and recombination: an analysis of the evolutionary dynamics. C Ferreira, JCIS. 2002</p>
<p>Genetic programming needs better benchmarks. J Mcdermott, D R Luke, S Manzoni, L Castelli, M Vanneschi, L , 10.1145/2330163.2330273Proceedings of the 14th annual conference on Genetic and evolutionary computation. the 14th annual conference on Genetic and evolutionary computation2012</p>            </div>
        </div>

    </div>
</body>
</html>