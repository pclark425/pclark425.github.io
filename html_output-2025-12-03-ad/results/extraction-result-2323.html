<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2323 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2323</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2323</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-63.html">extraction-schema-63</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <p><strong>Paper ID:</strong> paper-204743857</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/1910.07631v1.pdf" target="_blank">Machine learning and big scientific data</a></p>
                <p><strong>Paper Abstract:</strong> This paper reviews some of the challenges posed by the huge growth of experimental data generated by the new generation of large-scale experiments at UK national facilities at the Rutherford Appleton Laboratory (RAL) site at Harwell near Oxford. Such ‘Big Scientific Data’ comes from the Diamond Light Source and Electron Microscopy Facilities, the ISIS Neutron and Muon Facility and the UK's Central Laser Facility. Increasingly, scientists are now required to use advanced machine learning and other AI technologies both to automate parts of the data pipeline and to help find new scientific discoveries in the analysis of their data. For commercially important applications, such as object recognition, natural language processing and automatic translation, deep learning has made dramatic breakthroughs. Google's DeepMind has now used the deep learning technology to develop their AlphaFold tool to make predictions for protein folding. Remarkably, it has been able to achieve some spectacular results for this specific scientific problem. Can deep learning be similarly transformative for other scientific problems? After a brief review of some initial applications of machine learning at the RAL, we focus on challenges and opportunities for AI in advancing materials science. Finally, we discuss the importance of developing some realistic machine learning benchmarks using Big Scientific Data coming from several different scientific domains. We conclude with some initial examples of our ‘scientific machine learning’ benchmark suite and of the research challenges these benchmarks will enable. This article is part of a discussion meeting issue ‘Numerical algorithms for high-performance computational science’.</p>
                <p><strong>Cost:</strong> 0.024</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2323.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2323.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AlphaFold</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AlphaFold (DeepMind protein folding system)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A deep learning system developed by DeepMind that predicts three-dimensional protein structures from sequence information using large-scale comparative genomic data and predicted inter-residue distances/angles.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>De novo structure prediction with deeplearning based scoring</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>protein folding / structural biology</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Predict 3D protein tertiary structure from amino acid sequence information by learning inter-residue contacts, distances and orientations from large multiple-sequence alignments and structural databases.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Abundant for many protein families: vast genomic sequence databases and numerous homologous sequences enable large training sets; however, some proteins lack many homologs (limited data) which reduces performance.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Sequence data (primary amino-acid sequences), multiple-sequence alignments, and derived pairwise distance/angle maps; heterogeneous multimodal inputs (sequence + evolutionary covariation features).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High: high-dimensional, highly non-linear mapping from sequence to 3D structure with a huge combinatorial conformational space; benefits strongly from large data and compute.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Mature experimental structural biology with well-established physics and databases, but computational prediction is an active, rapidly advancing area.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium-to-high: scientific utility requires accurate and physically plausible models; physics-based interpretability is desirable even if ML is used as a predictive engine (commentary notes AlphaFold used Rosetta for physical model building).</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Deep learning (deep neural networks for distance/angle prediction)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Deep neural networks trained on large sequence and structural databases to predict contact probabilities, pairwise distances and angles, then combined with energy-based/model-building tools (e.g., Rosetta) to produce final structures; leverages co-evolutionary features and large compute.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>supervised deep learning (with hybrid ML + physics postprocessing)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable and highly effective for proteins with sufficient homologous sequence data; limitations for proteins with few homologs or cases requiring explicit physical-chemical refinement.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Reported to outperform 97 other CASP competitors on average in the referenced CASP assessment (no numeric accuracy quoted in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Remarkably good predictions on many targets; outperformed other methods on average; caveats: weaker when homologous sequences are scarce and lacks detailed physical chemistry in the ML stage (authors note Rosetta used for final model-building).</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High: demonstrated transformative potential for structural biology, accelerating structure determination and enabling biological insights where experimental structure is unavailable.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared favorably to all other CASP competitors in the referenced contest; noted that approaches relying more on physical chemistry may perform better where co-evolutionary data are scarce.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Large training datasets (sequence databases), leveraging co-evolutionary information, sophisticated network architectures, and hybridization with physics-based model-building.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Deep supervised models that exploit large evolutionary sequence databases can achieve breakthrough predictive performance in domains where abundant homologous data encode strong statistical signals, but performance degrades where such data are scarce and physics-based refinement remains important.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Machine learning and big scientific data', 'publication_date_yy_mm': '2020-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2323.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2323.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SuRVoS segmentation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Super-Region Volume Segmentation (SuRVoS) workbench</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A segmentation workbench using shallow machine learning and limited user annotations to accelerate 3D tomographic segmentation for Cryo-Soft X-ray Tomography (CryoSXT) where labeled data are scarce and data diversity is high.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Super-Region Volume Segmentation workbench</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>cellular tomographic image segmentation (cryo-soft X-ray tomography)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Segment 3D tomograms to distinguish cellular compartments and organelles (nucleus, cytoplasm, organelles) in whole-cell imaging with limited or no chemical/mechanical modification.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Limited labelled data: few pre-labelled image sets and large diversity across cell types; data are available from facility archives but annotated ground truth is scarce.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>3D volumetric image data (tomograms) — unstructured image voxels with high variability; often small numbers of labelled volumes and many unlabeled volumes.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High in heterogeneity and class variability, but moderate computational complexity for segmentation algorithms; challenge arises from limited labelled examples and large morphological diversity.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Experimental imaging domain is established, but automated segmentation workflows for CryoSXT are emerging; significant domain expertise is required to interpret images.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High: segmentation must be accurate to enable downstream biological interpretation; human-in-the-loop annotation and interpretability are important.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Shallow machine learning classifiers with user annotation (SuRVoS)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Shallow ML techniques trained on a small set of user-annotated images (or regions) to classify voxels/regions into cellular compartments; integrated into a workbench that supports semi-automated segmentation and citizen-science annotation.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>supervised learning (human-in-the-loop / semi-supervised workflow)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Appropriate due to scarcity of labels and high data diversity; shallow models plus user annotation reduce the need for very large labeled datasets and are practical for facility workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Qualitatively effective in speeding up segmentation when few labelled examples exist; combined with citizen science annotation to bootstrap classifiers, but full automation is limited by label scarcity and diversity.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Medium: enables higher throughput segmentation at national facility scale and facilitates analysis of tomograms that would otherwise be bottlenecked by manual annotation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Deep learning not straightforwardly applicable due to lack of large labeled sets; hence shallow ML with annotation chosen over deep CNNs.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Use of human annotations to bootstrap models, integration into a segmentation workbench, and leveraging citizen science to increase labelled examples.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>When labeled imaging data are scarce and data heterogeneity is large, shallow ML with targeted user annotation and human-in-the-loop workflows is a pragmatic, effective approach compared to off-the-shelf deep learning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Machine learning and big scientific data', 'publication_date_yy_mm': '2020-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2323.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2323.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Topaz</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Topaz (positive-unlabeled CNN for particle picking)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A positive-unlabeled convolutional neural network that learns particle detection in cryo-electron micrographs from a small set of annotated particles by treating unlabeled regions as unlabeled rather than negative.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Positive-unlabeled convolutional neural networks for particle picking in cryo-electron micrographs</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>single-particle cryo-electron microscopy (particle picking)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Locate and pick individual particles (molecular complexes) in low-contrast micrographs to feed into 3D reconstruction pipelines; requires identifying many (tens to hundreds of thousands) particles per dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Large amounts of raw micrograph imagery are archived (e.g., EMPIAR), but labelled particle annotations are relatively small; datasets can be large but high-quality labels are limited.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>2D micrograph images with low signal-to-noise ratio, containing many particle instances and contaminants (unstructured image data).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High: low contrast, multiple views per particle, overlapping particles, contaminants, and requirement to identify very large numbers of instances for high-resolution reconstructions.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Rapidly maturing with strong community infrastructure (e.g., repositories) and active development of automated tools; domain expertise remains important for validation.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium: accurate particle selection directly impacts reconstruction quality, but black-box pickers can be acceptable when validated by downstream reconstruction improvements.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Positive-unlabeled convolutional neural network (PU-CNN)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>CNN trained in a positive-vs-unlabeled framework where a small set of positive particle annotations and many unlabeled regions are used to learn particle appearance without requiring exhaustive negative labelling; outputs candidate particle locations.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>supervised / weakly-supervised deep learning</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Well-suited: addresses label scarcity by treating unlabeled data appropriately; reduces human time validating picks and can increase particle yields.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>In a cited ribosome dataset, Topaz picked 1.72x more particles than the published manual picks, resulting in the highest-resolution reconstruction for that dataset to date.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Worked well in practice: increased particle counts and improved reconstruction resolution; reduces manual effort though picked particles still require validation in pipelines.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High for cryoEM workflows: enables more complete particle harvesting, higher-resolution reconstructions, and reduced manual labor.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Outperformed previously published manual picks (1.72x more particles) in the cited example; advantage stems from PU formulation versus naive supervised approaches needing negative labels.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Using a PU learning formulation to handle label scarcity, CNN image recognition advances, and availability of micrograph archives for training/validation.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Weakly-supervised CNNs that leverage small positive annotations and treat unlabeled data appropriately can substantially increase usable sample sizes and downstream reconstruction quality in domains with many unlabeled images.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Machine learning and big scientific data', 'publication_date_yy_mm': '2020-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2323.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2323.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FLImP UNET</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>UNet-based segmentation for FLImP automation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A UNet convolutional neural network adapted to automatically segment micrograph regions appropriate for Fluorescence Localisation Imaging with Photobleaching (FLImP), aiming to automate a previously user-intensive selection task.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>single-molecule imaging / super-resolution microscopy (FLImP)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Automatically select regions of interest in micrographs with appropriate fluorescent object density and background homogeneity required for FLImP, enabling high-throughput assays and clinical translation.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Moderate: facility-collected micrographs exist; however, diverse clinical samples are more variable — monocell culture data used for initial training, clinical data being collected for extension.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>2D microscopy images (multi-channel possibly) with diffraction-limited single-fluorophore signals and background variations.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High due to diffraction-limited signals, need to discriminate single-molecule signals from background and other cell populations, and variable labeling densities; segmentation must be precise.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Experimental technique is established (FLImP), but automation and clinical translation are emerging and require robust segmentation and validation.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High: segmentation results directly influence single-molecule structural measurements and clinical diagnostics, so interpretability and validation are important.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>UNet (deep convolutional segmentation network)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>A UNet-based encoder-decoder CNN trained on micrographs from monocell cultures to predict regions with appropriate FLImP object density; to be extended to multi-label classification for diverse clinical samples.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>supervised deep learning (image segmentation)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable with adaptation: UNet architectures suit segmentation but require careful training data reflecting clinical variability; challenges from diffraction-limited features require specialized preprocessing and training.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Successfully segments regions suitable for FLImP in monocell culture micrographs and reduces manual selection time; extension to complex clinical samples remains an ongoing challenge.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High if extended to clinical samples: could enable high-throughput, standardized FLImP assays for personalized cancer diagnostics and reduce operator expertise requirements.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Conventional CNNs struggle with diffraction-limited single-fluorophore segmentation; UNet chosen for superior segmentation performance over simple CNN classifiers.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Use of an architecture specialized for segmentation (UNet), initial training on controlled monocell culture data, and planned multi-label extension for clinical heterogeneity.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Segmentation architectures (UNet) can automate selection for sensitive single-molecule imaging when trained on appropriate representative data, but clinical translation requires handling greater sample heterogeneity and multi-label classification.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Machine learning and big scientific data', 'publication_date_yy_mm': '2020-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2323.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2323.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DMS CNN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Convolutional neural network for Diffuse Multiple Scattering (DMS) azimuthal angle prediction</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A CNN trained on a large simulated dataset of DMS patterns to regress the azimuthal sample angle, dramatically reducing time required for this bottleneck parameter estimation in DMS experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>crystallography / diffuse multiple scattering analysis</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Predict the azimuthal angle of a sample from observed 2D diffuse multiple scattering patterns to enable correct indexing and analysis without time-consuming expert-driven procedures.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Large synthetic dataset available: >250,000 simulated DMS patterns were generated and used as labelled training data; experimental labelled data scarce but simulation provides ground truth.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>2D image patterns of scattering intensity (gridded detector images); structured image arrays.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Moderate-to-high: pattern analysis requires extracting geometric relationships from images; inverse mapping from pattern to angle is non-linear but constrained by crystallographic geometry.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Technique (DMS) is relatively new; domain has established physics but experiments require expert setup — machine assistance is emerging.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium: accurate angle prediction is needed for downstream physical interpretation, but a regression output is acceptable as long as it is validated against physics.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Convolutional Neural Network (CNN) regression model (two conv layers + dense layers)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>CNN with two convolutional layers (32 and 64 filters with 3x3 kernels), maxpooling, dropout, followed by dense layers (32 then 16 nodes) and a linear output for regression; trained on 75% of ~250k simulated patterns and validated on 25%; ReLU activations and dropout used to prevent overfitting.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>supervised deep learning (regression)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable: simulation enables abundant labeled training data matching experimental geometry; CNN effectively maps complex image features to the azimuthal angle.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Trained NN predicts azimuthal angle to within 6.5 degrees (median or average error reported in text); training dataset size >250,000 simulated patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Provided answers in a fraction of the time required for exhaustive image comparison and expert analysis; effective at alleviating a bottleneck in DMS workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Medium-to-high: reduces expert time and accelerates DMS experiments, enabling wider routine application of the technique at synchrotron facilities.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Traditional method is expert-driven, time-consuming exhaustive comparison; CNN outperforms in speed and provides sufficient accuracy for practical use.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Availability of a large, high-fidelity simulator to generate labeled training data; problem is well-constrained by physics so supervised regression is effective; careful network design and regularisation.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>When high-fidelity simulators exist to produce large labelled datasets, supervised CNNs can accurately regress experimental setup parameters (here azimuthal angle), turning a prior expert bottleneck into an automated, fast step.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Machine learning and big scientific data', 'publication_date_yy_mm': '2020-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2323.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2323.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Magnon CNN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Convolutional neural network for predicting magnetic coupling constants from inelastic neutron scattering</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A CNN trained on simulated spin-wave spectra to predict nearest-neighbor (J) and next-nearest-neighbor (J') magnetic coupling constants, validated on experimental data for Rb2MnF4 with high accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>magnetism / inelastic neutron scattering</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Infer microscopic magnetic coupling constants (J and J') from 2D inelastic neutron scattering spectra to enable rapid extraction of Hamiltonian parameters from experimental data.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Moderate labelled simulated data: 29,957 simulated spin-wave spectra used for training/validation (split described); experimental spectra available for validation but limited in number.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>2D energy-integrated scattering intensity maps (converted to 128x128 histograms), with detector geometry masks applied.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High: mapping from spectral features to small variations in coupling constants is subtle and requires sensitivity to fine features (non-linear regression in high-dimensional image space).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Well-established experimental domain with known theories (Heisenberg Hamiltonian); prior knowledge used to choose parameter ranges and features for simulation.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High: predicting physical Hamiltonian parameters requires interpretable, physically consistent estimates validated against known experimental values.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Convolutional Neural Network (deep CNN regression: 4 conv layers + dense outputs)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>CNN with four convolutional layers (32, 64, 32, 16 3x3 filters), maxpooling after each, flattening and a densely connected 2-node linear output for regression to (J, J'); ReLU activations; trained on 27,000 images and validated on 2,957 images; input images preprocessed to 128x128 histograms and masked for detector geometry.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>supervised deep learning (regression)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable and effective because a physics-based simulator provided labelled training data and prior domain knowledge constrained parameter ranges, enabling ML to learn subtle spectral-to-parameter mappings.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Mean absolute error on held-out simulated data: ±0.0055 meV for J and ±0.0036 meV for J'. For an experimental spectrum, the NN predicted J=0.6763 meV and J'=0.0104 meV, consistent with previously measured experimental values (e.g., J≈0.648–0.673 meV, J'≈0.006–0.012 meV).</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>The CNN accurately recovered fine features including the small next-nearest-neighbour coupling; demonstrated the capability to learn subtle physical parameters from images when trained on representative simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High for speeding up parameter estimation in neutron scattering experiments and enabling on-the-fly or near-real-time interpretation of spectra at facilities.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Traditional fitting and expert-driven analysis are time-consuming; CNN matched experimental values and captured small coupling terms, offering faster automated alternatives when trained on appropriate simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Availability of a reliable simulator (SpinW) to generate representative training data, incorporation of prior physical knowledge to bound parameter ranges, careful preprocessing (histograms, masking), and appropriate CNN architecture for regression.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Coupling simulated data with CNN regression and domain-informed training ranges allows ML to recover subtle Hamiltonian parameters from experimental spectra with accuracy comparable to traditional fitting but much faster.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Machine learning and big scientific data', 'publication_date_yy_mm': '2020-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2323.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2323.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MSD-NN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mixed-Scale Dense Neural Network (MSD-NN)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A mixed-scale dense convolutional architecture using dilation filters and dense inter-layer connectivity that can learn from significantly smaller datasets and requires less hyperparameter tuning than standard CNNs for image analysis tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A mixed-scale dense convolutional neural network for image analysis</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>image segmentation and analysis (materials and microscopy imaging)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Improve image analysis/segmentation performance when labelled datasets are small and long-range correlations in images are important.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Designed for scenarios with limited labeled data; specifically motivated by materials science imaging where large labelled datasets are rare.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>2D/3D image data with features at multiple scales (images where long-range correlations matter).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Moderate-to-high: requires capturing multi-scale image features with effective parameter efficiency to avoid overfitting on small datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Emerging ML architecture (recent research); application to materials imaging is exploratory and under investigation by the SciML team.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium: interpretability of segmentation outputs is important for scientific use; architecture reduces data needs but doesn't inherently provide physics-based interpretability.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Mixed-Scale Dense Neural Network (MSD-NN)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Uses dilation filters to capture longer-range correlations, and full dense connectivity between convolved layers (not strictly sequential) so information persists across layers; claimed to require less data and tuning than deep sequential CNNs.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>supervised deep learning (image analysis) / architecture innovation</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Promising for scientific imaging problems with small labelled datasets and multi-scale features; SciML is exploring MSD-NN for soft X-ray segmentation and materials classification.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Reported in cited work to learn with significantly smaller datasets and reduced hyperparameter tuning compared to traditional CNNs; regarded as promising for facility-scale imaging tasks with limited labels.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Medium: could lower labelled-data requirements and accelerate adoption of ML for scientific image segmentation where labels are scarce.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Claims better performance/data-efficiency relative to deep CNNs on small-dataset image tasks in cited research; SciML is evaluating applicability to their datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Architectural design capturing multi-scale correlations and dense connectivity that preserves information across layers, enabling learning from less data.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Architectures that encode multi-scale receptive fields and dense inter-layer connectivity can reduce labelled-data requirements and hyperparameter sensitivity, enabling ML application in scientific imaging domains where large ground truth datasets are rare.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Machine learning and big scientific data', 'publication_date_yy_mm': '2020-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2323.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2323.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>XAS neural nets & ensemble</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural network and ensemble learning approaches for X-ray Absorption Spectroscopy (XAS) analysis</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Supervised neural networks and ensemble learning algorithms trained on large computed XAS datasets to identify oxidation state, coordination environment, and structural transformations from spectra.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>High-throughput computational X-ray absorption spectroscopy</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>materials characterization / X-ray absorption spectroscopy (XAS)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Interpret experimental XAS spectra to infer local chemical/structural environments (oxidation state, coordination, structural transformations) rapidly and without manual bias.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Recently made large computed XAS datasets available (high-throughput computed spectra), enabling supervised training; experimental beamline data also exist but ground truth often limited.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>1D spectral data (intensity vs energy) — structured high-dimensional continuous signals.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Moderate-to-high: mapping spectra to structural descriptors is non-linear and affected by noise, experimental conditions, and subtle spectral features.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Established spectroscopy domain with robust theoretical models; ML approaches are relatively new but supported by growing computed databases.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High: scientific interpretation requires correct identification of chemical environments and physical plausibility; models are used as decision aids and require validation.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Supervised neural networks and ensemble learning</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Neural networks trained on large sets of computed XAS spectra to map spectral features to labels (oxidation state, coordination); ensemble learning applied to improve robustness and generalizability; used for on-the-fly predictions and identification of sub-nanometer assemblies.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>supervised learning (regression/classification) and ensemble methods</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable where large simulated/computed spectral datasets exist; enables rapid automated interpretation of spectra that previously relied on manual fitting and expertise.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Cited works report unprecedented analysis capability and availability of an ensemble algorithm capable of identifying oxidation state and coordination across diverse chemistries (no single numeric metric provided in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Enables automated characterization of structural transformations and chemical environments, identification of subtle signals missed by manual inspection; ensemble approaches increase robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High: accelerates experimental interpretation, supports on-the-fly beamline analysis, and reduces human bias in spectral interpretation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared to manual/physics-only interpretation, ML approaches provide faster, automated, and potentially more sensitive analysis when trained on comprehensive computed datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Availability of large, high-quality computed spectral databases, and appropriate supervised architectures and ensembles to generalize across chemistries.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>When comprehensive simulated spectral libraries are available, supervised ML and ensemble approaches can automate and enhance spectral interpretation, revealing subtle structural signals faster than traditional manual methods.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Machine learning and big scientific data', 'publication_date_yy_mm': '2020-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2323.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e2323.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SAXS-1D baseline</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SAXS-1D benchmark baseline (dense neural network)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A SciML benchmark subtask using a simple multilayer dense neural network to classify one-dimensional SAXS profiles (sphere vs parallelepiped) trained on fully simulated data to evaluate model suitability and platform performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>small-angle X-ray scattering (SAXS) / particle shape identification</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Classify 1D SAXS intensity profiles to identify particle shape (binary: sphere vs parallelepiped) using simulated one-dimensional scattering profiles.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Abundant simulated data: 20,000 1D profiles (10k per class) with unit dispersity; datasets include ideal simulated, noise-added simulated, and beamline (real) datasets (latter lacks ground truth).</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured 1D numerical arrays (intensity vs momentum transfer q) of dimension [1 x 300].</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Moderate: distinguishing shape signatures in 1D profiles can be non-trivial if orientation or polydispersity varies; sub-benchmark simplified to fixed orientation/parameters to be separable in 1D.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Established experimental method with mathematical forward models; ML application as benchmark and automated classifier is emerging.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium: classification aids structural understanding but full mechanistic interpretation may require model-based fitting; interpretability helpful for scientific trust.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Multi-layer dense neural network (baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Supervised feed-forward neural network with three dense layers: input layer accepting 300 intensity values, a hidden layer with 100 ReLU neurons, and a single-output sigmoid neuron for binary classification; trained on simulated labelled data.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>supervised deep learning (classification)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Appropriate as a baseline on simulated data; simple dense models suffice for this simplified 1D benchmark but more complex models might be needed for real/noisy/heterogeneous beamline data.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Benchmark experiments used 20,000 profiles with 70:30 train:test split; specific accuracy/F1 numbers are shown in figures in the paper but not enumerated in text; reported architecture/runtime differences: inference time was 40% of training time on CPU and 60% on GPU.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Baseline dense NN provides reasonable classification for the simplified simulated task; platform (CPU vs GPU) affects runtime tradeoffs though not necessarily accuracy for this simple model.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Low-to-medium as a baseline: demonstrates feasibility of ML classification on simulated SAXS data and serves as a benchmark to evaluate more advanced models and hardware.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Deliberately uses a simple dense model rather than CNNs to probe suitability; paper suggests more flexible models (e.g., CNNs) could be used but baseline suffices for the simplified task.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Availability of large simulated labelled dataset and a simplified problem setup (fixed orientation/parameters) that reduces the complexity to enable a small dense NN to perform well.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>On simplified, fully simulated 1D scattering tasks with abundant labelled data, small dense neural networks are sufficient baselines; hardware choices influence runtime but not necessarily classification capability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Machine learning and big scientific data', 'publication_date_yy_mm': '2020-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2323.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e2323.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Sentinel-SLSTR baseline</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Sentinel-SLSTR cloud masking baseline (dense neural network with Bayesian surrogate ground truth)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A SciML benchmark for cloud masking in Sentinel-3 SLSTR imagery that combines Bayesian surrogate ground truth generation with a simple multilayer dense neural network baseline to classify pixels as cloud/non-cloud.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>remote sensing / cloud detection from satellite imagery</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Per-pixel classification of SLSTR multi-channel satellite images into cloud vs non-cloud under realistic atmospheric conditions (cloud variability, snow/ice confusion, aerosols).</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Moderate: dataset of 1,000 SLSTR images (South Pacific, 2018) with 11 channels and two views; however, reliable ground truth is scarce and hand-labelling is infeasible, so Bayesian inference is used to generate surrogate labels.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Multispectral image tiles (M x N x channels), here sub-sampled to 250x250 pixels per channel (vectorised inputs); structured multi-band image data.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High: clouds are dynamic with variable texture and appearance, and discrimination is confounded by snow, ice, sun glint, aerosols and varying illumination; requires per-pixel decisions across spectral bands.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Mature remote sensing domain with many classical and ML approaches; cloud masking remains an active area with many sensor-specific challenges.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium-to-high: false positives/negatives have significant downstream impacts (e.g., SST retrieval), so probabilistic/confidence outputs and interpretability are valuable.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Multi-layer dense neural network (baseline) with Bayesian surrogate ground truth generation</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Ground truth surrogate generated per-pixel via Bayesian inference method from cited literature to provide labels/confidence; baseline classifier is a three-layer dense NN: input vectorised 9-channel image, hidden layer with 50 ReLU neurons, output sigmoid for binary classification; trained on 800 images with 200 validation.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>supervised learning with Bayesian label pre-processing (hybrid surrogate-label approach)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable as a baseline; Bayesian surrogate labels allow supervised training despite lack of reliable human-labelled ground truth; more sophisticated models (CNNs, LSTMs, GANs) have been used elsewhere and could improve performance.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Dataset split: 1,000 images (800 train / 200 validation); reported that GPU offers better training performance than CPU but no explicit accuracy/F1 metrics are enumerated in text.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Baseline dense NN trained on Bayesian-derived labels works as a starting point; limitations stem from surrogate ground truth uncertainty and the simplicity of the dense model for spatial image data.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Medium: provides a reproducible benchmark and baseline for cloud masking on SLSTR data; Bayesian surrogate labelling enables supervised ML in absence of human-labelled ground truth.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Paper notes many groups use deep CNNs, LSTMs, and GANs for cloud detection on other sensors; baseline intentionally simple to provide a reference point rather than state-of-the-art performance.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Use of Bayesian surrogate labelling to overcome lack of ground truth, availability of multi-channel SLSTR data, and a clear benchmark split enabling performance and runtime comparisons across hardware.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>When reliable human-labelled ground truth is infeasible, principled surrogate-label generation (Bayesian inference) enables supervised training and benchmarking, but model architecture must match spatial structure of the data for best results.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Machine learning and big scientific data', 'publication_date_yy_mm': '2020-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2323.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e2323.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Generative models (LSTM/ORGAN/GAN)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative neural network models for molecular/material design (LSTM, ORGAN, GANs)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Neural generative architectures (LSTM, generative adversarial networks with reinforcement learning biasing e.g., ORGAN) used to propose novel molecular/material candidates and bias generation toward desired properties.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Objectivereinforced generative adversarial networks (ORGAN) for sequence generation models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>molecular/material design, drug discovery</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Generate new chemical/molecular structures or compositions optimized for desired properties (e.g., activity, band gap) using learned generative models and property-driven reinforcement signals.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Varies: molecular databases can be large (e.g., chemical libraries), but labeled property data may be limited; cited work notes LSTMs can perform well with reduced training data in one-shot/low-data settings.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Discrete sequence representations (SMILES) or graph-based molecular encodings; structured variable-length sequences or graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Very high: combinatorial chemical space is enormous; mapping structures to properties is nonlinear and multi-objective; requires exploration and constrained optimization in large discrete spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Active research area with growing adoption; theoretical chemical/physical models exist but data-driven generative design is emerging.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High for downstream applicability: generated candidates require chemical validity and physical plausibility; interpretability and validation via simulations/experiments are necessary.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>LSTM, ORGAN (GAN+reinforcement learning), GANs</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Sequence-based LSTM models trained to generate SMILES strings; ORGAN couples a GAN generator with reinforcement learning to bias generation towards target metrics; methods can incorporate property predictors to guide generation.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>generative modelling (deep learning) with reinforcement learning conditioning</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable for proposing candidate molecules/materials; success depends on training data, validity checks, and integration with property evaluation pipelines (simulations/experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Cited work reports LSTM can perform one-shot/low-data drug discovery tasks with much reduced data compared to some methods; no numeric success rates provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Generative models show promise in suggesting novel candidates and steering generation toward desired properties, but require downstream validation and can produce chemically invalid structures without constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High: potential to accelerate materials and molecular discovery pipelines if integrated with property evaluators and validation workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Traditional computational chemistry relies on physics-based search/optimization; generative ML can explore larger chemical spaces more rapidly but needs coupling to physics-based validation to ensure realism.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Availability of chemical databases, ability to incorporate property feedback (reinforcement learning), and hybrid workflows for chemical validity checking and simulation-based validation.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Generative neural models can explore vast chemical spaces and be biased toward target properties, but their scientific utility depends critically on training data quality and integration with physical validation to ensure chemical plausibility.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Machine learning and big scientific data', 'publication_date_yy_mm': '2020-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Positive-unlabeled convolutional neural networks for particle picking in cryo-electron micrographs <em>(Rating: 2)</em></li>
                <li>A mixed-scale dense convolutional neural network for image analysis <em>(Rating: 2)</em></li>
                <li>Neural Network Approach for Characterizing Structural Transformations by X-Ray Absorption Fine Structure Spectroscopy <em>(Rating: 2)</em></li>
                <li>High-throughput computational X-ray absorption spectroscopy <em>(Rating: 2)</em></li>
                <li>Objectivereinforced generative adversarial networks (ORGAN) for sequence generation models <em>(Rating: 2)</em></li>
                <li>Diffuse multiple scattering <em>(Rating: 1)</em></li>
                <li>De novo structure prediction with deeplearning based scoring <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2323",
    "paper_id": "paper-204743857",
    "extraction_schema_id": "extraction-schema-63",
    "extracted_data": [
        {
            "name_short": "AlphaFold",
            "name_full": "AlphaFold (DeepMind protein folding system)",
            "brief_description": "A deep learning system developed by DeepMind that predicts three-dimensional protein structures from sequence information using large-scale comparative genomic data and predicted inter-residue distances/angles.",
            "citation_title": "De novo structure prediction with deeplearning based scoring",
            "mention_or_use": "mention",
            "scientific_problem_domain": "protein folding / structural biology",
            "problem_description": "Predict 3D protein tertiary structure from amino acid sequence information by learning inter-residue contacts, distances and orientations from large multiple-sequence alignments and structural databases.",
            "data_availability": "Abundant for many protein families: vast genomic sequence databases and numerous homologous sequences enable large training sets; however, some proteins lack many homologs (limited data) which reduces performance.",
            "data_structure": "Sequence data (primary amino-acid sequences), multiple-sequence alignments, and derived pairwise distance/angle maps; heterogeneous multimodal inputs (sequence + evolutionary covariation features).",
            "problem_complexity": "High: high-dimensional, highly non-linear mapping from sequence to 3D structure with a huge combinatorial conformational space; benefits strongly from large data and compute.",
            "domain_maturity": "Mature experimental structural biology with well-established physics and databases, but computational prediction is an active, rapidly advancing area.",
            "mechanistic_understanding_requirements": "Medium-to-high: scientific utility requires accurate and physically plausible models; physics-based interpretability is desirable even if ML is used as a predictive engine (commentary notes AlphaFold used Rosetta for physical model building).",
            "ai_methodology_name": "Deep learning (deep neural networks for distance/angle prediction)",
            "ai_methodology_description": "Deep neural networks trained on large sequence and structural databases to predict contact probabilities, pairwise distances and angles, then combined with energy-based/model-building tools (e.g., Rosetta) to produce final structures; leverages co-evolutionary features and large compute.",
            "ai_methodology_category": "supervised deep learning (with hybrid ML + physics postprocessing)",
            "applicability": "Applicable and highly effective for proteins with sufficient homologous sequence data; limitations for proteins with few homologs or cases requiring explicit physical-chemical refinement.",
            "effectiveness_quantitative": "Reported to outperform 97 other CASP competitors on average in the referenced CASP assessment (no numeric accuracy quoted in this paper).",
            "effectiveness_qualitative": "Remarkably good predictions on many targets; outperformed other methods on average; caveats: weaker when homologous sequences are scarce and lacks detailed physical chemistry in the ML stage (authors note Rosetta used for final model-building).",
            "impact_potential": "High: demonstrated transformative potential for structural biology, accelerating structure determination and enabling biological insights where experimental structure is unavailable.",
            "comparison_to_alternatives": "Compared favorably to all other CASP competitors in the referenced contest; noted that approaches relying more on physical chemistry may perform better where co-evolutionary data are scarce.",
            "success_factors": "Large training datasets (sequence databases), leveraging co-evolutionary information, sophisticated network architectures, and hybridization with physics-based model-building.",
            "key_insight": "Deep supervised models that exploit large evolutionary sequence databases can achieve breakthrough predictive performance in domains where abundant homologous data encode strong statistical signals, but performance degrades where such data are scarce and physics-based refinement remains important.",
            "uuid": "e2323.0",
            "source_info": {
                "paper_title": "Machine learning and big scientific data",
                "publication_date_yy_mm": "2020-01"
            }
        },
        {
            "name_short": "SuRVoS segmentation",
            "name_full": "Super-Region Volume Segmentation (SuRVoS) workbench",
            "brief_description": "A segmentation workbench using shallow machine learning and limited user annotations to accelerate 3D tomographic segmentation for Cryo-Soft X-ray Tomography (CryoSXT) where labeled data are scarce and data diversity is high.",
            "citation_title": "Super-Region Volume Segmentation workbench",
            "mention_or_use": "use",
            "scientific_problem_domain": "cellular tomographic image segmentation (cryo-soft X-ray tomography)",
            "problem_description": "Segment 3D tomograms to distinguish cellular compartments and organelles (nucleus, cytoplasm, organelles) in whole-cell imaging with limited or no chemical/mechanical modification.",
            "data_availability": "Limited labelled data: few pre-labelled image sets and large diversity across cell types; data are available from facility archives but annotated ground truth is scarce.",
            "data_structure": "3D volumetric image data (tomograms) — unstructured image voxels with high variability; often small numbers of labelled volumes and many unlabeled volumes.",
            "problem_complexity": "High in heterogeneity and class variability, but moderate computational complexity for segmentation algorithms; challenge arises from limited labelled examples and large morphological diversity.",
            "domain_maturity": "Experimental imaging domain is established, but automated segmentation workflows for CryoSXT are emerging; significant domain expertise is required to interpret images.",
            "mechanistic_understanding_requirements": "High: segmentation must be accurate to enable downstream biological interpretation; human-in-the-loop annotation and interpretability are important.",
            "ai_methodology_name": "Shallow machine learning classifiers with user annotation (SuRVoS)",
            "ai_methodology_description": "Shallow ML techniques trained on a small set of user-annotated images (or regions) to classify voxels/regions into cellular compartments; integrated into a workbench that supports semi-automated segmentation and citizen-science annotation.",
            "ai_methodology_category": "supervised learning (human-in-the-loop / semi-supervised workflow)",
            "applicability": "Appropriate due to scarcity of labels and high data diversity; shallow models plus user annotation reduce the need for very large labeled datasets and are practical for facility workflows.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Qualitatively effective in speeding up segmentation when few labelled examples exist; combined with citizen science annotation to bootstrap classifiers, but full automation is limited by label scarcity and diversity.",
            "impact_potential": "Medium: enables higher throughput segmentation at national facility scale and facilitates analysis of tomograms that would otherwise be bottlenecked by manual annotation.",
            "comparison_to_alternatives": "Deep learning not straightforwardly applicable due to lack of large labeled sets; hence shallow ML with annotation chosen over deep CNNs.",
            "success_factors": "Use of human annotations to bootstrap models, integration into a segmentation workbench, and leveraging citizen science to increase labelled examples.",
            "key_insight": "When labeled imaging data are scarce and data heterogeneity is large, shallow ML with targeted user annotation and human-in-the-loop workflows is a pragmatic, effective approach compared to off-the-shelf deep learning.",
            "uuid": "e2323.1",
            "source_info": {
                "paper_title": "Machine learning and big scientific data",
                "publication_date_yy_mm": "2020-01"
            }
        },
        {
            "name_short": "Topaz",
            "name_full": "Topaz (positive-unlabeled CNN for particle picking)",
            "brief_description": "A positive-unlabeled convolutional neural network that learns particle detection in cryo-electron micrographs from a small set of annotated particles by treating unlabeled regions as unlabeled rather than negative.",
            "citation_title": "Positive-unlabeled convolutional neural networks for particle picking in cryo-electron micrographs",
            "mention_or_use": "mention",
            "scientific_problem_domain": "single-particle cryo-electron microscopy (particle picking)",
            "problem_description": "Locate and pick individual particles (molecular complexes) in low-contrast micrographs to feed into 3D reconstruction pipelines; requires identifying many (tens to hundreds of thousands) particles per dataset.",
            "data_availability": "Large amounts of raw micrograph imagery are archived (e.g., EMPIAR), but labelled particle annotations are relatively small; datasets can be large but high-quality labels are limited.",
            "data_structure": "2D micrograph images with low signal-to-noise ratio, containing many particle instances and contaminants (unstructured image data).",
            "problem_complexity": "High: low contrast, multiple views per particle, overlapping particles, contaminants, and requirement to identify very large numbers of instances for high-resolution reconstructions.",
            "domain_maturity": "Rapidly maturing with strong community infrastructure (e.g., repositories) and active development of automated tools; domain expertise remains important for validation.",
            "mechanistic_understanding_requirements": "Medium: accurate particle selection directly impacts reconstruction quality, but black-box pickers can be acceptable when validated by downstream reconstruction improvements.",
            "ai_methodology_name": "Positive-unlabeled convolutional neural network (PU-CNN)",
            "ai_methodology_description": "CNN trained in a positive-vs-unlabeled framework where a small set of positive particle annotations and many unlabeled regions are used to learn particle appearance without requiring exhaustive negative labelling; outputs candidate particle locations.",
            "ai_methodology_category": "supervised / weakly-supervised deep learning",
            "applicability": "Well-suited: addresses label scarcity by treating unlabeled data appropriately; reduces human time validating picks and can increase particle yields.",
            "effectiveness_quantitative": "In a cited ribosome dataset, Topaz picked 1.72x more particles than the published manual picks, resulting in the highest-resolution reconstruction for that dataset to date.",
            "effectiveness_qualitative": "Worked well in practice: increased particle counts and improved reconstruction resolution; reduces manual effort though picked particles still require validation in pipelines.",
            "impact_potential": "High for cryoEM workflows: enables more complete particle harvesting, higher-resolution reconstructions, and reduced manual labor.",
            "comparison_to_alternatives": "Outperformed previously published manual picks (1.72x more particles) in the cited example; advantage stems from PU formulation versus naive supervised approaches needing negative labels.",
            "success_factors": "Using a PU learning formulation to handle label scarcity, CNN image recognition advances, and availability of micrograph archives for training/validation.",
            "key_insight": "Weakly-supervised CNNs that leverage small positive annotations and treat unlabeled data appropriately can substantially increase usable sample sizes and downstream reconstruction quality in domains with many unlabeled images.",
            "uuid": "e2323.2",
            "source_info": {
                "paper_title": "Machine learning and big scientific data",
                "publication_date_yy_mm": "2020-01"
            }
        },
        {
            "name_short": "FLImP UNET",
            "name_full": "UNet-based segmentation for FLImP automation",
            "brief_description": "A UNet convolutional neural network adapted to automatically segment micrograph regions appropriate for Fluorescence Localisation Imaging with Photobleaching (FLImP), aiming to automate a previously user-intensive selection task.",
            "citation_title": "here",
            "mention_or_use": "use",
            "scientific_problem_domain": "single-molecule imaging / super-resolution microscopy (FLImP)",
            "problem_description": "Automatically select regions of interest in micrographs with appropriate fluorescent object density and background homogeneity required for FLImP, enabling high-throughput assays and clinical translation.",
            "data_availability": "Moderate: facility-collected micrographs exist; however, diverse clinical samples are more variable — monocell culture data used for initial training, clinical data being collected for extension.",
            "data_structure": "2D microscopy images (multi-channel possibly) with diffraction-limited single-fluorophore signals and background variations.",
            "problem_complexity": "High due to diffraction-limited signals, need to discriminate single-molecule signals from background and other cell populations, and variable labeling densities; segmentation must be precise.",
            "domain_maturity": "Experimental technique is established (FLImP), but automation and clinical translation are emerging and require robust segmentation and validation.",
            "mechanistic_understanding_requirements": "High: segmentation results directly influence single-molecule structural measurements and clinical diagnostics, so interpretability and validation are important.",
            "ai_methodology_name": "UNet (deep convolutional segmentation network)",
            "ai_methodology_description": "A UNet-based encoder-decoder CNN trained on micrographs from monocell cultures to predict regions with appropriate FLImP object density; to be extended to multi-label classification for diverse clinical samples.",
            "ai_methodology_category": "supervised deep learning (image segmentation)",
            "applicability": "Applicable with adaptation: UNet architectures suit segmentation but require careful training data reflecting clinical variability; challenges from diffraction-limited features require specialized preprocessing and training.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Successfully segments regions suitable for FLImP in monocell culture micrographs and reduces manual selection time; extension to complex clinical samples remains an ongoing challenge.",
            "impact_potential": "High if extended to clinical samples: could enable high-throughput, standardized FLImP assays for personalized cancer diagnostics and reduce operator expertise requirements.",
            "comparison_to_alternatives": "Conventional CNNs struggle with diffraction-limited single-fluorophore segmentation; UNet chosen for superior segmentation performance over simple CNN classifiers.",
            "success_factors": "Use of an architecture specialized for segmentation (UNet), initial training on controlled monocell culture data, and planned multi-label extension for clinical heterogeneity.",
            "key_insight": "Segmentation architectures (UNet) can automate selection for sensitive single-molecule imaging when trained on appropriate representative data, but clinical translation requires handling greater sample heterogeneity and multi-label classification.",
            "uuid": "e2323.3",
            "source_info": {
                "paper_title": "Machine learning and big scientific data",
                "publication_date_yy_mm": "2020-01"
            }
        },
        {
            "name_short": "DMS CNN",
            "name_full": "Convolutional neural network for Diffuse Multiple Scattering (DMS) azimuthal angle prediction",
            "brief_description": "A CNN trained on a large simulated dataset of DMS patterns to regress the azimuthal sample angle, dramatically reducing time required for this bottleneck parameter estimation in DMS experiments.",
            "citation_title": "here",
            "mention_or_use": "use",
            "scientific_problem_domain": "crystallography / diffuse multiple scattering analysis",
            "problem_description": "Predict the azimuthal angle of a sample from observed 2D diffuse multiple scattering patterns to enable correct indexing and analysis without time-consuming expert-driven procedures.",
            "data_availability": "Large synthetic dataset available: &gt;250,000 simulated DMS patterns were generated and used as labelled training data; experimental labelled data scarce but simulation provides ground truth.",
            "data_structure": "2D image patterns of scattering intensity (gridded detector images); structured image arrays.",
            "problem_complexity": "Moderate-to-high: pattern analysis requires extracting geometric relationships from images; inverse mapping from pattern to angle is non-linear but constrained by crystallographic geometry.",
            "domain_maturity": "Technique (DMS) is relatively new; domain has established physics but experiments require expert setup — machine assistance is emerging.",
            "mechanistic_understanding_requirements": "Medium: accurate angle prediction is needed for downstream physical interpretation, but a regression output is acceptable as long as it is validated against physics.",
            "ai_methodology_name": "Convolutional Neural Network (CNN) regression model (two conv layers + dense layers)",
            "ai_methodology_description": "CNN with two convolutional layers (32 and 64 filters with 3x3 kernels), maxpooling, dropout, followed by dense layers (32 then 16 nodes) and a linear output for regression; trained on 75% of ~250k simulated patterns and validated on 25%; ReLU activations and dropout used to prevent overfitting.",
            "ai_methodology_category": "supervised deep learning (regression)",
            "applicability": "Highly applicable: simulation enables abundant labeled training data matching experimental geometry; CNN effectively maps complex image features to the azimuthal angle.",
            "effectiveness_quantitative": "Trained NN predicts azimuthal angle to within 6.5 degrees (median or average error reported in text); training dataset size &gt;250,000 simulated patterns.",
            "effectiveness_qualitative": "Provided answers in a fraction of the time required for exhaustive image comparison and expert analysis; effective at alleviating a bottleneck in DMS workflows.",
            "impact_potential": "Medium-to-high: reduces expert time and accelerates DMS experiments, enabling wider routine application of the technique at synchrotron facilities.",
            "comparison_to_alternatives": "Traditional method is expert-driven, time-consuming exhaustive comparison; CNN outperforms in speed and provides sufficient accuracy for practical use.",
            "success_factors": "Availability of a large, high-fidelity simulator to generate labeled training data; problem is well-constrained by physics so supervised regression is effective; careful network design and regularisation.",
            "key_insight": "When high-fidelity simulators exist to produce large labelled datasets, supervised CNNs can accurately regress experimental setup parameters (here azimuthal angle), turning a prior expert bottleneck into an automated, fast step.",
            "uuid": "e2323.4",
            "source_info": {
                "paper_title": "Machine learning and big scientific data",
                "publication_date_yy_mm": "2020-01"
            }
        },
        {
            "name_short": "Magnon CNN",
            "name_full": "Convolutional neural network for predicting magnetic coupling constants from inelastic neutron scattering",
            "brief_description": "A CNN trained on simulated spin-wave spectra to predict nearest-neighbor (J) and next-nearest-neighbor (J') magnetic coupling constants, validated on experimental data for Rb2MnF4 with high accuracy.",
            "citation_title": "here",
            "mention_or_use": "use",
            "scientific_problem_domain": "magnetism / inelastic neutron scattering",
            "problem_description": "Infer microscopic magnetic coupling constants (J and J') from 2D inelastic neutron scattering spectra to enable rapid extraction of Hamiltonian parameters from experimental data.",
            "data_availability": "Moderate labelled simulated data: 29,957 simulated spin-wave spectra used for training/validation (split described); experimental spectra available for validation but limited in number.",
            "data_structure": "2D energy-integrated scattering intensity maps (converted to 128x128 histograms), with detector geometry masks applied.",
            "problem_complexity": "High: mapping from spectral features to small variations in coupling constants is subtle and requires sensitivity to fine features (non-linear regression in high-dimensional image space).",
            "domain_maturity": "Well-established experimental domain with known theories (Heisenberg Hamiltonian); prior knowledge used to choose parameter ranges and features for simulation.",
            "mechanistic_understanding_requirements": "High: predicting physical Hamiltonian parameters requires interpretable, physically consistent estimates validated against known experimental values.",
            "ai_methodology_name": "Convolutional Neural Network (deep CNN regression: 4 conv layers + dense outputs)",
            "ai_methodology_description": "CNN with four convolutional layers (32, 64, 32, 16 3x3 filters), maxpooling after each, flattening and a densely connected 2-node linear output for regression to (J, J'); ReLU activations; trained on 27,000 images and validated on 2,957 images; input images preprocessed to 128x128 histograms and masked for detector geometry.",
            "ai_methodology_category": "supervised deep learning (regression)",
            "applicability": "Applicable and effective because a physics-based simulator provided labelled training data and prior domain knowledge constrained parameter ranges, enabling ML to learn subtle spectral-to-parameter mappings.",
            "effectiveness_quantitative": "Mean absolute error on held-out simulated data: ±0.0055 meV for J and ±0.0036 meV for J'. For an experimental spectrum, the NN predicted J=0.6763 meV and J'=0.0104 meV, consistent with previously measured experimental values (e.g., J≈0.648–0.673 meV, J'≈0.006–0.012 meV).",
            "effectiveness_qualitative": "The CNN accurately recovered fine features including the small next-nearest-neighbour coupling; demonstrated the capability to learn subtle physical parameters from images when trained on representative simulations.",
            "impact_potential": "High for speeding up parameter estimation in neutron scattering experiments and enabling on-the-fly or near-real-time interpretation of spectra at facilities.",
            "comparison_to_alternatives": "Traditional fitting and expert-driven analysis are time-consuming; CNN matched experimental values and captured small coupling terms, offering faster automated alternatives when trained on appropriate simulations.",
            "success_factors": "Availability of a reliable simulator (SpinW) to generate representative training data, incorporation of prior physical knowledge to bound parameter ranges, careful preprocessing (histograms, masking), and appropriate CNN architecture for regression.",
            "key_insight": "Coupling simulated data with CNN regression and domain-informed training ranges allows ML to recover subtle Hamiltonian parameters from experimental spectra with accuracy comparable to traditional fitting but much faster.",
            "uuid": "e2323.5",
            "source_info": {
                "paper_title": "Machine learning and big scientific data",
                "publication_date_yy_mm": "2020-01"
            }
        },
        {
            "name_short": "MSD-NN",
            "name_full": "Mixed-Scale Dense Neural Network (MSD-NN)",
            "brief_description": "A mixed-scale dense convolutional architecture using dilation filters and dense inter-layer connectivity that can learn from significantly smaller datasets and requires less hyperparameter tuning than standard CNNs for image analysis tasks.",
            "citation_title": "A mixed-scale dense convolutional neural network for image analysis",
            "mention_or_use": "mention",
            "scientific_problem_domain": "image segmentation and analysis (materials and microscopy imaging)",
            "problem_description": "Improve image analysis/segmentation performance when labelled datasets are small and long-range correlations in images are important.",
            "data_availability": "Designed for scenarios with limited labeled data; specifically motivated by materials science imaging where large labelled datasets are rare.",
            "data_structure": "2D/3D image data with features at multiple scales (images where long-range correlations matter).",
            "problem_complexity": "Moderate-to-high: requires capturing multi-scale image features with effective parameter efficiency to avoid overfitting on small datasets.",
            "domain_maturity": "Emerging ML architecture (recent research); application to materials imaging is exploratory and under investigation by the SciML team.",
            "mechanistic_understanding_requirements": "Medium: interpretability of segmentation outputs is important for scientific use; architecture reduces data needs but doesn't inherently provide physics-based interpretability.",
            "ai_methodology_name": "Mixed-Scale Dense Neural Network (MSD-NN)",
            "ai_methodology_description": "Uses dilation filters to capture longer-range correlations, and full dense connectivity between convolved layers (not strictly sequential) so information persists across layers; claimed to require less data and tuning than deep sequential CNNs.",
            "ai_methodology_category": "supervised deep learning (image analysis) / architecture innovation",
            "applicability": "Promising for scientific imaging problems with small labelled datasets and multi-scale features; SciML is exploring MSD-NN for soft X-ray segmentation and materials classification.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Reported in cited work to learn with significantly smaller datasets and reduced hyperparameter tuning compared to traditional CNNs; regarded as promising for facility-scale imaging tasks with limited labels.",
            "impact_potential": "Medium: could lower labelled-data requirements and accelerate adoption of ML for scientific image segmentation where labels are scarce.",
            "comparison_to_alternatives": "Claims better performance/data-efficiency relative to deep CNNs on small-dataset image tasks in cited research; SciML is evaluating applicability to their datasets.",
            "success_factors": "Architectural design capturing multi-scale correlations and dense connectivity that preserves information across layers, enabling learning from less data.",
            "key_insight": "Architectures that encode multi-scale receptive fields and dense inter-layer connectivity can reduce labelled-data requirements and hyperparameter sensitivity, enabling ML application in scientific imaging domains where large ground truth datasets are rare.",
            "uuid": "e2323.6",
            "source_info": {
                "paper_title": "Machine learning and big scientific data",
                "publication_date_yy_mm": "2020-01"
            }
        },
        {
            "name_short": "XAS neural nets & ensemble",
            "name_full": "Neural network and ensemble learning approaches for X-ray Absorption Spectroscopy (XAS) analysis",
            "brief_description": "Supervised neural networks and ensemble learning algorithms trained on large computed XAS datasets to identify oxidation state, coordination environment, and structural transformations from spectra.",
            "citation_title": "High-throughput computational X-ray absorption spectroscopy",
            "mention_or_use": "mention",
            "scientific_problem_domain": "materials characterization / X-ray absorption spectroscopy (XAS)",
            "problem_description": "Interpret experimental XAS spectra to infer local chemical/structural environments (oxidation state, coordination, structural transformations) rapidly and without manual bias.",
            "data_availability": "Recently made large computed XAS datasets available (high-throughput computed spectra), enabling supervised training; experimental beamline data also exist but ground truth often limited.",
            "data_structure": "1D spectral data (intensity vs energy) — structured high-dimensional continuous signals.",
            "problem_complexity": "Moderate-to-high: mapping spectra to structural descriptors is non-linear and affected by noise, experimental conditions, and subtle spectral features.",
            "domain_maturity": "Established spectroscopy domain with robust theoretical models; ML approaches are relatively new but supported by growing computed databases.",
            "mechanistic_understanding_requirements": "High: scientific interpretation requires correct identification of chemical environments and physical plausibility; models are used as decision aids and require validation.",
            "ai_methodology_name": "Supervised neural networks and ensemble learning",
            "ai_methodology_description": "Neural networks trained on large sets of computed XAS spectra to map spectral features to labels (oxidation state, coordination); ensemble learning applied to improve robustness and generalizability; used for on-the-fly predictions and identification of sub-nanometer assemblies.",
            "ai_methodology_category": "supervised learning (regression/classification) and ensemble methods",
            "applicability": "Highly applicable where large simulated/computed spectral datasets exist; enables rapid automated interpretation of spectra that previously relied on manual fitting and expertise.",
            "effectiveness_quantitative": "Cited works report unprecedented analysis capability and availability of an ensemble algorithm capable of identifying oxidation state and coordination across diverse chemistries (no single numeric metric provided in this paper).",
            "effectiveness_qualitative": "Enables automated characterization of structural transformations and chemical environments, identification of subtle signals missed by manual inspection; ensemble approaches increase robustness.",
            "impact_potential": "High: accelerates experimental interpretation, supports on-the-fly beamline analysis, and reduces human bias in spectral interpretation.",
            "comparison_to_alternatives": "Compared to manual/physics-only interpretation, ML approaches provide faster, automated, and potentially more sensitive analysis when trained on comprehensive computed datasets.",
            "success_factors": "Availability of large, high-quality computed spectral databases, and appropriate supervised architectures and ensembles to generalize across chemistries.",
            "key_insight": "When comprehensive simulated spectral libraries are available, supervised ML and ensemble approaches can automate and enhance spectral interpretation, revealing subtle structural signals faster than traditional manual methods.",
            "uuid": "e2323.7",
            "source_info": {
                "paper_title": "Machine learning and big scientific data",
                "publication_date_yy_mm": "2020-01"
            }
        },
        {
            "name_short": "SAXS-1D baseline",
            "name_full": "SAXS-1D benchmark baseline (dense neural network)",
            "brief_description": "A SciML benchmark subtask using a simple multilayer dense neural network to classify one-dimensional SAXS profiles (sphere vs parallelepiped) trained on fully simulated data to evaluate model suitability and platform performance.",
            "citation_title": "here",
            "mention_or_use": "use",
            "scientific_problem_domain": "small-angle X-ray scattering (SAXS) / particle shape identification",
            "problem_description": "Classify 1D SAXS intensity profiles to identify particle shape (binary: sphere vs parallelepiped) using simulated one-dimensional scattering profiles.",
            "data_availability": "Abundant simulated data: 20,000 1D profiles (10k per class) with unit dispersity; datasets include ideal simulated, noise-added simulated, and beamline (real) datasets (latter lacks ground truth).",
            "data_structure": "Structured 1D numerical arrays (intensity vs momentum transfer q) of dimension [1 x 300].",
            "problem_complexity": "Moderate: distinguishing shape signatures in 1D profiles can be non-trivial if orientation or polydispersity varies; sub-benchmark simplified to fixed orientation/parameters to be separable in 1D.",
            "domain_maturity": "Established experimental method with mathematical forward models; ML application as benchmark and automated classifier is emerging.",
            "mechanistic_understanding_requirements": "Medium: classification aids structural understanding but full mechanistic interpretation may require model-based fitting; interpretability helpful for scientific trust.",
            "ai_methodology_name": "Multi-layer dense neural network (baseline)",
            "ai_methodology_description": "Supervised feed-forward neural network with three dense layers: input layer accepting 300 intensity values, a hidden layer with 100 ReLU neurons, and a single-output sigmoid neuron for binary classification; trained on simulated labelled data.",
            "ai_methodology_category": "supervised deep learning (classification)",
            "applicability": "Appropriate as a baseline on simulated data; simple dense models suffice for this simplified 1D benchmark but more complex models might be needed for real/noisy/heterogeneous beamline data.",
            "effectiveness_quantitative": "Benchmark experiments used 20,000 profiles with 70:30 train:test split; specific accuracy/F1 numbers are shown in figures in the paper but not enumerated in text; reported architecture/runtime differences: inference time was 40% of training time on CPU and 60% on GPU.",
            "effectiveness_qualitative": "Baseline dense NN provides reasonable classification for the simplified simulated task; platform (CPU vs GPU) affects runtime tradeoffs though not necessarily accuracy for this simple model.",
            "impact_potential": "Low-to-medium as a baseline: demonstrates feasibility of ML classification on simulated SAXS data and serves as a benchmark to evaluate more advanced models and hardware.",
            "comparison_to_alternatives": "Deliberately uses a simple dense model rather than CNNs to probe suitability; paper suggests more flexible models (e.g., CNNs) could be used but baseline suffices for the simplified task.",
            "success_factors": "Availability of large simulated labelled dataset and a simplified problem setup (fixed orientation/parameters) that reduces the complexity to enable a small dense NN to perform well.",
            "key_insight": "On simplified, fully simulated 1D scattering tasks with abundant labelled data, small dense neural networks are sufficient baselines; hardware choices influence runtime but not necessarily classification capability.",
            "uuid": "e2323.8",
            "source_info": {
                "paper_title": "Machine learning and big scientific data",
                "publication_date_yy_mm": "2020-01"
            }
        },
        {
            "name_short": "Sentinel-SLSTR baseline",
            "name_full": "Sentinel-SLSTR cloud masking baseline (dense neural network with Bayesian surrogate ground truth)",
            "brief_description": "A SciML benchmark for cloud masking in Sentinel-3 SLSTR imagery that combines Bayesian surrogate ground truth generation with a simple multilayer dense neural network baseline to classify pixels as cloud/non-cloud.",
            "citation_title": "here",
            "mention_or_use": "use",
            "scientific_problem_domain": "remote sensing / cloud detection from satellite imagery",
            "problem_description": "Per-pixel classification of SLSTR multi-channel satellite images into cloud vs non-cloud under realistic atmospheric conditions (cloud variability, snow/ice confusion, aerosols).",
            "data_availability": "Moderate: dataset of 1,000 SLSTR images (South Pacific, 2018) with 11 channels and two views; however, reliable ground truth is scarce and hand-labelling is infeasible, so Bayesian inference is used to generate surrogate labels.",
            "data_structure": "Multispectral image tiles (M x N x channels), here sub-sampled to 250x250 pixels per channel (vectorised inputs); structured multi-band image data.",
            "problem_complexity": "High: clouds are dynamic with variable texture and appearance, and discrimination is confounded by snow, ice, sun glint, aerosols and varying illumination; requires per-pixel decisions across spectral bands.",
            "domain_maturity": "Mature remote sensing domain with many classical and ML approaches; cloud masking remains an active area with many sensor-specific challenges.",
            "mechanistic_understanding_requirements": "Medium-to-high: false positives/negatives have significant downstream impacts (e.g., SST retrieval), so probabilistic/confidence outputs and interpretability are valuable.",
            "ai_methodology_name": "Multi-layer dense neural network (baseline) with Bayesian surrogate ground truth generation",
            "ai_methodology_description": "Ground truth surrogate generated per-pixel via Bayesian inference method from cited literature to provide labels/confidence; baseline classifier is a three-layer dense NN: input vectorised 9-channel image, hidden layer with 50 ReLU neurons, output sigmoid for binary classification; trained on 800 images with 200 validation.",
            "ai_methodology_category": "supervised learning with Bayesian label pre-processing (hybrid surrogate-label approach)",
            "applicability": "Applicable as a baseline; Bayesian surrogate labels allow supervised training despite lack of reliable human-labelled ground truth; more sophisticated models (CNNs, LSTMs, GANs) have been used elsewhere and could improve performance.",
            "effectiveness_quantitative": "Dataset split: 1,000 images (800 train / 200 validation); reported that GPU offers better training performance than CPU but no explicit accuracy/F1 metrics are enumerated in text.",
            "effectiveness_qualitative": "Baseline dense NN trained on Bayesian-derived labels works as a starting point; limitations stem from surrogate ground truth uncertainty and the simplicity of the dense model for spatial image data.",
            "impact_potential": "Medium: provides a reproducible benchmark and baseline for cloud masking on SLSTR data; Bayesian surrogate labelling enables supervised ML in absence of human-labelled ground truth.",
            "comparison_to_alternatives": "Paper notes many groups use deep CNNs, LSTMs, and GANs for cloud detection on other sensors; baseline intentionally simple to provide a reference point rather than state-of-the-art performance.",
            "success_factors": "Use of Bayesian surrogate labelling to overcome lack of ground truth, availability of multi-channel SLSTR data, and a clear benchmark split enabling performance and runtime comparisons across hardware.",
            "key_insight": "When reliable human-labelled ground truth is infeasible, principled surrogate-label generation (Bayesian inference) enables supervised training and benchmarking, but model architecture must match spatial structure of the data for best results.",
            "uuid": "e2323.9",
            "source_info": {
                "paper_title": "Machine learning and big scientific data",
                "publication_date_yy_mm": "2020-01"
            }
        },
        {
            "name_short": "Generative models (LSTM/ORGAN/GAN)",
            "name_full": "Generative neural network models for molecular/material design (LSTM, ORGAN, GANs)",
            "brief_description": "Neural generative architectures (LSTM, generative adversarial networks with reinforcement learning biasing e.g., ORGAN) used to propose novel molecular/material candidates and bias generation toward desired properties.",
            "citation_title": "Objectivereinforced generative adversarial networks (ORGAN) for sequence generation models",
            "mention_or_use": "mention",
            "scientific_problem_domain": "molecular/material design, drug discovery",
            "problem_description": "Generate new chemical/molecular structures or compositions optimized for desired properties (e.g., activity, band gap) using learned generative models and property-driven reinforcement signals.",
            "data_availability": "Varies: molecular databases can be large (e.g., chemical libraries), but labeled property data may be limited; cited work notes LSTMs can perform well with reduced training data in one-shot/low-data settings.",
            "data_structure": "Discrete sequence representations (SMILES) or graph-based molecular encodings; structured variable-length sequences or graphs.",
            "problem_complexity": "Very high: combinatorial chemical space is enormous; mapping structures to properties is nonlinear and multi-objective; requires exploration and constrained optimization in large discrete spaces.",
            "domain_maturity": "Active research area with growing adoption; theoretical chemical/physical models exist but data-driven generative design is emerging.",
            "mechanistic_understanding_requirements": "High for downstream applicability: generated candidates require chemical validity and physical plausibility; interpretability and validation via simulations/experiments are necessary.",
            "ai_methodology_name": "LSTM, ORGAN (GAN+reinforcement learning), GANs",
            "ai_methodology_description": "Sequence-based LSTM models trained to generate SMILES strings; ORGAN couples a GAN generator with reinforcement learning to bias generation towards target metrics; methods can incorporate property predictors to guide generation.",
            "ai_methodology_category": "generative modelling (deep learning) with reinforcement learning conditioning",
            "applicability": "Applicable for proposing candidate molecules/materials; success depends on training data, validity checks, and integration with property evaluation pipelines (simulations/experiments).",
            "effectiveness_quantitative": "Cited work reports LSTM can perform one-shot/low-data drug discovery tasks with much reduced data compared to some methods; no numeric success rates provided in this paper.",
            "effectiveness_qualitative": "Generative models show promise in suggesting novel candidates and steering generation toward desired properties, but require downstream validation and can produce chemically invalid structures without constraints.",
            "impact_potential": "High: potential to accelerate materials and molecular discovery pipelines if integrated with property evaluators and validation workflows.",
            "comparison_to_alternatives": "Traditional computational chemistry relies on physics-based search/optimization; generative ML can explore larger chemical spaces more rapidly but needs coupling to physics-based validation to ensure realism.",
            "success_factors": "Availability of chemical databases, ability to incorporate property feedback (reinforcement learning), and hybrid workflows for chemical validity checking and simulation-based validation.",
            "key_insight": "Generative neural models can explore vast chemical spaces and be biased toward target properties, but their scientific utility depends critically on training data quality and integration with physical validation to ensure chemical plausibility.",
            "uuid": "e2323.10",
            "source_info": {
                "paper_title": "Machine learning and big scientific data",
                "publication_date_yy_mm": "2020-01"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Positive-unlabeled convolutional neural networks for particle picking in cryo-electron micrographs",
            "rating": 2,
            "sanitized_title": "positiveunlabeled_convolutional_neural_networks_for_particle_picking_in_cryoelectron_micrographs"
        },
        {
            "paper_title": "A mixed-scale dense convolutional neural network for image analysis",
            "rating": 2,
            "sanitized_title": "a_mixedscale_dense_convolutional_neural_network_for_image_analysis"
        },
        {
            "paper_title": "Neural Network Approach for Characterizing Structural Transformations by X-Ray Absorption Fine Structure Spectroscopy",
            "rating": 2,
            "sanitized_title": "neural_network_approach_for_characterizing_structural_transformations_by_xray_absorption_fine_structure_spectroscopy"
        },
        {
            "paper_title": "High-throughput computational X-ray absorption spectroscopy",
            "rating": 2,
            "sanitized_title": "highthroughput_computational_xray_absorption_spectroscopy"
        },
        {
            "paper_title": "Objectivereinforced generative adversarial networks (ORGAN) for sequence generation models",
            "rating": 2,
            "sanitized_title": "objectivereinforced_generative_adversarial_networks_organ_for_sequence_generation_models"
        },
        {
            "paper_title": "Diffuse multiple scattering",
            "rating": 1,
            "sanitized_title": "diffuse_multiple_scattering"
        },
        {
            "paper_title": "De novo structure prediction with deeplearning based scoring",
            "rating": 2,
            "sanitized_title": "de_novo_structure_prediction_with_deeplearning_based_scoring"
        }
    ],
    "cost": 0.024150249999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Machine Learning and Big Scientific Data</p>
<p>Tony Hey 
Scientific Computing Department Rutherford Appleton Laboratory Science and Technology Facilities Council
OX11 0QXDidcotUK</p>
<p>Keith Butler 
Scientific Computing Department Rutherford Appleton Laboratory Science and Technology Facilities Council
OX11 0QXDidcotUK</p>
<p>Sam Jackson 
Scientific Computing Department Rutherford Appleton Laboratory Science and Technology Facilities Council
OX11 0QXDidcotUK</p>
<p>Jeyarajan Thiyagalingam 
Scientific Computing Department Rutherford Appleton Laboratory Science and Technology Facilities Council
OX11 0QXDidcotUK</p>
<p>Machine Learning and Big Scientific Data
A265FF0371E956687E33059B9045423A
This paper reviews some of the challenges posed by the huge growth of experimental data generated by the new generation of large-scale experiments at UK national facilities at the Rutherford Appleton Laboratory site at Harwell near Oxford.Such 'Big Scientific Data' comes from the Diamond Light Source and Electron Microscopy Facilities, the ISIS Neutron and Muon Facility, and the UK's Central Laser Facility.Increasingly, scientists are now needing to use advanced machine learning and other AI technologies both to automate parts of the data pipeline and also to help find new scientific discoveries in the analysis of their data.For commercially important applications, such as object recognition, natural language processing and automatic translation, deep learning has made dramatic breakthroughs.Google's DeepMind has now also used deep learning technology to develop their AlphaFold tool to make predictions for protein folding.Remarkably, they have been able to achieve some spectacular results for this specific scientific problem.Can deep learning be similarly transformative for other scientific problems?After a brief review of some initial applications of machine learning at the Rutherford Appleton Laboratory, we focus on challenges and opportunities for AI in advancing materials science.Finally, we discuss the importance of developing some realistic machine learning benchmarks using Big Scientific Data coming from a number of different scientific domains.We conclude with some initial examples of our 'SciML' benchmark suite and of the research challenges these benchmarks will enable.</p>
<p>The Deep Learning Revolution and 'AI for Science'</p>
<p>It is arguable that the Deep Learning revolution we are now witnessing dates back to the ImageNet database and the AlexNet Deep Learning network [1].ImageNet was a project that was led by Professor Fei-Fei Li from Stanford University and the database contained over 14 million high-resolution images collected from the Web.The images were labeled by crowd-sourcing human labelers recruited using Amazon's Mechanical Turk.Starting in 2010, an annual competition called the ImageNet Large-Scale Visual Recognition Challenge [2] was held using the database.The competition used a subset of the ImageNet collection with roughly 1000 images in each of 1000 categories.In all, there were roughly 1.2 million training images, 50,000 validation images, and 150,000 testing images.The intent was to provide the computer science community with a focus for evaluating the effectiveness and progress of computer vision systems.A landmark breakthrough in image classification was made in 2012 by Geoffrey Hinton and two of his PhD students, Alex Krizhevsky and Ilya Sutskever.AlexNet, as their neural network implementation became to be called, used a so-called 'Deep Neural Network' consisting of five convolutional layers and three fully connected layers and was implemented using two GPUs.</p>
<p>Their paper won the 2012 ImageNet competition and reduced the error rate by an astonishing 10.8% compared to the previous winner [3].The 2015 competition was won by a team from Microsoft Research using a very deep neural network of over 100 layers and achieved an error rate for object recognition comparable to human error rates [4].In the words of Geoffrey Hinton, 'Deep Learning is an algorithm which has no theoretical limitations on what it can learn; the more data you give and the more computational time you provide the better it is' [5].</p>
<p>Can such AI algorithms benefit scientific research?Google's DeepMind subsidiary in the UK has brought together physicists, machine learning experts and structural biologists to create a system called 'AlphaFold' [6].The DeepMind team entered the biennial competition organized by CASP (Critical Assessment of protein Structure Prediction) that assesses the state of the art in threedimensional protein structure modeling [7].David Baker, a CASP organizer and developer of the Rosetta protein folding program at the University of Washington in Seattle [8], commented that 'DeepMind's scientists built on two algorithm strategies pioneered by others.First, by comparing vast troves of genomic data on other proteins, AlphaFold was able to better decipher which pairs of amino acids were most likely to wind up close to one another in folded proteins.Second, related comparisons also helped them gauge the most probable distance between neighboring pairs of amino acids and the angles at which they bound to their neighbors.Both approaches do better with the more data they evaluate, which makes them more apt to benefit from machine learning computer algorithms, such as AlphaFold, that solve problems by crunching large data sets' [9].The predictions of the AlphaFold system were remarkably good and better on average than the other 97 competitors.However, there is still hope for scientists.After the competition David Baker remarked that 'Deep Mind made much better fold level predictions than everybody, including us, using DL on co-evolution data.For problems where there are not many homologous sequences, and for protein structure refinement, I would expect their approach to work less well, as it doesn't have any physical chemistry (they used Rosetta to build their final models from predicted distances)' [10].</p>
<p>In this paper, we make some initial explorations into the application of such Deep Learning approaches applied to scientific data.The Rutherford Appleton Laboratory (RAL), at Harwell near Oxford, hosts several large-scale experimental facilities that now generate large volumes of increasingly complex scientific data.These are the Diamond Synchrotron Light Source and Electron Beam Facility, the ISIS Neutron and Muon Facility and the UK's Central Laser Facility.In addition, the Scientific Computing Department at the Laboratory hosts the UK's Tier 1 Centre for particle physics data from the Large Hadron Collider at CERN and the Natural Environmental Research Council's JASMIN 'Super Data Cluster' that supports their Centre for Environmental Data Analysis.The Scientific Machine Learning (SciML) group at the Lab is now partnering with the Alan Turing Institute, the UK's national institute for data science and artificial intelligence, in their new 'AI for Science' research theme.The SciML group will also be providing the 'PEARL' GPU computing service to Turing researchers on two NVIDIA DGX-2 GPU systems.</p>
<p>After outlining three example applications of machine learning applied to data generated by the RAL Facilities, we discuss the challenges in combining experimental and computational simulation data for progress in materials science.The article concludes with a discussion of progress towards the creation of a scientific machine learning benchmark suite.</p>
<p>Scientific Machine Learning at the Rutherford Appleton Laboratory: Three Examples</p>
<p>Introduction</p>
<p>Machine learning has the potential to be applied for the enhanced operation and functioning of large-scale big science projects.Our work in this area builds on notable successes from the application of machine learning to analyse and interpret data at national facilities, particularly in the USA.At Argonne National Laboratory machine learning is being used to complement reverse Monte Carlo structure determination from scattering experiments, by applying reinforcement learning [11].Researchers are X-ray tomography are also applying machine learning to assist with experiment orientation and facilitating better signal to noise ratios in low-dose experiments [12,13] and also using machine learning approaches to correlate diffraction and microscopy techniques to allow for advanced characterisation of phenomena such as lattice vibrations [14].</p>
<p>The Advanced Light Source at Berkeley is using machine learning to automate the collection and analysis of data from micro tomography experiments [15] and is also working with Argonne and the Materials Virtual Laboratory to automate the collection and curation of X-ray spectroscopic data [16].At Oak Ridge National Laboratory machine learning is being applied to the analysis of electron microscopy data for following materials dynamics, such as perovskite octahedral tilting</p>
<p>[17] and silicon migration in graphene [18], while researchers at the lab's spallation neutron source have used autoencoders to build physical models from inelastic neutron scattering experiments on a spin-ice material [19].Example also exist demonstrating how machine learning can be used for the enhanced operation of large facilities, recently a notable effort showed deep learning with multi-modal data could be used to predict plasma instabilities in large-scale fusion reactors [20].</p>
<p>Diamond Light Source and Cryo-Soft X-ray Tomography (CryoSXT)</p>
<p>The first example is from the Diamond Light Source, an experiment on tomographic biological imaging.Cryo-SXT is a 3D imaging method for the visualisation of cellular ultrastructure and specifically addresses the need for detailed, 3D information on cellular features in thick specimens, such as whole cells, with little or no chemical or mechanical modification [21].A major bottleneck in the analysis of the 3-D images created by such tomograms is in the segmentation of the images to distinguish between the cell nucleus, cytoplasm and the individual organelles.</p>
<p>Because there are few pre-labelled image sets, and the diversity of different cells is very large, it is not possible to straightforwardly use Deep Learning techniques.Instead, Michele Darrow and Mark Basham and their team have used 'shallow' machine learning techniques with some user annotation of a subset of images to speed up the segmentation process.These techniques have been incorporated into their SuRVoS segmentation workbench [22].Figure 1 gives an indication of this process.The team have also enlisted the help of citizen scientists using the Zooinverse platform for their 'Science Scribbler' project [23].showing how user annotation of a few images can be used to train a machine learning classifier to distinguish between the cell nucleus and cytoplasm.(Thanks to Mark Basham, DLS.)</p>
<p>Electron Cryo-Microscopy</p>
<p>Thanks to improvements in instrumentation and software, the use of electron cryo-microscopy (cryoEM) in molecular and cellular biology has increased dramatically in recent years.In the technique of single particle reconstruction, micrographs taken from flash-frozen samples of purified macromolecular complexes allow the reconstruction of high-resolution 3D molecular structures from multiple 2D views [24].Figure 2   Investment in infrastructure, such as the eBIC facility on the Harwell campus [26] and CCP-EM [27], is supporting a rapid expansion in the use of cryoEM in structural studies.Structure determination involves a sequence of steps, each of which could benefit from algorithmic and computational improvements.Given the large amount of data produced by modern microscopes and detectors, much of which is archived by the facilities themselves or by repositories such as EMPIAR [28], this is a promising area for data-driven approaches.</p>
<p>Machine learning approaches are beginning to be developed for cryoEM, in particular exploiting recent advances in image recognition.The particle picking step of single particle analysis, in which individual molecular complexes are located in micrographs, has attracted the most attention.</p>
<p>Due to the intrinsic low contrast of soft matter, and the low dose applied in order to avoid radiation damage, identification of particles is not trivial.Particles represent different views of a molecular complex, depending on their orientation in the sample, and there may be multiple molecular species, as well as contaminants and other artefacts.Furthermore, tens or hundreds of thousands need to be identified from a set of micrographs to yield a high-resolution 3D reconstruction.The promise of machine learning is to reduce the amount of human time required to validate automatically picked particles or to pick missed ones.</p>
<p>As a recent example, Topaz is one of several new programs that use CNNs to learn how to recognise particles in a micrograph [29].It uses a positive vs unlabelled classification scheme to train a model based on a small set of annotated particles.In the case of a ribosome dataset, Topaz picked 1.72x more particles than the published picks, resulting in the highest resolution structure of this dataset to date.</p>
<p>Fluorescence Localisation Imaging with Photobleaching (FLImP)</p>
<p>The OCTOPUS (Optics Clustered To OutPut Unique Solutions) imaging facility in the Central Laser Facility at RAL combines multidisciplinary expertise, techniques and infrastructure to generate and explore data for understanding biological processes from the scale of cells to single molecules [30].Automation is increasingly important to help address this challenge, both to increase throughput and exploitation of the instrumentation, and to reduce the expertise needed by users to use the facility and translate its methods outside the facility environment.A key project is a focus on automation of the Fluorescence Localisation Imaging with Photobleaching (FLImP) method.FLImP, developed in OCTOPUS, is a single molecule method which allows molecular structure determination in fixed cells at ~5nm.It has been used to measure structural fingerprints of cancer-causing proteins in cells with unprecedented detail [31].</p>
<p>A recent collaboration led by the OCTOPUS team, and involving partners from medicine, the pharmaceutical industry and a commercial instrumentation company, seeks to utilise deep learning techniques to automate FLImP to deliver a convenient, high-throughput assay for more efficient use of FLImP in the laboratory and to translate it to the clinic as a new method for precise, personalized cancer diagnosis and treatment.As with all super-resolution imaging techniques, FLImP requires images that meet a number of conditions for implementation of the technique, including: the correct density of fluorescently labelled proteins, the ability to differentiate cells from non-specific background labelling, relative background homogeneity and obtaining sufficient frames to observe the required number of photo-bleaching events and photons.At present, successful FLImP imaging is a user-intensive process, requiring operators to manually select regions of interest for image acquisition.The successful translation of FLImP technology from bench to bedside therefore requires the automation of this image segmentation task to enable the scale-up of this technology.This is a challenging problem, particularly as single fluorescently labelled proteins are diffraction limited in size and therefore difficult to individually segment from images using conventional convolutional neural networks [32].To this end, the OCTOPUS team have utilised a UNET based model capable of automatically and rapidly segmenting regions of appropriate FLImP object density from micrographs derived from monocell cultures (Figure 3 (C)).The team is currently working with clinical collaborators to extend this technique to permit multi-label classification to identify cells of interest from more diverse clinically derived samples that may include cells from a number of populations, only some of which are suitable for FLImP, and integrate these models into instrumentation suitable for clinical translation.</p>
<p>Machine Learning and Materials Science</p>
<p>Overview of Materials Science and Machine Learning</p>
<p>Machine learning has started to change the way that we do materials science; contributing to accelerated characterization, synthesis and modelling.These advances are driven by the availability of easy to use packages for building machine learning models, e.g.Scikit-Learn [33] and Keras [34], as well as a recent proliferation of publicly available datasets, resulting in a materials science "ImageNet moment" where the availability of data fuels a step-change in datadriven approaches.We will briefly survey some of the cutting-edge machine learning work in the areas of materials discovery and characterization as well as outlining some of the work of the SciML team that is using machine learning to analyse data produced at the UK's large national scientific facilities.</p>
<p>Computational materials science dates back to mid-twentieth century, an early example being the quantum chemistry exchange programme, which allowed experimental chemists to perform quantum chemical calculations with relative ease [35].At this early stage, the paradigm of computational materials science was to use computational methods to help interpret experimental results by doing a small number of expensive calculations on materials whose structure was already well known.Density functional theory (DFT) was popularized by Walter Kohn and co-workers in the 1960s; with the advent of powerful super-computers in the late twentieth century performing large numbers of DFT calculations suddenly became feasible [36,37].Structure prediction methods based on global optimization algorithms such as particle swarm optimization and genetic algorithms mean that it is now possible to predict structure and properties for new materials starting from the composition alone [38].The availability of rapid and accurate DFT calculations has also facilitated the development of large, high-quality databases of calculated materials properties, for example the Materials Project, Aflow, Open Quantum Materials Database and Nomad [39].</p>
<p>The sudden availability of these datasets is revolutionizing the way that data-driven approaches are used in materials science.Figure 4 plots the number of publications containing "machine learning materials" in them from the Web of Science.We also indicate on the figure dates that some notable databases became available, suggestive of the important role of these datasets are playing in driving the development of a new paradigm of computational materials science [40].</p>
<p>New machine learning approaches trained on computational databases are capable of making rapid and accurate predictions of materials properties by considering composition alone.The electronic band gap is a good example of a material property that is important in a range of applications from microelectronics to photovoltaics.A number of studies have reported machine learning algorithms that are capable of predicting the band gap of a material from its composition [41 -43].These kinds of algorithms can be incorporated into materials discovery workflows and have recently been applied to the prediction of new photoactive earth-abundant materials for photocatalysis [44].Generative models, using neural networks, are also now being used to postulate new molecular materials [45].For example, the long short-term memory (LSTM) neural network architecture has recently been shown to be able to predict new drug molecules using greatly reduced training data compared to other approaches [46].In the ORGAN project, a combination of generative adversarial network and reinforcement learning combine to bias molecular generation algorithms towards desired final metrics, potentially allowing the automated design of a molecule to meet a specific property [47].Interpretation of complicated experimental spectra has regularly relied on calculations for clarification, but now with databases of calculated properties available it is possible to develop machine learning algorithms to interpret spectra in an automated way, free from human bias and capable of identifying signals which are missed during manual inspection.A powerful recent example is in the field of X-ray absorption spectroscopy (XAS) where a dataset of calculated spectra was recently made available [48].Calculated spectra have been used to train neural networks, which are facilitating unprecedented analysis of materials datasets, for example, in characterising structural transformations in materials, in making on-the-fly predictions about the presence of chemical environments in a sample and in identifying sub-nanometer atomic assemblies [49 -51].Recently an ensemble learning algorithm trained on this dataset that is capable of identifying the oxidation state and coordination environment in a diverse range of chemistries has been made publicly available [52].</p>
<p>Machine Learning and Experimental Materials Data</p>
<p>The rapidly expanding capability of large-scale facilities to analyse material samples means that the demand for robust, automated, on-the-fly analysis is becoming ever more pressing.Examples such as the XAS studies described above show how a fusion of experiment, simulated data and machine learning algorithms can facilitate rapid interpretation of these rich new data sources.In the SciML team we are developing a range of machine learning algorithms for materials data analysis.</p>
<p>Inspired and challenged by the progress in machine learning at other large scale facilities outlined in the start of section 2 we have started to build a machine learning capability at the Rutherford Appleton Laboratory for analysis of materials science data collected on site.Here we present our work on diffuse multiple scattering experiments at the Diamond Light Source and on inelastic neutron scattering experiments at ISIS neutron and muon source.</p>
<p>Diffuse multiple scattering</p>
<p>Diffuse multiple scattering (DMS) is a relatively new crystallographic technique and has been made possible by the immense increase in flux of modern synchrotron sources and modern detector systems [53].DMS can be a powerful technique for allowing measurement of fine details such as lattice strain and for following structural phase transitions in materials.However, the detailed experimental setup requires expert knowledge and several time-consuming steps which limit the routine application of the technique.</p>
<p>One of the parameters that must be known for experimental analysis of DMS data is the azimuthal angle of the sample, which is not known a priori and determines the values at which reciprocal crystal lattice vectors cross the Ewald sphere, as defined in [53].We have trained a neural network consisting of convolutional and densely connected layers to predict the azimuthal angle of sample based on the observed scattering pattern.Typically, determination of the azimuthal angle is time-consuming task, requiring expert knowledge and representing a serious bottleneck for application of DMS.</p>
<p>We have built a database of 250,000+ simulated patterns, Ψ(R)T, using the DMS Python code, which are used to train the neural network [53]</p>
<p>DMS network methods:</p>
<p>The NN used for predicting the azimuthal angle of a DMS sample consists of convolutional and densely connected layers.The first convolutional layer contains 32 3x3 kernel filters, followed by a maxpooling of 2x2; the second convolutional layer contains 64 3x3 filters, followed by maxpooling of 2x2.We include a dropout rate of 0.2 between the convolutional layers to guard against over-fitting.The 2D data is then flattened and fed into a densely connected layer of 32 nodes, connected to a densely connected layer of 16 nodes.The final hidden layer is connected to a single output node with a linear activation function to allow the network to perform regression.All hidden layers are connected with rectified linear unit (ReLU) activation functions.The network is trained on 75% of the dataset and then validated on the remaining 25%.The training and validation curves are shown in Figure 6.</p>
<p>Magnon neutron scattering</p>
<p>Inelastic neutron scattering can provide detailed information about microscopic materials structure.In particular, the magnetic moment of neutrons allows one to probe the magnetic structure and ordering in a material.In this example we have investigated the use of NNs for predicting the magnetic coupling constants (J) in Rb2MnF4.Rb2MnF4 is a near-ideal 2D, spin 5/2 Heisenberg antiferromagnet and has been used extensively to test predictions for the 2D Heisenberg quantum Hamiltonian [54,55].As such, this system provides an ideal test case for exploring the ability of a NN for this task.</p>
<p>Rb2MnF4 consists of planes of MnF2 layers, with magnetic Mn arranged in a square lattice.</p>
<p>Experimentally it has been established that Rb2MnF4 has magnetic coupling between nearest neighbor Mn sites with a coupling constant variously measured as J=0.648±0.003,0.6544±0.014and 0.673±0.028meV depending on the experiment and fitting model [54,55].Careful examination of the spin wave energies along the antiferromagnetic zone boundary reveal that in addition to the nearest neighbor coupling, there is a next-nearest neighbor term in the Hamiltonian J', which has been measured to be 0.006±0.003and 0.012±0.002meV in different experiments [55,56].</p>
<p>In our study we built a training set of 29957 simulated spin wave spectra in the 2D (h, k, 0) plane from 0 ≤ h, k &lt; 1 of the of Rb2MnF4 using the SpinW code [57].This serves as our labelled training set R. We then train our NN to learn the relation between R and (J, J'); (J, J') = f(R), where the function f is the NN.After training (details below), we obtain a NN that has a mean average error of ±0.0055 meV on J and ±0.0036 meV on J', using data that was not included in the training set.</p>
<p>As a true test of the NN we provided experimental data collected on the MARI instrument at the ISIS neutron and muon source.The data was collected on a sample of Rb2MnF4 and the image of the integrated energy over the over the plane is shown in Figure 7.</p>
<p>The NN trained on simulated data predicts a value of J=0.6763 meV and J'=0.0104 meV for the experimental spectrum, in excellent agreement with previous experimental results.This demonstrates the ability of a convolutional NN to learn to predict magnetic coupling constants from simulated data, even picking up subtle, difficult to spot features, such as the value of the next-nearest-neighbour coupling constant J'.We stress here that prior knowledge was used to select a training set representative of a reasonable range of final values together with our intuition about the number of coupling constants present.This fusion of prior knowledge and NN architectures helps to greatly improve the efficiency of training and allows development of highquality models with significantly less data than would otherwise be required.We consider this an example of how NN can be used to augment existing expertise and assist in difficult analysis where some prior knowledge already exists.</p>
<p>Magnon network methods:</p>
<p>The NN used for predicting the magnetic coupling constants consist of four convolutional layers terminated by a densely connected layer.The first convolutional layer contains 32 3x3 kernel filters; the second convolutional layer contains 64 3x3 filters; the third convolutional layer contains 32 3x3 kernel filters; and the final convolutional layer contains 16 3x3 kernel filters, all convolutional layers are followed by maxpooling of 2x2.The 2D data is then flattened and fed into a densely connected layer of 2 nodes with a linear activation function to allow the network to perform regression.All hidden layers are connected with ReLU activation functions.</p>
<p>The network is trained on 27000 images of the dataset and then validated on the remaining 2957 images.The training and validation curves are shown in Figure 8.Before feeding the simulated images into the network they are converted to a 2D histogram of 128 x 128, we also apply a mask to the simulated data to cover the regions of the pattern that are not recorded due to the detector geometry -these appear as areas of purple in the image in Figure 7.</p>
<p>Figure 8 Training and validation scores for the mean absolute error for prediction of the coupling constants from an inelastic neutron scattering pattern.</p>
<p>Further work</p>
<p>In the examples given here, we have used convolutional neural nets (CNNs) to analyse spectra and patterns collected at synchrotron facilities and represented as images.Deep CNNs have revolutionised the field of image processing and recognition in many fields of business and research.As alluded to earlier, the explosion in popularity of NNs, and in particular of deep CNNs for image applications, has been driven largely by the availability of large labelled datasets for training.Deep CNNs typically rely on combinations of many types of operation and connection to achieve their most powerful results on the most difficult problems.This results in networks that not only require vast amounts of labelled data, but also have many tunable hyperparameters.This can hamper application in many materials science problems, where labelled datasets are limited.</p>
<p>Recently a new type of image recognition architecture, the mixed-scale dense MSD-NN neural network was introduced by researchers at Berkeley Laboratory [58].This architecture has several differences from traditional CNNs.The MSD-NN uses dilation filters rather than traditional convolutional kernels, this means that longer range correlations in images can be captured, depending on dilation settings (see Figure 9).In the MSD-NN all of the convolved layers are also fully connected, unlike a CNN where layers connect sequentially.This full connectivity means that the network does not have to remember information from layer to layer for the final outcome.</p>
<p>In initial work it has been shown that the MSD-NN can learn on significantly smaller datasets and with less hyper-parameter tuning than CNNs.In SciML, we are currently exploring the application of MSD-NNs for soft X-ray image segmentation and for a range of materials' science classification problems.</p>
<p>Figure 9 Top an illustration of a typical convolution filter (left) which convolves information from neighbour pixels and a dilation filter (right) which can convolve with pixels further removed.Lower a schematic representation of the fully connected mixed-dense neural network architecture.</p>
<p>Big Scientific Data and Machine Learning Benchmarks</p>
<p>Introduction</p>
<p>Benchmarking, as a means for measuring and assessing the performance of a given computer system, or as a software framework, has been a cornerstone of computing for years.Historically, these efforts began using small kernels or excerpts of loops, such as the Lawrence Livermore Loops, the Dhrystone and Whetstone benchmarks, and the LINPACK linear algebra benchmark.The key driver for these efforts was to compare runtime performance or the number of floating-point operations per second (Mflop/s) for different computer architectures.Over the years, however, the art of performance evaluation has changed to include a suite of benchmarks, such as the SPEC, ASCI, SPLASH, and NPB benchmark suites, and the measured parameters included multiple metrics, such as runtime performance and energy consumption.Although LINPACK is still a major baseline benchmark for estimating peak performance of the TOP500 supercomputing systems in the world, detailed system evaluation relies on multiple benchmark measurements covering multiple hardware platforms, often incorporating both CPUs and GPUs.More recently, new benchmark suites have been developed to cover other important aspects of computing systems such as storage and networking, with appropriate metrics.</p>
<p>Although architectures and compilers still play a critical role in the development of computing systems, the performance of machine learning systems is now becoming equally important with the rise of commercial applications of machine learning.As can be seen from our discussion above, machine learning is now also beginning to play a major role in scientific applications.Suitable scientific machine learning benchmarks are therefore now required not only to assess systems for these applications but also to assess the overall machine learning ecosystem in a scientific context.The complexity and diversity of machine learning frameworks, available hardware systems, evaluation techniques, suitable metrics for quantification, and the limited availability of appropriate scientific datasets make this a challenging endeavour.Early initiatives on this front include MLPerf [59], AI Benchmark Suites from BenchCouncil [60], CORAL-2 [61], and Deep500 [62,63].</p>
<p>• The MLPerf benchmark suite currently relies on several common commercially important machine learning-oriented tasks, such as image and object recognition, speech-to-text, sentiment analysis, translation and recommendation applications along with a set of baseline models [59].</p>
<p>However, it is very likely that the suite will incorporate scientific applications.The key metric of the MLPerf suite is speedup relative to a reference implementation.The MLPerf suite also relies on a number of large-scale datasets, covering different application cases within MLPerf.This collection of datasets is also likely to be extended to include scientific cases.</p>
<p>• The international BenchCouncil [http://www.benchcouncil.org] is organizing an AI System and Algorithm competition in 2019 [60].A number of their benchmark suites, namely, AIBench, HPC AI500, AIoT Bench, Edge AIBench, and BigDataBench, although not primarily focused on scientific applications, could be a useful complement to the SciML benchmarks proposed here.Each of these benchmark suites targets different domain of problem, such as IoTs or Edge computing devices, and includes a number of different types of benchmarks covering micro kernels, components and applications [64][65][66][67][68].</p>
<p>• The CORAL-2 suite includes a ML/DL micro-benchmark suite that captures operations that are fundamental to deep learning and machine learning [61].These include dense/sparse matrix multiplications, convolutions, recurrent-layers, and one-and two-dimensional Fast and Discrete Fourier Transform kernels (FFTs and DFTs).</p>
<p>• Finally, the Deep500 effort is predominantly focused on techniques for reliably reporting performance of deep learning applications using metrics such as scalability, throughput, communication volume and time-to-solution [62,63].This is more focused on methodology (and a corresponding framework) for quantifying and reporting deep learning performance than on any specific application.</p>
<p>One of the key motivations for this work reported in this paper is the lack of a comprehensive machine learning benchmarking initiative for scientific applications, such as particle physics, earth and environmental science, materials, space and life sciences.Such a scientific benchmark suite would facilitate better understanding of machine learning models and their suitability for different operations in a scientific context, rather than being solely oriented on performance.</p>
<p>The SciML Suite -An Overview</p>
<p>Our scientific machine learning benchmark suite, SciML, is intended to span multiple scientific domains, and cover several of the different types of problems arising in each domain.We will therefore provide a number of reasonably large and complex datasets specific to each domain together with one or more baseline models addressing particular domain-specific problems.In addition, the evaluation metrics for the SciML suite go beyond just the simple runtime performance (or speedup).Our goal is to capture the overall performance of a given scientific application by assessing both the training and inference times per sample, as well as the classification accuracy using one or more appropriate metrics.Here, we use classification accuracy, classification loss and F1 score as the relevant metrics.Classification accuracy is the ratio of correctly predicted outcomes to total number of predictions, and thus higher the accuracy, the better the model.The second metric, classification loss, measures the performance of the model by measuring how the predicted outcomes diverge from the actual ones.Finally, the F1 score is the harmonic mean of precision and recall, where the precision is the number of correct positive results divided by the number of all positive results returned by the classifier, and recall is the number of correct positive results divided by the number of all samples that should have been identified as positive.As such, the F1 score is often more useful than the raw classification accuracy when the class distributions are uneven.</p>
<p>The SciML suite will provide the specification of the task plus a reference implementation and can therefore be used to evaluate:</p>
<p>• Different hardware platforms, such as GPUs, TPUs or CPUs • Different ML-specific frameworks like TensorFlow or PyTorch</p>
<p>• Different implementation of models</p>
<p>The benchmark suite is currently in development and is intended to cover a number of different scientific domains with several problems of varying degrees of difficulty that demand different machine learning techniques.We discuss two of our prototype benchmarks in the subsections that follow.</p>
<p>Example 1: Small Angle X-Ray Scattering (SAXS)</p>
<p>The problem Small Angle X-Ray Scattering (SAXS) is one of the benchmarks within the domain of materials science and is particularly relevant to the structure of materials.SAXS helps identify how different materials are structurally organised at the particle level [69,70].Here, the term particle means the collective arrangement of several atoms [70].At this intermediate level of detail, each material can be regarded as being made up of particles of different shapes, such as spheres, rods, ellipsoids and parallelepipeds, and of different sizes, characterised by relevant parameters [71].</p>
<p>When an X-ray beam is sent through a material, particles within the target diffract the incoming X-rays, and the particle sizes, shapes and orientation with respect to the incoming beam determine the resulting diffraction pattern.The distributions of the scattered X-rays are recorded as two-dimensional images.We illustrate an example of different diffraction patterns in Figure 10.This two-dimensional diffraction pattern, at times, may contain more data than necessary.For instance, in some cases the material can be isotropic with particle arrangements symmetric in every direction, yielding diffraction patterns that are two-dimensionally symmetric.Under these circumstances, a one-dimensional profile can be obtained by integrating the two-dimensional profile over the two-dimensional domain.We show an example for a spherical particle which generates an isotropic two-dimensional profile and the matching one-dimensional profile shown in Figure 11.Fig. 11: An example of two-dimensional and one-dimensional scattering profile of a simple spherical particle.The profiles were generated by using the SASView Software [54].</p>
<p>The SAXS benchmark aims to characterise the material given its scattering profile, either one-or two-dimensional.The benchmark uses both simulated and real-world datasets as detailed below.</p>
<p>Here, we present a sub-benchmark of SAXS, namely SAXS-1D.This particular sub-benchmark focusses on the binary classification of a set of simulated one-dimensional profiles.The benchmark includes a dataset and a baseline model as discussed below.</p>
<p>SAXS Dataset</p>
<p>The SAXS-1D benchmark includes a purely simulated dataset with unit dispersity (particle sizes are not mixed).The actual datasets within the SAXS benchmark are in three categories: ideal simulated datasets; noise-added simulated datasets; and beamline datasets.The first two are generated using the relevant mathematical models [73], while the latter dataset is obtained from one of the beamlines at the Diamond Light Source.The key limitation of the last dataset is that there is no established ground truth, whereas the ground truth information is fully known for the simulated data of the other two cases.</p>
<p>The dataset for this benchmark is focused on identifying two different particle shapes: spheres and parallelepipeds.The sphere is characterised by the radius and is two-dimensionally isotropic.</p>
<p>The parallelepiped has three different shape parameters and multiple possible orientations.This sub-benchmark is a simplified case in which the orientation of the parallelepiped and two of the dimensional parameters remain unchanged so that the one-dimensional profile can clearly differentiate the parallelepiped from a sphere.</p>
<p>The simulated dataset contains 10,000 one-dimensional profiles for spheres and 10,000 onedimensional profiles for parallelepipeds.Out of these, we use 16,000 for training and 4,000 for testing with classes of the particle shapes equally distributed across the datasets.Each of these one-dimensional profiles provides the intensity (I) vs magnitude of the momentum vector (q) and has dimension of [1 x 300].</p>
<p>Baseline Model</p>
<p>Although there are several approaches for addressing this challenge, the easiest and perhaps the simplest model is a supervised learning model.Given that the underlying data is obtained through simulation, the ground truth is readily available.</p>
<p>As mentioned in the introductory section, one of the key expectations from the benchmark suite is to obtain a better understanding of different machine learning models and their suitability for different tasks.For this reason, instead of using a more flexible model like a convolutional neural network (CNN) and deep learning, for this sub-benchmark we use a simple, multi-layer neural network for the baseline version.More specifically, this baseline model consists of three densely connected layers, with the first layer capturing the input, which is an array of 300 intensity values, the middle layer with 100 neurons using ReLU as the activation function, and finally the output layer of size one with a sigmoid activation function.</p>
<p>Example 2: Sentinel Cloud Masking</p>
<p>This benchmark is intended to capture one of the challenges arising from the earth and atmospheric sciences, namely, the identification of clouds from satellite imagery.This process is often called 'cloud masking'.The masking or quantification of cloud is often an important precursor to using satellite imagery.Clouds are highly dynamic, and this influences their texture, thickness, opaqueness and transparency.The identification process can be very challenging in the presence of snow, sea ice, aerosols and sun glint.We show a cloud masking example in Figure 12.The Sentinel Cloud Masking benchmark will have several sub-benchmarks covering different image modalities, datasets and challenges.Here, we describe the sub-benchmark Sentinel-SLSTR.</p>
<p>Sentinel-3 is a constellation of two satellites carrying an array of instruments, including the Sea and Land Surface Radiometer (SLSTR) for measuring sea and land surface temperature, colour and topography to high accuracy.The Sentinel-SLSTR benchmark deals with this specific Sentinel modality.Here we describe the simplest case in which the masking is required above a part of the ocean where there is no sun glint.</p>
<p>The Sentinel-SLSTR benchmark deals with the problem of processing the SLSTR-based data.Given an M x N image, the task is to build a machine learning model for marking each pixel as either cloud or non-cloud, using one of the simplest cases.This benchmark uses the SLSTR images only for the purposes of classification.</p>
<p>Sentinel SLSTR Dataset</p>
<p>The overall Sentinel-3 benchmark relies on multiple datasets obtained from different sensors and covers multiple bands in the electromagnetic-spectrum.The Sentinel-SLSTR part of the benchmark uses a collection of 1,000 SLSTR images captured over the South Pacific Ocean region in 2018.The dataset contains significant variation in the number of cloudy pixels with near-ideal illumination of clouds.The data includes 11 channels ranging from very near infra-red, VNIR (0.55 micrometer) to thermal infra-red IR (12.0 micrometer) wavelengths and has two views (nadir and oblique).The spatial resolution is 0.5km in the VNIR and short-wave infra-red (SWIR) channels and 1km in the thermal IR channels.In all experiments the nadir view of channels S1-S9 are used as inputs.To reduce the computational demand, this particular benchmark uses sub-sampled images of 250x250 pixels for each channel.The suite specifies a random selection of 800 images for training with the remaining 200 images for validation.</p>
<p>Baseline Model</p>
<p>Unlike our SAXS-1D benchmark that uses simulated data, the key difficulty in building any supervised machine learning model for this Cloud benchmark is the lack of a reliable ground truth.Collective or crowd-sourced hand labelling of these images for ground truth is infeasible for two reasons: the time required for hand-labelling is prohibitive given the volume of images, and secondly, this is a very subjective process even with among experts.For this reason, we use Bayesian inference to generate our surrogate artificial "ground truth" [74][75][76].More specifically, for each pixel, we apply the method in reference [74] to mark each pixel as cloud or non-cloud with a corresponding confidence value.This is used as a ground truth in training our networks.</p>
<p>The baseline model we implement for masking cloud on SLSTR data is a plain, multi-layer neural network.Although CNNs or DCNNs have not been used for SLSTR or Sentinel-3 data, many authors have attempted to apply deep learning [77][78][79][80][81][82][83][84] and other complex NN models, such as LSTMs [85] and GANs [86] to cloud screening using other remote sensing instruments.In our case, the neural network-based baseline model consists of three densely connected layers with the first layer capturing the nine-channel images as vectorised inputs, the middle layer with 50 neurons using ReLU as the activation function, and finally the output layer using the sigmoid activation function with one neuron.</p>
<p>Results</p>
<p>The SAXS-1D and Sentinel-SLSTR benchmarks were evaluated on two architectures.These were a CPU system with two Xeon E5-2630-v3 processors, 20MB Cache, 64GB RAM, and 16 cores (32 hyper-threaded), and a GPU system with a TITAN-X (Pascal) GPU with 12GB DDR and 3840 GPU cores.</p>
<p>For both cases we report the classification performance (F1, accuracy and loss) and runtimes (training and inference time per sample).Wherever possible, we repeat the same across the different datasets.In Figure 13, we show the classification performance of the SAXS-1D benchmark.The dataset has 20,000 1D profiles (with a 70:30 train:test split).For a simple baseline, it can be observed that different architectures yield different classification performance (both loss and accuracy).As the class divisions are even between the spheres and the parallelepiped, the F1 performance and the classification accuracy are the same here.We then show the overall training time and inference time performance for the same benchmark in Figure 14.The key observation here is that the inference time, as a percentage of overall training time, is different between two different architectures.More specifically, the inference time is 40% of the training time for the CPU architecture while for GPU it is 60%.</p>
<p>We show the classification and runtime performance for the Sentinel-SLSTR in Figure 15, using the dataset described above.Given the baseline is with a single data set, we cannot draw any conclusions on the relationship between accuracy and dataset size.However, we observe that, as expected, the GPU architecture offers better training performance compared to the CPU platform.</p>
<p>Concluding Remarks</p>
<p>Deep learning is transforming many areas of computer science and underpinning the AI revolution that is happening around us.At the UK's Rutherford Appleton Laboratory, the large experimental facilities are now generating large volumes of increasingly complex data which will require new AI technologies to manage and interpret.In this paper we have given some examples of the opportunities for machine learning to play an important role both in the generation and analysis of some of these large datasets.In many areas of science, we are now seeing the emergence of a genuinely new 'Fourth Paradigm' of data-intensive scientific discovery [87,88].</p>
<p>For example, the combination of chemical databases, experimental data and detailed computer simulations is now leading to exciting new opportunities in materials science.</p>
<p>We have also introduced initial results on creating a scientific machine learning benchmark suite (SciML) covering a range of different scientific domains.Such a benchmark suite, based on scientific datasets of a significant scale and complexity, will enable scientists, computer scientists and data scientists to map out the applicability and limitations of deep learning neural networks and other machine learning algorithms applied to a range of real applications.Analysis of the SciML benchmark results will also reveal the strengths and weaknesses of the different computing platforms -from commercial Clouds and HPC systems to GPUs and FPGAs.These benchmarks will also provide scientists with hands-on experience of using machine learning algorithms and environments on realistic-scale scientific datasets.In addition, the SciML benchmark suite will provide an important platform for research.One urgent research issue for scientists is the need to develop a disciplined framework for the uncertainty quantification (UQ) of deep learning algorithms.Another important issue is the need for transparency in understanding how such deep neural networks reach their conclusions.The robustness of deep learning predictions and their vulnerability to adversarial noise attacks also give genuine cause for concern.For applications in areas such as materials science and the life sciences, the challenge of incorporating physical, chemical or biological constraints into deep learning algorithms is an exciting topic for research.Despite these undoubted research challenges, the success of DeepMind's AlphaFold project has shown the effectiveness of deep learning for protein folding prediction.Could deep learning have a similarly transformative impact on other areas of dataintensive science?</p>
<p>Fig. 1 :
1
Fig. 1: Schematic representation of the workflow for a Cryo-Soft X-ray tomography experiment</p>
<p>shows a schematic of the cryoEM data processing pipeline [25].</p>
<p>Fig. 2 A
2
Fig. 2 A schematic of the single particle reconstruction cryoEM pipeline.Image thanks to Creative Biostructure, https://www.creative-biostructure.com</p>
<p>Fig. 3 :
3
Fig. 3: [A] Overview of the techniques employed at OCTOPUS.[B] An illustration of the automating FLImP integrated intensity track selection process.[Bi] Raw FLImP track showing regions deemed suitable (blue) and unsuitable (red) for FLImP analysis.[Bii] Processed FLImP track from [Bi] with distinct levels detected.[C] Automatic detection of regions suitable for FLImP using a deep learning approach.</p>
<p>Figure 4 :
4
Figure 4: The ML explosion in materials science.The number of papers containing the terms machine learning and materials are plotted on a bar chart.We also indicate the dates of materials data repositories becoming available and plot the number of citations for popular machine learning toolkit, Scikit-Learn over the same period.</p>
<p>. The simulated patterns provide a labelled ground truth of azimuthal angles, as a function of the patterns Ψ(R)T.We then train our NN to predict Ψ based on the input image R, updating the filters, weights and biases of the NN to minimize the difference between predicted Ψ(R)NN and Ψ(R)T.The NN that we train is then capable of predicting the azimuthal angle to within 6.5⁰, see Figure 5.The NN, once trained, can provide an answer in a fraction of the time required for exhaustive comparison of images.</p>
<p>Figure 5
5
Figure 5 Schematic representation of the CNN used to predict coupling azimuthal angle from diffuse multiple scattering images.A 2D map of multiple scattering lines is passed through 2 convolutional layers, flattened and passed through two densely connected layers and finally passed to a single output node for Ψ.Note that the numbers of filters and nodes are just for illustration, see methods section on DMS network for details.</p>
<p>Figure 6
6
Figure 6 Training and validation scores for the mean absolute error for prediction of the azimuthal angle of a DMS pattern.</p>
<p>Fig. 7
7
Fig. 7 Schematic representation of the CNN used to predict coupling constants from inelastic neutron scattering images.A 2D map of integrated energy is passed through 4 convolutional layers, flattened and densely connected to two output nodes for J and J'.Note numbers of filters and nodes are just for illustration, see methods section on Magnon network for details.</p>
<p>Fig. 10 :
10
Fig.10: An example of two-dimensional scattering patterns for sub-shapes of sphere, cylinder, ellipsoid and parallelepiped shapes, from left to right, respectively.The profiles were generated by using the SASView Software[72].</p>
<p>Fig. 12 .
12
Fig. 12.This shows an example of cloud masking data.Left to right: actual image, ground truth, our generated probability mask, and our generated map.Here, white regions represent the cloud and yellow regions provide the probability map.The colours in the first image are due to the different reflective behavior of different elements in the image, such as sea, ice, land and cloud.</p>
<p>Fig. 13 :
13
Fig. 13: Performance of the SAXS-baseline model on CPU and GPU systems.The figure shows the classification performance of the binary classification problem on the 1D profiles of mono-disperse shapes on two different datasets, on two different architectures.</p>
<p>Fig. 14 .
14
Fig.14.Training and inference time per sample across two datasets for the SAXS-1D benchmark.</p>
<p>Figure 15 .
15
Figure 15.Classification and runtime performance for the Sentinel-SLSTR benchmark, where the classification task is to mark each pixel as 'Cloud' or 'Not Cloud'.</p>
<p>AcknowledgementsThe authors wish to thank Mark Basham; Tom Burnley, Martyn Winn and Jola Mirecka; Ben Davies and Dan Rolfe for their assistance in describing their work at the Diamond Light Source; at the Electron cryoEM Facility; and the OCTOPUS Laser Facility, respectively.This work was supported by Wave 1 of The UKRI Strategic Priorities Fund under the EPSRC Grant EP/T001569/1, particularly the "AI for Science" theme within that grant &amp; The Alan Turing Institute.We are grateful to James Hetherington, Oonagh McGee, Amit Mulji, Jon Rowe and Adrian Smith at the Turing Institute for their help and support.
The Deep Learning Revolution. T J Sejnowski, 2018 Oct 23MIT Press</p>
<p>ImageNet: A large-scale hierarchical image database. J Deng, W Dong, R Socher, L-J Li, Kai Li, Li Fei-Fei, 10.1109/CVPR.2009.5206848</p>
<p>Imagenet classification with deep convolutional neural networks. A Krizhevsky, I Sutskever, G E Hinton, Advances in Neural Information Processing Systems. 2012</p>
<p>Deep residual learning for image recognition. K He, X Zhang, S Ren, J Sun, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition2016</p>
<p>. Geoffrey Hinton, Lukas Masuch, Dec 2015. 26th August, 2019</p>
<p>De novo structure prediction with deeplearning based scoring. R Evans, J Jumper, J Kirkpatrick, L Sifre, T F Green, C Qin, A Zidek, A Nelson, A Bridgland, H Penedones, S Petersen, Annu Rev Biochem. 772018</p>
<p>Critical Assessment of protein Structure Prediction). 4 th September, 2019</p>
<p>. Rosetta , 4 th September, 2019</p>
<p>Google's DeepMind aces protein folding. R Service, 10.1126/science.aaw2747Science. 2018 Dec 6</p>
<p>. David Baker, February 2019private communication</p>
<p>. 10.1002/jcc.24304</p>
<p>. 10.1107/S1600577516020117</p>
<p>. 10.1038/s41598-018-19426-7</p>
<p>. 10.1088/0957-4484/27/37/374002</p>
<p>. 10.1117/12.2274731</p>
<p>. 10.1016/j.commatsci.2019.01.013arXiv:1902.06876</p>
<p>. 10.1038/s41586-019-1116-4</p>
<p>Cryo-soft X-ray tomography: using soft X-rays to explore the ultrastructure of whole cells. Emerging Topics in Life Sciences. M Harkiolaki, M C Darrow, M C Spink, E Kosior, K Dent, E Duke, 10.1042/ETLS201700862018 Mar 292</p>
<p>Super-Region Volume Segmentation workbench. I Luengo, M C Darrow, M C Spink, Y Sun, W Dai, C Y He, 10.1016/j.jsb.2017.02.007Journal of Structural Biology. 19812017 Apr</p>
<p>Zooniverse Science Scribbler: Virus Factory. 27th August, 2019</p>
<p>Cryo-electron microscopy -a primer for the non-microscopist. Jls Milne, M J Borgnia, A Bartesaghi, Eeh Tran, L A Earl, D M Schauder, 10.1111/febs.12078FEBS Journal. 28012012 Dec 17</p>
<p>Electron Bio-Imaging Centre (eBIC): the UK national research facility for biological electron microscopy. D K Clare, C A Siebert, C Hecksel, C Hagen, V Mordhorst, M Grange, 10.1107/S2059798317007756Acta Crystallographica Section D Structural Biology. 7362017 May 31</p>
<p>Collaborative Computational Project for Electron cryo-Microscopy. C Wood, T Burnley, A Patwardhan, S Scheres, M Topf, A Roseman, 10.1107/S1399004714018070Acta Crystallographica Section D Biological Crystallography. 7112015 Jan 1</p>
<p>EMPIAR: a public archive for raw electron microscopy image data. A Iudin, P K Korir, J Salavert-Torres, G J Kleywegt, A Patwardhan, 10.1038/nmeth.3806Nature Methods. 1352016 Mar 21</p>
<p>Positive-unlabeled convolutional neural networks for particle picking in cryo-electron micrographs. T Bepler, A Morin, J Brasch, S Lawrence, A J Noble, B Berger, Res Comput Mol Biol. 2018</p>
<p>. Apr. 10812</p>
<p>Optics clustered to output unique solutions: A multi-laser facility for combined single molecule and ensemble microscopy. D T Clarke, S W Botchway, B C Coles, S R Needham, S K Roberts, D J Rolfe, 10.1063/1.3635536Review of Scientific Instruments. 829937052011 Sep</p>
<p>EGFR oligomerization organizes kinase-active dimers into competent signalling platforms. S R Needham, S K Roberts, A Arkhipov, V P Mysore, C J Tynan, L C Zanetti-Domingues, 10.1038/ncomms13307Nature Communications. 712016 Oct 31</p>
<p>Lightweight Deep Convolutional Network for Tiny Object Recognition. T-D Truong, V-T Nguyen, M-T Tran, 10.5220/0006752006750682Proceedings of the 7th International Conference on Pattern Recognition Applications and Methods. SCITEPRESS -Science and Technology Publications. the 7th International Conference on Pattern Recognition Applications and Methods. SCITEPRESS -Science and Technology Publications2018</p>
<p>Scikit-learn: Machine Learning in Python. F Pedregosa, Journal of Machine Learning Research. 122011 Oct. Oct</p>
<p>. F Chollet, 27th August 2019</p>
<p>Quantum Chemistry Program Exchange, Facilitator of Theoretical and Computational Chemistry in Pre-Internet History. D B Boyd, ACS Symposium Series. Internet</p>
<p>. 10.1021/bk-2013-1122.ch0082013American Chemical Society</p>
<p>Inhomogeneous Electron Gas. Physical Review. P Hohenberg, W Kohn, 10.1103/PhysRev.136.B8641964 Nov 9136</p>
<p>Self-Consistent Equations Including Exchange and Correlation Effects. W Kohn, L J Sham, 10.1103/PhysRev.140.A1133Physical Review. 1404A1965 Nov</p>
<p>Structure prediction drives materials discovery. A R Oganov, C J Pickard, Q Zhu, R J Needs, 10.1038/s41578-019-0101-8Nature Reviews Materials. 452019 Apr 4</p>
<p>The 2019 materials by design roadmap. K Alberi, M B Nardelli, A Zakutayev, L Mitas, S Curtarolo, A Jain, 10.1088/1361-6463/aad926Journal of Physics D: Applied Physics. 521130012018 Oct</p>
<p>Machine learning for molecular and materials science. K T Butler, D W Davies, H Cartwright, O Isayev, A Walsh, 10.1038/s41586-018-0337-2Nature. 55977152018 Jul</p>
<p>Prediction model of band gap for inorganic compounds by combination of density functional theory calculations and machine learning techniques. J Lee, A Seko, K Shitara, K Nakayama, I Tanaka, 10.1103/PhysRevB.93.115104Physical Review B. 93112016 Mar 1</p>
<p>Machine-Learning-Assisted Accurate Band Gap Predictions of Functionalized MXene. A C Rajan, A Mishra, S Satsangi, R Vaish, H Mizuseki, K-R Lee, 10.1021/acs.chemmater.8b00686Chemistry of Materials. 30122018 May 31</p>
<p>Predicting the Band Gaps of Inorganic Solids by Machine Learning. Y Zhuo, Mansouri Tehrani, A Brgoch, J , 10.1021/acs.jpclett.8b00124The Journal of Physical Chemistry Letters. 972018 Mar 13</p>
<p>Computer-aided design of metal chalcohalide semiconductors: from chemical composition to crystal structure. D W Davies, K T Butler, J M Skelton, C Xie, A R Oganov, A Walsh, 10.1039/C7SC03961AChemical Science. 942018</p>
<p>Inverse molecular design using machine learning: Generative models for matter engineering. B Sanchez-Lengeling, A Aspuru-Guzik, 10.1126/science.aat2663Science. 36164002018 Jul 26</p>
<p>Low Data Drug Discovery with One-Shot Learning. H Altae-Tran, B Ramsundar, A S Pappu, V Pande, 10.1021/acscentsci.6b00367ACS Central Science. 342017 Apr 3</p>
<p>Objectivereinforced generative adversarial networks (ORGAN) for sequence generation models. G L Guimaraes, B Sanchez-Lengeling, C Outeiral, P L Farias, A Aspuru-Guzik, arXiv:1705.108432017 May 30arXiv preprint</p>
<p>High-throughput computational X-ray absorption spectroscopy. Scientific Data. K Mathew, C Zheng, D Winston, C Chen, A Dozier, J J Rehr, 10.1038/sdata.2018.1512018 Jul 315</p>
<p>Neural Network Approach for Characterizing Structural Transformations by X-Ray Absorption Fine Structure Spectroscopy. J Timoshenko, A Anspoks, A Cintins, A Kuzmin, J Purans, A I Frenkel, 10.1103/PhysRevLett.120.225502Physical Review Letters. 120222018 May 31</p>
<p>Classification of local chemical environments from xray absorption spectra using supervised machine learning. M R Carbone, S Yoo, M Topsakal, D Lu, 10.1103/PhysRevMaterials.3.033604Physical Review Materials. 332019 Mar 13</p>
<p>Subnanometer Substructures in Nanoassemblies Formed from Clusters under a Reactive Atmosphere Revealed Using Machine Learning. J Timoshenko, A Halder, B Yang, S Seifert, M J Pellin, S Vajda, 10.1021/acs.jpcc.8b07952The Journal of Physical Chemistry C. 122372018 Aug 26</p>
<p>Automated generation and ensemble-learned matching of X-ray absorption spectra. npj Computational Materials. C Zheng, K Mathew, C Chen, Y Chen, H Tang, A Dozier, 10.1038/s41524-018-0067-x2018 Mar 204</p>
<p>Diffuse multiple scattering. Aga Nisbet, G Beutier, F Fabrizi, B Moser, S P Collins, 10.1107/S2053273314026515Acta Crystallographica Section A Foundations and Advances. 7112015 Jan 1</p>
<p>Neutron Scattering Investigation of Phase Transitions and Magnetic Correlations in the Two-Dimensional Antiferromagnets K2NiF4, Rb2MnF4, Rb2FeF4. Physical Review B. R J Birgeneau, H J Guggenheim, G Shirane, 10.1103/PhysRevB.1.22111970 Mar 11</p>
<p>Twomagnon excitations observed by neutron scattering in the two-dimensional spin-5/2 Heisenberg antiferromagnet Rb2MnF4. T Huberman, R Coldea, R A Cowley, D A Tennant, R L Leheny, R J Christianson, 10.1103/PhysRevB.72.014413Physical Review B. 7212005 Jul 6</p>
<p>Spin fluctuations in random magnetic-nonmagnetic two-dimensional antiferromagnets. I. Dynamics. Physical Review B. R A Cowley, G Shirane, R J Birgeneau, H J Guggenheim, 10.1103/PhysRevB.15.42921977 May 115</p>
<p>Linear spin wave theory for single-Q incommensurate magnetic structures. S Toth, B Lake, 10.1088/0953-8984/27/16/166002Journal of Physics: Condensed Matter. 27161660022015 Mar 30</p>
<p>A mixed-scale dense convolutional neural network for image analysis. D M Pelt, J A Sethian, 10.1073/pnas.1715832114Proceedings of the National Academy of Sciences. the National Academy of Sciences2017 Dec 26115</p>
<p>. Mlperf, 13 th May, 2019</p>
<p>BenchCouncil. 4 th September, 2019</p>
<p>Coral-2 Benchmark. 13 th May, 2019</p>
<p>A Modular Benchmarking Infrastructure for High-Performance and Reproducible Deep Learning. T Ben-Nun, M Besta, S Huber, A N Ziogas, D Peter, T Hoefler, IEEE International Parallel &amp; Distributed Processing Symposium. 2019 May33</p>
<p>T Ben-Nun, M Besta, S Huber, A N Ziogas, D Peter, T Hoefler, arXiv:1901.10183A Modular Benchmarking Infrastructure for High-Performance and Reproducible Deep Learning. 2019 Jan 29arXiv preprint</p>
<p>AIBench: An Industry Standard Internet Service AI Benchmark Suite. W Gao, 2019Technical Report</p>
<p>Z Jiang, BenchCouncil International Symposium on Benchmarking. 2018Technical ReportHPC AI500: A Benchmark Suite for HPC AI Systems</p>
<p>AIoT Bench: Towards Comprehensive Benchmarking Mobile and Embedded device Intelligence. C Luo, BenchCouncil International Symposium on Benchmarking. 2018Technical Report</p>
<p>T Hao, Edge AIBench: Towards Comprehensive End-to-end Edge Computing Benchmarking. 2018Technical ReportBenchCouncil International Symposium on Benchmarking</p>
<p>BigDataBench: a Scalable and Unified Big Data and AI Benchmark Suite. W Gao, 2018Technical Report</p>
<p>Small-angle scattering of X-rays. A Guinier, G Fournet, K L Yudowitch, 1955Wiley24</p>
<p>The SAXS guide: getting acquainted with the principles. H Schnablegger, Y Singh, 2011 OctAnton Paar GmbHAustria</p>
<p>SASView for small angle x-ray scattering. 13 th May, 2019</p>
<p>Small-angle X-ray scattering method to characterize molecular interactions: Proof of concept. N Allec, M Choi, N Yesupriya, B Szychowski, M R White, M G Kann, 10.1038/srep12085Scientific Reports. 512015 Jul 10</p>
<p>Atomic form factors, incoherent scattering functions, and photon scattering cross sections. J H Hubbell, W J Veigele, E A Briggs, R T Brown, D T Cromer, R J Howerton, 10.1063/1.555523Journal of Physical and Chemical Reference Data. 431975 Jul</p>
<p>Probabilistic physically based cloud screening of satellite infrared imagery for operational sea surface temperature retrieval. C J Merchant, A R Harris, E Maturi, S Maccallum, 10.1256/qj.05.15Quarterly Journal of the Royal Meteorological Society. 1316112005 Oct 1</p>
<p>Generalized Bayesian cloud detection for satellite imagery. Part 1: Technique and validation for night-time imagery over land and sea. S Mackie, O Embury, C Old, C J Merchant, P Francis, 10.1080/01431160903051703International Journal of Remote Sensing. 31102010 May 20</p>
<p>Generalized Bayesian cloud detection for satellite imagery. Part 2: Technique and validation for daytime imagery. S Mackie, C J Merchant, O Embury, P Francis, 10.1080/01431160903051711International Journal of Remote Sensing. 31102010 May 20</p>
<p>Cloud detection machine learning algorithms for PROBA-V. L Gomez-Chova, Mateo - Garcia, G Munoz-Mari, J , Camps- Valls, G , 10.1109/IGARSS.2017.81274372017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS). 2017</p>
<p>Fast Cloud Segmentation Using Convolutional Neural Networks. Remote Sensing. J Drönner, N Korfhage, S Egli, M Mühling, B Thies, J Bendix, 10.3390/rs101117822018 Nov 10101782</p>
<p>A Cloud Detection Algorithm for Remote Sensing Images Using Fully Convolutional Neural Networks. S Mohajerani, T A Krammer, P Saeedi, 10.1109/MMSP.2018.8547095IEEE 20th International Workshop on Multimedia Signal Processing (MMSP). IEEE2018. 2018</p>
<p>Cloud and cloud shadow detection in Landsat imagery based on deep convolutional neural networks. Remote Sensing of Environment. D Chai, S Newsam, H K Zhang, Y Qiu, J Huang, 10.1016/j.rse.2019.03.0072019 May225</p>
<p>Clouds Classification from Sentinel-2 Imagery with Deep Residual Learning and Semantic Image Segmentation. Remote Sensing. C-C Liu, Y-C Zhang, P-Y Chen, C-C Lai, Y-H Chen, J-H Cheng, 10.3390/rs110201192019 Jan 1011119</p>
<p>Deep learning based cloud detection for medium and high resolution remote sensing images of different sensors. Z Li, H Shen, Q Cheng, Y Liu, S You, Z He, 10.1016/j.isprsjprs.2019.02.017ISPRS Journal of Photogrammetry and Remote Sensing. 1502019 Apr</p>
<p>Distinguishing Cloud and Snow in Satellite Images via Deep Convolutional Network. IEEE Geoscience and Remote Sensing Letters. Y Zhan, J Wang, J Shi, G Cheng, L Yao, W Sun, 10.1109/LGRS.2017.27358012017 Oct14</p>
<p>Utilizing Multilevel Features for Cloud Detection on Satellite Imagery. Remote Sensing. X Wu, Z Shi, 10.3390/rs101118532018 Nov 21101853</p>
<p>M Rußwurm, M Körner, arXiv:1811.02471Convolutional LSTMs for Cloud-Robust Segmentation of Remote Sensing Imagery. 2018 OctarXiv preprint</p>
<p>Cloud Removal for Sentinel-2 Imagery Using a Cyclic Consistent Generative Adversarial Networks. P Singh, N Komodakis, Cloud-Gan, 10.1109/IGARSS.2018.8519033IGARSS 2018 -2018 IEEE International Geoscience and Remote Sensing Symposium. IEEE2018</p>
<p>The fourth paradigm: data-intensive scientific discovery. T Hey, S Tansley, K M Tolle, Hey AJ2009 OctMicrosoft researchRedmond, WA</p>
<p>The Fourth Paradigm Ten Years On. T Hey, A Trefethen, 2019</p>            </div>
        </div>

    </div>
</body>
</html>