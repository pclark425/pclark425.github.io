<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7889 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7889</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7889</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-144.html">extraction-schema-144</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods that use large language models to synthesize, distill, or generate scientific theories, hypotheses, or structured knowledge from collections of scholarly papers.</div>
                <p><strong>Paper ID:</strong> paper-3ddc8365ab4f048a4b8e6c4c3c7a99777c9dcf13</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/3ddc8365ab4f048a4b8e6c4c3c7a99777c9dcf13" target="_blank">KNIMEZoBot: Enhancing Literature Review with Zotero and KNIME OpenAI Integration using Retrieval-Augmented Generation</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> KNIMEZoBot represents an innovative integration of Zotero, OpenAI, and the KNIME visual programming platform to automate literature review tasks for users with no coding experience, demonstrating how thoughtfully designed AI tools can expand accessibility and accelerate knowledge building across diverse research domains.</p>
                <p><strong>Paper Abstract:</strong> Academic researchers face challenges keeping up with exponentially growing published findings in their field. Performing comprehensive literature reviews to synthesize knowledge is time-consuming and labor-intensive using manual approaches. Recent advances in artificial intelligence provide promising solutions, yet many require coding expertise, limiting accessibility. KNIMEZoBot represents an innovative integration of Zotero, OpenAI, and the KNIME visual programming platform to automate literature review tasks for users with no coding experience. By leveraging KNIME's intuitive graphical interface, researchers can create workflows to search their Zotero libraries and utilize OpenAI models to extract key information without coding. Users simply provide API keys and configure settings through a user-friendly interface in a locally stored copy of the workflow. KNIMEZoBot then allows asking natural language questions via a chatbot and retrieves relevant passages from papers to generate synthesized answers. This system has significant potential to expedite literature reviews for researchers unfamiliar with coding by automating retrieval and analysis of publications in personal Zotero libraries. KNIMEZoBot demonstrates how thoughtfully designed AI tools can expand accessibility and accelerate knowledge building across diverse research domains.</p>
                <p><strong>Cost:</strong> 0.009</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7889.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7889.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods that use large language models to synthesize, distill, or generate scientific theories, hypotheses, or structured knowledge from collections of scholarly papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RAG</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Retrieval-Augmented Generation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method that augments large language model generation with a retrieval step: documents are chunked and embedded into a vector store, nearest-neighbor passages are retrieved for a query, and an LLM conditions on those retrieved passages to produce grounded, cross-document summaries or answers.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>KNIMEZoBot: Enhancing Literature Review with Zotero and KNIME OpenAI Integration using Retrieval-Augmented Generation.</td>
                        </tr>
                        <tr>
                            <td><strong>authors</strong></td>
                            <td>Suad Alshammari et al.</td>
                        </tr>
                        <tr>
                            <td><strong>year</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Retrieval-Augmented Generation (RAG)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Documents (PDFs) are split into overlapping chunks, each chunk is converted to an embedding and stored in a vector index (FAISS); at query time the user query is embedded, nearest neighbor chunks are retrieved by semantic similarity, and an LLM (OpenAI GPT family) is prompted with the query plus retrieved passages to synthesize a coherent, grounded natural-language answer.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>Full-text PDFs (from Zotero library), metadata and extracted passages</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Synthesized natural-language answers / cross-document summaries (answer text), with citations/passages used for grounding</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_technique</strong></td>
                            <td>Retrieval-augmented generation (RAG); system message conditioning to restrict answers to provided library content</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>OpenAI GPT models (GPT-4, GPT-3.5 Turbo mentioned as selectable)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>datasets_used</strong></td>
                            <td>User Zotero libraries (collections of full-text scholarly PDFs); no standard benchmark dataset reported</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Qualitative demonstration: KNIMEZoBot can semantically search Zotero PDFs, retrieve relevant passages, and synthesize answers to user queries in a chatbot interface; no quantitative evaluation metrics reported.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Known LLM limitations (context window size and potential hallucination) are discussed; chunking required to stay within model input limits; no systematic accuracy evaluation provided.</td>
                        </tr>
                        <tr>
                            <td><strong>counterpoint</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'KNIMEZoBot: Enhancing Literature Review with Zotero and KNIME OpenAI Integration using Retrieval-Augmented Generation', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7889.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7889.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods that use large language models to synthesize, distill, or generate scientific theories, hypotheses, or structured knowledge from collections of scholarly papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>KNIMEZoBot</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>KNIMEZoBot (KNIME + Zotero + OpenAI RAG workflow)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An integrated, low-code workflow that implements a RAG pipeline inside KNIME to let non-coders query and synthesize knowledge from their Zotero libraries using OpenAI models, FAISS vector store, and LangChain-based PDF chunking.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>KNIMEZoBot: Enhancing Literature Review with Zotero and KNIME OpenAI Integration using Retrieval-Augmented Generation.</td>
                        </tr>
                        <tr>
                            <td><strong>authors</strong></td>
                            <td>Suad Alshammari et al.</td>
                        </tr>
                        <tr>
                            <td><strong>year</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>KNIMEZoBot (RAG-based Zotero-KNIME integration)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>The workflow programmatically pulls PDFs and metadata from Zotero via API, uses LangChain to load and chunk PDFs, computes embeddings (text-embedding-ada-002) and stores them in a FAISS index, and then uses OpenAI LLMs within KNIME nodes to answer user queries by retrieving semantically similar chunks and conditioning the LLM to synthesize answers constrained to the retrieved content.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>Full-text scholarly PDFs and associated metadata from Zotero (user or group libraries, optionally filtered by collection)</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Question-answer responses and synthesized summaries in natural language; downloadable chat history (.csv)</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_technique</strong></td>
                            <td>Retrieval-augmented generation (RAG) with an explicit system prompt instructing the agent to answer only from provided library content; agent-based prompting via KNIME AI nodes</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>OpenAI GPT family (user-selectable; examples: GPT-3.5 Turbo, GPT-4)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>datasets_used</strong></td>
                            <td>User-specific Zotero libraries (custom corpora); no public benchmark datasets used</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>System demonstration and qualitative description of functionality: automates PDF retrieval, chunking, embedding, vector indexing, and enables conversational Q&A over a user's Zotero library; no quantitative benchmarks or user study results reported.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Accuracy and sophistication of automated analysis not fully validated; remaining risks of LLM hallucination and context-window constraints requiring chunking; requires API keys and local setup; no formal evaluation of correctness or coverage.</td>
                        </tr>
                        <tr>
                            <td><strong>counterpoint</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'KNIMEZoBot: Enhancing Literature Review with Zotero and KNIME OpenAI Integration using Retrieval-Augmented Generation', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7889.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7889.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods that use large language models to synthesize, distill, or generate scientific theories, hypotheses, or structured knowledge from collections of scholarly papers.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM Agent + Vector Store</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Agentic LLMs combined with vector stores (KNIME AI Extension / OpenAI Functions Agent)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An agent-style approach that composes LLMs with vector databases and function-calling to dynamically select relevant knowledge stores and produce grounded responses by combining retrieval, tool use, and LLM generation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>KNIME AI Extension (Labs)</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>paper_title</strong></td>
                            <td>KNIMEZoBot: Enhancing Literature Review with Zotero and KNIME OpenAI Integration using Retrieval-Augmented Generation.</td>
                        </tr>
                        <tr>
                            <td><strong>authors</strong></td>
                            <td>Suad Alshammari et al.</td>
                        </tr>
                        <tr>
                            <td><strong>year</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Agentic LLM + Vector Store (OpenAI Functions Agent via KNIME)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>The KNIME AI Extension's agent nodes (e.g., OpenAI Functions Agent Creator and Agent Prompter) are used to configure system messages and create agents that, given a query and conversation history, can query the FAISS vector store and instruct the LLM to produce answers while enforcing constraints (e.g., answer only from provided documents). Agents can dynamically choose which vector store or tools to invoke to assemble a grounded response.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>Query text and conversation history; retrieved text chunks from FAISS vector store (embeddings computed from PDF chunks)</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Agent-generated conversational responses synthesized by the LLM, optionally augmented by retrieved passages or structured function outputs</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_technique</strong></td>
                            <td>Agent prompting (system message conditioning) combined with retrieval-augmented generation and function-calling style prompts</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>OpenAI GPT models (via KNIME AI Extension; unspecified exact model selection at runtime)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>datasets_used</strong></td>
                            <td>User Zotero libraries as the indexed knowledge base</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Descriptive: agent nodes enabled a chat interface that uses retrieved passages and system-conditioned LLM behavior to provide answers; no quantitative agent performance metrics presented.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Potential for hallucination if retrieval fails to find relevant grounding; reliance on chunking/embedding quality and correct prompt constraints; no formal validation of agent correctness reported.</td>
                        </tr>
                        <tr>
                            <td><strong>counterpoint</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'KNIMEZoBot: Enhancing Literature Review with Zotero and KNIME OpenAI Integration using Retrieval-Augmented Generation', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks <em>(Rating: 2)</em></li>
                <li>Benchmarking Large Language Models in Retrieval-Augmented Generation <em>(Rating: 2)</em></li>
                <li>Introduction | Langchain <em>(Rating: 1)</em></li>
                <li>KNIME AI Extension (Labs) <em>(Rating: 1)</em></li>
                <li>Streamlining Systematic Reviews: Harnessing Large Language Models for Quality Assessment and Risk-of-Bias Evaluation <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7889",
    "paper_id": "paper-3ddc8365ab4f048a4b8e6c4c3c7a99777c9dcf13",
    "extraction_schema_id": "extraction-schema-144",
    "extracted_data": [
        {
            "name_short": "RAG",
            "name_full": "Retrieval-Augmented Generation",
            "brief_description": "A method that augments large language model generation with a retrieval step: documents are chunked and embedded into a vector store, nearest-neighbor passages are retrieved for a query, and an LLM conditions on those retrieved passages to produce grounded, cross-document summaries or answers.",
            "citation_title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
            "mention_or_use": "use",
            "paper_title": "KNIMEZoBot: Enhancing Literature Review with Zotero and KNIME OpenAI Integration using Retrieval-Augmented Generation.",
            "authors": "Suad Alshammari et al.",
            "year": null,
            "method_name": "Retrieval-Augmented Generation (RAG)",
            "method_description": "Documents (PDFs) are split into overlapping chunks, each chunk is converted to an embedding and stored in a vector index (FAISS); at query time the user query is embedded, nearest neighbor chunks are retrieved by semantic similarity, and an LLM (OpenAI GPT family) is prompted with the query plus retrieved passages to synthesize a coherent, grounded natural-language answer.",
            "input_type": "Full-text PDFs (from Zotero library), metadata and extracted passages",
            "output_type": "Synthesized natural-language answers / cross-document summaries (answer text), with citations/passages used for grounding",
            "prompting_technique": "Retrieval-augmented generation (RAG); system message conditioning to restrict answers to provided library content",
            "model_name": "OpenAI GPT models (GPT-4, GPT-3.5 Turbo mentioned as selectable)",
            "model_size": null,
            "datasets_used": "User Zotero libraries (collections of full-text scholarly PDFs); no standard benchmark dataset reported",
            "evaluation_metric": null,
            "reported_results": "Qualitative demonstration: KNIMEZoBot can semantically search Zotero PDFs, retrieve relevant passages, and synthesize answers to user queries in a chatbot interface; no quantitative evaluation metrics reported.",
            "limitations": "Known LLM limitations (context window size and potential hallucination) are discussed; chunking required to stay within model input limits; no systematic accuracy evaluation provided.",
            "counterpoint": true,
            "uuid": "e7889.0",
            "source_info": {
                "paper_title": "KNIMEZoBot: Enhancing Literature Review with Zotero and KNIME OpenAI Integration using Retrieval-Augmented Generation",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "KNIMEZoBot",
            "name_full": "KNIMEZoBot (KNIME + Zotero + OpenAI RAG workflow)",
            "brief_description": "An integrated, low-code workflow that implements a RAG pipeline inside KNIME to let non-coders query and synthesize knowledge from their Zotero libraries using OpenAI models, FAISS vector store, and LangChain-based PDF chunking.",
            "citation_title": "here",
            "mention_or_use": "use",
            "paper_title": "KNIMEZoBot: Enhancing Literature Review with Zotero and KNIME OpenAI Integration using Retrieval-Augmented Generation.",
            "authors": "Suad Alshammari et al.",
            "year": null,
            "method_name": "KNIMEZoBot (RAG-based Zotero-KNIME integration)",
            "method_description": "The workflow programmatically pulls PDFs and metadata from Zotero via API, uses LangChain to load and chunk PDFs, computes embeddings (text-embedding-ada-002) and stores them in a FAISS index, and then uses OpenAI LLMs within KNIME nodes to answer user queries by retrieving semantically similar chunks and conditioning the LLM to synthesize answers constrained to the retrieved content.",
            "input_type": "Full-text scholarly PDFs and associated metadata from Zotero (user or group libraries, optionally filtered by collection)",
            "output_type": "Question-answer responses and synthesized summaries in natural language; downloadable chat history (.csv)",
            "prompting_technique": "Retrieval-augmented generation (RAG) with an explicit system prompt instructing the agent to answer only from provided library content; agent-based prompting via KNIME AI nodes",
            "model_name": "OpenAI GPT family (user-selectable; examples: GPT-3.5 Turbo, GPT-4)",
            "model_size": null,
            "datasets_used": "User-specific Zotero libraries (custom corpora); no public benchmark datasets used",
            "evaluation_metric": null,
            "reported_results": "System demonstration and qualitative description of functionality: automates PDF retrieval, chunking, embedding, vector indexing, and enables conversational Q&A over a user's Zotero library; no quantitative benchmarks or user study results reported.",
            "limitations": "Accuracy and sophistication of automated analysis not fully validated; remaining risks of LLM hallucination and context-window constraints requiring chunking; requires API keys and local setup; no formal evaluation of correctness or coverage.",
            "counterpoint": true,
            "uuid": "e7889.1",
            "source_info": {
                "paper_title": "KNIMEZoBot: Enhancing Literature Review with Zotero and KNIME OpenAI Integration using Retrieval-Augmented Generation",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "LLM Agent + Vector Store",
            "name_full": "Agentic LLMs combined with vector stores (KNIME AI Extension / OpenAI Functions Agent)",
            "brief_description": "An agent-style approach that composes LLMs with vector databases and function-calling to dynamically select relevant knowledge stores and produce grounded responses by combining retrieval, tool use, and LLM generation.",
            "citation_title": "KNIME AI Extension (Labs)",
            "mention_or_use": "use",
            "paper_title": "KNIMEZoBot: Enhancing Literature Review with Zotero and KNIME OpenAI Integration using Retrieval-Augmented Generation.",
            "authors": "Suad Alshammari et al.",
            "year": null,
            "method_name": "Agentic LLM + Vector Store (OpenAI Functions Agent via KNIME)",
            "method_description": "The KNIME AI Extension's agent nodes (e.g., OpenAI Functions Agent Creator and Agent Prompter) are used to configure system messages and create agents that, given a query and conversation history, can query the FAISS vector store and instruct the LLM to produce answers while enforcing constraints (e.g., answer only from provided documents). Agents can dynamically choose which vector store or tools to invoke to assemble a grounded response.",
            "input_type": "Query text and conversation history; retrieved text chunks from FAISS vector store (embeddings computed from PDF chunks)",
            "output_type": "Agent-generated conversational responses synthesized by the LLM, optionally augmented by retrieved passages or structured function outputs",
            "prompting_technique": "Agent prompting (system message conditioning) combined with retrieval-augmented generation and function-calling style prompts",
            "model_name": "OpenAI GPT models (via KNIME AI Extension; unspecified exact model selection at runtime)",
            "model_size": null,
            "datasets_used": "User Zotero libraries as the indexed knowledge base",
            "evaluation_metric": null,
            "reported_results": "Descriptive: agent nodes enabled a chat interface that uses retrieved passages and system-conditioned LLM behavior to provide answers; no quantitative agent performance metrics presented.",
            "limitations": "Potential for hallucination if retrieval fails to find relevant grounding; reliance on chunking/embedding quality and correct prompt constraints; no formal validation of agent correctness reported.",
            "counterpoint": true,
            "uuid": "e7889.2",
            "source_info": {
                "paper_title": "KNIMEZoBot: Enhancing Literature Review with Zotero and KNIME OpenAI Integration using Retrieval-Augmented Generation",
                "publication_date_yy_mm": "2023-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks",
            "rating": 2
        },
        {
            "paper_title": "Benchmarking Large Language Models in Retrieval-Augmented Generation",
            "rating": 2
        },
        {
            "paper_title": "Introduction | Langchain",
            "rating": 1
        },
        {
            "paper_title": "KNIME AI Extension (Labs)",
            "rating": 1
        },
        {
            "paper_title": "Streamlining Systematic Reviews: Harnessing Large Language Models for Quality Assessment and Risk-of-Bias Evaluation",
            "rating": 1
        }
    ],
    "cost": 0.008953,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>KNIMEZoBot: Enhancing Literature Review with Zotero and KNIME OpenAI Integration using Retrieval-Augmented Generation.</h1>
<p>Suad Alshammari ${ }^{1,2}$, Lama Basalelah ${ }^{1,3}$, Walaa Abu Rukbah ${ }^{1,4}$, Ali Alsuhibani ${ }^{1,5}$ and Dayanjan S. Wijesinghe ${ }^{1,6,7}$.</p>
<ol>
<li>Department of Pharmacotherapy and Outcomes Sciences, School of Pharmacy, Virginia Commonwealth University. 2. Faculty of Pharmacy, Northern Border University, Saudi Arabia. 3. Faculty of Pharmacy, Imam Abdulrahman Bin Faisal University, Saudi Arabia. 4. Faculty of Pharmacy, University of Tabuk, Saudi Arabia. 5. Department of Pharmacy Practice, Unaizah College of Pharmacy, Qassim University, Unaizah, Saudi Arabia. 6. Institute for Structural Biology, Drug Discovery and Development, Virginia Commonwealth University, Richmond, Virginia, USA. 7. Da Vinci Center, School of Pharmacy, Virginia Commonwealth University School of Medicine, Richmond, Virginia, USA.</li>
</ol>
<p>Project files to be found at: https://github.com/dayanjan-lab/KNIMEZoBot</p>
<h4>Abstract</h4>
<p>Academic researchers face challenges keeping up with exponentially growing published findings in their field. Performing comprehensive literature reviews to synthesize knowledge is time-consuming and labor-intensive using manual approaches. Recent advances in artificial intelligence provide promising solutions, yet many require coding expertise, limiting accessibility. KNIMEZoBot represents an innovative integration of Zotero, OpenAI, and the KNIME visual programming platform to automate literature review tasks for users with no coding experience. By leveraging KNIME's intuitive graphical interface, researchers can create workflows to search their Zotero libraries and utilize OpenAI models to extract key information without coding. Users simply provide API keys and configure settings through a user-friendly interface in a locally stored copy of the workflow. KNIMEZoBot then allows asking natural language questions via a chatbot and retrieves relevant passages from papers to generate synthesized answers. This system has significant potential to expedite literature reviews for researchers unfamiliar with coding by automating retrieval and analysis of publications in personal Zotero libraries. KNIMEZoBot demonstrates how thoughtfully designed Al tools can expand accessibility and accelerate knowledge building across diverse research domains.</p>
<h1>Introduction:</h1>
<p>The current era witnesses academicians, clinicians, and researchers grappling with the formidable challenge of information overload ${ }^{1,2}$. The incessant surge in published research findings over recent years has significantly outpaced the ability to stay updated. This challenge is poised to intensify with the advent of natural language optimized Al technologies, which are expected to propel the pace of discoveries and subsequent publications at an even faster rate ${ }^{3}$. The dire need for a mechanism to proficiently manage and assimilate this burgeoning knowledge is palpable. Within this complex quandary, two distinct scenarios emerge:</p>
<p>Firstly, the task of extracting precise answers from a pre-existing knowledge corpus poses a hurdle ${ }^{1}$. Researchers typically amass publications pertinent to their expertise in reference libraries. This textual corpus expands over time with the continual influx of new findings. The task of extracting specific information from this meticulously curated content escalates in complexity with the growing volume of publications, compelling users to sift through numerous documents. Consequently, the appeal for an Al-driven platform capable of synthesizing information from multiple different publications to precise queries from an ever-expanding corpus of curated scientific literature within personal and group reference libraries is burgeoning.</p>
<p>Secondly, the endeavor of encapsulating knowledge through exhaustive literature reviews unveils knowledge gaps and unveils avenues for consequential research ${ }^{4}$. This endeavor entails the conduct of meticulous literature reviews which begin with the identification and collation of relevant publications to address the posed inquiries. Post collection, a thorough analysis of the amassed information is essential to derive answers to specific queries. The conventional workflow of executing literature reviews is notably time-consuming and labor-intensive ${ }^{5}$. Given the swift pace of new discoveries, the traditional approach often yields a knowledge summary that becomes obsolete by the time of its completion.</p>
<p>The imperativeness for simplified, automated strategies enabling researchers to query curated literature libraries and routinely refresh their domain knowledge is apparent. The recent strides in artificial intelligence (AI), particularly the Large Language Models (LLMs), harbor the potential to alleviate the aforementioned challenges ${ }^{6}$. Platforms like ChatGPT, Claude, or Bard are proficient in summarizing papers and synthesizing findings across multiple documents ${ }^{7}$. However, their native "chat" formats present certain impediments for academic research. These include constraint of context window lengths ${ }^{8}$ and the propensity for confabulation (hallucination) ${ }^{9}$. For instance, publicly available chatGPT4 has a context window of about 5000 words, while Claude's window extends to 75,000 words, rendering a bulk of academic publications too lengthy for chat GPT. Claude, although capable of summarizing single publications, finds its utility curtailed across multiple documents.</p>
<p>A notable breakthrough addressing the context window limitations and hallucination and aiding in data summarization from diverse documents is the Retrieval Augmented Generation (RAG) approach ${ }^{10,11}$. The operational workflow of RAG commences with the segmentation of broad text corpora into smaller, overlapping textual fragments. Following this, these fragments</p>
<p>are transformed into vector representations and cataloged within a vector-based database. Upon query submission, it's converted into a vector form. A vectorial similarity assessment is then executed to identify all text segments within the database showcasing semantic alignment. The query, along with all relevant text fragments, is forwarded to a Large Language Model (LLM) to formulate a coherent and pertinent response. This technique adeptly navigates the context window constraints, fostering response synthesis across varied domains. The capability to repeatedly execute this process establishes a robust question-and-answer framework, invaluable for extensive literature reviews, serving scholars and medical professionals.</p>
<p>The RAG-based system, although expedient in summarizing information, hitherto necessitated substantial coding knowledge. Recognizing that a sizable faction of academicians and clinicians lacks coding expertise, we orchestrated a code-free, open-source strategy, culminating in the creation of KNIMEZoBot. This innovation amalgamates three pivotal elements: Konstanz Information Miner (KNIME) - a code-free data science platform, Zotero - an open-source reference management system, and GPT4 from Open AI - the chosen language model for knowledge synthesis. KNIMEZoBot heralds a revolutionary stride in enhancing the literature review workflow by seamlessly integrating the prowess of reference managers, scholarly databases, and AI. Through this ingenious approach, we have democratized access to AIpowered research tools, opening doors for those with non-coding backgrounds to harness natural language queries for interacting with the curated publications housed in their Zotero libraries, thereby significantly amplifying the accessibility and utility of Al in academic spheres.</p>
<h1>Materials and Methods</h1>
<p>KNIME: For the development of the KNIMEZoBot platform, KNIME played an integral role in providing the graphical modular interface for building the workflow steps, integrating the Zotero and OpenAI APIs seamlessly via dedicated nodes, processing the extracted text data, creating the FAISS vector indexing workflow, and hosting the final chatbot user interface. KNIME is an open-source platform originating from the University of Konstanz in Germany, catering to data analytics, reporting, and integration needs, with a strong footing in data science and machine learning domains ${ }^{12}$. It's a free, community-enhanced tool, widely embraced by data professionals globally owing to its user-friendly, graphical interface enabling code-free workflow creation, modification, and visualization. KNIME's core strength is its extensive node repository facilitating seamless data pipeline construction for tasks ranging from data preprocessing to advanced analytics using a non/low code approach. It boasts robust data integration, connecting effortlessly to various data sources like databases and web services, thus centralizing data for comprehensive analysis. Scalability is a hallmark of KNIME, adeptly managing small to large datasets, with ease of integration into big data frameworks like Apache Hadoop and Apache Spark. The platform supports building, training, and evaluating machine learning models utilizing popular libraries such as scikit-learn and TensorFlow, alongside offering an array of statistical and analytical techniques. Automation is seamless with KNIME, allowing scheduled workflow executions, while its server facilitates collaborative efforts and workflow sharing. Commercial versions of KNIME extend advanced features and support, enriching its open-source ecosystem. It's a versatile tool for creating insightful reports, visualizing data, and finds applications across</p>
<p>diverse fields including bioinformatics, predictive analytics, business intelligence, and industrial research.</p>
<h1>KNIME extensions used:</h1>
<p>KNIME AI Extension (Labs) ${ }^{13}$ : The KNIME labs extension enables users to leverage powerful large language models (LLMs) from OpenAI, Hugging Face Hub, and GPT4ALL for tasks like chat and text embeddings. It also provides connectivity to vector stores like Chroma and FAISS for building knowledge bases that can inform chatbot responses. The extension allows combining vector stores and LLMs into intelligent agents. These agents can dynamically select the most relevant vector store to query based on the user input, enabling more natural and knowledgeable conversations. Overall, this extension brings together state-of-the-art LLMs and vector stores within the KNIME analytics platform, unlocking new possibilities for building conversational interfaces and knowledge-powered AI assistants.</p>
<p>KNIME REST Client Extension ${ }^{14}$ : The KNIME REST Client Extension provides nodes for making REST API calls within KNIME workflows. This enables seamless integration with web services and APIs.</p>
<p>The Get Request node ${ }^{15}$ is used to send HTTP GET requests to REST endpoints. It allows specifying the URL, headers, query parameters, and authentication settings. The response from the REST API is returned as a JSON/XML document that can be further processed in the KNIME workflow ${ }^{14}$.</p>
<p>KNIME Python 2 Integration (legacy) ${ }^{16}$ : This extension encompasses the legacy version of KNIME Python integration. It facilitates the integration of Python 2 and Python 3 scripts within the KNIME platform. The extension operates by executing Python scripts in a local Python installation, which is not included in the extension package.</p>
<p>KNIME Python Integration ${ }^{17}$ : The "KNIME Python Integration" is the modern and preferred choice for Python integration within KNIME. This extension incorporates nodes that enable the execution of Python 3 scripts seamlessly in the KNIME workflow. Notably, this integration brings substantial performance improvements compared to its legacy counterpart. It also provides enhanced support for handling larger-than-memory datasets. Additionally, this extension comes equipped with a Python installation that includes a curated selection of essential Python packages.</p>
<p>Note: Throughout our workflow, we employed both the "KNIME Python 2 Integration (legacy)" and the "KNIME Python Integration" extensions interchangeably.</p>
<p>KNIME JSON-Processing ${ }^{18}$ : The KNIME JSON-Processing extension provides nodes for working with JSON data within KNIME workflows. It allows for parsing, creating, transforming, and serializing JSON documents. The JSON To Table node enables easy ingestion of JSON data into tabular form for use in KNIME workflows. It reduces the complexity of handling nested JSON structures and schemas.</p>
<p>Python (Version 3.9) ${ }^{19}$ : Integrating of Python and Anaconda with KNIME can be a powerful combination that allows data scientists and analysts to leverage the extensive libraries and capabilities of Python within the KNIME analytics platform. This integration provides a seamless way to utilize Python scripts, packages, and machine learning models within the KNIME workflows. A detailed guide for Python integration in KNIME has been published elsewhere ${ }^{20}$</p>
<p>Specifically, Python nodes were utilized to execute API calls to extract metadata and PDF files from the Zotero reference manager using its REST API bindings. The Python Requests library facilitated sending GET requests to the API and processing the responses. Another vital usage was the Langchain library ${ }^{21}$ within a Python node to load in the full text of PDF papers and segment them into smaller chunks that meet the length limits of the GPT model inputs.</p>
<p>The Python nodes accept inputs from earlier workflow components, run the defined Python logic and code using those inputs, and return any outputs to subsequent nodes in the workflow. For instance, a node might accept a list of extracted PDFs from the Zotero API calls, utilize Langchain to chunk each PDF into shorter text segments, and output these chunks to the next node for vectorization.</p>
<p>The following Python packages were installed and imported within the Python nodes in KNIME to support core functionality. The installation can be done in multiple ways; we used the following:</p>
<p>1- Open Anaconda Prompt from the Start menu.
2- Write this command: "conda activate <your_environment>." Your_environment is the environment name that is set up in the KNIME Python preference.
3- After the name is changed from base to the name of the environment, install the following libraries via pip:</p>
<ul>
<li>pip install pandas openai langchain unstructured fitz PyPDF2 PyMuPDF "unstructured[pdf]"</li>
</ul>
<h1>Zotero:</h1>
<p>Zotero, a free, open-source reference management software ${ }^{22}$, is cherished by a broad spectrum of academia and professionals for easing the collection, organization, and citation of research materials. Originating from George Mason University, it's a boon for scholarly research and writing, streamlining reference, citation, and bibliography management. Key facets include effortless reference collection from diverse sources like websites and academic journals, with automatic citation information extraction from web pages and PDFs. Its intuitive interface facilitates organizing references via folders, tags, and notes, ensuring easy retrieval. A hallmark feature is its citation and bibliography generation in numerous styles like APA and MLA, significantly reducing formatting time. Integration with prevalent word processors like Microsoft Word and Google Docs allows direct citation insertion and bibliography generation in documents, ensuring accuracy and consistency. Its PDF management capability lets users attach, organize, and annotate PDFs within the reference library. Zotero encourages collaborative research through shared library features, vital for research teams. It offers cloud synchronization for easy access across devices and data backup, enhancing data security. Browser extensions for Chrome and</p>
<p>Firefox simplify capturing references online. Being open-source, it's continually evolved by community contributions, and its cross-platform availability extends its reach. Applications are vast, aiding academic research, education, library assistance, and professionals across legal, medical, and media fields in managing and citing a vast array of references effortlessly.</p>
<h1>Results and Discussion</h1>
<h2>KNIMEZoBot:</h2>
<p>The developed application "KNIMEZoBot", represents an innovative integration of Zotero and OpenAI through the code free platform KNIME to streamline literature reviews and research. This project seamlessly combines the above-mentioned Zotero reference manager, with OpenAI's powerful natural language processing capabilities via a RAG based approach using KNIME as the interface. The primary goal is to simplify retrieving PDFs from Zotero libraries and collections and then utilize OpenAI within KNIME workflows to ask insightful questions and extract key information from academic papers.</p>
<p>KNIMEZoBot uses a Retrieval-Augmented Generation (RAG) architecture, first conducting a semantic search to identify relevant passages from retrieved PDFs. It then leverages large language models (in this case OpenAI's GPT models) to synthesize natural language answers based on the extracted information. This enables KNIMEZoBot to provide informative responses to questions by efficiently searching academic papers and distilling salient facts and main points. Overall, the integration of Zotero and OpenAI represents an innovative approach to enhance literature reviews and research by combining reference management, scholarly databases, and OpenAI.
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure1: Underlying overall workflow for KNIMEZoBot.</p>
<h2>First component (Setup and configure Zotero):</h2>
<p>In order to effectively use the KNIMEZoBot, users need to follow a series of key steps. The first requirement is selecting the type of Zotero library they want to access - either a personal</p>
<p>Zotero library or a group library. Based on that choice, users will need to input their corresponding Zotero API key, which allows the system to interface with the library.</p>
<p>Additionally, users will need to provide either their personal Zotero user ID if accessing their own library, or the group ID if accessing a shared group library. To assist users in easily finding and copying their user ID or group ID, we have included hyperlinks within the system interface that direct users to Zotero guides with instructions on locating that information.</p>
<p>Furthermore, to enable more targeted searches, users have the option to filter based on Zotero collections. This allows them to refine the content being retrieved from their library down to specific collections, rather than everything in the library. The system was designed to be flexible - some users may want to search across their entire library, while others may want to narrow in on papers from select collections.
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Component "Setup Zotero" when executed - User interface of KNIMEZoBot. Users are required to complete the Zotero information fields.</p>
<div class="codehilite"><pre><span></span><code><span class="nx">Step</span><span class="w"> </span><span class="mi">4</span><span class="p">:</span><span class="w"> </span><span class="nx">Interacting</span><span class="w"> </span><span class="nx">with</span><span class="w"> </span><span class="nx">Collections</span><span class="p">:</span>
<span class="w">    </span><span class="nx">Select</span><span class="w"> </span><span class="err">&quot;</span><span class="nx">Set</span><span class="w"> </span><span class="nx">X</span><span class="p">:</span>
<span class="w">    </span><span class="mi">1</span><span class="p">.</span><span class="w"> </span><span class="nx">You</span><span class="w"> </span><span class="nx">have</span><span class="w"> </span><span class="nx">specific</span><span class="w"> </span><span class="nx">collections</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nx">your</span><span class="w"> </span><span class="nx">group</span><span class="w"> </span><span class="kn">library</span><span class="w"> </span><span class="nx">that</span><span class="w"> </span><span class="nx">you</span><span class="w"> </span><span class="nx">want</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">interact</span><span class="w"> </span><span class="nx">with</span>
<span class="w">    </span><span class="mi">2</span><span class="p">.</span><span class="w"> </span><span class="nx">You</span><span class="w"> </span><span class="nx">want</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">interact</span><span class="w"> </span><span class="nx">with</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="nx">collection</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nx">your</span><span class="w"> </span><span class="nx">own</span><span class="w"> </span><span class="kn">library</span>
<span class="w">    </span><span class="nx">Select</span><span class="w"> </span><span class="nx">Yes</span><span class="err">&#39;</span><span class="nx">X</span><span class="p">:</span>
<span class="w">    </span><span class="mi">1</span><span class="p">.</span><span class="w"> </span><span class="nx">You</span><span class="w"> </span><span class="nx">want</span><span class="w"> </span><span class="nx">these</span><span class="w"> </span><span class="nx">key</span><span class="w"> </span><span class="nx">collections</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">group</span><span class="w"> </span><span class="kn">library</span>
<span class="w">    </span><span class="mi">2</span><span class="p">.</span><span class="w"> </span><span class="nx">You</span><span class="w"> </span><span class="nx">have</span><span class="w"> </span><span class="nx">collections</span><span class="w"> </span><span class="nx">of</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">group</span><span class="w"> </span><span class="kn">library</span><span class="w"> </span><span class="nx">that</span><span class="w"> </span><span class="nx">you</span><span class="w"> </span><span class="nx">want</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">interact</span><span class="w"> </span><span class="nx">with</span><span class="w"> </span><span class="nx">all</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">PDFs</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="kn">library</span>
<span class="w">    </span><span class="mi">3</span><span class="p">.</span><span class="w"> </span><span class="nx">You</span><span class="w"> </span><span class="nx">want</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">interact</span><span class="w"> </span><span class="nx">with</span><span class="w"> </span><span class="nx">all</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">PDF</span><span class="w"> </span><span class="nx">files</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nx">your</span><span class="w"> </span><span class="nx">own</span><span class="w"> </span><span class="kn">library</span>
<span class="w">    </span><span class="nx">Note</span><span class="p">:</span>
<span class="w">    </span><span class="nx">Collection</span><span class="w"> </span><span class="nx">ID</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="nx">part</span><span class="w"> </span><span class="nx">of</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">group</span><span class="w"> </span><span class="nx">user</span><span class="w"> </span><span class="nx">URL</span><span class="w"> </span><span class="nx">after</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">collections</span><span class="w"> </span><span class="nx">want</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="nx">collections</span><span class="o">/</span><span class="nx">COREQAD</span><span class="p">.</span><span class="w"> </span><span class="nx">The</span><span class="w"> </span><span class="nx">collection</span><span class="w"> </span><span class="nx">ID</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nx">this</span><span class="w"> </span><span class="nx">example</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="mi">1</span><span class="nx">COREQAD</span><span class="p">.</span>
<span class="w">    </span><span class="nx">Do</span><span class="w"> </span><span class="nx">you</span><span class="w"> </span><span class="nx">want</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">interact</span><span class="w"> </span><span class="nx">with</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="nx">collection</span><span class="p">?</span>
<span class="w">    </span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="nx">Yes</span>
<span class="w">    </span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="w"> </span><span class="nx">Yes</span>
<span class="w">    </span><span class="nx">Collection</span><span class="w"> </span><span class="nx">ID</span><span class="p">:</span>
<span class="w">    </span><span class="mi">1</span>
<span class="w">    </span><span class="mi">2</span>
</code></pre></div>

<p>Figure 3: Continuation of the first component when executed. We provided options to filter by specific collections.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 4: The "setup Zotero" component contains widget nodes ${ }^{23}$ that allow the user to input the information required by the system. It also includes text output nodes and a header node that control the appearance of the user interface.</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 5: The first metanode processes information from the "setup zotero" component. Specifically, the "python script" node ${ }^{24}$ accesses and extracts all data from the Zotero library. The "get request" node ${ }^{15}$ (a child node) retrieves attached files for each Zotero item. Subsequently, the 'binary objects to files' node ${ }^{25}$ is employed to facilitate the secure storage of PDF documents in a pre-defined temporary directory within the workflow.</p>
<h1>Second component (Setup OpenAI):</h1>
<p>The second core component of the system involves setting up the OpenAI environment according to the user's preferences. Users have the ability to adjust key settings such as chunk size and chunk overlap. Chunk size refers to the maximum number of tokens processed per API request, while overlap determines the number of duplicated tokens between chunks. Giving users control over these parameters enables them to customize the configuration based on their specific computational needs and use case.</p>
<p>After inputting their OpenAI API key, which grants access to the AI models, users can select from a variety of available models offered through the OpenAI API. Users can make a selection from a range of available OpenAI models, including but not limited to GPT-3.5 Turbo and GPT-4.</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 6: Component "Setup OpenAI" when executed- Users are required to select chunk size and overlap settings for text processing, enter their OpenAI API key, and select an AI model.
<img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 7: The "setup OpenAI" component contains widget nodes enabling users to input their OpenAI API key, chunk size, chunk overlap, and select an AI model as required by the system. Additionally, text output nodes and a header node are included for the appearance of the user interface. The "Python Script" node was used to read and split the PDFs to smaller chunks. We used the Langchain package ${ }^{21}$ "unstructuredPDFLoader" to load the documents. The documents were then split into smaller chunks because of size limitation as GPT models have a maximum input size, usually 1024-2048 tokens. Breaking PDFs into smaller chunks allows to feed longer documents into the models.</p>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 8: In the metanode, we used the "FAISS Vector Store Creator" node ${ }^{26}$. This node will store the numerical vector representation created by the embedding model from the "OpenAI Embeddings Connector" node ${ }^{27}$. Also, we selected "text-embedding-ada-002" as the embedding model.</p>
<p>The "OpenAI Functions Agent Creator" node ${ }^{28}$ is used to customize the system message. We rote the following message "You are KnimeZoBot, an AI assistant specifically designed to seamlessly integrate the power of the KNIME platform with the vast knowledge stored within your Zotero library. Your mission is to provide the user with a unique and efficient way to access information, answer questions, and streamline users' research tasks by tapping into your personal Zotero library. Get the answer only from the provided information and if it is not store there write "I apologize, but I do not have any information about it in my Zotero library."</p>
<h1>Last component (Chat app):</h1>
<p>The last component of the system is the Chat application, which provides an interactive interface for users to engage with their Zotero library. This chatbot-style app enables users to pose questions and queries about the content of their Zotero library in a natural conversational format. The seamless integration of the chatbot with the Zotero reference database creates a convenient and user-friendly method for users to search for information within their library.</p>
<p>In addition, users have the option to download their full conversation history with the chatbot in a .csv format. This allows users to save all of their questions and the chatbot's responses so they can refer back to the information later.</p>
<p><img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 9: Final Component "Chat App"- Chat Interface when deployed. This component allows users to ask questions and receive answers through a conversational chatbot. Users can also download their full chat history as a CSV file.
<img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<p>Figure 10: The final "Chat app" component utilizes an "Agent Prompter" node ${ }^{29}$ to leverage an AI agent, prompts, and the conversation history from the input table to generate responses. The conversation table requires at least two string columns to store previous exchanges. Additionally, an option is provided to save the chat history.</p>
<h1>Conclusion:</h1>
<p>In summary, the KNIMEZoBot represents a promising integration of technologies to expedite literature reviews or undertake natural language queries of existing Zotero libraries. By</p>
<p>unifying the capabilities of Zotero, OpenAI, and KNIME, this system automates laborious tasks such as combing through academic papers to identify relevant information. Researchers can save significant time while benefiting from state-of-the-art Al techniques for synthesizing knowledge in a low code manner. This innovation demonstrates the potential for Al to assume a greater role in accelerating informed research. While further enhancements to the accuracy and sophistication of the automated analysis remain desirable, KNIMEZoBot marks an important step toward streamlining access to critical information in existing literature by domain experts who are not coders by training. By facilitating more rapid and comprehensive understanding of prior work, this system could substantially benefit the research community and knowledge-building process.</p>
<h1>References:</h1>
<ol>
<li>Arnold M, Goldschmitt M, Rigotti T. Dealing with information overload: a comprehensive review. Front Psychol. 2023;14:1122200. doi:10.3389/fpsyg.2023.1122200</li>
<li>Bornmann L, Haunschild R, Mutz R. Growth rates of modern science: a latent piecewise growth curve approach to model publication numbers from established and new literature databases. Humanit Soc Sci Commun. 2021;8(1):1-15. doi:10.1057/s41599-021-00903-w</li>
<li>Kousha K, Thelwall M. Artificial intelligence to support publishing and peer review: A summary and review. Learn Publ. n/a(n/a). doi:10.1002/leap. 1570</li>
<li>Par G, Kitsiou S. Chapter 9 Methods for Literature Reviews. In: Handbook of eHealth Evaluation: An Evidence-Based Approach [Internet]. University of Victoria; 2017. Accessed November 3, 2023. https://www.ncbi.nlm.nih.gov/books/NBK481583/</li>
<li>Tay A. How to write a superb literature review. Nature. Published online December 4, 2020. doi:10.1038/d41586-020-03422-x</li>
<li>Wagner G, Lukyanenko R, Par G. Artificial intelligence and the conduct of literature reviews. J Inf Technol. 2022;37(2):209-226. doi:10.1177/02683962211048201</li>
<li>Nashwan AJ, Jaradat JH. Streamlining Systematic Reviews: Harnessing Large Language Models for Quality Assessment and Risk-of-Bias Evaluation. Cureus. 15(8):e43023. doi:10.7759/cureus. 43023</li>
<li>Stern J. GPT-4 Has the Memory of a Goldfish. The Atlantic. Published March 17, 2023. Accessed November 3, 2023. https://www.theatlantic.com/technology/archive/2023/03/gpt-4-has-memory-context-window/673426/</li>
<li>Sharun K, Banu SA, Pawde AM, et al. ChatGPT and artificial hallucinations in stem cell research: assessing the accuracy of generated references - a preliminary study. Ann Med Surg 2012. 2023;85(10):5275-5278. doi:10.1097/MS9.0000000000001228</li>
<li>Lewis P, Perez E, Piktus A, et al. Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. Published online April 12, 2021. doi:10.48550/arXiv.2005.11401</li>
<li>Chen J, Lin H, Han X, Sun L. Benchmarking Large Language Models in RetrievalAugmented Generation. Published online September 4, 2023. doi:10.48550/arXiv.2309.01431</li>
<li>Berthold MR, Cebron N, Dill F, et al. KNIME - the Konstanz information miner: version 2.0 and beyond. ACM SIGKDD Explor Newsl. 2009;11(1):26-31. doi:10.1145/1656274.1656280</li>
<li>KNIME AI Extension (Labs). KNIME Community Hub. Accessed November 7, 2023. https://hub.knime.com/knime/extensions/org.knime.python.features.llm/latest</li>
<li>
<p>KNIME REST Client Extension. KNIME Community Hub. Accessed November 7, 2023. https://hub.knime.com/knime/extensions/org.knime.features.rest/latest</p>
</li>
<li>
<p>GET Request. KNIME Community Hub. Accessed November 7, 2023.
https://hub.knime.com/knime/extensions/org.knime.features.rest/latest/org.knime.rest.nodes .get.RestGetNodeFactory</p>
</li>
<li>KNIME Python 2 Integration (legacy). KNIME Community Hub. Accessed November 7, 2023. https://hub.knime.com/knime/extensions/org.knime.features.python2/latest</li>
<li>KNIME Python Integration. KNIME Community Hub. Accessed November 7, 2023. https://hub.knime.com/knime/extensions/org.knime.features.python3.scripting/latest</li>
<li>KNIME JSON-Processing. KNIME Community Hub. Accessed November 7, 2023. https://hub.knime.com/knime/extensions/org.knime.features.json/latest</li>
<li>Python Release Python 3.9.0. Python.org. Accessed November 7, 2023. https://www.python.org/downloads/release/python-390/</li>
<li>KNIME Python Integration Guide. Accessed November 7, 2023. https://docs.knime.com/2021-12/python_installation_guide/index.html#_introduction</li>
<li>Introduction | Langchain. Accessed November 7, 2023. https://python.langchain.com/docs/get_started/introduction</li>
<li>credits_and_acknowledgments [Zotero Documentation]. Accessed November 3, 2023. https://www.zotero.org/support/credits_and_acknowledgments#about_zotero</li>
<li>Explore the Wonderful World of KNIME Widgets. KNIME. Accessed November 7, 2023. https://www.knime.com/blog/mini-guide-widget-examples</li>
<li>Python Script. KNIME Community Hub. Accessed November 7, 2023. https://hub.knime.com/knime/extensions/org.knime.features.python3.scripting/latest/org.kni me.python3.scripting.nodes.script.PythonScriptNodeFactory</li>
<li>Binary Objects to Files. KNIME Community Hub. Accessed November 7, 2023. https://hub.knime.com/knime/extensions/org.knime.features.base.filehandling/latest/org.kni me.base.filehandling.binaryobjects.writer.BinaryObjectsToFilesNodeFactory</li>
<li>FAISS Vector Store Creator. KNIME Community Hub. Accessed November 7, 2023. https://hub.knime.com/knime/extensions/org.knime.python.features.llm/latest/org.knime.pyth on3.nodes.extension.ExtensionNodeSetFactory\$DynamicExtensionNodeFactory:e1168c28</li>
<li>OpenAI Embeddings Connector. KNIME Community Hub. Accessed November 7, 2023. https://hub.knime.com/knime/extensions/org.knime.python.features.llm/latest/org.knime.pyth on3.nodes.extension.ExtensionNodeSetFactory\$DynamicExtensionNodeFactory:3a4ffd4b</li>
<li>OpenAI Functions Agent Creator. KNIME Community Hub. Accessed November 7, 2023. https://hub.knime.com/knime/extensions/org.knime.python.features.llm/latest/org.knime.pyth on3.nodes.extension.ExtensionNodeSetFactory\$DynamicExtensionNodeFactory:232d61e6</li>
<li>Agent Prompter. KNIME Community Hub. Accessed November 7, 2023. https://hub.knime.com/knime/extensions/org.knime.python.features.llm/latest/org.knime.pyth on3.nodes.extension.ExtensionNodeSetFactory\$DynamicExtensionNodeFactory:378eea</li>
</ol>
<p>https://github.com/dayanjan-lab/KNIMEZoBot</p>            </div>
        </div>

    </div>
</body>
</html>