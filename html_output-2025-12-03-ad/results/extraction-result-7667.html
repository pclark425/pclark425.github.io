<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7667 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7667</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7667</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-140.html">extraction-schema-140</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of a problem/prompt influences the performance of large language models, including details of the format, the task, the model, and reported performance differences.</div>
                <p><strong>Paper ID:</strong> paper-1f874c94d531f6776f65e0aa807adbf432ea35cf</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/1f874c94d531f6776f65e0aa807adbf432ea35cf" target="_blank">Understanding and Mitigating Language Confusion in LLMs</a></p>
                <p><strong>Paper Venue:</strong> Conference on Empirical Methods in Natural Language Processing</p>
                <p><strong>Paper TL;DR:</strong> The Language Confusion Benchmark (LCB) is created, which serves as a first layer of efficient, scalable multilingual evaluation and finds that language confusion can be partially mitigated via few-shot prompting, multilingual SFT and preference tuning.</p>
                <p><strong>Paper Abstract:</strong> We investigate a surprising limitation of LLMs: their inability to consistently generate text in a user’s desired language. We create the Language Confusion Benchmark (LCB) to evaluate such failures, covering 15 typologically diverse languages with existing and newly-created English and multilingual prompts. We evaluate a range of LLMs on monolingual and cross-lingual generation reflecting practical use cases, finding that Llama Instruct and Mistral models exhibit high degrees of language confusion and even the strongest models fail to consistently respond in the correct language. We observe that base and English-centric instruct models are more prone to language confusion, which is aggravated by complex prompts and high sampling temperatures. We find that language confusion can be partially mitigated via few-shot prompting, multilingual SFT and preference tuning. We release our language confusion benchmark, which serves as a first layer of efficient, scalable multilingual evaluation.</p>
                <p><strong>Cost:</strong> 0.024</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7667.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7667.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of a problem/prompt influences the performance of large language models, including details of the format, the task, the model, and reported performance differences.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Prompt complexity (Complex vs Okapi/ShareGPT)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Prompt complexity: Complex human-authored prompts versus simpler Okapi/ShareGPT prompts</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cross-lingual prompt complexity (more complex, multi-step or contextual prompts) strongly increases language confusion in LLMs compared to simpler prompts (Okapi, ShareGPT); effect is observed across model families but is most pronounced for models with English-centric behaviour.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Various (Command R, Command R+, Llama 2/3, Mixtral, Mistral, GPT-3.5/4/4o)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Instruction-tuned and base large transformer LLMs evaluated on monolingual and cross-lingual generation; models include base and instruction-tuned variants across several families.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>various (8x7B, 35B, 70B, 104B, etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Language Confusion Benchmark (cross-lingual generation)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Instruction in English asking the model to produce output in a target non-English language; measures whether the model produces output entirely in the requested language.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Natural-language instruction prompts; dataset split by source (Okapi, ShareGPT, Complex prompts collected by authors).</td>
                        </tr>
                        <tr>
                            <td><strong>format_category</strong></td>
                            <td>prompt style / prompt complexity</td>
                        </tr>
                        <tr>
                            <td><strong>format_details</strong></td>
                            <td>Three dataset sources compared for cross-lingual generation: Okapi (synthetic/MT, simpler instructions), ShareGPT (mostly English user prompts), and Complex prompts (human-authored, multi-step, integrated instructions). For cross-lingual examples the English instruction to produce the target language was added either at start, end, or integrated. Default decoding: nucleus sampling p=0.75, T=0.3, max 100 tokens.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Line-level Pass Rate (LPR)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Command R: Okapi 75.6% LPR, ShareGPT 89.7% LPR, Complex prompts 39.0% LPR (cross-lingual average reported in Table 5)</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td>Command R on ShareGPT: 89.7% LPR</td>
                        </tr>
                        <tr>
                            <td><strong>performance_change</strong></td>
                            <td>Command R Complex vs ShareGPT: -50.7 percentage points (absolute) in LPR</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_setting</strong></td>
                            <td>Cross-lingual generation (English instruction -> target language), nucleus sampling p=0.75, T=0.3, up to 100 tokens; results aggregated by dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Understanding and Mitigating Language Confusion in LLMs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7667.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7667.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of a problem/prompt influences the performance of large language models, including details of the format, the task, the model, and reported performance differences.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Instruction position (isolated vs integrated)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Position of the language-control instruction: isolated (start/end) versus integrated in prompt</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Placing an isolated language instruction at the start or end of a prompt yields substantially lower language confusion than embedding the language instruction inside a longer/integrated prompt; integrated instructions are harder for models to follow, but few-shot demonstrations can reduce this difficulty.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Command R (and evaluated for GPT-4, Command R+, variants)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Instruction-tuned transformer LLM (Command R family and comparisons to GPT-4); evaluated on cross-lingual generation.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Command R: 35B; Command R+: 104B; GPT-4: proprietary sizes</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Cross-lingual generation with language instruction placed at different positions</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Generate output in a target language when an English instruction 'Reply in X' is placed at the start, integrated in the prompt body, or at the end.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Natural-language instruction with explicit 'Reply in <language>' inserted at start / integrated / end</td>
                        </tr>
                        <tr>
                            <td><strong>format_category</strong></td>
                            <td>prompt style / instruction placement</td>
                        </tr>
                        <tr>
                            <td><strong>format_details</strong></td>
                            <td>Three instruction positions tested: 'Start' (isolated instruction at beginning), 'Integrated' (language requirement embedded, e.g., 'Write an essay in Korean...'), and 'End' (isolated instruction appended). Also tested effect of adding a one-shot demonstration.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Line-level Pass Rate (LPR)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Command R: Start 86.7% LPR, Integrated 69.0% LPR, End 85.1% LPR (Table A11)</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td>Start (isolated) instruction: 86.7% LPR</td>
                        </tr>
                        <tr>
                            <td><strong>performance_change</strong></td>
                            <td>Integrated vs Start: -17.7 percentage points absolute in LPR for Command R; one-shot prompting raised integrated-case LPR from 69.0% to 80.6% (+11.6 pp)</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_setting</strong></td>
                            <td>Cross-lingual prompts; default decoding p=0.75, T=0.3; one-shot example format shown in §6.3.</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Understanding and Mitigating Language Confusion in LLMs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7667.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7667.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of a problem/prompt influences the performance of large language models, including details of the format, the task, the model, and reported performance differences.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Prompt length</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Prompt length (short / medium / long) as a determinant of confusion</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Prompt length by itself does not consistently predict language confusion; the paper finds no clear monotonic relationship between prompt length and LPR, suggesting that prompt complexity (not length) is the primary driver.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Various (Command R, Command R+, GPT-4, Mixtral)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Evaluations across multiple LLMs on the 'Complex prompts' dataset separated into length buckets.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>various</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Cross-lingual generation (complex prompts grouped by length)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Assess LPR for prompts split into short/medium/long buckets (equal-sized tertiles by word count).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Natural-language prompts of varying token/word lengths</td>
                        </tr>
                        <tr>
                            <td><strong>format_category</strong></td>
                            <td>prompt property / length</td>
                        </tr>
                        <tr>
                            <td><strong>format_details</strong></td>
                            <td>Prompts sorted by word length and split into three equal bins: short [21,65], medium [68,224], long [227,2971]; LPR computed per bin (Table A10).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Line-level Pass Rate (LPR)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Example: Command R LPR on Complex prompts: short 42.7%, medium 28.1%, long 38.0% (Table A10). GPT-4: short 89.3%, medium 72.9%, long 71.8%.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_change</strong></td>
                            <td>No consistent monotonic change with length; differences vary by model (paper conclusion: complexity > length)</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_setting</strong></td>
                            <td>Cross-lingual 'Complex' prompts; default decoding p=0.75, T=0.3; buckets defined as above.</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Understanding and Mitigating Language Confusion in LLMs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7667.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e7667.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of a problem/prompt influences the performance of large language models, including details of the format, the task, the model, and reported performance differences.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Few-shot prompting (Base models)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Few-shot prompting for base (non-instruction-tuned) models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Providing few-shot demonstrations (1-shot, 5-shot) dramatically reduces language confusion for base models that otherwise translate or ignore non-English instructions; e.g., Command R Base goes from near-zero cross-lingual LPR to very high with a few examples.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Command R Base</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Base model (not instruction-tuned) that tends to translate instead of answer; few-shot demonstrations provided as localized answers.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>35B (Command R base)</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Monolingual and cross-lingual generation with few-shot demonstrations</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Assess LPR and WPR when 0-shot, 1-shot, and 5-shot demonstrations are prepended (demonstrations translated into example languages).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Few-shot prompt template (5 examples translated via Google Translate for base model experiments); 0-shot Q/A template also tested.</td>
                        </tr>
                        <tr>
                            <td><strong>format_category</strong></td>
                            <td>few-shot / prompt template</td>
                        </tr>
                        <tr>
                            <td><strong>format_details</strong></td>
                            <td>Demonstrations are English prompts + answers translated into the demonstration languages; experiments include: Q/A template (0-shot), 1-shot, 5-shot. Cross-lingual prompts contain explicit English instruction to generate in target language.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Line-level Pass Rate (LPR); Word-level Pass Rate (WPR)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Command R Base: Monolingual LPR 86.2% (0-shot baseline) -> 1-shot 94.1% -> 5-shot 99.0%. Cross-lingual LPR 1.1% (0-shot) -> 1-shot 90.7% -> 5-shot 95.0% (Table 11). WPR also reaches ~100% with few-shot.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td>0-shot (Command R Base) cross-lingual LPR 1.1%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_change</strong></td>
                            <td>Cross-lingual LPR +94. - absolute increase from 1.1% to 95.0% with 5-shot (Command R Base); monolingual +12.8 pp from 86.2% to 99.0% with 5-shot.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_setting</strong></td>
                            <td>Cross-lingual generation, nucleus sampling p=0.75, T=0.3, up to 100 tokens; few-shot demos language-mismatched from target in some cases (see §6.3).</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Understanding and Mitigating Language Confusion in LLMs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7667.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e7667.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of a problem/prompt influences the performance of large language models, including details of the format, the task, the model, and reported performance differences.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Few-shot prompting (Instruction-tuned models)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Few-shot prompting effects for instruction-tuned models (adverse monolingual effect)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Providing a one-shot demonstration to instruction-tuned models can hurt monolingual LPR (they may be confused by a demonstration in a different language), while improving cross-lingual adherence in some cases.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Command R (instruction-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Instruction-tuned variant of Command R family evaluated with and without a 1-shot demonstration.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>35B (Command R), 104B (Command R+ variants also reported)</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Monolingual and cross-lingual generation with 1-shot demonstration</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Compare LPR/WPR of instruction-tuned models with and without a single demonstration prepended.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>1-shot demonstration (example prompt+answer) inserted before the query; demonstration language may differ from target task language.</td>
                        </tr>
                        <tr>
                            <td><strong>format_category</strong></td>
                            <td>few-shot / demonstration effect</td>
                        </tr>
                        <tr>
                            <td><strong>format_details</strong></td>
                            <td>Command R (instr-tuned) baseline reported; then +1-shot example (presented as conversational turns in some tests).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Line-level Pass Rate (LPR); Word-level Pass Rate (WPR)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Command R (instr-tuned): Monolingual LPR baseline 98.6% -> with 1-shot 68.3% (drop). Cross-lingual LPR baseline 68.1% -> with 1-shot 82.9% (gain) (Table 11). WPR shows smaller decreases.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td>Instruction-tuned Command R monolingual LPR 98.6% (no demo)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_change</strong></td>
                            <td>Monolingual LPR -30.3 pp (98.6% -> 68.3%) after 1-shot; Cross-lingual LPR +14.8 pp (68.1% -> 82.9%).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_setting</strong></td>
                            <td>Monolingual/cross-lingual settings; one-shot demonstrations may be in different languages than the test target; default decoding p=0.75, T=0.3.</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Understanding and Mitigating Language Confusion in LLMs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7667.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e7667.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of a problem/prompt influences the performance of large language models, including details of the format, the task, the model, and reported performance differences.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Decoding temperature & nucleus size</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Sampling hyperparameters: temperature (T) and nucleus sampling (p)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Higher sampling temperature substantially increases the probability of sampling wrong-language tokens, reducing word-level language purity (WPR); reducing temperature (sharpening) mitigates language confusion. Nucleus p has smaller effects.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Command R</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Instruction-tuned LLM evaluated under different sampling hyperparameters.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>35B (Command R)</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Monolingual generation WPR vs sampling hyperparameters</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Evaluate percentage of responses with no English words (WPR) in non-Latin-script target languages under different T and p.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Nucleus sampling with varying temperature T and nucleus fraction p (default p=0.75, T=0.3).</td>
                        </tr>
                        <tr>
                            <td><strong>format_category</strong></td>
                            <td>decoding hyperparameters</td>
                        </tr>
                        <tr>
                            <td><strong>format_details</strong></td>
                            <td>Monolingual experiments varied T in {0.0,0.3,0.5,0.7,1.0} and p in {0.1,0.3,0.5,0.75}. Greedy (T=0) corresponds to top-K=1.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Word-level Pass Rate (WPR)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Command R monolingual WPR (non-Latin script avg): T=0.3 (default) 96.3% WPR; T=1.0 86.5% WPR. Example per-language drops: Japanese 93.9% (T=0.3) -> 74.5% (T=1.0); Chinese 92.3% -> 74.7% (Table 8).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td>Default nucleus sampling p=0.75, T=0.3: 96.3% WPR (avg, non-Latin languages)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_change</strong></td>
                            <td>Increasing T to 1.0: -9.8 percentage points absolute in avg WPR (96.3% -> 86.5%) for Command R.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_setting</strong></td>
                            <td>Monolingual generation on non-Latin-script languages; nucleus sampling with p and T variations; max 100 tokens.</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Understanding and Mitigating Language Confusion in LLMs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7667.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e7667.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of a problem/prompt influences the performance of large language models, including details of the format, the task, the model, and reported performance differences.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Beam search vs sampling</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Decoding strategy: beam search (beam size 1..10) compared to nucleus sampling</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Beam search (increasing beam size) slightly improves word-level purity (WPR) in monolingual settings but tends to reduce cross-lingual line-level fidelity (LPR), especially for non-Indo-European languages.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Command R</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Instruction-tuned LLM evaluated with beam search decoding at various beam sizes.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>35B (Command R)</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Monolingual and cross-lingual language adherence under beam search</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Measure WPR and LPR as beam size is increased (beam sizes 1/greedy to 10).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Decoding using beam search with beam sizes 1,2,3,5,10 compared to nucleus sampling baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>format_category</strong></td>
                            <td>decoding strategy</td>
                        </tr>
                        <tr>
                            <td><strong>format_details</strong></td>
                            <td>Reported monolingual WPR and cross-lingual LPR for beam sizes 1..10. Default nucleus sampling baseline also reported in other sections.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>WPR (monolingual) and LPR (cross-lingual)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Beam size 1 (greedy) monolingual WPR 97.8% (Table 9/A14); cross-lingual LPR overall 74.1% at beam=1. Increasing beam to 10: monolingual WPR ~99.0% (slight improvement), cross-lingual LPR falls to 68.4% overall and non-IndoEuropean LPR drops from 73.9% -> 65.6% (Table 9).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td>Beam=1 (greedy) cross-lingual LPR 74.1% overall (Command R)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_change</strong></td>
                            <td>Beam=10 vs Beam=1: cross-lingual LPR -5.7 percentage points overall, non-IE languages -8.3 pp; monolingual WPR improved modestly (~+1-2 pp).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_setting</strong></td>
                            <td>Beam search decoding with beam sizes 1..10; other decoding defaults when comparing: nucleus sampling p=0.75, T=0.3 for sampling baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Understanding and Mitigating Language Confusion in LLMs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7667.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e7667.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of a problem/prompt influences the performance of large language models, including details of the format, the task, the model, and reported performance differences.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Instruction tuning language bias (English-only vs multilingual SFT/pref)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Instruction tuning composition: English-only instruction fine-tuning and preference tuning versus inclusion of multilingual data</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>English-only instruction/preference tuning can exacerbate language confusion (models over-prefer English), while adding even modest multilingual SFT data or multilingual preference-tuning substantially alleviates monolingual line-level confusion; cross-lingual effects are mixed.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Command R base -> variants; Llama base vs instruct</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Comparisons of base vs SFT (supervised fine-tuning) and preference-tuning variants with English-only or multilingual data mixtures.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>35B (Command R family), Llama variants 70B</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Monolingual and cross-lingual language adherence after different instruction tuning regimes</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Assess LPR/WPR after applying English-only SFT, English-only preference tuning, multilingual SFT (~10% non-English), multilingual preference tuning (~50% multilingual), and compare to base/instruction-tuned models.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Training-time format: composition of SFT and preference-tuning datasets (English-only vs multilingual mixture).</td>
                        </tr>
                        <tr>
                            <td><strong>format_category</strong></td>
                            <td>training data composition / instruction tuning style</td>
                        </tr>
                        <tr>
                            <td><strong>format_details</strong></td>
                            <td>English-only SFT and preference tuning used publicly-available English instruction data; multilingual SFT used machine-translated Dolly/ShareGPT augmentations; SFT mixture ~90% English, preference data ~50% multilingual.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Line-level Pass Rate (LPR); Word-level Pass Rate (WPR)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Command R Base -> English SFT: monolingual LPR drops to 77.8% (from Base 86.2%); multilingual SFT raises monolingual LPR to 98.3% (Table 11). Cross-lingual LPR: English-only SFT 78.3%, multilingual SFT 78.2% (similar). Llama 2 70B base LPR 98.5% vs Llama 2 70B-I (instruction-tuned, English-centric) LPR 6.0% (Table 6).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_performance</strong></td>
                            <td>Command R Base monolingual LPR 86.2%; Llama 2 base monolingual LPR 98.5%</td>
                        </tr>
                        <tr>
                            <td><strong>performance_change</strong></td>
                            <td>English-only SFT: Command R monolingual LPR -8.4 pp (86.2% -> 77.8%); Multilingual SFT: +12.1 pp (86.2% -> 98.3%). Llama instruction tuning (English-centric) caused collapse of monolingual LPR for Llama 2 (98.5% -> 6.0%).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_setting</strong></td>
                            <td>SFT and preference-tuning regimes as described; SFT mix ~90% English for multilingual SFT; preference tuning multilingual ~50%. Evaluations on monolingual and cross-lingual LCB tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Understanding and Mitigating Language Confusion in LLMs', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Why does zeroshot cross-lingual generation fail? an explanation and a solution. <em>(Rating: 2)</em></li>
                <li>On the off-target problem of zero-shot multilingual neural machine translation. <em>(Rating: 2)</em></li>
                <li>Overcoming catastrophic forgetting in zero-shot cross-lingual generation. <em>(Rating: 2)</em></li>
                <li>Turning english-centric llms into polyglots: How much multilinguality is needed? <em>(Rating: 2)</em></li>
                <li>mmT5: Modular multilingual pre-training solves source language hallucinations. <em>(Rating: 1)</em></li>
                <li>Evaluating the elementary multilingual capabilities of large language models with multiq. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7667",
    "paper_id": "paper-1f874c94d531f6776f65e0aa807adbf432ea35cf",
    "extraction_schema_id": "extraction-schema-140",
    "extracted_data": [
        {
            "name_short": "Prompt complexity (Complex vs Okapi/ShareGPT)",
            "name_full": "Prompt complexity: Complex human-authored prompts versus simpler Okapi/ShareGPT prompts",
            "brief_description": "Cross-lingual prompt complexity (more complex, multi-step or contextual prompts) strongly increases language confusion in LLMs compared to simpler prompts (Okapi, ShareGPT); effect is observed across model families but is most pronounced for models with English-centric behaviour.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Various (Command R, Command R+, Llama 2/3, Mixtral, Mistral, GPT-3.5/4/4o)",
            "model_description": "Instruction-tuned and base large transformer LLMs evaluated on monolingual and cross-lingual generation; models include base and instruction-tuned variants across several families.",
            "model_size": "various (8x7B, 35B, 70B, 104B, etc.)",
            "task_name": "Language Confusion Benchmark (cross-lingual generation)",
            "task_description": "Instruction in English asking the model to produce output in a target non-English language; measures whether the model produces output entirely in the requested language.",
            "problem_format": "Natural-language instruction prompts; dataset split by source (Okapi, ShareGPT, Complex prompts collected by authors).",
            "format_category": "prompt style / prompt complexity",
            "format_details": "Three dataset sources compared for cross-lingual generation: Okapi (synthetic/MT, simpler instructions), ShareGPT (mostly English user prompts), and Complex prompts (human-authored, multi-step, integrated instructions). For cross-lingual examples the English instruction to produce the target language was added either at start, end, or integrated. Default decoding: nucleus sampling p=0.75, T=0.3, max 100 tokens.",
            "performance_metric": "Line-level Pass Rate (LPR)",
            "performance_value": "Command R: Okapi 75.6% LPR, ShareGPT 89.7% LPR, Complex prompts 39.0% LPR (cross-lingual average reported in Table 5)",
            "baseline_performance": "Command R on ShareGPT: 89.7% LPR",
            "performance_change": "Command R Complex vs ShareGPT: -50.7 percentage points (absolute) in LPR",
            "experimental_setting": "Cross-lingual generation (English instruction -&gt; target language), nucleus sampling p=0.75, T=0.3, up to 100 tokens; results aggregated by dataset.",
            "statistical_significance": null,
            "uuid": "e7667.0",
            "source_info": {
                "paper_title": "Understanding and Mitigating Language Confusion in LLMs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Instruction position (isolated vs integrated)",
            "name_full": "Position of the language-control instruction: isolated (start/end) versus integrated in prompt",
            "brief_description": "Placing an isolated language instruction at the start or end of a prompt yields substantially lower language confusion than embedding the language instruction inside a longer/integrated prompt; integrated instructions are harder for models to follow, but few-shot demonstrations can reduce this difficulty.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Command R (and evaluated for GPT-4, Command R+, variants)",
            "model_description": "Instruction-tuned transformer LLM (Command R family and comparisons to GPT-4); evaluated on cross-lingual generation.",
            "model_size": "Command R: 35B; Command R+: 104B; GPT-4: proprietary sizes",
            "task_name": "Cross-lingual generation with language instruction placed at different positions",
            "task_description": "Generate output in a target language when an English instruction 'Reply in X' is placed at the start, integrated in the prompt body, or at the end.",
            "problem_format": "Natural-language instruction with explicit 'Reply in &lt;language&gt;' inserted at start / integrated / end",
            "format_category": "prompt style / instruction placement",
            "format_details": "Three instruction positions tested: 'Start' (isolated instruction at beginning), 'Integrated' (language requirement embedded, e.g., 'Write an essay in Korean...'), and 'End' (isolated instruction appended). Also tested effect of adding a one-shot demonstration.",
            "performance_metric": "Line-level Pass Rate (LPR)",
            "performance_value": "Command R: Start 86.7% LPR, Integrated 69.0% LPR, End 85.1% LPR (Table A11)",
            "baseline_performance": "Start (isolated) instruction: 86.7% LPR",
            "performance_change": "Integrated vs Start: -17.7 percentage points absolute in LPR for Command R; one-shot prompting raised integrated-case LPR from 69.0% to 80.6% (+11.6 pp)",
            "experimental_setting": "Cross-lingual prompts; default decoding p=0.75, T=0.3; one-shot example format shown in §6.3.",
            "statistical_significance": null,
            "uuid": "e7667.1",
            "source_info": {
                "paper_title": "Understanding and Mitigating Language Confusion in LLMs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Prompt length",
            "name_full": "Prompt length (short / medium / long) as a determinant of confusion",
            "brief_description": "Prompt length by itself does not consistently predict language confusion; the paper finds no clear monotonic relationship between prompt length and LPR, suggesting that prompt complexity (not length) is the primary driver.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Various (Command R, Command R+, GPT-4, Mixtral)",
            "model_description": "Evaluations across multiple LLMs on the 'Complex prompts' dataset separated into length buckets.",
            "model_size": "various",
            "task_name": "Cross-lingual generation (complex prompts grouped by length)",
            "task_description": "Assess LPR for prompts split into short/medium/long buckets (equal-sized tertiles by word count).",
            "problem_format": "Natural-language prompts of varying token/word lengths",
            "format_category": "prompt property / length",
            "format_details": "Prompts sorted by word length and split into three equal bins: short [21,65], medium [68,224], long [227,2971]; LPR computed per bin (Table A10).",
            "performance_metric": "Line-level Pass Rate (LPR)",
            "performance_value": "Example: Command R LPR on Complex prompts: short 42.7%, medium 28.1%, long 38.0% (Table A10). GPT-4: short 89.3%, medium 72.9%, long 71.8%.",
            "baseline_performance": null,
            "performance_change": "No consistent monotonic change with length; differences vary by model (paper conclusion: complexity &gt; length)",
            "experimental_setting": "Cross-lingual 'Complex' prompts; default decoding p=0.75, T=0.3; buckets defined as above.",
            "statistical_significance": null,
            "uuid": "e7667.2",
            "source_info": {
                "paper_title": "Understanding and Mitigating Language Confusion in LLMs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Few-shot prompting (Base models)",
            "name_full": "Few-shot prompting for base (non-instruction-tuned) models",
            "brief_description": "Providing few-shot demonstrations (1-shot, 5-shot) dramatically reduces language confusion for base models that otherwise translate or ignore non-English instructions; e.g., Command R Base goes from near-zero cross-lingual LPR to very high with a few examples.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Command R Base",
            "model_description": "Base model (not instruction-tuned) that tends to translate instead of answer; few-shot demonstrations provided as localized answers.",
            "model_size": "35B (Command R base)",
            "task_name": "Monolingual and cross-lingual generation with few-shot demonstrations",
            "task_description": "Assess LPR and WPR when 0-shot, 1-shot, and 5-shot demonstrations are prepended (demonstrations translated into example languages).",
            "problem_format": "Few-shot prompt template (5 examples translated via Google Translate for base model experiments); 0-shot Q/A template also tested.",
            "format_category": "few-shot / prompt template",
            "format_details": "Demonstrations are English prompts + answers translated into the demonstration languages; experiments include: Q/A template (0-shot), 1-shot, 5-shot. Cross-lingual prompts contain explicit English instruction to generate in target language.",
            "performance_metric": "Line-level Pass Rate (LPR); Word-level Pass Rate (WPR)",
            "performance_value": "Command R Base: Monolingual LPR 86.2% (0-shot baseline) -&gt; 1-shot 94.1% -&gt; 5-shot 99.0%. Cross-lingual LPR 1.1% (0-shot) -&gt; 1-shot 90.7% -&gt; 5-shot 95.0% (Table 11). WPR also reaches ~100% with few-shot.",
            "baseline_performance": "0-shot (Command R Base) cross-lingual LPR 1.1%",
            "performance_change": "Cross-lingual LPR +94. - absolute increase from 1.1% to 95.0% with 5-shot (Command R Base); monolingual +12.8 pp from 86.2% to 99.0% with 5-shot.",
            "experimental_setting": "Cross-lingual generation, nucleus sampling p=0.75, T=0.3, up to 100 tokens; few-shot demos language-mismatched from target in some cases (see §6.3).",
            "statistical_significance": null,
            "uuid": "e7667.3",
            "source_info": {
                "paper_title": "Understanding and Mitigating Language Confusion in LLMs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Few-shot prompting (Instruction-tuned models)",
            "name_full": "Few-shot prompting effects for instruction-tuned models (adverse monolingual effect)",
            "brief_description": "Providing a one-shot demonstration to instruction-tuned models can hurt monolingual LPR (they may be confused by a demonstration in a different language), while improving cross-lingual adherence in some cases.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Command R (instruction-tuned)",
            "model_description": "Instruction-tuned variant of Command R family evaluated with and without a 1-shot demonstration.",
            "model_size": "35B (Command R), 104B (Command R+ variants also reported)",
            "task_name": "Monolingual and cross-lingual generation with 1-shot demonstration",
            "task_description": "Compare LPR/WPR of instruction-tuned models with and without a single demonstration prepended.",
            "problem_format": "1-shot demonstration (example prompt+answer) inserted before the query; demonstration language may differ from target task language.",
            "format_category": "few-shot / demonstration effect",
            "format_details": "Command R (instr-tuned) baseline reported; then +1-shot example (presented as conversational turns in some tests).",
            "performance_metric": "Line-level Pass Rate (LPR); Word-level Pass Rate (WPR)",
            "performance_value": "Command R (instr-tuned): Monolingual LPR baseline 98.6% -&gt; with 1-shot 68.3% (drop). Cross-lingual LPR baseline 68.1% -&gt; with 1-shot 82.9% (gain) (Table 11). WPR shows smaller decreases.",
            "baseline_performance": "Instruction-tuned Command R monolingual LPR 98.6% (no demo)",
            "performance_change": "Monolingual LPR -30.3 pp (98.6% -&gt; 68.3%) after 1-shot; Cross-lingual LPR +14.8 pp (68.1% -&gt; 82.9%).",
            "experimental_setting": "Monolingual/cross-lingual settings; one-shot demonstrations may be in different languages than the test target; default decoding p=0.75, T=0.3.",
            "statistical_significance": null,
            "uuid": "e7667.4",
            "source_info": {
                "paper_title": "Understanding and Mitigating Language Confusion in LLMs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Decoding temperature & nucleus size",
            "name_full": "Sampling hyperparameters: temperature (T) and nucleus sampling (p)",
            "brief_description": "Higher sampling temperature substantially increases the probability of sampling wrong-language tokens, reducing word-level language purity (WPR); reducing temperature (sharpening) mitigates language confusion. Nucleus p has smaller effects.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Command R",
            "model_description": "Instruction-tuned LLM evaluated under different sampling hyperparameters.",
            "model_size": "35B (Command R)",
            "task_name": "Monolingual generation WPR vs sampling hyperparameters",
            "task_description": "Evaluate percentage of responses with no English words (WPR) in non-Latin-script target languages under different T and p.",
            "problem_format": "Nucleus sampling with varying temperature T and nucleus fraction p (default p=0.75, T=0.3).",
            "format_category": "decoding hyperparameters",
            "format_details": "Monolingual experiments varied T in {0.0,0.3,0.5,0.7,1.0} and p in {0.1,0.3,0.5,0.75}. Greedy (T=0) corresponds to top-K=1.",
            "performance_metric": "Word-level Pass Rate (WPR)",
            "performance_value": "Command R monolingual WPR (non-Latin script avg): T=0.3 (default) 96.3% WPR; T=1.0 86.5% WPR. Example per-language drops: Japanese 93.9% (T=0.3) -&gt; 74.5% (T=1.0); Chinese 92.3% -&gt; 74.7% (Table 8).",
            "baseline_performance": "Default nucleus sampling p=0.75, T=0.3: 96.3% WPR (avg, non-Latin languages)",
            "performance_change": "Increasing T to 1.0: -9.8 percentage points absolute in avg WPR (96.3% -&gt; 86.5%) for Command R.",
            "experimental_setting": "Monolingual generation on non-Latin-script languages; nucleus sampling with p and T variations; max 100 tokens.",
            "statistical_significance": null,
            "uuid": "e7667.5",
            "source_info": {
                "paper_title": "Understanding and Mitigating Language Confusion in LLMs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Beam search vs sampling",
            "name_full": "Decoding strategy: beam search (beam size 1..10) compared to nucleus sampling",
            "brief_description": "Beam search (increasing beam size) slightly improves word-level purity (WPR) in monolingual settings but tends to reduce cross-lingual line-level fidelity (LPR), especially for non-Indo-European languages.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Command R",
            "model_description": "Instruction-tuned LLM evaluated with beam search decoding at various beam sizes.",
            "model_size": "35B (Command R)",
            "task_name": "Monolingual and cross-lingual language adherence under beam search",
            "task_description": "Measure WPR and LPR as beam size is increased (beam sizes 1/greedy to 10).",
            "problem_format": "Decoding using beam search with beam sizes 1,2,3,5,10 compared to nucleus sampling baseline.",
            "format_category": "decoding strategy",
            "format_details": "Reported monolingual WPR and cross-lingual LPR for beam sizes 1..10. Default nucleus sampling baseline also reported in other sections.",
            "performance_metric": "WPR (monolingual) and LPR (cross-lingual)",
            "performance_value": "Beam size 1 (greedy) monolingual WPR 97.8% (Table 9/A14); cross-lingual LPR overall 74.1% at beam=1. Increasing beam to 10: monolingual WPR ~99.0% (slight improvement), cross-lingual LPR falls to 68.4% overall and non-IndoEuropean LPR drops from 73.9% -&gt; 65.6% (Table 9).",
            "baseline_performance": "Beam=1 (greedy) cross-lingual LPR 74.1% overall (Command R)",
            "performance_change": "Beam=10 vs Beam=1: cross-lingual LPR -5.7 percentage points overall, non-IE languages -8.3 pp; monolingual WPR improved modestly (~+1-2 pp).",
            "experimental_setting": "Beam search decoding with beam sizes 1..10; other decoding defaults when comparing: nucleus sampling p=0.75, T=0.3 for sampling baseline.",
            "statistical_significance": null,
            "uuid": "e7667.6",
            "source_info": {
                "paper_title": "Understanding and Mitigating Language Confusion in LLMs",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Instruction tuning language bias (English-only vs multilingual SFT/pref)",
            "name_full": "Instruction tuning composition: English-only instruction fine-tuning and preference tuning versus inclusion of multilingual data",
            "brief_description": "English-only instruction/preference tuning can exacerbate language confusion (models over-prefer English), while adding even modest multilingual SFT data or multilingual preference-tuning substantially alleviates monolingual line-level confusion; cross-lingual effects are mixed.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Command R base -&gt; variants; Llama base vs instruct",
            "model_description": "Comparisons of base vs SFT (supervised fine-tuning) and preference-tuning variants with English-only or multilingual data mixtures.",
            "model_size": "35B (Command R family), Llama variants 70B",
            "task_name": "Monolingual and cross-lingual language adherence after different instruction tuning regimes",
            "task_description": "Assess LPR/WPR after applying English-only SFT, English-only preference tuning, multilingual SFT (~10% non-English), multilingual preference tuning (~50% multilingual), and compare to base/instruction-tuned models.",
            "problem_format": "Training-time format: composition of SFT and preference-tuning datasets (English-only vs multilingual mixture).",
            "format_category": "training data composition / instruction tuning style",
            "format_details": "English-only SFT and preference tuning used publicly-available English instruction data; multilingual SFT used machine-translated Dolly/ShareGPT augmentations; SFT mixture ~90% English, preference data ~50% multilingual.",
            "performance_metric": "Line-level Pass Rate (LPR); Word-level Pass Rate (WPR)",
            "performance_value": "Command R Base -&gt; English SFT: monolingual LPR drops to 77.8% (from Base 86.2%); multilingual SFT raises monolingual LPR to 98.3% (Table 11). Cross-lingual LPR: English-only SFT 78.3%, multilingual SFT 78.2% (similar). Llama 2 70B base LPR 98.5% vs Llama 2 70B-I (instruction-tuned, English-centric) LPR 6.0% (Table 6).",
            "baseline_performance": "Command R Base monolingual LPR 86.2%; Llama 2 base monolingual LPR 98.5%",
            "performance_change": "English-only SFT: Command R monolingual LPR -8.4 pp (86.2% -&gt; 77.8%); Multilingual SFT: +12.1 pp (86.2% -&gt; 98.3%). Llama instruction tuning (English-centric) caused collapse of monolingual LPR for Llama 2 (98.5% -&gt; 6.0%).",
            "experimental_setting": "SFT and preference-tuning regimes as described; SFT mix ~90% English for multilingual SFT; preference tuning multilingual ~50%. Evaluations on monolingual and cross-lingual LCB tasks.",
            "statistical_significance": null,
            "uuid": "e7667.7",
            "source_info": {
                "paper_title": "Understanding and Mitigating Language Confusion in LLMs",
                "publication_date_yy_mm": "2024-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Why does zeroshot cross-lingual generation fail? an explanation and a solution.",
            "rating": 2
        },
        {
            "paper_title": "On the off-target problem of zero-shot multilingual neural machine translation.",
            "rating": 2
        },
        {
            "paper_title": "Overcoming catastrophic forgetting in zero-shot cross-lingual generation.",
            "rating": 2
        },
        {
            "paper_title": "Turning english-centric llms into polyglots: How much multilinguality is needed?",
            "rating": 2
        },
        {
            "paper_title": "mmT5: Modular multilingual pre-training solves source language hallucinations.",
            "rating": 1
        },
        {
            "paper_title": "Evaluating the elementary multilingual capabilities of large language models with multiq.",
            "rating": 1
        }
    ],
    "cost": 0.0236555,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Understanding and Mitigating Language Confusion in LLMs</h1>
<p>Kelly Marchisio<em>, Wei-Yin Ko</em>, Alexandre Bérard, Théo Dehaze, Sebastian Ruder*<br>Cohere</p>
<h4>Abstract</h4>
<p>We investigate a surprising limitation of LLMs: their inability to consistently generate text in a user's desired language. We create the Language Confusion Benchmark (LCB) to evaluate such failures, covering 15 typologically diverse languages with existing and newly-created English and multilingual prompts. We evaluate a range of LLMs on monolingual and crosslingual generation reflecting practical use cases, finding that Llama Instruct and Mistral models exhibit high degrees of language confusion and even the strongest models fail to consistently respond in the correct language. We observe that base and English-centric instruct models are more prone to language confusion, which is aggravated by complex prompts and high sampling temperatures. We find that language confusion can be partially mitigated via fewshot prompting, multilingual SFT and preference tuning. We release our language confusion benchmark, which serves as a first layer of efficient, scalable multilingual evaluation. ${ }^{1}$</p>
<h2>1 Introduction</h2>
<p>Large language models (LLMs) are increasingly used in a variety of applications across the globe (Kaddour et al., 2023). While early LLMs focused on English (Joshi et al., 2020; Hu et al., 2020), recent models are more multilingual. Nevertheless, LLMs do not provide equal utility to non-English speakers due to higher latency, increased costs, and reduced performance (Ahia et al., 2023; Asai et al., 2023; Held et al., 2023).</p>
<p>To be useful, an LLM must understand intent and provide a response that is appropriate in both form, e.g., correct grammar, style, tone, register, and content, e.g., truthful, coherent, concise (Grice,</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Language Confusion can occur at the word level, line level, or over the entire output response.</p>
<p>1975; Wilson and Sperber, 2012). While contentrelated issues such as hallucinations have attracted substantial attention (Ji et al., 2023; Bang et al., 2023), they are often subtle and difficult to evaluate (Gudibande et al., 2024; Hosking et al., 2024), particularly in multilingual settings (Guerreiro et al., 2023). Form-related errors indicate a more obvious failure to fulfill a request and-in extreme casesmay cause confusing or unintelligible responses.</p>
<p>We identify a surprising form limitation that drastically reduces LLMs' utility for non-English languages: LLMs are often unable to consistently generate text in the user's desired language, or the appropriate language given the context. We call this category of error "language confusion". ${ }^{2}$</p>
<p>Take an Arabic prompt as an example: an LLM may inappropriately respond fully in English (fullresponse confusion), produce some lines in the desired language and some in another language (line-level confusion), or sporadically insert single</p>
<p><sup id="fnref:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<p>words or phrases in another language (word-level confusion). Figure 1 shows example errors. Even if such errors occur rarely, they cause a jarring user 经验 (experience).</p>
<p>We investigate language confusion on the line and word level in two practical settings: a) Monolingual generation, where a user queries the LLM in a given language, implicitly requesting an answer in the same language; and b) cross-lingual generation, where a user explicitly instructs a model to generate text in a different language.</p>
<p>We create and release a language confusion benchmark covering 15 typologically diverse languages, sourcing prompts from public English and multilingual instruction datasets, and additionally creating new data with more complex prompts. We evaluate a range of state-of-the-art LLMs including Llama, Command R, Mistral, and OpenAI family models. We find that Llama Instruct and Mistral LLMs exhibit severe language confusion in many languages. While Command R and OpenAI models fare much better on monolingual generation, even the strongest cannot consistently generate text in the correct language cross-lingually.
Our contributions are the following:</p>
<ol>
<li>We identify and describe the issue of language confusion in LLMs.</li>
<li>We introduce a new benchmark and metrics to measure language confusion in LLMs.</li>
<li>We perform a systematic evaluation of various LLMs, investigating when language confusion occurs in practice.</li>
<li>We propose methods to mitigate language confusion in LLMs.</li>
</ol>
<h2>2 Language Confusion Benchmark</h2>
<p>While some datasets to evaluate LLMs' performance on natural code-switched data exist (Khanuja et al., 2020; Winata et al., 2023), there are none designed to assess language confusion in LLMs. We create the Language Confusion Benchmark (LCB) by collecting a diverse set of prompts reflecting realistic use cases across a typologically diverse set of languages. The benchmark is easily extensible, cheap, and efficient to evaluate.</p>
<h3>2.1 Generation settings</h3>
<p>We measure language confusion in two settings: monolingual and cross-lingual generation.</p>
<p>Monolingual generation A speaker queries a model in language $l$ and expects a response in $l$.</p>
<p>This is the most common usage scenario as users often prefer to interact with technology in their native language (Kantar and IAMAI, 2023).</p>
<p>Cross-lingual generation A user instructs a model in language $l$ to fulfill a request in another language $l^{\prime}$. In this challenging setting, the requested language $l^{\prime}$ is different from the instruction language $l$. This setting is relevant in applications where multilingual outputs are required, but optimizing a prompt for each input language is inefficient in practice or when a user requires a generation in a language they do not speak. We set the instruction language to English.</p>
<h3>2.2 Language Confusion Metrics</h3>
<p>To detect language confusion, we rely on off-theshelf language identification (LID) tools. We employ fastText (Joulin et al., 2016) as a strong alternative to expensive LLM-based evaluation.</p>
<p>Line-level detection We split a response into lines (by newline character) and check each line against the user's desired language with fastText. ${ }^{3}$</p>
<p>Word-level detection Off-the-shelf tools do not support word-level LID and LLMs only achieve 7986 F1 detecting word-level code-switching (Zhang et al., 2023), too low for use as automatic evaluators. Consequently, we take a two-pronged heuristic approach to detecting word-level language confusion focusing on settings where it achieves high precision. For non-Latin script languages, we observe that word-level language confusion in top LLMs mainly occurs with English. To avoid natural code-switching false positives, ${ }^{4}$ we check for English words that do not typically occur in target language text. ${ }^{5}$ We evaluate word-level confusion in Arabic (ar), Hindi (hi), Japanese (ja), Korean (ko), Russian (ru), and Simplified Chinese (zh). For Latin script languages where word-level language confusion is rarer, ${ }^{6}$ we detect tokens where any character is outside of the Unicode range of the language's script. We evaluate word-level confusion in German (de), English (en), Spanish (es),</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>|  | Dataset name | Reference | Nature of data | $|L|$ | $|D|$ | Languages | $W$ |
| :--: | :--: | :--: | :--: | :--: | :--: | :--: |
| $\sim$ | Aya | Singh et al. (2024) | Human-generated | 100 | 500 | en, tr, ar, zh, pt |
|  | Dolly | Singh et al. (2024) | MT post-edited | 100 | 500 | hi, ru, fr, ar, es |
|  | Okapi | Lai et al. (2023) | Synthetic + MT | 100 | 1.2 k | en, fr, it, de, zh, vi, ru, es, id, pt, ar, hi |
|  | Native prompts | Ours | Human-generated | 100 | 400 | es, fr, ja, ko |
| $\begin{aligned} &amp; \text { O } \ &amp; \text { O } \end{aligned}$ | Okapi | Lai et al. (2023) | Synthetic | 100 | 1.5 k | $\mathcal{L}$ |
|  | ShareGPT | https://sharegpt.com/ | Human-generated | 100 | 1.5 k | $\mathcal{L}$ |
|  | Complex prompts | Ours | Human-generated | 99 | 1.5 k | $\mathcal{L}$ |</p>
<p>Table 1: Data sources in the LCB for monolingual and cross-lingual generation. $|D|$ is the total number of examples per data source and $|L|$ is the number of examples per language. For the crosslingual setting, the model is instructed in English to generate in the target language $l \in \mathcal{L}$ where $\mathcal{L}=$ ${\mathrm{fr}$, de, es, pt, it, ja, ko, zh, ar, tr, hi, ru, id, vi $}$. $W$ is the median length in words of the prompts in each dataset.</p>
<p>French (fr), Indonesian (id), Italian (it), Portuguese (pt), Turkish (tr), and Vietnamese (vi).</p>
<p>Binary evaluation A response is only correct when entirely in the correct language, as even one instance of language confusion can damage intelligibility and cause a jarring user experience. We calculate binary metrics to indicate whether a response contains any instance of a) a line in an incorrect language and b) an isolated English word for languages using $\neg$ Latin scripts and an out-of-Unicode-range character for Latin script languages. These main metrics are defined below.</p>
<p>Line-level pass rate (LPR): percentage of model responses that pass our line-level language confusion detector without error. A response is "correct" if all lines match the user's desired language.</p>
<p>$$
\mathrm{LPR}=\frac{\left|R \backslash E_{L}\right|}{|R|}
$$</p>
<p>where $R$ is the set of all responses and $E_{L}$ the set of responses that contain line-level errors. ${ }^{7}$</p>
<p>Word-level pass rate (WPR): percentage of responses where all words are in the desired language. We exclude responses with line-level errors as most line-level errors would also be counted as wordlevel errors, making it difficult to disentangle the two error types. For languages that use a $\neg$ Latin script, we detect erroneous English words while for Latin script languages, we identify characters outside of the script's Unicode range.</p>
<p>$$
\mathrm{WPR}=\frac{\left|\left(R \backslash E_{L}\right) \backslash E_{W}\right|}{\left|R \backslash E_{L}\right|}
$$</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup>where $R$ is the set of all responses, $E_{L}$ the set of responses with line-level errors and $E_{W}$ the set of responses with word-level errors.</p>
<p>Language confusion pass rate (LCPR): harmonic mean ${ }^{8}$ of LPR and WPR:</p>
<p>$$
\mathrm{LCPR}=2 \times \frac{\mathrm{LPR} \times \mathrm{WPR}}{\mathrm{LPR}+\mathrm{WPR}}
$$</p>
<p>LCPR is elucidating in cases of severe issues producing output in the correct language. ${ }^{9}$</p>
<h3>2.3 Data sources</h3>
<p>The monolingual and cross-lingual tasks respectively comprise 2600 and 4500 prompts in total, across 15 typologically diverse languages: English, French, German, Spanish, Portuguese, Italian, Japanese, Korean, Chinese, Arabic, Turkish, Hindi, Russian, Indonesian, and Vietnamese. Details are shown in Table 1.</p>
<p>The prompts are sourced from the datasets below, focusing on human-annotated or human-edited prompts. We filter each dataset to make it most useful for evaluating language confusion.</p>
<p>Aya 250 original human-written prompts in 7 languages each from the aya-human-annotated subset of the Aya Evaluation Suite (Singh et al., 2024).</p>
<p>Dolly 200 machine-translated Dolly (Conover et al., 2023) prompts post-edited by fluent speakers for 6 languages from the Aya Evaluation Suite's dolly-human-edited subset (Singh et al., 2024).</p>
<p><sup id="fnref2:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">Prompt</th>
<th style="text-align: center;">Translation</th>
<th style="text-align: center;">Data source</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Monolingual</td>
<td style="text-align: center;">同: 如何清洗和保养孩子?</td>
<td style="text-align: center;">Q: How to clean and maintain chopsticks?</td>
<td style="text-align: center;">Aya</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">¿Cómo escapar de un helicóptero atrapado en el agua?</td>
<td style="text-align: center;">How to escape from a helicopter stuck in water?</td>
<td style="text-align: center;">Dolly</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Erklären Sie, wie der Gini-Index berechnet wird.</td>
<td style="text-align: center;">Explain how the Gini index is calculated.</td>
<td style="text-align: center;">Okapi</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">日本で救急隊員を目指す人は、どのような教育や トレーニングを受ける必要がありますか。</td>
<td style="text-align: center;">What kind of education and training do people who want to become emergency workers in Japan need to undergo?</td>
<td style="text-align: center;">Native prompts (Ours)</td>
</tr>
<tr>
<td style="text-align: center;">Cross-lingual</td>
<td style="text-align: center;">Generate an essay in Korean of at least 500 words that argues in favor of regulating artificial intelligence.</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Okapi</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Respond in French. You are a medical communications expert. Please provide a summary on how pharma companies are approaching diversity and inclusion, and health inequalities globally. Focus on the general approach and include information on clinical trials.</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">ShareGPT</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Based solely on the text below: 1. Extract the statistical techniques and machine learning algorithms analysts employ to uncover relationships and patterns within the data. 2. Generate 5 fill-in-the-blanks style questions 3. Summarize the text in 100 words [...] Reply in Turkish.</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Complex <br> prompts <br> (Ours)</td>
</tr>
</tbody>
</table>
<p>Table 2: An example prompt from each dataset used for monolingual and cross-lingual generation. English translations are shown for convenience. For cross-lingual generation, prompts are in English and have been amended with an instruction to generate the output in another language. The complex prompt example is truncated.</p>
<p>Okapi We use the multilingual-alpaca-52k subset of the Okapi data, which contains ChatGPTgenerated translations of 52k English instructions from Alpaca (Taori et al., 2023) into 26 languages.</p>
<p>ShareGPT We use prompts from the first turn of 90,000 mostly English user conversations with ChatGPT, scraped via the ShareGPT API ${ }^{10}$ before it was shut down. ${ }^{11}$</p>
<p>Native prompts (Ours) For Japanese and Korean, under-represented in the above datasets, as well as Spanish and French, we commission native annotators to collect our own prompts (see §A.2).</p>
<p>Complex prompts (Ours) As prompts from the above sources are relatively simple, we collect complex English prompts written by human annotators.</p>
<h3>2.4 Data Filtering and Processing</h3>
<p>Suitability for LID As LID tools underperform on short sequences and non-standard text, we manually filter out: a) examples answerable with a single word/phrase; b) multiple-choice questions and prompts asking for lists; c) prompts requiring code generation, math equations, or data formats such as HTML. For datasets where completions are available, we filter out prompts with very short completions (less than 5 words).</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup>Western-centric responses Many datasets created via translation contain questions about Western-centric concepts (e.g., US National Parks, presidents or US-based brands) which can cause false positives with our word-level detector. We manually filter out such questions.</p>
<p>Prompt format For cross-lingual generation, we semi-automatically amend prompts with an instruction to generate in a target language (see §A. 3 for details). Prompts are used as-is for monolingual generation. Some examples are shown in Table 2.</p>
<h2>3 Experiments</h2>
<p>Models We evaluate the following LLMs covering various scales and model families: Llama 270B Instruct (Touvron et al., 2023), Llama 3 and 3.1 70B Instruct (Dubey et al., 2024), Command R (35B), ${ }^{12}$ Command R+ (104B parameters), ${ }^{13}$ Command R Refresh (command-r-08-2024), Command R+ Refresh (command-r-plus-08-2024), Mixtral 8x7B (Jiang et al., 2024), Mistral Large, ${ }^{14}$ GPT-3.5 Turbo (gpt-3.5-turbo-012524; Brown et al., 2020), GPT-4 Turbo (gpt-4-turbo-040924; Achiam et al., 2023), and GPT-4o (gpt-4o-2024-08-06). For Llama and Command models, we also evaluate base versions (see §4.5). We generate at most</p>
<p><sup id="fnref3:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">Monolingual</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">avg</td>
<td style="text-align: center;">ar</td>
<td style="text-align: center;">de</td>
<td style="text-align: center;">en</td>
<td style="text-align: center;">es</td>
<td style="text-align: center;">fr</td>
<td style="text-align: center;">hi</td>
<td style="text-align: center;">id</td>
<td style="text-align: center;">it</td>
<td style="text-align: center;">ja</td>
<td style="text-align: center;">ko</td>
<td style="text-align: center;">pt</td>
<td style="text-align: center;">ru</td>
<td style="text-align: center;">tr</td>
<td style="text-align: center;">vi</td>
<td style="text-align: center;">zh</td>
</tr>
<tr>
<td style="text-align: center;">Llama 2 70B-I</td>
<td style="text-align: center;">48.3</td>
<td style="text-align: center;">0.3</td>
<td style="text-align: center;">59.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">95.7</td>
<td style="text-align: center;">87.7</td>
<td style="text-align: center;">1.0</td>
<td style="text-align: center;">62.0</td>
<td style="text-align: center;">72.0</td>
<td style="text-align: center;">7.0</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">91.0</td>
<td style="text-align: center;">88.9</td>
<td style="text-align: center;">33.0</td>
<td style="text-align: center;">17.0</td>
<td style="text-align: center;">10.5</td>
</tr>
<tr>
<td style="text-align: center;">Llama 3 70B-I</td>
<td style="text-align: center;">46.0</td>
<td style="text-align: center;">21.7</td>
<td style="text-align: center;">31.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.3</td>
<td style="text-align: center;">88.7</td>
<td style="text-align: center;">23.0</td>
<td style="text-align: center;">21.0</td>
<td style="text-align: center;">88.0</td>
<td style="text-align: center;">10.0</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">95.5</td>
<td style="text-align: center;">77.0</td>
<td style="text-align: center;">18.0</td>
<td style="text-align: center;">10.0</td>
<td style="text-align: center;">8.0</td>
</tr>
<tr>
<td style="text-align: center;">Llama 3.1 70B-I</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">98.9</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">94.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">96.9</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
</tr>
<tr>
<td style="text-align: center;">Mixtral 8x7B</td>
<td style="text-align: center;">73.0</td>
<td style="text-align: center;">48.3</td>
<td style="text-align: center;">90.9</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">89.3</td>
<td style="text-align: center;">95.3</td>
<td style="text-align: center;">71.0</td>
<td style="text-align: center;">58.0</td>
<td style="text-align: center;">72.0</td>
<td style="text-align: center;">66.7</td>
<td style="text-align: center;">61.2</td>
<td style="text-align: center;">85.0</td>
<td style="text-align: center;">65.0</td>
<td style="text-align: center;">90.0</td>
<td style="text-align: center;">57.0</td>
<td style="text-align: center;">45.5</td>
</tr>
<tr>
<td style="text-align: center;">Mistral Large</td>
<td style="text-align: center;">69.9</td>
<td style="text-align: center;">48.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">19.0</td>
<td style="text-align: center;">31.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">48.0</td>
<td style="text-align: center;">64.0</td>
<td style="text-align: center;">79.5</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">71.0</td>
<td style="text-align: center;">29.0</td>
<td style="text-align: center;">66.0</td>
</tr>
<tr>
<td style="text-align: center;">Command R</td>
<td style="text-align: center;">98.6</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">95.7</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">92.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">98.5</td>
</tr>
<tr>
<td style="text-align: center;">Command R+</td>
<td style="text-align: center;">99.2</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">97.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">97.5</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">97.5</td>
</tr>
<tr>
<td style="text-align: center;">Command R Refresh</td>
<td style="text-align: center;">98.9</td>
<td style="text-align: center;">99.6</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">92.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.0</td>
</tr>
<tr>
<td style="text-align: center;">Command R+ Refresh</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">96.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">97.5</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.0</td>
</tr>
<tr>
<td style="text-align: center;">GPT-3.5 Turbo</td>
<td style="text-align: center;">99.1</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">96.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">97.0</td>
</tr>
<tr>
<td style="text-align: center;">GPT-4 Turbo</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">96.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
</tr>
<tr>
<td style="text-align: center;">GPT-4o</td>
<td style="text-align: center;">98.9</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">94.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">97.5</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">98.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Cross-lingual</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">avg</td>
<td style="text-align: center;">ar</td>
<td style="text-align: center;">de</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">es</td>
<td style="text-align: center;">fr</td>
<td style="text-align: center;">hi</td>
<td style="text-align: center;">id</td>
<td style="text-align: center;">it</td>
<td style="text-align: center;">ja</td>
<td style="text-align: center;">ko</td>
<td style="text-align: center;">pt</td>
<td style="text-align: center;">ru</td>
<td style="text-align: center;">tr</td>
<td style="text-align: center;">vi</td>
<td style="text-align: center;">zh</td>
</tr>
<tr>
<td style="text-align: center;">Llama 2 70B-I</td>
<td style="text-align: center;">38.4</td>
<td style="text-align: center;">12.4</td>
<td style="text-align: center;">52.3</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">77.3</td>
<td style="text-align: center;">71.1</td>
<td style="text-align: center;">21.2</td>
<td style="text-align: center;">46.0</td>
<td style="text-align: center;">66.5</td>
<td style="text-align: center;">16.2</td>
<td style="text-align: center;">4.8</td>
<td style="text-align: center;">75.9</td>
<td style="text-align: center;">38.3</td>
<td style="text-align: center;">24.0</td>
<td style="text-align: center;">20.4</td>
<td style="text-align: center;">11.1</td>
</tr>
<tr>
<td style="text-align: center;">Llama 3 70B-I</td>
<td style="text-align: center;">30.3</td>
<td style="text-align: center;">31.1</td>
<td style="text-align: center;">34.7</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">61.1</td>
<td style="text-align: center;">53.1</td>
<td style="text-align: center;">46.4</td>
<td style="text-align: center;">25.4</td>
<td style="text-align: center;">36.4</td>
<td style="text-align: center;">1.4</td>
<td style="text-align: center;">0.8</td>
<td style="text-align: center;">54.4</td>
<td style="text-align: center;">38.4</td>
<td style="text-align: center;">17.4</td>
<td style="text-align: center;">18.7</td>
<td style="text-align: center;">4.3</td>
</tr>
<tr>
<td style="text-align: center;">Llama 3.1 70B-I</td>
<td style="text-align: center;">81.4</td>
<td style="text-align: center;">77.2</td>
<td style="text-align: center;">87.5</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">90.4</td>
<td style="text-align: center;">90.5</td>
<td style="text-align: center;">95.6</td>
<td style="text-align: center;">97.1</td>
<td style="text-align: center;">88.1</td>
<td style="text-align: center;">59.4</td>
<td style="text-align: center;">51.5</td>
<td style="text-align: center;">86.0</td>
<td style="text-align: center;">76.5</td>
<td style="text-align: center;">85.7</td>
<td style="text-align: center;">93.6</td>
<td style="text-align: center;">69.9</td>
</tr>
<tr>
<td style="text-align: center;">Mixtral 8x7B</td>
<td style="text-align: center;">69.0</td>
<td style="text-align: center;">59.1</td>
<td style="text-align: center;">76.4</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">79.1</td>
<td style="text-align: center;">79.0</td>
<td style="text-align: center;">39.2</td>
<td style="text-align: center;">72.8</td>
<td style="text-align: center;">85.0</td>
<td style="text-align: center;">57.9</td>
<td style="text-align: center;">56.9</td>
<td style="text-align: center;">79.4</td>
<td style="text-align: center;">72.4</td>
<td style="text-align: center;">76.0</td>
<td style="text-align: center;">75.8</td>
<td style="text-align: center;">57.5</td>
</tr>
<tr>
<td style="text-align: center;">Mistral Large</td>
<td style="text-align: center;">58.2</td>
<td style="text-align: center;">36.1</td>
<td style="text-align: center;">74.5</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">68.5</td>
<td style="text-align: center;">71.9</td>
<td style="text-align: center;">58.5</td>
<td style="text-align: center;">59.2</td>
<td style="text-align: center;">65.8</td>
<td style="text-align: center;">44.5</td>
<td style="text-align: center;">41.1</td>
<td style="text-align: center;">64.5</td>
<td style="text-align: center;">63.3</td>
<td style="text-align: center;">65.9</td>
<td style="text-align: center;">54.8</td>
<td style="text-align: center;">46.5</td>
</tr>
<tr>
<td style="text-align: center;">Command R</td>
<td style="text-align: center;">68.1</td>
<td style="text-align: center;">61.6</td>
<td style="text-align: center;">63.2</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">72.5</td>
<td style="text-align: center;">74.4</td>
<td style="text-align: center;">65.5</td>
<td style="text-align: center;">70.8</td>
<td style="text-align: center;">65.7</td>
<td style="text-align: center;">65.3</td>
<td style="text-align: center;">69.2</td>
<td style="text-align: center;">67.2</td>
<td style="text-align: center;">69.4</td>
<td style="text-align: center;">67.7</td>
<td style="text-align: center;">65.7</td>
<td style="text-align: center;">75.0</td>
</tr>
<tr>
<td style="text-align: center;">Command R+</td>
<td style="text-align: center;">91.2</td>
<td style="text-align: center;">93.4</td>
<td style="text-align: center;">91.6</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">91.7</td>
<td style="text-align: center;">91.5</td>
<td style="text-align: center;">90.2</td>
<td style="text-align: center;">85.9</td>
<td style="text-align: center;">93.8</td>
<td style="text-align: center;">93.8</td>
<td style="text-align: center;">91.1</td>
<td style="text-align: center;">88.5</td>
<td style="text-align: center;">93.0</td>
<td style="text-align: center;">92.0</td>
<td style="text-align: center;">91.1</td>
<td style="text-align: center;">89.5</td>
</tr>
<tr>
<td style="text-align: center;">Command R Refresh</td>
<td style="text-align: center;">93.1</td>
<td style="text-align: center;">91.9</td>
<td style="text-align: center;">96.1</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">96.4</td>
<td style="text-align: center;">94.0</td>
<td style="text-align: center;">95.0</td>
<td style="text-align: center;">85.1</td>
<td style="text-align: center;">93.8</td>
<td style="text-align: center;">95.0</td>
<td style="text-align: center;">93.8</td>
<td style="text-align: center;">94.0</td>
<td style="text-align: center;">92.2</td>
<td style="text-align: center;">93.4</td>
<td style="text-align: center;">94.1</td>
<td style="text-align: center;">88.9</td>
</tr>
<tr>
<td style="text-align: center;">Command R+ Refresh</td>
<td style="text-align: center;">95.4</td>
<td style="text-align: center;">95.4</td>
<td style="text-align: center;">97.5</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">97.6</td>
<td style="text-align: center;">97.2</td>
<td style="text-align: center;">98.2</td>
<td style="text-align: center;">88.9</td>
<td style="text-align: center;">96.2</td>
<td style="text-align: center;">95.1</td>
<td style="text-align: center;">95.9</td>
<td style="text-align: center;">91.7</td>
<td style="text-align: center;">96.4</td>
<td style="text-align: center;">97.9</td>
<td style="text-align: center;">97.9</td>
<td style="text-align: center;">90.2</td>
</tr>
<tr>
<td style="text-align: center;">GPT-3.5 Turbo</td>
<td style="text-align: center;">89.8</td>
<td style="text-align: center;">90.8</td>
<td style="text-align: center;">90.2</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">93.3</td>
<td style="text-align: center;">87.8</td>
<td style="text-align: center;">92.0</td>
<td style="text-align: center;">84.5</td>
<td style="text-align: center;">91.3</td>
<td style="text-align: center;">88.3</td>
<td style="text-align: center;">90.3</td>
<td style="text-align: center;">89.9</td>
<td style="text-align: center;">91.8</td>
<td style="text-align: center;">89.2</td>
<td style="text-align: center;">91.8</td>
<td style="text-align: center;">86.4</td>
</tr>
<tr>
<td style="text-align: center;">GPT-4 Turbo</td>
<td style="text-align: center;">90.3</td>
<td style="text-align: center;">88.9</td>
<td style="text-align: center;">93.0</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">93.1</td>
<td style="text-align: center;">90.7</td>
<td style="text-align: center;">91.0</td>
<td style="text-align: center;">87.3</td>
<td style="text-align: center;">91.8</td>
<td style="text-align: center;">87.7</td>
<td style="text-align: center;">89.7</td>
<td style="text-align: center;">91.0</td>
<td style="text-align: center;">90.0</td>
<td style="text-align: center;">91.4</td>
<td style="text-align: center;">90.0</td>
<td style="text-align: center;">87.9</td>
</tr>
<tr>
<td style="text-align: center;">GPT-4o</td>
<td style="text-align: center;">92.4</td>
<td style="text-align: center;">95.0</td>
<td style="text-align: center;">92.9</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">95.8</td>
<td style="text-align: center;">93.5</td>
<td style="text-align: center;">91.9</td>
<td style="text-align: center;">85.4</td>
<td style="text-align: center;">94.1</td>
<td style="text-align: center;">92.5</td>
<td style="text-align: center;">92.4</td>
<td style="text-align: center;">88.0</td>
<td style="text-align: center;">92.6</td>
<td style="text-align: center;">95.1</td>
<td style="text-align: center;">92.7</td>
<td style="text-align: center;">91.3</td>
</tr>
</tbody>
</table>
<p>Table 3: Line-level pass rate (LPR) on monolingual and cross-lingual generation, by language.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">Monolingual</th>
<th style="text-align: center;">Cross-lingual</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Llama 2 70B-I</td>
<td style="text-align: center;">97.9</td>
<td style="text-align: center;">84.2</td>
</tr>
<tr>
<td style="text-align: left;">Llama 3 70B-I</td>
<td style="text-align: center;">93.0</td>
<td style="text-align: center;">94.4</td>
</tr>
<tr>
<td style="text-align: left;">Llama 3.1 70B-I</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">95.0</td>
</tr>
<tr>
<td style="text-align: left;">Mixtral 8x7B</td>
<td style="text-align: center;">73.7</td>
<td style="text-align: center;">68.2</td>
</tr>
<tr>
<td style="text-align: left;">Mistral Large</td>
<td style="text-align: center;">98.4</td>
<td style="text-align: center;">93.8</td>
</tr>
<tr>
<td style="text-align: left;">Command R</td>
<td style="text-align: center;">96.3</td>
<td style="text-align: center;">94.0</td>
</tr>
<tr>
<td style="text-align: left;">Command R+</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">95.1</td>
</tr>
<tr>
<td style="text-align: left;">Command R Refresh</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">97.2</td>
</tr>
<tr>
<td style="text-align: left;">Command R+ Refresh</td>
<td style="text-align: center;">$\mathbf{9 9 . 8}$</td>
<td style="text-align: center;">96.5</td>
</tr>
<tr>
<td style="text-align: left;">GPT-3.5 Turbo</td>
<td style="text-align: center;">$\mathbf{9 9 . 8}$</td>
<td style="text-align: center;">$\mathbf{9 8 . 7}$</td>
</tr>
<tr>
<td style="text-align: left;">GPT-4 Turbo</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">96.6</td>
</tr>
<tr>
<td style="text-align: left;">GPT-4o</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">98.1</td>
</tr>
</tbody>
</table>
<p>Table 4: Average word-level pass rate (WPR) on nonLatin script languages. See Tables A3 and A4 for detailed WPR results on non-Latin and Latin script languages respectively.</p>
<p>100 tokens per prompt using nucleus sampling with $p=0.75$ and $T=0.3$.</p>
<p>LPR, WPR, and LCPR results are in Tables 3, 4, and A5, respectively. ${ }^{15}$ We show language confusion examples for different models in Table A6.</p>
<p>Monolingual generation Command and GPT models perform well on average on the line level (LPR in [98.6, 99.3]), but Llama 2 and 3 and Mistral models struggle to consistently generate text in the correct language (LPR in [48.3, 73.0]). Llama</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup>3.1 performs much better, however. Mistral Large is better on some European languages while Llama 2 and 3 exhibit language confusion even for highresource languages such as German. Most models have WPR within the same range and perform better on Latin script vs non-Latin script languages; however, Mixtral 8x7B is considerably worse. GPT4 Turbo is strongest on LCPR, with Command R+ Refresh and GPT-4o only slightly behind. Llama models' preference for English responses leads to very low LCPR.</p>
<p>Cross-lingual generation In the challenging cross-lingual setting, the best models have LPRs in the low 90s. The Command R and R+ Refresh models outperform their original versions, with Command R Refresh in particular showing a large improvement over Command R, which performs poorly cross-lingually. OpenAI and Command models perform best; Command R+ Refresh achieves the best performance overall. Llama 2 and 3 models perform poorly: both scoring in the 30s due to a tendency to respond in English. Llama 3.1 shows improved performance but still tends to generate in English for some languages. Mistral Large is worse than Mixtral, even in European languages. On LCPR, Command R+ Refresh performs best, followed by GPT-4o.</p>
<h2>4 Analyses</h2>
<h3>4.1 Impact of dataset</h3>
<p>In creating the language confusion test sets, we aimed to include prompts covering various use cases and domains. We show differences of LPR by dataset in Tables 5 and A7 for cross-lingual and monolingual generation, with WPR and LCPR in Tables A8 and A9 in §A.4. Differences between datasets are small for monolingual generation. Cross-lingually, the difference is more pronounced: models perform fairly well on Okapi and ShareGPT, but are much worse on our Complex prompts, indicating their more challenging nature.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">avg</th>
<th style="text-align: center;">Okapi</th>
<th style="text-align: center;">ShareGPT</th>
<th style="text-align: center;">Complex <br> (Ours)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Llama 2 70B-I</td>
<td style="text-align: center;">38.4</td>
<td style="text-align: center;">43.4</td>
<td style="text-align: center;">46.0</td>
<td style="text-align: center;">25.7</td>
</tr>
<tr>
<td style="text-align: left;">Llama 3 70B-I</td>
<td style="text-align: center;">30.3</td>
<td style="text-align: center;">35.0</td>
<td style="text-align: center;">39.5</td>
<td style="text-align: center;">16.3</td>
</tr>
<tr>
<td style="text-align: left;">Llama 3.1 70B-I</td>
<td style="text-align: center;">81.3</td>
<td style="text-align: center;">85.3</td>
<td style="text-align: center;">91.0</td>
<td style="text-align: center;">67.7</td>
</tr>
<tr>
<td style="text-align: left;">Mixtral 8x7B</td>
<td style="text-align: center;">69.0</td>
<td style="text-align: center;">77.4</td>
<td style="text-align: center;">79.8</td>
<td style="text-align: center;">49.9</td>
</tr>
<tr>
<td style="text-align: left;">Mistral Large</td>
<td style="text-align: center;">58.2</td>
<td style="text-align: center;">68.0</td>
<td style="text-align: center;">56.2</td>
<td style="text-align: center;">50.5</td>
</tr>
<tr>
<td style="text-align: left;">Command R</td>
<td style="text-align: center;">68.1</td>
<td style="text-align: center;">75.6</td>
<td style="text-align: center;">89.7</td>
<td style="text-align: center;">39.0</td>
</tr>
<tr>
<td style="text-align: left;">Command R+</td>
<td style="text-align: center;">91.2</td>
<td style="text-align: center;">96.1</td>
<td style="text-align: center;">98.7</td>
<td style="text-align: center;">78.9</td>
</tr>
<tr>
<td style="text-align: left;">Command R Refresh</td>
<td style="text-align: center;">93.1</td>
<td style="text-align: center;">$\mathbf{9 8 . 3}$</td>
<td style="text-align: center;">$\mathbf{9 9 . 4}$</td>
<td style="text-align: center;">81.7</td>
</tr>
<tr>
<td style="text-align: left;">Command R+ Refresh</td>
<td style="text-align: center;">$\mathbf{9 5 . 4}$</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">98.7</td>
<td style="text-align: center;">$\mathbf{8 9 . 6}$</td>
</tr>
<tr>
<td style="text-align: left;">GPT-3.5 Turbo</td>
<td style="text-align: center;">89.8</td>
<td style="text-align: center;">97.7</td>
<td style="text-align: center;">96.8</td>
<td style="text-align: center;">75.0</td>
</tr>
<tr>
<td style="text-align: left;">GPT-4 Turbo</td>
<td style="text-align: center;">90.3</td>
<td style="text-align: center;">96.6</td>
<td style="text-align: center;">96.4</td>
<td style="text-align: center;">77.7</td>
</tr>
<tr>
<td style="text-align: left;">GPT-4o</td>
<td style="text-align: center;">92.4</td>
<td style="text-align: center;">97.4</td>
<td style="text-align: center;">97.6</td>
<td style="text-align: center;">82.1</td>
</tr>
</tbody>
</table>
<p>Table 5: Line-level pass rate (LPR) by dataset on cross-lingual generation.</p>
<h3>4.2 Impact of prompt length</h3>
<p>We analyze whether the difficulty of our Complex prompts is caused by their much higher length (see Table 1) by grouping the prompts into three length buckets: short, medium and long, each with one third of the prompts. Table A10 shows the LPR of several models over the different lengths. We find no clear pattern, suggesting that higher confusion is caused by prompt complexity rather than length.</p>
<h3>4.3 Impact of instruction position</h3>
<p>Cross-lingual prompts include an instruction with the desired output language at the beginning, at the end, or integrated in the prompt (e.g., "Write an essay in Korean [...]"). Table A11 shows that across all models, line-level confusion is low for isolated instructions, with similar performance whether they are at the start or the end. Integrated instructions cause more confusion: Command R has only $69 \%$ LPR on this type of prompt, versus $\sim 85 \%$ for isolated types. This difficulty can be greatly reduced
with one-shot prompting ( $80.6 \%$ LPR; see §6.4). ${ }^{16}$</p>
<h3>4.4 Impact of quantization</h3>
<p>Quantization maps higher-precision LLM weights and activations to lower precision, reducing storage and inference costs, potentially at the cost of performance. We compare FP16 with W8, W8A8, and W4 variants of Command R+ on monolingual generation. Negative effects appear at W4, shown in Table A12. Details of quantization are in §A.6.</p>
<h3>4.5 Impact of instruction tuning</h3>
<p>We compare the base with instruction-tuned variants of Llama and Command models on monolingual generation in Table 6. While instruction-tuned Command R models exhibit less language confusion than their base versions, instruction-tuned Llama models are much more confused, indicating English-centric instruction tuning, which is confirmed by our mitigation experiments (see §6.4).</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">avg</th>
<th style="text-align: center;">ar</th>
<th style="text-align: center;">hi</th>
<th style="text-align: center;">ja</th>
<th style="text-align: center;">ko</th>
<th style="text-align: center;">vi</th>
<th style="text-align: center;">zh</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Llama 2 70B</td>
<td style="text-align: center;">$\mathbf{9 8 . 5}$</td>
<td style="text-align: center;">$\mathbf{9 9 . 6}$</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">$\mathbf{9 8 . 0}$</td>
<td style="text-align: center;">$\mathbf{9 3 . 2}$</td>
</tr>
<tr>
<td style="text-align: left;">Llama 2 70B-I</td>
<td style="text-align: center;">6.0</td>
<td style="text-align: center;">0.3</td>
<td style="text-align: center;">1.0</td>
<td style="text-align: center;">7.0</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">17.0</td>
<td style="text-align: center;">10.5</td>
</tr>
<tr>
<td style="text-align: left;">Llama 3 70B</td>
<td style="text-align: center;">$\mathbf{9 4 . 7}$</td>
<td style="text-align: center;">$\mathbf{9 6 . 7}$</td>
<td style="text-align: center;">$\mathbf{9 7 . 9}$</td>
<td style="text-align: center;">$\mathbf{8 7 . 9}$</td>
<td style="text-align: center;">$\mathbf{9 8 . 8}$</td>
<td style="text-align: center;">$\mathbf{9 7 . 0}$</td>
<td style="text-align: center;">$\mathbf{9 0 . 0}$</td>
</tr>
<tr>
<td style="text-align: left;">Llama 3 70B-I</td>
<td style="text-align: center;">12.1</td>
<td style="text-align: center;">21.7</td>
<td style="text-align: center;">23.0</td>
<td style="text-align: center;">10.0</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">10.0</td>
<td style="text-align: center;">8.0</td>
</tr>
<tr>
<td style="text-align: left;">Command R base</td>
<td style="text-align: center;">85.9</td>
<td style="text-align: center;">94.9</td>
<td style="text-align: center;">81.0</td>
<td style="text-align: center;">93.9</td>
<td style="text-align: center;">94.2</td>
<td style="text-align: center;">83.0</td>
<td style="text-align: center;">68.1</td>
</tr>
<tr>
<td style="text-align: left;">Command R</td>
<td style="text-align: center;">$\mathbf{9 9 . 6}$</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">$\mathbf{9 9 . 0}$</td>
<td style="text-align: center;">$\mathbf{9 8 . 5}$</td>
</tr>
<tr>
<td style="text-align: left;">Command R+ base</td>
<td style="text-align: center;">78.4</td>
<td style="text-align: center;">92.8</td>
<td style="text-align: center;">67.0</td>
<td style="text-align: center;">90.5</td>
<td style="text-align: center;">93.5</td>
<td style="text-align: center;">65.7</td>
<td style="text-align: center;">60.9</td>
</tr>
<tr>
<td style="text-align: left;">Command R+</td>
<td style="text-align: center;">$\mathbf{9 9 . 2}$</td>
<td style="text-align: center;">$\mathbf{9 9 . 7}$</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">$\mathbf{9 9 . 0}$</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">$\mathbf{9 9 . 0}$</td>
<td style="text-align: center;">$\mathbf{9 7 . 5}$</td>
</tr>
</tbody>
</table>
<p>Table 6: Line-level pass rate (LPR) of base vs instruction-tuned LLMs on monolingual generation for a subset of languages. Full results in Table A17, §A.8.</p>
<h2>5 When does language confusion occur?</h2>
<p>We study a sample of prompts to better understand where language confusion occurs. Intuitively, if a token in an undesired language is assigned sufficient probability, it may be sampled. We observe that language confusion typically occurs when the distribution over next tokens is flat and the nucleus is large (see §A. 10 for background).</p>
<p>We generate responses to 15 Chinese prompts from Okapi with Command R. ${ }^{17}$ We examine outputs to identify instances of English language confusion, finding it in 5 of 15 outputs. For each, we find the first position where an English token was</p>
<p><sup id="fnref6:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: A model is vulnerable to world-level language confusion when the number of tokens in the sampling nucleus is high, and the distribution is flat. Metrics: Shannon entropy; in brackets: # of tokens in nucleus.
elicited, which we call the confusion point (CP). ${ }^{18}$ There are 9 such CPs. ${ }^{19}$</p>
<p>We calculate Shannon entropy (Shannon, 1948) and nucleus size at each sampling point. We show an example output of Command R in Figure 2, indicating Shannon entropy and the number of tokens in the nucleus at select sampling points, and the next possible tokens with normalized probabilities at the confusion point. In the example, "called" was third most likely but occurred with sufficient probability to be sampled ( 0.221 ). We generate 100 tokens per prompt, so there are 1500 points: 9 of which are CPs. We refer to the others as $\neg$ CPs.</p>
<p>We average nucleus size and entropy over examples containing no instances of language confusion ( 10 samples, $1000 \neg$ CPs), at least one instance ( 5 examples, $9 \mathrm{CPs}, 491 \neg$ CPs), and overall ( 15 samples, $9 \mathrm{CPs}, 1491 \neg$ CPs). Results are in Table 7. ${ }^{20}$ Outputs with and without language confusion show similar average nucleus size and entropy ( 1.64 vs . 1.61, and 0.353 vs. 0.365 ). At CPs, however, average nucleus size and entropy is considerably higher: 3.56 nucleus size and 1.228 entropy vs 1.61/0.356 at $\neg$ CPs, indicating that confusion tends to occur when nucleus size and entropy are high.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">Avg. Nucleus Size</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Avg. Entropy</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">Overall</td>
<td style="text-align: center;">@CP</td>
<td style="text-align: center;">$\neg$ @CP</td>
<td style="text-align: center;">Overall</td>
<td style="text-align: center;">@CP</td>
<td style="text-align: center;">$\neg$ @CP</td>
</tr>
<tr>
<td style="text-align: left;">Has CP</td>
<td style="text-align: center;">1.64</td>
<td style="text-align: center;">3.56</td>
<td style="text-align: center;">1.61</td>
<td style="text-align: center;">0.353</td>
<td style="text-align: center;">1.228</td>
<td style="text-align: center;">0.337</td>
</tr>
<tr>
<td style="text-align: left;">No CP</td>
<td style="text-align: center;">1.61</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">1.61</td>
<td style="text-align: center;">0.365</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.365</td>
</tr>
<tr>
<td style="text-align: left;">All</td>
<td style="text-align: center;">1.62</td>
<td style="text-align: center;">3.56</td>
<td style="text-align: center;">1.61</td>
<td style="text-align: center;">0.361</td>
<td style="text-align: center;">1.228</td>
<td style="text-align: center;">0.356</td>
</tr>
</tbody>
</table>
<p>Table 7: Avg. nucleus size, entropy at confusion points (sampling points where language switch did [@CP] or did not [ $\neg$ @CP] occur) for 15 Chinese responses. Responses are split into those which had at least one CP ("Has CP") or zero CPs ("No CP").</p>
<p><sup id="fnref7:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h2>6 Mitigating Language Confusion</h2>
<p>Based on the insights from our analyses in $\S 4.5$ and $\S 5$, we propose inference-time and training-time mitigations for language confusion.</p>
<h3>6.1 Reducing temperature and nucleus size</h3>
<p>Modifying sampling hyper-parameters affects which tokens are chosen at inference time. Section A. 10 explains nucleus sampling with temperature, and Figure 3 has a toy example of manipulating the hyperparameter $T$. Framing language confusion as an undesired side-effect of sampling, it is intuitive that we might control it by sharpening the distribution over the next tokens at each timestep.</p>
<p>We try to reduce the chance of having a wronglanguage token sampled by manipulating temperature and nucleus size. Table 8 shows the results on monolingual WPR for Command R, with crosslingual and LPR results in Section A.7. Higher $T$ encourages language confusion: $T=1$ shows an average WPR of only $83.5 \%$, and as low as $72.0 \%$ and $69.5 \%$ for Japanese and Chinese. Increasing $p$, resulting in a smaller nucleus, has a smaller effect. Note that setting $T=0.0$ is equivalent to sampling with top- $\mathrm{K}=1$ (greedy search).</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">avg</th>
<th style="text-align: center;">ar</th>
<th style="text-align: center;">hi</th>
<th style="text-align: center;">ja</th>
<th style="text-align: center;">ko</th>
<th style="text-align: center;">ru</th>
<th style="text-align: center;">zh</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">T=0.0</td>
<td style="text-align: center;">$\mathbf{9 7 . 2}$</td>
<td style="text-align: center;">97.6</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">$\mathbf{9 6 . 9}$</td>
<td style="text-align: center;">97.0</td>
<td style="text-align: center;">$\mathbf{9 6 . 0}$</td>
<td style="text-align: center;">$\mathbf{9 5 . 9}$</td>
</tr>
<tr>
<td style="text-align: center;">T=0.3</td>
<td style="text-align: center;">96.3</td>
<td style="text-align: center;">$\mathbf{9 9 . 3}$</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">93.9</td>
<td style="text-align: center;">97.0</td>
<td style="text-align: center;">$\mathbf{9 6 . 0}$</td>
<td style="text-align: center;">92.3</td>
</tr>
<tr>
<td style="text-align: center;">T=0.5</td>
<td style="text-align: center;">96.4</td>
<td style="text-align: center;">97.9</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">94.9</td>
<td style="text-align: center;">$\mathbf{9 9 . 0}$</td>
<td style="text-align: center;">95.0</td>
<td style="text-align: center;">92.3</td>
</tr>
<tr>
<td style="text-align: center;">T=0.7</td>
<td style="text-align: center;">94.2</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">91.8</td>
<td style="text-align: center;">93.9</td>
<td style="text-align: center;">93.0</td>
<td style="text-align: center;">90.3</td>
</tr>
<tr>
<td style="text-align: center;">T=1.0</td>
<td style="text-align: center;">86.5</td>
<td style="text-align: center;">95.9</td>
<td style="text-align: center;">93.8</td>
<td style="text-align: center;">74.5</td>
<td style="text-align: center;">92.8</td>
<td style="text-align: center;">87.5</td>
<td style="text-align: center;">74.7</td>
</tr>
<tr>
<td style="text-align: center;">p=0.1</td>
<td style="text-align: center;">97.4</td>
<td style="text-align: center;">98.3</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">$\mathbf{9 7 . 0}$</td>
<td style="text-align: center;">95.0</td>
<td style="text-align: center;">95.9</td>
</tr>
<tr>
<td style="text-align: center;">p=0.3</td>
<td style="text-align: center;">97.3</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">$\mathbf{9 9 . 0}$</td>
<td style="text-align: center;">$\mathbf{9 7 . 0}$</td>
<td style="text-align: center;">94.0</td>
<td style="text-align: center;">95.9</td>
</tr>
<tr>
<td style="text-align: center;">p=0.5</td>
<td style="text-align: center;">$\mathbf{9 7 . 6}$</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">96.9</td>
<td style="text-align: center;">96.0</td>
<td style="text-align: center;">$\mathbf{9 8 . 0}$</td>
<td style="text-align: center;">$\mathbf{9 6 . 9}$</td>
</tr>
<tr>
<td style="text-align: center;">p=0.75</td>
<td style="text-align: center;">96.3</td>
<td style="text-align: center;">$\mathbf{9 9 . 3}$</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">93.9</td>
<td style="text-align: center;">$\mathbf{9 7 . 0}$</td>
<td style="text-align: center;">96.0</td>
<td style="text-align: center;">92.3</td>
</tr>
</tbody>
</table>
<p>Table 8: Effect of varying temperature ( $T$ ) or nucleus size $(p)$ on monolingual word-level language confusion (WPR) of Command $\boldsymbol{R}$. Default values are $p=0.75$ and $T=0.3$. Best score. Worst score.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Effect of Temperature $(T)$ in Nucleus Sampling. Tokens in the nucleus at $p=0.75$ are bold. Middle: Effect of $T$ on the softmax probabilities (Equation 1). Right: Effect of $T$ on the probabilities of tokens in the nucleus right before sampling (Equation A.10). As $T$ increases, the token 狐狸 has less chance to be sampled.</p>
<h3>6.2 Beam search decoding</h3>
<p>We explore the effect of beam search decoding on language confusion for Command R. Table 9 shows aggregate results for beam sizes 1 (greedy search) to 10, with full results in Section A.7. Increasing beam size helps moderately over greedy search on WPR, with little noticable effect on monolingual LPR. Increasing beam size consistently hurts crosslingual LPR and is most pronounced for non-IndoEuropean languages, where average LPR drops from 73.9 with greedy search to 65.6 with beam size $=10$.</p>
<table>
<thead>
<tr>
<th></th>
<th>Monoling. WPR</th>
<th>LPR</th>
<th>WPR</th>
<th>Crosslingual LPR</th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>Overall</td>
<td></td>
<td></td>
<td>$\sim I E$</td>
<td></td>
<td></td>
<td>$I E$</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>1</td>
<td>97.8</td>
<td>99.0</td>
<td>94.9</td>
<td>74.1</td>
<td>-</td>
<td>73.9</td>
<td>-</td>
<td>74.2</td>
<td>-</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>98.6</td>
<td>99.0</td>
<td>95.4</td>
<td>72.2</td>
<td>$(-1.9)$</td>
<td>71.1</td>
<td>$(-2.8)$</td>
<td>73.6</td>
<td>$(-0.6)$</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>3</td>
<td>98.6</td>
<td>98.7</td>
<td>97.1</td>
<td>71.5</td>
<td>$(-2.5)$</td>
<td>70.1</td>
<td>$(-3.8)$</td>
<td>73.4</td>
<td>$(-0.9)$</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>5</td>
<td>99.0</td>
<td>99.0</td>
<td>96.7</td>
<td>70.3</td>
<td>$(-3.8)$</td>
<td>68.3</td>
<td>$(-5.6)$</td>
<td>72.9</td>
<td>$(-1.4)$</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>10</td>
<td>99.0</td>
<td>98.5</td>
<td>96.7</td>
<td>68.4</td>
<td>$(-5.7)$</td>
<td>65.6</td>
<td>$(-8.3)$</td>
<td>72.1</td>
<td>$(-2.1)$</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Table 9: Effect of beam search decoding on language confusion metrics for Command $\boldsymbol{R}$. Beam sizes: 1-10.</p>
<p>Table 10 aggregates the best average score achieved for beam search and nucleus sampling from Tables 8, A13, A14, A15, A16. Beam search is always better than nucleus sampling for WPR and for cross-lingual LPR, and both methods seem equally effective for monolingual LPR, suggesting that beam search may be an effective decoding strategy for lessening language confusion (though at higher computational cost).</p>
<h3>6.3 Few-shot prompting</h3>
<p>Non-instruction-tuned LLMs often do not answer instructions as expected. When prompted with an instruction in a non-English language, for instance, Command R Base often translates it instead of answering. We thus employ few-shot prompting to</p>
<table>
<thead>
<tr>
<th></th>
<th>WPR</th>
<th></th>
<th></th>
<th></th>
<th>LPR</th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Beam S. <br> $\max$</td>
<td>Nuc. Samp. <br> min</td>
<td></td>
<td>Beam S. <br> $\max$</td>
<td>Nuc. Samp. <br> min</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Mono.</td>
<td>99.0</td>
<td>97.8</td>
<td>97.6</td>
<td>86.5</td>
<td>99.0</td>
<td>98.5</td>
<td>98.9</td>
<td>96.8</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Cross.</td>
<td>97.1</td>
<td>94.9</td>
<td>94.6</td>
<td>80.1</td>
<td>74.1</td>
<td>68.4</td>
<td>68.2</td>
<td>64.0</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Table 10: Beam Search vs. Nucleus Sampling. Shown: best and second-best overall average score. guide Command R Base towards the correct behavior. We cherry-pick 5 prompt/answer pairs in English and translate them with Google Translate. ${ }^{21}$</p>
<p>For cross-lingual generation, we use a similar format to the test sets. Figure A2 shows the template used to prompt the base model. For comparison, we also apply one-shot prompting to Command R where the example is presented as turns in a conversation. Table 11 shows the results. Tables A19 and A18 in Appendix show the detailed results per language for monolingual and crosslingual language confusion respectively.</p>
<p>Few-shot prompting greatly reduces Command R Base's language confusion and almost completely eliminates the problem in the monolingual setting. While one-shot prompting with Command R is detrimental monolingually-indicating a difficulty of dealing with demonstrations in other languages-it enables the model to better follow the cross-lingual instructions.</p>
<h3>6.4 Multilingual instruction tuning</h3>
<p>We additionally study the impact of English-centric and multilingual instruction tuning by fine-tuning Command R Base with several techniques:</p>
<p>English-only tuning We fine-tune the base model with English-only publicly available instruc-</p>
<p><sup id="fnref8:0"><a class="footnote-ref" href="#fn:0">1</a></sup> <sup id="fnref9:0"><a class="footnote-ref" href="#fn:0">1</a></sup>: ${ }^{21}$ Few-shot demonstrations are in different languages than the current task's target language. The goal is to help a model understand the task, not find the language to generate into.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: left;">Monolingual</th>
<th style="text-align: left;"></th>
<th style="text-align: center;">Cross-lingual</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">LPR</td>
<td style="text-align: left;">WPR</td>
<td style="text-align: center;">LPR</td>
<td style="text-align: center;">WPR</td>
</tr>
<tr>
<td style="text-align: left;">Command R Base</td>
<td style="text-align: left;">86.2</td>
<td style="text-align: left;">98.7</td>
<td style="text-align: center;">1.1</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
</tr>
<tr>
<td style="text-align: left;">+ Q/A template (0-shot)</td>
<td style="text-align: left;">85.3</td>
<td style="text-align: left;">99.7</td>
<td style="text-align: center;">20.9</td>
<td style="text-align: center;">97.0</td>
</tr>
<tr>
<td style="text-align: left;">+ 1-shot</td>
<td style="text-align: left;">94.1</td>
<td style="text-align: left;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">90.7</td>
<td style="text-align: center;">98.6</td>
</tr>
<tr>
<td style="text-align: left;">+ 5-shot</td>
<td style="text-align: left;">$\mathbf{9 9 . 0}$</td>
<td style="text-align: left;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">$\mathbf{9 5 . 0}$</td>
<td style="text-align: center;">99.7</td>
</tr>
<tr>
<td style="text-align: left;">+ English SFT</td>
<td style="text-align: left;">77.8</td>
<td style="text-align: left;">96.2</td>
<td style="text-align: center;">78.3</td>
<td style="text-align: center;">91.7</td>
</tr>
<tr>
<td style="text-align: left;">+ English pref. tuning</td>
<td style="text-align: left;">74.3</td>
<td style="text-align: left;">90.9</td>
<td style="text-align: center;">85.7</td>
<td style="text-align: center;">87.4</td>
</tr>
<tr>
<td style="text-align: left;">+ Multilingual SFT</td>
<td style="text-align: left;">98.3</td>
<td style="text-align: left;">95.5</td>
<td style="text-align: center;">78.2</td>
<td style="text-align: center;">90.0</td>
</tr>
<tr>
<td style="text-align: left;">+ Multi. pref. tuning</td>
<td style="text-align: left;">98.9</td>
<td style="text-align: left;">93.4</td>
<td style="text-align: center;">89.4</td>
<td style="text-align: center;">86.9</td>
</tr>
<tr>
<td style="text-align: left;">Command $R$</td>
<td style="text-align: left;">98.6</td>
<td style="text-align: left;">96.3</td>
<td style="text-align: center;">68.1</td>
<td style="text-align: center;">94.0</td>
</tr>
<tr>
<td style="text-align: left;">+ 1-shot</td>
<td style="text-align: left;">68.3</td>
<td style="text-align: left;">92.7</td>
<td style="text-align: center;">82.9</td>
<td style="text-align: center;">92.3</td>
</tr>
</tbody>
</table>
<p>Table 11: Effect of few-shot prompting and instruction tuning on language confusion.
tion data (SFT; Touvron et al., 2023), then apply English-only preference tuning to this model.</p>
<p>Multilingual tuning We extend the English data with multilingual data, most of which comes from machine-translated Dolly and ShareGPT (Üstün et al., 2024). Due to the scarcity of multilingual data, our SFT data mixture is $90 \%$ English. For preference tuning, we use $50 \%$ multilingual data. Results are in Table 11.</p>
<p>English-only tuning (both SFT and pref. tuning) exacerbates language confusion monolingually: likely the reason for high language confusion of Llama-Instruct models (see §4.5). English-only preference tuning has a strong negative impact on word-level confusion. However, SFT with just 10\% multilingual data is enough to almost eliminate the problem of line-level confusion monolingually. Cross-lingually, multilingual tuning does not give better line-level performance than English-only tuning. This may be because cross-lingual datasets only have English prompts and it is more important for the model to learn to follow English instructions (e.g., "Reply in French").</p>
<h2>7 Discussion</h2>
<p>We discuss several aspects that raise important questions including the behavior of base models, the English centricity of models, the impact of preference tuning, and the importance of other factors in Appendix A.11.</p>
<h2>8 Related Work</h2>
<p>Code-switching There has been much research on natural alternations between languages, i.e., code-switching (Doğruöz et al., 2021) in natural
language processing (NLP). Prior work focused on evaluating capabilities on standard NLP tasks using code-switching data (Khanuja et al., 2020; Winata et al., 2023) including sentiment analysis, machine translation, summarization and word-level language identification. These tasks typically employ data created by humans where word-level code-switching occurs between English and another language such as Hindi, Spanish, or Arabic. Current models still struggle to generate and understand code-switched text in some languages (Yong et al., 2023; Zhang et al., 2023). In contrast, we investigate unnatural and erroneous code-switchingor language confusion-in the LLM's generations.</p>
<p>Language confusion Prior work has observed 'source language hallucinations' in zero-shot crosslingual transfer (Vu et al., 2022; Li and Murray, 2023; Pfeiffer et al., 2023; Chirkova and Nikoulina, 2024) when models are fine-tuned on English data and applied to generate text in another language. The problem of language confusion is known in the machine translation field as 'off-target translation' (Chen et al., 2023; Sennrich et al., 2024). It typically occurs on English-centric multilingual models, when used in a zero-shot manner (to translate between two languages unseen at training). For LLMs, there is no source language per se. A few studies (Kew et al., 2023; Faisal and Anastasopoulos, 2023; Chen et al., 2024) have provided evidence of LLMs generating in an incorrect language on the response level. Holtermann et al. (2024) analyze which languages are confused on the response level using mainly smaller LLMs. To the best of our knowledge, we are the first to show results on the line and word level and the first to systematically study language confusion in LLMs.</p>
<h2>9 Conclusion</h2>
<p>We have introduced the Language Confusion Benchmark. We have shown that some LLMs exhibit severe language confusion and even the strongest LLMs do not achieve perfect performance cross-lingually. We observed that base and Englishcentric instruct models are particularly susceptible to language confusion, which is exacerbated by complex prompts. Finally, we proposed measures to mitigate language confusion at inference and training. Our benchmark is efficient to evaluate and easy to extend and can help ensure that models achieve equal utility across languages.</p>
<h2>Acknowledgements</h2>
<p>We thank Sander Land, Florian Strub, Mo Gheshlaghi Azar, and Olivier Pietquin for early discussions on language confusion. We are grateful to Sander Land for help with an initial version of a script to analyze nucleus sampling generations. We thank our internal annotators and the team at Cohere.</p>
<h2>Limitations</h2>
<p>As this is to our knowledge, the first systematic study on language confusion in LLMs, there are several natural research directions that we were not able to cover:</p>
<p>Conversations We focus on single-turn inputs, and do not consider the impact of multiple turns of a conversation or users employing different languages across different turns.</p>
<p>Code-switched input We focus on the setting where a user's prompt is in a single language (the target language in the monolingual setting and English in the cross-lingual setting). We do not consider inputs that are naturally code-switched.</p>
<p>Inputs with cross-lingual context Content may not always be available in a user's language, which is relevant for applications such as cross-lingual summarization or cross-lingual QA.</p>
<p>Language varieties We evaluate generation into standardized languages. Future work may expand to language varieties and dialects, styles, and registers.</p>
<p>Our metrics are applied to model outputs of at most 100 tokens. But what is a token depends on the model's tokenizer. Models with more aggressive tokenization could be advantaged with regard to the binary metrics (LPR and WPR). Likewise, because we allow models to stop their generation early (by producing an end-of-sequence token), models which are less verbose could have an advantage. Furthermore, because current LID tools do not support word-level language identification, our WPR metric is currently limited to assessing nonLatin script languages for unintended switching into English. As LID tools</p>
<h2>References</h2>
<p>Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman,</p>
<p>Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774.</p>
<p>Orevaoghene Ahia, Sachin Kumar, Hila Gonen, Jungo Kasai, David Mortensen, Noah Smith, and Yulia Tsvetkov. 2023. Do all languages cost the same? tokenization in the era of commercial language models. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 9904-9923, Singapore. Association for Computational Linguistics.</p>
<p>Akari Asai, Sneha Kudugunta, Xinyan Velocity Yu, Terra Blevins, Hila Gonen, Machel Reid, Yulia Tsvetkov, Sebastian Ruder, and Hannaneh Hajishirzi. 2023. Buffet: Benchmarking large language models for few-shot cross-lingual transfer. arXiv preprint arXiv:2305.14857.</p>
<p>Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, Quyet V. Do, Yan Xu, and Pascale Fung. 2023. A multitask, multilingual, multimodal evaluation of ChatGPT on reasoning, hallucination, and interactivity. In Proceedings of the 13th International Joint Conference on Natural Language Processing and the 3rd Conference of the AsiaPacific Chapter of the Association for Computational Linguistics (Volume 1: Long Papers), pages 675-718, Nusa Dua, Bali. Association for Computational Linguistics.</p>
<p>Terra Blevins and Luke Zettlemoyer. 2022. Language contamination helps explains the cross-lingual capabilities of English pretrained models. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 3563-3574, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.</p>
<p>Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33:1877-1901.</p>
<p>Liang Chen, Shuming Ma, Dongdong Zhang, Furu Wei, and Baobao Chang. 2023. On the off-target problem of zero-shot multilingual neural machine translation. In Findings of the Association for Computational Linguistics: ACL 2023, pages 9542-9558, Toronto, Canada. Association for Computational Linguistics.</p>
<p>Pinzhen Chen, Shaoxiong Ji, Nikolay Bogoychev, Andrey Kutuzov, Barry Haddow, and Kenneth Heafield. 2024. Monolingual or multilingual instruction tuning: Which makes a better alpaca. In Findings of the Association for Computational Linguistics: EACL 2024, pages 1347-1356, St. Julian's, Malta. Association for Computational Linguistics.</p>
<p>Nadezhda Chirkova and Vassilina Nikoulina. 2024. Key ingredients for effective zero-shot cross-lingual</p>
<p>knowledge transfer in generative tasks. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 7222-7238, Mexico City, Mexico. Association for Computational Linguistics.</p>
<p>Mike Conover, Matt Hayes, Ankit Mathur, Jianwei Xie, Jun Wan, Sam Shah, Ali Ghodsi, Patrick Wendell, Matei Zaharia, and Reynold Xin. 2023. Free dolly: Introducing the world's first truly open instructiontuned llm. Company Blog of Databricks.
A. Seza Doğruöz, Sunayana Sitaram, Barbara E. Bullock, and Almeida Jacqueline Toribio. 2021. A survey of code-switching: Linguistic and social perspectives for language technologies. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1654-1666, Online. Association for Computational Linguistics.</p>
<p>Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. 2024. The llama 3 herd of models. arXiv preprint arXiv:2407.21783.</p>
<p>Fahim Faisal and Antonios Anastasopoulos. 2023. Geographic and geopolitical biases of language models. In Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL), pages 139-163, Singapore. Association for Computational Linguistics.</p>
<p>Elias Frantar, Saleh Ashkboos, Torsten Hoefler, and Dan Alistarh. 2022. GPTQ: Accurate post-training compression for generative pretrained transformers. arXiv preprint arXiv:2210.17323.</p>
<p>Herbert P Grice. 1975. Logic and conversation. In Speech acts, pages 41-58. Brill.</p>
<p>Arnav Gudibande, Eric Wallace, Charlie Victor Snell, Xinyang Geng, Hao Liu, Pieter Abbeel, Sergey Levine, and Dawn Song. 2024. The false promise of imitating proprietary language models. In Proceedings of ICLR 2024.</p>
<p>Nuno M Guerreiro, Duarte M Alves, Jonas Waldendorf, Barry Haddow, Alexandra Birch, Pierre Colombo, and André FT Martins. 2023. Hallucinations in large multilingual translation models. Transactions of the Association for Computational Linguistics, 11:15001517 .</p>
<p>William Held, Camille Harris, Michael Best, and Diyi Yang. 2023. A material lens on coloniality in nlp. arXiv preprint arXiv:2311.08391.</p>
<p>Carolin Holtermann, Paul Röttger, Timm Dill, and Anne Lauscher. 2024. Evaluating the elementary multilingual capabilities of large language models with multiq. arXiv preprint arXiv:2403.03814.</p>
<p>Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. 2019. The curious case of neural text degeneration. In International Conference on Learning Representations.</p>
<p>Tom Hosking, Phil Blunsom, and Max Bartolo. 2024. Human feedback is not gold standard. In Proceedings of ICLR 2024.</p>
<p>Junjie Hu, Sebastian Ruder, Aditya Siddhant, Graham Neubig, Orhan Firat, and Melvin Johnson. 2020. Xtreme: A massively multilingual multi-task benchmark for evaluating cross-lingual generalisation. In International Conference on Machine Learning, pages 4411-4421. PMLR.</p>
<p>Ziwei Ji, Tiezheng Yu, Yan Xu, Nayeon Lee, Etsuko Ishii, and Pascale Fung. 2023. Towards mitigating llm hallucination via self reflection. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 1827-1843.</p>
<p>Albert Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand, et al. 2024. Mixtral of experts. arXiv preprint arXiv:2401.04088.</p>
<p>Pratik Joshi, Sebastin Santy, Amar Budhiraja, Kalika Bali, and Monojit Choudhury. 2020. The state and fate of linguistic diversity and inclusion in the NLP world. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 6282-6293, Online. Association for Computational Linguistics.</p>
<p>Armand Joulin, Edouard Grave, Piotr Bojanowski, and Tomas Mikolov. 2016. Bag of tricks for efficient text classification. arXiv preprint arXiv:1607.01759.</p>
<p>Jean Kaddour, Joshua Harris, Maximilian Mozes, Herbie Bradley, Roberta Raileanu, and Robert McHardy. 2023. Challenges and applications of large language models. arXiv preprint arXiv:2307.10169.</p>
<p>Kantar and IAMAI. 2023. Internet in India 2023. Technical report, Internet And Mobile Association of India.</p>
<p>Tannon Kew, Florian Schottmann, and Rico Sennrich. 2023. Turning english-centric llms into polyglots: How much multilinguality is needed? arXiv preprint arXiv:2312.12683.</p>
<p>Simran Khanuja, Sandipan Dandapat, Anirudh Srinivasan, Sunayana Sitaram, and Monojit Choudhury. 2020. GLUECoS: An evaluation benchmark for code-switched NLP. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 3575-3585, Online. Association for Computational Linguistics.</p>
<p>Viet Lai, Chien Nguyen, Nghia Ngo, Thuat Nguyen, Franck Dernoncourt, Ryan Rossi, and Thien Nguyen. 2023. Okapi: Instruction-tuned large language models in multiple languages with reinforcement learning</p>
<p>from human feedback. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 318-327, Singapore. Association for Computational Linguistics.</p>
<p>Tianjian Li and Kenton Murray. 2023. Why does zeroshot cross-lingual generation fail? an explanation and a solution. In Findings of the Association for Computational Linguistics: ACL 2023, pages 12461-12476, Toronto, Canada. Association for Computational Linguistics.</p>
<p>Jonas Pfeiffer, Francesco Piccinno, Massimo Nicosia, Xinyi Wang, Machel Reid, and Sebastian Ruder. 2023. mmT5: Modular multilingual pre-training solves source language hallucinations. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 1978-2008, Singapore. Association for Computational Linguistics.</p>
<p>Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher D Manning, Stefano Ermon, and Chelsea Finn. 2023. Direct preference optimization: Your language model is secretly a reward model. In Advances in Neural Information Processing Systems, volume 36, pages 53728-53741. Curran Associates, Inc.</p>
<p>Rico Sennrich, Jannis Vamvas, and Alireza Mohammadshahi. 2024. Mitigating hallucinations and offtarget machine translation with source-contrastive and language-contrastive decoding. In Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics (Volume 2: Short Papers), pages 21-33, St. Julian's, Malta. Association for Computational Linguistics.</p>
<p>Claude Elwood Shannon. 1948. A mathematical theory of communication. The Bell system technical journal, 27(3):379-423.</p>
<p>Shivalika Singh, Freddie Vargus, Daniel Dsouza, Börje F Karlsson, Abinaya Mahendiran, Wei-Yin Ko, Herumb Shandilya, Jay Patel, Deividas Mataciunas, Laura OMahony, et al. 2024. Aya dataset: An open-access collection for multilingual instruction tuning. arXiv preprint arXiv:2402.06619.</p>
<p>Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B Hashimoto. 2023. Alpaca: A strong, replicable instruction-following model. Stanford Center for Research on Foundation Models.</p>
<p>Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288.</p>
<p>Ahmet Üstün, Viraat Aryabumi, Zheng-Xin Yong, WeiYin Ko, Daniel D'souza, Gbemileke Onilude, Neel Bhandari, Shivalika Singh, Hui-Lee Ooi, Amr Kayid, et al. 2024. Aya model: An instruction finetuned open-access multilingual language model. arXiv preprint arXiv:2402.07827.</p>
<p>Tu Vu, Aditya Barua, Brian Lester, Daniel Cer, Mohit Iyyer, and Noah Constant. 2022. Overcoming catastrophic forgetting in zero-shot cross-lingual generation. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 9279-9300, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.</p>
<p>Deirdre Wilson and Dan Sperber. 2012. Linguistic form and relevance. Wilson \&amp; Sperber (Eds.), Meaning and Relevance, pages 149-168.</p>
<p>Genta Winata, Alham Fikri Aji, Zheng Xin Yong, and Thamar Solorio. 2023. The decades progress on codeswitching research in NLP: A systematic survey on trends and challenges. In Findings of the Association for Computational Linguistics: ACL 2023, pages 2936-2978, Toronto, Canada. Association for Computational Linguistics.</p>
<p>Shusheng Xu, Wei Fu, Jiaxuan Gao, Wenjie Ye, Weilin Liu, Zhiyu Mei, Guangju Wang, Chao Yu, and Yi Wu. 2024. Is dpo superior to ppo for llm alignment? a comprehensive study. Preprint, arXiv:2404.10719.</p>
<p>Yuzi Yan, Yibo Miao, Jialian Li, Yipin Zhang, Jian Xie, Zhijie Deng, and Dong Yan. 2024. 3d-properties: Identifying challenges in dpo and charting a path forward. Preprint, arXiv:2406.07327.</p>
<p>Zheng Xin Yong, Ruochen Zhang, Jessica Forde, Skyler Wang, Arjun Subramonian, Holy Lovenia, Samuel Cahyawijaya, Genta Winata, Lintang Sutawika, Jan Christian Blaise Cruz, Yin Lin Tan, Long Phan, Long Phan, Rowena Garcia, Thamar Solorio, and Alham Aji. 2023. Prompting multilingual large language models to generate code-mixed texts: The case of south East Asian languages. In Proceedings of the 6th Workshop on Computational Approaches to Linguistic Code-Switching, pages 43-63, Singapore. Association for Computational Linguistics.</p>
<p>Lifan Yuan, Ganqu Cui, Hanbin Wang, Ning Ding, Xingyao Wang, Jia Deng, Boji Shan, Huimin Chen, Ruobing Xie, Yankai Lin, Zhenghao Liu, Bowen Zhou, Hao Peng, Zhiyuan Liu, and Maosong Sun. 2024. Advancing llm reasoning generalists with preference trees. Preprint, arXiv:2404.02078.</p>
<p>Ruochen Zhang, Samuel Cahyawijaya, Jan Christian Blaise Cruz, Genta Winata, and Alham Aji. 2023. Multilingual large language models are not (yet) code-switchers. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pages 12567-12582, Singapore. Association for Computational Linguistics.</p>
<p>Jun Zhao, Zhihao Zhang, Qi Zhang, Tao Gui, and Xuanjing Huang. 2024. Llama beyond english: An empirical study on language capability transfer. arXiv preprint arXiv:2401.01055.</p>
<h1>A Appendix</h1>
<h2>A. 1 Extended Results</h2>
<p>Prompt: que partes tiene una noticia?
Completion: Una noticia típica suele tener las siguientes partes: ...
Prompt: y los epigrafes?
Completion: ... Los epígraf瓦解 también se pueden utilizar para resaltar citas importantes, proporcionar transiciones entre temas o simplemente dividir el texto en secciones más manejables y digeribles.</p>
<p>Figure A1: Example of non-English word-level language confusion produced by an LLM.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Monolingual</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">avg</td>
<td style="text-align: center;">ar</td>
<td style="text-align: center;">de</td>
<td style="text-align: center;">en</td>
<td style="text-align: center;">es</td>
<td style="text-align: center;">fr</td>
<td style="text-align: center;">hi</td>
<td style="text-align: center;">id</td>
<td style="text-align: center;">it</td>
<td style="text-align: center;">ja</td>
<td style="text-align: center;">ko</td>
<td style="text-align: center;">pt</td>
<td style="text-align: center;">ru</td>
<td style="text-align: center;">tr</td>
<td style="text-align: center;">vi</td>
<td style="text-align: center;">zh</td>
</tr>
<tr>
<td style="text-align: center;">Llama 2 70B-I</td>
<td style="text-align: center;">49.8</td>
<td style="text-align: center;">3.2</td>
<td style="text-align: center;">60.3</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">96.7</td>
<td style="text-align: center;">89.8</td>
<td style="text-align: center;">2.3</td>
<td style="text-align: center;">65.6</td>
<td style="text-align: center;">73.0</td>
<td style="text-align: center;">7.3</td>
<td style="text-align: center;">0.7</td>
<td style="text-align: center;">92.5</td>
<td style="text-align: center;">91.2</td>
<td style="text-align: center;">35.5</td>
<td style="text-align: center;">17.7</td>
<td style="text-align: center;">11.7</td>
</tr>
<tr>
<td style="text-align: center;">Llama 3 70B-I</td>
<td style="text-align: center;">47.3</td>
<td style="text-align: center;">27.7</td>
<td style="text-align: center;">31.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.8</td>
<td style="text-align: center;">89.1</td>
<td style="text-align: center;">25.4</td>
<td style="text-align: center;">21.5</td>
<td style="text-align: center;">88.9</td>
<td style="text-align: center;">11.2</td>
<td style="text-align: center;">2.3</td>
<td style="text-align: center;">97.8</td>
<td style="text-align: center;">77.0</td>
<td style="text-align: center;">19.6</td>
<td style="text-align: center;">10.4</td>
<td style="text-align: center;">9.4</td>
</tr>
<tr>
<td style="text-align: center;">Mixtral 8x7B</td>
<td style="text-align: center;">74.2</td>
<td style="text-align: center;">49.5</td>
<td style="text-align: center;">90.9</td>
<td style="text-align: center;">99.8</td>
<td style="text-align: center;">90.0</td>
<td style="text-align: center;">95.3</td>
<td style="text-align: center;">72.2</td>
<td style="text-align: center;">60.2</td>
<td style="text-align: center;">72.0</td>
<td style="text-align: center;">70.6</td>
<td style="text-align: center;">62.1</td>
<td style="text-align: center;">86.2</td>
<td style="text-align: center;">65.7</td>
<td style="text-align: center;">90.0</td>
<td style="text-align: center;">59.4</td>
<td style="text-align: center;">49.2</td>
</tr>
<tr>
<td style="text-align: center;">Mistral Large</td>
<td style="text-align: center;">70.3</td>
<td style="text-align: center;">48.7</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">99.6</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">19.5</td>
<td style="text-align: center;">31.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">48.0</td>
<td style="text-align: center;">64.3</td>
<td style="text-align: center;">80.9</td>
<td style="text-align: center;">98.7</td>
<td style="text-align: center;">71.5</td>
<td style="text-align: center;">29.0</td>
<td style="text-align: center;">67.0</td>
</tr>
<tr>
<td style="text-align: center;">Command R</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">99.9</td>
<td style="text-align: center;">98.7</td>
<td style="text-align: center;">99.9</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">96.8</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.9</td>
<td style="text-align: center;">99.6</td>
</tr>
<tr>
<td style="text-align: center;">Command R+</td>
<td style="text-align: center;">99.8</td>
<td style="text-align: center;">99.9</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.8</td>
<td style="text-align: center;">99.9</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.8</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">99.1</td>
</tr>
<tr>
<td style="text-align: center;">GPT-3.5 Turbo</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.8</td>
<td style="text-align: center;">99.8</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">98.3</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.7</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">98.3</td>
</tr>
<tr>
<td style="text-align: center;">GPT-4 Turbo</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">99.2</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.8</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.7</td>
</tr>
</tbody>
</table>
<p>Table A1: Line-level language ID accuracy of different LLMs on monolingual generation. Line accuracy is calculated by $\frac{# \text { lines responded in correct language }}{\text { Total # of lines generated }}$</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Cross-lingual</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">avg</td>
<td style="text-align: center;">ar</td>
<td style="text-align: center;">de</td>
<td style="text-align: center;">es</td>
<td style="text-align: center;">fr</td>
<td style="text-align: center;">hi</td>
<td style="text-align: center;">id</td>
<td style="text-align: center;">it</td>
<td style="text-align: center;">ja</td>
<td style="text-align: center;">ko</td>
<td style="text-align: center;">pt</td>
<td style="text-align: center;">ru</td>
<td style="text-align: center;">tr</td>
<td style="text-align: center;">vi</td>
<td style="text-align: center;">zh</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Llama 2 70B-I</td>
<td style="text-align: center;">46.0</td>
<td style="text-align: center;">23.5</td>
<td style="text-align: center;">58.3</td>
<td style="text-align: center;">80.5</td>
<td style="text-align: center;">74.6</td>
<td style="text-align: center;">31.4</td>
<td style="text-align: center;">51.1</td>
<td style="text-align: center;">73.4</td>
<td style="text-align: center;">26.9</td>
<td style="text-align: center;">15.9</td>
<td style="text-align: center;">79.9</td>
<td style="text-align: center;">47.0</td>
<td style="text-align: center;">28.1</td>
<td style="text-align: center;">30.0</td>
<td style="text-align: center;">23.3</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Llama 3 70B-I</td>
<td style="text-align: center;">53.4</td>
<td style="text-align: center;">60.3</td>
<td style="text-align: center;">65.8</td>
<td style="text-align: center;">77.4</td>
<td style="text-align: center;">73.8</td>
<td style="text-align: center;">69.7</td>
<td style="text-align: center;">58.2</td>
<td style="text-align: center;">65.5</td>
<td style="text-align: center;">6.2</td>
<td style="text-align: center;">2.8</td>
<td style="text-align: center;">75.8</td>
<td style="text-align: center;">65.2</td>
<td style="text-align: center;">55.2</td>
<td style="text-align: center;">61.4</td>
<td style="text-align: center;">10.4</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Mixtral 8x7B</td>
<td style="text-align: center;">72.7</td>
<td style="text-align: center;">61.5</td>
<td style="text-align: center;">79.7</td>
<td style="text-align: center;">82.5</td>
<td style="text-align: center;">82.5</td>
<td style="text-align: center;">41.7</td>
<td style="text-align: center;">78.9</td>
<td style="text-align: center;">85.9</td>
<td style="text-align: center;">64.1</td>
<td style="text-align: center;">61.3</td>
<td style="text-align: center;">83.0</td>
<td style="text-align: center;">75.2</td>
<td style="text-align: center;">78.1</td>
<td style="text-align: center;">79.4</td>
<td style="text-align: center;">64.6</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Mistral Large</td>
<td style="text-align: center;">65.7</td>
<td style="text-align: center;">45.4</td>
<td style="text-align: center;">79.8</td>
<td style="text-align: center;">74.9</td>
<td style="text-align: center;">76.7</td>
<td style="text-align: center;">63.3</td>
<td style="text-align: center;">68.6</td>
<td style="text-align: center;">73.5</td>
<td style="text-align: center;">58.2</td>
<td style="text-align: center;">51.9</td>
<td style="text-align: center;">72.4</td>
<td style="text-align: center;">68.7</td>
<td style="text-align: center;">69.5</td>
<td style="text-align: center;">61.4</td>
<td style="text-align: center;">56.1</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Command R</td>
<td style="text-align: center;">75.7</td>
<td style="text-align: center;">67.5</td>
<td style="text-align: center;">75.4</td>
<td style="text-align: center;">80.0</td>
<td style="text-align: center;">81.7</td>
<td style="text-align: center;">69.7</td>
<td style="text-align: center;">78.9</td>
<td style="text-align: center;">74.1</td>
<td style="text-align: center;">75.4</td>
<td style="text-align: center;">76.3</td>
<td style="text-align: center;">73.2</td>
<td style="text-align: center;">76.0</td>
<td style="text-align: center;">76.3</td>
<td style="text-align: center;">72.3</td>
<td style="text-align: center;">83.1</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Command R+</td>
<td style="text-align: center;">95.3</td>
<td style="text-align: center;">95.9</td>
<td style="text-align: center;">95.5</td>
<td style="text-align: center;">95.8</td>
<td style="text-align: center;">95.3</td>
<td style="text-align: center;">94.0</td>
<td style="text-align: center;">93.2</td>
<td style="text-align: center;">95.9</td>
<td style="text-align: center;">96.4</td>
<td style="text-align: center;">95.4</td>
<td style="text-align: center;">94.5</td>
<td style="text-align: center;">96.1</td>
<td style="text-align: center;">94.9</td>
<td style="text-align: center;">95.8</td>
<td style="text-align: center;">95.0</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">GPT-3.5 Turbo</td>
<td style="text-align: center;">91.5</td>
<td style="text-align: center;">91.5</td>
<td style="text-align: center;">91.5</td>
<td style="text-align: center;">94.9</td>
<td style="text-align: center;">90.9</td>
<td style="text-align: center;">92.2</td>
<td style="text-align: center;">88.0</td>
<td style="text-align: center;">92.7</td>
<td style="text-align: center;">89.7</td>
<td style="text-align: center;">91.3</td>
<td style="text-align: center;">93.9</td>
<td style="text-align: center;">92.6</td>
<td style="text-align: center;">90.5</td>
<td style="text-align: center;">92.5</td>
<td style="text-align: center;">89.4</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">GPT-4 Turbo</td>
<td style="text-align: center;">92.4</td>
<td style="text-align: center;">91.0</td>
<td style="text-align: center;">94.0</td>
<td style="text-align: center;">94.7</td>
<td style="text-align: center;">93.1</td>
<td style="text-align: center;">92.6</td>
<td style="text-align: center;">92.0</td>
<td style="text-align: center;">93.2</td>
<td style="text-align: center;">90.5</td>
<td style="text-align: center;">91.5</td>
<td style="text-align: center;">94.4</td>
<td style="text-align: center;">92.0</td>
<td style="text-align: center;">92.4</td>
<td style="text-align: center;">91.5</td>
<td style="text-align: center;">90.3</td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>Table A2: Line-level language ID accuracy of different LLMs on cross-lingual generation. Line accuracy is calculated by $\frac{# \text { lines responded in correct language }}{\text { Total # of lines generated }}$</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">Monolingual</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Cross-lingual</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Avg</td>
<td style="text-align: center;">ar</td>
<td style="text-align: center;">hi</td>
<td style="text-align: center;">ja</td>
<td style="text-align: center;">ko</td>
<td style="text-align: center;">ru</td>
<td style="text-align: center;">zh</td>
<td style="text-align: center;">Avg</td>
<td style="text-align: center;">ar</td>
<td style="text-align: center;">hi</td>
<td style="text-align: center;">ja</td>
<td style="text-align: center;">ko</td>
<td style="text-align: center;">ru</td>
<td style="text-align: center;">zh</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Llama 2 70B-I</td>
<td style="text-align: center;">97.9</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">93.2</td>
<td style="text-align: center;">94.4</td>
<td style="text-align: center;">84.2</td>
<td style="text-align: center;">91.4</td>
<td style="text-align: center;">85.3</td>
<td style="text-align: center;">84.4</td>
<td style="text-align: center;">86.7</td>
<td style="text-align: center;">81.5</td>
<td style="text-align: center;">75.9</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Llama 3 70B-I</td>
<td style="text-align: center;">93.0</td>
<td style="text-align: center;">95.6</td>
<td style="text-align: center;">95.7</td>
<td style="text-align: center;">80.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">93.5</td>
<td style="text-align: center;">93.3</td>
<td style="text-align: center;">94.4</td>
<td style="text-align: center;">95.7</td>
<td style="text-align: center;">97.7</td>
<td style="text-align: center;">91.7</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">89.1</td>
<td style="text-align: center;">92.3</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Llama 3.1 70B-I</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">95.0</td>
<td style="text-align: center;">95.7</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;">90.3</td>
<td style="text-align: center;">97.4</td>
<td style="text-align: center;">93.4</td>
<td style="text-align: center;">94.4</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Mixtral 8x7B</td>
<td style="text-align: center;">73.7</td>
<td style="text-align: center;">86.0</td>
<td style="text-align: center;">78.9</td>
<td style="text-align: center;">68.2</td>
<td style="text-align: center;">61.7</td>
<td style="text-align: center;">83.1</td>
<td style="text-align: center;">64.7</td>
<td style="text-align: center;">68.2</td>
<td style="text-align: center;">76.3</td>
<td style="text-align: center;">71.5</td>
<td style="text-align: center;">51.5</td>
<td style="text-align: center;">67.3</td>
<td style="text-align: center;">80.5</td>
<td style="text-align: center;">62.1</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Mistral Large</td>
<td style="text-align: center;">98.4</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">94.7</td>
<td style="text-align: center;">97.9</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">98.9</td>
<td style="text-align: center;">93.8</td>
<td style="text-align: center;">93.5</td>
<td style="text-align: center;">95.4</td>
<td style="text-align: center;">91.5</td>
<td style="text-align: center;">92.0</td>
<td style="text-align: center;">92.8</td>
<td style="text-align: center;">97.7</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Command R</td>
<td style="text-align: center;">96.3</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">93.9</td>
<td style="text-align: center;">97.0</td>
<td style="text-align: center;">96.0</td>
<td style="text-align: center;">92.3</td>
<td style="text-align: center;">94.0</td>
<td style="text-align: center;">94.3</td>
<td style="text-align: center;">98.6</td>
<td style="text-align: center;">88.5</td>
<td style="text-align: center;">97.2</td>
<td style="text-align: center;">94.0</td>
<td style="text-align: center;">91.1</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Command R+</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">95.1</td>
<td style="text-align: center;">97.9</td>
<td style="text-align: center;">96.0</td>
<td style="text-align: center;">95.5</td>
<td style="text-align: center;">96.1</td>
<td style="text-align: center;">89.7</td>
<td style="text-align: center;">95.6</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Command R Refresh</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">97.2</td>
<td style="text-align: center;">97.0</td>
<td style="text-align: center;">98.8</td>
<td style="text-align: center;">96.7</td>
<td style="text-align: center;">96.6</td>
<td style="text-align: center;">95.5</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Command R+ Refresh</td>
<td style="text-align: center;">99.8</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">96.5</td>
<td style="text-align: center;">97.3</td>
<td style="text-align: center;">97.8</td>
<td style="text-align: center;">96.6</td>
<td style="text-align: center;">96.9</td>
<td style="text-align: center;">94.5</td>
<td style="text-align: center;">95.7</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">GPT-3.5 Turbo</td>
<td style="text-align: center;">99.8</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.7</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.1</td>
<td style="text-align: center;">98.6</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;">98.3</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">GPT-4 Turbo</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">96.6</td>
<td style="text-align: center;">97.4</td>
<td style="text-align: center;">97.3</td>
<td style="text-align: center;">95.6</td>
<td style="text-align: center;">96.8</td>
<td style="text-align: center;">95.7</td>
<td style="text-align: center;">97.1</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">GPT-4o</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.1</td>
<td style="text-align: center;">99.2</td>
<td style="text-align: center;">97.0</td>
<td style="text-align: center;">97.5</td>
<td style="text-align: center;">99.1</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">97.6</td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>Table A3: Word-level pass rate (WPR) on monolingual and cross-lingual generation in non-Latin script languages (\% of responses containing no English words). Llama models are instruction-tuned variants.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">Monolingual</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Cross-lingual</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Avg</td>
<td style="text-align: center;">de</td>
<td style="text-align: center;">en</td>
<td style="text-align: center;">es</td>
<td style="text-align: center;">fr</td>
<td style="text-align: center;">id</td>
<td style="text-align: center;">it</td>
<td style="text-align: center;">pt</td>
<td style="text-align: center;">tr</td>
<td style="text-align: center;">vi</td>
<td style="text-align: center;">Avg</td>
<td style="text-align: center;">de</td>
<td style="text-align: center;">es</td>
<td style="text-align: center;">fr</td>
<td style="text-align: center;">id</td>
<td style="text-align: center;">it</td>
<td style="text-align: center;">pt</td>
</tr>
<tr>
<td style="text-align: center;">Llama 3 70B-I</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">90.9</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
</tr>
<tr>
<td style="text-align: center;">Llama 3.1 70B-I</td>
<td style="text-align: center;">99.6</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.9</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.1</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.2</td>
<td style="text-align: center;">99.6</td>
<td style="text-align: center;">99.1</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.6</td>
</tr>
<tr>
<td style="text-align: center;">Command R</td>
<td style="text-align: center;">99.2</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">96.9</td>
<td style="text-align: center;">96.0</td>
<td style="text-align: center;">97.9</td>
<td style="text-align: center;">98.9</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">96.4</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.5</td>
</tr>
<tr>
<td style="text-align: center;">Command R+</td>
<td style="text-align: center;">99.6</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">97.0</td>
<td style="text-align: center;">98.6</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.6</td>
<td style="text-align: center;">99.6</td>
<td style="text-align: center;">100.0</td>
</tr>
<tr>
<td style="text-align: center;">Command R Refresh</td>
<td style="text-align: center;">99.9</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.9</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
</tr>
<tr>
<td style="text-align: center;">Command R+ Refresh</td>
<td style="text-align: center;">99.9</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.9</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.1</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
</tr>
<tr>
<td style="text-align: center;">GPT-3.5 Turbo</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.9</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.9</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
</tr>
<tr>
<td style="text-align: center;">GPT-4o</td>
<td style="text-align: center;">99.8</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.9</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.1</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
</tr>
</tbody>
</table>
<p>Table A4: Word-level pass rate (WPR) on monolingual and cross-lingual generation in Latin script languages (\% of responses containing no characters that are outside the corresponding script's Unicode range). Llama models are instruction-tuned variants.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">Monolingual</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Cross-lingual</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Avg</td>
<td style="text-align: center;">ar</td>
<td style="text-align: center;">hi</td>
<td style="text-align: center;">ja</td>
<td style="text-align: center;">ko</td>
<td style="text-align: center;">ru</td>
<td style="text-align: center;">zh</td>
<td style="text-align: center;">Avg</td>
<td style="text-align: center;">ar</td>
<td style="text-align: center;">hi</td>
<td style="text-align: center;">ja</td>
<td style="text-align: center;">ko</td>
<td style="text-align: center;">ru</td>
<td style="text-align: center;">zh</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Llama 2 70B-I</td>
<td style="text-align: center;">20.9</td>
<td style="text-align: center;">0.7</td>
<td style="text-align: center;">2.0</td>
<td style="text-align: center;">13.1</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">91.0</td>
<td style="text-align: center;">18.9</td>
<td style="text-align: center;">27.2</td>
<td style="text-align: center;">21.8</td>
<td style="text-align: center;">33.9</td>
<td style="text-align: center;">27.2</td>
<td style="text-align: center;">9.0</td>
<td style="text-align: center;">52.1</td>
<td style="text-align: center;">19.3</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Llama 3 70B-I</td>
<td style="text-align: center;">31.6</td>
<td style="text-align: center;">35.3</td>
<td style="text-align: center;">37.1</td>
<td style="text-align: center;">17.8</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">84.5</td>
<td style="text-align: center;">14.7</td>
<td style="text-align: center;">29.3</td>
<td style="text-align: center;">46.9</td>
<td style="text-align: center;">62.9</td>
<td style="text-align: center;">2.7</td>
<td style="text-align: center;">1.5</td>
<td style="text-align: center;">53.7</td>
<td style="text-align: center;">8.3</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Llama 3.1 70B-I</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">97.9</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">81.0</td>
<td style="text-align: center;">85.5</td>
<td style="text-align: center;">97.0</td>
<td style="text-align: center;">71.7</td>
<td style="text-align: center;">67.4</td>
<td style="text-align: center;">84.1</td>
<td style="text-align: center;">80.3</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Mixtral 8x7B</td>
<td style="text-align: center;">65.3</td>
<td style="text-align: center;">61.9</td>
<td style="text-align: center;">74.7</td>
<td style="text-align: center;">67.4</td>
<td style="text-align: center;">61.4</td>
<td style="text-align: center;">72.9</td>
<td style="text-align: center;">53.4</td>
<td style="text-align: center;">61.6</td>
<td style="text-align: center;">66.6</td>
<td style="text-align: center;">50.6</td>
<td style="text-align: center;">54.5</td>
<td style="text-align: center;">61.7</td>
<td style="text-align: center;">76.2</td>
<td style="text-align: center;">59.7</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Mistral Large</td>
<td style="text-align: center;">69.4</td>
<td style="text-align: center;">64.9</td>
<td style="text-align: center;">31.7</td>
<td style="text-align: center;">64.4</td>
<td style="text-align: center;">78.0</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;">79.2</td>
<td style="text-align: center;">63.3</td>
<td style="text-align: center;">52.1</td>
<td style="text-align: center;">72.5</td>
<td style="text-align: center;">59.9</td>
<td style="text-align: center;">56.9</td>
<td style="text-align: center;">75.3</td>
<td style="text-align: center;">63.0</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Command R</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">96.9</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">95.3</td>
<td style="text-align: center;">78.6</td>
<td style="text-align: center;">74.5</td>
<td style="text-align: center;">78.7</td>
<td style="text-align: center;">75.1</td>
<td style="text-align: center;">80.9</td>
<td style="text-align: center;">79.9</td>
<td style="text-align: center;">82.3</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Command R+</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">98.7</td>
<td style="text-align: center;">93.4</td>
<td style="text-align: center;">95.6</td>
<td style="text-align: center;">93.0</td>
<td style="text-align: center;">94.6</td>
<td style="text-align: center;">93.5</td>
<td style="text-align: center;">91.3</td>
<td style="text-align: center;">92.5</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Command R Refresh</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">99.6</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;">94.9</td>
<td style="text-align: center;">94.4</td>
<td style="text-align: center;">96.9</td>
<td style="text-align: center;">95.8</td>
<td style="text-align: center;">95.2</td>
<td style="text-align: center;">93.8</td>
<td style="text-align: center;">93.5</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Command R+ Refresh</td>
<td style="text-align: center;">99.6</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">95.8</td>
<td style="text-align: center;">96.4</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">95.8</td>
<td style="text-align: center;">96.4</td>
<td style="text-align: center;">95.4</td>
<td style="text-align: center;">92.9</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">GPT-3.5 Turbo</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;">94.1</td>
<td style="text-align: center;">94.7</td>
<td style="text-align: center;">95.4</td>
<td style="text-align: center;">93.2</td>
<td style="text-align: center;">94.2</td>
<td style="text-align: center;">94.9</td>
<td style="text-align: center;">92.3</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">GPT-4 Turbo</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">92.8</td>
<td style="text-align: center;">93.0</td>
<td style="text-align: center;">94.1</td>
<td style="text-align: center;">91.5</td>
<td style="text-align: center;">93.1</td>
<td style="text-align: center;">92.8</td>
<td style="text-align: center;">92.3</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">GPT-4o</td>
<td style="text-align: center;">99.6</td>
<td style="text-align: center;">99.8</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.2</td>
<td style="text-align: center;">99.2</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">95.1</td>
<td style="text-align: center;">97.0</td>
<td style="text-align: center;">94.9</td>
<td style="text-align: center;">96.7</td>
<td style="text-align: center;">96.2</td>
<td style="text-align: center;">94.9</td>
<td style="text-align: center;">91.1</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>Table A5: Aggregate language confusion pass rate (LCPR) of LLMs on monolingual and cross-lingual tasks.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">models</th>
<th style="text-align: center;">prompt</th>
<th style="text-align: center;">generation</th>
<th style="text-align: center;">confusion type</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Llama 3 70B-I</td>
<td style="text-align: center;">ロイングエクサ サイズの果に ついてじる事 を1,000文字以内 でいてくだき い。</td>
<td style="text-align: center;"><strong>The Effects of Rowing Exercise: A Comprehensive Review</strong> \n\nRowing exercise has gained popularity in recent years due to its numerous benefits for physical and mental health. As a low-impact, full-body workout, rowing has been shown to improve cardiovascular fitness, increase muscle strength and endurance, and enhance overall well-being. In this article, we will discuss the effects of rowing exercise and explore its advantages for individuals of all fitness levels.\n\n<strong>Cardiovascular Benefits</strong> $\backslash \mathrm{n} \backslash$ nRowing is an excellent cardiovascular</td>
<td style="text-align: center;">Full response</td>
</tr>
<tr>
<td style="text-align: center;">Mixtral 8x7B</td>
<td style="text-align: center;">问题：油在生活中有哪些用途？</td>
<td style="text-align: center;">'油在我们的日常生活中有许多用途，主要包括： $\backslash \mathrm{n} \backslash \mathrm{n} 1$ 。 烹饪：油是烹饪中不可或缺的一种原料，它可以用来油炸、煎炸、烧烤等 verschiedenen Kochtechniken. Es kann auch als Salatöl oder Dressing verwendet werden.\n'</td>
<td style="text-align: center;">Line level</td>
</tr>
<tr>
<td style="text-align: center;">Command R</td>
<td style="text-align: center;">교실에서 시작하 는 디지털 시민 성 교육 에 관한 교육 자료를 초등 학교 수준으로 쉬 운 말투를 사용하 여 200 단 어 이내 로 작성해줘.</td>
<td style="text-align: center;">디지털 시민이란 인터넷과 디지털 기술로 연결된 세상에서 다른 사람들과 상호작용 하고, 소통하는 방법을 아는 사람을 말해. 디지털 세상에서 우리는 좋은 친구들이나 가족들처럼 행동해야 해. \n\n교실에서 디 지털 시민이 되는 법을 배워보아요! 우리 는 먼저 인터넷에서 주의해야 할 점을 알 아볼 거야. 디지털 세상에서 우리 would 안 전한 웹사이트만 방문하고, 우리 개인정보 를 소중히 지켜야 해.</td>
<td style="text-align: center;">Word level</td>
</tr>
</tbody>
</table>
<p>Table A6: Examples of different types of language confusion across models.</p>
<h1>A. 2 Annotator statistics</h1>
<p>Prompts were written by native-level speakers of the respective languages, each of whom is also fluent in English. Annotators were paid by the hour, with compensation above the federal minimum wage of the country of employment.</p>
<h2>A. 3 Cross-lingual prompt generation</h2>
<p>In order to generate prompts for the cross-lingual setting, we semi-automatically amend English prompts with an English instruction to generate text in the target language. For each English prompt and target language, we randomly choose an English instruction (e.g., "Respond in French", "Reply in Turkish"). To control for the position of the instruction in the prompt, for each prompt separate examples are created where an instruction is inserted at the beginning and at the end respectively. For each prompt, we additionally generate another example where an instruction is manually integrated into the prompt, e.g., "Generate an essay in Korean". The same process is applied to Okapi, ShareGPT, and our complex prompts. Table 2 shows representative examples where instructions are integrated in the middle, inserted at the beginning and at the end of the original prompts.</p>
<h1>A. 4 Dataset Language Confusion Metrics</h1>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">Avg</th>
<th style="text-align: center;">Okapi</th>
<th style="text-align: center;">Aya</th>
<th style="text-align: center;">Dolly</th>
<th style="text-align: center;">Native (Ours)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Llama 2 70B-I</td>
<td style="text-align: center;">54.0</td>
<td style="text-align: center;">57.2</td>
<td style="text-align: center;">49.6</td>
<td style="text-align: center;">55.2</td>
<td style="text-align: center;">49.0</td>
</tr>
<tr>
<td style="text-align: left;">Llama 3 70B-I</td>
<td style="text-align: center;">56.2</td>
<td style="text-align: center;">56.0</td>
<td style="text-align: center;">50.8</td>
<td style="text-align: center;">61.8</td>
<td style="text-align: center;">47.0</td>
</tr>
<tr>
<td style="text-align: left;">Llama 3.1 70B-I</td>
<td style="text-align: center;">$\mathbf{9 9 . 7}$</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">99.5</td>
</tr>
<tr>
<td style="text-align: left;">Mixtral 8x7B</td>
<td style="text-align: center;">74.9</td>
<td style="text-align: center;">70.7</td>
<td style="text-align: center;">78.3</td>
<td style="text-align: center;">75.8</td>
<td style="text-align: center;">78.2</td>
</tr>
<tr>
<td style="text-align: left;">Mistral Large</td>
<td style="text-align: center;">75.6</td>
<td style="text-align: center;">68.4</td>
<td style="text-align: center;">82.0</td>
<td style="text-align: center;">76.4</td>
<td style="text-align: center;">77.8</td>
</tr>
<tr>
<td style="text-align: left;">Command R</td>
<td style="text-align: center;">98.7</td>
<td style="text-align: center;">97.8</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">98.8</td>
</tr>
<tr>
<td style="text-align: left;">Command R+</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.8</td>
<td style="text-align: center;">99.2</td>
</tr>
<tr>
<td style="text-align: left;">Command R Refresh</td>
<td style="text-align: center;">99.2</td>
<td style="text-align: center;">98.4</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">99.5</td>
</tr>
<tr>
<td style="text-align: left;">Command R+ Refresh</td>
<td style="text-align: center;">99.2</td>
<td style="text-align: center;">99.2</td>
<td style="text-align: center;">98.6</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">$\mathbf{9 9 . 8}$</td>
</tr>
<tr>
<td style="text-align: left;">GPT-3.5 Turbo</td>
<td style="text-align: center;">99.1</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">98.6</td>
<td style="text-align: center;">99.8</td>
<td style="text-align: center;">99.5</td>
</tr>
<tr>
<td style="text-align: left;">GPT-4 Turbo</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">98.9</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">99.8</td>
<td style="text-align: center;">99.2</td>
</tr>
<tr>
<td style="text-align: left;">GPT-4o</td>
<td style="text-align: center;">99.1</td>
<td style="text-align: center;">98.8</td>
<td style="text-align: center;">98.8</td>
<td style="text-align: center;">99.2</td>
<td style="text-align: center;">99.5</td>
</tr>
</tbody>
</table>
<p>Table A7: Line-level pass rate (LPR) by dataset on monolingual generation.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">Monolingual</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Cross-lingual</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">Avg</td>
<td style="text-align: center;">Okapi</td>
<td style="text-align: center;">Aya</td>
<td style="text-align: center;">Dolly</td>
<td style="text-align: center;">Native (Ours)</td>
<td style="text-align: center;">Avg</td>
<td style="text-align: center;">Okapi</td>
<td style="text-align: center;">ShareGPT Complex (Ours)</td>
</tr>
<tr>
<td style="text-align: left;">Llama 2 70B-I</td>
<td style="text-align: center;">97.4</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">94.4</td>
<td style="text-align: center;">97.7</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">84.2</td>
<td style="text-align: center;">90.0</td>
<td style="text-align: center;">78.9</td>
</tr>
<tr>
<td style="text-align: left;">Llama 3 70B-I</td>
<td style="text-align: center;">95.1</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">93.3</td>
<td style="text-align: center;">91.9</td>
<td style="text-align: center;">90.0</td>
<td style="text-align: center;">94.4</td>
<td style="text-align: center;">98.9</td>
<td style="text-align: center;">87.9</td>
</tr>
<tr>
<td style="text-align: left;">Llama 3.1 70B-I</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">95.0</td>
<td style="text-align: center;">97.7</td>
<td style="text-align: center;">93.3</td>
</tr>
<tr>
<td style="text-align: left;">Mixtral 8x7B</td>
<td style="text-align: center;">78.0</td>
<td style="text-align: center;">77.9</td>
<td style="text-align: center;">74.8</td>
<td style="text-align: center;">81.3</td>
<td style="text-align: center;">64.9</td>
<td style="text-align: center;">68.2</td>
<td style="text-align: center;">75.8</td>
<td style="text-align: center;">68.0</td>
</tr>
<tr>
<td style="text-align: left;">Mistral Large</td>
<td style="text-align: center;">98.9</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">98.9</td>
<td style="text-align: center;">97.9</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">93.8</td>
<td style="text-align: center;">98.7</td>
<td style="text-align: center;">95.4</td>
</tr>
<tr>
<td style="text-align: left;">Command R</td>
<td style="text-align: center;">96.5</td>
<td style="text-align: center;">97.4</td>
<td style="text-align: center;">93.8</td>
<td style="text-align: center;">98.3</td>
<td style="text-align: center;">95.5</td>
<td style="text-align: center;">94.0</td>
<td style="text-align: center;">95.3</td>
<td style="text-align: center;">93.7</td>
</tr>
<tr>
<td style="text-align: left;">Command R+</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">95.1</td>
<td style="text-align: center;">97.4</td>
<td style="text-align: center;">97.6</td>
</tr>
<tr>
<td style="text-align: left;">Command R Refresh</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">98.8</td>
<td style="text-align: center;">99.6</td>
<td style="text-align: center;">99.6</td>
</tr>
<tr>
<td style="text-align: left;">Command R+ Refresh</td>
<td style="text-align: center;">99.6</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">98.3</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">99.1</td>
</tr>
<tr>
<td style="text-align: left;">GPT-3.5 Turbo</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">98.7</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">$\mathbf{9 9 . 8}$</td>
</tr>
<tr>
<td style="text-align: left;">GPT-4 Turbo</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">96.6</td>
<td style="text-align: center;">99.8</td>
<td style="text-align: center;">99.5</td>
</tr>
<tr>
<td style="text-align: left;">GPT-4o</td>
<td style="text-align: center;">99.8</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">$\mathbf{9 9 . 0}$</td>
<td style="text-align: center;">$\mathbf{1 0 0 . 0}$</td>
<td style="text-align: center;">99.6</td>
</tr>
</tbody>
</table>
<p>Table A8: WPR by dataset for monolingual and cross-lingual generation.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">Monolingual</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Cross-lingual</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">Avg</td>
<td style="text-align: center;">Okapi</td>
<td style="text-align: center;">Aya</td>
<td style="text-align: center;">Dolly</td>
<td style="text-align: center;">Native (Ours)</td>
<td style="text-align: center;">Avg</td>
<td style="text-align: center;">Okapi</td>
<td style="text-align: center;">ShareGPT Complex (Ours)</td>
</tr>
<tr>
<td style="text-align: left;">Llama 2 70B-I</td>
<td style="text-align: center;">69.4</td>
<td style="text-align: center;">72.8</td>
<td style="text-align: center;">65.0</td>
<td style="text-align: center;">70.5</td>
<td style="text-align: center;">65.8</td>
<td style="text-align: center;">52.0</td>
<td style="text-align: center;">58.6</td>
<td style="text-align: center;">58.1</td>
</tr>
<tr>
<td style="text-align: left;">Llama 3 70B-I</td>
<td style="text-align: center;">70.5</td>
<td style="text-align: center;">71.8</td>
<td style="text-align: center;">65.8</td>
<td style="text-align: center;">73.9</td>
<td style="text-align: center;">61.8</td>
<td style="text-align: center;">44.7</td>
<td style="text-align: center;">51.7</td>
<td style="text-align: center;">54.5</td>
</tr>
<tr>
<td style="text-align: left;">Llama 3.1 70B-I</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">87.3</td>
<td style="text-align: center;">91.1</td>
<td style="text-align: center;">92.1</td>
</tr>
<tr>
<td style="text-align: left;">Mixtral 8x7B</td>
<td style="text-align: center;">76.4</td>
<td style="text-align: center;">74.1</td>
<td style="text-align: center;">76.5</td>
<td style="text-align: center;">78.5</td>
<td style="text-align: center;">71.0</td>
<td style="text-align: center;">68.3</td>
<td style="text-align: center;">76.6</td>
<td style="text-align: center;">73.4</td>
</tr>
<tr>
<td style="text-align: left;">Mistral Large</td>
<td style="text-align: center;">85.6</td>
<td style="text-align: center;">81.2</td>
<td style="text-align: center;">89.7</td>
<td style="text-align: center;">85.8</td>
<td style="text-align: center;">87.1</td>
<td style="text-align: center;">71.7</td>
<td style="text-align: center;">80.5</td>
<td style="text-align: center;">70.8</td>
</tr>
<tr>
<td style="text-align: left;">Command R</td>
<td style="text-align: center;">97.6</td>
<td style="text-align: center;">97.6</td>
<td style="text-align: center;">96.5</td>
<td style="text-align: center;">98.7</td>
<td style="text-align: center;">97.1</td>
<td style="text-align: center;">76.9</td>
<td style="text-align: center;">84.3</td>
<td style="text-align: center;">91.6</td>
</tr>
<tr>
<td style="text-align: left;">Command R+</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">$\mathbf{9 9 . 5}$</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">93.0</td>
<td style="text-align: center;">96.7</td>
<td style="text-align: center;">98.2</td>
</tr>
<tr>
<td style="text-align: left;">Command R Refresh</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">99.2</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">95.7</td>
<td style="text-align: center;">$\mathbf{9 8 . 9}$</td>
<td style="text-align: center;">$\mathbf{9 9 . 5}$</td>
</tr>
<tr>
<td style="text-align: left;">Command R+ Refresh</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">$\mathbf{9 9 . 6}$</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.2</td>
<td style="text-align: center;">$\mathbf{9 9 . 9}$</td>
<td style="text-align: center;">$\mathbf{9 6 . 8}$</td>
<td style="text-align: center;">98.6</td>
<td style="text-align: center;">98.9</td>
</tr>
<tr>
<td style="text-align: left;">GPT-3.5 Turbo</td>
<td style="text-align: center;">$\mathbf{9 9 . 6}$</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">$\mathbf{9 9 . 9}$</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">93.8</td>
<td style="text-align: center;">98.8</td>
<td style="text-align: center;">98.3</td>
</tr>
<tr>
<td style="text-align: left;">GPT-4 Turbo</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">99.2</td>
<td style="text-align: center;">$\mathbf{9 9 . 9}$</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">93.3</td>
<td style="text-align: center;">98.2</td>
<td style="text-align: center;">97.9</td>
</tr>
<tr>
<td style="text-align: left;">GPT-4o</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">99.6</td>
<td style="text-align: center;">95.5</td>
<td style="text-align: center;">98.7</td>
<td style="text-align: center;">98.6</td>
</tr>
</tbody>
</table>
<p>Table A9: LCPR by dataset for monolingual and cross-lingual generation.</p>
<h2>A. 5 Extended Impacts</h2>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">Short <br> $[21,65]$</th>
<th style="text-align: center;">Medium <br> $[68,224]$</th>
<th style="text-align: center;">Long <br> $[227,2971]$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Command R</td>
<td style="text-align: center;">42.7</td>
<td style="text-align: center;">28.1</td>
<td style="text-align: center;">38.0</td>
</tr>
<tr>
<td style="text-align: left;">+ one-shot</td>
<td style="text-align: center;">59.5</td>
<td style="text-align: center;">49.1</td>
<td style="text-align: center;">67.7</td>
</tr>
<tr>
<td style="text-align: left;">Command R+</td>
<td style="text-align: center;">82.1</td>
<td style="text-align: center;">74.8</td>
<td style="text-align: center;">79.8</td>
</tr>
<tr>
<td style="text-align: left;">GPT-4</td>
<td style="text-align: center;">89.3</td>
<td style="text-align: center;">72.9</td>
<td style="text-align: center;">71.8</td>
</tr>
</tbody>
</table>
<p>Table A10: Line-level pass rate (LPR) on our "Complex prompts" dataset for cross-lingual generation, depending on length of the prompts. We sort the prompts by length and split them into 3 length buckets of the same size (each containing one third of the prompts). [a, b]: min and max length in words of each bucket's prompts.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">Start</th>
<th style="text-align: center;">Integrated</th>
<th style="text-align: center;">End</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Command R</td>
<td style="text-align: center;">86.7</td>
<td style="text-align: center;">69.0</td>
<td style="text-align: center;">85.1</td>
</tr>
<tr>
<td style="text-align: left;">+ one-shot</td>
<td style="text-align: center;">88.7</td>
<td style="text-align: center;">80.6</td>
<td style="text-align: center;">90.6</td>
</tr>
<tr>
<td style="text-align: left;">Command R+</td>
<td style="text-align: center;">94.4</td>
<td style="text-align: center;">90.3</td>
<td style="text-align: center;">95.2</td>
</tr>
<tr>
<td style="text-align: left;">GPT-4</td>
<td style="text-align: center;">93.0</td>
<td style="text-align: center;">91.7</td>
<td style="text-align: center;">95.0</td>
</tr>
</tbody>
</table>
<p>Table A11: Line-level pass rate (LPR) on crosslingual generation depending on the position of the language control instruction. "Integrated" corresponds to instructions of the form "Write an essay of 100 words in Korean about artificial intelligence." "Start" and "End" are isolated instructions of the form "Reply in French." placed either at the start or at the end of the prompt.</p>
<h2>A. 6 Quantization</h2>
<p>It is common to train at half-precision floatingpoint (FP16), where weights and activations of a network use 16 bits ( 2 bytes) to represent a floatingpoint value. It is common to quantize weights to INT8 (8-bit integers), often referred to as W8. More extreme quantization of weights to INT4 (4-bit) is called W4. Quantizing both weights and activations to INT8 is commonly called W8A8. In Section 4.4, we compare FP16 with W8, W8A8, and W4 ${ }^{22}$ variants of Command R+ on monolingual generation.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">Line-level Pass Rate (LPR)</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">avg</td>
<td style="text-align: center;">ar</td>
<td style="text-align: center;">hi</td>
<td style="text-align: center;">ja</td>
<td style="text-align: center;">ko</td>
<td style="text-align: center;">ru</td>
<td style="text-align: center;">zh</td>
<td style="text-align: center;">id</td>
</tr>
<tr>
<td style="text-align: center;">FP16</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">97.5</td>
<td style="text-align: center;">97.0</td>
</tr>
<tr>
<td style="text-align: center;">W8</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">97.0</td>
</tr>
<tr>
<td style="text-align: center;">W8A8</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;">98.0</td>
</tr>
<tr>
<td style="text-align: center;">W4-g</td>
<td style="text-align: center;">98.8</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;">91.0</td>
</tr>
<tr>
<td style="text-align: center;">Word-level Pass Rate (WPR)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">FP16</td>
<td style="text-align: center;">98.2</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">95.0</td>
<td style="text-align: center;">96.0</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">W8</td>
<td style="text-align: center;">98.3</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">96.0</td>
<td style="text-align: center;">96.5</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">W8A8</td>
<td style="text-align: center;">98.7</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">97.0</td>
<td style="text-align: center;">97.0</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">W4-g</td>
<td style="text-align: center;">98.1</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">93.9</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;">-</td>
</tr>
</tbody>
</table>
<p>Table A12: Effect of quantization on LPR and WPR on monolingual generation.</p>
<p><sup id="fnref10:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>A. 7 Extended Beam Search and Nucleus Sampling Results</h1>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">avg</th>
<th style="text-align: center;">ar</th>
<th style="text-align: center;">hi</th>
<th style="text-align: center;">ja</th>
<th style="text-align: center;">ko</th>
<th style="text-align: center;">ru</th>
<th style="text-align: center;">zh</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">$\mathrm{~T}=0.0$</td>
<td style="text-align: center;">93.3</td>
<td style="text-align: center;">$\mathbf{9 8 . 9}$</td>
<td style="text-align: center;">94.6</td>
<td style="text-align: center;">86.4</td>
<td style="text-align: center;">96.7</td>
<td style="text-align: center;">93.0</td>
<td style="text-align: center;">90.0</td>
</tr>
<tr>
<td style="text-align: left;">$\mathrm{~T}=0.3$</td>
<td style="text-align: center;">94.0</td>
<td style="text-align: center;">94.3</td>
<td style="text-align: center;">$\mathbf{9 8 . 6}$</td>
<td style="text-align: center;">88.5</td>
<td style="text-align: center;">$\mathbf{9 7 . 2}$</td>
<td style="text-align: center;">94.0</td>
<td style="text-align: center;">91.1</td>
</tr>
<tr>
<td style="text-align: left;">$\mathrm{~T}=0.5$</td>
<td style="text-align: center;">94.2</td>
<td style="text-align: center;">$\mathbf{9 8 . 9}$</td>
<td style="text-align: center;">96.1</td>
<td style="text-align: center;">87.1</td>
<td style="text-align: center;">95.2</td>
<td style="text-align: center;">$\mathbf{9 5 . 5}$</td>
<td style="text-align: center;">$\mathbf{9 2 . 3}$</td>
</tr>
<tr>
<td style="text-align: left;">$\mathrm{~T}=0.7$</td>
<td style="text-align: center;">$\mathbf{9 4 . 6}$</td>
<td style="text-align: center;">97.9</td>
<td style="text-align: center;">99.1</td>
<td style="text-align: center;">$\mathbf{9 0 . 8}$</td>
<td style="text-align: center;">95.7</td>
<td style="text-align: center;">94.6</td>
<td style="text-align: center;">89.6</td>
</tr>
<tr>
<td style="text-align: left;">$\mathrm{~T}=1.0$</td>
<td style="text-align: center;">80.1</td>
<td style="text-align: center;">93.5</td>
<td style="text-align: center;">88.6</td>
<td style="text-align: center;">70.5</td>
<td style="text-align: center;">85.5</td>
<td style="text-align: center;">71.0</td>
<td style="text-align: center;">71.2</td>
</tr>
<tr>
<td style="text-align: left;">$\mathrm{p}=0.1$</td>
<td style="text-align: center;">93.6</td>
<td style="text-align: center;">97.4</td>
<td style="text-align: center;">96.6</td>
<td style="text-align: center;">$\mathbf{8 9 . 0}$</td>
<td style="text-align: center;">97.5</td>
<td style="text-align: center;">93.3</td>
<td style="text-align: center;">87.6</td>
</tr>
<tr>
<td style="text-align: left;">$\mathrm{p}=0.3$</td>
<td style="text-align: center;">$\mathbf{9 4 . 0}$</td>
<td style="text-align: center;">$\mathbf{9 8 . 0}$</td>
<td style="text-align: center;">97.6</td>
<td style="text-align: center;">85.7</td>
<td style="text-align: center;">98.4</td>
<td style="text-align: center;">92.0</td>
<td style="text-align: center;">$\mathbf{9 2 . 3}$</td>
</tr>
<tr>
<td style="text-align: left;">$\mathrm{p}=0.5$</td>
<td style="text-align: center;">$\mathbf{9 4 . 0}$</td>
<td style="text-align: center;">95.0</td>
<td style="text-align: center;">97.3</td>
<td style="text-align: center;">$\mathbf{8 9 . 0}$</td>
<td style="text-align: center;">$\mathbf{9 8 . 8}$</td>
<td style="text-align: center;">93.8</td>
<td style="text-align: center;">90.1</td>
</tr>
<tr>
<td style="text-align: left;">$\mathrm{p}=0.75$</td>
<td style="text-align: center;">$\mathbf{9 4 . 0}$</td>
<td style="text-align: center;">94.3</td>
<td style="text-align: center;">$\mathbf{9 8 . 6}$</td>
<td style="text-align: center;">88.5</td>
<td style="text-align: center;">97.2</td>
<td style="text-align: center;">$\mathbf{9 4 . 0}$</td>
<td style="text-align: center;">91.1</td>
</tr>
</tbody>
</table>
<p>Table A13: Effect of varying temperature $(T)$ or nucleus size $(p)$ on cross-lingual word-level language confusion (WPR) of Command $\boldsymbol{R}$. Default values are $p=0.75$ and $T=0.3$. Best score is in bold.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Monolingual</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">avg</td>
<td style="text-align: center;">ar</td>
<td style="text-align: center;">hi</td>
<td style="text-align: center;">ja</td>
<td style="text-align: center;">ko</td>
<td style="text-align: center;">ru</td>
<td style="text-align: center;">zh</td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">97.8</td>
<td style="text-align: center;">98.6</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">97.0</td>
<td style="text-align: center;">97.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">96.4</td>
</tr>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: center;">98.6</td>
<td style="text-align: center;">98.2</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">97.4</td>
</tr>
<tr>
<td style="text-align: center;">3</td>
<td style="text-align: center;">98.6</td>
<td style="text-align: center;">98.9</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">96.9</td>
</tr>
<tr>
<td style="text-align: center;">5</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">97.4</td>
</tr>
<tr>
<td style="text-align: center;">10</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.4</td>
</tr>
<tr>
<td style="text-align: center;">Cross-lingual</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">avg</td>
<td style="text-align: center;">ar</td>
<td style="text-align: center;">hi</td>
<td style="text-align: center;">ja</td>
<td style="text-align: center;">ko</td>
<td style="text-align: center;">ru</td>
<td style="text-align: center;">zh</td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">94.9</td>
<td style="text-align: center;">98.9</td>
<td style="text-align: center;">97.2</td>
<td style="text-align: center;">89.4</td>
<td style="text-align: center;">97.5</td>
<td style="text-align: center;">95.8</td>
<td style="text-align: center;">90.4</td>
</tr>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: center;">95.4</td>
<td style="text-align: center;">99.2</td>
<td style="text-align: center;">97.1</td>
<td style="text-align: center;">91.1</td>
<td style="text-align: center;">95.7</td>
<td style="text-align: center;">97.2</td>
<td style="text-align: center;">92.4</td>
</tr>
<tr>
<td style="text-align: center;">3</td>
<td style="text-align: center;">97.1</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">97.9</td>
<td style="text-align: center;">95.7</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">96.4</td>
<td style="text-align: center;">94.5</td>
</tr>
<tr>
<td style="text-align: center;">5</td>
<td style="text-align: center;">96.7</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">98.3</td>
<td style="text-align: center;">95.1</td>
<td style="text-align: center;">96.4</td>
<td style="text-align: center;">96.2</td>
<td style="text-align: center;">94.7</td>
</tr>
<tr>
<td style="text-align: center;">10</td>
<td style="text-align: center;">96.7</td>
<td style="text-align: center;">98.3</td>
<td style="text-align: center;">98.3</td>
<td style="text-align: center;">96.7</td>
<td style="text-align: center;">98.4</td>
<td style="text-align: center;">94.5</td>
<td style="text-align: center;">93.7</td>
</tr>
</tbody>
</table>
<p>Table A14: Monolingual and Cross-lingual word-level pass rate (WPR) of Command $R$ using beam search with beam sizes 1-10. $(\neg) I E=$ (non-) Indo-European language. $(\neg)$ Latin $=$ (non-) Latin script.</p>
<p>Monolingual</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">avg</th>
<th style="text-align: center;">ar</th>
<th style="text-align: center;">de</th>
<th style="text-align: center;">en</th>
<th style="text-align: center;">es</th>
<th style="text-align: center;">fr</th>
<th style="text-align: center;">hi</th>
<th style="text-align: center;">id</th>
<th style="text-align: center;">it</th>
<th style="text-align: center;">ja</th>
<th style="text-align: center;">ko</th>
<th style="text-align: center;">pt</th>
<th style="text-align: center;">ru</th>
<th style="text-align: center;">tr</th>
<th style="text-align: center;">vi</th>
<th style="text-align: center;">zh</th>
<th style="text-align: center;">$\neg$ IE</th>
<th style="text-align: center;">IE</th>
<th style="text-align: center;">$\neg$ Latin</th>
<th style="text-align: center;">Latin</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">T=0.0</td>
<td style="text-align: center;">98.8</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">96.7</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">96.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.1</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">98.3</td>
</tr>
<tr>
<td style="text-align: center;">T=0.3</td>
<td style="text-align: center;">98.6</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">95.7</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">92.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;">98.6</td>
<td style="text-align: center;">98.6</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">97.8</td>
</tr>
<tr>
<td style="text-align: center;">T=0.5</td>
<td style="text-align: center;">98.7</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">96.3</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">94.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;">98.7</td>
<td style="text-align: center;">98.6</td>
<td style="text-align: center;">99.6</td>
<td style="text-align: center;">98.1</td>
</tr>
<tr>
<td style="text-align: center;">T=0.7</td>
<td style="text-align: center;">98.9</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">95.7</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">98.6</td>
</tr>
<tr>
<td style="text-align: center;">T=1.0</td>
<td style="text-align: center;">96.8</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">96.0</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">95.0</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">91.9</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">97.0</td>
<td style="text-align: center;">97.0</td>
<td style="text-align: center;">92.9</td>
<td style="text-align: center;">93.0</td>
<td style="text-align: center;">97.5</td>
<td style="text-align: center;">96.2</td>
<td style="text-align: center;">97.6</td>
<td style="text-align: center;">98.2</td>
<td style="text-align: center;">95.9</td>
</tr>
<tr>
<td style="text-align: center;">$\mathrm{p}=0.1$</td>
<td style="text-align: center;">98.9</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">96.7</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">96.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.2</td>
<td style="text-align: center;">98.6</td>
<td style="text-align: center;">99.8</td>
<td style="text-align: center;">98.3</td>
</tr>
<tr>
<td style="text-align: center;">$\mathrm{p}=0.3$</td>
<td style="text-align: center;">98.9</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">96.3</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">96.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.1</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">98.3</td>
</tr>
<tr>
<td style="text-align: center;">$\mathrm{p}=0.5$</td>
<td style="text-align: center;">98.8</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">96.3</td>
<td style="text-align: center;">98.7</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">96.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;">99.1</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;">99.6</td>
<td style="text-align: center;">98.3</td>
</tr>
<tr>
<td style="text-align: center;">$\mathrm{p}=0.75$</td>
<td style="text-align: center;">98.6</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">95.7</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">92.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;">98.6</td>
<td style="text-align: center;">98.6</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">97.8</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Cross-lingual</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">avg</td>
<td style="text-align: center;">ar</td>
<td style="text-align: center;">de</td>
<td style="text-align: center;">en</td>
<td style="text-align: center;">es</td>
<td style="text-align: center;">fr</td>
<td style="text-align: center;">hi</td>
<td style="text-align: center;">id</td>
<td style="text-align: center;">it</td>
<td style="text-align: center;">ja</td>
<td style="text-align: center;">ko</td>
<td style="text-align: center;">pt</td>
<td style="text-align: center;">ru</td>
<td style="text-align: center;">tr</td>
<td style="text-align: center;">vi</td>
<td style="text-align: center;">zh</td>
<td style="text-align: center;">$\neg$ IE</td>
<td style="text-align: center;">IE</td>
<td style="text-align: center;">$\neg$ Latin</td>
<td style="text-align: center;">Latin</td>
</tr>
<tr>
<td style="text-align: center;">T=0.0</td>
<td style="text-align: center;">68.1</td>
<td style="text-align: center;">61.7</td>
<td style="text-align: center;">61.9</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">70.7</td>
<td style="text-align: center;">74.6</td>
<td style="text-align: center;">65.2</td>
<td style="text-align: center;">70.4</td>
<td style="text-align: center;">65.9</td>
<td style="text-align: center;">68.1</td>
<td style="text-align: center;">70.8</td>
<td style="text-align: center;">68.8</td>
<td style="text-align: center;">68.8</td>
<td style="text-align: center;">65.6</td>
<td style="text-align: center;">65.7</td>
<td style="text-align: center;">74.8</td>
<td style="text-align: center;">68.2</td>
<td style="text-align: center;">67.8</td>
<td style="text-align: center;">68.2</td>
<td style="text-align: center;">67.9</td>
</tr>
<tr>
<td style="text-align: center;">T=0.3</td>
<td style="text-align: center;">68.1</td>
<td style="text-align: center;">61.6</td>
<td style="text-align: center;">63.2</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">72.5</td>
<td style="text-align: center;">74.4</td>
<td style="text-align: center;">65.5</td>
<td style="text-align: center;">70.8</td>
<td style="text-align: center;">65.7</td>
<td style="text-align: center;">65.3</td>
<td style="text-align: center;">69.2</td>
<td style="text-align: center;">67.2</td>
<td style="text-align: center;">69.4</td>
<td style="text-align: center;">67.7</td>
<td style="text-align: center;">65.7</td>
<td style="text-align: center;">75.0</td>
<td style="text-align: center;">68.1</td>
<td style="text-align: center;">68.1</td>
<td style="text-align: center;">67.7</td>
<td style="text-align: center;">68.4</td>
</tr>
<tr>
<td style="text-align: center;">T=0.5</td>
<td style="text-align: center;">67.9</td>
<td style="text-align: center;">60.7</td>
<td style="text-align: center;">62.5</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">72.1</td>
<td style="text-align: center;">74.3</td>
<td style="text-align: center;">64.3</td>
<td style="text-align: center;">69.6</td>
<td style="text-align: center;">66.2</td>
<td style="text-align: center;">67.1</td>
<td style="text-align: center;">70.2</td>
<td style="text-align: center;">67.8</td>
<td style="text-align: center;">67.1</td>
<td style="text-align: center;">67.0</td>
<td style="text-align: center;">65.6</td>
<td style="text-align: center;">76.2</td>
<td style="text-align: center;">67.9</td>
<td style="text-align: center;">67.9</td>
<td style="text-align: center;">67.6</td>
<td style="text-align: center;">68.1</td>
</tr>
<tr>
<td style="text-align: center;">T=0.7</td>
<td style="text-align: center;">67.9</td>
<td style="text-align: center;">60.7</td>
<td style="text-align: center;">63.2</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">72.1</td>
<td style="text-align: center;">74.3</td>
<td style="text-align: center;">65.6</td>
<td style="text-align: center;">68.8</td>
<td style="text-align: center;">66.2</td>
<td style="text-align: center;">68.1</td>
<td style="text-align: center;">69.7</td>
<td style="text-align: center;">68.4</td>
<td style="text-align: center;">68.4</td>
<td style="text-align: center;">64.4</td>
<td style="text-align: center;">65.7</td>
<td style="text-align: center;">75.5</td>
<td style="text-align: center;">67.7</td>
<td style="text-align: center;">68.3</td>
<td style="text-align: center;">68.0</td>
<td style="text-align: center;">67.9</td>
</tr>
<tr>
<td style="text-align: center;">T=1.0</td>
<td style="text-align: center;">64.0</td>
<td style="text-align: center;">63.3</td>
<td style="text-align: center;">63.0</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">70.6</td>
<td style="text-align: center;">72.4</td>
<td style="text-align: center;">63.3</td>
<td style="text-align: center;">63.9</td>
<td style="text-align: center;">62.0</td>
<td style="text-align: center;">65.4</td>
<td style="text-align: center;">65.2</td>
<td style="text-align: center;">66.1</td>
<td style="text-align: center;">62.7</td>
<td style="text-align: center;">57.1</td>
<td style="text-align: center;">51.7</td>
<td style="text-align: center;">69.8</td>
<td style="text-align: center;">62.4</td>
<td style="text-align: center;">66.2</td>
<td style="text-align: center;">64.9</td>
<td style="text-align: center;">63.3</td>
</tr>
<tr>
<td style="text-align: center;">$\mathrm{p}=0.1$</td>
<td style="text-align: center;">68.0</td>
<td style="text-align: center;">61.3</td>
<td style="text-align: center;">62.5</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">71.1</td>
<td style="text-align: center;">75.0</td>
<td style="text-align: center;">65.1</td>
<td style="text-align: center;">70.1</td>
<td style="text-align: center;">66.9</td>
<td style="text-align: center;">67.8</td>
<td style="text-align: center;">70.2</td>
<td style="text-align: center;">68.4</td>
<td style="text-align: center;">68.3</td>
<td style="text-align: center;">65.9</td>
<td style="text-align: center;">65.7</td>
<td style="text-align: center;">74.2</td>
<td style="text-align: center;">67.9</td>
<td style="text-align: center;">68.2</td>
<td style="text-align: center;">67.8</td>
<td style="text-align: center;">68.2</td>
</tr>
<tr>
<td style="text-align: center;">$\mathrm{p}=0.3$</td>
<td style="text-align: center;">68.1</td>
<td style="text-align: center;">61.3</td>
<td style="text-align: center;">62.5</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">70.7</td>
<td style="text-align: center;">74.6</td>
<td style="text-align: center;">65.4</td>
<td style="text-align: center;">69.7</td>
<td style="text-align: center;">66.6</td>
<td style="text-align: center;">67.7</td>
<td style="text-align: center;">69.8</td>
<td style="text-align: center;">68.1</td>
<td style="text-align: center;">68.4</td>
<td style="text-align: center;">67.2</td>
<td style="text-align: center;">65.7</td>
<td style="text-align: center;">75.2</td>
<td style="text-align: center;">68.1</td>
<td style="text-align: center;">68.0</td>
<td style="text-align: center;">68.0</td>
<td style="text-align: center;">68.1</td>
</tr>
<tr>
<td style="text-align: center;">$\mathrm{p}=0.5$</td>
<td style="text-align: center;">68.2</td>
<td style="text-align: center;">61.1</td>
<td style="text-align: center;">62.9</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">71.4</td>
<td style="text-align: center;">75.3</td>
<td style="text-align: center;">65.1</td>
<td style="text-align: center;">69.2</td>
<td style="text-align: center;">66.6</td>
<td style="text-align: center;">68.1</td>
<td style="text-align: center;">70.1</td>
<td style="text-align: center;">68.8</td>
<td style="text-align: center;">69.5</td>
<td style="text-align: center;">66.8</td>
<td style="text-align: center;">65.9</td>
<td style="text-align: center;">74.5</td>
<td style="text-align: center;">68.2</td>
<td style="text-align: center;">68.3</td>
<td style="text-align: center;">68.1</td>
<td style="text-align: center;">68.4</td>
</tr>
<tr>
<td style="text-align: center;">$\mathrm{p}=0.75$</td>
<td style="text-align: center;">68.1</td>
<td style="text-align: center;">61.6</td>
<td style="text-align: center;">63.2</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">72.5</td>
<td style="text-align: center;">74.4</td>
<td style="text-align: center;">65.5</td>
<td style="text-align: center;">70.8</td>
<td style="text-align: center;">65.7</td>
<td style="text-align: center;">65.3</td>
<td style="text-align: center;">69.2</td>
<td style="text-align: center;">67.2</td>
<td style="text-align: center;">69.4</td>
<td style="text-align: center;">67.7</td>
<td style="text-align: center;">65.7</td>
<td style="text-align: center;">75.0</td>
<td style="text-align: center;">68.1</td>
<td style="text-align: center;">68.1</td>
<td style="text-align: center;">67.7</td>
<td style="text-align: center;">68.4</td>
</tr>
</tbody>
</table>
<p>Table A15: Effect of varying temperature ( $T$ ) or nucleus size ( $p$ ) on monolingual and crossingual line-level language confusion (LPR) of Command $\boldsymbol{R}$. Default values are $p=0.75$ and $T=0.3$. Best score. $(\neg)$ IE $=$ (non-) Indo-European language. $(\neg)$ Latin $=$ (non-) Latin script.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Monolingual</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">avg</td>
<td style="text-align: center;">ar</td>
<td style="text-align: center;">de</td>
<td style="text-align: center;">en</td>
<td style="text-align: center;">es</td>
<td style="text-align: center;">fr</td>
<td style="text-align: center;">hi</td>
<td style="text-align: center;">id</td>
<td style="text-align: center;">it</td>
<td style="text-align: center;">ja</td>
<td style="text-align: center;">ko</td>
<td style="text-align: center;">pt</td>
<td style="text-align: center;">ru</td>
<td style="text-align: center;">tr</td>
<td style="text-align: center;">vi</td>
<td style="text-align: center;">zh</td>
<td style="text-align: center;">$\neg$ IE</td>
<td style="text-align: center;">IE</td>
<td style="text-align: center;">$\neg$ Latin</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Latin</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">96.0</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">97.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">97.9</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.2</td>
<td style="text-align: center;">98.8</td>
<td style="text-align: center;">99.8</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.6</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">95.6</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">96.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.9</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.2</td>
<td style="text-align: center;">98.7</td>
<td style="text-align: center;">99.8</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">98.4</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">3</td>
<td style="text-align: center;">98.7</td>
<td style="text-align: center;">99.6</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">95.7</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">96.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.9</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">98.9</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">98.3</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">5</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">96.0</td>
<td style="text-align: center;">99.7</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">96.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.9</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;">99.1</td>
<td style="text-align: center;">98.9</td>
<td style="text-align: center;">99.6</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">98.6</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">10</td>
<td style="text-align: center;">98.5</td>
<td style="text-align: center;">98.9</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">99.5</td>
<td style="text-align: center;">95.7</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">96.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">98.0</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">97.8</td>
<td style="text-align: center;">99.0</td>
<td style="text-align: center;">96.9</td>
<td style="text-align: center;">98.4</td>
<td style="text-align: center;">98.6</td>
<td style="text-align: center;">99.1</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">98.1</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Cross-lingual</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">avg</td>
<td style="text-align: center;">ar</td>
<td style="text-align: center;">de</td>
<td style="text-align: center;">en</td>
<td style="text-align: center;">es</td>
<td style="text-align: center;">fr</td>
<td style="text-align: center;">hi</td>
<td style="text-align: center;">id</td>
<td style="text-align: center;">it</td>
<td style="text-align: center;">ja</td>
<td style="text-align: center;">ko</td>
<td style="text-align: center;">pt</td>
<td style="text-align: center;">ru</td>
<td style="text-align: center;">tr</td>
<td style="text-align: center;">vi</td>
<td style="text-align: center;">zh</td>
<td style="text-align: center;">$\neg$ IE</td>
<td style="text-align: center;">IE</td>
<td style="text-align: center;">$\neg$ Latin</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Latin</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">1</td>
<td style="text-align: center;">74.1</td>
<td style="text-align: center;">68.4</td>
<td style="text-align: center;">70.9</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">76.9</td>
<td style="text-align: center;">77.2</td>
<td style="text-align: center;">74.7</td>
<td style="text-align: center;">74.9</td>
<td style="text-align: center;">72.0</td>
<td style="text-align: center;">73.5</td>
<td style="text-align: center;">76.4</td>
<td style="text-align: center;">73.7</td>
<td style="text-align: center;">73.6</td>
<td style="text-align: center;">73.8</td>
<td style="text-align: center;">73.0</td>
<td style="text-align: center;">77.8</td>
<td style="text-align: center;">73.9</td>
<td style="text-align: center;">74.2</td>
<td style="text-align: center;">74.1</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">74.0</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: center;">72.2</td>
<td style="text-align: center;">67.0</td>
<td style="text-align: center;">70.5</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">76.5</td>
<td style="text-align: center;">75.7</td>
<td style="text-align: center;">74.0</td>
<td style="text-align: center;">72.5</td>
<td style="text-align: center;">70.8</td>
<td style="text-align: center;">70.9</td>
<td style="text-align: center;">73.8</td>
<td style="text-align: center;">74.3</td>
<td style="text-align: center;">70.8</td>
<td style="text-align: center;">69.5</td>
<td style="text-align: center;">70.8</td>
<td style="text-align: center;">73.5</td>
<td style="text-align: center;">71.1</td>
<td style="text-align: center;">73.6</td>
<td style="text-align: center;">71.6</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">72.6</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">3</td>
<td style="text-align: center;">71.5</td>
<td style="text-align: center;">67.2</td>
<td style="text-align: center;">69.8</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">76.5</td>
<td style="text-align: center;">76.4</td>
<td style="text-align: center;">75.0</td>
<td style="text-align: center;">69.8</td>
<td style="text-align: center;">71.6</td>
<td style="text-align: center;">69.2</td>
<td style="text-align: center;">73.1</td>
<td style="text-align: center;">71.1</td>
<td style="text-align: center;">69.3</td>
<td style="text-align: center;">67.6</td>
<td style="text-align: center;">70.1</td>
<td style="text-align: center;">74.8</td>
<td style="text-align: center;">70.1</td>
<td style="text-align: center;">73.4</td>
<td style="text-align: center;">71.4</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">71.6</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">5</td>
<td style="text-align: center;">70.3</td>
<td style="text-align: center;">65.0</td>
<td style="text-align: center;">69.6</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">76.2</td>
<td style="text-align: center;">76.3</td>
<td style="text-align: center;">75.1</td>
<td style="text-align: center;">67.0</td>
<td style="text-align: center;">71.0</td>
<td style="text-align: center;">68.2</td>
<td style="text-align: center;">72.4</td>
<td style="text-align: center;">69.1</td>
<td style="text-align: center;">67.6</td>
<td style="text-align: center;">65.5</td>
<td style="text-align: center;">66.7</td>
<td style="text-align: center;">73.8</td>
<td style="text-align: center;">68.3</td>
<td style="text-align: center;">72.9</td>
<td style="text-align: center;">70.4</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">70.2</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">10</td>
<td style="text-align: center;">68.4</td>
<td style="text-align: center;">65.0</td>
<td style="text-align: center;">68.6</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">75.9</td>
<td style="text-align: center;">75.7</td>
<td style="text-align: center;">75.7</td>
<td style="text-align: center;">66.2</td>
<td style="text-align: center;">70.2</td>
<td style="text-align: center;">66.1</td>
<td style="text-align: center;">68.8</td>
<td style="text-align: center;">66.7</td>
<td style="text-align: center;">63.7</td>
<td style="text-align: center;">60.6</td>
<td style="text-align: center;">64.7</td>
<td style="text-align: center;">69.6</td>
<td style="text-align: center;">65.6</td>
<td style="text-align: center;">72.1</td>
<td style="text-align: center;">68.1</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">68.6</td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>Table A16: Monolingual and Cross-lingual line-level pass rate (LPR) of Command $R$ using beam search with beam sizes 1-10. $(\neg)$ IE $=$ (non-) Indo-European language. $(\neg)$ Latin $=$ (non-) Latin script.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{22}$ W4 with group-wise scaling using GPTQ (Frantar et al., 2022).&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref6:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref7:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref8:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref9:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref10:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:1">
<p>${ }^{12}$ https://cohere.com/blog/command-r
${ }^{13}$ https://cohere.com/blog/
command-r-plus-microsoft-azure
${ }^{14}$ https://mistral.ai/news/mistral-large/&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 2 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:1" title="Jump back to footnote 2 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:1" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>