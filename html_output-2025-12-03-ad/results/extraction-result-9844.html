<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9844 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9844</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9844</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-166.html">extraction-schema-166</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using LLMs or related models to distill, extract, or discover quantitative laws, equations, or mathematical relationships from large collections of scholarly papers, including methods, results, challenges, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-8f5a280ed048200d926d8f200617c34a1511ac00</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/8f5a280ed048200d926d8f200617c34a1511ac00" target="_blank">Extracting Structured Seed-Mediated Gold Nanorod Growth Procedures from Literature with GPT-3</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> An approach using the powerful GPT-3 language model to extract structured multi-step seed-mediated growth procedures and outcomes for gold nanorods from unstructured scientific text by developing tools to extract relevant structured data in an automated, high-throughput manner.</p>
                <p><strong>Paper Abstract:</strong> Although gold nanorods have been the subject of much research, the pathways for controlling their shape and thereby their optical properties remain largely heuristically understood. Although it is apparent that the simultaneous presence of and interaction between various reagents during synthesis control these properties, computational and experimental approaches for exploring the synthesis space can be either intractable or too time-consuming in practice. This motivates an alternative approach leveraging the wealth of synthesis information already embedded in the body of scientific literature by developing tools to extract relevant structured data in an automated, high-throughput manner. To that end, we present an approach using the powerful GPT-3 language model to extract structured multi-step seed-mediated growth procedures and outcomes for gold nanorods from unstructured scientific text. GPT-3 prompt completions are fine-tuned to predict synthesis templates in the form of JSON documents from unstructured text input with an overall accuracy of $86\%$. The performance is notable, considering the model is performing simultaneous entity recognition and relation extraction. We present a dataset of 11,644 entities extracted from 1,137 papers, resulting in 268 papers with at least one complete seed-mediated gold nanorod growth procedure and outcome for a total of 332 complete procedures.</p>
                <p><strong>Cost:</strong> 0.017</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9844.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9844.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using LLMs or related models to distill, extract, or discover quantitative laws, equations, or mathematical relationships from large collections of scholarly papers, including methods, results, challenges, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3 (Davinci)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative Pre-trained Transformer 3 (Davinci, 175B)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 175-billion-parameter autoregressive transformer LLM (OpenAI Davinci) fine-tuned to perform sequence-to-sequence mapping from unstructured synthesis paragraphs to structured JSON synthesis templates; used here to extract structured experimental entities from large collections of papers enabling downstream quantitative analyses.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Extracting Structured Seed-Mediated Gold Nanorod Growth Procedures from Literature with GPT-3</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3 Davinci (175B)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Autoregressive transformer language model (GPT-3 family), 175 billion parameters; used in this work in its Davinci variant with fine-tuning via OpenAI API (default fine-tune settings) and temperature=0 for predictions. Employed both zero-shot QA completions and supervised fine-tuning (sequence-to-sequence style) to map paragraph text to JSON-formatted templates.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Materials chemistry / nanomaterials synthesis (gold nanorod seed-mediated growth)</td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>Empirical/Statistical relationships derived from extracted experimental measurements (e.g., linear relations between aspect ratio and LSPR; geometric identity between length/width ratio and reported aspect ratio)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Two-stage approach: (1) zero-shot question-answering with GPT-3 to populate template fields for an initial small annotated set, then manual correction; (2) supervised fine-tuning of GPT-3 (Davinci) on paragraph→JSON pairs to produce complete templates in a single inference. Iterative loop of prediction → human correction → incremental fine-tuning. Downstream discovery used conventional statistical analysis (linear regression, outlier detection) on GPT-3-extracted numerical entities.</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Corpus derived from a text-mined gold nanoparticle literature collection: 1,137 papers filtered for seed-mediated nanorod synthesis, 2,969 relevant paragraphs; initial annotated training set from 240 papers (661 paragraphs); testing set 40 papers (117 paragraphs). Fine-tuned model applied to full 1,137 papers, extracting 11,644 entity instances (post-processed to 11,770 unique entities) and yielding 332 complete procedures from 268 papers. Preprocessing pipeline included TF-IDF filtering and BERT paragraph classifiers for initial selection; paragraphs were annotated and split to respect GPT-3 token limits.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Two-stage evaluation: (a) placement evaluation (binary existence of information in template fields) measured by precision, recall, F1; (b) transcription accuracy for true-positive placements (exact string/unit match or numeric similarity using s(p,q)=2*min(p,q)/(p+q)). Combined metric = placement F1 * transcription accuracy. Also human verification and manual correction used for test set.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Fine-tuned GPT-3 attained placement F1 ≈ 0.90, transcription accuracy ≈ 0.96, resulting in an adjusted combined score ≈ 0.86 (86%). Extracted 11,644 entities (≈87% unique), produced 332 complete seed-mediated AuNR procedures from 268 papers. Costs reported for fine-tuning and prediction (≈$85.30 fine-tune; prediction/testing ≈$14.39; full-run $384.31 over 33 hours).</td>
                        </tr>
                        <tr>
                            <td><strong>notable_examples</strong></td>
                            <td>Using GPT-3-extracted numerical measurements they derived and validated quantitative relationships: (1) length/width ratio vs reported aspect ratio — after outlier removal the regression matches the identity relationship; (2) linear correlation between longitudinal surface plasmon resonance (LSPR) peak and aspect ratio — text-mined empirical trend broadly consistent with simulated relationship, with deviations attributed to experimental factors and extraction errors. These are concrete examples of discovering quantitative empirical relationships from literature via LLM-enabled extraction combined with classical regression.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Primary limitations reported: (1) difficulty identifying/new precursors not present in training set (misses when novel names/aliases absent from training); (2) template rigidity — static template enforces fixed relations so entity recognition and relation extraction are entangled and cannot be easily disentangled for direct comparison with multi-step pipelines; (3) cross-paragraph conflicts and repetitions (same entity reported differently in multiple paragraphs) require manual/heuristic resolution; (4) specific extraction errors (e.g., confusing 'borohydride' aliasing with NaBH4, swapping LSPR/TSPR, confusing seed sizes from multi-step overgrowth procedures), requiring outlier detection and manual verification; (5) zero-shot QA is useful for seeding but insufficient alone (poor single-request template completion prior to fine-tuning); (6) limited generality — fine-tuned model focused on seed-mediated AuNR templates and may require new templates / more examples for other synthesis types.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to prior NER and pipeline approaches: prior BiLSTM-based NER reported precursor-detection F1 ≈ 0.90 (did not distinguish seed vs growth solution), MatBERT had morphology/size F1s reported in prior work (e.g., morphology measurements via MatBERT reported ~70% F1 for some tasks). The GPT-3 templating approach improved overall combined extraction performance (adjusted F1 ≈ 86%) and succeeded at linking entities to solution-specific relations (seed vs growth). The authors also note prior solid-state synthesis extraction work reporting ~51% overall accuracy for recipe items, making the 86% a substantial improvement for this application.</td>
                        </tr>
                        <tr>
                            <td><strong>additional_notes</strong></td>
                            <td>Practical constraints reported: 2,048 token limit per request (shared input+output), cost/latency considerations for large-scale application, and the need for human-in-the-loop correction during iterative fine-tuning. The extraction outputs were post-processed to split lists and annotate sources for provenance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Extracting Structured Seed-Mediated Gold Nanorod Growth Procedures from Literature with GPT-3', 'publication_date_yy_mm': '2023-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9844.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9844.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using LLMs or related models to distill, extract, or discover quantitative laws, equations, or mathematical relationships from large collections of scholarly papers, including methods, results, challenges, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Zero-shot GPT-3 QA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Zero-shot question-answering using GPT-3</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An approach using the untuned GPT-3 model to answer targeted questions about paragraph content to fill individual fields of a structured template; used to bootstrap an annotated dataset prior to fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Extracting Structured Seed-Mediated Gold Nanorod Growth Procedures from Literature with GPT-3</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3 Davinci (zero-shot QA)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Standard pre-trained GPT-3 (Davinci) used without fine-tuning to answer targeted queries (one field per request) about paragraph content. Responses aggregated into JSON entries and corrected by human annotators to create initial training examples.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Materials synthesis information extraction</td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>N/A (method for extracting numerical/qualitative entities rather than direct law distillation)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Pattern-detection in paragraph triggers targeted GPT-3 queries for common precursor names/aliases and specified conditions (volumes, concentrations, ages, stir rates); completions aggregated per paragraph to populate template fields, followed by manual correction.</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Initial set: 40 randomly sampled papers from the candidate set; targeted only eight most-common precursors and several auxiliary metadata fields. Used as seed-training data (40 papers → corrected templates) for subsequent fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Qualitative assessment of annotation speed and quality. Observed that most completions required corrections rather than full manual entry. Used corrected outputs to seed fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Zero-shot QA was found to be a useful bootstrap tool: it sped manual annotation (initial templates required ~4 minutes to correct, decreasing to ~1 minute as models improved). However, zero-shot alone produced poor single-request template completions and did not scale due to many requests needed per paragraph.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_examples</strong></td>
                            <td>Worked well to capture frequent precursors and common field formats, but failed to capture less-common precursors and complex relation structures without human correction.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>High per-field request overhead (many API calls per paragraph), poorer single-request fidelity compared to fine-tuned model, limited to precursors and fields anticipated in the initial schema, and inability to capture rarer phrasing/aliases unless enumerated.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Inferior to the fine-tuned GPT-3 single-request template completion; valuable only as a seeding/annotation-acceleration strategy.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Extracting Structured Seed-Mediated Gold Nanorod Growth Procedures from Literature with GPT-3', 'publication_date_yy_mm': '2023-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9844.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9844.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using LLMs or related models to distill, extract, or discover quantitative laws, equations, or mathematical relationships from large collections of scholarly papers, including methods, results, challenges, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Text-mined regression pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Text-mined extraction followed by statistical regression and outlier filtering</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A downstream analysis pipeline that uses structured entities extracted (via GPT-3 and earlier NLP tools) from literature to compute empirical quantitative relationships (e.g., regressions between geometric ratios and optical peaks) with outlier detection and manual verification.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Extracting Structured Seed-Mediated Gold Nanorod Growth Procedures from Literature with GPT-3</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Statistical regression + outlier detection (elliptic envelope)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Classical statistical analysis methods (linear regression) and robust outlier detection (elliptic envelope) applied to numeric entities extracted from literature to reveal empirical relationships between experimental variables (e.g., aspect ratio, length/width, LSPR).</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Materials/nanoparticle characterization (plasmonics vs geometry)</td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>Empirical linear relationships (observational laws) and identity/geometry checks</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Select co-occurring numeric measurements from same paragraph (no derived measurements), perform linear regression between pairs (e.g., aspect ratio vs LSPR; aspect ratio vs length/width ratio), detect outliers via elliptic envelope followed by manual verification, and compare trends to simulations where available.</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Numerical outputs from GPT-3-extracted templates: co-occurring reported aspect ratios, explicit lengths and widths, and LSPR/TSPR peaks drawn from the post-processed dataset (11,770 unique entities; subset of 78 and 86 co-occurring datapoints used in two comparisons respectively after filtering).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Compare fitted regressions to theoretical/simulated expectations (e.g., simulated LSPR vs aspect ratio) and to identity expectations (length/width ratio ~ reported aspect ratio). Assess outliers and manually verify errors; report number of outliers removed and effect on regression.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>After outlier removal and manual verification, the length/width vs reported aspect ratio regression matched the identity relation closely (few outliers — 8 of 78). LSPR vs aspect ratio showed a strong linear trend consistent with simulations qualitatively, though text-mined trend differed at small aspect ratios (empirical intercept ~580–590 nm vs ideal ~520 nm); 9 of 86 datapoints flagged as outliers. Demonstrates that LLM-enabled extraction can be combined with classical statistics to recover meaningful empirical relationships from literature-scale data.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_examples</strong></td>
                            <td>Recovered near-identity between explicit geometric ratio and reported aspect ratio; recovered an LSPR-aspect-ratio linear trend consistent with physical expectations and simulation-derived trend, with deviations attributed to experimental conditions and extraction errors.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Downstream regressions limited by extraction errors (swapped labels, multi-step procedure confusion), sparse co-occurrence of the exact measurements in single paragraphs (limits datapoint count), conflicts/repetitions across paragraphs requiring resolution, and biases from literature reporting practices (e.g., selective reporting, reference to previously published protocols rather than full procedure). Manual verification and outlier filtering were required to obtain physically meaningful regressions.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>No direct prior baseline for literature-scale numeric-law discovery in this subdomain reported in paper; authors contrast to prior text-mined datasets (e.g., Cruse et al., Kononova et al.) that provided many entities but lacked linked relations necessary for reliable regression — the GPT-3 templating approach offered improved linking and therefore better suitability for downstream quantitative discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Extracting Structured Seed-Mediated Gold Nanorod Growth Procedures from Literature with GPT-3', 'publication_date_yy_mm': '2023-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9844.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9844.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using LLMs or related models to distill, extract, or discover quantitative laws, equations, or mathematical relationships from large collections of scholarly papers, including methods, results, challenges, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BiLSTM / MatBERT / BERT classifiers</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BiLSTM-based NER, MatBERT NER, and BERT paragraph classifiers (previous pipeline components)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Components of the prior text-mining pipeline used to filter and extract materials synthesis information: TF-IDF + BERT paragraph classifiers for filtering, BiLSTM-based NER for extraction of synthesis procedure tokens, and MatBERT for morphology/size NER; used here as preprocessing and baseline comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Extracting Structured Seed-Mediated Gold Nanorod Growth Procedures from Literature with GPT-3</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BiLSTM NER; MatBERT (domain-specific BERT); BERT paragraph classifiers</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>BiLSTM: recurrent neural network-based named entity recognition models used previously for precursor extraction. MatBERT: domain-specific BERT model pre-trained on materials science text for NER of morphology/size. BERT paragraph classifiers: BERT-family binary classifiers to classify paragraphs as synthesis- or characterization-related. These were used upstream to build the corpus and extract initial entities prior to GPT-3 templating.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Materials science NLP / information extraction</td>
                        </tr>
                        <tr>
                            <td><strong>law_type</strong></td>
                            <td>N/A (these models extract entities/measurements that can be used to compute empirical relationships)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>TF-IDF filtering to identify candidate papers, BERT-based binary paragraph classifiers to select relevant paragraphs, then BiLSTM and MatBERT NER models to extract precursor names, concentrations, morphologies, and sizes; outputs served as the starting corpus and comparison baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Applied to large full-text database (~4.9 million materials science articles) to identify gold nanoparticle synthesis papers (5,145 papers identified), and to extract initial synthesis/characterization entities used to construct the candidate paragraphs for GPT-3 processing.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Reported previous NER metrics in cited works: BiLSTM precursor detection reported F1 ≈ 0.90 (did not distinguish seed vs growth); MatBERT morphology/size extraction had varied F1s (examples in related work: morphology ~70%, size ~69%, unit extraction ~91% in cited prior work). These served as baselines for comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>These prior models provided valuable large-scale extraction but had limitations: inability to distinguish seed vs growth solution entities, inability to detect materials referenced by non-standard names (e.g., 'AuNP seed solution'), and propagation of errors across multi-step pipelines. GPT-3 templating improved relational linking (seed vs growth) and overall combined extraction performance in this application.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_examples</strong></td>
                            <td>BiLSTM precursor detection F1 ~90% (prior work). MatBERT used to extract morphology and size from characterization paragraphs in the upstream dataset that seeded this work.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Two-step pipelines prone to error propagation (separate models for entity extraction and relation linking), limited detection of non-formulaic mentions, and limited ability to link entities across multi-step procedures. These shortcomings motivated the single-step templating approach with GPT-3.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to GPT-3 templating: BiLSTM/MatBERT pipelines achieved reasonable NER scores but lacked solution-specific linking and relation extraction competency; GPT-3 fine-tuned single-step approach achieved higher end-to-end adjusted combined extraction score (~86%) and explicit linking of entities to seed/growth solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Extracting Structured Seed-Mediated Gold Nanorod Growth Procedures from Literature with GPT-3', 'publication_date_yy_mm': '2023-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Structured information extraction from complex scientific text with fine-tuned large language models <em>(Rating: 2)</em></li>
                <li>Text-mined dataset of inorganic materials synthesis recipes <em>(Rating: 2)</em></li>
                <li>Text-mined dataset of gold nanoparticle synthesis procedures, morphologies, and size entities <em>(Rating: 2)</em></li>
                <li>Language models are few-shot learners <em>(Rating: 1)</em></li>
                <li>Quantifying the advantage of domain-specific pre-training on named entity recognition tasks in materials science <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9844",
    "paper_id": "paper-8f5a280ed048200d926d8f200617c34a1511ac00",
    "extraction_schema_id": "extraction-schema-166",
    "extracted_data": [
        {
            "name_short": "GPT-3 (Davinci)",
            "name_full": "Generative Pre-trained Transformer 3 (Davinci, 175B)",
            "brief_description": "A 175-billion-parameter autoregressive transformer LLM (OpenAI Davinci) fine-tuned to perform sequence-to-sequence mapping from unstructured synthesis paragraphs to structured JSON synthesis templates; used here to extract structured experimental entities from large collections of papers enabling downstream quantitative analyses.",
            "citation_title": "Extracting Structured Seed-Mediated Gold Nanorod Growth Procedures from Literature with GPT-3",
            "mention_or_use": "use",
            "model_name": "GPT-3 Davinci (175B)",
            "model_description": "Autoregressive transformer language model (GPT-3 family), 175 billion parameters; used in this work in its Davinci variant with fine-tuning via OpenAI API (default fine-tune settings) and temperature=0 for predictions. Employed both zero-shot QA completions and supervised fine-tuning (sequence-to-sequence style) to map paragraph text to JSON-formatted templates.",
            "scientific_domain": "Materials chemistry / nanomaterials synthesis (gold nanorod seed-mediated growth)",
            "law_type": "Empirical/Statistical relationships derived from extracted experimental measurements (e.g., linear relations between aspect ratio and LSPR; geometric identity between length/width ratio and reported aspect ratio)",
            "method_description": "Two-stage approach: (1) zero-shot question-answering with GPT-3 to populate template fields for an initial small annotated set, then manual correction; (2) supervised fine-tuning of GPT-3 (Davinci) on paragraph→JSON pairs to produce complete templates in a single inference. Iterative loop of prediction → human correction → incremental fine-tuning. Downstream discovery used conventional statistical analysis (linear regression, outlier detection) on GPT-3-extracted numerical entities.",
            "input_corpus_description": "Corpus derived from a text-mined gold nanoparticle literature collection: 1,137 papers filtered for seed-mediated nanorod synthesis, 2,969 relevant paragraphs; initial annotated training set from 240 papers (661 paragraphs); testing set 40 papers (117 paragraphs). Fine-tuned model applied to full 1,137 papers, extracting 11,644 entity instances (post-processed to 11,770 unique entities) and yielding 332 complete procedures from 268 papers. Preprocessing pipeline included TF-IDF filtering and BERT paragraph classifiers for initial selection; paragraphs were annotated and split to respect GPT-3 token limits.",
            "evaluation_method": "Two-stage evaluation: (a) placement evaluation (binary existence of information in template fields) measured by precision, recall, F1; (b) transcription accuracy for true-positive placements (exact string/unit match or numeric similarity using s(p,q)=2*min(p,q)/(p+q)). Combined metric = placement F1 * transcription accuracy. Also human verification and manual correction used for test set.",
            "results_summary": "Fine-tuned GPT-3 attained placement F1 ≈ 0.90, transcription accuracy ≈ 0.96, resulting in an adjusted combined score ≈ 0.86 (86%). Extracted 11,644 entities (≈87% unique), produced 332 complete seed-mediated AuNR procedures from 268 papers. Costs reported for fine-tuning and prediction (≈$85.30 fine-tune; prediction/testing ≈$14.39; full-run $384.31 over 33 hours).",
            "notable_examples": "Using GPT-3-extracted numerical measurements they derived and validated quantitative relationships: (1) length/width ratio vs reported aspect ratio — after outlier removal the regression matches the identity relationship; (2) linear correlation between longitudinal surface plasmon resonance (LSPR) peak and aspect ratio — text-mined empirical trend broadly consistent with simulated relationship, with deviations attributed to experimental factors and extraction errors. These are concrete examples of discovering quantitative empirical relationships from literature via LLM-enabled extraction combined with classical regression.",
            "limitations_challenges": "Primary limitations reported: (1) difficulty identifying/new precursors not present in training set (misses when novel names/aliases absent from training); (2) template rigidity — static template enforces fixed relations so entity recognition and relation extraction are entangled and cannot be easily disentangled for direct comparison with multi-step pipelines; (3) cross-paragraph conflicts and repetitions (same entity reported differently in multiple paragraphs) require manual/heuristic resolution; (4) specific extraction errors (e.g., confusing 'borohydride' aliasing with NaBH4, swapping LSPR/TSPR, confusing seed sizes from multi-step overgrowth procedures), requiring outlier detection and manual verification; (5) zero-shot QA is useful for seeding but insufficient alone (poor single-request template completion prior to fine-tuning); (6) limited generality — fine-tuned model focused on seed-mediated AuNR templates and may require new templates / more examples for other synthesis types.",
            "baseline_comparison": "Compared to prior NER and pipeline approaches: prior BiLSTM-based NER reported precursor-detection F1 ≈ 0.90 (did not distinguish seed vs growth solution), MatBERT had morphology/size F1s reported in prior work (e.g., morphology measurements via MatBERT reported ~70% F1 for some tasks). The GPT-3 templating approach improved overall combined extraction performance (adjusted F1 ≈ 86%) and succeeded at linking entities to solution-specific relations (seed vs growth). The authors also note prior solid-state synthesis extraction work reporting ~51% overall accuracy for recipe items, making the 86% a substantial improvement for this application.",
            "additional_notes": "Practical constraints reported: 2,048 token limit per request (shared input+output), cost/latency considerations for large-scale application, and the need for human-in-the-loop correction during iterative fine-tuning. The extraction outputs were post-processed to split lists and annotate sources for provenance.",
            "uuid": "e9844.0",
            "source_info": {
                "paper_title": "Extracting Structured Seed-Mediated Gold Nanorod Growth Procedures from Literature with GPT-3",
                "publication_date_yy_mm": "2023-04"
            }
        },
        {
            "name_short": "Zero-shot GPT-3 QA",
            "name_full": "Zero-shot question-answering using GPT-3",
            "brief_description": "An approach using the untuned GPT-3 model to answer targeted questions about paragraph content to fill individual fields of a structured template; used to bootstrap an annotated dataset prior to fine-tuning.",
            "citation_title": "Extracting Structured Seed-Mediated Gold Nanorod Growth Procedures from Literature with GPT-3",
            "mention_or_use": "use",
            "model_name": "GPT-3 Davinci (zero-shot QA)",
            "model_description": "Standard pre-trained GPT-3 (Davinci) used without fine-tuning to answer targeted queries (one field per request) about paragraph content. Responses aggregated into JSON entries and corrected by human annotators to create initial training examples.",
            "scientific_domain": "Materials synthesis information extraction",
            "law_type": "N/A (method for extracting numerical/qualitative entities rather than direct law distillation)",
            "method_description": "Pattern-detection in paragraph triggers targeted GPT-3 queries for common precursor names/aliases and specified conditions (volumes, concentrations, ages, stir rates); completions aggregated per paragraph to populate template fields, followed by manual correction.",
            "input_corpus_description": "Initial set: 40 randomly sampled papers from the candidate set; targeted only eight most-common precursors and several auxiliary metadata fields. Used as seed-training data (40 papers → corrected templates) for subsequent fine-tuning.",
            "evaluation_method": "Qualitative assessment of annotation speed and quality. Observed that most completions required corrections rather than full manual entry. Used corrected outputs to seed fine-tuning.",
            "results_summary": "Zero-shot QA was found to be a useful bootstrap tool: it sped manual annotation (initial templates required ~4 minutes to correct, decreasing to ~1 minute as models improved). However, zero-shot alone produced poor single-request template completions and did not scale due to many requests needed per paragraph.",
            "notable_examples": "Worked well to capture frequent precursors and common field formats, but failed to capture less-common precursors and complex relation structures without human correction.",
            "limitations_challenges": "High per-field request overhead (many API calls per paragraph), poorer single-request fidelity compared to fine-tuned model, limited to precursors and fields anticipated in the initial schema, and inability to capture rarer phrasing/aliases unless enumerated.",
            "baseline_comparison": "Inferior to the fine-tuned GPT-3 single-request template completion; valuable only as a seeding/annotation-acceleration strategy.",
            "uuid": "e9844.1",
            "source_info": {
                "paper_title": "Extracting Structured Seed-Mediated Gold Nanorod Growth Procedures from Literature with GPT-3",
                "publication_date_yy_mm": "2023-04"
            }
        },
        {
            "name_short": "Text-mined regression pipeline",
            "name_full": "Text-mined extraction followed by statistical regression and outlier filtering",
            "brief_description": "A downstream analysis pipeline that uses structured entities extracted (via GPT-3 and earlier NLP tools) from literature to compute empirical quantitative relationships (e.g., regressions between geometric ratios and optical peaks) with outlier detection and manual verification.",
            "citation_title": "Extracting Structured Seed-Mediated Gold Nanorod Growth Procedures from Literature with GPT-3",
            "mention_or_use": "use",
            "model_name": "Statistical regression + outlier detection (elliptic envelope)",
            "model_description": "Classical statistical analysis methods (linear regression) and robust outlier detection (elliptic envelope) applied to numeric entities extracted from literature to reveal empirical relationships between experimental variables (e.g., aspect ratio, length/width, LSPR).",
            "scientific_domain": "Materials/nanoparticle characterization (plasmonics vs geometry)",
            "law_type": "Empirical linear relationships (observational laws) and identity/geometry checks",
            "method_description": "Select co-occurring numeric measurements from same paragraph (no derived measurements), perform linear regression between pairs (e.g., aspect ratio vs LSPR; aspect ratio vs length/width ratio), detect outliers via elliptic envelope followed by manual verification, and compare trends to simulations where available.",
            "input_corpus_description": "Numerical outputs from GPT-3-extracted templates: co-occurring reported aspect ratios, explicit lengths and widths, and LSPR/TSPR peaks drawn from the post-processed dataset (11,770 unique entities; subset of 78 and 86 co-occurring datapoints used in two comparisons respectively after filtering).",
            "evaluation_method": "Compare fitted regressions to theoretical/simulated expectations (e.g., simulated LSPR vs aspect ratio) and to identity expectations (length/width ratio ~ reported aspect ratio). Assess outliers and manually verify errors; report number of outliers removed and effect on regression.",
            "results_summary": "After outlier removal and manual verification, the length/width vs reported aspect ratio regression matched the identity relation closely (few outliers — 8 of 78). LSPR vs aspect ratio showed a strong linear trend consistent with simulations qualitatively, though text-mined trend differed at small aspect ratios (empirical intercept ~580–590 nm vs ideal ~520 nm); 9 of 86 datapoints flagged as outliers. Demonstrates that LLM-enabled extraction can be combined with classical statistics to recover meaningful empirical relationships from literature-scale data.",
            "notable_examples": "Recovered near-identity between explicit geometric ratio and reported aspect ratio; recovered an LSPR-aspect-ratio linear trend consistent with physical expectations and simulation-derived trend, with deviations attributed to experimental conditions and extraction errors.",
            "limitations_challenges": "Downstream regressions limited by extraction errors (swapped labels, multi-step procedure confusion), sparse co-occurrence of the exact measurements in single paragraphs (limits datapoint count), conflicts/repetitions across paragraphs requiring resolution, and biases from literature reporting practices (e.g., selective reporting, reference to previously published protocols rather than full procedure). Manual verification and outlier filtering were required to obtain physically meaningful regressions.",
            "baseline_comparison": "No direct prior baseline for literature-scale numeric-law discovery in this subdomain reported in paper; authors contrast to prior text-mined datasets (e.g., Cruse et al., Kononova et al.) that provided many entities but lacked linked relations necessary for reliable regression — the GPT-3 templating approach offered improved linking and therefore better suitability for downstream quantitative discovery.",
            "uuid": "e9844.2",
            "source_info": {
                "paper_title": "Extracting Structured Seed-Mediated Gold Nanorod Growth Procedures from Literature with GPT-3",
                "publication_date_yy_mm": "2023-04"
            }
        },
        {
            "name_short": "BiLSTM / MatBERT / BERT classifiers",
            "name_full": "BiLSTM-based NER, MatBERT NER, and BERT paragraph classifiers (previous pipeline components)",
            "brief_description": "Components of the prior text-mining pipeline used to filter and extract materials synthesis information: TF-IDF + BERT paragraph classifiers for filtering, BiLSTM-based NER for extraction of synthesis procedure tokens, and MatBERT for morphology/size NER; used here as preprocessing and baseline comparison.",
            "citation_title": "Extracting Structured Seed-Mediated Gold Nanorod Growth Procedures from Literature with GPT-3",
            "mention_or_use": "use",
            "model_name": "BiLSTM NER; MatBERT (domain-specific BERT); BERT paragraph classifiers",
            "model_description": "BiLSTM: recurrent neural network-based named entity recognition models used previously for precursor extraction. MatBERT: domain-specific BERT model pre-trained on materials science text for NER of morphology/size. BERT paragraph classifiers: BERT-family binary classifiers to classify paragraphs as synthesis- or characterization-related. These were used upstream to build the corpus and extract initial entities prior to GPT-3 templating.",
            "scientific_domain": "Materials science NLP / information extraction",
            "law_type": "N/A (these models extract entities/measurements that can be used to compute empirical relationships)",
            "method_description": "TF-IDF filtering to identify candidate papers, BERT-based binary paragraph classifiers to select relevant paragraphs, then BiLSTM and MatBERT NER models to extract precursor names, concentrations, morphologies, and sizes; outputs served as the starting corpus and comparison baselines.",
            "input_corpus_description": "Applied to large full-text database (~4.9 million materials science articles) to identify gold nanoparticle synthesis papers (5,145 papers identified), and to extract initial synthesis/characterization entities used to construct the candidate paragraphs for GPT-3 processing.",
            "evaluation_method": "Reported previous NER metrics in cited works: BiLSTM precursor detection reported F1 ≈ 0.90 (did not distinguish seed vs growth); MatBERT morphology/size extraction had varied F1s (examples in related work: morphology ~70%, size ~69%, unit extraction ~91% in cited prior work). These served as baselines for comparison.",
            "results_summary": "These prior models provided valuable large-scale extraction but had limitations: inability to distinguish seed vs growth solution entities, inability to detect materials referenced by non-standard names (e.g., 'AuNP seed solution'), and propagation of errors across multi-step pipelines. GPT-3 templating improved relational linking (seed vs growth) and overall combined extraction performance in this application.",
            "notable_examples": "BiLSTM precursor detection F1 ~90% (prior work). MatBERT used to extract morphology and size from characterization paragraphs in the upstream dataset that seeded this work.",
            "limitations_challenges": "Two-step pipelines prone to error propagation (separate models for entity extraction and relation linking), limited detection of non-formulaic mentions, and limited ability to link entities across multi-step procedures. These shortcomings motivated the single-step templating approach with GPT-3.",
            "baseline_comparison": "Compared to GPT-3 templating: BiLSTM/MatBERT pipelines achieved reasonable NER scores but lacked solution-specific linking and relation extraction competency; GPT-3 fine-tuned single-step approach achieved higher end-to-end adjusted combined extraction score (~86%) and explicit linking of entities to seed/growth solutions.",
            "uuid": "e9844.3",
            "source_info": {
                "paper_title": "Extracting Structured Seed-Mediated Gold Nanorod Growth Procedures from Literature with GPT-3",
                "publication_date_yy_mm": "2023-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Structured information extraction from complex scientific text with fine-tuned large language models",
            "rating": 2
        },
        {
            "paper_title": "Text-mined dataset of inorganic materials synthesis recipes",
            "rating": 2
        },
        {
            "paper_title": "Text-mined dataset of gold nanoparticle synthesis procedures, morphologies, and size entities",
            "rating": 2
        },
        {
            "paper_title": "Language models are few-shot learners",
            "rating": 1
        },
        {
            "paper_title": "Quantifying the advantage of domain-specific pre-training on named entity recognition tasks in materials science",
            "rating": 1
        }
    ],
    "cost": 0.017363,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Extracting Structured Seed-Mediated Gold Nanorod Growth Procedures from Literature with GPT-3</h1>
<p>Nicholas Walker ${ }^{1}$, John Dagdelen ${ }^{1,4}$, Kevin Cruse ${ }^{2,4}$, Sanghoon Lee ${ }^{1,4}$, Samuel Gleason ${ }^{1,5}$, Alexander Dunn ${ }^{1,4}$, Gerbrand Ceder ${ }^{2,4}$, A. Paul Alivisatos ${ }^{2,4,5,6}$, Kristin A. Persson ${ }^{3,4,6}$ and Anubhav Jain ${ }^{1}$<br>${ }^{1}$ Energy Technologies Area, Lawrence Berkeley National Laboratory, 1 Cyclotron Road, Berkeley, 94720, CA, United States of America<br>${ }^{2}$ Materials Sciences Division, Lawrence Berkeley National Laboratory, 1 Cyclotron Road, Berkeley, 94720, CA, United States of America<br>${ }^{3}$ Molecular Foundry, Lawrence Berkeley National Laboratory, 1 Cyclotron Road, Berkeley, 94720, CA, United States of America<br>${ }^{4}$ Department of Materials Science and Engineering, University of California Berkeley, 210 Hearst Memorial Mining Building, Berkeley, 94720, CA, United States of America<br>${ }^{5}$ Department of Chemistry, University of California Berkeley, 419 Latimer Hall, Berkeley, 94720, CA, United States of America<br>${ }^{6}$ Kavli Energy NanoScience Institute, University of California Berkeley, 101C Campbell Hall, Berkeley, 94720, CA, United States of America</p>
<h4>Abstract</h4>
<p>Although gold nanorods have been the subject of much research, the pathways for controlling their shape and thereby their optical properties remain largely heuristically understood. Although it is apparent that the simultaneous presence of and interaction between various reagents during synthesis control these properties, computational and experimental approaches for exploring the synthesis space can be either intractable or too time-consuming in practice. This motivates an alternative approach leveraging the wealth of synthesis information already embedded in the body of scientific literature by developing tools to extract relevant structured data in an automated, high-throughput manner. To that end, we present an approach using the powerful GPT-3 language model to extract structured multi-step seed-mediated growth procedures and outcomes for gold nanorods from unstructured scientific text. GPT-3 prompt completions are finetuned to predict synthesis templates in the form of JSON documents from unstructured text input with an overall accuracy of $86 \%$. The performance is notable, considering the model is performing simultaneous entity recognition and relation extraction. We present a dataset of 11,644 entities extracted from 1,137 papers, resulting in 268 papers with at least one complete seed-mediated gold nanorod growth procedure and outcome for a total of 332 complete procedures.</p>
<h2>I. INTRODUCTION</h2>
<p>Gold nanoparticles have been synthesized for centuries due to their interesting optical properties, dating back to the Lycurgus Cup from $4^{\text {th }}$ century Rome,[1] as well as imperial bowls and decorated dishes from the Qing dynasty.[2] However, scientific interest did not develop until the work of Michael Faraday in the mid- $19^{\text {th }}$ century, when he accidentally synthesized colloidal gold while investigating the interaction between light and matter.[3] In the last three decades, chemists have developed the ability to synthesize anisotropic metal nanoparticles in a controllable and re-</p>
<p>Contact data: Anubhav Jain, ajain@lbl.gov
producible fashion.[4] Around the turn of the millennium, multi-step seed-mediated growth methods were developed to prepare gold nanorods with aspect ratios ranging from 8 to $20.[4,5,6]$ This generated a great deal of interest in anisotropic gold nanoparticles due to a combination of the convenience of the wet-chemistry approach, as well as the ability to tune the shape of the synthesized nanorods. The anisotropic gold nanoparticles, in turn, provide access to shape-dependent optical phenomena not observed with spherical gold nanoparticles.[7, 8, 9, 10] Their applications are widespread across many domains, including semiconductor technology,[11, 12] biomedicine,[13, 14] and cosmetics.[15] The suitability of a nanoparticle for a particular application depends on its morphology and size, which correspond to different plasmonic properties.[16, 17, 18]</p>
<p>Despite the popularity of anisotropic gold nanoparticles,</p>
<p>systematic investigation of the control of these properties has only recently been approached.[19] Although some theories and models do exist for identifying and explaining the mechanisms of synthesis that determine nanoparticle morphology,[4, 20, 21, 22] most synthesis exploration is still guided by heuristics based on domain knowledge.</p>
<p>For gold nanorods, it is clear that the simultaneous presence of various reagents during the synthesis affects the characteristics of the resulting gold nanoparticles.[4] To better understand these effects, computational simulation and analysis of the formation energetics of the nanoparticles or the nucleation and growth steps can be used. Density functional theory (DFT) can be used to investigate the energetic landscape of potential gold nanoparticle morphologies, including the effects of surface ligands that are vital for the solution-phase synthesis of noble metal nanoparticles.[23, 24, 25] However, this approach does not account for the nuances of nucleation and growth competition in solutionbased nanoparticle syntheses. These aspects can be addressed by modeling real-time growth and dispersity dynamics with continuum-level model, though this sacrifices access to small-scale energetics granted by DFT.[26] Alternatively, direct experimentation can be used to explore the synthesis space by varying precursor amounts over many experiments, though this is impractical due to the both the number of experiments required to sample the synthesis space and the condition that a single experiment can take many hours to complete. Automated labs may address this problem in the future, though most are still in their infancy.</p>
<p>A third approach seeks to leverage the wealth of information contained in scientific literature. Many seed-mediated gold nanorod recipes have been published in the materials science and chemistry literature, but parsing them requires domain experts to manually read these articles to retrieve the relevant precursors, procedures, laboratory conditions, and target characterizations. This comes with its own complications, however, as over time, the body of materials science literature has grown to an unwieldy extent, preventing researchers from absorbing the full breadth of information contained in established literature or even reasonably following research progress as it emerges.[27] Thus, it is unreasonable to expect domain experts in gold nanoparticle synthesis to manually read and parse the complete existing synthesis literature efficiently, motivating the development of highthroughput text-mining methods to extract this information.</p>
<p>The resulting databases built with these methods are the first steps toward developing data-driven approaches to understanding synthesis, which are being developed at an accelerating pace as a rapidly emerging third paradigm of scientific investigation. Generally speaking, these approaches involve the use of both conventional and machine learning methods to both build large databases and perform downstream analysis and inference over said databases. Natu-
ral language processing (NLP) has been successfully applied in the chemical, medical, and materials sciences to produce structured data from unstructured text using methods and models such as pattern recognition, recurrent neural networks, and language models.[28, 29, 30, 31, 32, 33, 34, 28, $35,36,37,38,39,40,41,42,43,44,45,46,47,48,49]$</p>
<p>For applications specifically related to materials synthesis, data-driven approaches have been successful for tasks such as materials discovery, synthesis protocol querying, and simulation and interpretation of characterization results.[50, 51, 52, 53, 54] However, these approaches are fundamentally limited by the quality of the data, such as the completeness and substance of the data source. To address this, careful data curation is necessary, as seen with the construction and maintenance of large databases of characteristic features of nanostructures.[55]</p>
<p>Recently, the wealth of unstructured information about gold nanoparticle synthesis and characterization in literature has been directly tapped through the combination of various NLP models and other text-mining techniques to produce a dataset of over five thousand codified gold nanoparticle synthesis protocols and outcomes.[56] This general dataset contains a wealth of information, including detected materials, material quantities, morphologies, synthesis actions, and synthesis conditions, as well as tags for seed-mediated synthesis, synthesis paragraph classifications, and characterization paragraph classifications.</p>
<p>Despite the breadth of accurate information provided, the general dataset still suffers from a few pitfalls: (i) the inability to distinguish between seed and growth solution procedures in seed-mediated growth synthesis; (ii) the inability to detect references to materials that do not contain specific formulae or chemical names (e.g. "AuNP seed solution"); and (iii) the inability to detect target morphologies as opposed to incidentally mentioned morphologies. To address these issues, this work intends to use a large sequence-tosequence language model to extract full synthesis procedures and outcomes in a single-step inference. Generally speaking, a sequence-to-sequence model in NLP maps an input sequence to an output sequence by learning to produce the most likely completion of the input by conditioning the output on the input.[57]</p>
<p>In this work, we leverage the capabilities of the latest language model in the Generative Pre-trained Transformer (GPT) family, GPT-3,[58] to build a dataset of highly structured synthesis templates for seed-mediated gold nanorod growth. A similar approach using GPT-3 to build materials science datasets has been applied to extracting dopant-host material pairs, cataloging metal-organic frameworks, and extracting general chemistry/phase/morphology/application information for materials.[59] We extracted these templates for seed-mediated gold nanorod growth from 2,969 paragraphs across 1,137 papers, starting with using a question-answering</p>
<p>framework aided by the zero-shot performance of GPT-3 to construct a small initial dataset. We then fine-tuned GPT-3 to produce complete synthesis templates for input paragraphs. Fine-tuning GPT-3 consists of using multiple examples of paragraph and synthesis template pairs to train GPT-3 to perform this specific task. Each synthesis template in the final dataset contains information on relevant synthesis precursors, precursor amounts, synthesis conditions, and characterization results, all structured in a JSON format. This dataset provides reproducible summaries of procedures and outcomes, explicitly establishing the relationships between the components of the recipe (e.g. accurately linking the correct volumes and concentrations with the correct precursors in the correct solution). However, this specificity comes at the cost of generality, as the dataset focuses on seed-mediated gold nanorod growth. The final dataset consists of 11,644 entities extracted from 1,137 papers, 268 of which contain least one complete seed-mediated gold nanorod growth procedure and outcome for a total of 332 complete procedures.</p>
<h2>II. DATASET</h2>
<p>The relevant data for constructing the training, testing, and prediction data for this model was collected using the database of gold nanoparticle synthesis protocols and outcomes developed by Cruse et al.[56] from the full-text database developed by Kononova et al.[28] through text- and data-mining agreements with several major scientific journal publishers. The original full-text database contains more than 4.9 million materials science articles, and the pipeline for identifying and extracting gold nanoparticle synthesis articles consists of progressively finer-meshed filtering steps using text-mining tools adapted from Kononova et al.[28] and Wang et al.[60] These steps include regular expression matching to identify nanomaterial papers, document and vocabulary vectorization using term frequency-inverse document frequency (TF-IDF) to reveal papers related more to gold than other noble metals, BERT-based binary classifiers to identify paragraphs related to gold nanoparticle synthesis or characterization (particularly morphological information), a combination of BiLSTM-based named entity recognition (NER) and rules-based methods to extract synthesis procedure details from synthesis paragraphs, and MatBERT[49] NER to extract morphology and size information from characterization paragraphs.</p>
<p>Using the extracted information, 5,145 papers were identified to contain gold nanoparticle synthesis protocols,[61] of which 1,137 papers were found to contain seed-mediated recipes using the "seed_mediated" flag as well as rodlike morphologies ("rod or "NR" in "morphologies" under "morphological_information") or aspect ratio measurements ("aspect" or "AR" in "measurments" under "morphological_information"). This was done to filter the total papers down to only those likely to contain seed-mediated synthesis
recipes for gold nanorods.</p>
<h2>III. Methods</h2>
<p>At the core of the GPT-1 model was a focus on improving language understanding by generative pre-training involving the use of a large language model in conjunction with a very large and diverse pre-training corpus with long stretches of contiguous text, which greatly facilitated the model's ability to learn "world knowledge" alongside its ability to process long-range dependencies.[62] For a sequence-to-sequence generative model, outputs are generated by maximizing the log probability of $p$ (output|input).[57] To further improve zero-shot performance for both learning and task transfer, GPT-2 modified the training objective to include task conditioning, $p$ (output|input, task), thus establishing the model as an unsupervised multitask learner.[63] With GPT-3, more extensions of the model size and the pre-training corpus have produced a model with considerable capacity for few-shot learning that is capable of producing text that is difficult to distinguish from human-written text or performing tasks it was not explicitly trained on, such as writing code or summing numbers.[58] We employed the 175 billion parameter variant of GPT-3 (OpenAI Davinci) for this work.</p>
<p>Of the 1,137 papers identified to contain information about seed-mediated gold nanorod synthesis, 240 (consisting of 661 relevant paragraphs) were randomly sampled and fully annotated with JSON-formatted recipes by a single annotator with machine assistance to serve as a training set. An additional 40 papers (consisting of 117 paragraphs) were used for prediction and corrected to serve as a testing set. Each relevant paragraph was separately annotated due to length constraints imposed by GPT-3, which limits the capability to process an entire article at once. A limit of 2,048 tokens is shared between the input prompt and the output completion, corresponding to approximately 1,500 words.[58]</p>
<h2>a. Overall Procedure</h2>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Fig. 1: A diagram illustrating the overall procedural approach for extracting synthesis templates from text with GPT-3 is shown. All unstructured text paragraphs were drawn from the seed-mediated gold nanorod growth dataset of 1,137 papers (purple). The first stage involves filling initial templates using a zero-shot question/answer framework with GPT-3, which is then corrected (orange). The plus sign indicates a combination of the texts and queries used as input. Template correction is done through manual editing of the templates. These corrected templates are used to fine-tune an initial GPT-3 model, which produces complete templates in a single prediction (green). From there, the process of iteratively predicting more templates with a fine-tuned model, correcting them, adding them to the training set, and then fine-tuning the model again is then performed (blue). The plus signs for these stages indicate that text-template pairs are used as input for fine-tuning.</p>
<p>A diagram outlining the general process for producing the final fine-tuned model for template-filling is shown in Figure 1. In the initial stage (orange), a simple question-answering framework is used to individually fill in templates for an initial set of paragraphs. These results are then corrected and used as an initial training set for fine-tuning GPT-3 to produce complete templates in the second stage (green). The final stage is an iterative training process in which new templates are predicted, corrected, and added to the training set to update the fine-tuned model, thus improving its performance with each iteration. All input texts for each stage are drawn from the original dataset of synthesis text filtered down to paragraphs likely to describe seed-mediated gold nanorod growth (purple). Default settings through the OpenAI API are used for all fine-tunes of the GPT-3 Davinci
model, and a temperature of zero is used for all model predictions with a double line break as the stop sequence.</p>
<h2>b. Template Structure and Annotation Scheme</h2>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Fig. 2: A diagram representing the structure of the seed-mediated gold nanorod growth JSON template. From left to right, the structure is divided into three components, the seed solution, the growth solution, and the resulting gold nanorods. For the seed and growth solution components, there are entries for the precursors and their associated quantities, as well as entries for experimental conditions such as the age and aging temperatures of the solutions and stir rates when adding the reducing agent (for the seed solution) or the seed solution (for the growth solution). For the gold nanorod component, there are entries for the characterization information that may be present, including the aspect ratio (ar), length (l), and longitudinal/transverse surface plasmon resonances (l/tspr).</p>
<p>The structure and content of the synthesis templates are shown in Figure 2. The synthesis templates are stored as JSON documents, which contain three components: the seed solution, the growth solution, and the resulting nanorods. For the seed and growth solutions, the precursors and their associated volumes (vol), concentrations (concn), and/or masses are recorded, as well as the ages of the respective mixed solutions at the time of use and the temperatures (temp) at which they are aged. Furthermore, the stirring rates when adding sodium borohydride $(\mathrm{NaBH} 4)$ to the seed solution and when adding the seed solution to the growth solution are recorded.</p>
<p>The shape and size of the gold seeds in the seed solution are also noted. For the gold nanorods (AuNR), the aspect ratios (ar), lengths (l), widths (w), and longitudinal/transverse surface plasmon resonances (SPRs) are recorded. The JSON documents have identical structures and thus contain an entry for every value that can be requested; any values not present in a given paragraph are filled with an empty string.</p>
<p>When available, numerical quantities with units are extracted. For precursor volumes, the units are provided in variations of liters, though the concentrations may be measured in either molarity, molality, or weight percentage. In some cases, the total volume of a collection of precursors may be specified instead of the individual volumes of the precursors. In this case, the explicit volume is associated with the first precursor and the volumes for the remaining precursors refer to the name of the first precursor, implicitly communicating a shared volume. For temperatures, degrees Celsius are most commonly provided, though more qualitative descriptions such as "room temperature" will still be recorded if the explicit temperature is not provided in the text but a qualitative description is. Similarly, for solution ages, minutes or hours are most common, but sometimes only descriptions like "overnight" are provided and recorded. For stirring rates, the revolutions per minute (rpm) is preferred, but many papers will instead provide descriptions such as "gentle" or "vigorous" that are recorded. For the gold nanorod properties, aspect ratios are unitless while the other quantities (length, width, SPRs) are provided in units of length, with the exception of some cases where the LSPR is only provided as "NIR" (near-infrared). Throughout all stages of the annotation process, three additional researchers were consulted to reach a consensus on the appropriate annotations for various edge cases caused by unclear wording or other ambiguities.</p>
<h2>c. Question Answering Completions</h2>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Fig. 3: An example of a question answering completion using GPT-3. The input is bounded by a purple box containing the prompt (orange), paragraph text (green), and query (blue). The output is bounded by a red box.</p>
<p>Unfortunately, the standard pre-trained GPT-3 Davinci model is not capable of providing consistent completed tem-
plates of high quality in one request. However, the model is capable of answering simple questions about synthesis paragraphs without any fine-tuning, which allows for the fields of the synthesis templates to be individually filled using answers from a simple question-answering framework using GPT-3. An example is shown in Figure 3.[64] This machineassisted annotation approach avoids the laborious process of manually filling in each field of the templates by hand, as an annotator only needs to verify and correct the provided answers as-needed. However, this approach does not scale well to large numbers of papers, as each query is a separate model request, meaning that each paragraph in each paper would require a large number of requests in order to fill a single template. Therefore, this approach is used to construct an initial dataset consisting of synthesis templates for paragraphs from a small number of papers. Due to the small number of papers used, this initial dataset does not necessarily capture the variety of precursors or manners in which critical data can be communicated in text. Nevertheless, these initial templates, when corrected, provide a suitable starting point for fine-tuning GPT-3 to provide complete synthesis templates in single requests for each paragraph. Through an iterative process of fine-tuning GPT-3 on the available templates, predicting new templates, correcting them, and fine-tuning a new model using all of the corrected templates constructed thus far, a final fine-tuned model can be obtained.</p>
<p>The initial synthesis template dataset was constructed using the zero-shot question-answering framework with 40 randomly sampled papers. If a relevant precursor, condition, or characterization was identified with regular expression pattern matching in the paragraph, the framework would be to request the information using GPT-3. For example, if "ascorbic acid", "AA", "vitamin C", or "C6H8O6" appeared in the paragraph, the framework would request the volume, concentration, and mass of ascorbic acid. This initial dataset only requested information about the eight most common precursors, including "HAuCl4", "CTAB", and "NaBH4" for the seed solution, and "HAuCl4", "CTAB", "AgNO3", "AA", and "seed solution" for the growth solution. To capture different ways of expressing each precursor, multiple aliases were checked to include variations on chemical names as well as the chemical formulas. Additionally, the framework requested information about the stir rate when adding $\mathrm{NaBH}_{4}$ to the seed solution, the age of the seed solution, the temperature of the seed solution during aging, the size and shape of the seeds, the stir rate when adding the seed solution to the growth solution, the age of the growth solution, and the temperature of the growth solution during aging. All request completions for each paragraph were aggregated into a single JSON entry according to the synthesis template scheme shown in Figure 2.</p>
<p>The approach of using zero-shot GPT-3 question answering requests to fill the templates tended to produce poor re-</p>
<p>sults, but it offered an acceptable starting point for collecting structured recipes. Most of the templates only required correcting the incorrect entries, rather than filling them in manually from scratch, which greatly accelerated the creation of the initial dataset. However, some entries had to be added from scratch due to recipes including precursors outside the initial set of eight common precursors. Note that the static nature of the synthesis templates across all paragraphs means that when one paragraph requires the addition of a new precursor to the template, this is applied to all templates for all paragraphs. Additionally, annotation was done strictly, requiring that the synthesis method must be seed-mediated growth and the target gold nanoparticle morphology must be nanorods. This provides an important test for the model, as the difference between recipes that produce very similar morphologies can sometimes be subtle.</p>
<h2>d. Fine-tuning Procedure and Dataset Construction</h2>
<p>These corrected templates derived from the question answering completions provided an initial training set for finetuning GPT-3 to produce the desired filled templates. From there, templates for paragraphs from 40 more randomly sampled papers were iteratively predicted, corrected (adding new precursors as necessary), and added to the training set until templates for paragraphs from 240 papers had been corrected in total. With each iteration, the correction process became much easier and faster. Initially, templates for information-dense paragraphs took approximately 4 minutes to validate and correct, whereas, by the end of the process, they took around a minute each. This is because GPT-3 largely predicted filled templates with high accuracy. The testing dataset was composed of paragraphs from an additional random sampling of 40 papers. Not all of the papers filtered from the original dataset were guaranteed to contain information that should be placed into synthesis templates. For example, seed-mediated growth or nanorod measurements and morphologies may only be incidentally mentioned in a given paragraph that is otherwise not relevant to a specific seed-mediated gold nanorod growth procedure. Of the 240 papers in the training set and the 40 papers in the testing set, 141 and 23 papers respectively contained at least one paragraph with information that could be placed into a synthesis template.</p>
<h2>IV. ReSults</h2>
<p>The described training dataset of synthesis templates was used to fine-tune a GPT-3 model to reproduce said synthesis templates from the unstructured text. Default parameters for the fine-tuning process were employed, incurring a cost of 85.30 USD. The predictions over the testing dataset ( 40 papers composed of 117 paragraphs) took around eighty minutes to complete and incurred a cost of 14.39 USD. The
performance of the fine-tuned model was then evaluated using the corrected testing dataset.</p>
<h2>a. Error Evaluation Examples and Definitions</h2>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Fig. 4: A model prediction example is shown, with empty entries omitted. The original unstructured text is shown on the left, and the components of the predicted synthesis template in JSON form are shown on the right. The important information from the unstructured text is colored in orange (for precursors) and green (for quantities), while any errors are highlighted in red.</p>
<p>An example prediction is depicted in Figure 4.[65] Errors are highlighted in red. For this example, two errors were made. First, the quantities for "Borohydride" in the seed solution were instead placed under "NaBH4" in the seed solution. Arguably, this is not truly an error since sodium borohydride is often conventionally referred to as "borohydride", possibly indicating "world knowledge" exhibited by GPT-3.</p>
<p>However, there are technically other borohydrides, such as potassium borohydride, that can be used as a reducing agent for seed-mediated gold nanorod growth, [66] so this was still marked as incorrect due to possible ambiguity. The second error was the failure to extract the HCl volume. Note the rather complex relationship in the growth solution precursor volumes, where CTAB, HAuCl4, ascorbic acid, AgNO3, and HCl all share the same 25 mL volume. To avoid confusion, the volume is explicitly associated with the first-mentioned precursor in the mixture, and the following precursors refer back to that first precursor. This ensures that downstream applications can unambiguously process the data to mean that the precursors are sharing a single volume. Other than these two errors, the model performs very well at extracting quantities in this example.
<img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Fig. 5: A diagram depicting the different types of prediction errors made by the model is presented. Generally, two categories of errors exist: placement errors and transcription errors. Placement errors refer to whether the prediction has placed any information, correct or incorrect, into the appropriate fields as determined by the ground truth. These are indicated with the lines connecting the fields in the ground truth and the prediction templates. A false positive prediction occurs when the prediction places information in a field that is empty, while a false negative prediction is the reverse. A true negative prediction is when a field is empty in both the ground truth and the prediction, and a true positive prediction is when a field is non-empty in both the ground truth and the prediction. Since the placement evaluations do not consider whether the predicted value in a field is actually correct for true positives, an additional transcription evaluation is used to measure how well the predicted value explicitly matches the ground truth value. These are indicated with boxes encapsulating the fields. The transcription evaluation is only applied to true positive placements.</p>
<p>For the 117 testing paragraphs, two types of errors are tracked: placement errors and transcription errors. This is done in order to evaluate the model's capability for separately identifying which fields of the synthesis templates should contain information, as well as how accurate the appropriately placed information is. To evaluate information place-
ment, only the existence of information in the fields of the prediction and ground truth synthesis templates are considered. For example, if the same field contains information (as opposed to being empty) in both templates, that is considered a true positive prediction regardless of whether the information explicitly matches. If both fields are empty, then that is a true negative. If the prediction field contains information while the ground truth field is empty, then that is a false positive, while the reverse is a false negative. These categories of placement errors are used to calculate the precision, recall, and F1-score for information placement. Examples of these evaluations are shown in Figure 5.</p>
<p>For evaluating transcription accuracy, only the agreement between the prediction and the annotation for true positive placements are considered, as the other types of errors are accounted for by the evaluations of information placement. For numerical values with units, the units must be exactly correct and the quantitative relative error was calculated according to the function $s(p, q)=2 \cdot \min (p, q) /(p+q)$, which is derived from the absolute proportional difference $r(p, q)=$ $|p-q| /(p+q)$ and is bounded on $[0,1]$ for non-negative $p$ and $q$. Some values may have modifiers attached, such as " $&gt;3 \mathrm{~h}$ ". If the prediction misses this information, e.g., gives " 3 h ", the prediction is considered half-correct even if the quantity and unit are both correct. Some quantities will additionally be expressed as a range or list of values. In these cases, the range boundaries are split into a list as necessary, and the transcription accuracies are scored and aggregated across the values in the list with proper ordering enforced. For non-numerical predictions such as stir rates described as "vigorous" or gold seed morphologies, an exact string match is required for the prediction to be marked as correct. The combined accuracy is presented as the product of the F1score for information placement and the transcription accuracy.</p>
<h2>b. Model Performance</h2>
<p>The total performance of the model aggregated over each recipe component as well as all entries is shown in Table 1. The model appears to be proficient at generally identifying which information should be filled in the template based on the content of the text, with a rather high F1-score of $90 \%$ that favors neither precision nor recall. It additionally performs exceptionally at accurately transcribing the information to provide an impressive overall score of $86 \%$. This indicates a significant improvement over comparable efforts in solid-state synthesis text-mining, which report an overall accuracy of $51 \%$ for extracting all recipe items (chemistry, operations, and attributes of the operations).[28] Direct comparison is, however, rather challenging, as some aspects of the two-step, seed-mediated growth synthesis are more complicated, such as the presence of two solutions with distinct precursor sets and a greater amount of precursor informa-</p>
<p>Table 1: Model F1-scores and accuracies for recipe entities aggregated by recipe component. The support numbers in parentheses account for only the true positives used for the accuracy calculation.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: left;">Placement</th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: left;">Transcription</th>
<th style="text-align: left;">Combined</th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Precision</td>
<td style="text-align: left;">Recall</td>
<td style="text-align: left;">F1</td>
<td style="text-align: left;">Accuracy</td>
<td style="text-align: left;">Adj. F1</td>
<td style="text-align: left;">Support</td>
</tr>
<tr>
<td style="text-align: left;">Seed Solution</td>
<td style="text-align: left;">0.97</td>
<td style="text-align: left;">0.92</td>
<td style="text-align: left;">0.94</td>
<td style="text-align: left;">0.95</td>
<td style="text-align: left;">0.90</td>
<td style="text-align: left;">$159(142)$</td>
</tr>
<tr>
<td style="text-align: left;">Growth Solution</td>
<td style="text-align: left;">0.90</td>
<td style="text-align: left;">0.94</td>
<td style="text-align: left;">0.92</td>
<td style="text-align: left;">0.96</td>
<td style="text-align: left;">0.88</td>
<td style="text-align: left;">$244(206)$</td>
</tr>
<tr>
<td style="text-align: left;">AuNR</td>
<td style="text-align: left;">0.79</td>
<td style="text-align: left;">0.74</td>
<td style="text-align: left;">0.76</td>
<td style="text-align: left;">0.95</td>
<td style="text-align: left;">0.72</td>
<td style="text-align: left;">$96(59)$</td>
</tr>
<tr>
<td style="text-align: left;">Overall</td>
<td style="text-align: left;">$\mathbf{0 . 9 0}$</td>
<td style="text-align: left;">$\mathbf{0 . 9 0}$</td>
<td style="text-align: left;">$\mathbf{0 . 9 0}$</td>
<td style="text-align: left;">$\mathbf{0 . 9 6}$</td>
<td style="text-align: left;">$\mathbf{0 . 8 6}$</td>
<td style="text-align: left;">$499(407)$</td>
</tr>
</tbody>
</table>
<p>Table 2: Model performance for precursor detection in the seed and growth solution information.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: left;">Seed Solution</th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: left;">Growth Solution</th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Precision</td>
<td style="text-align: left;">Recall</td>
<td style="text-align: left;">F1</td>
<td style="text-align: left;">Support</td>
<td style="text-align: left;">Precision</td>
<td style="text-align: left;">Recall</td>
<td style="text-align: left;">F1</td>
<td style="text-align: left;">Support</td>
</tr>
<tr>
<td style="text-align: left;">Precursor</td>
<td style="text-align: left;">0.98</td>
<td style="text-align: left;">0.90</td>
<td style="text-align: left;">$\mathbf{0 . 9 4}$</td>
<td style="text-align: left;">61</td>
<td style="text-align: left;">0.93</td>
<td style="text-align: left;">0.92</td>
<td style="text-align: left;">$\mathbf{0 . 9 2}$</td>
<td style="text-align: left;">118</td>
</tr>
</tbody>
</table>
<p>tion needed due to the solution-based format. On the other hand, solid-state synthesis extraction carries its own challenges, considering the greater variation in procedural steps and conditions that must be considered.</p>
<p>It is clear that the F1-scores for the recipe entities associated with the seed and growth solutions are very promising, indicating that the model is reliable for extracting the necessary information from the text for the component solutions to the synthesis procedure. However, the performance is worse overall for the gold nanorod properties, with an adjusted F1-score of approximately $72 \%$. This is still an improvement over established results, however, as the gold nanoparticle synthesis protocol and outcome database developed by Cruse et al.,[56] extracts morphology measurements, sizes, and units with F1-scores of $70 \%, 69 \%$, and $91 \%$ via NER with MatBERT, without linking them together. This would inevitably introduce additional sources of error and performance would be additionally constrained by the lowest performing extractions.</p>
<p>Table 2 shows the model performance for detecting precursors in the seed and growth solutions. Precursor detection is calculated implicitly based on which precursors the extracted volumes, concentrations, and masses are associated with. This is a clear improvement over the results in the gold nanoparticle synthesis protocol and outcome database developed by Cruse et al.,[56]. The prior work detected precursors via a BiLSTM-based NER model with an F1-score of $90 \%$ without distinguishing between seed or growth solution precursors and additionally without the capability for detecting precursors that do not contain specific formulae or chemical names, such as the seed solution that is added to the growth solution. The fine-tuned GPT-3 model missed cases where cationic surfactant, $\mathrm{PP}, \mathrm{BH}<em 3="3">{4}$, and $\mathrm{AuCl}</em>$ were used as well as a case where HCl was used in the seed solution. None of these cases occurred in the training set. Notably, the model correctly normalized "AsA" to "AA", despite "AsA" never appearing in the training data.</p>
<h2>c. Full Dataset</h2>
<p>The fine-tuned GPT-3 model was applied to the full dataset of 1,137 papers (2,969 paragraphs) at a total cost of 384.31 USD over 33 hours. In total, 11,644 entities were extracted from the paragraphs that contained information of interest. The dataset is presented as a JSON file containing a list with each element corresponding to a single article. Table 3 summarizes the structure of the JSON documents for each paper alongside a breakdown of how the total extracted entities across the entire dataset are distributed across the entity types. While the template extractions were performed paragraph-by-paragraph, the templates have been merged by article for convenience. However, this does mean that some conflicts and repetitions are present in the dataset. A conflict arises when a particular entity type in a paper (e.g. the volume of a particular precursor) is specified with different values across multiple paragraphs and a repetition arises when it is specified with the same value across multiple paragraphs. Of the 11,644 extracted entities, 10,098 ( $\sim 87 \%$ ) are uniquely identified, meaning there are no conflicts or repetitions (the associated value is extracted from exactly one paragraph). An additional 353 entries present at least one conflict without any repetitions, 251 with at least one repetition and no conflicts, and 57 with both conflicts and repetitions. Repetitions do not need to be manually resolved since this arises from the specification of identical information across multiple paragraphs (e.g. mentioning the gold nanorod aspect ratios in paragraphs about both the synthesis procedure as well as the nanorod characterization), but conflicts can be challenging to resolve in a consistent manner without manual inspection. For instance, if two separate volumes for a particular precursor are provided in two separate paragraphs, it can be ambiguous whether the volumes are part of the same synthesis procedure or distinct synthesis procedures in the same paper due to the lack of cross-paragraph context. With this in mind, of the 11,644 extracted entities, 10,349 ( $\sim 89 \%$ ) can be safely extracted by automatically resolving repetitions and discarding entities with conflicts. Of the entities with con-</p>
<p>Table 3: A table depicting the format of each data record for each article in the dataset is presented (constructed by merging paragraph templates). The "doi" key contains the article DOI and the "text" key contains index keys of the relevent paragraphs within that article which in turn contain the paragraph text. The "seed" and "growth" keys respectively contain the keys for the seed and growth solution information, including the "prec" key for precursors, the "stir" key for stir rates (when adding the reducing agent for the seed solution and when adding the seed solution for the growth solution), the "temp" key for the aging temperature, and the "age" key for the solution aging time. The "seed" key has an additional "seed" key that contains the "size" and "shape" keys for the size and shape of the seeds in the seed solution. The "prec" key for each solution contains multiple keys for each precursor in each solution, anonymized as "<precursor name>" in the table. For each precursor, there are three keys: "vol", "concn", and "mass" for the precursor volume, concentration, and mass, respectively. The "AuNR" key contains keys for measurements of gold nanorod dimensions: "ar", "l", "w", "lspr", and "tspr" for the aspect ratio, length, width, LSPR, and TSPR, respectively. Each extracted value is additionally stored as a key with a corresponding list of the paragraph indices that the value was extracted from in order to preserve information about entity sources. The final column displays the total number of entities extracted for each key (with no subkeys).</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Root Key</th>
<th style="text-align: center;">First Subkey</th>
<th style="text-align: center;">Second Subkey</th>
<th style="text-align: center;">Third Subkey</th>
<th style="text-align: center;">Description</th>
<th style="text-align: center;">Total</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">doi</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Article DOI</td>
<td style="text-align: center;">1137</td>
</tr>
<tr>
<td style="text-align: center;">text</td>
<td style="text-align: center;"><integer></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Paragraph text for <integer> ${ }^{\text {th }}$ paragraph</td>
<td style="text-align: center;">2969</td>
</tr>
<tr>
<td style="text-align: center;">seed</td>
<td style="text-align: center;">prec</td>
<td style="text-align: center;"><precursor name></td>
<td style="text-align: center;">volume</td>
<td style="text-align: center;">Seed solution precursor volume</td>
<td style="text-align: center;">1347</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">concentration</td>
<td style="text-align: center;">Seed solution precursor concentration</td>
<td style="text-align: center;">1385</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">mass</td>
<td style="text-align: center;">Seed solution precursor mass</td>
<td style="text-align: center;">6</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">seed</td>
<td style="text-align: center;">size</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Seed solution seed size</td>
<td style="text-align: center;">137</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">shape</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Seed solution seed shape</td>
<td style="text-align: center;">24</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">stir</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Seed solution reducing agent stir rate</td>
<td style="text-align: center;">266</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">temp</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Seed solution aging temperature</td>
<td style="text-align: center;">284</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">age</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Seed solution aging time</td>
<td style="text-align: center;">352</td>
</tr>
<tr>
<td style="text-align: center;">growth</td>
<td style="text-align: center;">prec</td>
<td style="text-align: center;"><precursor name></td>
<td style="text-align: center;">volume</td>
<td style="text-align: center;">Growth solution precursor volume</td>
<td style="text-align: center;">2664</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">concentration</td>
<td style="text-align: center;">Growth solution precursor concentration</td>
<td style="text-align: center;">2178</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">mass</td>
<td style="text-align: center;">Growth solution precursor mass</td>
<td style="text-align: center;">65</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">stir</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Growth solution reducing agent stir rate</td>
<td style="text-align: center;">134</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">temp</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Growth solution aging temperature</td>
<td style="text-align: center;">322</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">age</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Growth solution aging time</td>
<td style="text-align: center;">464</td>
</tr>
<tr>
<td style="text-align: center;">AuNR</td>
<td style="text-align: center;">ar</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Gold nanorod aspect ratio</td>
<td style="text-align: center;">587</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Gold nanorod length</td>
<td style="text-align: center;">443</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">w</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Gold nanorod width</td>
<td style="text-align: center;">452</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">1spr</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Gold nanorod LSPR</td>
<td style="text-align: center;">357</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">tspr</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Gold nanorod TSPR</td>
<td style="text-align: center;">177</td>
</tr>
</tbody>
</table>
<p>Table 4: A table depicting the format of each extracted value in the post-processed version of the dataset.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Key</th>
<th style="text-align: left;">Structure</th>
<th style="text-align: left;">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">mod</td>
<td style="text-align: left;">$&lt;$ modifier&gt;</td>
<td style="text-align: left;">A string indicating if a value is a range, ap- <br> proximate, bounding, or unprocessed.</td>
</tr>
<tr>
<td style="text-align: left;">val</td>
<td style="text-align: left;">$[&lt;$ value $&gt;, \ldots,&lt;$ value $&gt;]$</td>
<td style="text-align: left;">A list of the extracted values. Ranges will <br> consist of two values for the range bound- <br> aries. Processed values will be numbers <br> while unprocessed values will be strings.</td>
</tr>
<tr>
<td style="text-align: left;">unit</td>
<td style="text-align: left;">$&lt;$ unit&gt;</td>
<td style="text-align: left;">The units for the extracted values, if appli- <br> cable, as a string.</td>
</tr>
<tr>
<td style="text-align: left;">src</td>
<td style="text-align: left;">$[[&lt;$ index $&gt;, \ldots,&lt;$ index $&gt;], \ldots,[\ldots]]$</td>
<td style="text-align: left;">A list of lists of paragraph indices to indi- <br> cate the source for the extracted informa- <br> tion.</td>
</tr>
<tr>
<td style="text-align: left;">index</td>
<td style="text-align: left;">$[[&lt;$ index $&gt;, \ldots,&lt;$ index $&gt;], \ldots,[\ldots]]$</td>
<td style="text-align: left;">A list of lists of positional indices to retain <br> ordering for values that were split from a <br> list during post-processing.</td>
</tr>
</tbody>
</table>
<p>flicts, 341 have two distinct values, 47 have three, 12 have five, 9 have four, and 1 has five.</p>
<h2>d. Full Dataset Analysis</h2>
<h2>1. Procedure Completeness Analysis</h2>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Fig. 6: A diagram showing the proportional overlaps of papers with complete synthesis procedure and outcome components. Each vertex of the triangle corresponds to the labeled recipe component. The areas of the circles are proportional to the corresponding number of papers inscribed. The circles on the midpoints of the edges correspond to papers with complete recipe components corresponding to the bounding vertices. The center circle corresponds to the papers with complete recipes and complete characterizations.</p>
<p>With post-processing applied (as was done for evaluation of the testing dataset), splitting lists of extracted values into distinct entities and resolving repetitions of identical information extracted across different paragraphs within the same papers results in a total of 11,770 unique entities. In the postprocessed version of the dataset, each property contains a list of dictionaries with structures indicated in Table 4.</p>
<p>An ideal database of gold nanorod growth procedures should contain fully-specified, reproducible procedures alongside their outcomes. This is desirable because missing information could inhibit downstream applications that need complete information about the synthesis procedure. For instance, if a scientist wants to reproduce an experiment that produces gold nanorods of a particular aspect ratio, they would at the very least need to know all of the relevant seed and growth solution precursors with their amounts. Similarly, a data science project that intends to investigate the relationship between procedures and outcomes will need complete information for the seed and growth solutions in addition to the gold nanorod measurements in order to produce reliable predictions. To evaluate the completeness of the information this dataset contains, we examined 1,137 papers in the full prediction dataset. Of these, 701 (62\%) contained at least one paragraph with a non-empty synthesis template. Of these 701 papers, 678 (97\%) fully specified at least one synthesis component: the seed solution, the growth solution, or the gold nanorod dimensions. This is encouraging since the vast majority of the papers that contain information at least fully specify one component of the procedure or the outcome.</p>
<p>In order to evaluate the completeness of the components of the procedure and the outcome, for seed and growth solutions, only fully specified precursors were considered necessary for reproducibility. Auxiliary information, such as stirring rates, aging times, aging temperatures, and seed particle morphologies and sizes, while useful, was not considered necessary. The precursor information was considered to be full specified for a given paper if all of the precursor quantities were fully specified with either volume and concentration, mass, or a specific concentration within another solution for each precursor with extracted quantities. Exceptions were made for water and the seed solution that is added to the growth solution, which both only needed a reported volume or mass. Additionally, seed solution in the growth solution precursors was required for the growth solution precursors to be considered complete. For the gold nanorod dimensions to be considered complete, either the aspect ratio, length, or LSPR measurement had to be specified, with the latter two at least providing an avenue for estimation of the aspect ratio if reported alone.</p>
<p>Figure 6 shows how the papers in the full prediction dataset are distributed across fully-specified synthesis procedure and outcome components according to these criteria. The vast majority of the papers reported gold nanorod dimensions, with $80 \%$ of the 678 papers with at least one fully specified synthesis component containing fully-specified gold nanorod dimensions. Additionally, the majority of the papers fully-specified the seed and growth solutions (respectively $61 \%$ and $67 \%$ ). However, they are distributed such that $40 \%$ (268) of the papers fully specified all three components. This is a reasonable result considering that many papers will
directly report the relevant gold nanorod dimensions without specifying a synthesis procedure, opting instead to reference the established recipe that the researchers used to produce the gold nanorods. Additionally, some researchers will opt to purchase gold seed solution instead of producing their own, which accounts for cases where some papers are missing information about seed solution preparation. Most of the papers with fully-specified synthesis procedures and outcomes (162) used the typical 8 -precursor synthesis and an additional 49 use the same synthesis precursors with the addition of HCl in the growth solution. In the post-processed version of the dataset, it is determined that of the 268 papers that fully specified all three components, 233 contained exactly one procedure. An additional 16 contained two, 13 contained three, 3 contained four, 2 contained five, and 1 contained six for a total of 332 complete procedures. This final dataset should be suitable for downstream analysis and inference, given the overall model performance for extracting complete synthesis procedures and outcomes from the literature.</p>
<h2>2. Data Consistency Analysis</h2>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Fig. 7: A diagram showing the relationships between the gold nanorod aspect ratios and other gold nanorod measurements extracted from the literature including the (a) ratio between length and width and (b) the LSPR peak. The inlier datapoints are shown in purple and the outlier datapoints in red. The linear regressions derived from the text-mined data using all of the available data and only the inlier data are respectively shown in red and purple on each sub-diagram. For the comparison to the ratio between length and width (a), the ideal relation is shown with a dashed black line and for the LSPR comparison (b), a simulated relationship is shown with a dashed black line.[67]</p>
<p>Figure 7 shows the relationship between various measurements extracted from text compared to the aspect ratios extracted from the text. Only co-occurring measurements explicitly present within the extracted information from a given paragraph are considered data points for comparison. No derived measurements were used. As a sanity check, the first diagram (a) shows the relationship between the ratios of the explicit lengths and widths present in the text (excluding ranges) and the reported aspect ratios. Ideally, the relationship should be an identity as shown with the dashed line. However, while the vast majority of the data approximately complies with this trend, there are several outliers that produce deviation from the ideal trend in the regression of the text-mined data. This is primarily caused by two papers
with mismatches in measurements extracted from three-step seed-mediated gold nanorod overgrowth procedures where the dimensions of the nanorod seeds used for overgrowth into nanowires are confused with the dimensions of the nanowires themselves. With all outliers removed via outlier detection using an elliptic envelope followed by manual verification, the linear regression almost exactly matches the ideal relationship. The most common errors were caused by nanorod overgrowth measurements taken from three-step seed mediated growth procedures and cases in which the ordering of the aspect ratios and the lengths and widths were mismatched (e.g. the lengths and widths are listed while the aspect ratios are presented as a range). Only 8 of the 78 data points were identified as outliers. For the comparison between the LSPR peaks and the aspect ratios (b), a strong linear trend is similarly present. However, for this relationship, there is an additional comparison to a relationship derived from simulation using a set refractive index for gold nanorods shown in blue, which is in general agreement with the relationship derived from text-mined empirical data.[67] The deviations can be explained by multiple factors including deviations from ideal conditions shifting the LSPR peaks such as deviation from spherical end-cap geometries, low nanorod yields, or impurities in the gold nanorod solution or the nanorods themselves that change the refractive index (including poor cleaning or high concentrations of silver in procedures using $\mathrm{AgNO}_{3}$ ). [67, 68] While there are extraction errors present, outlier removal using an elliptic envelope followed by manual verification does not significantly change the linear regression. Outliers were most commonly caused by extraction errors that swapped the LSPR and TSPR measurements provided in the text. Only 9 of the 86 data points were identified as outliers. Deviation from the theory in such a manner is to be expected when considering empirical data from realworld experiments. Still, the LSPR for spheres should be around 520 nm while the text-mined trend line points towards a value closer to $580 \sim 590 \mathrm{~nm}$. However, for larger aspect ratios, the text-mined trend line is more representative of the text-mined empirical data than the trend line derived from simulation. The major outlier present in the text-mined data is once again explained by a mismatch in measurements from a three-step seed-mediated gold nanorod overgrowth procedure.</p>
<h2>3. Gold Nanorod Aspect Ratio Distribution Analysis</h2>
<p><img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Fig. 8: A diagram showing the distributions of gold nanorod aspect ratios resulting from different precursor sets including the (a) standard procedure, (b) the addition of HCl in the growth solution, and (c) all complete precursor sets. Negligible contributions for aspect ratios larger than 20 are not shown $(P(A R&gt;12)&lt;0.02)$. In each sub-diagram, the median is shown with a solid black line and the first and third quartiles are shown with dashed black lines.</p>
<p>Figure 8 shows the distributions of the aspect ratios extracted from fully-specified experiments using precursor sets found in more than 10 papers in the full prediction database (Figures 8a and 8b), in addition to the complete set of papers (Figure 8c). For many of the papers, the aspect ratios were directly reported. However, there are multiple different ways that they are reported that must be addressed in order to properly construct the distributions. If the aspect ratio is provided as a range of values, the distribution across that range was taken to be a normal distribution with a mean and standard deviation determined by the midpoint and endpoints of the range, respectively. For papers that did not report aspect ratios directly, length and width information was used instead. In cases where the lengths and widths were presented as ranges, they were similarly cast as normal distributions, and the distributions of the aspect ratios were calculated as ratio distributions. For cases where only the LSPR was provided, the text-mined linear relationship with outliers removed shown in Figure 7 was used to estimate the aspect ratios. In cases where any quantities were accompanied by an approximation modifier (e.g. $\sim$ ), the values were cast as uniform distributions over the range of $\pm 10 \%$ of the value. Any calculated aspect ratios that fell below 1 (e.g. due to overlaps in length and width distributions for gold nanorods
with small aspect ratios) were inverted.
From the distribution of the standard recipe, it is readily apparent that the median nanorod aspect ratio is 3.3 with respective first and third quartiles of 2.75 and 3.98 . Comparing with experiments reporting that varying the concentration of $\mathrm{AgNO}_{3}$ in the growth solution varies the resulting nanorod aspect ratios from 1.83 to $5.04,[69]$ the distribution of gold nanorod aspect ratios text-mined from the literature is consistent with this range, though it is narrower. Notably, there is a non-negligible amount of samples with aspect ratios greater than 5 in the distribution for the standard procedure. This is not consistent with heuristic knowledge of the limitations of the standard procedure for producing large aspect ratio gold nanorods, usually due to shorter growth times compared to procedures that adjust the pH of the growth solution to retard the nanorod growth.[70, 71] This is primarily due to erroneous extractions of nanowire measurements from overgrowth experiments or missed precursors based on manual inspection of the data. However, the statistics are still dominated by the lower aspect ratios. Comparing to the distribution for experiments using HCl in the growth solution, it is apparent that the addition produces a distribution shifted towards larger aspect ratios. This is consistent with experiments that have determined that the use of HCl in the growth solution grants broader tunability of the gold nanorod aspect ratios, allowing for more controlled growth of longer nanorods relative to the standard procedure.[72, 73] Notably, $\sim 7 \%$ of the procedures using the standard procedure and $\sim 9 \%$ of the procedures using HCl in the growth solution provide nanorods with aspect ratios of 5 or higher. However, when all recipes are considered, it is clear that even longer nanorods can be synthesized, though these recipes are not as popular in the literature.</p>
<h2>V. DISCUSSION</h2>
<p>Overall, the model performs well at identifying and extracting relevant information specific to seed-mediated gold nanorod growth procedures in the literature. The model achieves an overall adjusted F1-score of $86 \%$ on the testing dataset, indicating that it performs rather well at the task of simultaneous entity recognition and relation extraction. However, due to the static nature of the relations provided by the synthesis template and the single inference step, the entity recognition and relation extraction tasks are not easily disentangled, which limits direct comparison with conventional two-step approaches. Instead, the model performance for information retrieval is evaluated according to its ability to place information into fields of the template where information should exist and then the accuracy of the information that is correctly placed. For information placement, the precision, recall, and F1-score are balanced at $90 \%$, indicating notable performance with no preference for false positives or false negatives. Of the information that is correctly</p>
<p>placed in the templates, the model predicts the specific values with $96 \%$ accuracy. Thus, the primary source of error is the accurate placement of information into the template rather than the accurate prediction of correctly placed information. However, the template model struggles with identifying new precursors that were not present in the training set.</p>
<p>The dataset produced by the model provides a wealth of information about seed-mediated gold nanorod growth experiments and, to our knowledge, constitutes the largest structured database with this level of depth and completeness. The model's ability to distinguish between precursors in the seed and growth solutions provides an example of very useful information. The simultaneous identification of precursors alongside linking them to the appropriate solutions in the two-step seed-mediated procedure had proven difficult using established methods due to the propagation of errors introduced by the reliance on separate models for entity extraction and relation. However, with this model, if a researcher wants to quickly find papers that used a particular precursor in the seed solution for seed-mediated growth of gold nanorods, this task can be accomplished with high fidelity using the predicted templates. Access to this information can be expected to greatly improve tools for scientific literature searches, as conventional simple keyword searches do not offer this specific relational dependence for complicated multi-step procedures.</p>
<p>For a more ambitious goal, the full synthesis procedure data can be leveraged for multiple downstream tasks, which would require the creation of additional models for inference. One example would be a model that predicts gold nanorod dimensions conditioned on a specific synthesis procedure: $p$ (properties|procedure). Such a model may be leveraged to predict the outcomes of proposed procedures without the need to perform them explicitly. Building on this, the inverse problem, $p$ (procedure|properties), can also be modeled. This would be very useful for streamlining synthesis experiments, as the necessary procedures for synthesizing gold nanorods with the desired properties can be inferred to provide a starting point that reduces the number of experiments that must be conducted to synthesize the desired gold nanorods. However, in the most likely case, any model trained on literature data alone will be incomplete and require further data generation and fine tuning.</p>
<p>Furthermore, it is worth considering how these templates fit into a larger project for downstream synthesis outcome predictions and synthesis procedure recommendations. The data extracted from literature can be used to pre-train models used for these purposes, while explicit experimental data can be used to further train the models to produce better predictions. The new templates provided by the experimental results are expected to be of extremely high quality, which will mitigate the errors present in the pre-training data from literature over time as more experimental results are added to
the template database.
While this dataset is restricted to seed-mediated gold nanorod growth, the flexibility and performance of the templating approach using GPT-3 motivates application to other tasks for structured information retrieval from unstructured scientific text as has been shown in recent literature.[59] To this end, the dataset can be extended to accommodate seed-mediated growth of other gold nanoparticle morphologies, which may even improve overall model performance, as many errors were caused by the model erroneously extracting information from procedures that mentioned nanorod morphologies, but synthesized a different morphology. Additionally, more complex synthesis methods, such as three-step processes in which nanorods are first synthesized via seedmediated growth to be used as seeds in a growth solution for overgrowth into nanowires, as well as other synthesis methods, such as citrate reduction, may require the creation of new templates and fine-tuning a separate model for each synthesis method to improve overall performance. Generally, it can be expected that more complex templates will require more examples for fine-tuning.</p>
<h2>VI. CONCLUSIONS</h2>
<p>The presented model for static structured templating of seed-mediated gold nanorod growth procedures extracted from unstructured text using GPT-3 is demonstrated to be a promising approach for constructing high-quality structured databases of information from the scientific literature. This approach for extracting seed-mediated gold nanorod procedures and outcomes achieves an impressive adjusted F1score of $86 \%$ for the simultaneous identification and linking of synthesis procedure components. We present a final dataset of 11,644 entities extracted from 1,137 papers, resulting in 268 papers with at least one complete seed-mediated gold nanorod growth procedure and outcome for a total of 332 complete procedures. This method can potentially be utilized for many downstream applications including procedure searches oriented around specific features, statistical analysis of synthesis outcomes, synthesis outcome predictions conditioned on procedures, and synthesis procedure recommendations conditioned on outcomes among others given the wealth of structured information present. Overall, we present this approach as a flexible candidate for generalpurpose structured data extraction from unstructured scientific text and contribute a dataset that may serve as a useful tool for investigating synthesis pathways beyond heuristics.</p>
<h2>DATA AND CODE AVAILABILITY</h2>
<p>The data composed of DOIs and associated structured JSON outputs can be found online at https://doi.org/10. 6084/m9.figshare.19719310.v3.[74] The texts for the paragraphs in each paper are excerpted due to copyright re-</p>
<p>strictions.</p>
<h2>AUTHOR CONTRIBUTIONS</h2>
<p>A.J., G.C., and K.A.P. supervised the research. K.C. wrote the data collection infrastructure, performed the data collection, and wrote and applied the initial gold nanoparticle article classification and information extraction models. S.G. provided experimental domain knowledge necessary for the template design. J.D. introduced the GPT-3 sequenceto-sequence information extraction methodology and prepared the graphic representation of the extraction template. N.W. co-developed the GPT-3 sequence-to-sequence information extraction methodology, designed the extraction templates, wrote the code for interfacing with GPT-3, performed all annotations, performed all GPT-3 experiments, and prepared all results. S.L. provided additional result validation. All authors contributed to the discussion and writing of the manuscript.</p>
<h2>CONFLICTS OF INTEREST</h2>
<p>There are no conflicts to declare.</p>
<h2>ACKNOWLEDGEMENTS</h2>
<p>This work was funded and intellectually led by the U.S. Department of Energy, Office of Science, Office of Basic Energy Sciences, Materials Sciences and Engineering Division under Contract No. DE-AC02-05CH11231 (D2S2 program KCD2S2). Additional funding used for data set generation via the OpenAI API was provided by Toyota Research Institute through the Accelerated Materials Design and Discovery program. This research used resources of the National Energy Research Scientific Computing Center (NERSC), a U.S. Department of Energy Office of Science User Facility operated under Contract No. DE-AC02-05CH11231. This work also used the Extreme Science and Engineering Discovery Environment (XSEDE) GPU resources, specifically the Bridges-2 supercomputer at the Pittsburgh Supercomputing Center, through allocation TG-DMR970008S.[75]</p>
<h2>REFERENCES</h2>
<p>[1] S. Mohan Bhagyaraj and O. S. Oluwafemi, "Chapter 1 - nanotechnology: The science of the invisible," in Synthesis of Inorganic Nanomaterials, ser. Micro and Nano Technologies, S. Mohan Bhagyaraj, O. S. Oluwafemi, N. Kalarikkal, and S. Thomas, Eds. Woodhead Publishing, 2018, pp. 1-18. [Online]. Available: https: //www.sciencedirect.com/science/article/pii/B9780081019757000014
[2] P. Colomban, M. Gironda, G. Simsek Franci, and P. d'Abrigeon, "Distinguishing genuine imperial qing dynasty porcelain from ancient replicas by On-Site Non-Invasive XRF and raman spectroscopy," Materials (Basel), vol. 15, no. 16, Aug. 2022.
[3] S. Szunerits and R. Boukherroub, "Near-infrared photothermal heating with gold nanostructures," in Encyclopedia of Interfacial Chemistry, K. Wandelt, Ed. Oxford: Elsevier, 2018, pp. 500-510.
[Online]. Available: https://www.sciencedirect.com/science/article/ pii/B9780124095472132287
[4] S. E. Lohse and C. J. Murphy, "The quest for shape control: A history of gold nanorod synthesis," Chemistry of Materials, vol. 25, no. 8, pp. 1250-1261, Apr 2013. [Online]. Available: https://doi.org/10.1021/cm303708p
[5] N. D. Burrows, S. Harvey, F. A. Idesis, and C. J. Murphy, "Understanding the seed-mediated growth of gold nanorods through a fractional factorial design of experiments," Langmuir, vol. 33, no. 8, pp. 1891-1907, Feb 2017. [Online]. Available: https: //doi.org/10.1021/acs.langmuir.6b03606
[6] L. Gou and C. J. Murphy, "Fine-tuning the shape of gold nanorods," Chemistry of Materials, vol. 17, no. 14, pp. 3668-3672, Jul 2005. [Online]. Available: https://doi.org/10.1021/cm050525w
[7] P. K. Jain, X. Huang, I. H. El-Sayed, and M. A. El-Sayed, "Noble metals on the nanoscale: Optical and photothermal properties and some applications in imaging, sensing, biology, and medicine," Accounts of Chemical Research, vol. 41, no. 12, pp. 1578-1586, Dec 2008. [Online]. Available: https://doi.org/10.1021/ar7002804
[8] E. C. Dreaden, A. M. Alkilany, X. Huang, C. J. Murphy, and M. A. ElSayed, "The golden age: gold nanoparticles for biomedicine," Chem Soc Rev, vol. 41, no. 7, pp. 2740-2779, Nov. 2011.
[9] S. Eustis and M. A. El-Sayed, "Why gold nanoparticles are more precious than pretty gold: noble metal surface plasmon resonance and its enhancement of the radiative and nonradiative properties of nanocrystals of different shapes," Chemical society reviews, vol. 35, no. 3, pp. 209-217, 2006.
[10] J. C. Hulteen and C. R. Martin, "A general template-based method for the preparation of nanomaterials," Journal of materials chemistry, vol. 7, no. 7, pp. 1075-1087, 1997.
[11] K. Sandeep, B. Manoj, and K. G. Thomas, "Gold nanoparticle on semiconductor quantum dot: Do surface ligands influence fermi level equilibration," The Journal of Chemical Physics, vol. 152, no. 4, p. 044710, 2020. [Online]. Available: https://doi.org/10.1063/1.5138216
[12] M. Lau, A. Ziefuss, T. Komossa, and S. Barcikowski, "Inclusion of supported gold nanoparticles into their semiconductor support," Phys. Chem. Chem. Phys., vol. 17, pp. 29 311-29 318, 2015. [Online]. Available: http://dx.doi.org/10.1039/C5CP04296H
[13] L. A. Dykman and N. G. Khlebtsov, "Gold nanoparticles in biology and medicine: recent advances and prospects," Acta naturae, vol. 3, no. 2, pp. 34-55, Apr 2011, 22649683[pmid]. [Online]. Available: https://pubmed.ncbi.nlm.nih.gov/22649683
[14] X. Huang and M. A. El-Sayed, "Gold nanoparticles: Optical properties and implementations in cancer diagnosis and photothermal therapy," Journal of Advanced Research, vol. 1, no. 1, pp. 13-28, 2010. [Online]. Available: https://www.sciencedirect.com/science/ article/pii/S2090123210000056
[15] S. Kaul, N. Gulati, D. Verma, S. Mukherjee, and U. Nagaich, "Role of nanotechnology in cosmeceuticals: A review of recent advances," Journal of pharmaceutics, vol. 2018, pp. 34202043420 204, Mar 2018, 29785318[pmid]. [Online]. Available: https: //pubmed.ncbi.nlm.nih.gov/29785318
[16] K. I. Requejo, A. V. Liopo, P. J. Derry, and E. R. Zubarev, "Accelerating gold nanorod synthesis with nanomolar concentrations of poly(vinylpyrrolidone)," Langmuir, vol. 33, no. 44, pp. 12 68112688, Nov 2017. [Online]. Available: https://doi.org/10.1021/acs. langmuir.7b02942
[17] Y. C. Dong, M. Hajfathalian, P. S. N. Maidment, J. C. Hsu, P. C. Naha, S. Si-Mohamed, M. Breuilly, J. Kim, P. Chhour, P. Douek, H. I. Litt, and D. P. Cormode, "Effect of gold nanoparticle size on their properties as contrast agents for computed tomography," Scientific Reports, vol. 9, no. 1, p. 14912, Oct 2019. [Online]. Available: https://doi.org/10.1038/s41598-019-50332-8</p>
<p>[18] S. A. Ng, K. A. Razak, A. A. Aziz, and K. Y. Cheong, "The effect of size and shape of gold nanoparticles on thin film properties," Journal of Experimental Nanoscience, vol. 9, no. 1, pp. 64-77, 2014. [Online]. Available: https://doi.org/10.1080/17458080.2013.813651
[19] C. Daruich De Souza, B. Ribeiro Nogueira, and M. E. C. Rostelato, "Review of the methodologies used in the synthesis gold nanoparticles by chemical reduction," Journal of Alloys and Compounds, vol. 798, pp. 714-740, 2019. [Online]. Available: https: //www.sciencedirect.com/science/article/pii/S092583881931833X
[20] E. Agunloye, L. Panariello, A. Gavriilidis, and L. Mazzei, "A model for the formation of gold nanoparticles in the citrate synthesis method," Chemical Engineering Science, vol. 191, pp. 318-331, 2018. [Online]. Available: https://www.sciencedirect.com/science/ article/pii/S0009250918304160
[21] M. L. Personick and C. A. Mirkin, "Making sense of the mayhem behind shape control in the synthesis of gold nanoparticles," Journal of the American Chemical Society, vol. 135, no. 49, pp. 18238-18247, Dec 2013. [Online]. Available: https://doi.org/10.1021/ja408645b
[22] M. Grzelczak, J. Pérez-Juste, P. Mulvaney, and L. M. Liz-Marzán, "Shape control in gold nanoparticle synthesis," Colloidal Synthesis of Plasmonic Nanometals, pp. 197-220, 2020.
[23] D. F. Mukhamedzyanova, N. K. Ratmanova, D. A. Pichugina, and N. E. Kuz'menko, "A structural and stability evaluation of au12 from an isolated cluster to the deposited material," The Journal of Physical Chemistry C, vol. 116, no. 21, pp. 11507-11518, May 2012. [Online]. Available: https://doi.org/10.1021/jp212367z
[24] M. Domingo, M. Shahrokhi, I. N. Remediakis, and N. Lopez, "Shape control in gold nanoparticles by n-containing ligands: Insights from density functional theory and wulff constructions," Topics in Catalysis, vol. 61, no. 5, pp. 412-418, May 2018. [Online]. Available: https://doi.org/10.1007/s11244-017-0880-3
[25] I. Chakraborty and T. Pradeep, "Atomically precise clusters of noble metals: Emerging link between atoms and nanoparticles," Chemical Reviews, vol. 117, no. 12, pp. 8208-8271, Jun 2017. [Online]. Available: https://doi.org/10.1021/acs.chemrev. 6600769
[26] D. V. Talapin, A. L. Rogach, M. Haase, and H. Weller, "Evolution of an ensemble of nanoparticles in a colloidal solution: theoretical study," The Journal of Physical Chemistry B, vol. 105, no. 49, pp. 12278-12285, Dec 2001. [Online]. Available: https://doi.org/10.1021/jp012229m
[27] O. Kononova, T. He, H. Huo, A. Trewartha, E. A. Olivetti, and G. Ceder, "Opportunities and challenges of text mining in materials research," iScience, vol. 24, no. 3, p. 102155, Mar 2021.
[28] O. Kononova, H. Huo, T. He, Z. Rong, T. Botari, W. Sun, V. Tshitoyan, and G. Ceder, "Text-mined dataset of inorganic materials synthesis recipes," Scientific Data, vol. 6, no. 1, p. 203, Oct 2019. [Online]. Available: https://doi.org/10.1038/s41597-019-0224-1
[29] S. Eltyeb and N. Salim, "Chemical named entities recognition: a review on approaches and applications," Journal of cheminformatics, vol. 6, pp. 17-17, Apr 2014. [Online]. Available: https://doi.org/10. 1186/1758-2946-6-17
[30] P. Corbett and J. Boyle, "Chemlistem: chemical named entity recognition using recurrent neural networks," Journal of Cheminformatics, vol. 10, no. 1, p. 59, Dec 2018. [Online]. Available: https://doi.org/10.1186/s13321-018-0313-8
[31] Z. Liang, J. Chen, Z. Xu, Y. Chen, and T. Hao, "A pattern-based method for medical entity recognition from chinese diagnostic imaging text," Frontiers in Artificial Intelligence, vol. 2, p. 1, 2019. [Online]. Available: https://www.frontiersin.org/article/10.3389/frai. 2019.00001
[32] A. Sniegula, A. Poniszewska-Maranda, and L. Chomatek, "Study of named entity recognition methods in biomedical field," Procedia Computer Science, vol. 160, pp. 260-265, 2019, the 10th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN-2019) / The 9th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (ICTH-2019) / Affiliated Workshops. [Online]. Available: https: //www.sciencedirect.com/science/article/pii/S1877050919316813
[33] K. r. Kanakarajan, B. Kundumani, and M. Sankarasubbu, "BioELECTRA:pretrained biomedical text encoder using discriminators," in Proceedings of the 20th Workshop on Biomedical Language Processing. Online: Association for Computational Linguistics, Jun. 2021, pp. 143-154. [Online]. Available: https://aclanthology.org/2021.bionlp-1.16
[34] L. Weston, V. Tshitoyan, J. Dagdelen, O. Kononova, A. Trewartha, K. Persson, G. Ceder, and A. Jain, "Named entity recognition and normalization applied to large-scale information extraction from the materials science literature," J. Chem. Inf. Model., vol. 59, pp. 36923702, 2019.
[35] T. He, W. Sun, H. Huo, O. Kononova, Z. Rong, V. Tshitoyan, T. Botari, and G. Ceder, "Similarity of precursors in solid-state synthesis as text-mined from scientific literature," Chemistry of Materials, vol. 32, no. 18, pp. 7861-7873, 2020. [Online]. Available: https://doi.org/10.1021/acs.chemmater.0c02553
[36] K. Hatakeyama-Sato and K. Oyaizu, "Integrating multiple materials science projects in a single neural network," Communications Materials, vol. 1, no. 1, p. 49, Jul 2020. [Online]. Available: https://doi.org/10.1038/s43246-020-00052-8
[37] O. Kononova, T. He, H. Huo, A. Trewartha, E. A. Olivetti, and G. Ceder, "Opportunities and challenges of text mining in materials research," iScience, vol. 24, no. 3, p. 102155, 2021. [Online]. Available: https://www.sciencedirect.com/science/article/ pii/S2589004221001231
[38] E. A. Olivetti, J. M. Cole, E. Kim, O. Kononova, G. Ceder, T. Y.-J. Han, and A. M. Hiszpanski, "Data-driven materials research enabled by natural language processing and information extraction," Applied Physics Reviews, vol. 7, no. 4, p. 041317, 2020. [Online]. Available: https://doi.org/10.1063/5.0021106
[39] T. Dieb, M. Yoshioka, S. Hara, and M. Newton, "Framework for automatic information extraction from research papers on nanocrystal devices," Beilstein J. Nanotechnol., vol. 6, pp. 1872-1882, 2015.
[40] M. Gaultois, T. Sparks, C. Borg, R. Seshadri, W. Bonificio, and D. Clarke, "Data-driven review of thermoelectric materials: Performance and resource considerations," Chem. Mater., vol. 25, pp. 29112920, 2013.
[41] N. Pang, L. Qian, W. Lyu, and J.-D. Yang, "Transfer learning for scientific data chain extraction in small chemical corpus with bert-crf model," 2019.
[42] P. Corbett and A. Copestake, "Cascaded classifiers for confidencebased chemical named entity recognition," BMC Bioinformatics, vol. 9, no. Suppl 11, p. S4, 2008.
[43] M. Krallinger, O. Rabal, A. Lourenço, J. Oyarzabal, and A. Valencia, "Information retrieval and text mining technologies for chemistry," Chem. Rev., vol. 117, pp. 7673-7761, 2017.
[44] T. Rocktäschel, M. Weidlich, and U. Leser, "Chemspot: A hybrid system for chemical named entity recognition," Bioinformatics, vol. 28, pp. 1633-1640, 2012.
[45] M. Krallinger, O. Rabal, F. Leitner, M. Vazquez, D. Salgado et al., "The cherndner corpus of chemicals and drugs and its annotation principles," J. Cheminform., vol. 7, p. S2, 2015.
[46] R. Leaman, C.-H. Wei, and Z. Lu, "tmchem: a high performance approach for chemical named entity recognition and normalization," $J$. Cheminform., vol. 7, p. S3, 2015.</p>
<p>[47] I. Korvigo, M. Holmatov, A. Zaikovskii, and M. Skoblov, "Putting hands to rest: efficient deep cnn-rnn architecture for chemical named entity recognition with no hand-crafted rules," J. Cheminform., vol. 10, p. 28, 2018.
[48] M. García-Remesal, A. García-Ruiz, D. Pérez-Rey, D. De La Iglesia, and V. Maojo, "Using nanoinformatics methods for automatically identifying relevant nanotoxicology entities from the literature," Biomed. Res. Int., vol. 2013, 2013.
[49] A. Trewartha, N. Walker, H. Huo, S. Lee, K. Cruse, J. Dagdelen, A. Dunn, K. A. Persson, G. Ceder, and A. Jain, "Quantifying the advantage of domain-specific pre-training on named entity recognition tasks in materials science," Patterns, vol. 3, no. 4, p. 100488, 2022. [Online]. Available: https://www.sciencedirect.com/science/article/ pii/S2666389922000733
[50] F. Ren, L. Ward, T. Williams, K. J. Laws, C. Wolverton, J. Hattrick-Simpers, and A. Mehta, "Accelerated discovery of metallic glasses through iteration of machine learning and high-throughput experiments," Science Advances, vol. 4, no. 4, p. eaaq1566, 2018. [Online]. Available: https://www.science.org/doi/abs/10.1126/sciadv. aaq 1566
[51] C. C. Fischer, K. J. Tibbetts, D. Morgan, and G. Ceder, "Predicting crystal structure by merging data mining with quantum mechanics," Nature Materials, vol. 5, no. 8, pp. 641-646, Aug 2006. [Online]. Available: https://doi.org/10.1038/nmat1691
[52] L. Weston, V. Tshitoyan, J. Dagdelen, O. Kononova, A. Trewartha, K. A. Persson, G. Ceder, and A. Jain, "Named entity recognition and normalization applied to large-scale information extraction from the materials science literature," Journal of Chemical Information and Modeling, vol. 59, no. 9, pp. 3692-3702, Sep 2019. [Online]. Available: https://doi.org/10.1021/acs.jcim.9b00470
[53] X. Wang, J. Li, H. D. Ha, J. C. Dahl, J. C. Ondry, I. MorenoHernandez, T. Head-Gordon, and A. P. Alivisatos, "Autodetect-mnp: An unsupervised machine learning algorithm for automated analysis of transmission electron microscope images of metal nanoparticles," JACS Au, vol. 1, no. 3, pp. 316-327, Mar 2021. [Online]. Available: https://doi.org/10.1021/jacsau.0c00030
[54] N. J. Szymanski, C. J. Bartel, Y. Zeng, Q. Tu, and G. Ceder, "Probabilistic deep learning approach to automate the interpretation of multi-phase diffraction spectra," Chemistry of Materials, vol. 33, no. 11, pp. 4204-4215, Jun 2021. [Online]. Available: https: //doi.org/10.1021/acs.chemmater.1c01071
[55] X. Yan, A. Sedykh, W. Wang, B. Yan, and H. Zhu, "Construction of a web-based nanomaterial database by big data curation and modeling friendly nanostructure annotations," Nature Communications, vol. 11, no. 1, p. 2519, May 2020. [Online]. Available: https://doi.org/10. 1038/s41467-020-16413-3
[56] K. Cruse, A. Trewartha, S. Lee, Z. Wang, H. Huo, T. He, O. Kononova, A. Jain, and G. Ceder, "Text-mined dataset of gold nanoparticle synthesis procedures, morphologies, and size entities," Scientific Data, vol. 9, no. 1, p. 234, May 2022. [Online]. Available: https://doi.org/10.1038/s41597-022-01321-6
[57] I. Sutskever, O. Vinyals, and Q. V. Le, "Sequence to sequence learning with neural networks," 2014. [Online]. Available: https: //arxiv.org/abs/1409.3215
[58] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell et al., "Language models are few-shot learners," Advances in neural information processing systems, vol. 33, pp. 1877-1901, 2020.
[59] A. Dunn, J. Dagdelen, N. Walker, S. Lee, A. S. Rosen, G. Ceder, K. Persson, and A. Jain, "Structured information extraction from complex scientific text with fine-tuned large language models," 2022. [Online]. Available: https://arxiv.org/abs/2212.05238
[60] Z. Wang, O. Kononova, K. Cruse, T. He, H. Huo, Y. Fei, Y. Zeng, Y. Sun, Z. Cai, W. Sun, and G. Ceder, "Dataset of solution-based inorganic materials synthesis recipes extracted from the scientific literature," 2021. [Online]. Available: https: //doi.org/10.48550/arXiv.2111.10874
[61] K. Cruse, A. Trewartha, S. Lee, Z. Wang, H. Huo, T. He, O. Kononova, A. Jain, and G. Ceder, "Text-mined aunp synthesis recipes dataset," figshare, 2021. [Online]. Available: https: //doi.org/10.6084/m9.figshare.16614262.v3
[62] A. Radford and K. Narasimhan, "Improving language understanding by generative pre-training," 2018.
[63] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever, "Language models are unsupervised multitask learners," 2019.
[64] M. Ma, H. Chen, Y. Chen, X. Wang, F. Chen, X. Cui, and J. Shi, "Au capped magnetic core/mesoporous silica shell nanoparticles for combined photothermo-/chemo-therapy and multimodal imaging," Biomaterials, vol. 33, no. 3, pp. 989-998, 2012. [Online]. Available: https: //www.sciencedirect.com/science/article/pii/S0142961211012208
[65] K. W. Smith, H. Zhao, H. Zhang, A. Sánchez-Iglesias, M. Grzelczak, Y. Wang, W.-S. Chang, P. Nordlander, L. M. Liz-Marzán, and S. Link, "Chiral and achiral nanodumbbell dimers: The effect of geometry on plasmonic properties," ACS Nano, vol. 10, no. 6, pp. 6180-6188, Jun 2016. [Online]. Available: https://doi.org/10.1021/acsnano.6b02194
[66] M. Zareie, X. Xu, and M. Cortie, "In situ organization of gold nanorods on mixed self-assembled-monolayer substrates," Small, vol. 3, no. 1, pp. 139-145, 2007. [Online]. Available: https://onlinelibrary.wiley.com/doi/abs/10.1002/smll.200600280
[67] X. Huang, S. Neretina, and M. A. El-Sayed, "Gold nanorods: from synthesis and properties to biological and biomedical applications," Adv Mater, vol. 21, no. 48, pp. 4880-4910, Jul. 2009.
[68] L. Vigderman and E. R. Zubarev, "High-yield synthesis of gold nanorods with longitudinal spr peak greater than 1200 nm using hydroquinone as a reducing agent," Chemistry of Materials, vol. 25, no. 8, pp. 1450-1457, Apr 2013. [Online]. Available: https://doi.org/10.1021/cm303661d
[69] L. Feng, Z. Xuan, J. Ma, J. Chen, D. Cui, C. Su, J. Guo, and Y. Zhang, "Preparation of gold nanorods with different aspect ratio and the optical response to solution refractive index," Journal of Experimental Nanoscience, vol. 10, no. 4, pp. 258-267, 2015. [Online]. Available: https://doi.org/10.1080/17458080.2013.824619
[70] N. D. Burrows, S. Harvey, F. A. Idesis, and C. J. Murphy, "Understanding the seed-mediated growth of gold nanorods through a fractional factorial design of experiments," Langmuir, vol. 33, no. 8, pp. 1891-1907, Feb 2017. [Online]. Available: https: //doi.org/10.1021/acs.langmuir.6b03606
[71] "Hcl-retarded gold nanorod growth for aspect ratio and shape tuning," Journal of Nanoscience and Nanotechnology, vol. 16, no. 1, 2016.
[72] Y. Wang, Y. Guo, Y. Shen, R. Chen, F. Wang, D. Zhou, and S. Guo, "HCl-Retarded gold nanorod growth for aspect ratio and shape tuning," J Nanosci Nanotechnol, vol. 16, no. 1, pp. 1194-1201, Jan. 2016.
[73] M.-Z. Wei, T.-S. Deng, Q. Zhang, Z. Cheng, and S. Li, "Seedmediated synthesis of gold nanorods at low concentrations of ctab," ACS Omega, vol. 6, no. 13, pp. 9188-9195, Apr 2021. [Online]. Available: https://doi.org/10.1021/acsomega.1c00510
[74] "GPT-3 seed-mediated AuNR synthesis extraction datasets," 2023. [Online]. Available: https://doi.org/10.6084/m9.figshare. 19719310.v2
[75] J. Towns, T. Cockerill, M. Dahan, I. Foster, K. Gaither, A. Grimshaw, V. Hazlewood, S. Lathrop, D. Lifka, G. D. Peterson, R. Roskies, J. R. Scott, and N. Wilkins-Diehr, "Xsede: Accelerating scientific discovery," Computing in Science \&amp; Engineering, vol. 16, no. 5, pp. 62-74, Sept.-Oct. 2014. [Online]. Available: doi.ieeecomputersociety. org/10.1109/MCSE. 2014.80</p>            </div>
        </div>

    </div>
</body>
</html>