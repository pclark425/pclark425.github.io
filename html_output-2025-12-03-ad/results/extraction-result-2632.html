<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2632 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2632</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2632</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-67.html">extraction-schema-67</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <p><strong>Paper ID:</strong> paper-1a7d8120697ac7410bf0f27bec037cb576c3b5fc</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/1a7d8120697ac7410bf0f27bec037cb576c3b5fc" target="_blank">Asynchronous Batch Bayesian Optimisation with Improved Local Penalisation</a></p>
                <p><strong>Paper Venue:</strong> International Conference on Machine Learning</p>
                <p><strong>Paper TL;DR:</strong> This work develops an approach, Penalising Locally for Asynchronous Bayesian Optimisation on $k$ workers (PLAyBOOK), for asynchronous parallel BO, and demonstrates empirically the efficacy of PLAyBOOK and its variants on synthetic tasks and a real-world problem.</p>
                <p><strong>Paper Abstract:</strong> Batch Bayesian optimisation (BO) has been successfully applied to hyperparameter tuning using parallel computing, but it is wasteful of resources: workers that complete jobs ahead of others are left idle. We address this problem by developing an approach, Penalising Locally for Asynchronous Bayesian Optimisation on $k$ workers (PLAyBOOK), for asynchronous parallel BO. We demonstrate empirically the efficacy of PLAyBOOK and its variants on synthetic tasks and a real-world problem. We undertake a comparison between synchronous and asynchronous BO, and show that asynchronous BO often outperforms synchronous batch BO in both wall-clock time and number of function evaluations.</p>
                <p><strong>Cost:</strong> 0.025</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2632.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2632.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PLAyBOOK</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Penalising Locally for Asynchronous Bayesian Optimisation Of K workers</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An asynchronous batch Bayesian optimisation framework that multiplies an acquisition function by analytic penaliser functions tied to currently busy evaluations to avoid redundant samples and improve resource utilisation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>PLAyBOOK (asynchronous penalisation-based BO)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>PLAyBOOK is an asynchronous parallel Bayesian optimisation system that, whenever one or more workers become free, selects new evaluation points by maximising an acquisition function (UCB in the paper) multiplied by penaliser functions centred at the busy (under-evaluation) locations. Penalisation uses GP posterior mean and variance together with Lipschitz-based radii to create exclusion zones around busy locations; variants include PLAyBOOK-L (naïve local penaliser), PLAyBOOK-H (Hard Local Penaliser), and versions using locally estimated Lipschitz constants (PLAyBOOK-LL, PLAyBOOK-HL). It avoids repeated sampling near busy locations, scales well to large batch sizes, and is implemented with GP surrogates and UCB acquisition.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>General black-box expensive function optimisation (hyperparameter tuning, synthetic global optimisation benchmarks); examples mentioned: neural network hyperparameter tuning, drug discovery/high-throughput screening.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocate new tasks to idle workers immediately (asynchronously). Selection for each new task maximises alpha(x) * product_i phi(x | x_i) where alpha is the acquisition (UCB) computed on the currently available dataset and phi are penaliser functions centered at busy locations; penaliser radii are derived from the GP posterior mean/variance and a Lipschitz constant (global or locally estimated). This strategy prioritises high-acquisition locations while excluding regions near busy evaluations to promote diversity and avoid wasted re-evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Wall-clock time (simulated runtimes sampled from a half-normal distribution with mean 1) and number of function evaluations; also mentions computational costs of repeated GP updates as a concern (but PLAyBOOK aims to be computationally efficient compared to sampling-based approaches).</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Not explicitly an information-theoretic acquisition; uses UCB (mu + kappa * sigma) as acquisition which trades mean (exploitation) and posterior uncertainty (exploration). Penaliser uses expected Lipschitz radius estimated from GP mean/variance (a proxy derived from posterior statistics).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Exploration/exploitation is controlled primarily by the base acquisition function (UCB) via the kappa parameter: mu(x) promotes exploitation, sigma(x) promotes exploration; penalisation reduces utility near busy evaluations thereby encouraging exploration elsewhere and preserving high-utility locations when surrogate for busy locations is less informed.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Explicit diversity promotion via analytic penaliser functions phi(x | x_j). The Hard Local Penaliser (HLP) sets phi proportional to distance normalized by an expected exclusion radius (derived from GP mean/variance and Lipschitz constant) and enforces phi(x_j)=0, preventing selection in that exclusion zone; local Lipschitz estimates allow variable-sized exclusion zones (larger in flat/uncertain regions, smaller in high-variability regions).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Computational resources expressed as number of parallel workers k and wall-clock time budget; implicitly also fixed number of evaluations in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Handles budget by asynchronous allocation to workers to maximise utilisation (assign new tasks as soon as workers free), penalisation avoids redundant evaluations thereby improving effective use of evaluation budget; experiments compare performance vs synchronous batching under comparable time/evaluation budgets.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Simple regret (difference between true global minimum f(x*) and best observed function value), reported as log(simple regret); for real-world hyperparameter tuning, validation error and final test accuracy on CIFAR-10 are used as performance/outcome metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Primary metric: log(simple regret) over time and number of evaluations (median and quartiles over trials). Real-world metric: CIFAR-10 test accuracy after retraining chosen hyperparameters; reported numbers in paper's Table 1: for k=2 PLAyBOOK reported 84.7% test accuracy (compared to TS 81.0% and KB 83.9%); for k=4 PLAyBOOK reported 82.5% (TS 81.2%, KB 82.8%). PLAyBOOK variants also show lower median log regret on benchmarks across a range of k values (detailed tables in supplementary material).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared against asynchronous Thompson Sampling (TS), asynchronous Kriging Believer heuristic (KB), synchronous variants of the same methods, and other batch BO strategies in related work (e.g., LP).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>PLAyBOOK outperforms TS and KB on many benchmark tasks and on a CNN hyperparameter tuning task; shows both faster decrease in regret when plotted vs wall-clock time (because asynchronous execution yields more evaluations per time) and often better sample efficiency (lower regret per number of evaluations) especially as batch size k increases. On CIFAR-10 hyperparameter tuning PLAyBOOK variants reached higher test accuracy than TS and KB (examples: 84.7% vs 81.0% for k=2).</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Qualitative gains: higher resource utilisation (asynchronous) leading to more evaluations per wall-clock time; empirical gains in sample efficiency for PLAyBOOK vs synchronous LP and other baselines particularly at larger batch sizes. Paper does not provide a single aggregated percent speedup across all tasks, but figures and tables show clear median regret reductions and improvements in final test accuracy on the real task.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>The paper explicitly analyses the tradeoff between wall-clock time and number of evaluations: asynchronous methods process more evaluations per unit time but may (in general) be less data-efficient because decisions are made with fewer completed observations. Empirically PLAyBOOK often achieves both better wall-clock and better sample efficiency because penalisation preserves high-utility locations and avoids redundant sampling. The paper also analyses tradeoffs in penaliser design: stronger penalisation (HLP) can mitigate underestimation of the global minimum and reduce redundant sampling, while locally estimated Lipschitz constants balance exploration (bigger exclusion zones in uncertain/flat regions) vs exploitation (smaller exclusion zones in high-variability regions).</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Recommendations: use asynchronous BO (over synchronous) with penalisation-based batch strategies; prefer PLAyBOOK variants (HLP and local-L versions) particularly for larger batch sizes; estimate Lipschitz constants locally (per busy location) rather than globally to create exclusion zones appropriate to local surrogate variability; choose HLP (hard penalisation) to avoid redundant sampling at busy locations and mitigate effects of approximating the global minimum.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Asynchronous Batch Bayesian Optimisation with Improved Local Penalisation', 'publication_date_yy_mm': '2019-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2632.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2632.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HLP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hard Local Penaliser</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A penaliser function introduced in this paper that enforces zero acquisition at busy locations and scales penalisation by a Lipschitz-derived exclusion radius computed from GP posterior mean/variance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Hard Local Penaliser (HLP)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>HLP is an analytic penaliser phi(x | x_j) = min( ||x - x_j|| / (E[r_j] + gamma * sigma(x_j)/L ), 1 ), where E[r_j] is an expected Lipschitz radius computed from GP posterior mean and gamma is a constant; approximated by a differentiable form for optimisation. HLP ensures phi(x_j)=0 and creates exclusion zones that scale with expected distance-to-optimum estimated from the GP, penalising candidate points near busy evaluations to avoid redundancy.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Used inside asynchronous Bayesian optimisation for general expensive black-box optimisation (benchmarks and CNN hyperparameter tuning).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>When assigning a new evaluation, candidate utility is acquisition(x) * product_j phi(x | x_j) over busy locations. HLP shapes phi to strongly remove utility near busy points, steering allocations away from likely-redundant regions.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Influences computational cost indirectly by reducing redundant evaluations; direct cost metrics used in experiments: wall-clock time and number of evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Does not directly compute information gain; uses GP posterior mean and variance and Lipschitz-derived radius (a proxy for how informative evaluating near x_j would be) to set exclusion zones.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Combines with base acquisition (e.g., UCB) that balances exploration/exploitation; HLP reduces exploitation that would pick near-busy points by setting their acquisition to zero at center and lowering nearby utility, thereby encouraging exploration of other regions.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Explicit: HLP forces diversity by excluding neighborhoods around busy locations; local-L variants vary exclusion size by local surrogate behaviour to encourage diversity where beneficial.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Parallel worker count and time budget (asynchronous scheduling).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>HLP reduces wasted budget (redundant evaluations), improving effective utilisation under fixed worker/time budgets.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Measured indirectly via log simple regret and final validation/test performance in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>HLP variants (PLAyBOOK-H, PLAyBOOK-HL) are reported to outperform naïve LP and other baselines on many benchmark tasks and in wall-clock time; exact quantitative comparisons are shown in per-task regret tables and plots.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared to LP (local penalisation from González et al.), TS, KB, and synchronous variants.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>HLP penalisation is described and demonstrated to reduce redundant sampling compared to LP and to improve empirical optimisation performance in asynchronous settings (figures and tables in paper).</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Enables better sample efficiency and wall-clock performance in asynchronous batches by preventing redundant samples; specific gains are reported per-task in the paper's figures/tables rather than a single summary metric.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>HLP penalises more strongly than LP to counter underestimation of the global minimum; tradeoff between penalisation strength and missing informative nearby evaluations is discussed, and mitigated by local Lipschitz estimation.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>HLP with locally estimated Lipschitz constants (HL) is recommended when busy locations are in regions of varying surrogate variability; HLP helps asynchronous methods match or exceed synchronous sample efficiency while improving wall-clock time.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Asynchronous Batch Bayesian Optimisation with Improved Local Penalisation', 'publication_date_yy_mm': '2019-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2632.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2632.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Local Penalisation (González et al., 2016)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A synchronous batch BO method that sequentially constructs a batch by penalising the acquisition function in the neighbourhood of already-selected batch points to encourage diversity.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Batch Bayesian optimization via local penalization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Local Penalisation (LP)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>LP constructs batches by sequentially selecting points; after adding a point x_j to the batch it multiplies the acquisition function by a penaliser centered at x_j to downweight nearby locations, encouraging diversity in simultaneous evaluations. The penaliser is based on Lipschitz assumptions and/or GP posterior features.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Synchronous parallel Bayesian optimisation for expensive black-box functions (hyperparameter tuning, general optimisation).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocates k evaluations simultaneously by sequentially selecting points and penalising the acquisition in neighbourhoods of already-chosen batch points to avoid redundancy within the batch.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Number of evaluations per synchronous iteration and total wall-clock time (implicit; LP is a synchronous method so idle-worker waiting costs are a consideration).</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Not explicitly information-theoretic; penaliser uses Lipschitz-radius proxies based on GP posterior statistics. The selection still depends on the acquisition function employed (could be UCB, EI, etc.).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Relies on base acquisition function (e.g., UCB) for exploration-exploitation trade-off; penalisation encourages spatial diversity in batch to increase exploration.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Explicit penalisation around chosen batch points to ensure spatial diversity.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Batch size k (parallel workers) and iteration-based evaluations; synchronous waiting causes idle time when runtime variance exists.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Chooses all k batch points at once; does not handle runtime heterogeneity between evaluations which can lead to idle workers and poorer wall-clock efficiency.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Typically simple regret or improvement in objective; in this paper LP is referenced as prior art and as baseline behaviour for batch diversity.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Referenced as state of the art for synchronous batch BO in prior work; in this paper PLAyBOOK variants are compared against LP-derived behaviour.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared in literature and as inspiration for PLAyBOOK; used as synchronous baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Paper claims PLAyBOOK (asynchronous penalisation variants) can outperform LP in wall-clock time and sample efficiency when run asynchronously; LP naive application in asynchronous setting can lead to redundant sampling because its penaliser may not enforce zero acquisition at busy points.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>LP improves batch diversity relative to naive simultaneous selection, but synchronous LP can waste wall-clock time in presence of heterogeneous evaluation runtimes.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>LP trades off between penalisation strength and possibly excluding informative nearby points; paper motivates HLP to address LP's failure to set acquisition to zero at busy centers and to mitigate underestimation of global minimum.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>LP is effective for synchronous batches but should be adapted (e.g., HLP, local L) for asynchronous operation to avoid redundancy and improve wall-clock efficiency.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Asynchronous Batch Bayesian Optimisation with Improved Local Penalisation', 'publication_date_yy_mm': '2019-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2632.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2632.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TS (parallel)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Parallelised Bayesian Optimisation via Thompson Sampling</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A scalable asynchronous batch BO method that selects batch points by sampling from the surrogate posterior (Thompson Sampling), placing each batch point at the minimiser of a posterior sample.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Parallelised Bayesian optimisation via Thompson sampling</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Parallel Thompson Sampling (TS)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>TS draws samples from the GP posterior and places batch points at minima of these draws; in an asynchronous setting this is efficient because batch points can be generated by independent posterior samples without repeated expensive posterior updates. It relies on the surrogate's uncertainty to provide diversity across the batch.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Parallel Bayesian optimisation for expensive black-box functions; used as a baseline in experiments including synthetic benchmarks and CNN hyperparameter tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocate next evaluation to idle worker by drawing a posterior sample and selecting its minimiser; effectively randomised allocation guided by posterior uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Computational cost measured in wall-clock time and number of evaluations; TS is noted for attractive scaling because it minimises repeated expensive GP computations compared to methods that recompute q-EI.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Indirect: exploration arises from posterior sampling variance rather than an explicit information-gain objective.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Exploration emerges from stochastic posterior samples (high-uncertainty regions get sampled more); exploitation occurs when posterior concentrates near minima.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Implicit via randomness of posterior samples; no explicit penaliser to enforce spatial diversity.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Parallel worker count and time budget.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Efficient asynchronous allocation because sampling is cheap; avoids repeated posterior recomputation per batch point.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Measured via log simple regret and downstream task performance (CIFAR-10 validation/test), used as experimental baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>In experiments TS often performed worse than PLAyBOOK and KB on synthetic tasks and the CNN tuning task (e.g., TS test accuracy ~81.0% for k=2 vs PLAyBOOK ~84.7%).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared directly against PLAyBOOK and KB.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>TS scaled well computationally but underperformed PLAyBOOK on many benchmarks (paper attributes this to TS relying heavily on surrogate uncertainty for exploration which can be insufficient).</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Computationally efficient scaling for large batches because sampling avoids expensive repeated posterior updates; however this computational efficiency did not always translate to better optimisation performance in the authors' experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>TS trades off cheaper computation per selection against potentially poorer batch diversity/utility compared to penalisation-based approaches; the paper empirically finds TS can perform worse in optimisation quality despite computational advantages.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>TS is attractive when computational cost of selection dominates and when posterior sampling provides sufficient exploration, but penalisation-based asynchronous approaches (PLAyBOOK) can give better empirical optimisation performance while remaining computationally tractable.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Asynchronous Batch Bayesian Optimisation with Improved Local Penalisation', 'publication_date_yy_mm': '2019-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2632.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2632.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>KB</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Kriging Believer heuristic</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A batch selection heuristic that 'hallucinates' the function values at chosen batch points (e.g., by assuming predicted GP mean) and updates the surrogate sequentially to choose the rest of the batch.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Kriging is well-suited to parallelize optimization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Kriging Believer (KB)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>KB constructs batches sequentially by, after selecting a point, pretending the evaluation returns the GP posterior mean (or another fill-in value), updating the surrogate with that hallucinated observation, and then selecting the next batch point; in asynchronous use the scheme can be applied when assigning points to free workers. KB requires recomputing the posterior for each sequential selection.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Parallel Bayesian optimisation for expensive black-box functions; used as baseline in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Sequential batch construction with surrogate updates using hallucinated (assumed) results for busy locations, thereby allocating diverse batch points under the current surrogate model assumptions.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Number of posterior updates and their computational cost, wall-clock time and number of evaluations; KB involves recomputing posterior and acquisition function per sequential selection which is more expensive than sampling-based approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Does not explicitly maximise information gain; uses surrogate mean to hallucinate results and then uses acquisition functions (e.g., UCB) on the updated surrogate.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Base acquisition function (e.g., UCB) controls exploration-exploitation; hallucinated updates affect where subsequent batch points are placed, influencing diversity/exploration.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Implicit via sequential updates with hallucinated values which discourage selecting points similar to the hallucinated ones.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Parallel workers and time budgets; computational cost of repeated surrogate updates is a practical consideration.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>KB does not directly address runtime heterogeneity between workers; its repeated posterior recomputation per batch point can be computationally heavier, impacting wall-clock performance in practice.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Measured via log simple regret and downstream validation/test performance in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>KB performs competitively on some tasks; in CIFAR-10 hyperparameter tuning KB achieved 83.9% (k=2) and 82.8% (k=4) test accuracy versus PLAyBOOK reported up to ~84.7% (k=2).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared against TS and PLAyBOOK in the paper's experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>KB sometimes outperforms TS but is generally outperformed by PLAyBOOK on many benchmark problems and on the CNN tuning task in the authors' experiments, particularly as batch sizes increase.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Provides batch diversity with surrogate-informed sequential updates but at higher computational cost for posterior recomputation compared to sampling-based methods; this can reduce wall-clock effectiveness when evaluation runtimes are heterogeneous.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>KB trades improved batch-informed selection (via hallucination and sequential surrogate updates) against additional computational expense of repeated posterior updates; PLAyBOOK aims to retain the diversity benefits while remaining computationally cheaper by using analytic penalisation instead.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>KB is a reasonable heuristic for batch diversity but may be less suitable than penalisation-based asynchronous methods (PLAyBOOK) when runtime heterogeneity and large batch sizes make efficient wall-clock utilisation important.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Asynchronous Batch Bayesian Optimisation with Improved Local Penalisation', 'publication_date_yy_mm': '2019-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2632.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2632.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Ginsbourger Asynch.</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Ginsbourger et al. asynchronous sampling-based marginalisation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A sampling-based asynchronous BO approach that marginalises unknown function values at busy locations by sampling from the surrogate posterior; accurate but computationally expensive and scales poorly with batch size.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Dealing with asynchronicity in parallel Gaussian process based global optimization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Sampling-based marginalisation for asynchronous BO (Ginsbourger et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Method approximates the integral over unknown function values at busy locations by drawing samples from the GP posterior at those locations and marginalising when selecting new points. This reduces bias from missing values but requires many posterior samples and repeated expensive computations, leading to poor scaling with batch size and BO steps.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Asynchronous parallel Gaussian process-based global optimisation.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>When a worker is free, choose new points by marginalising over possible outcomes at busy locations using posterior samples, thereby allocating points that account for uncertainty about those busy evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>High computational cost due to repeated posterior sampling and marginalisation; cost increases with batch size and number of required samples.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Implicitly accounts for uncertainty by marginalising over posterior draws; not formulated as an explicit mutual information objective but aims to select points robust to unknown busy values.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Exploration arises from sampling posterior uncertainty; exploitation from posterior mean in acquisition evaluations conditioned on sampled values.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Diversity arises indirectly by marginalising over uncertain busy values; no explicit analytic penaliser is used.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Computational budget for posterior sampling and wall-clock time; not optimised for large-scale asynchronous resource utilisation due to high cost.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Handles uncertainty about busy locations by sampling but at the cost of repeated expensive computation; not targeted at optimising wall-clock utilisation.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Not directly specified in this paper; referenced as prior work with computational trade-offs discussed.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Paper notes that sampling-based approach suffers from poor scaling with batch size and BO steps; not used as a baseline in large-scale experiments due to computational cost.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Mentioned as prior asynchronous method; contrasted with PLAyBOOK which is more computationally efficient.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Described as accurate but computationally prohibitive for large batches; PLAyBOOK aims to provide comparable practical performance with much lower selection cost.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>None; the approach has high selection-time cost which reduces wall-clock evaluation throughput.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Highlights tradeoff between correct marginalisation of busy-location uncertainty and computational feasibility; motivates development of cheaper analytic penalisation approaches like PLAyBOOK.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>While marginalisation is principled, its computational cost makes it less suitable for large asynchronous parallel settings; cheaper penalties that approximate the effect of marginalisation can achieve practical gains.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Asynchronous Batch Bayesian Optimisation with Improved Local Penalisation', 'publication_date_yy_mm': '2019-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2632.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2632.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MOE / q-EI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MOE (q-EI gradient estimator / optimizer, Wang et al. 2016)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An optimizer that estimates gradients of the multi-point expected improvement (q-EI) acquisition and uses stochastic gradient ascent to optimise q-EI for batch selection; computationally expensive but designed to directly optimise batch acquisition.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Parallel Bayesian global optimization of expensive functions</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>MOE q-EI gradient-based optimizer</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>MOE estimates the gradient of q-EI (the expected improvement for a batch of points) and applies stochastic gradient ascent to solve the high-dimensional maximisation problem of selecting all batch points jointly. This method targets optimal batch utility but the joint optimisation of q-EI is computationally intensive.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Batch Bayesian optimisation for expensive black-box functions where joint batch utility optimisation is desired.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Select a batch by directly maximising q-EI jointly for all k points, thereby allocating the available parallel evaluations to maximise expected improvement over the batch.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>High computational cost for gradient estimation and joint optimisation; paper discusses this as prohibitive for direct q-EI maximisation without specialized optimisers like MOE.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>q-EI is an expected improvement metric (expected reduction in objective value), not an explicit information-theoretic gain but an expected utility measure.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>q-EI balances exploration and exploitation through the expected improvement formulation which accounts for both mean and variance of GP posterior across the batch.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Diversity emerges from joint optimisation of the batch q-EI which internalises the mutual influence of batch members; not via explicit penaliser but via the expected improvement objective for the batch.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Computational budget for batch selection and time budget; also number of parallel workers k.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Handles batch allocation by direct optimisation of expected improvement across the batch, but at the cost of increased computational selection time which can reduce wall-clock evaluation throughput.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Expected improvement across the batch (q-EI) and downstream simple regret as measured experimentally.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Referenced as a principled batch acquisition, but its direct maximisation is computationally challenging and MOE provides an approximate scalable solution; not directly benchmarked in this paper's experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Described in related work and contrasted with sampling-based and penalisation-based batch methods.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Not experimentally compared in this paper; cited as computationally intensive motivating alternatives like TS and PLAyBOOK that prioritize selection-time efficiency.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>When effectively optimised, q-EI can provide high-quality batches but selection-time costs can negate wall-clock gains; MOE aims to make this tractable via gradient estimates.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper highlights tension between selecting high-quality batches (joint q-EI) and the computational cost of doing so; motivates cheaper alternatives for asynchronous contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Joint batch optimisation is attractive theoretically but practically expensive for asynchronous large-batch settings; approximate and cheaper schemes (penalisation, sampling) can be preferable in practice.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Asynchronous Batch Bayesian Optimisation with Improved Local Penalisation', 'publication_date_yy_mm': '2019-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2632.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2632.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Info-theoretic methods</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Information-theoretic acquisition methods (Entropy Search, Predictive Entropy Search, Max-value Entropy Search)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A class of acquisition functions that select points by maximising expected information about the global optimum (e.g., reduction in entropy of the minimiser or maximal value), thereby explicitly targeting information gain.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Entropy search for informationefficient global optimization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Information-theoretic acquisition methods (Entropy/Predictive/Max-value Entropy Search)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Methods such as Entropy Search, Predictive Entropy Search (PES), and Max-value Entropy Search (MES) compute acquisition values based on expected reduction in entropy (uncertainty) about the location/value of the global optimum. They directly quantify information gain and select evaluations to maximally reduce posterior uncertainty about the optimum.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Global optimisation of expensive black-box functions where obtaining information about the optimum quickly is important.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocate evaluations to maximise expected information gain about the global minimiser (or minimum value), often requiring expensive computations or approximations to estimate expected reduction in entropy.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Computational cost often dominated by the need to approximate mutual information/entropy integrals and to simulate posterior reductions; selection-time cost can be substantial compared to simpler acquisitions like UCB.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Explicit mutual information or expected reduction in posterior entropy about the minimiser or min-value.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Explicitly exploration-driven via information acquisition; exploitation arises indirectly as information leads to focused sampling near the optimum.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Diversity emerges from selecting points that reduce uncertainty across the posterior over minimiser locations; not via explicit penaliser but via information-theoretic objectives which naturally spread queries to reduce entropy.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Computational budget for selection-time computations and evaluation time budget.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>These methods can be computationally expensive per selection; practical implementations use approximations to make them tractable, but high selection cost can reduce wall-clock throughput in parallel asynchronous settings.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Expected information gain about the global minimiser; empirically evaluated via reduction in simple regret.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Referenced as methods that maximise information about the objective/minimiser; not used as experimental baselines in the main experiments of this paper but cited in related work.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Mentioned alongside other acquisition designs (UCB, EI, KG); contrasted by being explicitly information-centric.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Not empirically compared in this paper; cited as prior art focused on information gain that can be expensive to compute.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Potentially high sample efficiency by directly maximising information per evaluation, but selection-time computational cost can limit wall-clock efficiency in parallel asynchronous settings.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper situates these methods as alternatives focused on information gain; contrasts the computational cost of such approaches with the cheaper penalisation-based PLAyBOOK that trades an explicit information objective for scalable, diversity-promoting exclusion zones.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Information-theoretic objectives are principled for maximising per-evaluation information but may be less practical in large-scale asynchronous parallel contexts due to high selection-time cost; approximations or cheaper heuristics may be preferred depending on resource constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Asynchronous Batch Bayesian Optimisation with Improved Local Penalisation', 'publication_date_yy_mm': '2019-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Batch Bayesian optimization via local penalization <em>(Rating: 2)</em></li>
                <li>Parallelised Bayesian optimisation via Thompson sampling <em>(Rating: 2)</em></li>
                <li>Dealing with asynchronicity in parallel Gaussian process based global optimization <em>(Rating: 2)</em></li>
                <li>Parallel Bayesian global optimization of expensive functions <em>(Rating: 2)</em></li>
                <li>Parallel predictive entropy search for batch global optimization of expensive objective functions <em>(Rating: 2)</em></li>
                <li>Entropy search for informationefficient global optimization <em>(Rating: 1)</em></li>
                <li>Max-value entropy search for efficient Bayesian optimization <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2632",
    "paper_id": "paper-1a7d8120697ac7410bf0f27bec037cb576c3b5fc",
    "extraction_schema_id": "extraction-schema-67",
    "extracted_data": [
        {
            "name_short": "PLAyBOOK",
            "name_full": "Penalising Locally for Asynchronous Bayesian Optimisation Of K workers",
            "brief_description": "An asynchronous batch Bayesian optimisation framework that multiplies an acquisition function by analytic penaliser functions tied to currently busy evaluations to avoid redundant samples and improve resource utilisation.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "PLAyBOOK (asynchronous penalisation-based BO)",
            "system_description": "PLAyBOOK is an asynchronous parallel Bayesian optimisation system that, whenever one or more workers become free, selects new evaluation points by maximising an acquisition function (UCB in the paper) multiplied by penaliser functions centred at the busy (under-evaluation) locations. Penalisation uses GP posterior mean and variance together with Lipschitz-based radii to create exclusion zones around busy locations; variants include PLAyBOOK-L (naïve local penaliser), PLAyBOOK-H (Hard Local Penaliser), and versions using locally estimated Lipschitz constants (PLAyBOOK-LL, PLAyBOOK-HL). It avoids repeated sampling near busy locations, scales well to large batch sizes, and is implemented with GP surrogates and UCB acquisition.",
            "application_domain": "General black-box expensive function optimisation (hyperparameter tuning, synthetic global optimisation benchmarks); examples mentioned: neural network hyperparameter tuning, drug discovery/high-throughput screening.",
            "resource_allocation_strategy": "Allocate new tasks to idle workers immediately (asynchronously). Selection for each new task maximises alpha(x) * product_i phi(x | x_i) where alpha is the acquisition (UCB) computed on the currently available dataset and phi are penaliser functions centered at busy locations; penaliser radii are derived from the GP posterior mean/variance and a Lipschitz constant (global or locally estimated). This strategy prioritises high-acquisition locations while excluding regions near busy evaluations to promote diversity and avoid wasted re-evaluation.",
            "computational_cost_metric": "Wall-clock time (simulated runtimes sampled from a half-normal distribution with mean 1) and number of function evaluations; also mentions computational costs of repeated GP updates as a concern (but PLAyBOOK aims to be computationally efficient compared to sampling-based approaches).",
            "information_gain_metric": "Not explicitly an information-theoretic acquisition; uses UCB (mu + kappa * sigma) as acquisition which trades mean (exploitation) and posterior uncertainty (exploration). Penaliser uses expected Lipschitz radius estimated from GP mean/variance (a proxy derived from posterior statistics).",
            "uses_information_gain": false,
            "exploration_exploitation_mechanism": "Exploration/exploitation is controlled primarily by the base acquisition function (UCB) via the kappa parameter: mu(x) promotes exploitation, sigma(x) promotes exploration; penalisation reduces utility near busy evaluations thereby encouraging exploration elsewhere and preserving high-utility locations when surrogate for busy locations is less informed.",
            "diversity_mechanism": "Explicit diversity promotion via analytic penaliser functions phi(x | x_j). The Hard Local Penaliser (HLP) sets phi proportional to distance normalized by an expected exclusion radius (derived from GP mean/variance and Lipschitz constant) and enforces phi(x_j)=0, preventing selection in that exclusion zone; local Lipschitz estimates allow variable-sized exclusion zones (larger in flat/uncertain regions, smaller in high-variability regions).",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Computational resources expressed as number of parallel workers k and wall-clock time budget; implicitly also fixed number of evaluations in experiments.",
            "budget_constraint_handling": "Handles budget by asynchronous allocation to workers to maximise utilisation (assign new tasks as soon as workers free), penalisation avoids redundant evaluations thereby improving effective use of evaluation budget; experiments compare performance vs synchronous batching under comparable time/evaluation budgets.",
            "breakthrough_discovery_metric": "Simple regret (difference between true global minimum f(x*) and best observed function value), reported as log(simple regret); for real-world hyperparameter tuning, validation error and final test accuracy on CIFAR-10 are used as performance/outcome metrics.",
            "performance_metrics": "Primary metric: log(simple regret) over time and number of evaluations (median and quartiles over trials). Real-world metric: CIFAR-10 test accuracy after retraining chosen hyperparameters; reported numbers in paper's Table 1: for k=2 PLAyBOOK reported 84.7% test accuracy (compared to TS 81.0% and KB 83.9%); for k=4 PLAyBOOK reported 82.5% (TS 81.2%, KB 82.8%). PLAyBOOK variants also show lower median log regret on benchmarks across a range of k values (detailed tables in supplementary material).",
            "comparison_baseline": "Compared against asynchronous Thompson Sampling (TS), asynchronous Kriging Believer heuristic (KB), synchronous variants of the same methods, and other batch BO strategies in related work (e.g., LP).",
            "performance_vs_baseline": "PLAyBOOK outperforms TS and KB on many benchmark tasks and on a CNN hyperparameter tuning task; shows both faster decrease in regret when plotted vs wall-clock time (because asynchronous execution yields more evaluations per time) and often better sample efficiency (lower regret per number of evaluations) especially as batch size k increases. On CIFAR-10 hyperparameter tuning PLAyBOOK variants reached higher test accuracy than TS and KB (examples: 84.7% vs 81.0% for k=2).",
            "efficiency_gain": "Qualitative gains: higher resource utilisation (asynchronous) leading to more evaluations per wall-clock time; empirical gains in sample efficiency for PLAyBOOK vs synchronous LP and other baselines particularly at larger batch sizes. Paper does not provide a single aggregated percent speedup across all tasks, but figures and tables show clear median regret reductions and improvements in final test accuracy on the real task.",
            "tradeoff_analysis": "The paper explicitly analyses the tradeoff between wall-clock time and number of evaluations: asynchronous methods process more evaluations per unit time but may (in general) be less data-efficient because decisions are made with fewer completed observations. Empirically PLAyBOOK often achieves both better wall-clock and better sample efficiency because penalisation preserves high-utility locations and avoids redundant sampling. The paper also analyses tradeoffs in penaliser design: stronger penalisation (HLP) can mitigate underestimation of the global minimum and reduce redundant sampling, while locally estimated Lipschitz constants balance exploration (bigger exclusion zones in uncertain/flat regions) vs exploitation (smaller exclusion zones in high-variability regions).",
            "optimal_allocation_findings": "Recommendations: use asynchronous BO (over synchronous) with penalisation-based batch strategies; prefer PLAyBOOK variants (HLP and local-L versions) particularly for larger batch sizes; estimate Lipschitz constants locally (per busy location) rather than globally to create exclusion zones appropriate to local surrogate variability; choose HLP (hard penalisation) to avoid redundant sampling at busy locations and mitigate effects of approximating the global minimum.",
            "uuid": "e2632.0",
            "source_info": {
                "paper_title": "Asynchronous Batch Bayesian Optimisation with Improved Local Penalisation",
                "publication_date_yy_mm": "2019-01"
            }
        },
        {
            "name_short": "HLP",
            "name_full": "Hard Local Penaliser",
            "brief_description": "A penaliser function introduced in this paper that enforces zero acquisition at busy locations and scales penalisation by a Lipschitz-derived exclusion radius computed from GP posterior mean/variance.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Hard Local Penaliser (HLP)",
            "system_description": "HLP is an analytic penaliser phi(x | x_j) = min( ||x - x_j|| / (E[r_j] + gamma * sigma(x_j)/L ), 1 ), where E[r_j] is an expected Lipschitz radius computed from GP posterior mean and gamma is a constant; approximated by a differentiable form for optimisation. HLP ensures phi(x_j)=0 and creates exclusion zones that scale with expected distance-to-optimum estimated from the GP, penalising candidate points near busy evaluations to avoid redundancy.",
            "application_domain": "Used inside asynchronous Bayesian optimisation for general expensive black-box optimisation (benchmarks and CNN hyperparameter tuning).",
            "resource_allocation_strategy": "When assigning a new evaluation, candidate utility is acquisition(x) * product_j phi(x | x_j) over busy locations. HLP shapes phi to strongly remove utility near busy points, steering allocations away from likely-redundant regions.",
            "computational_cost_metric": "Influences computational cost indirectly by reducing redundant evaluations; direct cost metrics used in experiments: wall-clock time and number of evaluations.",
            "information_gain_metric": "Does not directly compute information gain; uses GP posterior mean and variance and Lipschitz-derived radius (a proxy for how informative evaluating near x_j would be) to set exclusion zones.",
            "uses_information_gain": false,
            "exploration_exploitation_mechanism": "Combines with base acquisition (e.g., UCB) that balances exploration/exploitation; HLP reduces exploitation that would pick near-busy points by setting their acquisition to zero at center and lowering nearby utility, thereby encouraging exploration of other regions.",
            "diversity_mechanism": "Explicit: HLP forces diversity by excluding neighborhoods around busy locations; local-L variants vary exclusion size by local surrogate behaviour to encourage diversity where beneficial.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Parallel worker count and time budget (asynchronous scheduling).",
            "budget_constraint_handling": "HLP reduces wasted budget (redundant evaluations), improving effective utilisation under fixed worker/time budgets.",
            "breakthrough_discovery_metric": "Measured indirectly via log simple regret and final validation/test performance in experiments.",
            "performance_metrics": "HLP variants (PLAyBOOK-H, PLAyBOOK-HL) are reported to outperform naïve LP and other baselines on many benchmark tasks and in wall-clock time; exact quantitative comparisons are shown in per-task regret tables and plots.",
            "comparison_baseline": "Compared to LP (local penalisation from González et al.), TS, KB, and synchronous variants.",
            "performance_vs_baseline": "HLP penalisation is described and demonstrated to reduce redundant sampling compared to LP and to improve empirical optimisation performance in asynchronous settings (figures and tables in paper).",
            "efficiency_gain": "Enables better sample efficiency and wall-clock performance in asynchronous batches by preventing redundant samples; specific gains are reported per-task in the paper's figures/tables rather than a single summary metric.",
            "tradeoff_analysis": "HLP penalises more strongly than LP to counter underestimation of the global minimum; tradeoff between penalisation strength and missing informative nearby evaluations is discussed, and mitigated by local Lipschitz estimation.",
            "optimal_allocation_findings": "HLP with locally estimated Lipschitz constants (HL) is recommended when busy locations are in regions of varying surrogate variability; HLP helps asynchronous methods match or exceed synchronous sample efficiency while improving wall-clock time.",
            "uuid": "e2632.1",
            "source_info": {
                "paper_title": "Asynchronous Batch Bayesian Optimisation with Improved Local Penalisation",
                "publication_date_yy_mm": "2019-01"
            }
        },
        {
            "name_short": "LP",
            "name_full": "Local Penalisation (González et al., 2016)",
            "brief_description": "A synchronous batch BO method that sequentially constructs a batch by penalising the acquisition function in the neighbourhood of already-selected batch points to encourage diversity.",
            "citation_title": "Batch Bayesian optimization via local penalization",
            "mention_or_use": "mention",
            "system_name": "Local Penalisation (LP)",
            "system_description": "LP constructs batches by sequentially selecting points; after adding a point x_j to the batch it multiplies the acquisition function by a penaliser centered at x_j to downweight nearby locations, encouraging diversity in simultaneous evaluations. The penaliser is based on Lipschitz assumptions and/or GP posterior features.",
            "application_domain": "Synchronous parallel Bayesian optimisation for expensive black-box functions (hyperparameter tuning, general optimisation).",
            "resource_allocation_strategy": "Allocates k evaluations simultaneously by sequentially selecting points and penalising the acquisition in neighbourhoods of already-chosen batch points to avoid redundancy within the batch.",
            "computational_cost_metric": "Number of evaluations per synchronous iteration and total wall-clock time (implicit; LP is a synchronous method so idle-worker waiting costs are a consideration).",
            "information_gain_metric": "Not explicitly information-theoretic; penaliser uses Lipschitz-radius proxies based on GP posterior statistics. The selection still depends on the acquisition function employed (could be UCB, EI, etc.).",
            "uses_information_gain": false,
            "exploration_exploitation_mechanism": "Relies on base acquisition function (e.g., UCB) for exploration-exploitation trade-off; penalisation encourages spatial diversity in batch to increase exploration.",
            "diversity_mechanism": "Explicit penalisation around chosen batch points to ensure spatial diversity.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Batch size k (parallel workers) and iteration-based evaluations; synchronous waiting causes idle time when runtime variance exists.",
            "budget_constraint_handling": "Chooses all k batch points at once; does not handle runtime heterogeneity between evaluations which can lead to idle workers and poorer wall-clock efficiency.",
            "breakthrough_discovery_metric": "Typically simple regret or improvement in objective; in this paper LP is referenced as prior art and as baseline behaviour for batch diversity.",
            "performance_metrics": "Referenced as state of the art for synchronous batch BO in prior work; in this paper PLAyBOOK variants are compared against LP-derived behaviour.",
            "comparison_baseline": "Compared in literature and as inspiration for PLAyBOOK; used as synchronous baseline.",
            "performance_vs_baseline": "Paper claims PLAyBOOK (asynchronous penalisation variants) can outperform LP in wall-clock time and sample efficiency when run asynchronously; LP naive application in asynchronous setting can lead to redundant sampling because its penaliser may not enforce zero acquisition at busy points.",
            "efficiency_gain": "LP improves batch diversity relative to naive simultaneous selection, but synchronous LP can waste wall-clock time in presence of heterogeneous evaluation runtimes.",
            "tradeoff_analysis": "LP trades off between penalisation strength and possibly excluding informative nearby points; paper motivates HLP to address LP's failure to set acquisition to zero at busy centers and to mitigate underestimation of global minimum.",
            "optimal_allocation_findings": "LP is effective for synchronous batches but should be adapted (e.g., HLP, local L) for asynchronous operation to avoid redundancy and improve wall-clock efficiency.",
            "uuid": "e2632.2",
            "source_info": {
                "paper_title": "Asynchronous Batch Bayesian Optimisation with Improved Local Penalisation",
                "publication_date_yy_mm": "2019-01"
            }
        },
        {
            "name_short": "TS (parallel)",
            "name_full": "Parallelised Bayesian Optimisation via Thompson Sampling",
            "brief_description": "A scalable asynchronous batch BO method that selects batch points by sampling from the surrogate posterior (Thompson Sampling), placing each batch point at the minimiser of a posterior sample.",
            "citation_title": "Parallelised Bayesian optimisation via Thompson sampling",
            "mention_or_use": "use",
            "system_name": "Parallel Thompson Sampling (TS)",
            "system_description": "TS draws samples from the GP posterior and places batch points at minima of these draws; in an asynchronous setting this is efficient because batch points can be generated by independent posterior samples without repeated expensive posterior updates. It relies on the surrogate's uncertainty to provide diversity across the batch.",
            "application_domain": "Parallel Bayesian optimisation for expensive black-box functions; used as a baseline in experiments including synthetic benchmarks and CNN hyperparameter tuning.",
            "resource_allocation_strategy": "Allocate next evaluation to idle worker by drawing a posterior sample and selecting its minimiser; effectively randomised allocation guided by posterior uncertainty.",
            "computational_cost_metric": "Computational cost measured in wall-clock time and number of evaluations; TS is noted for attractive scaling because it minimises repeated expensive GP computations compared to methods that recompute q-EI.",
            "information_gain_metric": "Indirect: exploration arises from posterior sampling variance rather than an explicit information-gain objective.",
            "uses_information_gain": false,
            "exploration_exploitation_mechanism": "Exploration emerges from stochastic posterior samples (high-uncertainty regions get sampled more); exploitation occurs when posterior concentrates near minima.",
            "diversity_mechanism": "Implicit via randomness of posterior samples; no explicit penaliser to enforce spatial diversity.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Parallel worker count and time budget.",
            "budget_constraint_handling": "Efficient asynchronous allocation because sampling is cheap; avoids repeated posterior recomputation per batch point.",
            "breakthrough_discovery_metric": "Measured via log simple regret and downstream task performance (CIFAR-10 validation/test), used as experimental baseline.",
            "performance_metrics": "In experiments TS often performed worse than PLAyBOOK and KB on synthetic tasks and the CNN tuning task (e.g., TS test accuracy ~81.0% for k=2 vs PLAyBOOK ~84.7%).",
            "comparison_baseline": "Compared directly against PLAyBOOK and KB.",
            "performance_vs_baseline": "TS scaled well computationally but underperformed PLAyBOOK on many benchmarks (paper attributes this to TS relying heavily on surrogate uncertainty for exploration which can be insufficient).",
            "efficiency_gain": "Computationally efficient scaling for large batches because sampling avoids expensive repeated posterior updates; however this computational efficiency did not always translate to better optimisation performance in the authors' experiments.",
            "tradeoff_analysis": "TS trades off cheaper computation per selection against potentially poorer batch diversity/utility compared to penalisation-based approaches; the paper empirically finds TS can perform worse in optimisation quality despite computational advantages.",
            "optimal_allocation_findings": "TS is attractive when computational cost of selection dominates and when posterior sampling provides sufficient exploration, but penalisation-based asynchronous approaches (PLAyBOOK) can give better empirical optimisation performance while remaining computationally tractable.",
            "uuid": "e2632.3",
            "source_info": {
                "paper_title": "Asynchronous Batch Bayesian Optimisation with Improved Local Penalisation",
                "publication_date_yy_mm": "2019-01"
            }
        },
        {
            "name_short": "KB",
            "name_full": "Kriging Believer heuristic",
            "brief_description": "A batch selection heuristic that 'hallucinates' the function values at chosen batch points (e.g., by assuming predicted GP mean) and updates the surrogate sequentially to choose the rest of the batch.",
            "citation_title": "Kriging is well-suited to parallelize optimization",
            "mention_or_use": "use",
            "system_name": "Kriging Believer (KB)",
            "system_description": "KB constructs batches sequentially by, after selecting a point, pretending the evaluation returns the GP posterior mean (or another fill-in value), updating the surrogate with that hallucinated observation, and then selecting the next batch point; in asynchronous use the scheme can be applied when assigning points to free workers. KB requires recomputing the posterior for each sequential selection.",
            "application_domain": "Parallel Bayesian optimisation for expensive black-box functions; used as baseline in experiments.",
            "resource_allocation_strategy": "Sequential batch construction with surrogate updates using hallucinated (assumed) results for busy locations, thereby allocating diverse batch points under the current surrogate model assumptions.",
            "computational_cost_metric": "Number of posterior updates and their computational cost, wall-clock time and number of evaluations; KB involves recomputing posterior and acquisition function per sequential selection which is more expensive than sampling-based approaches.",
            "information_gain_metric": "Does not explicitly maximise information gain; uses surrogate mean to hallucinate results and then uses acquisition functions (e.g., UCB) on the updated surrogate.",
            "uses_information_gain": false,
            "exploration_exploitation_mechanism": "Base acquisition function (e.g., UCB) controls exploration-exploitation; hallucinated updates affect where subsequent batch points are placed, influencing diversity/exploration.",
            "diversity_mechanism": "Implicit via sequential updates with hallucinated values which discourage selecting points similar to the hallucinated ones.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Parallel workers and time budgets; computational cost of repeated surrogate updates is a practical consideration.",
            "budget_constraint_handling": "KB does not directly address runtime heterogeneity between workers; its repeated posterior recomputation per batch point can be computationally heavier, impacting wall-clock performance in practice.",
            "breakthrough_discovery_metric": "Measured via log simple regret and downstream validation/test performance in experiments.",
            "performance_metrics": "KB performs competitively on some tasks; in CIFAR-10 hyperparameter tuning KB achieved 83.9% (k=2) and 82.8% (k=4) test accuracy versus PLAyBOOK reported up to ~84.7% (k=2).",
            "comparison_baseline": "Compared against TS and PLAyBOOK in the paper's experiments.",
            "performance_vs_baseline": "KB sometimes outperforms TS but is generally outperformed by PLAyBOOK on many benchmark problems and on the CNN tuning task in the authors' experiments, particularly as batch sizes increase.",
            "efficiency_gain": "Provides batch diversity with surrogate-informed sequential updates but at higher computational cost for posterior recomputation compared to sampling-based methods; this can reduce wall-clock effectiveness when evaluation runtimes are heterogeneous.",
            "tradeoff_analysis": "KB trades improved batch-informed selection (via hallucination and sequential surrogate updates) against additional computational expense of repeated posterior updates; PLAyBOOK aims to retain the diversity benefits while remaining computationally cheaper by using analytic penalisation instead.",
            "optimal_allocation_findings": "KB is a reasonable heuristic for batch diversity but may be less suitable than penalisation-based asynchronous methods (PLAyBOOK) when runtime heterogeneity and large batch sizes make efficient wall-clock utilisation important.",
            "uuid": "e2632.4",
            "source_info": {
                "paper_title": "Asynchronous Batch Bayesian Optimisation with Improved Local Penalisation",
                "publication_date_yy_mm": "2019-01"
            }
        },
        {
            "name_short": "Ginsbourger Asynch.",
            "name_full": "Ginsbourger et al. asynchronous sampling-based marginalisation",
            "brief_description": "A sampling-based asynchronous BO approach that marginalises unknown function values at busy locations by sampling from the surrogate posterior; accurate but computationally expensive and scales poorly with batch size.",
            "citation_title": "Dealing with asynchronicity in parallel Gaussian process based global optimization",
            "mention_or_use": "mention",
            "system_name": "Sampling-based marginalisation for asynchronous BO (Ginsbourger et al.)",
            "system_description": "Method approximates the integral over unknown function values at busy locations by drawing samples from the GP posterior at those locations and marginalising when selecting new points. This reduces bias from missing values but requires many posterior samples and repeated expensive computations, leading to poor scaling with batch size and BO steps.",
            "application_domain": "Asynchronous parallel Gaussian process-based global optimisation.",
            "resource_allocation_strategy": "When a worker is free, choose new points by marginalising over possible outcomes at busy locations using posterior samples, thereby allocating points that account for uncertainty about those busy evaluations.",
            "computational_cost_metric": "High computational cost due to repeated posterior sampling and marginalisation; cost increases with batch size and number of required samples.",
            "information_gain_metric": "Implicitly accounts for uncertainty by marginalising over posterior draws; not formulated as an explicit mutual information objective but aims to select points robust to unknown busy values.",
            "uses_information_gain": null,
            "exploration_exploitation_mechanism": "Exploration arises from sampling posterior uncertainty; exploitation from posterior mean in acquisition evaluations conditioned on sampled values.",
            "diversity_mechanism": "Diversity arises indirectly by marginalising over uncertain busy values; no explicit analytic penaliser is used.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Computational budget for posterior sampling and wall-clock time; not optimised for large-scale asynchronous resource utilisation due to high cost.",
            "budget_constraint_handling": "Handles uncertainty about busy locations by sampling but at the cost of repeated expensive computation; not targeted at optimising wall-clock utilisation.",
            "breakthrough_discovery_metric": "Not directly specified in this paper; referenced as prior work with computational trade-offs discussed.",
            "performance_metrics": "Paper notes that sampling-based approach suffers from poor scaling with batch size and BO steps; not used as a baseline in large-scale experiments due to computational cost.",
            "comparison_baseline": "Mentioned as prior asynchronous method; contrasted with PLAyBOOK which is more computationally efficient.",
            "performance_vs_baseline": "Described as accurate but computationally prohibitive for large batches; PLAyBOOK aims to provide comparable practical performance with much lower selection cost.",
            "efficiency_gain": "None; the approach has high selection-time cost which reduces wall-clock evaluation throughput.",
            "tradeoff_analysis": "Highlights tradeoff between correct marginalisation of busy-location uncertainty and computational feasibility; motivates development of cheaper analytic penalisation approaches like PLAyBOOK.",
            "optimal_allocation_findings": "While marginalisation is principled, its computational cost makes it less suitable for large asynchronous parallel settings; cheaper penalties that approximate the effect of marginalisation can achieve practical gains.",
            "uuid": "e2632.5",
            "source_info": {
                "paper_title": "Asynchronous Batch Bayesian Optimisation with Improved Local Penalisation",
                "publication_date_yy_mm": "2019-01"
            }
        },
        {
            "name_short": "MOE / q-EI",
            "name_full": "MOE (q-EI gradient estimator / optimizer, Wang et al. 2016)",
            "brief_description": "An optimizer that estimates gradients of the multi-point expected improvement (q-EI) acquisition and uses stochastic gradient ascent to optimise q-EI for batch selection; computationally expensive but designed to directly optimise batch acquisition.",
            "citation_title": "Parallel Bayesian global optimization of expensive functions",
            "mention_or_use": "mention",
            "system_name": "MOE q-EI gradient-based optimizer",
            "system_description": "MOE estimates the gradient of q-EI (the expected improvement for a batch of points) and applies stochastic gradient ascent to solve the high-dimensional maximisation problem of selecting all batch points jointly. This method targets optimal batch utility but the joint optimisation of q-EI is computationally intensive.",
            "application_domain": "Batch Bayesian optimisation for expensive black-box functions where joint batch utility optimisation is desired.",
            "resource_allocation_strategy": "Select a batch by directly maximising q-EI jointly for all k points, thereby allocating the available parallel evaluations to maximise expected improvement over the batch.",
            "computational_cost_metric": "High computational cost for gradient estimation and joint optimisation; paper discusses this as prohibitive for direct q-EI maximisation without specialized optimisers like MOE.",
            "information_gain_metric": "q-EI is an expected improvement metric (expected reduction in objective value), not an explicit information-theoretic gain but an expected utility measure.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "q-EI balances exploration and exploitation through the expected improvement formulation which accounts for both mean and variance of GP posterior across the batch.",
            "diversity_mechanism": "Diversity emerges from joint optimisation of the batch q-EI which internalises the mutual influence of batch members; not via explicit penaliser but via the expected improvement objective for the batch.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Computational budget for batch selection and time budget; also number of parallel workers k.",
            "budget_constraint_handling": "Handles batch allocation by direct optimisation of expected improvement across the batch, but at the cost of increased computational selection time which can reduce wall-clock evaluation throughput.",
            "breakthrough_discovery_metric": "Expected improvement across the batch (q-EI) and downstream simple regret as measured experimentally.",
            "performance_metrics": "Referenced as a principled batch acquisition, but its direct maximisation is computationally challenging and MOE provides an approximate scalable solution; not directly benchmarked in this paper's experiments.",
            "comparison_baseline": "Described in related work and contrasted with sampling-based and penalisation-based batch methods.",
            "performance_vs_baseline": "Not experimentally compared in this paper; cited as computationally intensive motivating alternatives like TS and PLAyBOOK that prioritize selection-time efficiency.",
            "efficiency_gain": "When effectively optimised, q-EI can provide high-quality batches but selection-time costs can negate wall-clock gains; MOE aims to make this tractable via gradient estimates.",
            "tradeoff_analysis": "Paper highlights tension between selecting high-quality batches (joint q-EI) and the computational cost of doing so; motivates cheaper alternatives for asynchronous contexts.",
            "optimal_allocation_findings": "Joint batch optimisation is attractive theoretically but practically expensive for asynchronous large-batch settings; approximate and cheaper schemes (penalisation, sampling) can be preferable in practice.",
            "uuid": "e2632.6",
            "source_info": {
                "paper_title": "Asynchronous Batch Bayesian Optimisation with Improved Local Penalisation",
                "publication_date_yy_mm": "2019-01"
            }
        },
        {
            "name_short": "Info-theoretic methods",
            "name_full": "Information-theoretic acquisition methods (Entropy Search, Predictive Entropy Search, Max-value Entropy Search)",
            "brief_description": "A class of acquisition functions that select points by maximising expected information about the global optimum (e.g., reduction in entropy of the minimiser or maximal value), thereby explicitly targeting information gain.",
            "citation_title": "Entropy search for informationefficient global optimization",
            "mention_or_use": "mention",
            "system_name": "Information-theoretic acquisition methods (Entropy/Predictive/Max-value Entropy Search)",
            "system_description": "Methods such as Entropy Search, Predictive Entropy Search (PES), and Max-value Entropy Search (MES) compute acquisition values based on expected reduction in entropy (uncertainty) about the location/value of the global optimum. They directly quantify information gain and select evaluations to maximally reduce posterior uncertainty about the optimum.",
            "application_domain": "Global optimisation of expensive black-box functions where obtaining information about the optimum quickly is important.",
            "resource_allocation_strategy": "Allocate evaluations to maximise expected information gain about the global minimiser (or minimum value), often requiring expensive computations or approximations to estimate expected reduction in entropy.",
            "computational_cost_metric": "Computational cost often dominated by the need to approximate mutual information/entropy integrals and to simulate posterior reductions; selection-time cost can be substantial compared to simpler acquisitions like UCB.",
            "information_gain_metric": "Explicit mutual information or expected reduction in posterior entropy about the minimiser or min-value.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Explicitly exploration-driven via information acquisition; exploitation arises indirectly as information leads to focused sampling near the optimum.",
            "diversity_mechanism": "Diversity emerges from selecting points that reduce uncertainty across the posterior over minimiser locations; not via explicit penaliser but via information-theoretic objectives which naturally spread queries to reduce entropy.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Computational budget for selection-time computations and evaluation time budget.",
            "budget_constraint_handling": "These methods can be computationally expensive per selection; practical implementations use approximations to make them tractable, but high selection cost can reduce wall-clock throughput in parallel asynchronous settings.",
            "breakthrough_discovery_metric": "Expected information gain about the global minimiser; empirically evaluated via reduction in simple regret.",
            "performance_metrics": "Referenced as methods that maximise information about the objective/minimiser; not used as experimental baselines in the main experiments of this paper but cited in related work.",
            "comparison_baseline": "Mentioned alongside other acquisition designs (UCB, EI, KG); contrasted by being explicitly information-centric.",
            "performance_vs_baseline": "Not empirically compared in this paper; cited as prior art focused on information gain that can be expensive to compute.",
            "efficiency_gain": "Potentially high sample efficiency by directly maximising information per evaluation, but selection-time computational cost can limit wall-clock efficiency in parallel asynchronous settings.",
            "tradeoff_analysis": "Paper situates these methods as alternatives focused on information gain; contrasts the computational cost of such approaches with the cheaper penalisation-based PLAyBOOK that trades an explicit information objective for scalable, diversity-promoting exclusion zones.",
            "optimal_allocation_findings": "Information-theoretic objectives are principled for maximising per-evaluation information but may be less practical in large-scale asynchronous parallel contexts due to high selection-time cost; approximations or cheaper heuristics may be preferred depending on resource constraints.",
            "uuid": "e2632.7",
            "source_info": {
                "paper_title": "Asynchronous Batch Bayesian Optimisation with Improved Local Penalisation",
                "publication_date_yy_mm": "2019-01"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Batch Bayesian optimization via local penalization",
            "rating": 2
        },
        {
            "paper_title": "Parallelised Bayesian optimisation via Thompson sampling",
            "rating": 2
        },
        {
            "paper_title": "Dealing with asynchronicity in parallel Gaussian process based global optimization",
            "rating": 2
        },
        {
            "paper_title": "Parallel Bayesian global optimization of expensive functions",
            "rating": 2
        },
        {
            "paper_title": "Parallel predictive entropy search for batch global optimization of expensive objective functions",
            "rating": 2
        },
        {
            "paper_title": "Entropy search for informationefficient global optimization",
            "rating": 1
        },
        {
            "paper_title": "Max-value entropy search for efficient Bayesian optimization",
            "rating": 1
        }
    ],
    "cost": 0.025298,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Asynchronous Batch Bayesian Optimisation with Improved Local Penalisation</h1>
<p>Ahsan S. Alvi* ${ }^{12}$ Binxin Ru ${ }^{11}$ Jan Calliess ${ }^{13}$ Stephen J. Roberts ${ }^{123}$ Michael A. Osborne ${ }^{12}$</p>
<h4>Abstract</h4>
<p>Batch Bayesian optimisation (BO) has been successfully applied to hyperparameter tuning using parallel computing, but it is wasteful of resources: workers that complete jobs ahead of others are left idle. We address this problem by developing an approach, Penalising Locally for Asynchronous Bayesian Optimisation on $k$ workers (PLAyBOOK), for asynchronous parallel BO. We demonstrate empirically the efficacy of PLAyBOOK and its variants on synthetic tasks and a real-world problem. We undertake a comparison between synchronous and asynchronous BO, and show that asynchronous BO often outperforms synchronous batch BO in both wall-clock time and number of function evaluations.</p>
<h2>1. Introduction</h2>
<p>Bayesian optimisation (BO) is a popular sequential global optimisation technique for functions that are expensive to evaluate (Brochu et al., 2010). Whilst standard BO may be sufficient for many applications, it is often the case that multiple experiments can be run at the same time in parallel. For example, in the case of drug discovery, many different compounds can be tested in parallel via high throughput screening equipment (Hernández-Lobato et al., 2017), and when optimising machine learning algorithms, we can train different model configurations concurrently on multiple workers (Chen et al., 2018; Kandasamy et al., 2018). This observation lead to the development of parallel ("batch") BO algorithms, which, at each optimisation step, recommend a batch of $k$ configurations to be evaluated.</p>
<p>In cases where the runtimes of tasks are roughly equal, this is usually sufficient, but, if the runtimes in a batch vary, this will lead to inefficient utilisation of our hardware. For</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>example, consider the optimisation of the number of units in the layers of a neural network. Training and evaluating a large network (greater number of units per layer) will take significantly longer than a small network (fewer units per layer), so for an iteration of (synchronous) batch BO to complete, we need to wait for the slowest configuration in the batch to finish, leaving the other workers idle. In order to improve the utilisation of parallel computing resources, we can run function evaluations asynchronously: as soon as $c$ workers $(c&lt;k)$ complete their jobs, we choose new tasks for them.</p>
<p>Although asynchronous batch BO has a clear advantage over synchronous batch BO in terms of wall-clock time (Kandasamy et al., 2018), it may lose out in terms of sample efficiency, as an asynchronous method takes decisions with less data than its synchronous counterpart at each stage of the optimisation. We investigate this empirically in this work.</p>
<p>Our contributions can be summarised as follows.</p>
<ul>
<li>We develop a new approach to asynchronous parallel BO, Penalising Locally for Asynchronous Bayesian Optimisation on $k$ workers (PLAyBOOK), which uses penalisation-based strategies to prevent redundant batch selection. We show that our approach compares favourably against existing asynchronous methods.</li>
<li>We propose a new penalisation function, which prevents redundant samples from being chosen. We also propose designing the penalisers using local (instead of global) variability features of the surrogate to more effectively explore the search space.</li>
<li>We demonstrate empirically that asynchronous methods perform at least as well as their synchronous variants. We also show that PLAyBOOK outperforms its synchronous variants both in terms of wall-clock time and sample efficiency, particularly for larger batch sizes. This renders PLAyBOOK a competitive parallel BO method.</li>
</ul>
<h2>2. Related work</h2>
<p>Many different synchronous batch BO methods have been proposed over the past years. Approaches include using</p>
<p>hallucinated observations (Ginsbourger et al., 2010; Desautels et al., 2014), knowledge gradient (Wu \&amp; Frazier, 2016), Determinental point processes (Kathuria et al., 2016), maximising the information gained about the objective function or the global minimiser (Contal et al., 2013; Shah \&amp; Ghahramani, 2015), and sampling-based simulation (Azimi et al., 2010; Kandasamy et al., 2018; Hernández-Lobato et al., 2017). A recent synchronous batch BO method that demonstrated promising empirical results is Local Penalisation (LP) (González et al., 2016). After adding a configuration $x_{j}$ to the batch, LP penalises the value of the acquisition function in the neighbourhood of $x_{j}$, encouraging diversity in the batch selection.</p>
<p>Asynchronous BO has received surprisingly little attention compared to synchronous BO to date. Ginsbourger et al. (2011) proposed a sampling-based approach that approximately marginalises out the unknown function values at busy locations by taking samples from the posterior at those locations. Due to its reliance on sampling, it suffers from poor scaling, both in batch size and BO steps.</p>
<p>Wang et al. (2016) developed an efficient global optimiser (MOE) which estimates the gradient of q-EI, a batch BO method proposed by Ginsbourger et al. (2008), and uses it in a stochastic gradient ascent algorithm to solve the prohibitively-expensive maximisation of the q-EI acquisition function, which selects all points in the batch simultaneously.</p>
<p>A more recent method utilizes Thompson Sampling (Kandasamy et al., 2018) (TS) to select new batch points. This has the benefit of attractive scaling, since the method minimises samples from the surrogate model's posterior. In the case of a Gaussian process (GP) model, a batch point is placed at the minimum location of a draw from a multivariate Gaussian distribution. The disadvantage of TS is that it relies on the uncertainty in the surrogate model to ensure that the batch points are well-distributed in the search space.</p>
<h2>3. Preliminaries</h2>
<p>To perform Bayesian optimisation to find the global minimum of an expensive objective function $f$, we must first decide on a surrogate model for $f$. Using a Gaussian process (GP) as the surrogate mode is a popular choice, due to the GP's potent function approximation properties and ability to quantify uncertainty. A GP is a prior over functions that allows us to encode our prior beliefs about the properties of the function $f$, such as smoothness and periodicity. A comprehensive introduction to GPs can be found in (Rasmussen \&amp; Williams, 2006).</p>
<p>For a scalar-valued function $f$ defined over a compact space $\mathcal{X}: \mathbb{R}^{d} \rightarrow \mathbb{R}$, we define a GP prior over $f$ to be $\mathcal{G P}\left(m(x), k\left(x, x^{\prime} ; \theta\right)\right)$ where $m(x)$ is the mean function, $k(\cdot, \cdot)$ is a covariance function (also known as the kernel) and $\theta$ are the hyperparameters of the kernel. The posterior distribution of the GP at an input $\tilde{x}$ is Gaussian:</p>
<p>$$
p\left(f(\tilde{x}) \mid \tilde{x}, \mathcal{D}_{s}\right)=\mathcal{N}\left(f(\tilde{x}) ; \mu(\tilde{x}), \sigma^{2}(\tilde{x})\right)
$$</p>
<p>with mean and variance</p>
<p>$$
\begin{aligned}
\mu(\tilde{x}) &amp; =k(\tilde{x}, X) K(X, X)^{-1} Y \
\sigma^{2}(\tilde{x}) &amp; =k\left(\tilde{x}, \tilde{x}^{\prime}\right)-k(\tilde{x}, X) K(X, X)^{-1} k\left(X, \tilde{x}^{\prime}\right)
\end{aligned}
$$</p>
<p>where $X$ is a matrix with an input location in each row $\left{x_{1}, x_{2}, \ldots, x_{N}\right}$ and $Y$ is a column vector of the corresponding observations $\left{y_{1}, y_{2}, \ldots, y_{N}\right}$, where $y_{i}=f\left(x_{i}\right)$. The hyperparameters of the model have been dropped in these equations for clarity.</p>
<p>The second choice we make is that of the acquisition function $\alpha: \mathbb{R}^{d} \rightarrow \mathbb{R}$. Many different functional forms for $\alpha(x)$ have been proposed to date (Kushner, 1964; Jones et al., 1998; Srinivas et al., 2010; Hennig \&amp; Schuler, 2012; Hernández-Lobato et al., 2014; Ru et al., 2018), each with their relative merits and disadvantages. Although our method is applicable to most acquisition functions, we use the popular GP Upper Confidence Bound (UCB) in our experiments (Srinivas et al., 2010). UCB is defined as</p>
<p>$$
\alpha_{\mathrm{UCB}}(x)=\mu(x)+\kappa \sigma(x)
$$</p>
<p>where $\mu(x)$ and $\sigma(x)$ are the mean and standard deviation of the GP posterior and $\kappa$ is a parameter that controls the trade-off between exploration (visiting unexplored areas in $\mathcal{X}$ ) and exploitation (refining our belief by querying close to previous samples). This parameter can be set according to an annealing schedule (Srinivas et al., 2010) or fixed to a constant value.</p>
<h2>4. Asynchronous vs synchronous BO</h2>
<p>In synchronous BO, the aim is to select a batch of promising locations $\mathcal{B}=\left{x_{j}\right}<em j="j">{j=1}^{k}$ that will be evaluated in parallel (Fig. 1). Solving this task directly is difficult, which is why most batch BO algorithms convert this selection into a sequential procedure, selecting one point at a time for the batch. At the $s$ th BO step, the optimal choice of batch point $x</em>$ that we have chosen so far for the batch:}(j \in{1,2, \ldots, k})$ should then not only take into account our current knowledge of $f$, but also marginalise over possible function values at the locations $\left{x_{i}\right}_{i=1}^{j-1</p>
<p>$$
\begin{aligned}
x_{j}= &amp; \underset{x \in \mathcal{X}}{\arg \max } \int \alpha\left(x \mid \mathcal{D}<em j-1="j-1">{s}, \mathcal{D}</em>\right) \
&amp; \prod_{i=1}^{j-1} p\left(y_{i} \mid x_{i}, \mathcal{D}<em i-1="i-1">{s}, \mathcal{D}</em>
\end{aligned}
$$}\right) d y_{i</p>
<p>where $\mathcal{D}<em j-1="j-1">{s}$ are the observations we have gathered so far and $\mathcal{D}</em>\right}}=\left{x_{i}, y_{i<em 0="0">{i=1}^{j-1}$ and $\mathcal{D}</em>=\varnothing$ (González et al., 2016).</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1. Illustration showing the difference between synchronous and asynchronous batch BO in the case of $k=3$ parallel workers. The blue bar indicates the processing time taken for a worker to evaluate its assigned task and the red bar indicates the waiting time for a worker between completing its previous task and beginning a new task. It is clear that asynchronous batch BO, which makes better use of the computing resources, can complete a greater number of evaluations than its synchronous counterpart within the same duration.</p>
<p>In asynchronous BO, the key motivation is to maximise the utilisation of our $k$ parallel workers. After a desired number of workers $c&lt;k$ complete their tasks, we assign new tasks to them without waiting for the remaining $b=(k-c)$ busy workers to complete their tasks. Now the general design for selecting the next query point marginalises over the likely function values both at locations under evaluation by busy workers, as well as the already-selected points in the batch:</p>
<p>$$
\begin{aligned}
x_{j}= &amp; \underset{x \in \mathcal{X}}{\arg \max } \iint \alpha\left(x \mid \mathcal{D}<em -="-">{s</em>}}, \mathcal{D<em j-1="j-1">{b}, \mathcal{D}</em>\right) \
&amp; \prod_{i=1}^{j-1} p\left(y_{i} \mid x_{i}, \mathcal{D}<em -="-">{s</em>}}, \mathcal{D<em i-1="i-1">{b}, \mathcal{D}</em>\right) \
&amp; \prod_{l=1}^{b} p\left(y_{l} \mid x_{l}, \mathcal{D}<em -="-">{s</em>
\end{aligned}
$$}}\right) d y_{i} d y_{l</p>
<p>where $j \in{1, \ldots, c}$ and $\mathcal{D}<em i="i">{b}=\left{x</em>\right}}, y_{i<em s__-="s_{-">{i=1}^{b}$ represents the locations and function values of the busy locations. $\mathcal{D}</em>}}$ are the observations available at the point of constructing the asynchronous batch. In general, $\mathcal{D<em -="-">{s</em>$ that would be used to select the equivalent batch of evaluations in the synchronous setting. Fig. 1 shows the case of $c=1$ and thus $b=k-1=2$.}}$contains fewer observations than the $\mathcal{D}_{s</p>
<p>In a given period of time, asynchronous batch BO is able to process a greater number of evaluations than the synchronous approach: asynchronous BO offers clear gains in resource utilisation. However, <em>Kandasamy et al. (2018)</em>
claim that the asynchronous setting may not lead to better performance when measured by the number of evaluations. The authors point out that a new evaluation in a sequentiallyselected synchronous batch will be selected with at most $k-1$ evaluations “missing” (that is, with knowledge of their locations $x$ but absent the knowledge of their values $y$ ), corresponding to the previously-selected points in the current batch (i.e. $j-1 \leq k-1$ in Eq. (5)). Evaluations in the asynchronous case are always chosen with $k-1$ "missing" evaluations.</p>
<p>However, to our knowledge, there exists little empirical investigation of the performance difference between synchronous and asynchronous batch methods. We conducted this comparison on a large set of benchmark test functions and found that asynchronous batch BO can be as good as synchronous batch BO for different batch selection methods. Additionally, for the penalisation-based methods we propose, asynchronous operation often outperforms the synchronous setting, particularly as the batch size increases. We will discuss this interesting empirical observation in Section 6.2 .</p>
<h2>5. Penalisation-based asynchronous BO</h2>
<p>We now present our core algorithmic contributions. As discussed in Section 2, the existing asynchronous BO methods suffer drawbacks such as the prohibitively high cost of repeatedly updating GP surrogates when selecting batch points <em>(Ginsbourger et al., 2011)</em> or the risk of redundant sampling at or near a busy location in the batch <em>(Kandasamy et al., 2018)</em>. In view of these limitations, we propose a penalisation-based asynchronous method which encourages sampling diversity among the points in the batch as well as eliminating the risk of repeated samples in the same batch. Our proposed method remains computationally efficient, and thus scales well to large batch sizes.</p>
<p>Inspired by the Local Penalisation approach (LP) in synchronous BO <em>(González et al., 2016)</em>, we approximate Eq. (6) for the case of $c=1$ as:</p>
<p>$$
x_{j}=\arg \max <em s__-="s_{-">{x \in \mathcal{X}}\left{\alpha\left(x \mid \mathcal{D}</em>}}\right) \prod_{i=1}^{k-1} \phi\left(x \mid x_{i}, \mathcal{D<em -="-">{s</em>\right)\right}
$$}</p>
<p>where $\phi\left(x \mid x_{i}, \mathcal{D}<em -="-">{s</em>\right}}}\right)$is the penaliser function centred at the busy locations $\left{x_{i<em i="i">{i=1}^{k-1}$. In the following subsections, we design effective penaliser functions by harnessing the Lipschitz properties of the function and its GP posterior. To simplify notation, we denote $\phi\left(x \mid x</em>}, \mathcal{D<em -="-">{s</em>}}\right)$as $\phi\left(x \mid x_{i}\right)$ and $\alpha\left(x \mid \mathcal{D<em -="-">{s</em>\right)$as $\alpha(x)$ in the remainder of the section.}</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2. Illustration of asynchronous batch selection by naïve LP and HLP. The top left plot shows the acquisition function $\alpha(x)$ and the locations (i.e. $x_{b1}$ and $x_{b2}$ denoted in black dots) under evaluation by busy workers. The top right plot shows the shapes of two penalisers at the busy location $x_{b1}$. Their respective penalisation effects on $\alpha(x)$ at $x_{b1}$ and $x_{b2}$ as well as the new batch point $x_{3}$ to be assigned to the available worker are shown in the subplots that follow, LP on the left and HLP on the right.</p>
<p>with $\hat{\phi}\left(x \mid x_{j}\right) \rightarrow \phi\left(x \mid x_{j}\right)$ as $p \rightarrow-\infty$.</p>
<p>In addition, the global optimum $M$ is unknown in practice and is usually approximated by the best function value observed $\hat{M}=\min \left{f\left(x_{i}\right)\right}<em j="j">{i}^{n}$ (González et al., 2016). This approximation tends to lead to underestimation of $\mu\left(x</em>&gt;M$.}\right)-M$ and thus $\mathbb{E}\left(r_{j}\right)$, reducing the extent of the penalisation at $x_{j}$ and in the region nearby. HLP mitigates this effect by penalising significantly harder than the penaliser proposed by González et al. (2016), and maximally at $x_{j}$ ( $\alpha\left(x_{j}\right)=0$ ). Thus, our method is less affected by over-estimation of the global minimum $\hat{M</p>
<h3>5.1. Hard Local Penaliser</h3>
<p>Assume the unknown objective function is Lipschitz continuous with constant $L$ and has a global minimum value $f\left(x^{*}\right)=M$ and $x_{j}$ is a busy task,</p>
<p>$$
\left|f\left(x_{j}\right)-M\right| \leq L\left|x_{j}-x^{*}\right|
$$</p>
<p>This implies $x^{*}$ cannot lie within the spherical region centred on $x_{j}$ with radius $r_{j}=\frac{f\left(x_{j}\right)-M}{L}$;</p>
<p>$$
\mathbb{S}\left(x_{j}, r_{j}\right)=\mathcal{X}\left{x \in \mathcal{X}:\left|x-x_{j}\right| \leq r_{j}\right}
$$</p>
<p>If $x_{j}$ is still under evaluation by a worker, there is no need for any further selections inside $\mathbb{S}\left(x_{j}, r_{j}\right)$.
Given that $f\left(x_{j}\right) \sim \mathcal{N}\left(\mu\left(x_{j}\right), \sigma^{2}\left(x_{j}\right)\right)$ and thus $\mathbb{E}\left(r_{j}\right)=$ $\frac{\left|\mu\left(x_{j}\right)-M\right|}{L}$, applying Hoeffding's inequality for all $\epsilon&gt;0$ (Jalali et al., 2013) gives</p>
<p>$$
P\left(r_{j}&gt;\mathbb{E}\left(r_{j}\right)+\epsilon\right) \leq \exp \left(-\frac{2 \epsilon^{2} L^{2}}{\sigma\left(x_{j}\right)^{2}}\right)
$$</p>
<p>which implies there is a high probability (around $99 \%$ ) that $r_{j} \leq \frac{\left|\mu\left(x_{j}\right)-M\right|}{L}+1.5 \frac{\sigma\left(x_{j}\right)}{L}$.
The penalisation function $\phi\left(x \mid x_{j}\right)$ should incorporate this belief to guide the selection of the next asynchronous batch point by reducing the value of the acquisition function at locations $\left{x \in \mathbb{S}\left(x_{j}, r_{j}\right)\right}$. A valid penaliser should possess the several properties:</p>
<ul>
<li>the penalisation region shrinks as the expected function value at $x_{j}$ gets close to the global minimum (i.e. small $\left|\mu\left(x_{j}\right)-M\right|$ ) (González et al., 2016);</li>
<li>the penalisation region shrinks as $L$ increases (González et al., 2016);</li>
<li>the extent of penalisation on $\alpha(x)$ increases as $x$ gets closer to $x_{j}$ with $\alpha\left(x_{j}\right)=0$ if $\alpha(x) \geq 0$ for all $x \in \mathcal{X}$.</li>
</ul>
<p>The Local Penaliser (LP) in (González et al., 2016) fulfils the first two properties but not the final one which we believe is crucial. Thus, directly using it for the asynchronous case makes the algorithm vulnerable to redundant sampling as illustrated in Fig. 2. In view of this limitation, we propose a simple yet effective Hard Local Penaliser (HLP) which satisfies all three conditions</p>
<p>$$
\phi\left(x \mid x_{j}\right)=\min \left{\frac{\left|x-x_{j}\right|}{\mathbb{E}\left(r_{j}\right)+\gamma \frac{\sigma\left(x_{j}\right)}{L}}, 1\right}
$$</p>
<p>where $\gamma$ is a constant.
The above expression can be made differentiable by the approximation:</p>
<p>$$
\hat{\phi}\left(x \mid x_{j}\right)=\left[\left(\frac{\left|x-x_{j}\right|}{\mathbb{E}\left(r_{j}\right)+\gamma \frac{\sigma\left(x_{j}\right)}{L}}\right)^{p}+1^{p}\right]^{1 / p}
$$</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 2. Illustration of asynchronous batch selection by naïve LP and HLP. The top left plot shows the acquisition function $\alpha(x)$ and the locations (i.e. $x_{b 1}$ and $x_{b 2}$ denoted in black dots) under evaluation by busy workers. The top right plot shows the shapes of two penalisers at the busy location $x_{b 1}$. Their respective penalisation effects on $\alpha(x)$ at $x_{b 1}$ and $x_{b 2}$ as well as the new batch point $x_{3}$ to be assigned to the available worker are shown in the subplots that follow, LP on the left and HLP on the right.
with $\hat{\phi}\left(x \mid x_{j}\right) \rightarrow \phi\left(x \mid x_{j}\right)$ as $p \rightarrow-\infty$.
In addition, the global optimum $M$ is unknown in practice and is usually approximated by the best function value observed $\hat{M}=\min \left{f\left(x_{i}\right)\right}<em j="j">{i}^{n}$ (González et al., 2016). This approximation tends to lead to underestimation of $\mu\left(x</em>&gt;M$.}\right)-M$ and thus $\mathbb{E}\left(r_{j}\right)$, reducing the extent of the penalisation at $x_{j}$ and in the region nearby. HLP mitigates this effect by penalising significantly harder than the penaliser proposed by González et al. (2016), and maximally at $x_{j}$ ( $\alpha\left(x_{j}\right)=0$ ). Thus, our method is less affected by over-estimation of the global minimum $\hat{M</p>
<h3>5.2. Local Estimated Lipschitz constants</h3>
<p>In BO, the global Lipschitz constant $L$ of the objective function is unknown. Assuming the true objective function $f$ is a draw from its GP surrogate model, we can approximate $L$ with $\hat{L}=\max <em _nabla="\nabla">{x \in \mathcal{X}}\left|\mu</em>$ is large, then the penaliser's radius will be small and we will end up selecting multiple points in the same unexplored region, which is undesirable.}(x)\right|$ where $\mu_{\nabla}(x)$ is the posterior mean of the derivative GP (González et al., 2016). However, using the estimated global Lipschitz constant $\hat{L}$ to design the shape of the penalisers at all busy locations in the batch may not be optimal. Consider the case where a point in an unexplored region is still under evaluation. If $\hat{L</p>
<p>Therefore, we propose to use a separate Lipschitz constant, which is locally estimated, for each busy location. Here,</p>
<p>"locality" is encoded in our choice of kernel and its hyperparameters, e.g. via the lengthscale parameter in the Matérn class of kernels. The use of local Lipschitz constants will enhance the efficiency of exploration because they allow the penaliser to create larger exclusion zones in areas in which we are very uncertain (the surrogate model is near its prior or has low curvature) and smaller penalisation zones in interesting, high-variability, areas. This insight is also corroborated in <em>(Blaas et al., 2019)</em>.</p>
<p>We demonstrate the different effects of using approximate global and local Lipschitz constants with a qualitative example. In Fig. 3a, the estimated global Lipschitz constant is used for penalisation at both busy locations $x_{b1}=-1$ and $x_{b2}=1$ (denoted as black dots). The relatively large value of the global Lipschitz constant ($\hat{L}<em b2="b2">{b1}=\hat{L}</em>}=\hat{L}=3.47$) due to the high curvature of the surrogate in the central region leads to a small penalisation zone around the two busy locations at the boundary. This causes the algorithm to miss the informative region in the centre and instead revisit the region near $x_{b1}$ to choose the new point in the asynchronous batch. On the other hand, in Fig. 3b, the use of a locally estimated Lipschitz constant allows us to penalise a larger zone around points where the surrogate is relatively flat ($\hat{L<em b1="b1">{b1}=0.712$ for $x</em>}$), while still penalising smaller regions where there is higher variability ($\hat{L<em 3="3">{3}=3.45$ at $x</em>$).</p>
<p>In our experiments we used a Matérn-52 kernel and defined the local region for evaluating the Lipschitz constant for a batch point $x_{j}$ to be a hypercube centred on $x_{j}$ with the length of the each side equal to the lengthscale corresponding to that input dimension.</p>
<p>In summary, we propose a new class of asynchronous BO methods, Penalisation Locally for Asynchronous Bayesian Optimisation Of K workers (PLAyBOOK), which uses analytic penaliser functions to prevent redundant sampling at or near the busy locations in the batch and encourage desirably explorative searching behaviour. We differentiate between PLAyBOOK-L, which uses a naïve Local penaliser, PLAyBOOK-H, that uses the HLP penaliser, as well as their variations with locally estimated Lipschitz constants, PLAyBOOK-LL and PLAyBOOK-HL.</p>
<h2>6. Experimental evaluation</h2>
<p>We begin our empirical investigations by performing a head-to-head comparison of synchronous and asynchronous BO methods, to test the intuitions described in Section 4. We specifically look at optimisation performance for asynchronous and synchronous variants of the parallel BO methods measured over time and number of evaluations, and we show empirically that asynchronous is preferable over synchronous BO on both counts.</p>
<p>We then experiment with our proposed asynchronous meth-</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" />
(a) Penalisation with global L (b) Penalisation with local L
Figure 3. Different penalisation effects on $\alpha(x)$ of using a single global Lipschitz constant compared to local Lipschitz constants. The top plots in both (a) and (b) show the true objective function (red line), six observed points (black crosses), the GP posterior mean (black line) and variance (blue shade), the two busy locations (black dots) and the next query point (red dot) selected by using the HLP with global and local Lipschitz constants respectively. The plots in (a) show the penalisation effect on busy locations using the same global Lipschitz constant while those in (b) show the effect of using local Lipschitz constants. It is clear that penalising the busy locations based on local Lipschitz constants allows the algorithm to capture the informative peak at the central region while selection based on the single global Lipschitz constant leads us to revisit the flat region near the boundary due to insufficient penalisation at $x_{1}$.
ods (PLAyBOOK-L, PLAyBOOK-H, PLAyBOOK-LL and PLAyBOOK-HL) on a number of benchmark test functions as well as a real-world expensive optimisation task. Our methods are compared against the state-of-the-art asynchronous BO methods, Thompson sampling (TS) <em>(Kandasamy et al., 2018)</em>, as well as the Kriging Believer heuristic method (KB) <em>(Ginsbourger et al., 2010)</em> applied asynchronously.</p>
<p>For all the benchmark functions, we measure the log of the simple regret $R$, which is the difference between the true minimum value $f\left(x^{*}\right)$ and the best value found by the BO method:</p>
<p>$$
\log (R)=\log \left|f\left(x^{*}\right)-\min_{i=1, \ldots, n} f\left(x_{i}\right)\right|
$$</p>
<h3>6.1. Implementation details</h3>
<p>To ensure a fair comparison, we implemented all methods in Python using the same packages ${ }^{1}$.</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 4. A head-to-head comparison of synchronous (orange) vs asynchronous (blue) versions of a parallel BO method. The median (solid line) and quartiles (shaded region) of the regret for optimising ack-5D for 30 random initialisations are shown. The top row shows regret vs evaluation time and the bottom row shows regret vs number of evaluations. Notice how asynchronous methods in the top row outperform their synchronous counterparts in terms of evaluation time. Note also how asynchronous methods in the bottom row outperform their synchronous counterparts in terms of sample efficiency, too.</p>
<p>In all experiments, we used a zero-mean Gaussian process surrogate model with a Matérn-52 kernel with ARD. We optimised the kernel and likelihood hyperparameters by maximising the log marginal likelihood. For the benchmark test functions, we fixed the noise variance to $\sigma^{2}=10^{-6}$ and started with $3 * d$ random initial observations. Each experiment was repeated with 30 different random initialisations and the input domains for all experiments were scaled to $[-1,1]^{d}$.</p>
<p>All methods except TS used UCB as the acquisition function $\alpha(x)$. For our PLAyBOOK-H and PLAyBOOK-HL, we choose $\gamma=1$ and $p=-5$ in the HLP (Eq. (12)). For TS, we use 10,000 sample points for each batch point selection. For the other methods, we evaluate $\alpha(x)$ at 3,000 random locations and then choose the best one after locally optimising the best 5 samples for a small number of local optimisation steps.</p>
<p>We evaluate the performance of the different batch BO strategies using popular global optimisation test functions ${ }^{2}$. We show results for the Eggholder function defined on $\mathbb{R}^{2}$ (egg2D), the Ackley function defined on $\mathbb{R}^{5}$ and the Michalewicz function defined on $\mathbb{R}^{10}$ (mic-10D). Results for experiments on different example tasks can be found in Sections 2 and 3 in the supplementary materials.</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h3>6.2. Synchronous vs asynchronous BO</h3>
<p>In this section we address the question of choosing between asynchronous and synchronous BO. In order to investigate their relative merits, we compared asynchronous and synchronous BO methods’ performance as a function of wallclock time and number of evaluations.</p>
<h3>6.2.1. Evaluation Time</h3>
<p>In order to facilitate this comparison, we needed to inject a measure of runtime for different tasks, as the test functions can be evaluated instantaneously. We followed the procedure proposed in <em>Kandasamy et al. (2018)</em> to sample an evaluation time for each task so as to simulate the asynchronous setting. We chose to use a half-normal distribution with scale parameter $\sigma=\sqrt{\pi / 2}$, which gives us a distribution of runtime values with mean at 1.</p>
<p>Results on the ack-5D task are shown in Figs. 4(a)-(d). Due to space constraints, results for further experiments can be found in Section 2 of the supplementary materials. We know that asynchronous BO has the advantage over synchronous BO in terms of utilisation of resources, as shown qualitatively in Fig. 1, simply due to the fact that any available worker is not required to wait for all evaluations in the batch to finish before moving on. Therefore, given the same time budget, a greater number of evaluations can be taken in the asynchronous setting than in the synchronous setting, which, as confirmed by our experiments, translates</p>
<p>to faster optimisation of $f$ in terms of the total (wall-clock) time spent evaluating tasks.</p>
<h3>6.2.2. NUMBER OF EVALUATIONS</h3>
<p>A more interesting question to answer is whether asynchronous BO methods are really less data efficient than synchronous BO methods as discussed in Section 4 Figs. 4(e)-(h) show a subset of the experiments we conducted. More results can be found in Section 2 in the supplementary materials.</p>
<p>An unexpected yet interesting behaviour we note is that as $k$ increases, the PLAyBOOK methods tend to clearly outperform their respective synchronous counterparts even in terms of sample efficiency. This observation runs counter to the guidance provided in Kandasamy et al. (2018) and such behaviour is less evident for the other two batch methods, TS and KB.</p>
<p>We think this observation may be explained by the difference in nature between the PLAyBOOK and TS/KB: in the case of TS we rely on stochasticity in sampling, and in KB we are re-computing the posterior variance and $\alpha(x)$ each time a batch point is selected. The penalisation-based methods, on the other hand, simply down-weight the acquisition function, and in the synchronous case these penalisers coincide with the high-value regions of the acquisition function. This means that unless the acquisition function has a large number of spaced-out peaks, we will quickly be left without high-utility locations to choose new batch points from.</p>
<p>This seems to be the reason for the superior performance of asynchronous PLAyBOOK methods over their synchronous variants because they benefit from the fact that the busy locations being penalised do not necessarily coincide with the peaks in $\alpha(x)$, as the surrogate used to compute $\alpha(x)$ is more informed than the one used to decide the locations of the busy locations previously. This means that points with high utilities are more likely to to be preserved.</p>
<p>Taking into account the fact that the asynchronous PLAyBOOK methods tend to perform at least equally well, if not significantly better than their synchronous variants on both time and efficiency, and that the asynchronous PLAyBOOK methods gain more advantage over synchronous ones as the batch size increases, we believe that this points to the fact that penalisation-based methods are inherently better suited as asynchronous methods. Hence, for users that are running parallel BO and have selected LP, we recommend they consider running PLAyBOOK instead due to its attractive benefits.</p>
<h3>6.3. Asynchronous parallel BO</h3>
<p>Now that we have strengthened the appeal of asynchronous BO, we turn to evaluating PLAyBOOK against existing asynchronous BO methods.</p>
<h3>6.3.1. SYNTHETIC EXPERIMENTS</h3>
<p>We ran PLAyBOOK and competing asynchronous BO methods on the global optimisation test functions described in Section 6.1. The results are shown in Fig. 5, and more results on different optimisation problems are provided in Section 3 in the supplementary materials.</p>
<p>On the global optimisation test functions we noted that in most cases PLAyBOOK outperforms the alternative asynchronous methods TS and KB. The TS algorithm performed poorly on this test, which we believe is caused by the fact that TS relies heavily on the surrogate's uncertainty to explore new regions.</p>
<p>PLAyBOOK methods show strong performance, achieving better optimisation performance than both TS and KB baselines.</p>
<h3>6.3.2. REAL-WORLD OPTIMISATION</h3>
<p>We further experimented on a real-world application of tuning the hyperparameters of a 6-layer Convolutional Neural Network (CNN) ${ }^{3}$ for an image classification task on CIFAR10 dataset (Krizhevsky, 2009). The 9 hyperparameters that we optimise with BO are the learning rate and momentum for the stochastic gradient descent training algorithm, the batch size used and the number of filters in each of the six convolutional layers. We trained the CNN on half of the training set for 20 epochs and each function evaluation returns the validation error of the model. We tested the use of $k=2$ and $k=4$ parallel workers to run this real-world experiment. The results are shown in Figs. 6a and 6b.</p>
<p>We can see that for both $k=2$ and $k=4$ parallel settings, all PLAyBOOK methods outperform the other asynchronous methods, TS and KB. In the case of $k=2$ (2 parallel processors), only one busy location is penalised in each batch so there is little gain from using a locally estimated Lipschitz constant. However, as the batch size increases to $k=4$, we see that methods using estimated Lipschitz constants (PLAyBOOK-LL and PLAyBOOK-HL) show faster decrease in validation error than PLAyBOOK-L and PLAyBOOK-H with PLAyBOOK-LL demonstrating the best performance.</p>
<p>We then took the final configurations recommended by each asynchronous BO method in the $k=2$ and $k=4$ settings and retrained the CNN model on the full training set of 50 K images for 80 epochs. The accuracy on the test set of 10 K images achieved with the best model chosen by</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 5. The median (solid line) and quartiles (shaded region) of the regret for different asynchronous BO methods on the global optimisation test functions for 30 random intialisations is shown. We can see that our proposed PLAyBOOK methods perform competitively, especially when we start choosing larger batch sizes.</p>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 6. Asynchronous optimisation of 9 hyperparameters of a 6-layer CNN for image classification on the CIFAR10 dataset. The network is trained on half of the training set and evaluated on the second half. The objective being minimised is the classification accuracy on the validation set. PLAyBOOK outperforms both KB and TS in this expensive optimisation task.</p>
<p>each BO method is shown in Table 1. In both settings, our PLAyBOOK methods achieve superior performance over TS with PLAyBOOK-H providing the best test accuracy when</p>
<p>$$k = 2$$ and PLAyBOOK-LL doing the best when $$k = 4$$.</p>
<p>Table 1. Test accuracy (%) on CIFAR-10 after training the best model chosen by various asynchronous BO methods for 80 epochs</p>
<table>
<thead>
<tr>
<th>$k$</th>
<th>TS</th>
<th>KB</th>
<th>PLAyBOOK</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td></td>
<td>L</td>
</tr>
<tr>
<td>2</td>
<td>81.0</td>
<td>83.9</td>
<td>84.7</td>
</tr>
<tr>
<td>4</td>
<td>81.2</td>
<td>82.8</td>
<td>82.5</td>
</tr>
</tbody>
</table>
<h2>7 Conclusions</h2>
<p>We argue for the use of asynchronous (over synchronous) Bayesian optimisation (BO), and provide supporting empirical evidence. Additionally, we developed a new approach, PLAyBOOK, for asynchronous BO, based on penalisation of the acquisition function using information about tasks that are still under evaluation. Empirical evaluation on synthetic functions and a real-world optimisation task showed that PLAyBOOK improves upon the state of the art. Finally, we demonstrate that, for penalisation-based batch BO, PLAyBOOK's asynchronous BO is more efficient than synchronous BO in both wall-clock time and the number of samples.</p>
<h2>Acknowledgements</h2>
<p>We thank our colleagues at the Machine Learning Research Group at the University of Oxford, especially Edward Wagstaff, for providing discussions that assisted the research. We would also like to express our gratitude to our anonymous reviewers for their valuable comments and feedback.</p>
<p>Computational resources were supported by Arcus HTC and JADE HPC at the University of Oxford and Hartree national computing facilities, UK.</p>
<h2>References</h2>
<p>Azimi, J., Fern, A., and Fern, X. Z. Batch Bayesian optimization via simulation matching. In Advances in Neural Information Processing Systems, pp. 109-117, 2010.</p>
<p>Blaas, A., Manzano, J. M., Limon, D., and Calliess, J. Localised kinky inference. In Proceedings of the European Control Conference, 2019.</p>
<p>Brochu, E., Cora, V. M., and De Freitas, N. A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning. arXiv preprint arXiv:1012.2599, 2010.</p>
<p>Chen, Y., Huang, A., Wang, Z., Antonoglou, I., Schrittwieser, J., Silver, D., and de Freitas, N. Bayesian optimization in AlphaGo. arXiv preprint arXiv:1812.06855, 2018.</p>
<p>Contal, E., Buffoni, D., Robicquet, A., and Vayatis, N. Parallel Gaussian process optimization with Upper Confidence Bound and Pure Exploration. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 225-240. Springer, 2013.</p>
<p>Desautels, T., Krause, A., and Burdick, J. W. Parallelizing exploration-exploitation tradeoffs in Gaussian process bandit optimization. The Journal of Machine Learning Research, 15(1):3873-3923, 2014.</p>
<p>Ginsbourger, D., Le Riche, R., and Carraro, L. A multipoints criterion for deterministic parallel global optimization based on Gaussian processes. 2008.</p>
<p>Ginsbourger, D., Le Riche, R., and Carraro, L. Kriging is well-suited to parallelize optimization. In Computational intelligence in expensive optimization problems, pp. 131162. Springer, 2010.</p>
<p>Ginsbourger, D., Janusevskis, J., and Le Riche, R. Dealing with asynchronicity in parallel Gaussian process based global optimization. In 4th International Conference of the ERCIM WG on computing \&amp; statistics (ERCIM'11), 2011.</p>
<p>González, J., Dai, Z., Hennig, P., and Lawrence, N. Batch Bayesian optimization via local penalization. In Artificial Intelligence and Statistics, pp. 648-657, 2016.</p>
<p>Hennig, P. and Schuler, C. J. Entropy search for informationefficient global optimization. Journal of Machine Learning Research, 13(Jun):1809-1837, 2012.</p>
<p>Hernández-Lobato, J. M., Hoffman, M. W., and Ghahramani, Z. Predictive entropy search for efficient global optimization of black-box functions. In Advances in neural information processing systems, pp. 918-926, 2014.</p>
<p>Hernández-Lobato, J. M., Requeima, J., Pyzer-Knapp, E. O., and Aspuru-Guzik, A. Parallel and distributed Thompson sampling for large-scale accelerated exploration of chemical space. In International Conference on Machine Learning (ICML), 2017.</p>
<p>Jalali, A., Azimi, J., Fern, X., and Zhang, R. A Lipschitz exploration-exploitation scheme for Bayesian optimization. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pp. 210-224. Springer, 2013.</p>
<p>Jones, D. R., Schonlau, M., and Welch, W. J. Efficient global optimization of expensive black-box functions. Journal of Global optimization, 13(4):455-492, 1998.</p>
<p>Kandasamy, K., Krishnamurthy, A., Schneider, J., and Póczos, B. Parallelised Bayesian optimisation via Thompson sampling. In International Conference on Artificial Intelligence and Statistics, pp. 133-142, 2018.</p>
<p>Kathuria, T., Deshpande, A., and Kohli, P. Batched Gaussian process bandit optimization via determinantal point processes. In Advances in Neural Information Processing Systems, pp. 4206-4214, 2016.</p>
<p>Krizhevsky, A. Learning multiple layers of features from tiny images. Technical report, Citeseer, 2009.</p>
<p>Kushner, H. J. A new method of locating the maximum point of an arbitrary multipeak curve in the presence of noise. Journal of Basic Engineering, 86(1):97-106, 1964.</p>
<p>Rasmussen, C. E. and Williams, C. K. Gaussian processes for machine learning, volume 1. MIT press Cambridge, 2006.</p>
<p>Ru, B., McLeod, M., Granziol, D., and Osborne, M. A. Fast information-theoretic Bayesian optimisation. In International Conference on Machine Learning (ICML), 2018.</p>
<p>Shah, A. and Ghahramani, Z. Parallel predictive entropy search for batch global optimization of expensive objective functions. In Advances in Neural Information Processing Systems, pp. 3330-3338, 2015.</p>
<p>Srinivas, N., Krause, A., Kakade, S. M., and Seeger, M. Gaussian process optimization in the bandit setting: No regret and experimental design. In International Conference on Machine Learning (ICML), 2010.</p>
<p>Wang, J., Clark, S. C., Liu, E., and Frazier, P. I. Parallel Bayesian global optimization of expensive functions. arXiv preprint arXiv:1602.05149, 2016.</p>
<p>Wang, Z. and Jegelka, S. Max-value entropy search for efficient Bayesian optimization. In International Conference on Machine Learning (ICML), 2017.</p>
<p>Wu, J. and Frazier, P. The parallel knowledge gradient method for batch Bayesian optimization. In Advances in Neural Information Processing Systems, pp. 3126-3134, 2016.</p>
<h1>Supplementary material</h1>
<h2>1. Summary of experimental tasks</h2>
<p>As mentioned in the main text, we conducted empirical evaluations on a large number of synthetic test problems:</p>
<ul>
<li>The tasks mat-2 and mat-6 refer to functions drawn from a Gaussian process(GP) with Matérn-52 kernel in $\mathbb{R}^{2}$ and $\mathbb{R}^{6}$ respectively.</li>
<li>The global optimisation tasks ${ }^{4}$ that we considered are the Ackley function defined on $\mathbb{R}^{5}$ and $\mathbb{R}^{10}$ (ack-5 and ack-10), the Michalewicz function defined on $\mathbb{R}^{5}$ and $\mathbb{R}^{10}$ (mic-5 and mic-10) and the Eggholder function in $\mathbb{R}^{2}$ (egg-2).</li>
<li>We also selected a robot pushing simulation experiment, which was first explored in a BO context by Wang \&amp; Jegelka (2017). Here the task is to learn the correct pushing action to minimise the distance of the robot to a goal. The problem has 4 inputs: the robot's location $\left(r_{x}, r_{y}\right)$, the angle of the pushing force $r_{\theta}$ and the pushing duration $t_{r}$. We used the input space suggested by Wang \&amp; Jegelka (2017).</li>
</ul>
<h2>2. Asynchronous vs. synchronous parallel BO</h2>
<p>Similar to Fig. 4 in the main text, Figs. 7 and 8 show head-tohead comparisons of synchronous and asynchronous methods, here on the ack-10 task.</p>
<h2>3. Asynchronous BO</h2>
<p>We conducted a large number of experiments testing the different approaches for asynchronous BO. We computed the mean and standard deviation of the log of the simple regret across 30 random initialisations (see Eq. 13 in the main text for the definition). Tables 2, 3 and 4 show the results after 50, 75 and 100 asynchronous BO steps respectively.</p>
<p>Across all of these experiments, we can see that PLAyBOOK is performing competitively, making it an attractive choice for asynchronous BO problems.</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<table>
<thead>
<tr>
<th style="text-align: center;">k</th>
<th style="text-align: center;">Task</th>
<th style="text-align: center;">KB</th>
<th style="text-align: center;">TS</th>
<th style="text-align: center;">PLAyBOOK</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">L</td>
<td style="text-align: center;">LL</td>
<td style="text-align: center;">H</td>
<td style="text-align: center;">HL</td>
</tr>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: center;">ack-10</td>
<td style="text-align: center;">$-0.30(0.16)$</td>
<td style="text-align: center;">$-0.01(0.03)$</td>
<td style="text-align: center;">$-0.23(0.15)$</td>
<td style="text-align: center;">$-0.37(0.25)$</td>
<td style="text-align: center;">$-0.32(0.18)$</td>
<td style="text-align: center;">$-0.27(0.18)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ack-5</td>
<td style="text-align: center;">$-0.55(0.39)$</td>
<td style="text-align: center;">$-0.22(0.20)$</td>
<td style="text-align: center;">$-0.85(0.52)$</td>
<td style="text-align: center;">$-0.52(0.40)$</td>
<td style="text-align: center;">$-0.64(0.39)$</td>
<td style="text-align: center;">$-0.71(0.48)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">egg-2</td>
<td style="text-align: center;">0.28 (0.72)</td>
<td style="text-align: center;">0.89 (0.92)</td>
<td style="text-align: center;">$-0.12(1.26)$</td>
<td style="text-align: center;">$-0.05(1.03)$</td>
<td style="text-align: center;">$-0.44(2.13)$</td>
<td style="text-align: center;">$-0.31(1.62)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mat-2</td>
<td style="text-align: center;">0.81 (0.30)</td>
<td style="text-align: center;">1.05 (0.26)</td>
<td style="text-align: center;">0.78 (0.28)</td>
<td style="text-align: center;">0.82 (0.26)</td>
<td style="text-align: center;">0.81 (0.21)</td>
<td style="text-align: center;">0.89 (0.20)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mat-6</td>
<td style="text-align: center;">1.02 (0.16)</td>
<td style="text-align: center;">1.13 (0.14)</td>
<td style="text-align: center;">0.85 (0.43)</td>
<td style="text-align: center;">0.92 (0.33)</td>
<td style="text-align: center;">0.88 (0.26)</td>
<td style="text-align: center;">0.86 (0.31)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mic-10</td>
<td style="text-align: center;">1.84 (0.08)</td>
<td style="text-align: center;">1.92 (0.07)</td>
<td style="text-align: center;">1.78 (0.11)</td>
<td style="text-align: center;">1.80 (0.09)</td>
<td style="text-align: center;">1.82 (0.11)</td>
<td style="text-align: center;">1.83 (0.10)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mic-5</td>
<td style="text-align: center;">0.71 (0.28)</td>
<td style="text-align: center;">1.02 (0.13)</td>
<td style="text-align: center;">0.67 (0.27)</td>
<td style="text-align: center;">0.66 (0.26)</td>
<td style="text-align: center;">0.69 (0.33)</td>
<td style="text-align: center;">0.87 (0.16)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">nrobot-4</td>
<td style="text-align: center;">$-0.71(1.05)$</td>
<td style="text-align: center;">$-0.52(1.21)$</td>
<td style="text-align: center;">$-0.88(0.91)$</td>
<td style="text-align: center;">$-0.78(0.86)$</td>
<td style="text-align: center;">$-0.89(0.69)$</td>
<td style="text-align: center;">$-0.87(0.91)$</td>
</tr>
<tr>
<td style="text-align: center;">4</td>
<td style="text-align: center;">ack-10</td>
<td style="text-align: center;">$-0.29(0.17)$</td>
<td style="text-align: center;">$-0.01(0.03)$</td>
<td style="text-align: center;">$-0.26(0.16)$</td>
<td style="text-align: center;">$-0.32(0.17)$</td>
<td style="text-align: center;">$-0.25(0.14)$</td>
<td style="text-align: center;">$-0.34(0.18)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ack-5</td>
<td style="text-align: center;">$-0.54(0.36)$</td>
<td style="text-align: center;">$-0.21(0.13)$</td>
<td style="text-align: center;">$-0.66(0.45)$</td>
<td style="text-align: center;">$-0.41(0.27)$</td>
<td style="text-align: center;">$-0.53(0.41)$</td>
<td style="text-align: center;">$-0.71(0.52)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">egg-2</td>
<td style="text-align: center;">0.19 (1.06)</td>
<td style="text-align: center;">0.79 (0.92)</td>
<td style="text-align: center;">0.53 (0.91)</td>
<td style="text-align: center;">0.23 (0.98)</td>
<td style="text-align: center;">0.29 (0.86)</td>
<td style="text-align: center;">$-0.06(1.26)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mat-2</td>
<td style="text-align: center;">0.77 (0.30)</td>
<td style="text-align: center;">0.98 (0.37)</td>
<td style="text-align: center;">0.94 (0.22)</td>
<td style="text-align: center;">1.01 (0.28)</td>
<td style="text-align: center;">0.82 (0.25)</td>
<td style="text-align: center;">0.87 (0.22)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mat-6</td>
<td style="text-align: center;">1.06 (0.17)</td>
<td style="text-align: center;">1.13 (0.05)</td>
<td style="text-align: center;">0.99 (0.18)</td>
<td style="text-align: center;">1.01 (0.26)</td>
<td style="text-align: center;">0.95 (0.23)</td>
<td style="text-align: center;">0.94 (0.20)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mic-10</td>
<td style="text-align: center;">1.82 (0.11)</td>
<td style="text-align: center;">1.92 (0.07)</td>
<td style="text-align: center;">1.82 (0.08)</td>
<td style="text-align: center;">1.83 (0.08)</td>
<td style="text-align: center;">1.78 (0.09)</td>
<td style="text-align: center;">1.80 (0.08)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mic-5</td>
<td style="text-align: center;">0.66 (0.28)</td>
<td style="text-align: center;">1.01 (0.16)</td>
<td style="text-align: center;">0.78 (0.23)</td>
<td style="text-align: center;">0.87 (0.19)</td>
<td style="text-align: center;">0.76 (0.20)</td>
<td style="text-align: center;">0.82 (0.33)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">nrobot-4</td>
<td style="text-align: center;">$-0.67(1.00)$</td>
<td style="text-align: center;">$-0.39(1.04)$</td>
<td style="text-align: center;">-1.01 (0.94)</td>
<td style="text-align: center;">$-0.94(0.97)$</td>
<td style="text-align: center;">$-0.75(0.70)$</td>
<td style="text-align: center;">$-0.63(0.79)$</td>
</tr>
<tr>
<td style="text-align: center;">6</td>
<td style="text-align: center;">ack-10</td>
<td style="text-align: center;">$-0.24(0.19)$</td>
<td style="text-align: center;">$-0.01(0.04)$</td>
<td style="text-align: center;">$-0.29(0.15)$</td>
<td style="text-align: center;">$-0.25(0.14)$</td>
<td style="text-align: center;">$-0.20(0.14)$</td>
<td style="text-align: center;">$-0.31(0.16)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ack-5</td>
<td style="text-align: center;">$-0.51(0.28)$</td>
<td style="text-align: center;">$-0.20(0.20)$</td>
<td style="text-align: center;">$-0.54(0.40)$</td>
<td style="text-align: center;">$-0.27(0.18)$</td>
<td style="text-align: center;">$-0.35(0.24)$</td>
<td style="text-align: center;">$-0.49(0.27)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">egg-2</td>
<td style="text-align: center;">0.37 (1.05)</td>
<td style="text-align: center;">0.78 (0.88)</td>
<td style="text-align: center;">0.71 (0.83)</td>
<td style="text-align: center;">0.77 (0.82)</td>
<td style="text-align: center;">0.07 (1.25)</td>
<td style="text-align: center;">0.32 (1.11)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mat-2</td>
<td style="text-align: center;">0.85 (0.25)</td>
<td style="text-align: center;">1.04 (0.19)</td>
<td style="text-align: center;">0.98 (0.34)</td>
<td style="text-align: center;">1.06 (0.23)</td>
<td style="text-align: center;">0.84 (0.23)</td>
<td style="text-align: center;">0.85 (0.25)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mat-6</td>
<td style="text-align: center;">1.01 (0.17)</td>
<td style="text-align: center;">1.07 (0.18)</td>
<td style="text-align: center;">0.95 (0.28)</td>
<td style="text-align: center;">1.02 (0.28)</td>
<td style="text-align: center;">1.03 (0.16)</td>
<td style="text-align: center;">0.99 (0.24)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mic-10</td>
<td style="text-align: center;">1.84 (0.08)</td>
<td style="text-align: center;">1.92 (0.07)</td>
<td style="text-align: center;">1.84 (0.08)</td>
<td style="text-align: center;">1.81 (0.08)</td>
<td style="text-align: center;">1.84 (0.08)</td>
<td style="text-align: center;">1.80 (0.09)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mic-5</td>
<td style="text-align: center;">0.76 (0.21)</td>
<td style="text-align: center;">1.04 (0.15)</td>
<td style="text-align: center;">0.84 (0.23)</td>
<td style="text-align: center;">0.89 (0.24)</td>
<td style="text-align: center;">0.88 (0.19)</td>
<td style="text-align: center;">0.87 (0.20)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">nrobot-4</td>
<td style="text-align: center;">$-0.58(0.96)$</td>
<td style="text-align: center;">$-0.22(0.95)$</td>
<td style="text-align: center;">$-0.69(1.04)$</td>
<td style="text-align: center;">$-0.47(0.85)$</td>
<td style="text-align: center;">$-0.63(1.02)$</td>
<td style="text-align: center;">$-0.51(0.99)$</td>
</tr>
<tr>
<td style="text-align: center;">8</td>
<td style="text-align: center;">ack-10</td>
<td style="text-align: center;">$-0.23(0.17)$</td>
<td style="text-align: center;">$-0.01(0.03)$</td>
<td style="text-align: center;">$-0.26(0.17)$</td>
<td style="text-align: center;">$-0.34(0.15)$</td>
<td style="text-align: center;">$-0.17(0.11)$</td>
<td style="text-align: center;">$-0.40(0.14)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ack-5</td>
<td style="text-align: center;">$-0.44(0.27)$</td>
<td style="text-align: center;">$-0.19(0.14)$</td>
<td style="text-align: center;">$-0.65(0.40)$</td>
<td style="text-align: center;">$-0.33(0.21)$</td>
<td style="text-align: center;">$-0.38(0.30)$</td>
<td style="text-align: center;">$-0.68(0.37)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">egg-2</td>
<td style="text-align: center;">0.31 (0.93)</td>
<td style="text-align: center;">0.65 (0.92)</td>
<td style="text-align: center;">0.60 (1.20)</td>
<td style="text-align: center;">0.93 (0.77)</td>
<td style="text-align: center;">0.42 (0.61)</td>
<td style="text-align: center;">0.17 (1.05)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mat-2</td>
<td style="text-align: center;">0.80 (0.22)</td>
<td style="text-align: center;">0.93 (0.26)</td>
<td style="text-align: center;">0.81 (0.44)</td>
<td style="text-align: center;">1.09 (0.20)</td>
<td style="text-align: center;">0.87 (0.27)</td>
<td style="text-align: center;">0.79 (0.30)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mat-6</td>
<td style="text-align: center;">1.01 (0.19)</td>
<td style="text-align: center;">1.13 (0.06)</td>
<td style="text-align: center;">1.03 (0.17)</td>
<td style="text-align: center;">1.02 (0.22)</td>
<td style="text-align: center;">1.03 (0.15)</td>
<td style="text-align: center;">1.03 (0.20)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mic-10</td>
<td style="text-align: center;">1.84 (0.09)</td>
<td style="text-align: center;">1.91 (0.07)</td>
<td style="text-align: center;">1.82 (0.08)</td>
<td style="text-align: center;">1.81 (0.10)</td>
<td style="text-align: center;">1.80 (0.13)</td>
<td style="text-align: center;">1.78 (0.08)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mic-5</td>
<td style="text-align: center;">0.70 (0.33)</td>
<td style="text-align: center;">1.02 (0.20)</td>
<td style="text-align: center;">0.68 (0.32)</td>
<td style="text-align: center;">0.79 (0.25)</td>
<td style="text-align: center;">0.73 (0.32)</td>
<td style="text-align: center;">0.69 (0.32)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">nrobot-4</td>
<td style="text-align: center;">$-0.61(0.78)$</td>
<td style="text-align: center;">$-0.20(0.96)$</td>
<td style="text-align: center;">$-0.94(0.92)$</td>
<td style="text-align: center;">$-0.62(1.14)$</td>
<td style="text-align: center;">$-0.76(1.11)$</td>
<td style="text-align: center;">$-0.39(0.73)$</td>
</tr>
<tr>
<td style="text-align: center;">16</td>
<td style="text-align: center;">ack-10</td>
<td style="text-align: center;">$-0.13(0.08)$</td>
<td style="text-align: center;">$-0.02(0.04)$</td>
<td style="text-align: center;">$-0.24(0.13)$</td>
<td style="text-align: center;">$-0.24(0.13)$</td>
<td style="text-align: center;">$-0.22(0.10)$</td>
<td style="text-align: center;">$-0.44(0.13)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ack-5</td>
<td style="text-align: center;">$-0.36(0.30)$</td>
<td style="text-align: center;">$-0.18(0.16)$</td>
<td style="text-align: center;">$-0.49(0.34)$</td>
<td style="text-align: center;">$-0.36(0.24)$</td>
<td style="text-align: center;">$-0.28(0.19)$</td>
<td style="text-align: center;">$-0.73(0.26)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">egg-2</td>
<td style="text-align: center;">0.58 (0.73)</td>
<td style="text-align: center;">0.56 (1.10)</td>
<td style="text-align: center;">1.04 (0.51)</td>
<td style="text-align: center;">1.22 (0.50)</td>
<td style="text-align: center;">0.30 (0.96)</td>
<td style="text-align: center;">0.71 (0.53)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mat-2</td>
<td style="text-align: center;">0.82 (0.27)</td>
<td style="text-align: center;">0.89 (0.24)</td>
<td style="text-align: center;">1.07 (0.17)</td>
<td style="text-align: center;">1.12 (0.20)</td>
<td style="text-align: center;">0.92 (0.31)</td>
<td style="text-align: center;">0.90 (0.31)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mat-6</td>
<td style="text-align: center;">1.10 (0.05)</td>
<td style="text-align: center;">1.14 (0.03)</td>
<td style="text-align: center;">1.05 (0.14)</td>
<td style="text-align: center;">1.06 (0.21)</td>
<td style="text-align: center;">1.02 (0.26)</td>
<td style="text-align: center;">1.00 (0.26)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mic-10</td>
<td style="text-align: center;">1.86 (0.08)</td>
<td style="text-align: center;">1.90 (0.07)</td>
<td style="text-align: center;">1.82 (0.07)</td>
<td style="text-align: center;">1.82 (0.09)</td>
<td style="text-align: center;">1.83 (0.08)</td>
<td style="text-align: center;">1.79 (0.09)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mic-5</td>
<td style="text-align: center;">0.81 (0.25)</td>
<td style="text-align: center;">1.02 (0.19)</td>
<td style="text-align: center;">0.85 (0.21)</td>
<td style="text-align: center;">0.84 (0.23)</td>
<td style="text-align: center;">0.81 (0.22)</td>
<td style="text-align: center;">0.82 (0.25)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">nrobot-4</td>
<td style="text-align: center;">$-0.43(0.94)$</td>
<td style="text-align: center;">$-0.22(0.99)$</td>
<td style="text-align: center;">$-0.78(0.95)$</td>
<td style="text-align: center;">$-0.14(0.77)$</td>
<td style="text-align: center;">$-0.37(0.80)$</td>
<td style="text-align: center;">$-0.40(0.81)$</td>
</tr>
</tbody>
</table>
<p>Table 2. Mean and standard deviation of the $\log ($ regret $)$ after 50 steps of asynchronous BO.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">k</th>
<th style="text-align: center;">Task</th>
<th style="text-align: center;">KB</th>
<th style="text-align: center;">TS</th>
<th style="text-align: center;">PLAyBOOK</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">L</td>
<td style="text-align: center;">LL</td>
<td style="text-align: center;">H</td>
<td style="text-align: center;">HL</td>
</tr>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: center;">ack-10</td>
<td style="text-align: center;">$-0.43(0.18)$</td>
<td style="text-align: center;">$-0.01(0.03)$</td>
<td style="text-align: center;">$-0.48(0.27)$</td>
<td style="text-align: center;">-0.58 (0.26)</td>
<td style="text-align: center;">$-0.55(0.32)$</td>
<td style="text-align: center;">$-0.45(0.28)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ack-5</td>
<td style="text-align: center;">$-0.91(0.56)$</td>
<td style="text-align: center;">$-0.32(0.22)$</td>
<td style="text-align: center;">-1.15 (0.58)</td>
<td style="text-align: center;">$-0.76(0.50)$</td>
<td style="text-align: center;">$-1.03(0.52)$</td>
<td style="text-align: center;">$-0.92(0.51)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">egg-2</td>
<td style="text-align: center;">$-0.12(0.92)$</td>
<td style="text-align: center;">0.87 (0.91)</td>
<td style="text-align: center;">$-0.59(1.16)$</td>
<td style="text-align: center;">-1.13 (2.14)</td>
<td style="text-align: center;">$-0.81(1.99)$</td>
<td style="text-align: center;">$-0.82(1.68)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mat-2</td>
<td style="text-align: center;">0.80 (0.30)</td>
<td style="text-align: center;">1.05 (0.27)</td>
<td style="text-align: center;">0.76 (0.28)</td>
<td style="text-align: center;">0.81 (0.26)</td>
<td style="text-align: center;">0.81 (0.21)</td>
<td style="text-align: center;">0.87 (0.20)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mat-6</td>
<td style="text-align: center;">0.95 (0.21)</td>
<td style="text-align: center;">1.17 (0.14)</td>
<td style="text-align: center;">0.74 (0.53)</td>
<td style="text-align: center;">0.87 (0.31)</td>
<td style="text-align: center;">0.84 (0.34)</td>
<td style="text-align: center;">0.89 (0.29)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mic-10</td>
<td style="text-align: center;">1.79 (0.12)</td>
<td style="text-align: center;">1.92 (0.07)</td>
<td style="text-align: center;">1.75 (0.11)</td>
<td style="text-align: center;">1.76 (0.14)</td>
<td style="text-align: center;">1.79 (0.12)</td>
<td style="text-align: center;">1.79 (0.13)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mic-5</td>
<td style="text-align: center;">0.52 (0.42)</td>
<td style="text-align: center;">0.97 (0.17)</td>
<td style="text-align: center;">0.61 (0.29)</td>
<td style="text-align: center;">0.56 (0.24)</td>
<td style="text-align: center;">0.57 (0.37)</td>
<td style="text-align: center;">0.73 (0.28)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">nrobot-4</td>
<td style="text-align: center;">$-1.06(1.08)$</td>
<td style="text-align: center;">$-0.83(1.18)$</td>
<td style="text-align: center;">$-1.20(0.86)$</td>
<td style="text-align: center;">-1.31 (0.75)</td>
<td style="text-align: center;">$-1.24(0.78)$</td>
<td style="text-align: center;">$-1.29(0.80)$</td>
</tr>
<tr>
<td style="text-align: center;">4</td>
<td style="text-align: center;">ack-10</td>
<td style="text-align: center;">-0.52 (0.21)</td>
<td style="text-align: center;">$-0.01(0.03)$</td>
<td style="text-align: center;">$-0.51(0.27)$</td>
<td style="text-align: center;">$-0.42(0.19)$</td>
<td style="text-align: center;">$-0.46(0.22)$</td>
<td style="text-align: center;">$-0.50(0.22)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ack-5</td>
<td style="text-align: center;">$-0.83(0.48)$</td>
<td style="text-align: center;">$-0.31(0.23)$</td>
<td style="text-align: center;">-1.10 (0.53)</td>
<td style="text-align: center;">$-0.57(0.33)$</td>
<td style="text-align: center;">$-0.75(0.62)$</td>
<td style="text-align: center;">$-0.90(0.54)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">egg-2</td>
<td style="text-align: center;">$-0.19(0.87)$</td>
<td style="text-align: center;">0.69 (1.13)</td>
<td style="text-align: center;">0.16 (1.70)</td>
<td style="text-align: center;">$-0.81(2.55)$</td>
<td style="text-align: center;">$-0.23(1.10)$</td>
<td style="text-align: center;">-0.89 (2.48)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mat-2</td>
<td style="text-align: center;">0.75 (0.29)</td>
<td style="text-align: center;">0.98 (0.37)</td>
<td style="text-align: center;">0.93 (0.22)</td>
<td style="text-align: center;">1.01 (0.28)</td>
<td style="text-align: center;">0.80 (0.25)</td>
<td style="text-align: center;">0.85 (0.22)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mat-6</td>
<td style="text-align: center;">0.97 (0.27)</td>
<td style="text-align: center;">1.18 (0.06)</td>
<td style="text-align: center;">0.95 (0.23)</td>
<td style="text-align: center;">1.02 (0.24)</td>
<td style="text-align: center;">0.86 (0.28)</td>
<td style="text-align: center;">0.87 (0.30)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mic-10</td>
<td style="text-align: center;">1.77 (0.12)</td>
<td style="text-align: center;">1.92 (0.07)</td>
<td style="text-align: center;">1.77 (0.09)</td>
<td style="text-align: center;">1.78 (0.09)</td>
<td style="text-align: center;">1.74 (0.09)</td>
<td style="text-align: center;">1.77 (0.10)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mic-5</td>
<td style="text-align: center;">0.56 (0.30)</td>
<td style="text-align: center;">0.97 (0.14)</td>
<td style="text-align: center;">0.69 (0.25)</td>
<td style="text-align: center;">0.76 (0.19)</td>
<td style="text-align: center;">0.63 (0.22)</td>
<td style="text-align: center;">0.67 (0.34)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">nrobot-4</td>
<td style="text-align: center;">$-0.92(0.95)$</td>
<td style="text-align: center;">$-1.01(1.31)$</td>
<td style="text-align: center;">-1.51 (0.88)</td>
<td style="text-align: center;">$-1.23(0.89)$</td>
<td style="text-align: center;">$-1.07(0.68)$</td>
<td style="text-align: center;">$-1.04(0.79)$</td>
</tr>
<tr>
<td style="text-align: center;">6</td>
<td style="text-align: center;">ack-10</td>
<td style="text-align: center;">$-0.41(0.22)$</td>
<td style="text-align: center;">$-0.01(0.04)$</td>
<td style="text-align: center;">-0.50 (0.26)</td>
<td style="text-align: center;">$-0.30(0.15)$</td>
<td style="text-align: center;">$-0.32(0.18)$</td>
<td style="text-align: center;">$-0.38(0.19)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ack-5</td>
<td style="text-align: center;">$-0.83(0.46)$</td>
<td style="text-align: center;">$-0.32(0.23)$</td>
<td style="text-align: center;">-0.86 (0.54)</td>
<td style="text-align: center;">$-0.36(0.23)$</td>
<td style="text-align: center;">$-0.52(0.31)$</td>
<td style="text-align: center;">$-0.76(0.37)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">egg-2</td>
<td style="text-align: center;">0.19 (1.00)</td>
<td style="text-align: center;">0.64 (1.14)</td>
<td style="text-align: center;">0.56 (0.93)</td>
<td style="text-align: center;">0.75 (0.84)</td>
<td style="text-align: center;">-0.34 (1.48)</td>
<td style="text-align: center;">$-0.21(1.03)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mat-2</td>
<td style="text-align: center;">0.82 (0.26)</td>
<td style="text-align: center;">1.03 (0.20)</td>
<td style="text-align: center;">0.98 (0.34)</td>
<td style="text-align: center;">1.06 (0.23)</td>
<td style="text-align: center;">0.82 (0.22)</td>
<td style="text-align: center;">0.84 (0.25)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mat-6</td>
<td style="text-align: center;">0.92 (0.25)</td>
<td style="text-align: center;">1.14 (0.17)</td>
<td style="text-align: center;">0.86 (0.36)</td>
<td style="text-align: center;">1.08 (0.25)</td>
<td style="text-align: center;">0.95 (0.28)</td>
<td style="text-align: center;">0.94 (0.26)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mic-10</td>
<td style="text-align: center;">1.81 (0.08)</td>
<td style="text-align: center;">1.92 (0.07)</td>
<td style="text-align: center;">1.81 (0.08)</td>
<td style="text-align: center;">1.79 (0.09)</td>
<td style="text-align: center;">1.80 (0.10)</td>
<td style="text-align: center;">1.78 (0.10)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mic-5</td>
<td style="text-align: center;">0.63 (0.28)</td>
<td style="text-align: center;">1.00 (0.14)</td>
<td style="text-align: center;">0.74 (0.29)</td>
<td style="text-align: center;">0.82 (0.22)</td>
<td style="text-align: center;">0.76 (0.26)</td>
<td style="text-align: center;">0.69 (0.33)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">nrobot-4</td>
<td style="text-align: center;">$-1.02(0.88)$</td>
<td style="text-align: center;">$-0.73(1.20)$</td>
<td style="text-align: center;">$-0.99(1.04)$</td>
<td style="text-align: center;">$-0.78(0.96)$</td>
<td style="text-align: center;">-1.04 (1.02)</td>
<td style="text-align: center;">$-1.02(0.95)$</td>
</tr>
<tr>
<td style="text-align: center;">8</td>
<td style="text-align: center;">ack-10</td>
<td style="text-align: center;">$-0.44(0.21)$</td>
<td style="text-align: center;">$-0.01(0.03)$</td>
<td style="text-align: center;">$-0.47(0.21)$</td>
<td style="text-align: center;">$-0.40(0.20)$</td>
<td style="text-align: center;">$-0.28(0.17)$</td>
<td style="text-align: center;">-0.52 (0.16)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ack-5</td>
<td style="text-align: center;">$-0.77(0.40)$</td>
<td style="text-align: center;">$-0.33(0.20)$</td>
<td style="text-align: center;">-1.04 (0.45)</td>
<td style="text-align: center;">$-0.39(0.22)$</td>
<td style="text-align: center;">$-0.52(0.41)$</td>
<td style="text-align: center;">$-0.92(0.36)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">egg-2</td>
<td style="text-align: center;">-0.11 (0.96)</td>
<td style="text-align: center;">0.57 (1.00)</td>
<td style="text-align: center;">0.40 (1.22)</td>
<td style="text-align: center;">0.85 (0.84)</td>
<td style="text-align: center;">0.22 (0.51)</td>
<td style="text-align: center;">$-0.05(0.96)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mat-2</td>
<td style="text-align: center;">0.78 (0.23)</td>
<td style="text-align: center;">0.91 (0.26)</td>
<td style="text-align: center;">0.81 (0.44)</td>
<td style="text-align: center;">1.09 (0.20)</td>
<td style="text-align: center;">0.82 (0.26)</td>
<td style="text-align: center;">0.76 (0.30)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mat-6</td>
<td style="text-align: center;">0.95 (0.24)</td>
<td style="text-align: center;">1.18 (0.10)</td>
<td style="text-align: center;">0.97 (0.20)</td>
<td style="text-align: center;">1.10 (0.20)</td>
<td style="text-align: center;">0.93 (0.25)</td>
<td style="text-align: center;">0.97 (0.28)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mic-10</td>
<td style="text-align: center;">1.80 (0.09)</td>
<td style="text-align: center;">1.91 (0.07)</td>
<td style="text-align: center;">1.75 (0.09)</td>
<td style="text-align: center;">1.78 (0.09)</td>
<td style="text-align: center;">1.78 (0.13)</td>
<td style="text-align: center;">1.76 (0.08)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mic-5</td>
<td style="text-align: center;">0.58 (0.38)</td>
<td style="text-align: center;">0.98 (0.19)</td>
<td style="text-align: center;">0.59 (0.36)</td>
<td style="text-align: center;">0.70 (0.26)</td>
<td style="text-align: center;">0.61 (0.33)</td>
<td style="text-align: center;">0.55 (0.53)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">nrobot-4</td>
<td style="text-align: center;">$-0.92(0.89)$</td>
<td style="text-align: center;">$-0.65(1.01)$</td>
<td style="text-align: center;">-1.25 (0.82)</td>
<td style="text-align: center;">$-0.92(1.08)$</td>
<td style="text-align: center;">$-1.07(1.10)$</td>
<td style="text-align: center;">$-0.92(0.88)$</td>
</tr>
<tr>
<td style="text-align: center;">16</td>
<td style="text-align: center;">ack-10</td>
<td style="text-align: center;">$-0.27(0.14)$</td>
<td style="text-align: center;">$-0.02(0.04)$</td>
<td style="text-align: center;">$-0.43(0.21)$</td>
<td style="text-align: center;">$-0.31(0.20)$</td>
<td style="text-align: center;">$-0.31(0.14)$</td>
<td style="text-align: center;">-0.54 (0.16)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ack-5</td>
<td style="text-align: center;">$-0.55(0.34)$</td>
<td style="text-align: center;">$-0.29(0.19)$</td>
<td style="text-align: center;">$-0.77(0.42)$</td>
<td style="text-align: center;">$-0.39(0.25)$</td>
<td style="text-align: center;">$-0.39(0.28)$</td>
<td style="text-align: center;">-0.94 (0.30)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">egg-2</td>
<td style="text-align: center;">0.26 (0.74)</td>
<td style="text-align: center;">0.41 (1.18)</td>
<td style="text-align: center;">0.89 (0.63)</td>
<td style="text-align: center;">1.21 (0.50)</td>
<td style="text-align: center;">-0.39 (1.81)</td>
<td style="text-align: center;">0.42 (0.61)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mat-2</td>
<td style="text-align: center;">0.79 (0.27)</td>
<td style="text-align: center;">0.88 (0.24)</td>
<td style="text-align: center;">1.07 (0.17)</td>
<td style="text-align: center;">1.12 (0.20)</td>
<td style="text-align: center;">0.87 (0.30)</td>
<td style="text-align: center;">0.86 (0.31)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mat-6</td>
<td style="text-align: center;">1.03 (0.20)</td>
<td style="text-align: center;">1.20 (0.03)</td>
<td style="text-align: center;">0.95 (0.21)</td>
<td style="text-align: center;">1.08 (0.25)</td>
<td style="text-align: center;">0.94 (0.26)</td>
<td style="text-align: center;">0.96 (0.36)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mic-10</td>
<td style="text-align: center;">1.83 (0.09)</td>
<td style="text-align: center;">1.90 (0.07)</td>
<td style="text-align: center;">1.79 (0.08)</td>
<td style="text-align: center;">1.79 (0.09)</td>
<td style="text-align: center;">1.79 (0.10)</td>
<td style="text-align: center;">1.75 (0.13)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mic-5</td>
<td style="text-align: center;">0.66 (0.27)</td>
<td style="text-align: center;">0.95 (0.21)</td>
<td style="text-align: center;">0.77 (0.25)</td>
<td style="text-align: center;">0.73 (0.39)</td>
<td style="text-align: center;">0.75 (0.23)</td>
<td style="text-align: center;">0.75 (0.25)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">nrobot-4</td>
<td style="text-align: center;">$-0.72(0.87)$</td>
<td style="text-align: center;">$-0.80(1.24)$</td>
<td style="text-align: center;">-1.00 (1.01)</td>
<td style="text-align: center;">$-0.61(0.95)$</td>
<td style="text-align: center;">$-0.72(0.61)$</td>
<td style="text-align: center;">$-0.79(0.78)$</td>
</tr>
</tbody>
</table>
<p>Table 3. Mean and standard deviation of the $\log ($ regret $)$ after 75 steps of asynchronous BO.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">k</th>
<th style="text-align: center;">Task</th>
<th style="text-align: center;">KB</th>
<th style="text-align: center;">TS</th>
<th style="text-align: center;">PLAyBOOK</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">L</td>
<td style="text-align: center;">LL</td>
<td style="text-align: center;">H</td>
<td style="text-align: center;">HL</td>
</tr>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: center;">ack-10</td>
<td style="text-align: center;">$-0.67(0.27)$</td>
<td style="text-align: center;">$-0.01(0.03)$</td>
<td style="text-align: center;">$-0.72(0.34)$</td>
<td style="text-align: center;">$-0.73(0.29)$</td>
<td style="text-align: center;">$-0.80(0.35)$</td>
<td style="text-align: center;">$-0.58(0.26)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ack-5</td>
<td style="text-align: center;">$-1.28(0.70)$</td>
<td style="text-align: center;">$-0.35(0.22)$</td>
<td style="text-align: center;">$-1.49(0.65)$</td>
<td style="text-align: center;">$-0.95(0.53)$</td>
<td style="text-align: center;">$-1.39(0.62)$</td>
<td style="text-align: center;">$-1.08(0.47)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">egg-2</td>
<td style="text-align: center;">$-0.42(1.62)$</td>
<td style="text-align: center;">0.80 (0.92)</td>
<td style="text-align: center;">$-1.10(1.56)$</td>
<td style="text-align: center;">$-1.58(2.49)$</td>
<td style="text-align: center;">$-1.54(2.28)$</td>
<td style="text-align: center;">$-1.30(2.01)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mat-2</td>
<td style="text-align: center;">0.79 (0.30)</td>
<td style="text-align: center;">1.04 (0.25)</td>
<td style="text-align: center;">0.76 (0.28)</td>
<td style="text-align: center;">0.81 (0.26)</td>
<td style="text-align: center;">0.81 (0.21)</td>
<td style="text-align: center;">0.87 (0.19)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mat-6</td>
<td style="text-align: center;">1.00 (0.21)</td>
<td style="text-align: center;">1.27 (0.17)</td>
<td style="text-align: center;">0.93 (0.36)</td>
<td style="text-align: center;">1.00 (0.31)</td>
<td style="text-align: center;">0.94 (0.26)</td>
<td style="text-align: center;">1.01 (0.27)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mic-10</td>
<td style="text-align: center;">1.76 (0.13)</td>
<td style="text-align: center;">1.92 (0.07)</td>
<td style="text-align: center;">1.72 (0.10)</td>
<td style="text-align: center;">1.73 (0.13)</td>
<td style="text-align: center;">1.72 (0.13)</td>
<td style="text-align: center;">1.76 (0.12)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mic-5</td>
<td style="text-align: center;">0.39 (0.51)</td>
<td style="text-align: center;">0.94 (0.18)</td>
<td style="text-align: center;">0.54 (0.31)</td>
<td style="text-align: center;">0.45 (0.24)</td>
<td style="text-align: center;">0.45 (0.36)</td>
<td style="text-align: center;">0.65 (0.28)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">nrobot-4</td>
<td style="text-align: center;">$-1.33(1.02)$</td>
<td style="text-align: center;">$-1.12(1.21)$</td>
<td style="text-align: center;">$-1.54(0.84)$</td>
<td style="text-align: center;">$-1.51(0.85)$</td>
<td style="text-align: center;">$-1.46(0.74)$</td>
<td style="text-align: center;">$-1.58(0.78)$</td>
</tr>
<tr>
<td style="text-align: center;">4</td>
<td style="text-align: center;">ack-10</td>
<td style="text-align: center;">$-0.72(0.24)$</td>
<td style="text-align: center;">$-0.01(0.03)$</td>
<td style="text-align: center;">$-0.68(0.28)$</td>
<td style="text-align: center;">$-0.54(0.24)$</td>
<td style="text-align: center;">$-0.67(0.24)$</td>
<td style="text-align: center;">$-0.56(0.24)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ack-5</td>
<td style="text-align: center;">$-1.13(0.59)$</td>
<td style="text-align: center;">$-0.41(0.25)$</td>
<td style="text-align: center;">$-1.46(0.59)$</td>
<td style="text-align: center;">$-0.68(0.32)$</td>
<td style="text-align: center;">$-0.98(0.73)$</td>
<td style="text-align: center;">$-1.04(0.52)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">egg-2</td>
<td style="text-align: center;">$-0.27(0.82)$</td>
<td style="text-align: center;">0.65 (1.12)</td>
<td style="text-align: center;">$-0.16(1.71)$</td>
<td style="text-align: center;">$-1.09(2.57)$</td>
<td style="text-align: center;">$-0.50(1.03)$</td>
<td style="text-align: center;">$-1.17(2.53)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mat-2</td>
<td style="text-align: center;">0.74 (0.29)</td>
<td style="text-align: center;">0.98 (0.37)</td>
<td style="text-align: center;">0.93 (0.22)</td>
<td style="text-align: center;">1.01 (0.28)</td>
<td style="text-align: center;">0.79 (0.25)</td>
<td style="text-align: center;">0.85 (0.22)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mat-6</td>
<td style="text-align: center;">1.03 (0.25)</td>
<td style="text-align: center;">1.30 (0.06)</td>
<td style="text-align: center;">1.07 (0.19)</td>
<td style="text-align: center;">1.12 (0.20)</td>
<td style="text-align: center;">0.98 (0.25)</td>
<td style="text-align: center;">1.01 (0.23)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mic-10</td>
<td style="text-align: center;">1.74 (0.11)</td>
<td style="text-align: center;">1.92 (0.07)</td>
<td style="text-align: center;">1.75 (0.09)</td>
<td style="text-align: center;">1.74 (0.10)</td>
<td style="text-align: center;">1.70 (0.09)</td>
<td style="text-align: center;">1.74 (0.11)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mic-5</td>
<td style="text-align: center;">0.44 (0.32)</td>
<td style="text-align: center;">0.96 (0.14)</td>
<td style="text-align: center;">0.55 (0.27)</td>
<td style="text-align: center;">0.63 (0.21)</td>
<td style="text-align: center;">0.50 (0.27)</td>
<td style="text-align: center;">0.63 (0.34)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">nrobot-4</td>
<td style="text-align: center;">$-1.14(0.88)$</td>
<td style="text-align: center;">$-1.24(1.23)$</td>
<td style="text-align: center;">$-1.73(0.88)$</td>
<td style="text-align: center;">$-1.48(0.72)$</td>
<td style="text-align: center;">$-1.32(0.83)$</td>
<td style="text-align: center;">$-1.24(0.83)$</td>
</tr>
<tr>
<td style="text-align: center;">6</td>
<td style="text-align: center;">ack-10</td>
<td style="text-align: center;">$-0.63(0.27)$</td>
<td style="text-align: center;">$-0.01(0.04)$</td>
<td style="text-align: center;">$-0.65(0.29)$</td>
<td style="text-align: center;">$-0.37(0.20)$</td>
<td style="text-align: center;">$-0.44(0.25)$</td>
<td style="text-align: center;">$-0.43(0.20)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ack-5</td>
<td style="text-align: center;">$-1.19(0.60)$</td>
<td style="text-align: center;">$-0.39(0.26)$</td>
<td style="text-align: center;">$-1.17(0.65)$</td>
<td style="text-align: center;">$-0.39(0.22)$</td>
<td style="text-align: center;">$-0.68(0.41)$</td>
<td style="text-align: center;">$-0.87(0.40)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">egg-2</td>
<td style="text-align: center;">$-0.18(1.05)$</td>
<td style="text-align: center;">0.57 (1.15)</td>
<td style="text-align: center;">0.50 (0.94)</td>
<td style="text-align: center;">0.65 (0.98)</td>
<td style="text-align: center;">$-0.53(1.40)$</td>
<td style="text-align: center;">$-0.45(0.99)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mat-2</td>
<td style="text-align: center;">0.82 (0.25)</td>
<td style="text-align: center;">1.02 (0.20)</td>
<td style="text-align: center;">0.98 (0.34)</td>
<td style="text-align: center;">1.06 (0.23)</td>
<td style="text-align: center;">0.81 (0.22)</td>
<td style="text-align: center;">0.83 (0.24)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mat-6</td>
<td style="text-align: center;">1.02 (0.24)</td>
<td style="text-align: center;">1.25 (0.16)</td>
<td style="text-align: center;">0.99 (0.28)</td>
<td style="text-align: center;">1.18 (0.27)</td>
<td style="text-align: center;">1.05 (0.23)</td>
<td style="text-align: center;">1.03 (0.23)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mic-10</td>
<td style="text-align: center;">1.77 (0.10)</td>
<td style="text-align: center;">1.92 (0.07)</td>
<td style="text-align: center;">1.76 (0.08)</td>
<td style="text-align: center;">1.76 (0.08)</td>
<td style="text-align: center;">1.76 (0.13)</td>
<td style="text-align: center;">1.77 (0.10)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mic-5</td>
<td style="text-align: center;">0.51 (0.34)</td>
<td style="text-align: center;">0.96 (0.15)</td>
<td style="text-align: center;">0.66 (0.27)</td>
<td style="text-align: center;">0.72 (0.25)</td>
<td style="text-align: center;">0.66 (0.37)</td>
<td style="text-align: center;">0.63 (0.30)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">nrobot-4</td>
<td style="text-align: center;">$-1.27(0.80)$</td>
<td style="text-align: center;">$-1.12(1.28)$</td>
<td style="text-align: center;">$-1.24(0.89)$</td>
<td style="text-align: center;">$-1.03(0.94)$</td>
<td style="text-align: center;">$-1.35(0.95)$</td>
<td style="text-align: center;">$-1.27(1.00)$</td>
</tr>
<tr>
<td style="text-align: center;">8</td>
<td style="text-align: center;">ack-10</td>
<td style="text-align: center;">$-0.57(0.22)$</td>
<td style="text-align: center;">$-0.01(0.03)$</td>
<td style="text-align: center;">$-0.62(0.26)$</td>
<td style="text-align: center;">$-0.44(0.23)$</td>
<td style="text-align: center;">$-0.41(0.25)$</td>
<td style="text-align: center;">$-0.63(0.16)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ack-5</td>
<td style="text-align: center;">$-1.16(0.47)$</td>
<td style="text-align: center;">$-0.42(0.24)$</td>
<td style="text-align: center;">$-1.32(0.46)$</td>
<td style="text-align: center;">$-0.47(0.23)$</td>
<td style="text-align: center;">$-0.70(0.51)$</td>
<td style="text-align: center;">$-1.12(0.41)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">egg-2</td>
<td style="text-align: center;">$-0.24(0.91)$</td>
<td style="text-align: center;">0.42 (1.13)</td>
<td style="text-align: center;">$-0.02(2.20)$</td>
<td style="text-align: center;">0.78 (0.86)</td>
<td style="text-align: center;">$-0.04(0.54)$</td>
<td style="text-align: center;">$-0.27(0.85)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mat-2</td>
<td style="text-align: center;">0.78 (0.23)</td>
<td style="text-align: center;">0.90 (0.25)</td>
<td style="text-align: center;">0.81 (0.44)</td>
<td style="text-align: center;">1.09 (0.20)</td>
<td style="text-align: center;">0.81 (0.26)</td>
<td style="text-align: center;">0.75 (0.30)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mat-6</td>
<td style="text-align: center;">1.01 (0.23)</td>
<td style="text-align: center;">1.30 (0.09)</td>
<td style="text-align: center;">1.07 (0.17)</td>
<td style="text-align: center;">1.23 (0.17)</td>
<td style="text-align: center;">1.02 (0.19)</td>
<td style="text-align: center;">1.04 (0.25)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mic-10</td>
<td style="text-align: center;">1.78 (0.08)</td>
<td style="text-align: center;">1.91 (0.07)</td>
<td style="text-align: center;">1.72 (0.10)</td>
<td style="text-align: center;">1.75 (0.09)</td>
<td style="text-align: center;">1.74 (0.13)</td>
<td style="text-align: center;">1.74 (0.08)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mic-5</td>
<td style="text-align: center;">0.46 (0.37)</td>
<td style="text-align: center;">0.93 (0.19)</td>
<td style="text-align: center;">0.53 (0.35)</td>
<td style="text-align: center;">0.68 (0.26)</td>
<td style="text-align: center;">0.50 (0.32)</td>
<td style="text-align: center;">0.50 (0.52)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">nrobot-4</td>
<td style="text-align: center;">$-1.24(0.76)$</td>
<td style="text-align: center;">$-1.18(1.23)$</td>
<td style="text-align: center;">$-1.44(0.84)$</td>
<td style="text-align: center;">$-1.17(0.98)$</td>
<td style="text-align: center;">$-1.35(1.02)$</td>
<td style="text-align: center;">$-1.13(0.85)$</td>
</tr>
<tr>
<td style="text-align: center;">16</td>
<td style="text-align: center;">ack-10</td>
<td style="text-align: center;">$-0.44(0.20)$</td>
<td style="text-align: center;">$-0.02(0.04)$</td>
<td style="text-align: center;">$-0.63(0.24)$</td>
<td style="text-align: center;">$-0.37(0.18)$</td>
<td style="text-align: center;">$-0.40(0.18)$</td>
<td style="text-align: center;">$-0.61(0.16)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ack-5</td>
<td style="text-align: center;">$-0.83(0.43)$</td>
<td style="text-align: center;">$-0.41(0.23)$</td>
<td style="text-align: center;">$-1.03(0.51)$</td>
<td style="text-align: center;">$-0.41(0.24)$</td>
<td style="text-align: center;">$-0.43(0.30)$</td>
<td style="text-align: center;">$-1.11(0.35)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">egg-2</td>
<td style="text-align: center;">$-0.41(2.18)$</td>
<td style="text-align: center;">0.34 (1.17)</td>
<td style="text-align: center;">0.83 (0.67)</td>
<td style="text-align: center;">1.21 (0.49)</td>
<td style="text-align: center;">$-0.86(2.23)$</td>
<td style="text-align: center;">$-0.53(2.03)$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mat-2</td>
<td style="text-align: center;">0.79 (0.26)</td>
<td style="text-align: center;">0.88 (0.24)</td>
<td style="text-align: center;">1.07 (0.16)</td>
<td style="text-align: center;">1.12 (0.20)</td>
<td style="text-align: center;">0.86 (0.29)</td>
<td style="text-align: center;">0.83 (0.31)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mat-6</td>
<td style="text-align: center;">1.09 (0.18)</td>
<td style="text-align: center;">1.31 (0.04)</td>
<td style="text-align: center;">1.02 (0.21)</td>
<td style="text-align: center;">1.21 (0.20)</td>
<td style="text-align: center;">1.01 (0.23)</td>
<td style="text-align: center;">1.02 (0.42)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mic-10</td>
<td style="text-align: center;">1.80 (0.11)</td>
<td style="text-align: center;">1.90 (0.07)</td>
<td style="text-align: center;">1.75 (0.09)</td>
<td style="text-align: center;">1.77 (0.10)</td>
<td style="text-align: center;">1.76 (0.10)</td>
<td style="text-align: center;">1.72 (0.13)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">mic-5</td>
<td style="text-align: center;">0.53 (0.33)</td>
<td style="text-align: center;">0.91 (0.21)</td>
<td style="text-align: center;">0.68 (0.25)</td>
<td style="text-align: center;">0.67 (0.38)</td>
<td style="text-align: center;">0.66 (0.28)</td>
<td style="text-align: center;">0.60 (0.36)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">nrobot-4</td>
<td style="text-align: center;">$-1.10(0.86)$</td>
<td style="text-align: center;">$-1.15(1.20)$</td>
<td style="text-align: center;">$-1.39(0.95)$</td>
<td style="text-align: center;">$-0.95(1.02)$</td>
<td style="text-align: center;">$-0.86(0.60)$</td>
<td style="text-align: center;">$-1.07(0.92)$</td>
</tr>
</tbody>
</table>
<p>Table 4. Mean and standard deviation of the $\log ($ regret) after 100 steps of asynchronous BO.</p>
<p><img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 7. Head-to-head comparison on ack-10
<img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<p>Figure 8. Head-to-head comparison on ack-10</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{4}$ Details for these and other challenging global optimisation test functions can be found at https://www.sfu.ca/ -ssurjano/optimization.html&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>