<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3209 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3209</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3209</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-74.html">extraction-schema-74</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <p><strong>Paper ID:</strong> paper-081edae651e709e448bdd8a1f1b5760c7c7e1f53</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/081edae651e709e448bdd8a1f1b5760c7c7e1f53" target="_blank">Long Time No See! Open-Domain Conversation with Long-Term Persona Memory</a></p>
                <p><strong>Paper Venue:</strong> Findings</p>
                <p><strong>Paper TL;DR:</strong> This is the first attempt to conduct real-time dynamic management of persona information of both parties, including the user and the bot, using a dialogue generation framework with Long-Term Memory (LTM) mechanism (called PLATO-LTM).</p>
                <p><strong>Paper Abstract:</strong> Most of the open-domain dialogue models tend to perform poorly in the setting of long-term human-bot conversations. The possible reason is that they lack the capability of understanding and memorizing long-term dialogue history information. To address this issue, we present a novel task of Long-term Memory Conversation (LeMon) and then build a new dialogue dataset DuLeMon and a dialogue generation framework with Long-Term Memory (LTM) mechanism (called PLATO-LTM). This LTM mechanism enables our system to accurately extract and continuously update long-term persona memory without requiring multiple-session dialogue datasets for model training. To our knowledge, this is the first attempt to conduct real-time dynamic management of persona information of both parties, including the user and the bot. Results on DuLeMon indicate that PLATO-LTM can significantly outperform baselines in terms of long-term dialogue consistency, leading to better dialogue engagingness.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3209.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3209.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PLATO-LTM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PLATO with Long-Term Memory (PLATO-LTM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A plug-in long-term persona memory added to the PLATO-2 dialogue generator to extract, store, update and retrieve explicit persona sentences for both user and chatbot to improve long-term conversational consistency and engagingness.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>PLATO-LTM</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Generation backbone: PLATO-2 (transformer-based dialogue LM); augmented with three modules: Persona Extractor (ERNIE-CNN classifier), dual Long-Term Memory (separate user and chatbot persona stores), and a retriever (context-persona matching) that concatenates retrieved persona with context for generation; role embeddings/tokens used to mark persona sources.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>explicit external long-term persona memory (retrieval-augmented / episodic-style)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Persona Extractor (ERNIE-CNN) labels persona clauses from dialog history; write: store persona sentences with their dense embeddings E_ρ(rho_i), deduplicate by cosine similarity (replace if sim > s_dup=0.95); read: dense vector similarity search plus a context-persona matching (CPM) model (encoders E_c, E_ρ trained with triplet loss, margin α=0.2) to rank candidates, filter by similarity threshold s_c=0.7 and return top-k per memory (k=5); retrieved persona sentences are concatenated to the generator input (with role token/embedding) for decoding. Retrieval AUC=0.76, recall@5=0.83 reported for CPM.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>LeMon / DuLeMon long-term memory conversation</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Open-domain long-term persona conversation where the system must extract, maintain and use both user and bot persona (mutual persona) across sessions to generate consistent, engaging responses; dataset: DuLeMon (Chinese) collected with persona grounding labels.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>dialogue</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Human eval (self-chat, 32L models): Coherence=1.67 (scale 0-2), Consistency=0.87, Engagingness=1.54; Retrieval CPM: AUC=0.76, recall@5=0.83.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Adding explicit LTM dramatically improves persona consistency (Consistency 0.87 vs 0.40 for PLATO-FT), and increases engagingness; CPM retrieval is effective (AUC 0.76, recall@5 0.83). Using the persona extractor (PE) substantially improves results compared to storing raw history.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Fine-tuning on the (small) dataset can hurt overall coherence compared to the pre-trained PLATO-2; persona sparsity and the need for a good persona extractor are important (PLATO-LTM w/o PE performs worse). Memory capacity was left unbounded; potential retrieval/noise issues not exhaustively analyzed.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Long Time No See! Open-Domain Conversation with Long-Term Persona Memory', 'publication_date_yy_mm': '2022-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3209.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3209.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PLATO-LTM w/o PE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PLATO-LTM without Persona Extractor</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Variant of PLATO-LTM that writes all history utterances (separately for user and bot) into memory without using the persona extractor filtering step.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>PLATO-LTM w/o PE</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Same PLATO-2 generation backbone and LTM read/write mechanics, but the write pipeline stores raw historical utterances (user and bot separately) instead of first extracting persona sentences with the ERNIE-CNN persona extractor.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>explicit external long-term memory (raw-history storage, retrieval-augmented)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>All historical utterances are candidate writes; deduplication and dense embedding storage still applied; retrieval via CPM and top-k selection with same thresholds. No supervised persona filtering before write.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>LeMon / DuLeMon long-term memory conversation</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Same long-term persona conversation task; tests whether unfiltered memory helps generation.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>dialogue</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Human eval (32L): Coherence=1.57, Consistency=0.49, Engagingness=1.43.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Storing raw history in memory still improves persona consistency relative to PLATO-FT (0.49 vs 0.40) but substantially underperforms the PE-filtered LTM, showing the value of filtering persona-relevant content before storage.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>No persona filtering leads to weaker improvements; likely more noise and lower-quality retrievals than PE-enabled LTM.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Long Time No See! Open-Domain Conversation with Long-Term Persona Memory', 'publication_date_yy_mm': '2022-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3209.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3209.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PLATO-FT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PLATO-2 fine-tuned on DuLeMon (PLATO-FT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>PLATO-2 model fine-tuned on the DuLeMon dataset with role embedding/token strategies but without an external LTM component.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>PLATO-FT</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>PLATO-2 transformer-based dialogue model fine-tuned on DuLeMon; uses role embedding and role token strategies to mark personas but does not use an external memory store.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>context-window-only (no external memory)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>No separate read/write memory; relies on conditional generation from the immediate dialog context (and any persona text concatenated during training) within model context window.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>LeMon / DuLeMon long-term memory conversation</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Same long-term mutual persona dialogue task; serves as an ablation baseline to measure benefit of LTM.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>dialogue</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Human eval (32L): Coherence=1.59, Consistency=0.40, Engagingness=1.40; automatic (best generative variant PLATO-FT 32L + role_embed + role_token): PPL=9.380, BLEU-1/2=0.194/0.087, DISTINCT-1/2=0.068/0.296, F1=22.61 (Table 4).</td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Fine-tuning PLATO-2 on DuLeMon improves some automatic metrics (lower PPL) but without LTM it achieves much lower persona consistency; fine-tuning alone can slightly harm coherence versus pre-trained PLATO-2 in open self-chat.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Fine-tuning on the small DuLeMon dataset may reduce general coherence for wide-open self-play topics; lacks mechanisms to accumulate/update persona across sessions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Long Time No See! Open-Domain Conversation with Long-Term Persona Memory', 'publication_date_yy_mm': '2022-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3209.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e3209.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PLATO-2</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PLATO-2: towards building an open-domain chatbot via curriculum learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>State-of-the-art pre-trained open-domain dialogue transformer used as the generation backbone and baseline for experiments in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>PLATO-2: towards building an open-domain chatbot via curriculum learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>PLATO-2</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Large-scale transformer-based dialogue generation model pre-trained on massive dialogue corpora; used here as baseline and backbone for PLATO-FT and PLATO-LTM.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>context-window-only (no external LTM in original model)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Generative LM that conditions on provided context (no explicit long-term external memory in original PLATO-2); in this paper augmented by concatenating retrieved persona when used within PLATO-LTM.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>LeMon / DuLeMon long-term memory conversation (baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Open-domain dialogue generation evaluated on long-term persona conversation via self-chat.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>dialogue</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Human eval (32L baseline): Coherence=1.70, Consistency=0.13, Engagingness=1.46.</td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Pre-trained PLATO-2 (without DuLeMon fine-tuning or LTM) achieves high coherence but very low persona consistency in long-term conversation settings, motivating the LTM augmentation.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Lacks mechanisms to extract, store, and retrieve long-term persona; poor long-term persona consistency.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Long Time No See! Open-Domain Conversation with Long-Term Persona Memory', 'publication_date_yy_mm': '2022-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3209.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e3209.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MSC (Xu et al. 2021)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Beyond goldfish memory: Long-term open-domain conversation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-session extension of PersonaChat that annotates summaries of important personal points and demonstrates retrieval/summary-style memory for long sessions; discussed as related work.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Beyond goldfish memory: Long-term open-domain conversation</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>MSC-style retrieval-augmented generative models</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Retrieval-augmented dialogue approach that summarizes and recalls previous conversations (stored documents not dynamically modified) to provide context for generation.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>summary-based retrieval-augmented memory (static stored documents)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Summaries of previous sessions stored as documents and retrieved for future generation; stored documents grow with conversation and are not dynamically edited in MSC's setup.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Multi-session persona conversation (MSC)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Long-session multi-session dialogues where important personal points are summarized and can be retrieved for future sessions; addresses long-term memory in dialogues.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>dialogue</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>MSC shows that pre-trained generative models struggle in long-term conversation and that storing/retrieving summarized conversational facts can help, but stored documents are static and grow unbounded.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Stored documents are not dynamically modified and increase infinitely; requires long-session datasets for training which are costly.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Long Time No See! Open-Domain Conversation with Long-Term Persona Memory', 'publication_date_yy_mm': '2022-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3209.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e3209.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bang et al. 2015</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Example-based chat-oriented dialogue system with personalized long-term memory</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Rule-based/chat-oriented system that memorizes user-related information and uses it to rewrite responses; cited as prior episodic-memory style work.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Example-based chat-oriented dialogue system with personalized long-term memory</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Example-based personalized dialogue agent (Bang et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A rule/example-based dialogue system that stores personalized long-term user information and uses it in reply generation.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>episodic long-term memory (rule-based storage and rewrite)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Memory stores user-related facts from interactions and applies them in response rewriting/generation according to rules/examples.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Personalized chat with long-term memory</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Personalized dialog requiring recall of user-specific facts across sessions.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>dialogue</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Demonstrated utility of memorizing user information in rule-based systems for personalization.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Rule-based, not based on large-scale pretraining; scalability and integration with neural LMs are not addressed.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Long Time No See! Open-Domain Conversation with Long-Term Persona Memory', 'publication_date_yy_mm': '2022-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3209.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e3209.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Campos et al. 2018</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Challenges in exploiting conversational memory in human-agent interaction</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Analysis and demonstration that conversational memory can be used to revisit shared history with users but that it is hard to leverage shared history with individuals and accommodate coordination patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Challenges in exploiting conversational memory in human-agent interaction</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Conversational memory agent (Campos et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Agent architecture that uses conversational memory to revisit shared history to maintain social relationships; more conceptual/architectural analysis than large-scale LM implementation.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>conversational memory / episodic memory</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Memory mechanisms for determining prevalent contexts and revisiting shared history; emphasis on social coherence rather than neural retrieval pipelines.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Conversational social coherence / long-term interaction</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Maintaining coherent social relationships over time by referencing past interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>dialogue</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Using shared history is challenging: hard to leverage individualized shared history and to accommodate expected conversational coordination patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Practical difficulty in exploiting shared history; challenges in personalized retrieval and coordination.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Long Time No See! Open-Domain Conversation with Long-Term Persona Memory', 'publication_date_yy_mm': '2022-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3209.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e3209.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Elvir et al. 2017</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Remembering a conversation - a conversational memory architecture for embodied conversational agents</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Proposes a unified episodic memory architecture for embodied conversational agents to determine prevalent conversational contexts from prior interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Remembering a conversation - a conversational memory architecture for embodied conversational agents</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Episodic memory architecture for ECAs</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>An architecture for embodied conversational agents to store episodic conversational contexts and determine prevalent contexts for future use.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>episodic memory (architectural)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Processes to identify prevalent contexts in conversation logs and use them for future interactions; architectural focus rather than neural retrieval specifics.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Embodied conversational agents memory</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Storing and exploiting prior interactions for ECAs to maintain coherent, context-aware dialog behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>dialogue / embodied agents</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Provides an episodic memory architecture to support context-aware embodied conversational agents.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Integration with large pre-trained generative models is not covered; practical evaluation on large-scale neural systems is limited.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Long Time No See! Open-Domain Conversation with Long-Term Persona Memory', 'publication_date_yy_mm': '2022-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Beyond goldfish memory: Long-term open-domain conversation <em>(Rating: 2)</em></li>
                <li>Example-based chat-oriented dialogue system with personalized long-term memory <em>(Rating: 2)</em></li>
                <li>Challenges in exploiting conversational memory in human-agent interaction <em>(Rating: 2)</em></li>
                <li>Remembering a conversation - a conversational memory architecture for embodied conversational agents <em>(Rating: 2)</em></li>
                <li>PLATO-2: towards building an open-domain chatbot via curriculum learning <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3209",
    "paper_id": "paper-081edae651e709e448bdd8a1f1b5760c7c7e1f53",
    "extraction_schema_id": "extraction-schema-74",
    "extracted_data": [
        {
            "name_short": "PLATO-LTM",
            "name_full": "PLATO with Long-Term Memory (PLATO-LTM)",
            "brief_description": "A plug-in long-term persona memory added to the PLATO-2 dialogue generator to extract, store, update and retrieve explicit persona sentences for both user and chatbot to improve long-term conversational consistency and engagingness.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "PLATO-LTM",
            "agent_description": "Generation backbone: PLATO-2 (transformer-based dialogue LM); augmented with three modules: Persona Extractor (ERNIE-CNN classifier), dual Long-Term Memory (separate user and chatbot persona stores), and a retriever (context-persona matching) that concatenates retrieved persona with context for generation; role embeddings/tokens used to mark persona sources.",
            "memory_used": true,
            "memory_type": "explicit external long-term persona memory (retrieval-augmented / episodic-style)",
            "memory_mechanism_description": "Persona Extractor (ERNIE-CNN) labels persona clauses from dialog history; write: store persona sentences with their dense embeddings E_ρ(rho_i), deduplicate by cosine similarity (replace if sim &gt; s_dup=0.95); read: dense vector similarity search plus a context-persona matching (CPM) model (encoders E_c, E_ρ trained with triplet loss, margin α=0.2) to rank candidates, filter by similarity threshold s_c=0.7 and return top-k per memory (k=5); retrieved persona sentences are concatenated to the generator input (with role token/embedding) for decoding. Retrieval AUC=0.76, recall@5=0.83 reported for CPM.",
            "task_name": "LeMon / DuLeMon long-term memory conversation",
            "task_description": "Open-domain long-term persona conversation where the system must extract, maintain and use both user and bot persona (mutual persona) across sessions to generate consistent, engaging responses; dataset: DuLeMon (Chinese) collected with persona grounding labels.",
            "task_type": "dialogue",
            "performance_with_memory": "Human eval (self-chat, 32L models): Coherence=1.67 (scale 0-2), Consistency=0.87, Engagingness=1.54; Retrieval CPM: AUC=0.76, recall@5=0.83.",
            "performance_without_memory": null,
            "has_performance_comparison": true,
            "key_findings": "Adding explicit LTM dramatically improves persona consistency (Consistency 0.87 vs 0.40 for PLATO-FT), and increases engagingness; CPM retrieval is effective (AUC 0.76, recall@5 0.83). Using the persona extractor (PE) substantially improves results compared to storing raw history.",
            "limitations_or_challenges": "Fine-tuning on the (small) dataset can hurt overall coherence compared to the pre-trained PLATO-2; persona sparsity and the need for a good persona extractor are important (PLATO-LTM w/o PE performs worse). Memory capacity was left unbounded; potential retrieval/noise issues not exhaustively analyzed.",
            "uuid": "e3209.0",
            "source_info": {
                "paper_title": "Long Time No See! Open-Domain Conversation with Long-Term Persona Memory",
                "publication_date_yy_mm": "2022-03"
            }
        },
        {
            "name_short": "PLATO-LTM w/o PE",
            "name_full": "PLATO-LTM without Persona Extractor",
            "brief_description": "Variant of PLATO-LTM that writes all history utterances (separately for user and bot) into memory without using the persona extractor filtering step.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "PLATO-LTM w/o PE",
            "agent_description": "Same PLATO-2 generation backbone and LTM read/write mechanics, but the write pipeline stores raw historical utterances (user and bot separately) instead of first extracting persona sentences with the ERNIE-CNN persona extractor.",
            "memory_used": true,
            "memory_type": "explicit external long-term memory (raw-history storage, retrieval-augmented)",
            "memory_mechanism_description": "All historical utterances are candidate writes; deduplication and dense embedding storage still applied; retrieval via CPM and top-k selection with same thresholds. No supervised persona filtering before write.",
            "task_name": "LeMon / DuLeMon long-term memory conversation",
            "task_description": "Same long-term persona conversation task; tests whether unfiltered memory helps generation.",
            "task_type": "dialogue",
            "performance_with_memory": "Human eval (32L): Coherence=1.57, Consistency=0.49, Engagingness=1.43.",
            "performance_without_memory": null,
            "has_performance_comparison": true,
            "key_findings": "Storing raw history in memory still improves persona consistency relative to PLATO-FT (0.49 vs 0.40) but substantially underperforms the PE-filtered LTM, showing the value of filtering persona-relevant content before storage.",
            "limitations_or_challenges": "No persona filtering leads to weaker improvements; likely more noise and lower-quality retrievals than PE-enabled LTM.",
            "uuid": "e3209.1",
            "source_info": {
                "paper_title": "Long Time No See! Open-Domain Conversation with Long-Term Persona Memory",
                "publication_date_yy_mm": "2022-03"
            }
        },
        {
            "name_short": "PLATO-FT",
            "name_full": "PLATO-2 fine-tuned on DuLeMon (PLATO-FT)",
            "brief_description": "PLATO-2 model fine-tuned on the DuLeMon dataset with role embedding/token strategies but without an external LTM component.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "PLATO-FT",
            "agent_description": "PLATO-2 transformer-based dialogue model fine-tuned on DuLeMon; uses role embedding and role token strategies to mark personas but does not use an external memory store.",
            "memory_used": false,
            "memory_type": "context-window-only (no external memory)",
            "memory_mechanism_description": "No separate read/write memory; relies on conditional generation from the immediate dialog context (and any persona text concatenated during training) within model context window.",
            "task_name": "LeMon / DuLeMon long-term memory conversation",
            "task_description": "Same long-term mutual persona dialogue task; serves as an ablation baseline to measure benefit of LTM.",
            "task_type": "dialogue",
            "performance_with_memory": null,
            "performance_without_memory": "Human eval (32L): Coherence=1.59, Consistency=0.40, Engagingness=1.40; automatic (best generative variant PLATO-FT 32L + role_embed + role_token): PPL=9.380, BLEU-1/2=0.194/0.087, DISTINCT-1/2=0.068/0.296, F1=22.61 (Table 4).",
            "has_performance_comparison": true,
            "key_findings": "Fine-tuning PLATO-2 on DuLeMon improves some automatic metrics (lower PPL) but without LTM it achieves much lower persona consistency; fine-tuning alone can slightly harm coherence versus pre-trained PLATO-2 in open self-chat.",
            "limitations_or_challenges": "Fine-tuning on the small DuLeMon dataset may reduce general coherence for wide-open self-play topics; lacks mechanisms to accumulate/update persona across sessions.",
            "uuid": "e3209.2",
            "source_info": {
                "paper_title": "Long Time No See! Open-Domain Conversation with Long-Term Persona Memory",
                "publication_date_yy_mm": "2022-03"
            }
        },
        {
            "name_short": "PLATO-2",
            "name_full": "PLATO-2: towards building an open-domain chatbot via curriculum learning",
            "brief_description": "State-of-the-art pre-trained open-domain dialogue transformer used as the generation backbone and baseline for experiments in this paper.",
            "citation_title": "PLATO-2: towards building an open-domain chatbot via curriculum learning",
            "mention_or_use": "use",
            "agent_name": "PLATO-2",
            "agent_description": "Large-scale transformer-based dialogue generation model pre-trained on massive dialogue corpora; used here as baseline and backbone for PLATO-FT and PLATO-LTM.",
            "memory_used": false,
            "memory_type": "context-window-only (no external LTM in original model)",
            "memory_mechanism_description": "Generative LM that conditions on provided context (no explicit long-term external memory in original PLATO-2); in this paper augmented by concatenating retrieved persona when used within PLATO-LTM.",
            "task_name": "LeMon / DuLeMon long-term memory conversation (baseline)",
            "task_description": "Open-domain dialogue generation evaluated on long-term persona conversation via self-chat.",
            "task_type": "dialogue",
            "performance_with_memory": null,
            "performance_without_memory": "Human eval (32L baseline): Coherence=1.70, Consistency=0.13, Engagingness=1.46.",
            "has_performance_comparison": true,
            "key_findings": "Pre-trained PLATO-2 (without DuLeMon fine-tuning or LTM) achieves high coherence but very low persona consistency in long-term conversation settings, motivating the LTM augmentation.",
            "limitations_or_challenges": "Lacks mechanisms to extract, store, and retrieve long-term persona; poor long-term persona consistency.",
            "uuid": "e3209.3",
            "source_info": {
                "paper_title": "Long Time No See! Open-Domain Conversation with Long-Term Persona Memory",
                "publication_date_yy_mm": "2022-03"
            }
        },
        {
            "name_short": "MSC (Xu et al. 2021)",
            "name_full": "Beyond goldfish memory: Long-term open-domain conversation",
            "brief_description": "A multi-session extension of PersonaChat that annotates summaries of important personal points and demonstrates retrieval/summary-style memory for long sessions; discussed as related work.",
            "citation_title": "Beyond goldfish memory: Long-term open-domain conversation",
            "mention_or_use": "mention",
            "agent_name": "MSC-style retrieval-augmented generative models",
            "agent_description": "Retrieval-augmented dialogue approach that summarizes and recalls previous conversations (stored documents not dynamically modified) to provide context for generation.",
            "memory_used": true,
            "memory_type": "summary-based retrieval-augmented memory (static stored documents)",
            "memory_mechanism_description": "Summaries of previous sessions stored as documents and retrieved for future generation; stored documents grow with conversation and are not dynamically edited in MSC's setup.",
            "task_name": "Multi-session persona conversation (MSC)",
            "task_description": "Long-session multi-session dialogues where important personal points are summarized and can be retrieved for future sessions; addresses long-term memory in dialogues.",
            "task_type": "dialogue",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_comparison": null,
            "key_findings": "MSC shows that pre-trained generative models struggle in long-term conversation and that storing/retrieving summarized conversational facts can help, but stored documents are static and grow unbounded.",
            "limitations_or_challenges": "Stored documents are not dynamically modified and increase infinitely; requires long-session datasets for training which are costly.",
            "uuid": "e3209.4",
            "source_info": {
                "paper_title": "Long Time No See! Open-Domain Conversation with Long-Term Persona Memory",
                "publication_date_yy_mm": "2022-03"
            }
        },
        {
            "name_short": "Bang et al. 2015",
            "name_full": "Example-based chat-oriented dialogue system with personalized long-term memory",
            "brief_description": "Rule-based/chat-oriented system that memorizes user-related information and uses it to rewrite responses; cited as prior episodic-memory style work.",
            "citation_title": "Example-based chat-oriented dialogue system with personalized long-term memory",
            "mention_or_use": "mention",
            "agent_name": "Example-based personalized dialogue agent (Bang et al.)",
            "agent_description": "A rule/example-based dialogue system that stores personalized long-term user information and uses it in reply generation.",
            "memory_used": true,
            "memory_type": "episodic long-term memory (rule-based storage and rewrite)",
            "memory_mechanism_description": "Memory stores user-related facts from interactions and applies them in response rewriting/generation according to rules/examples.",
            "task_name": "Personalized chat with long-term memory",
            "task_description": "Personalized dialog requiring recall of user-specific facts across sessions.",
            "task_type": "dialogue",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_comparison": null,
            "key_findings": "Demonstrated utility of memorizing user information in rule-based systems for personalization.",
            "limitations_or_challenges": "Rule-based, not based on large-scale pretraining; scalability and integration with neural LMs are not addressed.",
            "uuid": "e3209.5",
            "source_info": {
                "paper_title": "Long Time No See! Open-Domain Conversation with Long-Term Persona Memory",
                "publication_date_yy_mm": "2022-03"
            }
        },
        {
            "name_short": "Campos et al. 2018",
            "name_full": "Challenges in exploiting conversational memory in human-agent interaction",
            "brief_description": "Analysis and demonstration that conversational memory can be used to revisit shared history with users but that it is hard to leverage shared history with individuals and accommodate coordination patterns.",
            "citation_title": "Challenges in exploiting conversational memory in human-agent interaction",
            "mention_or_use": "mention",
            "agent_name": "Conversational memory agent (Campos et al.)",
            "agent_description": "Agent architecture that uses conversational memory to revisit shared history to maintain social relationships; more conceptual/architectural analysis than large-scale LM implementation.",
            "memory_used": true,
            "memory_type": "conversational memory / episodic memory",
            "memory_mechanism_description": "Memory mechanisms for determining prevalent contexts and revisiting shared history; emphasis on social coherence rather than neural retrieval pipelines.",
            "task_name": "Conversational social coherence / long-term interaction",
            "task_description": "Maintaining coherent social relationships over time by referencing past interactions.",
            "task_type": "dialogue",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_comparison": null,
            "key_findings": "Using shared history is challenging: hard to leverage individualized shared history and to accommodate expected conversational coordination patterns.",
            "limitations_or_challenges": "Practical difficulty in exploiting shared history; challenges in personalized retrieval and coordination.",
            "uuid": "e3209.6",
            "source_info": {
                "paper_title": "Long Time No See! Open-Domain Conversation with Long-Term Persona Memory",
                "publication_date_yy_mm": "2022-03"
            }
        },
        {
            "name_short": "Elvir et al. 2017",
            "name_full": "Remembering a conversation - a conversational memory architecture for embodied conversational agents",
            "brief_description": "Proposes a unified episodic memory architecture for embodied conversational agents to determine prevalent conversational contexts from prior interactions.",
            "citation_title": "Remembering a conversation - a conversational memory architecture for embodied conversational agents",
            "mention_or_use": "mention",
            "agent_name": "Episodic memory architecture for ECAs",
            "agent_description": "An architecture for embodied conversational agents to store episodic conversational contexts and determine prevalent contexts for future use.",
            "memory_used": true,
            "memory_type": "episodic memory (architectural)",
            "memory_mechanism_description": "Processes to identify prevalent contexts in conversation logs and use them for future interactions; architectural focus rather than neural retrieval specifics.",
            "task_name": "Embodied conversational agents memory",
            "task_description": "Storing and exploiting prior interactions for ECAs to maintain coherent, context-aware dialog behavior.",
            "task_type": "dialogue / embodied agents",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_comparison": null,
            "key_findings": "Provides an episodic memory architecture to support context-aware embodied conversational agents.",
            "limitations_or_challenges": "Integration with large pre-trained generative models is not covered; practical evaluation on large-scale neural systems is limited.",
            "uuid": "e3209.7",
            "source_info": {
                "paper_title": "Long Time No See! Open-Domain Conversation with Long-Term Persona Memory",
                "publication_date_yy_mm": "2022-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Beyond goldfish memory: Long-term open-domain conversation",
            "rating": 2
        },
        {
            "paper_title": "Example-based chat-oriented dialogue system with personalized long-term memory",
            "rating": 2
        },
        {
            "paper_title": "Challenges in exploiting conversational memory in human-agent interaction",
            "rating": 2
        },
        {
            "paper_title": "Remembering a conversation - a conversational memory architecture for embodied conversational agents",
            "rating": 2
        },
        {
            "paper_title": "PLATO-2: towards building an open-domain chatbot via curriculum learning",
            "rating": 1
        }
    ],
    "cost": 0.0138395,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Long Time No See! Open-Domain Conversation with Long-Term Persona Memory</h1>
<p>Xinchao $\mathbf{X u}^{1 <em>}$, Zhibin Gou ${ }^{1,2 </em>}$, Wenquan $\mathbf{W u}^{1}$, Zheng-Yu Niu ${ }^{1}$, Hua Wu ${ }^{1}$, Haifeng Wang ${ }^{1}$ and Shihang Wang ${ }^{3}$<br>${ }^{1}$ Baidu Inc., China<br>${ }^{2}$ School of Computer Science, Beijing University of Posts and Telecommunications<br>${ }^{3}$ Columbia University<br>{xinchaoxu, wuwenquan01,niuzhengyu, wu_hua,wanghaifeng}@baidu.com zebgou@gmail.com, sw3275@columbia.edu</p>
<h4>Abstract</h4>
<p>Most of the open-domain dialogue models tend to perform poorly in the setting of long-term human-bot conversations. The possible reason is that they lack the capability of understanding and memorizing long-term dialogue history information. To address this issue, we present a novel task of Long-term Memory Conversation (LeMon) and then build a new dialogue dataset DuLeMon and a dialogue generation framework PLATO-LTM with a Long-Term Memory (LTM) mechanism. This LTM mechanism enables our system to accurately extract and continuously update long-term persona memory without requiring multiple-session dialogue datasets for model training. To our knowledge, this is the first attempt to conduct real-time dynamic management of persona information of both parties, including the user and the bot. Results on DuLeMon indicate that PLATO-LTM can significantly outperform baselines in terms of long-term dialogue consistency, leading to better dialogue engagingness ${ }^{1}$.</p>
<h2>1 Introduction</h2>
<p>Persona is crucial for open-domain dialogue systems to establish long-term intimacy with users (Huang et al., 2020). Existing persona dialogue datasets such as PersonaChat (Zhang et al., 2018; Dinan et al., 2019) and models (Li et al., 2016a; Zhang et al., 2017; Qian et al., 2018) have greatly facilitated the chatbot with configurable and persistent personalities.</p>
<p>Nevertheless, current open-domain dialogue systems still cannot build a long-term connection with humans. The possible reason is that they lack the capability of understanding and memorizing longterm dialogue history information, which we called</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: A sample of long-term conversation with memory. At first, the chat partner is not familiar with each other, so the goal is to get to know each other; Then, after multiple sessions, the chatbot already has a certain understanding and memory of the user's persona and its own persona, making the deep chat possible.
long-term persona ability. Remembering and actively utilizing the user's persona increases engagingness and contributes to long-term friendships between chatbot and user (Campos et al., 2018). Without this ability, the current state-of-the-art models, such as Meena (Adiwardana et al., 2020), Blender (Roller et al., 2021), and PLATO (Bao et al., 2020), tend to talk to people like strangers in long-term conversations.</p>
<p>Despite the importance and challenge of utilizing long-term persona in open-domain dialogue, as far as we know, the long-term persona ability of large-scale models is less studied due to a lack of both task design and corresponding dataset. Previous long-term persona dialogue systems (Kim et al., 2014; Bang et al., 2015) are mainly rule-based systems without large-scale pre-training models, in which researchers proposed various episodic memory architectures to extract, store and manage rel-</p>
<p>evant facts in prior interactions for use in future dialogs (Campos et al., 2018).</p>
<p>In addition, existing persona conversation datasets (Zhang et al., 2018; Dinan et al., 2019; Zheng et al., 2019) focus only on the consistency of the chatbot's own persona and ignore the memory and utilization of the user's persona. And they all set fixed persona that cannot be updated during the chat. Recently, Xu et al. (2021) proposed MSC dataset as a multi-session extension of PersonaChat, and its sessions are additionally annotated with summaries of important personal points. Similar to the previous episodic memory architecture, Xu et al. (2021) summarize and recall previous conversations for future dialogue generation. The stored documents in MSC will not be dynamically modified and will increase infinitely as the conversation progresses. Furthermore, the retrieval-augmented generative models rely on a long-session conversation dataset for training, which is expensive and difficult to annotate.</p>
<p>To address the limitations of existing models and the above issues, we defines the LeMon (Longterm Memory Conversation) task and propose a new dataset named DuLeMon, which focuses not only on the consistency of the bot's own persona but also on the active construction and utilization of the user's persona in a long-term interaction (ie. mutual persona). We demonstrate an example dialogue in DuLeMon in Figure 1. In DuLeMon, we assume that the two speakers have previously interacted with each other and that the chatbot remembers part of the user's persona. Besides, both the user and chatbot grounding persona are annotated in each utterance.</p>
<p>Based on our collected dataset, we carefully design a novel PLATO-LTM framework for the longterm persona dialogue setting by adding a plug-andplay long-term memory (LTM) to the state-of-theart open-domain dialogue model (Bao et al., 2020). It enables us to study long-term persona conversations without relying on the long-session dataset. PLATO-LTM can extract both parties' persona information from the conversation in real time, write it to persona memory respectively, and retrieve both parties' persona information from memory to generate responses. The PLATO-LTM framework consists of three modules: (1) Persona Extractor (PE): The memory is updated by filtering irrelevant information and extracting persona sentences through a classifier. (2) Long-Term Memory (LTM): Two
separated long-term memories store the explicit persona information of interlocutors. (3) Generation Module: We use the large-scale model and the retrieved persona sentences of the user and chatbot are directly concatenated with dialogue context as model input.</p>
<p>Our major contributions are as follows:
(1) We firstly propose the long-term persona chat task LeMon for Chinese long-term conversations. Our proposed DuLeMon dataset is also the largest multi-turn Chinese mutual persona chat dataset currently available.
(2) We proposed a PLATO-LTM framework that extracts and remembers both user's and the chatbot's persona in real time, enabling the chatbot to have long-term persona dialogue without training on long-session data.
(3) Automatic and human evaluation show that our method significantly improves the consistency of the state-of-the-art in long conversations, making the response more engaging while ensuring coherency.</p>
<h2>2 Related Work</h2>
<p>Persona Dialogue: As described in Huang et al. (2020), there is much work related to persona dialogue. Generally speaking, these works can be divided into implicit persona models and explicit persona models. In the implicit model, the persona is represented in the form of the semantic persona vector. Kim et al. (2014) proposed a retrieval-based method to integrate persona and user interests into the dialogue system. Because these models are implicit methods, they are not easy to interpret and control in target response generation. In Qian et al. (2018), an explicit persona model is proposed to generate consistent responses for given persona information. The persona information of the machine includes name, gender, hobbies, and so on. In this way, the given persona information can be better used for model generation. There are also many persona chat datasets that have been constructed to develop models, as shown in Table 1. In particular, the introduction of the PersonaChat (Zhang et al., 2018; Dinan et al., 2019) dataset has extensively promoted the development of this field where the crowd-workers are simply asked to "chat with the other person naturally and try to get to know each other." However, the user's persona was unknown</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Dataset</th>
<th style="text-align: left;">Persona</th>
<th style="text-align: left;">Mutual</th>
<th style="text-align: left;"># Dialogues</th>
<th style="text-align: left;">Language</th>
<th style="text-align: left;">Multi-turn</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">PersonaChat (Zhang et al., 2018)</td>
<td style="text-align: left;">Text</td>
<td style="text-align: left;">$\boldsymbol{X}$</td>
<td style="text-align: left;">10,907</td>
<td style="text-align: left;">English</td>
<td style="text-align: left;">Yes</td>
</tr>
<tr>
<td style="text-align: left;">PersonaIDialog (Zheng et al., 2019)</td>
<td style="text-align: left;">Structure</td>
<td style="text-align: left;">$\boldsymbol{X}$</td>
<td style="text-align: left;">$20,830,000$</td>
<td style="text-align: left;">Chinese</td>
<td style="text-align: left;">part</td>
</tr>
<tr>
<td style="text-align: left;">XPersona (Lin et al., 2020)</td>
<td style="text-align: left;">Text</td>
<td style="text-align: left;">$\boldsymbol{X}$</td>
<td style="text-align: left;">16,878</td>
<td style="text-align: left;">Multilingual</td>
<td style="text-align: left;">Yes</td>
</tr>
<tr>
<td style="text-align: left;">PEC (Zhong et al., 2020)</td>
<td style="text-align: left;">Text</td>
<td style="text-align: left;">$\boldsymbol{X}$</td>
<td style="text-align: left;">355,000</td>
<td style="text-align: left;">English</td>
<td style="text-align: left;">Yes</td>
</tr>
<tr>
<td style="text-align: left;">PCR (Mazaré et al., 2018)</td>
<td style="text-align: left;">Text</td>
<td style="text-align: left;">$\boldsymbol{X}$</td>
<td style="text-align: left;">$700,000,000$</td>
<td style="text-align: left;">English</td>
<td style="text-align: left;">Yes</td>
</tr>
<tr>
<td style="text-align: left;">MSC (Xu et al., 2021)</td>
<td style="text-align: left;">Text</td>
<td style="text-align: left;">$\checkmark$</td>
<td style="text-align: left;">5,001</td>
<td style="text-align: left;">English</td>
<td style="text-align: left;">Yes</td>
</tr>
<tr>
<td style="text-align: left;">DuLeMon (Ours)</td>
<td style="text-align: left;">Text</td>
<td style="text-align: left;">$\checkmark$</td>
<td style="text-align: left;">27,501</td>
<td style="text-align: left;">Chinese</td>
<td style="text-align: left;">Yes</td>
</tr>
</tbody>
</table>
<p>Table 1: Comparison of our dataset DuLeMon with other datasets.
to the bot, so the dialogue was like strangers exchanging information. In contrast, our proposed DuLeMon dataset requires the chatbot to actively remember and use the user's persona to improve conversational engagements and increase the intimacy between interlocutors in long-term interactions.
Dialogue Model with External Memory: As described in Lim (2012), there are various memory models used by the rule-based dialogue systems. In Bang et al. (2015), user-related information is memorized and used to rewrite the response. In Elvir et al. (2017), a unified episodic memory architecture for Embodied Conversational Agents (ECAs) is proposed. They describe a process that determines the prevalent contexts in the conversations obtained from the interactions. In Campos et al. (2018), the authors introduce an agent that uses its conversational memory to revisit shared history with users to maintain a coherent social relationship over time. However, they find it challenging to leverage the shared history with individual users and hard to accommodate expected conversational coordination patterns. Apart from studies in rulebased dialogue systems mentioned above, Xu et al. (2021) shows how large-scale pre-training generative dialogue models trained on existing datasets perform poorly in the long-term conversation setting and proposes a new extended English conversation dataset, entitled Multi-Session Chat (MSC). Different from them, our novel dataset DuLeMon does not rely on long sessions with high collection costs to study long-term memory problems in the persona chat, with significant differences in task design and data collection.</p>
<h2>3 Data Collection</h2>
<p>Task Definition. Given dialogue context $c=$ $\left{u_{1}, s_{1}, u_{2}, s_{2}, \ldots, u_{t-1}, s_{t-1}, u_{t}\right}$, where $u$ and $s$ represent the user and the chatbot respectively. Each speaker has its corresponding persona descrip-
tion that consists of a set of sentences, we define the user persona as $\rho^{u}=\left{\rho_{1}^{u}, \rho_{2}^{u}, \ldots, \rho_{m}^{u}\right}$, and the chatbot persona as $\rho^{s}=\left{\rho_{1}^{s}, \rho_{2}^{s}, \ldots, \rho_{n}^{s}\right}$. Given the dialogue context $c$, user persona $\rho^{u}$ and chatbot persona $\rho^{s}$, we are interested in finding the corresponding persona and predicting the chatbot response $s_{t}$.</p>
<p>To support our task, we collect and release a new dataset, entitled DuLeMon. In DuLeMon, the chatbot actively remembers and reasonably uses what the user has said about their persona while maintaining consistency in its persona, allowing the conversation to proceed more deeply. In a nutshell, our DuLeMon dataset has two essential features: During the conversation, the chatbot can see the persona of both parties; the other is that the persona associated with the response is explicitly annotated in our dataset. Unlike the PersonaChat dataset, the setting in DuLeMon is that one speaker plays the role of a chatbot, and the other plays the user's role. We elaborate on the construction process of the dataset as the following.
(1) Persona collection: The persona is mainly from the translation and rewriting of persona in PersonaChat. The chatbot's persona is only visible to itself, and the chatbot can use its persona information to chat with the user, as shown in Figure 2. The user's persona contains two parts: persona that the chatbot already knows and persona that the chatbot does not know. The first part is the user's persona that the chatbot has learned through historical conversations. This part is randomly selected from multiple personas of each user. The chatbot needs to use this information to guide the conversation during the chat process. It should be noted that in order to simulate the situation at the beginning of the chat, this part may be empty.
(2) Dialogue collection: For each dialogue, two crowd-workers (one plays the chatbot, the other plays the user) are randomly paired and given random persona. They are required to organize a di-</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Example of our proposed DuLeMon dataset with both chatbot's and user's persona. It has two important features: one is that during the conversation, the chatbot can see the persona of both parties; the other is that the persona information associated with the response is explicitly labeled in our dataset which is shown as the $\rho^{a}$ and $\rho^{a}$ in the figure.
alogue based on the given persona. The chatbot should think more about chatting to make it go on. It should utilize the known user's persona to conduct the in-depth chat. The user will act as an ordinary user to cooperate with the conversation. The content of the chat can be selected from the given persona. It must not be irrelevant for the given information, nor can it conflict with the given persona.
(3) Persona Grounding Labeling: This part annotates whether the current response uses the given persona information and whether the current sentence is a persona sentence. For each utterance, we first let the annotators label whether it uses persona or not. Furthermore, the annotator should label the grounding persona (from chatbot or user) being used in the response. Therefore, through this process, the direct relationship between the response and the persona can be given. Then, for sentences that use the persona, we further annotate whether the utterance is a persona sentence or not.</p>
<p>To scale the amount of data, we also collected conversations where the user's persona was not visible to the bot, following the PersonaChat (Zhang et al., 2018). Finally, our DuLeMon dataset consists of two parts. In DeLeMon-SELF, the bot only knows its own persona, while in DuLeMonBOTH, it also knows part of the user's persona (as described above). The overall statistics of the DuLeMon are shown in Table 2.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Category</th>
<th style="text-align: left;">SELF</th>
<th style="text-align: left;">BOTH</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"># Dialogues</td>
<td style="text-align: left;">24500</td>
<td style="text-align: left;">3001</td>
</tr>
<tr>
<td style="text-align: left;"># Utterances</td>
<td style="text-align: left;">400472</td>
<td style="text-align: left;">48522</td>
</tr>
<tr>
<td style="text-align: left;">Avg. # turns</td>
<td style="text-align: left;">16.3</td>
<td style="text-align: left;">16.2</td>
</tr>
<tr>
<td style="text-align: left;">Avg. length of utterances</td>
<td style="text-align: left;">19.7</td>
<td style="text-align: left;">21.2</td>
</tr>
<tr>
<td style="text-align: left;">Avg. # bot persona</td>
<td style="text-align: left;">4.0</td>
<td style="text-align: left;">4.0</td>
</tr>
<tr>
<td style="text-align: left;">Avg. # user persona (seen)</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">4.4</td>
</tr>
<tr>
<td style="text-align: left;">Avg. # user persona (unseen)</td>
<td style="text-align: left;">4.0</td>
<td style="text-align: left;">1.3</td>
</tr>
</tbody>
</table>
<p>Table 2: Statistics of DuLeMon.</p>
<h2>4 Model Architecture</h2>
<p>In this work, we propose a long-term memory dialogue system based on an explicit memory readwrite mechanism. It includes three parts: persona extractor, long-term persona memory, and generation module. Through the read and write operations of the long-term memory module, the user's and chatbot's persona can be stored, updated, and read. The overall framework is shown in Figure3.</p>
<h3>4.1 Persona Extractor</h3>
<p>Given an utterance or text span as input, our persona extractor can assign each input a label to indicate if it contains persona information. Here we train an ERNIE-CNN network architecture in a supervised way on an annotated persona-utterance dataset as this persona extractor. Specifically, the ERNIE-CNN network employs a pre-trained ERNIE $^{2}$ (Sun et al., 2019) network for sentence representation, and another CNN model (Kim, 2014)</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Illustration of our system PLATO-LTM. (a) shows the dialogue flow. (b) describes the modules and pipeline of our system. It consists of a persona extractor (PE), a long-term persona memory, a retriever, and a generator. (1) The long-term memory contains both user persona and chatbot persona extracted from the dialogue history by PE. (2) The retriever uses context as query to retrieve related personas in memory (3) concatenates the retrieved text to the context and use the generator to produce the generated response. (c) details our generator PLATO-2 and ranker CPM (Context Persona Matching).
for classification.
Training procedure. First, we collect the firstversion training dataset, in which there are 6 k utterances (from the DuLeMon corpus and Chinese social forum corpus) being human-annotated with positive or negative class labels. Second, using the aforementioned dataset, we train five ERNIE-CNN network (with different pre-training parameter versions) based models (called pc-stage1). Third, we employ these five models to automatically annotate 1.4 million utterances with labels, where these utterances are collected from the DuLeMon and the online Chinese social forum. We then refine this augmented dataset as the final-version dataset with the following steps: (a) Given an utterance, if there are at least two of the above five models identifying it as a positive sample, then it is attached with a positive label, (b) otherwise it is attached with a negative label. Finally, we train the five models on the final-version dataset and select the one with the best performance as our persona extractor (named pc-stage2).</p>
<p>Inference procedure. First, given an utterance, we segment it into clauses with the use of punctuation marks. Second, we use the persona extractor
mentioned above to classify each clause with a label and then collect the clause with a positive label as persona sentences.</p>
<h3>4.2 Long-Term Memory</h3>
<p>The long-term memory (LTM) module maintains memories to store the historical persona information from the user and the chatbot, respectively. The most critical operations are reading and writing based on the context persona matching (CPM) model. We use context encoder $E_{c}(\cdot)$ to encode the current context $c$, and use persona encoder $E_{\rho}(\cdot)$ to encode the persona $\rho_{i} . E(\cdot)$ is the encoder's output on the first input token ([CLS]), corresponding to the input's pooled representation.</p>
<p>The encoder $E_{c}$ and $E_{\rho}$ is initialized with the ERNIE model and then trained on our DuLeMon corpus. For each training sample, we define the positive persona as the persona used in the current user's utterance and the bot's response (including bot persona and user persona seen by bot), and the negative persona as the remaining persona of the current session. Given context $c$, a positive persona $\rho^{+}$, and a negative persona $\rho^{-}$, we use triplet loss</p>
<p>to tune the network as:</p>
<p>$$
\max \left(\operatorname{sim}\left(c, \rho^{+}\right)-\operatorname{sim}\left(c, \rho^{-}\right)+\alpha, 0\right)
$$</p>
<p>We set the margin $\alpha=0.2$ in our experiments. Below we describe the specific read and write process of the long-term memory module.</p>
<p>Write: We use the PE module to identify the persona in the dialogue history as the candidate information to be written. It needs to eliminate duplicates before writing. Specifically, calculate the cosine similarity with the persona in memory to get the most approximate persona $\rho_{j}$. When the similarity between $\rho_{i}$ and $\rho_{j}$ exceeds the given duplication threshold $s_{\text {dup }}$, replace $\rho_{j}$ in memory with $\rho_{i}$; otherwise, write $\rho_{i}$ directly into the memory. When writing to memory, save $\left{\rho_{i}, E_{\rho}\left(\rho_{i}\right)\right}$ pair for the subsequent reading. We measure the distance with the cosine similarity as:</p>
<p>$$
\operatorname{sim}\left(\rho_{i}, \rho_{j}\right)=\cos \left(E_{\rho}\left(\rho_{i}\right), E_{\rho}\left(\rho_{j}\right)\right)
$$</p>
<p>Read: The reading process can be regarded as the retrieval process from memory. First, we use the efficient similarity search of dense vectors to select candidates. Then a matching model is utilized to score the relevance of the candidates to the current context. The similarity between the context and the persona using cosine similarity:</p>
<p>$$
\operatorname{sim}\left(c, \rho_{i}\right)=\cos \left(E_{c}(c), E_{\rho}\left(\rho_{i}\right)\right)
$$</p>
<p>The top $k$ persona candidates $\rho^{u}$ in the user memory and top $k$ candidates $\rho^{s}$ in the chatbot memory are used for response generation. To model persona sparsity in dialogue, we filter out the persona, whose similarity score is lower than the similarity threshold $s_{c}$.</p>
<h3>4.3 Generation Module</h3>
<p>We trained our model on the basis of the PLATO2 (Bao et al., 2020) architecture which adopts the generic transformer language model (Vaswani et al., 2017) and leverages a stack of masked multi-head self-attention layers to train on massive dialogue data ${ }^{3}$.</p>
<p>Given the conversation context $c=$ $\left{u_{1}, s_{1}, u_{2}, s_{2}, \ldots, u_{t-1}, s_{t-1}, u_{t}\right}$, the corresponding user persona $\rho^{u}$ and chatbot persona $\rho^{s}$, the ground truth response as</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup>$r=\left{x_{m+1}, x_{m+2}, \ldots, x_{N}\right}$, the conditional probability of $p\left(r \mid c, \rho^{u}, \rho^{s}\right)$ can be written as the product of a series of conditional probabilities:</p>
<p>$$
p\left(r \mid c, \rho^{u}, \rho^{s}\right)=\prod_{t}^{N} p\left(r_{t} \mid c, \rho^{u}, \rho^{s}, r_{&lt;t}\right)
$$</p>
<p>Therefore, we need to minimize the following negative log-likelihood (NLL) loss:</p>
<p>$$
\begin{aligned}
\mathcal{L}<em t="1">{N L L} &amp; =-\mathbb{E} \log p\left(r \mid c, \rho^{u}, \rho^{s}\right) \
&amp; =-\mathbb{E} \sum</em>\right)
\end{aligned}
$$}^{T} \log p\left(r_{t} \mid c, \rho^{u}, \rho^{s}, r_{&lt;t</p>
<p>where $T$ is the length of the target response $r$ and $r_{&lt;t}$ denotes previously generated words. Since the response generation is a uni-directional decoding process, each token in the response only attends to those before it. As for the context, bi-directional attention is enabled for better natural language understanding.</p>
<p>We added two strategies to distinguish different roles in the dialogue and prevent the confusing use of persona information.</p>
<ul>
<li>Role Embedding (Bao et al., 2021): different role embedding is used to distinguish the persona of different chat parties, abbreviated role_embed.</li>
<li>Role Token: splicing "system persona" before the chatbot persona and "user persona" before the user persona, abbreviated role_token.</li>
</ul>
<h2>5 Experiments</h2>
<p>In this section, we present the baselines, experiment settings, model comparisons, and results of experiments.</p>
<h3>5.1 Compared Methods</h3>
<p>As baselines, we select state-of-the-art methods to compare with our method.</p>
<ul>
<li>PLATO-2 (Bao et al., 2020): The SOTA opendomain dialogue model.</li>
<li>PLATO-FT: The PLATO-2 model fine-tuned on our proposed DuLeMon dataset.</li>
<li>
<p>PLATO-LTM: The PLATO-FT model with our proposed long-term memory (LTM).</p>
</li>
<li>
<p>PLATO-LTM w/o PE: PLATO-LTM without the persona extractor (PE) module, which stores all history utterances (user and bot separately) into memory without persona extraction.</p>
</li>
</ul>
<h3>5.2 Experiment Settings</h3>
<p>Automatic Evaluation Metrics. We use Precision, Recall and F1 to evaluate the persona classification model. For the long-term memory module, we use the AUC and recall@k to evaluate the ranking model. We evaluate responses generated by the models using PPL, BLEU (Papineni et al., 2002), and F1 with reference to the human-annotated responses and DISTINCT-1/2 (Zhao et al., 2017). More recently, Adiwardana et al. (2020) has shown the correlation between perplexity and human judgment in open-domain chit-chat models.
Human Evaluation Metrics. In human evaluation, we employ three utterance-level metrics, including coherence, consistency, engagingness. Three crowd-sourcing workers are asked to score the response/dialogue quality on a scale of $[0,1,2]$. The higher score, the better. These criteria are discussed as follows:</p>
<ul>
<li>Coherence: an utterance-level metric, measuring whether the response is relevant and consistent with the context.</li>
<li>Consistency: an utterance-level metric, evaluating whether the response is consistent with the persona in the dialogue history.</li>
<li>Engagingness: an utterance-level metric, assessing whether the annotator would like to talk with the speaker for each response in the long-term conversation.</li>
</ul>
<h3>5.3 Results</h3>
<p>In this part, we first analyze the effects of each module and then analyze the results of the manual evaluation of our entire system, PLATO-LTM.</p>
<h3>5.3.1 Results of Persona Extractor</h3>
<p>We measure the performance of the persona extractor. To measure the performance of different models, we manually annotated the test set (the number of test sets is 200). We select the best of the first and second stages. The result is shown in Table 3. The pc-stage2 model is better than that of the pc-stage1 model. The F1 of the model exceeds</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Model</th>
<th style="text-align: left;">ACC</th>
<th style="text-align: left;">Precision</th>
<th style="text-align: left;">Recall</th>
<th style="text-align: left;">F1</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">pc-stage1</td>
<td style="text-align: left;">0.91</td>
<td style="text-align: left;">0.96</td>
<td style="text-align: left;">0.84</td>
<td style="text-align: left;">0.90</td>
</tr>
<tr>
<td style="text-align: left;">pc-stage2</td>
<td style="text-align: left;">0.92</td>
<td style="text-align: left;">0.95</td>
<td style="text-align: left;">0.87</td>
<td style="text-align: left;">0.91</td>
</tr>
</tbody>
</table>
<p>Table 3: Comparison of two-stage models of our persona classifier.
0.9 , which shows that our model can effectively recognize the persona information from the dialogue history and ensure that the persona information can be correctly stored in the long-term memory. Therefore, the pc-stage2 model is adopted in our system to recognize the persona in the dialogue history.</p>
<h3>5.3.2 Selection of Generative Models</h3>
<p>The generative model utilizes the current context and persona information retrieved from long-term memory to generate the response. We first evaluate the effect of the CPM model on retrieval persona information. The AUC on the automatic test set is 0.76 , recall@ 5 is 0.83 , which shows that our model can efficiently retrieve relevant persona from the long-term memory.</p>
<p>The effect of the generative model reflects the model's ability to use the content of long-term memory to generate the response. Therefore, we select the best generative model to utilize better the retrieved persona information to generate. The result is shown in Table 4. We use the 12L model to conduct experiments to compare different models. The experiment results show that PLATO-FT + role_embed + role_token is the best. Compared to PLATO-FT, the PPL can decrease to 13.377, showing that both strategies are effective. In order to further improve the model, we increased the model size and further trained with the 32L model. Experiment results have shown that the PPL of the 32L model is lower than the 12L model by 4.4 and F1 increased by 2.5 , which can further improve the generative model. Therefore, PLATO-FT 32L + role_embed + role_token model is adopted in our system.</p>
<h3>5.3.3 Human Evaluation</h3>
<p>Self-chat has been widely used in the evaluation of dialogue systems (Li et al., 2016b; Roller et al., 2021; Bao et al., 2020), where the model plays the roles of both parties in the dialogue. To better control variables, we use our proposed PLATOLTM as a user simulator in our experiments and ask all chatbots (including PLATO-LTM) to chat sepa-</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Model</th>
<th style="text-align: center;">PPL</th>
<th style="text-align: center;">BLUE-1/2</th>
<th style="text-align: center;">DISTINT-1/2</th>
<th style="text-align: center;">F1</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">PLATO-FT 12L</td>
<td style="text-align: center;">13.641</td>
<td style="text-align: center;">$0.190 / 0.081$</td>
<td style="text-align: center;">$0.061 / 0.277$</td>
<td style="text-align: center;">21.02</td>
</tr>
<tr>
<td style="text-align: left;">PLATO-FT 12L + role_embed</td>
<td style="text-align: center;">13.387</td>
<td style="text-align: center;">$0.180 / 0.080$</td>
<td style="text-align: center;">$0.062 / 0.274$</td>
<td style="text-align: center;">20.98</td>
</tr>
<tr>
<td style="text-align: left;">PLATO-FT 12L + role_token</td>
<td style="text-align: center;">13.553</td>
<td style="text-align: center;">$0.193 / 0.081$</td>
<td style="text-align: center;">$0.060 / 0.272$</td>
<td style="text-align: center;">21.28</td>
</tr>
<tr>
<td style="text-align: left;">PLATO-FT 12L + role_embed + role_token</td>
<td style="text-align: center;">$\mathbf{1 3 . 3 7 7}$</td>
<td style="text-align: center;">$\mathbf{0 . 1 9 4 / 0 . 0 8 1}$</td>
<td style="text-align: center;">$0.060 / 0.267$</td>
<td style="text-align: center;">$\mathbf{2 1 . 5 9}$</td>
</tr>
<tr>
<td style="text-align: left;">PLATO-FT 32L + role_embed + role_token</td>
<td style="text-align: center;">9.380</td>
<td style="text-align: center;">$0.194 / 0.087$</td>
<td style="text-align: center;">$0.068 / 0.296$</td>
<td style="text-align: center;">22.61</td>
</tr>
</tbody>
</table>
<p>Table 4: Comparison of automatic evaluation metric results among different generative models.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Model</th>
<th style="text-align: center;">Coherence</th>
<th style="text-align: center;">Consistency</th>
<th style="text-align: center;">Engagingness</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">PLATO-2</td>
<td style="text-align: center;">$\mathbf{1 . 7 0}$</td>
<td style="text-align: center;">0.13</td>
<td style="text-align: center;">1.46</td>
</tr>
<tr>
<td style="text-align: left;">PLATO-FT</td>
<td style="text-align: center;">1.59</td>
<td style="text-align: center;">0.40</td>
<td style="text-align: center;">1.40</td>
</tr>
<tr>
<td style="text-align: left;">PLATO-LTM</td>
<td style="text-align: center;">1.67</td>
<td style="text-align: center;">$\mathbf{0 . 8 7}$</td>
<td style="text-align: center;">$\mathbf{1 . 5 4}$</td>
</tr>
<tr>
<td style="text-align: left;">PLATO-LTM w/o PE</td>
<td style="text-align: center;">1.57</td>
<td style="text-align: center;">0.49</td>
<td style="text-align: center;">1.43</td>
</tr>
</tbody>
</table>
<p>Table 5: Comparison of human evaluation metric results on self-chat dialogues among our model and baselines. All the above generation models are 32L. The PLATO-FT is with role embedding and role token strategies.
rately with the user simulator. After that, the crowdsourcing workers evaluate only the responses generated by the chatbots other than the simulator. The details are as follows.</p>
<p>Each chatbot chats with the user simulator for 10 episodes, each containing 4 long sessions, and each session contains 16 rounds. As in Bao et al. (2020), we do not impose any restrictions on the chats except for specifying session openings. We pre-select some session openings from the DuLeMon test set, start the interactive conversation with these openings, and ask the two bots to perform chats given the context.</p>
<p>The results are shown in Table 5, from which we can get the following key results:
(1) The long-Term Memory mechanism can significantly improve dialogue consistency. As shown in Table 5, in terms of dialogue consistency, our two models, PLATO-LTM and PLATO-FT, can achieve scores of 0.87 and 0.40 , respectively, which is significantly better than the baseline model PLATO-2. Furthermore, when we compare the performance of PLATO-LTM with PLATO-FT, it can be seen that the use of Long-Term Memory and persona extractor can boost the performance of PLATO-FT with a relative improvement of $118 \%$. Moreover, the model of PLATO-LTM w/o PE can achieve a score of 0.49 , which is still better than the PLATO-FT model. It indicates that long-term memory without a persona extractor is still effective in improving persona consistency.
(2) With the long-term memory mechanism, the use of persona extractor can significantly improve persona consistency and dialogue engagingness. As shown in Table 5, in terms of dia-
logue consistency, the two models, PLATO-LTM (using PE) and PLATO-LTM w/o PE, can achieve scores of 0.87 and 0.49 respectively, indicating that the use of persona extractor can significantly improve dialogue consistency. In terms of dialogue engagingness, PLATO-LTM can obtain a score of 1.54, outperforming the baseline model PLATO-2. In addition, when we remove PE from PLATOLTM, its performance drops from 1.54 (the score of PLATO-LTM) to 1.43 (that of PLATO-LTM w/o PE), indicating that the use of persona extractor can improve the performance of PLATO-FT.
(3) Fine-tuning on the small-scale dataset will slightly hurt the performance of pre-trained dialogue models in dialogue coherence. In terms of dialogue coherence, the PLATO-FT model (finetuned on our dataset) achieve a score of 1.59 , which is lower than that of the baseline model PLATO (not finetuned on our dataset). The possible reason is that during the self-play procedure for system evaluation, their dialogs usually cover a wide range of topics, and then it is challenging to generate appropriate or coherent responses when given these open-domain topics in contexts. The finetuning procedure might hurt the capability of the pre-trained dialogue model in terms of response appropriateness or dialogue coherence, leading to the inferior performance of PLATO-LTM and its variants.</p>
<h2>6 Conclusion</h2>
<p>In this paper, We present a novel LeMon (Longterm Memory Conversation) task and then build the corresponding dataset DuLeMon, introducing longterm persona modelling into large-scale generative</p>
<p>dialogue models. We further propose a Long-Term Memory (LTM) as a plug-in component of state-of-the-art large-scale generative dialogue models. LTM consists of user memory and chatbot memory, where the user memory is for understanding and memorizing persona information mentioned by the user, and the chatbot memory attempts to keep its persona information to be continuously updated over time. Experiment results show that our system PLATO-LTM can make effective use of both parties' persona information from dialogue history to enhance dialogue consistency and engagingness when conducting a long-term conversation. In the future, we will further study the possibility of using reinforcement learning with human feedback signals to help long-term conversation.</p>
<h2>7 Ethical Considerations</h2>
<p>We are sure that DuLeMon has been collected in a manner that is consistent with the terms of use of any sources and the intellectual property and privacy rights of the original authors of the texts. Meanwhile, our project is approved by an IRB. Finally, we also provide details on the characteristics of DuLeMon and steps taken to ensure the potential problems with the quality of the dataset do not create additional risks.</p>
<h2>References</h2>
<p>Daniel Adiwardana, Minh-Thang Luong, David R. So, Jamie Hall, Noah Fiedel, Romal Thoppilan, Zi Yang, Apoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu, and Quoc V. Le. 2020. Towards a human-like opendomain chatbot. CoRR, abs/2001.09977.</p>
<p>Jeesoo Bang, Hyungjong Noh, Yonghee Kim, and Gary Geunbae Lee. 2015. Example-based chatoriented dialogue system with personalized longterm memory. In 2015 International Conference on Big Data and Smart Computing (BIGCOMP), pages 238-243.</p>
<p>Siqi Bao, Huang He, Fan Wang, Hua Wu, Haifeng Wang, Wenquan Wu, Zhen Guo, Zhibin Liu, and Xinchao Xu. 2020. PLATO-2: towards building an open-domain chatbot via curriculum learning. CoRR, abs/2006.16779.</p>
<p>Siqi Bao, Huang He, Fan Wang, Hua Wu, Haifeng Wang, Wenquan Wu, Zhihua Wu, Zhen Guo, Hua Lu, Xinxian Huang, Xin Tian, Xinchao Xu, Yingzhan Lin, and Zhengyu Niu. 2021. Plato-xl: Exploring the large-scale pre-training of dialogue generation.</p>
<p>Joana Campos, James Kennedy, and Jill F. Lehman. 2018. Challenges in exploiting conversational memory in human-agent interaction. In Proceedings of
the 17th International Conference on Autonomous Agents and MultiAgent Systems, AAMAS '18, page 1649-1657, Richland, SC. International Foundation for Autonomous Agents and Multiagent Systems.</p>
<p>Emily Dinan, Varvara Logacheva, Valentin Malykh, Alexander H. Miller, Kurt Shuster, Jack Urbanek, Douwe Kiela, Arthur Szlam, Iulian Serban, Ryan Lowe, Shrimai Prabhumoye, Alan W. Black, Alexander I. Rudnicky, Jason Williams, Joelle Pineau, Mikhail S. Burtsev, and Jason Weston. 2019. The second conversational intelligence challenge (convai2). CoRR, abs/1902.00098.</p>
<p>Miguel Elvir, Avelino J. Gonzalez, Christopher Walls, and Bryan Wilder. 2017. Remembering a conversation - a conversational memory architecture for embodied conversational agents. Journal of Intelligent Systems, 26(1):1-21.</p>
<p>Minlie Huang, Xiaoyan Zhu, and Jianfeng Gao. 2020. Challenges in building intelligent open-domain dialog systems. ACM Trans. Inf. Syst., 38(3).</p>
<p>Yonghee Kim, Jeesoo Bang, Junhwi Choi, Seonghan Ryu, Sangjun Koo, and Gary Geunbae Lee. 2014. Acquisition and use of long-term memory for personalized dialog systems. In Multimodal Analyses enabling Artificial Agents in Human-Machine Interaction - Second International Workshop, MA3HMI 2014, Held in Conjunction with INTERSPEECH 2014, Singapore, Singapore, September 14, 2014, Revised Selected Papers, volume 8757 of Lecture Notes in Computer Science, pages 78-87. Springer.</p>
<p>Yoon Kim. 2014. Convolutional neural networks for sentence classification. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014, October 25-29, 2014, Doha, Qatar, A meeting of SIGDAT, a Special Interest Group of the ACL, pages 1746-1751. ACL.</p>
<p>Diederik P. Kingma and Jimmy Ba. 2015. Adam: A method for stochastic optimization. In 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings.</p>
<p>Jiwei Li, Michel Galley, Chris Brockett, Georgios P. Spithourakis, Jianfeng Gao, and William B. Dolan. 2016a. A persona-based neural conversation model. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016, August 7-12, 2016, Berlin, Germany, Volume 1: Long Papers. The Association for Computer Linguistics.</p>
<p>Jiwei Li, Will Monroe, Alan Ritter, Michel Galley, Jianfeng Gao, and Dan Jurafsky. 2016b. Deep reinforcement learning for dialogue generation.</p>
<p>Mei Yii Lim. 2012. Memory Models for Intelligent Social Companions, pages 241-262. Springer Berlin Heidelberg, Berlin, Heidelberg.</p>
<p>Zhaojiang Lin, Zihan Liu, Genta Indra Winata, Samuel Cahyawijaya, Andrea Madotto, Yejin Bang, Etsuko Ishii, and Pascale Fung. 2020. Xpersona: Evaluating multilingual personalized chatbot. CoRR, abs/2003.07568.</p>
<p>Pierre-Emmanuel Mazaré, Samuel Humeau, Martin Raison, and Antoine Bordes. 2018. Training millions of personalized dialogue agents. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2775-2779, Brussels, Belgium. Association for Computational Linguistics.</p>
<p>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, July 6-12, 2002, Philadelphia, PA, USA, pages 311-318. ACL.</p>
<p>Qiao Qian, Minlie Huang, Haizhou Zhao, Jingfang Xu , and Xiaoyan Zhu. 2018. Assigning personality/profile to a chatting machine for coherent conversation generation. In Proceedings of the TwentySeventh International Joint Conference on Artificial Intelligence, IJCAI-18, pages 4279-4285. International Joint Conferences on Artificial Intelligence Organization.</p>
<p>Stephen Roller, Emily Dinan, Naman Goyal, Da Ju, Mary Williamson, Yinhan Liu, Jing Xu, Myle Ott, Eric Michael Smith, Y-Lan Boureau, and Jason Weston. 2021. Recipes for building an open-domain chatbot. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, EACL 2021, Online, April 19 - 23, 2021, pages 300-325. Association for Computational Linguistics.</p>
<p>Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Hao Tian, Hua Wu, and Haifeng Wang. 2019. Ernie 2.0: A continual pre-training framework for language understanding.</p>
<p>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc.</p>
<p>Jing Xu, Arthur Szlam, and Jason Weston. 2021. Beyond goldfish memory: Long-term open-domain conversation.</p>
<p>Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, and Jason Weston. 2018. Personalizing dialogue agents: I have a dog, do you have pets too? In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2204-2213, Melbourne, Australia. Association for Computational Linguistics.</p>
<p>Weinan Zhang, Ting Liu, Yifa Wang, and Qingfu Zhu. 2017. Neural personalized response generation as domain adaptation. CoRR, abs/1701.02073.</p>
<p>Tiancheng Zhao, Ran Zhao, and Maxine Eskénazi. 2017. Learning discourse-level diversity for neural dialog models using conditional variational autoencoders. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017, Vancouver, Canada, July 30 - August 4, Volume 1: Long Papers, pages 654-664. Association for Computational Linguistics.</p>
<p>Yinhe Zheng, Guanyi Chen, Minlie Huang, Song Liu, and Xuan Zhu. 2019. Personalized dialogue generation with diversified traits. CoRR, abs/1901.09672.</p>
<p>Peixiang Zhong, Chen Zhang, Hao Wang, Yong Liu, and Chunyan Miao. 2020. Towards persona-based empathetic conversational models. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 6556-6566, Online. Association for Computational Linguistics.</p>
<h2>A Details of Data Collection</h2>
<p>The collection processes of DuLeMon are as follows.</p>
<ul>
<li>The crowdworkers enter the chat interface in pairs, and role 1 initiates a conversation;</li>
<li>The chat content can include opening greetings, self-introduction, chatting content that conforms to the persona information, asking the other party's questions, answering the other's questions, and so on. The information used in the chat must be consistent with the given personal information;</li>
<li>The dialogue contains at least 8 turns (each person speaks at least 8 utterances);</li>
</ul>
<p>At the same time, we also let the crowdworkers pay attention to the follows: 1 . Use as many words as possible, and do not repeat them. The overall dialogue strives to be natural, smooth, and not embarrassing. 2. Do not simply copy and paste the sentences in the personal information and express them as richly as possible. If it is found that $50 \%$ of the fragments of any given sentence appear in the conversation, it is a non-compliant conversation. 3. When using persona information, do not copy it entirely, and talk about relevant content around the persona. For example, if the persona setting contains the sentence "I am a painter", the response can be that "I have painted many beautiful paintings and held several exhibitions"; 4. If the question raised by the other speaker is not covered in the given personal information, the reply can be freely used; if there is any reference or related information in the given personal information, reply according it.</p>
<h1>B Details of Models</h1>
<p>Generation Model For the Generation model, We follow PLATO-2 (Bao et al., 2020). The maximum length of context, user persona, and chatbot persona are set to 384,76 , and 52 , respectively. The vocabulary contains 30 K Chinese BPE tokens. We optimize all models using Adam (Kingma and Ba, 2015) with every batch of $B=16384$ tokens and learning rate of $l r=5 e-5$. We conduct all experiments on NVIDIA V100 32GB and A100 48GB GPUs.
Long-term Memory For both user memory and chatbot memory, we set duplication threshold $s_{\text {dup }}=0.95$, number of candidates $K=5$, and similarity threshold $s_{c}=0.7$. Due to the persona sparsity of dialogue and the efficiency of our persona storage, we do not limit the memory capacity.</p>
<h2>C Cases of PLATO-LTM</h2>
<p>To concretely demonstrate the long-term persona ability in a long-term conversation, we further provide a cherry-picked example of one episode conversation (between PLATO-LTM and PLATO-2) in Figure 4.</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: A cherry-picked example of one episode conversation between PLATO-LTM and PLATO-2.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{3}$ There are two stages within the PLATO-2 model, the first stage conduct candidate responses generation and the second stage conduct responses selection. We only implement our work on the first stage of PLATO-2.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>