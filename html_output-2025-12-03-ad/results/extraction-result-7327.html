<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7327 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7327</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7327</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-139.html">extraction-schema-139</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <p><strong>Paper ID:</strong> paper-276576134</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2502.17132v2.pdf" target="_blank">Applications of Large Models in Medicine</a></p>
                <p><strong>Paper Abstract:</strong> This paper explores the advancements and applications of large-scale models in the medical field, with a particular focus on Medical Large Models (MedLMs). These models, encompassing Large Language Models (LLMs), Vision Models, 3D Large Models, and Multimodal Models, are revolutionizing healthcare by enhancing disease prediction, diagnostic assistance, personalized treatment planning, and drug discovery. The integration of graph neural networks in medical knowledge graphs and drug discovery highlights the potential of Large Graph Models (LGMs) in understanding complex biomedical relationships. The study also emphasizes the transformative role of Vision-Language Models (VLMs) and 3D Large Models in medical image analysis, anatomical modeling, and prosthetic design. Despite the challenges, these technologies are setting new benchmarks in medical innovation, improving diagnostic accuracy, and paving the way for personalized healthcare solutions. This paper aims to provide a comprehensive overview of the current state and future directions of large models in medicine, underscoring their significance in advancing global health.</p>
                <p><strong>Cost:</strong> 0.006</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7327",
    "paper_id": "paper-276576134",
    "extraction_schema_id": "extraction-schema-139",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.0057125,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Applications of Large Models in Medicine
7 Oct 2025</p>
<p>Yunhe Su yunhe.su@outlook.com 
The First Clinical Medical School
MuDanJiang Medical University
HeilongjiangChina</p>
<p>Zhengyang Lu luzhengyang@jiangnan.edu.cn 
School of Design
Jiangnan University
WuxiChina</p>
<p>Junhui Liu 
Kunming, YunnanChina</p>
<p>Ke Pang pangke97@gmail.com 
Department of Anesthesiology
Third Xiangya Hospital</p>
<p>Central South University
Changsha, HunanChina</p>
<p>Haoran Dai 
Nanjing Medical University
NanjingChina</p>
<p>Sa Liu 
University of California
DavisCaliforniaUSA</p>
<p>Yuxin Jia 
Brown School
Washington University in St. Louis
LouisMissouriUSA</p>
<p>Lujia Ge 
School of Basic Medical Sciences
Capital Medical University
BeijingChina</p>
<p>Jing-Min Yang yangjingmin2021@163.com </p>
<p>WestChina Biomedical Big Data Center
WestChina Hospital
Sichuan University
ChengduChina</p>
<p>Applications of Large Models in Medicine
7 Oct 2025DE1701B2143360E01B9C27EF2FF201CDarXiv:2502.17132v2[cs.AI]Medical ModelsLarge Language ModelsVision ModelsMultimodal ModelsDrug Discovery
This paper explores the advancements and applications of large-scale models in the medical field, with a particular focus on Medical Large Models (MedLMs).These models, encompassing Large Language Models (LLMs), Vision Models, 3D Large Models, and Multimodal Models, are revolutionizing healthcare by enhancing disease prediction, diagnostic assistance, personalized treatment planning, and drug discovery.The integration of graph neural networks in medical knowledge graphs and drug discovery highlights the potential of Large Graph Models (LGMs) in understanding complex biomedical relationships.The study also emphasizes the transformative role of Vision-Language Models (VLMs) and 3D Large Models in medical image analysis, anatomical modeling, and prosthetic design.Despite the challenges, these technologies are setting new benchmarks in medical innovation, improving diagnostic accuracy, and paving the way for personalized healthcare solutions.This paper aims to provide a comprehensive overview of the current state and future directions of large models in medicine, underscoring their significance in advancing global health.</p>
<p>Introduction</p>
<p>Medical Large Models (MedLMs) refer to a class of largescale artificial intelligence models specifically trained to handle and analyze various types of medical-related data, such as clinical text [98], imaging data and genetic information.They are typically based on deep learning and neural network technologies, enabling them to perform a variety of tasks in the medical field, including disease prediction, diagnostic assistance, personalized treatment planning, and drug development.The core advantage of MedLMs lies in their powerful data processing capabilities and their ability to learn from vast amounts of data.</p>
<p>MedLMs can be categorized into distinct types, each serving different applications based on the data they handle.Large Language Models (LLMs) are designed primarily for processing clinical textual data (like MedPaLM), such as electronic health records (EHRs) such as [65,[141][142][143].These models excel at extracting pertinent information from a wide range of medical texts, including patient histories, symptoms, and treatment instructions.This capability reduces the manual workload for healthcare professionals and provides crucial decision-making support.Furthermore, LLMs are instrumental in generating clinical pathways, assisting in the creation of personalized treatment plans by analyzing a vast corpus of medical literature and integrating the latest clinical guidelines [126]   validations [17,91].</p>
<p>Another major category is Vision Models, which primarily deal with medical imaging data.These models, typically based on convolutional neural networks (CNNs), have proven effective in tasks such as detecting early-stage cancers through the analysis of medical images.For example, CNNs have been applied to detect skin cancer with dermatologist-level accuracy and are also used in the detec-tion of lung and breast cancers, providing physicians with fast and reliable diagnostic support.The ability to detect even minute abnormalities in images, with accuracy comparable to that of experienced specialists, has made vision models a powerful tool in modern medical practice [29].</p>
<p>3D Large Models, which focus on volumetric data analysis, represent another critical category within MedLMs.These models utilize 3D convolutional neural networks (CNNs) to handle medical images in three-dimensional formats, such as CT or MRI scans.By accurately segmenting tumors and analyzing their spatial characteristics, 3D models assist in determining tumor locations and volumes, essential for surgical planning.Additionally, these models contribute to virtual surgery simulations, allowing medical practitioners to plan surgeries more effectively and mitigate potential risks .The integration of 3D models into clinical practice is enhancing both the precision of tumor detection and the planning of surgical interventions [139].</p>
<p>In addition to these single-modal models, Multimodal Models integrate multiple types of data, such as clinical text, imaging, and genomic data, to provide a more comprehensive understanding of a patient's condition.By combining diverse data sources, these models enhance diagnostic accuracy and the ability to develop personalized treatment plans.For instance, multimodal models have been successfully used to improve the early diagnosis of lung cancer by combining CT images with clinical records, thus providing more accurate diagnostic insights .These models also play a crucial role in personalizing treatment plans for complex conditions, such as breast cancer, by integrating genomic data, imaging, and clinical histories [129].</p>
<p>Graph Large Models (Graph Neural Networks, GNNs) are another key type of MedLM, particularly in the field of genomics.GNNs are designed to analyze the relationships between genes, diseases, and therapeutic targets.By studying gene interaction networks, GNNs can predict disease risk factors and identify potential biomarkers, offering novel insights into early diagnosis and potential treatment options.Graph Large Models leveraging transformers with large parameters and trained with large biomedical datasets.These models have shown great promise in areas such as cancer risk prediction, where they analyze the complex interactions between genes and disease.</p>
<p>Medical large models (MedLMs) are bringing new possibilities to healthcare.They offer applications in disease prediction, diagnostics, treatment planning, and drug development.These models analyze extensive medical data and identify patterns that may indicate disease risks.For example, genetic interaction analysis can reveal potential cancer risks, supporting early preventive strategies [125].</p>
<p>MedLMs also contribute to improving diagnostic processes.By analyzing imaging data, they assist in identifying abnormalities that might be missed in manual reviews.Some models trained on dermatological imaging have been shown to classify skin conditions with a high degree of accuracy, providing clinicians with additional tools for decisionmaking.</p>
<p>In treatment planning, MedLMs combine imaging, genomic, and historical patient data.This combination sup-ports the development of personalized strategies for managing complex conditions.For diseases such as breast cancer, integrating these data sources has been associated with better-aligned treatment options for patients.</p>
<p>Drug discovery is another area where MedLMs show promise.They assist in predicting protein structures, which is a critical step in therapeutic development.Tools like Al-phaFold have been used to reduce the time and effort required for molecular design, helping researchers identify drug candidates more efficiently [55].</p>
<p>Medical large models (MedLMs) are experiencing widespread adoption across healthcare systems globally.</p>
<p>Their utilization is increasing rapidly, particularly in areas such as diagnostic assistance, disease prediction, personalized treatment planning, and drug discovery.These models have proven their value in enhancing the accuracy and efficiency of medical practices.Notably, many healthcare platforms have now integrated these models as standard tools, embedding them deeply into their operations.</p>
<p>For instance, Baidu's Lingyi Medical Model leverages MedLM technology to enhance diagnostic accuracy, supporting doctors in making more precise disease predictions and diagnoses.By analyzing vast datasets, the model assists healthcare professionals in better understanding complex conditions, leading to improved treatment outcomes.Additionally, MedGPT, developed by Yilian, is another example of a medical language model that facilitates the entire healthcare process, from intelligent consultation to diagnosis recommendations and personalized treatment plans.This model integrates seamlessly into clinical workflows, helping doctors save time and make informed decisions based on comprehensive data analysis.With these advancements, the high usage rate of MedLMs continues to rise, demonstrating their importance in modern healthcare settings.As the demand for precise and efficient healthcare grows, more medical institutions and research organizations are expected to adopt these models to support and enhance clinical decision-making, ultimately improving the quality of healthcare worldwide.</p>
<p>LLMs in Medical</p>
<p>The effectiveness of large language models (LLMs) in medical question answering hinges on their training methodologies and the quality of the datasets used [108].Leading research organizations, such as Google, have adopted advanced pretraining and fine-tuning methodologies to optimize the performance and efficacy of these models [1].For example, MedPaLM, built upon the general-purpose PaLM model, has been fine-tuned using high-quality, domainspecific medical datasets, enabling it to excel in understanding and reasoning about medical queries [109].To ensure the accuracy and comprehensiveness of these datasets, Google draws information from public medical databases (e.g., PubMed and MIMIC-III), professional guidelines, and detailed patient case records [94].These data sources are meticulously cleaned and reviewed by medical experts.Furthermore, multilingual processing capabilities are incorporated, enhancing the models' usability and robustness across diverse linguistic and cultural contexts [48].</p>
<p>LLMs have rapidly become transformative tools within the medical field, offering significant advancements in medical education [2].For students preparing for the United States Medical Licensing Examination (USMLE), LLMs serve as invaluable resources.They excel in solving intricate clinical reasoning problems, simulating exam scenarios, and providing in-depth explanations for incorrect answers, which significantly enhances students' exam preparation and understanding of key concepts [86].The success of LLMs in medical question-answering is largely attributed to the use of high-quality datasets.General-purpose datasets, such as PubMedQA and MIMIC-III, are essential for assessing clinical reasoning.While more specialized datasets like MedQA-USMLE, BioASQ, and MedMCQA address specific needs in the field1.For instance, MedQA-USMLE provides question-and-answer pairs that closely align with the structure and content of the USMLE [4], while BioASQ focuses on biomedical knowledge retrieval and response generation [60].By harnessing these diverse datasets, LLMs can generate precise, reliable, and contextually appropriate responses, solidifying their role as crucial tools in advancing medical education and practice.</p>
<p>AI large language models, such as GPT, are increasingly playing a pivotal role in the medical field, particularly in facilitating patient self-diagnosis and providing health management guidance [103].For example, Pahola offers reliable, alcohol-related information to a global audience, thereby contributing to the effective implementation of Screening and Brief Interventions (SBI) and enhancing alcohol health literacy [81].Similarly, research has demonstrated that many individuals utilize ChatGPT for self-diagnosis and to access health information.An example of this is ChatGPT's utility in aiding patients in identifying common orthopedic conditions, such as carpal tunnel syndrome (CTS), prior to seeking consultation with healthcare professionals [61].Moreover, AI-driven tools enable individuals to assess their mental health conveniently from the privacy of their homes [122].</p>
<p>To assess the performance of LLMs in medical questionanswering tasks, researchers employ diverse and rigorous evaluation metrics.Standard metrics like accuracy, precision, recall, and F1 scores are used to measure the correctness and comprehensiveness of model responses [3].For tasks requiring generated answers, BLEU scores evaluate the linguistic alignment between model outputs and reference answers [21].Moreover, domain-specific metrics, such as medical relevance and clinical applicability scores, are employed to gauge the professional and practical utility of the responses [8].Ethical and safety assessments are equally critical, utilizing measures such as harmful content detection rates and fairness evaluations to ensure the models' reliability and equity in medical applications [33].These comprehensive evaluation frameworks support the continuous improvement and refinement of LLMs.Notably, existing LLMs may produce incorrect content or known as "hallucinations".More details will be discussed in later sections.</p>
<p>Large Vision Models in Medical</p>
<p>Visual Anomaly Detection in Medical Images</p>
<p>Medical image anomaly detection represents a critical component in computer-aided diagnosis systems, serving as an essential tool for early disease detection and treatment planning.Despite significant advances in deep learning, the inherent complexity of medical anomalies, coupled with the scarcity of annotated pathological data, continues to pose substantial challenges.As highlighted by the comprehensive BMAD benchmark [14], which spans across five distinct medical domains, the field requires robust and generalizable approaches that can perform effectively across different modalities and anatomical structures.Recent developments in foundation models and generative approaches have introduced promising paradigms for addressing these challenges, revolutionizing how we approach medical anomaly detection.</p>
<p>Vision-Language Models for Zero-shot Medical Anomaly Detection</p>
<p>The emergence of vision-language foundation models has marked a significant breakthrough in medical anomaly detection, particularly in zero-shot scenarios.These models, pre-trained on vast corpora of image-text pairs, offer a promising solution to the perennial challenge of limited labeled medical data.Zhou et al. [140] introduced Anomaly-CLIP, a pioneering approach that adapts CLIP (Contrastive Language-Image Pretraining) for zero-shot anomaly detection through object-agnostic prompt learning.The development of domain-specific models, exemplified by BiomedCLIP [133], represents another significant advancement.Trained on an unprecedented 15 million biomedical image-text pairs, BiomedCLIP exhibits remarkable zero-shot capabilities across various medical imaging tasks, outperforming even specialized models in their respective domains.Park et al. [92] further refined these approaches by introducing Contrastive Language Prompting (CLAP), specifically addressing the challenge of false positives in medical anomaly detection through careful prompt engineering.</p>
<p>Diffusion Models for Unsupervised Detection</p>
<p>Diffusion models have emerged as a powerful framework for unsupervised anomaly detection in medical imaging, offering unique advantages in modeling complex data distributions and generating high-quality counterfactuals.The pioneering work of Wolleb et al. [123] combined denoising diffusion implicit models with classifier guidance, demonstrating superior performance in preserving fine anatomical details compared to traditional GAN-based methods.</p>
<p>A significant advancement in this domain came from Fontanella et al. [36], who introduced a novel approach for generating healthy counterfactuals of diseased images.Their method uniquely combines DDPM (Denoising Diffusion Probabilistic Models) and DDIM (Denoising Diffusion Implicit Models) at each sampling step, using DDPM to modify lesion areas while employing DDIM to preserve normal anatomy.This careful balance between modification</p>
<p>Strategy Medical Applications Evaluation Metrics Key Findings</p>
<p>Vision-Language Models (Zeroshot)</p>
<p>• Brain tumor detection (MRI) [140] • Chest abnormality detection (X-ray) [133] • Retinal disease screening [46] • AUROC [92] • Dice coefficient [9] • Sensitivity/Specificity [58] • Zero-shot transfer accuracy [133] • Performance varies significantly across modalities [46] • Superior in anatomical structure detection but struggles with subtle pathological changes [92] Diffusion Models • Lesion detection in brain MRI [123] • Lung nodule detection in CT [36] • Histopathological analysis [15] • FID score [123] • SSIM [15] • Image reconstruction error [49] • Lesion detection rate [32] • Excels in generating realistic counterfactuals [36] • Computational overhead remains a challenge [124] Self-supervised Learning • Multi-organ anomaly detection [115] • Dermatological lesion analysis [49] • Dental radiography [124] • Contrastive loss [115] • Reconstruction quality [49] • Feature clustering metrics [124] • Anomaly detection accuracy [115] • Effective with limited labeled data [49] • Robust to domain shift but requires careful architecture design [124] Semisupervised Learning</p>
<p>• Pathological tissue classification [135] • Cardiac MRI analysis [19] • Bone abnormality detection [88] • Classification accuracy [135] • Segmentation IoU [19] • Cohen's Kappa [88] • Expert consensus correlation [11] • Balanced performance between supervised and unsupervised approaches [135]; • Effective in clinical settings with partial annotations [19] and preservation has proven crucial for accurate anomaly detection.</p>
<p>The development of masked diffusion models represents another major innovation.Iqbal et al. [49] introduced mD-DPM, incorporating both Masked Image Modeling (MIM) and Masked Frequency Modeling (MFM) to enhance the model's ability to learn anatomically consistent representations.Liang et al. [69] extended this concept with their MMCCD framework, introducing cyclic modality translation as a mechanism for anomaly detection in multimodal MRI.</p>
<p>Recent work by Behrendt et al. [15] has focused on addressing the limitations of traditional anomaly scoring functions.Their approach introduces an adaptive ensembling strategy using Structural Similarity (SSIM) metrics, offering a more pathology-agnostic scoring mechanism that captures both intensity and structural disparities.Fan et al. [32] further advanced this field with their discrepancy dis-tribution medical diffusion (DDMD) model, which innovatively translates annotation inconsistencies into distribution discrepancies while preserving information within homogeneous samples.</p>
<p>Self-supervised Learning for Anomaly Detection</p>
<p>Self-supervised learning has emerged as a powerful paradigm for leveraging unlabeled medical data effectively.Tian et al. [115] introduced PMSACL, a groundbreaking self-supervised pre-training method that contrasts normal image classes against multiple pseudo classes of synthesized abnormal images.This approach addresses the critical challenge of learning effective low-dimensional representations capable of detecting unseen abnormal lesions of varying sizes and appearances.By enforcing dense clustering in the feature space, PMSACL significantly improves the sensitivity of anomaly detection across diverse medical imaging modalities.</p>
<p>Building on the success of masked modeling techniques, Iqbal et al. [49] developed a novel self-supervised framework incorporating both spatial and frequency domain masking strategies.Their approach enables the model to learn more robust and anatomically-aware representations without requiring explicit annotations.This innovation has proven particularly effective in detecting subtle anatomical variations that might indicate pathological conditions.</p>
<p>The advancement of self-supervised learning has also led to improved understanding of normal anatomical variations, crucial for accurate anomaly detection.Wu et al. [124] demonstrated how transformer-based architectures can be effectively combined with self-supervised learning objectives to capture long-range dependencies and structural relationships in medical images, leading to more reliable anomaly detection systems.</p>
<p>Semi-supervised Learning Approaches</p>
<p>Semi-supervised learning approaches have shown remarkable promise in leveraging both labeled and unlabeled data effectively for medical anomaly detection.Zhang et al. [135] developed SAGAN, a sophisticated framework incorporating position encoding and attention mechanisms to accurately focus on abnormal regions while preserving normal structures.Their approach innovatively relaxes the cyclic consistency requirements typical in unpaired image-to-image translation, achieving superior performance in generating high-quality healthy images from unlabeled data.</p>
<p>Cai et al. [19] proposed a groundbreaking dual-distribution discrepancy framework that effectively leverages unlabeled images containing anomalies.Their approach introduces normative distribution and unknown distribution modules, with intra-discrepancy and inter-discrepancy measures serving as refined anomaly scores.This method has demonstrated significant improvements across various medical imaging modalities, including chest X-rays, brain MRIs, and retinal fundus images.</p>
<p>The integration of semi-supervised learning with traditional generative models has also shown promising results.Özbey et al. [88] demonstrated how adversarial diffusion models could be effectively combined with semi-supervised learning strategies to improve image translation and anomaly detection performance.Their SynDiff framework showcases the potential of leveraging partially labeled datasets to enhance the fidelity and accuracy of generated medical images.</p>
<p>Challenges and Future Directions</p>
<p>Despite these advances, several critical challenges remain in medical anomaly detection.First, the balance between model complexity and clinical practicality continues to be a significant concern.While diffusion models offer supe-rior performance, their computational requirements can be prohibitive in clinical settings, as noted by Wu et al. [124].</p>
<p>Second, the integration of multiple expert annotations remains challenging, though recent work by Amit et al. [11] on consensus prediction offers promising directions.</p>
<p>Looking forward, the field appears to be moving toward more efficient and interpretable approaches.The success of frequency-guided methods [66] and structure-aware adaptations suggests that future developments may focus on incorporating domain-specific medical knowledge into foundation models.Additionally, the growing interest in selfsupervised and semi-supervised approaches indicates a shift toward methods that can better utilize the vast amounts of unlabeled medical data available while maintaining the high standards of accuracy required in clinical applications.</p>
<p>3.2.Applications in Pathological Images.</p>
<p>Image Segmentation with U-Net</p>
<p>In pathological image analysis, the main approaches include pathological image segmentation, anomaly detection, and image generation [10,37].The goal of pathological image segmentation is to divide different tissue or lesion regions within an image.Generally, it is the foundation of tasks including cancer tissue detection, lesion structure analysis, cell counting and so on.The U-Net consists of two main components: the encoder path and the decoder path [25].The encoder extracts features by transforming raw pathological images into lowresolution, high-semantic feature representations using convolutional and pooling operations, and it also introduces non-linearity through functions such as ReLU [68].The decoder restores image resolution by upsampling the encoded features to match the size of the input images, finally producing the segmentation output [23,89].The decoder path involves two key processes: deconvolution, which upsamples feature maps to restore resolution, and skip connections, which combine features from corresponding layers in the encoder and decoder keep spatial information lost in encoder.Meanwhile, convolutional operations integrate low-level details with high-level semantics to refine the segmentation results [127].In addition, there are several improved models based on U-Net, such as the Attention U-Net, which was proposed by Oktay et al. in 2018[87].This model introduces attention modules to enhance the model's focus on critical regions.Attention modules are integrated into each skip connection to dynamically adjust the fea-tures transferred from the encoder to the decoder.These modules calculate attention weights for the input features and amplify features of important regions while suppressing features of irrelevant areas.Based on the classic encoderdecoder structure of U-Net, the attention modules are embedded at key nodes along the decoding path and improve the model's focus on significant regions while maintaining overall segmentation accuracy.Image segmentation can be used in various pathological imaging tasks, like cell and nuclear segmentation.For example, when diagnosing corneal endothelial health states, U-Net-based CNN have achieved high accuracy in segmenting endothelial cells across images of varying cell sizes, and achieve precise measurement of cellular morphological parameters (AUROC 0.92, DICE 0.86) [31].</p>
<p>Moreover, because cell segmentation is the first step in quantitative tissue imaging data analysis and the basis for single-cell analysis, it is important in identifying malignant tumors.The abnormal enlargement of nuclei in cancer cells leads to a significantly increased nucleus-to-cytoplasm ratio, which is one of the criteria for diagnosing malignant tumors [106].Therefore, image segmentation can also be applied to the dividing of malignant regions in pathological images.For example, in squamous cell carcinoma (SCC), researchers utilized a patch dataset extracted from 200 digitized tissue images of 84 patients to train a U-Net-based segmentation model.The model achieved a segmentation AUC of 0.89 on the test set, and the average segmentation time is 72 seconds per image, which shows higher efficiency compared to traditional manual segmentation methods [77].</p>
<p>Image Generation with GANs</p>
<p>Pathological image generation uses artificial intelligence (AI) to produce high-quality synthetic pathology images and solves challenges such as limited datasets and annotation difficulties by enlarging and balancing datasets.Therefore, it is generally used for upstream tasks [34].Generative adversarial networks (GANs), introduced by Ian Goodfellow et al. in 2014 [40], are the primary methods for image generation.GANs consists of two neural network, including Generator and Discriminator, and train adversarially to produce realistic data , and it shows outstanding performance in the image generation [137].The method optimizes the generator and discriminator alternately.The generator samples from the real dataset, and inputs the sampled noise into the generator, and produces synthetic samples that resemble real data; the discriminator takes both real and synthetic data as input and judges whether each sample comes from the real dataset or is generated by the generator.The discriminator is updated to improve its ability to distinguish between real and synthetic data, while the generator is updated to enhance its ability to generate synthetic data [35].Through multiple iterations, the gen-erator produces samples that are realistic enough to make it difficult for the discriminator to distinguish between real and synthetic data and then complete the task of generating pathological images.Moreover, StyleGAN, a GANbased model, can also be used for generating pathological images [56].In traditional GANs, random noise with a Gaussian or uniform distribution is directly inputted into the generator to produce images.In contrast, StyleGAN introduces a style-mapping network, which maps noise Z to a new latent space W. The W is more expressive and easier to use for controlling specific features in the generated images, which helps adjust things like color, texture, or shape, making the images more realistic and diverse.Additionally, independent random noise is injected at each layer to generate random details in the images [78].Style-GAN also uses progressive growth [102], where the generator and discriminator initially handle low-resolution images during early training.The model gradually increases the resolution as training progresses until it achieves the target high resolution.To further improve the resolution of generated images, a multi-scale conditional GAN method has been proposed.This model used a pyramid-like structure to progressively increase the resolution while generating highresolution images and maintaining global consistency and detailed features of glandular structures.Through adversarial training, the generator captures the global layout of glands and the micro-textures of cell nuclei.Multi-layer discriminators ensure the authenticity and consistency of the generated image [64].In renal pathology image analysis, the morphological characteristics of glomeruli provide critical diagnostic and prognostic information.To improve diagnostic efficiency, an automated method based on CNNs was proposed.This method used GAN-based generative data augmentation to generate glomeruli pathological images with various morphologies and improve data diversity and model performance.The results showed that after applying generative data augmentation, the sensitivity of the classification model increased from 0.7077 to 0.7623, and specificity improved from 0.9316 to 0.9443 [54].</p>
<p>Anomaly Detection in Pathological Images</p>
<p>In addition to the pathological image segmentation and image generation above, there is also a downstream task, which is anomaly detection of pathological images.This involves using extracted image features to identify and localize abnormal images.In anomaly detection, there are generally two types of methods, which are supervised anomaly detection and unsupervised anomaly detection [117].</p>
<p>Supervised anomaly detection requires a dataset of annotated images including both normal and abnormal images.This kind of classification tasks could be performed using CNN-based model [144].CNN models extract features through convolutional layers, reduce the resolution of fea-ture maps using pooling layers, and map the extracted highdimensional features to classification outputs using fully connected layers.The final classification probabilities for normal or abnormal states are generated using Softmax or Sigmoid functions in the output layer [96].</p>
<p>For example, studies have shown that research based on deep CNNs shows significant advantages in classifying skin lesions.Using a dataset containing about 130000 images and covering almost 2000 diseases, CNNs achieved great performance comparable in two binary classification tasks.Besides, the CNN achieved an accuracy of 72.1% in a threeclass disease partitioning task and 55.4% in a nine-class disease partitioning task [30].</p>
<p>In unsupervised or self-supervised anomaly detection, the primary methods include contrastive learning [114] and generative models [44,144].Contrastive learning involves extracting high-level feature representations from normal samples to construct a feature space.Abnormal samples, due to their different feature distributions, deviate from the feature space of normal samples.If the deviation is sufficiently large, they are identified as anomalies.Generative models are similar to GANs.They use an encoder to extract high-dimensional feature representations from input data, capturing complex patterns and learning features.Subsequently, a decoder reconstructs the input data from these high-dimensional features to recreate the original image.For normal samples, as they conform to the feature distribution learned by the model, the reconstruction error is low.However, for abnormal samples, the reconstruction error is high, leading to their identification as anomalies.</p>
<p>Hui Liu et al. proposed a deep learning framework based on weakly supervised contrastive learning.This framework uses self-supervised pretraining on large-scale unlabeled patches from whole slide images (WSI) to extract highly informative pathological features.Combined with multitask learning, the framework successfully inferred breast cancer-related gene expression, molecular subtypes, and clinical outcomes.Experiments showed that this method achieved outstanding performance across multiple datasets, and the generated spatial heatmaps were highly consistent with pathologists' annotations and spatial transcriptomics data.This highlights its potential in linking genotypes with phenotypes and in the clinical applications of digital pathology [72].</p>
<p>Besides, in related research, a generative model combining GANs and autoencoders was employed for anomaly detection.By training the model on normal tissue data, regularization and multi-scale contextual data were used to improve generalizability.This approach achieved efficient anomaly detection on the toxicologic histopathology (TOX-PATH) dataset, with an AUC of 0.953 [131].</p>
<p>In general, pathological slide images can be used in different upstream and downstream tasks, such as classification and segmentation tasks.These include using image segmentation for cell counting [105],applying image generation in upstream tasks to perform pathological data augmentation [100],using image segmentation and anomaly detection for cancer diagnosis or the identification of other lesion regions [28,41],and conducting tasks such as tumor grading and progression prediction [50].</p>
<p>In addition to the neural network models mentioned above, the increasing computational capacity has led to the emergence of large models.These large models show powerful feature learning abilities through pretraining on largescale datasets.In recent years, the concept of foundation models [82] has emerged.</p>
<p>These models not only have larger parameter sizes, with commonly used architectures in the field of pathology image analysis including Vision Transformers, CLIP, and Mask2Former ranging from hundreds of millions to billions of parameters, but also use high-resolution pathology images for pretraining on large-scale datasets.</p>
<p>Generally, the architectures of these foundation models are based on Transformer [42].Initially it was developed for natural language processing, now it has been extended to the visual field.[119].Richard J. Che's team proposed the general-purpose self-supervised pathology model UNI.It was pretrained on over 100,000 diagnostic H&amp;E-stained WSIs and showed exceptional performance in 34 computational pathology tasks, including cancer subtype generalization [22].</p>
<p>Recently, multimodal foundation models have gained attention in pathology image analysis.By integrating visual and textual information, these models simultaneously capture the structural features of pathological images and the semantic information of clinical text.</p>
<p>CONCH is a foundational visual-language model that uses an image encoder, text encoder, and multimodal decoder.Through contrastive learning, it embeds images and text into a shared representation space while optimizing multimodal understanding through a captioning objective.During pretraining, CONCH leverages diverse pathology image-text pairs for unsupervised learning, significantly enhancing feature extraction capabilities.In cancer subtype classification, CONCH achieved 91.3% zero-shot accuracy [75].</p>
<p>The commonly used evaluation metrics in pathological image tasks are as follows:</p>
<p>Applications of Large Multimodal Model in Medical</p>
<p>Vision language models (VLMs) are multimodal generative AI models capable of reasoning over text, image, and video prompts.VLM has demonstrated excellent processing capabilities in image &amp; video generation, text-centric visual question answering, zero-shot detection, video summarization, and other fields, and some of the results have been successfully applied to autonomous driving, AI-generated image &amp; text generation, AR/VR techniques and other fields [16].In the past, machine learning-based graphics processing technology has been widely used for the diagnostics of radiology and medical education [59,101].As a new generation of image processing model, VLM has attracted the attention of medical workers with its potential, and its application as the superior substitution of traditional image processing models in the medical field is becoming another hot research direction.</p>
<p>In computer graphics, 3D modeling refers to the process of developing mathematical coordinate-based representations of the surface of objects (inanimate or biological) in three dimensions by manipulating edges, vertices and polygons in simulated 3D space through specialized software.3D modeling has been widely used in architecture and industrial design, video games, film industry, art and other fields, but traditional 3D modeling technique has a strong dependence on human resources and time cost.As a result, the cost and quality of the final product could be difficult to control.The recent emergence of 3D large models is bringing new changes to this field [38].Three-dimensional modeling was applied to multiple types of tasks in medicine (such as prosthetic and implant design, image reconstruction, anatomical modeling, medical education, etc.), and 3D large models may bring a technical revolution to these applications.</p>
<p>VLM for Medical Image Analysis</p>
<p>The models and algorithms based on traditional machine learning models (such as CNN) that have been widely used in the research of medical imaging [51].VLM as a technique that has shown great capabilities in processing complex relationships and multimodal information [16], is naturally adapted to the complexity of information contained in medical cases (text, charts, pictures, videos, audio, etc.); therefore, VLM is gradually attracting the attention of medical workers.</p>
<p>The application of VLM large models in medicine at present is mainly focused on the processing of medical images, especially for pathological and radiological imaging, for which have a much greater demand for softwires with efficient graphic processing capabilities than other subspecialties.There are already some studies involving VLM large</p>
<p>Task Type Evaluation Method Description</p>
<p>Image Segmentation [52] Dice Coefficient</p>
<p>Measures the overlap between the predicted segmentation and the ground truth, ranging from [0, 1], with higher values indicating better performance.</p>
<p>IoU (Intersection over Union)</p>
<p>Measures the ratio of the intersection area to the union area between the predicted and ground truth segmentation regions, ranging from [0, 1].</p>
<p>Image Generation [20,80,90] FID (Fréchet Inception Distance)</p>
<p>Assesses the difference in feature distributions between generated and real images; lower values indicate better performance.</p>
<p>IS (Inception Score)</p>
<p>Evaluates the diversity and quality of generated images based on a classification model; higher values indicate better performance.</p>
<p>Evaluation Methods in Downstream Tasks</p>
<p>The evaluation of image generation considers not only image quality (e. g., FID, IS) but also its impact on downstream tasks like classification and segmentation, using metrics such as accuracy or sensitivity to validate effectiveness.</p>
<p>Anomaly detection</p>
<p>Accuracy</p>
<p>Proportion of correctly classified samples, reflecting overall classification performance.</p>
<p>Sensitivity/Recall</p>
<p>Ability to detect anomalous samples (recall); higher values indicate better performance.</p>
<p>Specificity</p>
<p>Ability to correctly detect normal samples; higher values indicate better performance.</p>
<p>F1 Score Harmonic mean of precision and recall, providing a balanced performance metric, ranging from [0, 1].</p>
<p>ROC</p>
<p>Plots the curve of sensitivity against the false positive rate; performance is measured by AUC, with values closer to 1 indicating better performance.models for radiology and pathology, and this topic is discussed in details at other articles of our journal.</p>
<p>VLM for Medical Single Analysis</p>
<p>VLM models are also applied to the analysis of physiological signals.Just like traditional machine learning models, researches about the availability of VLMs for ECG, EEG analysis are also being conducted [83,95,118].</p>
<p>Due to the high correlation between VLM and computer vision, VLM is currently also used in the field of AI-based robotics.Currently, some EEG and sEMG combined technologies have been experimentally applied to the collection of limb movement data and the optimization of prosthetic movement patterns [24,73,121].Meta has already released two large datasets and benchmarks for sEMG-based typing and pose estimation in Dec. 2024 [6].</p>
<p>3D Large Models for Biometric Analysis</p>
<p>3D modeling technology has been widely used in the medical field, especially in human anatomical modeling, prosthetic design and 2D to 3D image conversion &amp; construction [76,107,112].With the advent of 3D large models, this technology has gradually been applied to the research in corresponding medical fields.</p>
<p>Another area of 3D modeling-3D human structure construction, has also been influenced by 3D large model with the production of some new research progresses.3D model construction has been applied for educational use to better demonstrate body structures.In addition, 3D printing is widely used in orthopedics, surgery, instrument design, drug research and many others in recent years.</p>
<p>Discussion and Outlook</p>
<p>Diagnostic techniques in neurology, psychiatry based on machine learning algorithms have been one of the hot areas in AI related medical research in the past few years.Motion capture in combination with deep learning is also applied to the research of clinical measurements for physical medicine and rehabilitation [74,116].There are some studies proved to be useful on the screening &amp; diagnosis of stroke, Parkinson's disease as well as some mental disorders based on facial expression analysis [63,70,71].VLM, as a new generation of graphic image model, also have strong prospects in these directions.At present, some results of emotion analysis research related to facial expression capture based on VLM have been published [5, 130,138].As algorithms develop and mature in the future, we can foresee that VLM will become more and more important in screening and remote diagnosis.The audio and video generation function based on VLM and 3D large models can also more vividly show the required content to medical workers and patients, so as to be applied for demonstration, diagnosis explanation, education and popularization.Medical knowledge based on 3D models has also been proven to have more advantages than traditional forms [12,18].3D large models can optimize traditional technology-based 3D anatomical structure construction and apply it to medical education and popularization.Traditional 3D model teaching software, such as visual body, has a certain distance from the requirements of actual teaching tasks in terms of the richness and accuracy of details.Many teaching scenes or structures that need to be understood in clinical applications are often not recorded or lack proper accuracy in these softwires.3D large models can not only provide better contents, but also customize them based on user needs (such as text image conversion, model scaling, highlighting, separation, etc.) [38].In addition, 3D large models can also be applied to 3D printing to produce realistic human anatomy models [13], which may better serve the purpose of demonstration.</p>
<p>In the past few decades, the development of prosthetics related to machine vision has always attracted many experts.The relevant mechanical design has long been mature.However, due to algorithm, materials along with other technical obstacles, traditional prosthetic designs always have limitations in final functions and user experience.The recent introduction of multimodal LLM and neuro-physical interface-related technologies has brought changes to this field.Auxiliary algorithms based on VLM and 3D large models, machine vision and image analysis technologies may become the key puzzle to solve the problem.Now with the help of AI techniques, there's finally a chance of modern prosthetics to achieve a difference from hooks and sticks.The researchers at Massachusetts Institute of Technology recently published a study on intelligent prosthetic design based on mechanism of antagonistic muscle groups [110].It can be seen that 3D large model technology can provide considerable assistance to the design of implants and the surgical implantation based on the construction and analysis of anatomical structures.</p>
<p>Machine vision and image analysis based on VLM and 3D large models can also be applied to the research of personalized intelligent vehicles, thereby providing a better experience for paralyzed patients or those who rely on wheelchairs.Take Simultaneous Localization and Mapping/SLAM as an example, it is a technique with remarkable capabilities on construct surrounding environments.</p>
<p>SLAM system can provide reference information for the action strategies, which makes it a key component in medical robotic design.As SLAM has its own limitations on map semantically similar objects in compact environments [7], VLM's capabilities on image analysis make it a choice with great potential to guide the actions of robotics in SLAM constructed models, which can further be applied for aforementioned fields.</p>
<p>In the future, 3D large models would be trained with a larger amount of data, which may facilitate to establish a unified database in the corresponding field, and construct subject models with a certain degree of universality, thereby saving the resources and time cost for personalized adjustment of modeling.3D modeling has already been used to aid procedures in endoscopy and some surgeries, it is also applied to aid the production of implants [79,97].The introduction of 3D large models may lower the overall cost of prosthetics &amp; implants customization for general surgery, orthopedics, plastic surgery, dentistry and other disciplines, and further guide the progress in these fields.</p>
<p>Micro-robots and soft robots have always been one of the hot areas of translational medicine.Research results in the field of soft robotics are gradually making such technologies practical.In these researches, 3D large models can provide basic support for anatomical structure reconstruction and dynamical simulation of such designs.</p>
<p>Limitations</p>
<p>Medical imaging will not be affected by image editing or false information like other contents, but the accuracy of trained models based on the complexity of the disease is an important issue.Take neurology as an example.In brain CT and MRI of difficult cases, the tiny lesions inside the brain often can only be visualized under the scale of millimeter level with strong interferences, and are also greatly affected by the equipment, shooting angle, patient compliance along with many other issues.For example, in general neurological imaging, a trained radiologist sometimes cannot correctly find the lesion, so the participation of superior specialists from neuroimaging is often required.This</p>
<p>VLMs</p>
<p>Medical Image Segmentation Dice score [67] mIoU metric [67] Medical report generation Bilingual Evaluation Understudy/ BLEU [43] Recall-Oriented Understudy for Gisting Evaluation/ROUGE [43] Metric for Evaluation of Translation with Explicit ORrdering/ METEOR [43] Perplexity [43] BERTScore [43] RadGraph F1 [43] Human evaluation [43] Clinical efficacy metrics Accuracy [43] Precision [43] Recall [43] F1 [43] Question answering Accuracy [43] Exact match [43] Human evaluation [43] 3D large models 3D Medical Image Analysis Dice score [113] Hausdorff Distance 95%/HD95 [113] Medical Image Segmentation &amp; generation Dice score [62] High-quality Medical Image Generation</p>
<p>Frechet Inception Distance/FID [120] Maximum Mean Discrepancy [120] Peak Signal-to-Noise Ratio/PSNR [120] Structural Similarity Index/SSIM [120] usually involves a complete review and detailed analysis of the patient's medical history, and the accumulation of this part of knowledge and experience cannot be completely replaced by the current model in a short time.Although data training of large models will gradually make progress, before achieving more ideal results, the application of such research in clinical practice will inevitably be limited by the concerns of patient safety issues.In contrast, for popular science and patient education, the requirements for accuracy of image analysis and model construction are relatively loose compared to clinical applications and professional teaching, and may usher in mature transformation one step earlier.</p>
<p>Neuro-physical interface is indeed a hot field at present, its combination with VLM and 3D large models is also very attractive.However, key technical issues related to BCI/NPI still exist [93].Limited by the development of materials science and computer science, even if the relevant tech-nical conditions are complete, the patient's rejection reaction, the accuracy of signal measurement, the propagation delay transduction, the accuracy of motion conversion, the patient's tolerance of invasive &amp; non-invasive devices (appearance, size, weight, etc.) are all important issues related to the transformation of results.</p>
<p>Large Graph Models in Medical</p>
<p>Introduction of Large Graph Models</p>
<p>Large Graph Models (LGMs) are characterized by having a vast number of parameters, which endows it with significantly greater capabilities compared to smaller models [134].This enhanced capacity facilitates the understanding, analysis, and processing of tasks related to graph data.</p>
<p>LGMs, particularly Graph neural networks (GNNs) and Graph transformer architectures, have emerged as powerful tools for processing and analyzing structured data, especially for complex and large-scale datasets.Their abil-ity to capture complex relationships between entities makes them especially suitable for various applications in the medical field, where understanding such interactions is often crucial.</p>
<p>LGMs utilizing transformer architecture and can be scaling up like LLMs.So they may requiring substantial computational overheads.</p>
<p>Healthcare primarily focus on management for patient care and administrative purposes rather than for data-driven research.Electronic health records (EHRs) typically consist of a mix of structured, semi-structured, and unstructured data, encompassing structured tables, images, waveforms, and clinical notes.These datasets capture a wide array of complex and interrelated concepts, leading to data that is inherently high-dimensional and heterogeneous [26] with suboptimal data quality due to the rapid pace of the clinical environment and the absence of manual curation.</p>
<p>Graphs offer a structured approach to explicitly model relational structures within data representations.Besides, graphs strike a balance between flexibility and structure when representing data, which allows for the seamless integration of multiple data modalities and the ability to exploit interdependencies across these modalities.This capability facilitates the mathematical incorporation of domainspecific prior knowledge to inform and enhance patient representations [84].Graph AI streamlines the transfer of</p>
<p>LGMs across various clinical tasks, allowing them to effectively apply to different patient populations with minimal or no additional parameters or retraining [53].</p>
<p>GNNs are a type of neural network model specifically designed for graph-structured data.They can learn representations for nodes, edges, and entire graphs.The field of graph representation learning has developed a variety of network architectures, each tailored to capture distinct types of complex relationships within graph-structured data.</p>
<p>For tasks involving predictions at the node, edge, or graph level, message-passing and transformer-based architectures are among the most prevalent [134].</p>
<p>There are numerous applications for Large Graph Models in biomedical field, including Brain Network Analysis, Medical Knowledge Graphs, Drug Discovery Analysis, and Protein-Protein Interaction Networks.preamble:</p>
<p>Brain Network Analysis</p>
<p>Within the realm of neuroscience, GNNs are instrumental in analyzing complex datasets like brain connectomes.By modeling the brain as a network of interconnected regions, GNNs can identify patterns associated with neurological disorders.</p>
<p>Graph-based approaches have offered valuable insights into brain functions by analyzing the connectome as a network, calculating functional connectivity (FC) between brain regions using functional neuroimaging.There are challenges remain in capturing the dynamic nature of FC networks, which fluctuate over time.Addressing these limitations, researchers built STAGIN [57], a method that incorporates spatio-temporal attention to learn the dynamic graph representation of brain connectomes, integrating temporal sequences of brain graphs with READOUT functions and a Transformer encoder for spatial and temporal explainability.Experiments on HCP-Rest and HCP-Task datasets show superior performance of STAGIN, with its spatiotemporal attention mechanisms providing interpretations aligned with existing neuroscientific knowledge, validating the approach.</p>
<p>Functional brain networks have been increasingly utilized for classifying brain disorders such as Autism Spectrum Disorder (ASD) and Alzheimer's Disease (AD).Traditional approaches often overlook non-imaging information and inter-subject relationships or fail to identify disease-specific brain regions and biomarkers, resulting in less accurate classifications.To overcome these challenges, researchers introduce the local-to-global graph neural network (LG-GNN) [132], which includes a local ROI-GNN for extracting feature embeddings of brain regions and identifying biomarkers, and a global Subject-GNN that leverages these embeddings and non-imaging data to learn inter-subject relationships.The LG-GNN was validated on public datasets for ASD and AD classification, achieving state-of-the-art performance across various evaluation metrics.</p>
<p>Medical Knowledge Graphs</p>
<p>GNNs also enhance medical knowledge graphs, which aggregate vast medical knowledge to inform diagnostics and treatment plans.For example, drug repurposing is typically an opportunistic effort to find new uses for approved drugs.However, it faces limitations due to AI models' focus on diseases with existing treatments.To solve this problem, TxGNN is introduced as a graph foundation model for zero-shot drug repurposing, aiming to identify therapeutic candidates for diseases with few or no treatments.By leveraging a medical knowledge graph, TxGNN uses a graph neural network and metric learning to rank drugs for potential indications and contraindications across 17,080 diseases.As a result, it outperforms eight other methods with improved prediction accuracy for both indications and contraindications [47].</p>
<p>In addition, EHRs are crucial for comprehensive patient care, although their complexity and verbosity can overwhelm healthcare providers and lead to diagnostic errors.While Large Language Models (LLMs) show promise in various language-related tasks, their application in health- LG-GNN [132] Prediction accuracy, Sensitivity, Specificity, F1 score, AUC-ROC Medical Knowledge Graphs Sampling diseases from the Knowledge Graphs TxGNN (GNN) [47] Prediction accuracy UMLS DR.KNOWS [39] Precision, Recall, F-score Drug Discovery Analysis Davis, Kiba GraphDTA (GNN) [85] Prediction accuracy GNBR Graph embedding [111] AUC-ROC Protein-Protein Interaction Networks AlphaFold Protein Structure Database, PDB GraphGPSM (GNN) [136] TM-scores, Prediction accuracy HPRD, OPHID, Bi-oGRID, STRING MGPPI (GNN) [45] Prediction accuracy, Precision, Recall, F1 score, AUC-ROC care must prioritize accuracy and safety to prevent patient harm.An approach has been proposed that enhances LLMs in automated diagnosis generation by integrating a medical knowledge graph (KG) derived from the Unified Medical Language System (UMLS) and a novel graph model inspired by clinical diagnostic reasoning.Experiments with real-world hospital data reveal that this combined approach improves diagnostic accuracy and provides an explainable diagnostic pathway, advancing AI-augmented decision support systems in healthcare [39].</p>
<p>Drug Discovery Analysis</p>
<p>The process of discovering new therapeutic applications for existing drugs involves key challenges, such as modeling the intricate interactions among genes, pathways, targets, and drugs, which leads to an exponentially vast search space.</p>
<p>GNNs are revolutionizing the process of drug discovery by predicting molecular properties essential for pharmaceutical efficacy.They provide insights into molecular interactions by modeling compounds as graphs.GraphDTA [85] is a new model which represents drugs as graphs and employs GNNs to predict drug-target affinity.It is found that GNNs not only achieve superior predictions of drug-target affinity compared to traditional non-deep learning models but also outperform other deep learning approaches.These results validate the suitability of deep learning models for predicting drug-target binding affinity and highlight the advantages of using graph representations for drugs in enhancing prediction accuracy.</p>
<p>Drug repurposing emerges as a promising alternative method for rare diseases, utilizing existing FDA-approved drugs for new therapeutic indications.To systematically generate drug repurposing hypotheses, it is crucial to integrate data from pharmacology, genetics, and pathology, which is facilitated by the Global Network of Biomedical Relationships (GNBR), a comprehensive knowledge graph.By applying a knowledge graph embedding method that models uncertainty and uses link prediction, this approach effectively generates and validates new drug repurposing hypotheses, achieving high performance (AUC-ROC = 0.89) and providing explanations for its predictions [111].</p>
<p>Protein-Protein Interaction Networks</p>
<p>Protein structure scoring models are typically categorized into unified field and protein-specific functions, yet current prediction methods still fall short in accurately modeling complex structures, such as multi-domain and orphan proteins.In understanding disease mechanisms, GNNs help predict protein-protein interactions, which are vital for biological processes and pathways.</p>
<p>Despite the preference for computational PPI prediction methods due to their cost-effectiveness and accuracy, many current approaches fall short in extracting detailed structural information and lack interpretability.MGPPI [136], a novel multiscale graph convolutional neural network, addresses these issues by effectively capturing both local and global protein structures and enhancing interpretability through Gradient Weighted Interaction Activation Mapping (Grad-WAM).Demonstrating superior performance across various datasets, MGPPI not only identifies key binding sites, such as those between the SARS-CoV-2 spike protein and human ACE2, but also highlights residues that could serve as biomarkers for predicting cancer patient survival, showcasing its potential for guiding personalized treatment and drug target identification.</p>
<p>In addition, GraphGPSM [45] is a new global scoring model based on an equivariant graph neural network (EGNN), has been developed to improve protein structure prediction and ranking.By integrating advanced features like residuelevel ultrafast shape recognition and Gaussian radial basis function encoding with Rosetta energy terms, GraphGPSM shows a strong correlation with TM-scores on CASP13, CASP14, and CAMEO test sets, outperforming existing models like REF2015, ModFOLD8, and AlphaFold2, particularly in modeling challenging proteins.</p>
<p>Conclusion</p>
<p>Large Graph Models, with their profound ability to model complex data structures, have unprecedented potential in various medical applications, offering innovative solutions to complex challenges encountered in healthcare.Nonetheless, the significance of human-centered design and model interpretability in clinical decision-making remains paramount.As graph AI models derive insights through localized neural transformations on relational datasets, they present both opportunities and challenges in explaining model logic.Knowledge graphs can improve interpretability by aligning insights generated by the models with established medical knowledge.New graph AI models are emerging that integrate diverse data modalities through pretraining, facilitate interactive feedback loops, and encourage human-AI collaboration, ultimately leading to clinically relevant predictions [53].</p>
<p>The future of GNNs in medicine hinges on continuing research and extensive datasets to refine these models further, interdisciplinary collaboration, driving forward the development of precision medicine and advancing the global health landscape.</p>
<p>F e a u r e s A d v e n ta g e s 6 .Figure 1 .
61
Figure 1.The overall structure of the survey.</p>
<p>Figure 2 .
2
Figure 2. Evolution timeline of Large Models and their applications in medical.Including language models, vision models, multi-modal models and graph-based models.</p>
<p>with practical clinical
-Huge parameters-Massive data-Complex Networks-Personalized treatment-Deneralized skills-Extensive knowledgeApplicationsApplications+Brain network analysis +Medical knowledge graphs +Protein struture analysis+UAMAL teacher +Health management +Diagnostic report analysis &amp; generationApplications ofLarge AI ModelsApplicationsin MedicalApplications+3D medical data+Anomaly detectionanalysis+Pathological image+High-quailty medicalanalysis3D image generation+Counterfactuals medical+Biometric Analysisdata synthesisApplications+Medical report generation+Medical single analysis+Medical VQA+Zero-shot anomalydetection</p>
<p>Table 1 .
1
Comparison of Different Approaches in Medical Visual Anomaly Detection</p>
<p>Table 2 .
2
Evaluation Methods for Different Tasks</p>
<p>Table 3 .
3
Evaluation Methods for Different Models
Model TypeApplicationEvaluation Metrics</p>
<p>Table 4 .
4
Summary of Large Graph Models with Datasets and Evaluation Metrics in the Medical Field.Abbr.HCP (Human Connectome Project); STAGIN (Spatio-Temporal Attention Graph Isomorphism Network); ADNI (Alzheimer's Disease Neuroimaging Initiative); UMLS (Unified Medical Language System); GDSC (Genomics of Drug Sensitivity in Cancer); GNBR (Global Network of Biomedical Relationships); PDB (Protein Data Bank); HPRD (Human Protein Reference Database); OPHID (Online Predicted Human Interaction Database); BioGRID (H.sapiens dataset from the Biological General Repository for Interaction Datasets); AUC-ROC (Area Under the Curve -Receiver Operating Characteristic)
ApplicationDatasetsMethod/ ModelEvaluation MetricsBrain Network AnalysisHCP-Rest, HCP-TaskSTAGIN[57]Prediction accuracy,AUC-ROCADNI</p>
<p>Distilling step-by-step: Outperforming larger language models with less training. </p>
<p>The future landscape of large language models in medicine. </p>
<p>Unveiling llm evaluation focused on metrics: Challenges and solutions. Funded by National Key R&amp;D Program of China. 2021YFF09014005</p>
<p>Medical question answering benchmark with multiple explanations. Medexqa, </p>
<p>Open Sourcing Surface Electromyography Datasets at NeurIPS. 2024. 2024</p>
<p>Foundation metrics for evaluating effectiveness of healthcare conversations powered by generative ai. Elham Mohammadreza Abbasian, Iman Khatibi, Azimi, Digital Medicine. 712024</p>
<p>Test-time adaptation with salip: A cascade of sam and clip for zero-shot medical image segmentation. Sidra Aleem, Fangyijie Wang, Mayug Maniparambil, Eric Arazo, Julia Dietlmeier, Kathleen Curran, Eo' Noel, Suzanne Connor, Little, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition202456</p>
<p>Image analysis in digital pathology utilizing machine learning and deep neural networks. P Amerikanos, I Maglogiannis, Journal of Personalized Medicine. 129</p>
<p>Annotator consensus prediction for medical image segmentation with diffusion models. Tomer Amit, Shmuel Shichrur, Tal Shaharabany, Lior Wolf, International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer202367</p>
<p>Efficacy of Three-Dimensional Models for Medical Education: A Systematic Scoping Review of Randomized Clinical Trials. C M Ardila, D González-Arroyave, M Zuluaga-Gómez, Heliyon. 92122023</p>
<p>Full-Sized Realistic 3D Printed Models of Liver and Tumour Anatomy: A Useful Tool for the Clinical Medicine Education of Beginning Trainees. G Bao, P Yang, J Yi, BMC Medical Education. 23122023</p>
<p>Bmad: Benchmarks for medical anomaly detection. Jinan Bao, Hanshi Sun, Hanqiu Deng, Yinsheng He, Zhaoxiang Zhang, Xingyu Li, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2024</p>
<p>Diffusion models with ensembled structurebased anomaly scoring for unsupervised anomaly detection. Finn Behrendt, Debayan Bhattacharya, Lennart Maack, Julia Krüger, Roland Opfer, Robin Mieling, Alexander Schlaefer, arXiv:2403.142622024arXiv preprint</p>
<p>An Introduction to Vision-Language Modeling. Florian Bordes, 2024arXiv preprint</p>
<p>Large language models for more efficient reporting of hospital quality measures. A Boussina, R Krishnamoorthy, K Quintero, 10.1056/aics2400420NEJM AI. 1112024</p>
<p>Role of Three-Dimensional Visualization Modalities in Medical Education. I Bui, A Bhattacharya, S H Wong, Frontiers in Pediatrics. 9122021</p>
<p>Dual-distribution discrepancy with self-supervised refinement for anomaly detection in medical images. Yu Cai, Hao Chen, Xin Yang, Yu Zhou, Kwang-Ting Cheng, Medical Image Analysis. 8672023</p>
<p>Generative artificial intelligence to produce high-fidelity blastocyst-stage embryo images. P Cao, Hum Reprod. 3962024</p>
<p>Evaluating question answering evaluation. Anthony Chen, Gabriel Stanovsky, Sameer Singh, Matt Gardner, Proceedings of the 2nd Workshop on Machine Reading for Question Answering. the 2nd Workshop on Machine Reading for Question AnsweringAssociation for Computational Linguistics2019</p>
<p>Towards a general-purpose foundation model for computational pathology. R J Chen, Nature Medicine. 3032024</p>
<p>Encoder-decoder structure fusing depth information for outdoor semantic segmentation. S Chen, Applied Sciences. 131799242023</p>
<p>EMGTFNet: Fuzzy Vision Transformer to Decode Upperlimb sEMG Signals for Hand Gestures Recognition. Joseph Cherre, Córdova , IEEE International Conference on Fuzzy Systems. FUZZ-IEEE2023</p>
<p>I2u-net: A dual-path u-net with rich information interaction for medical image segmentation. D Dai, Medical Image Analysis. 71032412024</p>
<p>Challenges and opportunities in secondary analyses of electronic health record data. Secondary analysis of electronic health records. Sunil Mit Critical Data, Douglas Nair, Leo Hsu, Celi Anthony, 201614</p>
<p>J Ding, arXiv:2307.02486Scaling transformers to 1,000,000,000 tokens. 2023arXiv preprint</p>
<p>Artificial intelligence and cellular segmentation in tissue microscopy images. The American journal of pathology. M S Durkee, 2021191</p>
<p>Dermatologist-level classification of skin cancer with deep neural networks. A Esteva, B Kuprel, R A Novoa, J Ko, Nature. 54276392017</p>
<p>Dermatologist-level classification of skin cancer with deep neural networks. A Esteva, nature. 54276392017</p>
<p>Segmentation of corneal endothelium images using a u-net-based convolutional neural network. Artificial intelligence in medicine. A Fabijańska, 201888</p>
<p>Discrepancy-based diffusion models for lesion detection in brain mri. Keqiang Fan, Xiaohao Cai, Mahesan Niranjan, arXiv:2405.049742024arXiv preprint</p>
<p>Ethical issues of artificial intelligence in medicine and healthcare. D Dariush, Sara Farhud, Zokaei, Iranian Journal of Public Health50</p>
<p>Automatic data augmentation to improve generalization of deep learning in h&amp;e stained histopathology. K Faryna, J Van Der Laak, G Litjens, Computers in Biology and Medicine. 1708108018. 2024</p>
<p>Survey on synthetic data generation. A Figueira, B Vaz, evaluation methods and gans. Mathematics. 10827332022</p>
<p>Diffusion models for counterfactual generation and anomaly detection in brain images. Alessandro Fontanella, Grant Mair, Joanna Wardlaw, Emanuele Trucco, Amos Storkey, IEEE Transactions on Medical Imaging. 562024</p>
<p>Machine learning empowering personalized medicine: A comprehensive review of medical image analysis methods. I Galić, Electronics. 122144112023</p>
<p>Jun Gao, A Generative Model of High Quality 3D Textured Shapes Learned from Images. 20221012arXiv preprint</p>
<p>Leveraging a medical knowledge graph into large language models for diagnosis prediction. Yanjun Gao, Ruizhe Li, John Caskey, Dmitriy Dligach, Timothy Miller, Matthew M Churpek, Majid Afshar, 202315</p>
<p>Generative adversarial nets. I Goodfellow, Advances in neural information processing systems. 2014</p>
<p>Using an anomaly detection approach for the segmentation of colorectal cancer tumors in whole slide images. Q Gu, Journal of Pathology Informatics. 1491003362023</p>
<p>Transformer in transformer. K Han, Advances in neural information processing systems. 2021</p>
<p>Vision-Language Models for Medical Report Generation and Visual Question Answering: A Review. Iryna Hartsock, Ghulam Rasool, Frontiers in Artificial Intelligence. 7132024</p>
<p>Evaluation of pseudo-healthy image reconstruction for anomaly detection with deep generative models: Application to brain fdg pet. R Hassanaly, arXiv:2401.163632024arXiv preprint</p>
<p>Graphgpsm: a global scoring model for protein structure using graph neural networks. Guangxing He, Jun Liu, Dong Liu, Guijun Zhang, Briefings in Bioinformatics. 244162023</p>
<p>Adapting visuallanguage models for generalizable anomaly detection in medical images. Chaoqin Huang, Aofan Jiang, Jinghao Feng, Ya Zhang, Xinchao Wang, Yanfeng Wang, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition202456</p>
<p>Nils Gehlenborg, and Marinka Zitnik. Zero-shot drug repurposing with geometric deep learning and clinician centered design. medRxiv. Kexin Huang, Payal Chandak, Qianwen Wang, Shreyas Havaldar, Akhil Vaid, Jure Leskovec, Girish Nadkarni, Benjamin S Glicksberg, 20241415</p>
<p>A survey on large language models with multilingualism: Recent advances and new frontiers. Kaizhi Huang, Fengran Mo, Haoyang Li, 2024arXiv preprint</p>
<p>Unsupervised anomaly detection in medical images using masked diffusion model. Hasan Iqbal, Umar Khalid, Chen Chen, Jing Hua, International Workshop on Machine Learning in Medical Imaging. Springer202367</p>
<p>Deep learning models for histologic grading of breast cancer and association with disease prognosis. R Jaroensri, NPJ Breast cancer. 811132022</p>
<p>Application of Convolutional Neural Networks in Medical Images: A Bibliometric Analysis. H Jia, J Zhang, K Ma, Quantitative Imaging in Medicine and Surgery. 1452024</p>
<p>Automatic three-dimensional nasal and pharyngeal airway subregions identification via vision transformer. S Jin, J Dent. 136111045952023</p>
<p>Graph ai in medicine. Ruth Johnson, Michelle M Li, Ayush Noori, Owen Queen, Marinka Zitnik, 20231416</p>
<p>Deep learning-based glomerulus detection and classification with generative morphology augmentation in renal pathology images. C.-F Juang, Computerized Medical Imaging and Graphics. 11581023752024</p>
<p>Highly accurate protein structure prediction with alphafold. J Jumper, R Evans, A Pritzel, Nature. 59678732021</p>
<p>A style-based generator architecture for generative adversarial networks. T Karras, S Laine, T Aila, arXiv:1812.04948.82018arXiv preprint</p>
<p>Learning dynamic graph representation of brain connectome with spatio-temporal attention. Byung-Hoon Kim, Jong Chul Ye, Jae-Jin Kim, Advances in Neural Information Processing Systems. Curran Associates, Inc20211415</p>
<p>Medclip-samv2: Towards universal text-driven medical image segmentation. Taha Koleilat, Hojat Asgariandehkordi, Hassan Rivaz, Yiming Xiao, arXiv:2409.19483202456arXiv preprint</p>
<p>Computer Image Analysis with Artificial Intelligence: A Practical Introduction to Convolutional Neural Networks for Medical Professionals. Georgios Kourounis, Ali Ahmed Elmahmudi, Brian Thomson, Postgraduate Medical Journal. 99101178. 2023</p>
<p>Bioasq-qa: A manually curated corpus for biomedical question answering. Anastasia Krithara, Anastasios Nentidis, Scientific Data. 1011702023Konstantinos Bougiatiotis, and Georgios Paliouras</p>
<p>The potential of chatgpt as a self-diagnostic tool in common orthopedic diseases: Exploratory study. Takuto Kuroiwa, Armin Sarcon, Toshihiro Ibara, Journal of Medical Internet Research. 251e476212023</p>
<p>3D UX-Net: A Large Kernel Volumetric ConvNet Modernizing Hierarchical Transformer for Medical Image Segmentation. Lee Ho Hin, 2022arXiv preprint</p>
<p>Y.-S Lee, W.-H Park, Diagnosis of Depressive Disorder Model on Facial Expression Based on Fast R-CNN. </p>
<p>. Diagnostics. 122122022</p>
<p>High resolution histopathology image generation and segmentation through adversarial training. W Li, Medical Image Analysis. 7581022512022</p>
<p>Pediatric pituitary neuroendocrine tumors-a 13-year experience in a tertiary center. Xiaoxu Li, Kan Deng, Yi Zhang, Ming Feng, Bing Xing, Wei Lian, Yong Yao, Frontiers in Oncology. 13112709582023</p>
<p>Zeroshot medical image translation via frequency-guided diffusion models. Yunxiang Li, Hua-Chieh Shao, Xiao Liang, Liyuan Chen, Ruiqi Li, Steve Jiang, Jing Wang, You Zhang, IEEE transactions on medical imaging. 72023</p>
<p>LViT: Language Meets Vision Transformer in Medical Image Segmentation. Zihan Li, IEEE Transactions on Medical Imaging. 43132022</p>
<p>N-net: an unet architecture with dual encoder for medical image segmentation. Signal, Image and Video Processing. B Liang, 202317</p>
<p>Modality cycles with masked conditional diffusion for unsupervised anomaly segmentation in mri. Ziyun Liang, Harry Anthony, Felix Wagner, Konstantinos Kamnitsas, International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer2023</p>
<p>An Integrated Biometric Voice and Facial Features for Early Detection of Parkinson's Disease. W S Lim, S I Chiu, M C Wu, Parkinson's Disease. 8122022</p>
<p>Measuring Depression Severity Based on Facial Expression and Body Movement Using Deep Convolutional Neural Network. Dongdong Liu, Bowen Liu, Tao Lin, Frontiers in Psychiatry. 13122022</p>
<p>Contrastive learningbased histopathological features infer molecular subtypes and clinical outcomes of breast cancer from unannotated whole slide images. H Liu, Y Zhang, J Luo, Computers in Biology and Medicine. 17091079972024</p>
<p>Integration of Convolutional Neural Network and Vision Transformer for Gesture Recognition Using sEMG. Xiaoguang Liu, Lijian Hu, Liang Tie, Biomedical Signal Processing and Control. 98111066862024</p>
<p>A Review of Combined Functional Neuroimaging and Motion Capture for Motor Rehabilitation. E A Lorenz, X Su, N Skjaeret-Maroni, Journal of NeuroEngineering and Rehabilitation. 213122024</p>
<p>A visual-language foundation model for computational pathology. M Y Lu, Nature Medicine. 3032024</p>
<p>Implementation of 3D Printing Technology in the Field of Prosthetics: Past, Present, and Future. A Manero, P Smith, J Sparkman, International Journal of Environmental Research and Public Health. 16916412019</p>
<p>Using a 22-layer u-net to perform segmentation of squamous cell carcinoma on digitized head and neck histological images. A Mavuduru, Proceedings of SPIE-the International Society for Optical Engineering. SPIE-the International Society for Optical EngineeringNIH Public Access2020</p>
<p>Face generation and editing with stylegan: A survey. A Melnik, IEEE Transactions on Pattern Analysis and Machine Intelligence. 82024</p>
<p>3D Printing Metal Implants in Orthopedic Surgery: Methods, Applications and Future Prospects. Meng Meng, Jinzuo Wang, Huagui Huang, Journal of Orthopaedic Translation. 42122023</p>
<p>Generative ai-based pipeline architecture for increasing training efficiency in intelligent weed control systems. S Modak, A Stein, arXiv:2411.005482024arXiv preprint</p>
<p>The development of the pan american health organization digital health specialist on alcohol use. G Maristela, Daniela Monteiro, Ilana Pantani, Thiago Pinsky, Hernandes Augusto, Rocha, Frontiers in Digital Health. 442022</p>
<p>Foundation models for generalist medical artificial intelligence. M Moor, Nature. 61679562023</p>
<p>Supervised Deep Learning with Vision Transformer Predicts Delirium Using Limited Lead EEG. M A Mulkey, H Huang, T Albanese, Scientific Reports. 131178902023</p>
<p>Integrating biomedical research and electronic health records to create knowledge based biologically meaningful machine readable embeddings. Charlotte A Nelson, Atul J Butte, Sergio E Baranzini, bioRxiv. 142019</p>
<p>Graphdta: predicting drug-target binding affinity with graph neural networks. Thin Nguyen, Hang Le, Tri Thomas P Quinn, Thuc Nguyen, Svetha Duy Le, Venkatesh, Bioinformatics. 378152020</p>
<p>Capabilities of gpt-4 on medical challenge problems. Harsha Nori, Nicholas King, Scott Mayer Mckinney, Dean Carignan, Eric Horvitz, 2023arXiv preprint</p>
<p>Attention u-net: Learning where to look for the pancreas. O Oktay, arXiv:1804.039992018arXiv preprint</p>
<p>Unsupervised medical image translation with adversarial diffusion models. Muzaffer Özbey, Onat Dalmaz, Salman Uh Dar, A Hasan, S Bedel, Alper ¸aban Özturk, Tolga C Güngör, ¸ukur, IEEE Transactions on Medical Imaging. 672023</p>
<p>Introduction to deep learning and diagnosis in medicine. A Oguz, O F Ertugrul, Diagnostic Biomedical Signal and Image Processing Applications with Deep Learning Methods. Elsevier2023</p>
<p>Generative convolution layer for image generation. S Park, Y G Shin, Neural Netw. 152112022</p>
<p>Artificial intelligence in urologic oncology: the actual clinical practice results of ibm watson for oncology in south korea. Taeyoung Park, Philip Gu, Chang-Hee Kim, Kwang Taek Kim, Kyung , Jin Chung, Tea Beom Kim, Han Jung, Sang , Jin Yoon, Jin Kyu Oh, Prostate International. 1142023</p>
<p>Contrastive language prompting to ease false positives in medical anomaly detection. Yeonghyeon Park, Myung , Jin Kim, Hyeong Seok, Kim , arXiv:2411.07546202456arXiv preprint</p>
<p>The State of Clinical Trials of Implantable Brain-Computer Interfaces. K M Patrick-Krueger, I Burkhart, J L Contreras-Vidal, Nature Reviews Bioengineering. 3132025</p>
<p>Transfer learning in biomedical natural language processing: An evaluation of bert and elmo on ten benchmarking datasets. Yifan Peng, Shankai Yan, Zhiyong Lu, 2019arXiv preprint</p>
<p>Seizure Prediction Based on Improved Vision Transformer Model for EEG Channel Optimization. N Qi, Y Piao, H Zhang, Computer Methods in Biomechanics and Biomedical Engineering. 112024</p>
<p>A biological image classification method based on improved cnn. J Qin, Ecological Informatics. 5891010932020</p>
<p>A A Raheem, P Hameed, R Whenish, Review on Development of Bio-Inspired Implants Using 3D Printing. 2021612</p>
<p>Machine learning in medicine. A Rajkomar, J Dean, I Kohane, New England Journal of Medicine. 38012019</p>
<p>U-net: Convolutional networks for biomedical image segmentation. O Ronneberger, P Fischer, T Brox, Medical image computing and computer-assisted intervention-MICCAI 2015: 18th international conference. GermanySpringerOctober 5-9, 2015. 2015proceedings, part III 18</p>
<p>Enhancing histopathological image classification performance through synthetic data generation with generative adversarial networks. J L Ruiz-Casado, M A Molina-Cabello, R M Luque-Baena, Sensors. 241237772024</p>
<p>D R Sarvamangala, R V Kulkarni, Convolutional Neural Networks in Medical Image Understanding: A Survey. 202215</p>
<p>Stylegan-xl: Scaling stylegan to large diverse datasets. A Sauer, K Schwarz, A Geiger, ACM SIGGRAPH 2022 conference proceedings. 2022</p>
<p>User intentions to use chatgpt for self-diagnosis and health-related purposes: Cross-sectional survey study. Yashar Shahsavar, Avishek Choudhury, JMIR Human Factors. 104e475642023</p>
<p>Apply maskedattention mask transformer to instance segmentation in pathology images. J.-C Sheng, Y.-S Liao, C.-R Huang, 2023 Sixth International Symposium on Computer, Consumer and Control (IS3C). IEEE2023</p>
<p>A systematic survey on biological cell image segmentation and cell counting techniques in microscopic images using machine learning. Wireless Personal. H Singh, H Kaur, Communications. 13722024</p>
<p>Nuclear morphological abnormalities in cancer: a search for unifying mechanisms. I Singh, T P Lele, Nuclear, chromosomal, and genomic architecture in biology and medicine. Springer2022</p>
<p>. S P Singh, L Wang, S Gupta, Deep Learning on Medical Images: A Review. Sensors. 201850972020</p>
<p>Large language models encode clinical knowledge. Karan Singhal, Shekoofeh Azizi, Tao Tu, Nature. 62079722023</p>
<p>Towards expert-level medical question answering with large language models. Karan Singhal, Tao Tu, Juraj Gottweis, 2023arXiv preprint</p>
<p>Continuous Neural Control of a Bionic Limb Restores Biomimetic Gait After Amputation. H Song, T H Hsieh, S H Yeon, Nature Medicine. 30122010-2019, 2024</p>
<p>A literature-based knowledge graph embedding method for identifying drug repurposing opportunities in rare diseases. N Daniel, Alexander Sosa, Margaret Derry, Eric Guo, Connor Wei, Russ B Brinton, Altman, bioRxiv. 152019</p>
<p>3D Printing in Medicine: Current Applications and Future Directions. Z Sun, Quantitative Imaging in Medicine and Surgery. 8112018</p>
<p>Self-Supervised of Swin Transformers for 3D Medical Image Analysis. Yucheng Tang, IEEE Conference on Computer Vision and Pattern Recognition. 2022</p>
<p>Contrastive multiple instance learning: An unsupervised framework for learning slide-level representations of whole slide histopathology images without labels. T E Tavolara, M N Gurcan, M K K Niazi, Cancers. 142357782022</p>
<p>Self-supervised pseudo multi-class pretraining for unsupervised anomaly detection and segmentation in medical images. Yu Tian, Fengbei Liu, Guansong Pang, Yuanhong Chen, Yuyuan Liu, Johan W Verjans, Rajvinder Singh, Gustavo Carneiro, Medical image analysis. 9061029302023</p>
<p>Deep Learning Based Markerless Motion Tracking as a Clinical Tool for Movement Disorders. Rex N Tien, Anand Tekriwal, Dylan J Calame, Frontiers in Signal Processing. 2122022</p>
<p>Anomaly detection in medical imaging-a mini review. M E Tschuchnig, M Gadermayr, International Data Science Conference. Springer2021</p>
<p>A Foundational Vision Transformer Improves Diagnostic Performance for Electrocardiograms. A Vaid, J Jiang, A Sawant, Digital Medicine. 6111082023</p>
<p>A foundation model for clinical-grade computational pathology and rare cancers detection. E Vorontsov, Nature medicine. 102024</p>
<p>Haoshen Wang, 3D MedDiffusion: A 3D Medical Diffusion Model for Controllable and High-Quality Medical Image Generation. 2024arXiv preprint</p>
<p>Integrating Computer Vision to Prosthetic Hand Control with sEMG: Preliminary Results in Grasp Classification. S Wang, J Zheng, Z Huang, Frontiers in Robotics and AI. 9119482382022</p>
<p>Critical review of self-diagnosis of mental health conditions using artificial intelligence. International Journal of Mental Health. Supra Wimbarti, H R Brynne, Trina E Kairupan, Tallei, Nursing. 3322024</p>
<p>Diffusion models for medical anomaly detection. Julia Wolleb, Florentin Bieder, Robin Sandkühler, Philippe C Cattin, International Conference on Medical image computing and computer-assisted intervention. Springer202256</p>
<p>Medsegdiff-v2: Diffusion-based medical image segmentation with transformer. Junde Wu, Wei Ji, Huazhu Fu, Min Xu, Yueming Jin, Yanwu Xu, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202467</p>
<p>Graph neural networks for medical data analysis. Z Wu, X Zhang, X Wei, IEEE Transactions on Neural Networks and Learning Systems. 32022</p>
<p>H Xiao, F Zhou, X Liu, T Liu, Z Li, X Liu, X Huang, A comprehensive survey of large language models and multimodal large language models in medicine. 2024arXiv preprint</p>
<p>Development of skip connection in deep neural networks for computer vision and medical image analysis: A survey. G Xu, arXiv:2405.017252024arXiv preprint</p>
<p>A whole-slide foundation model for digital pathology from real-world data. H Xu, Nature. 102024</p>
<p>3d medical image segmentation using convolutional neural networks. Z Yang, L Li, S Wang, Journal of Medical Imaging. 32020</p>
<p>VLM-EMO: Context-Aware Emotion Classification with CLIP. Y Yao, X Mei, J Xu, International Seminar on Artificial Intelligence, Networking and Information Technology. 202412</p>
<p>Multiscale generative model using regularized skip-connections and perceptual loss for anomaly detection in toxicologic histopathology. P Zehnder, Journal of Pathology Informatics. 1391001022022</p>
<p>Classification of brain disorders in rs-fmri via local-to-global graph neural networks. Hao Zhang, Ran Song, Liping Wang, Lin Zhang, Dawei Wang, Cong Wang, Wei Zhang, IEEE Transactions on Medical Imaging. 422152023</p>
<p>Biomedclip: a multimodal biomedical foundation model pretrained from fifteen million scientific image-text pairs. Sheng Zhang, Yanbo Xu, Naoto Usuyama, Hanwen Xu, Jaspreet Bagga, Robert Tinn, Sam Preston, Rajesh Rao, Mu Wei, Naveen Valluri, arXiv:2303.00915202356arXiv preprint</p>
<p>Graph meets llms: Towards large graph models. Ziwei Zhang, Haoyang Li, Zeyang Zhang, Yijian Qin, Xin Wang, Wenwu Zhu, 20231314</p>
<p>Spatial-aware attention generative adversarial network for semi-supervised anomaly detection in medical image. Zerui Zhang, Zhichao Sun, Zelong Liu, Zhou Zhao, Rui Yu, Bo Du, Yongchao Xu, International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer202467</p>
<p>Mgppi: multiscale graph neural networks for explainable protein-protein interaction prediction. Shiwei Zhao, Zhenyu Cui, Gonglei Zhang, Yanlong Gong, Lingtao Su, Frontiers in Genetics. 15152024</p>
<p>Evaluation of gan-based model for adversarial training. W Zhao, Q H Mahmoud, S Alwidian, Sensors. 23526972023</p>
<p>Prompting Visual-Language Models for Dynamic Facial Expression Recognition. Zengqun Zhao, I Patras, The British Machine Vision Conference. 202312</p>
<p>H Zhou, F Liu, B Gu, X Zou, J Huang, J Wu, Y Li, S S Chen, P Zhou, J Liu, Y Hua, C Mao, C You, X Wu, Y Zheng, L Clifton, Z Li, J Luo, D A Clifton, A survey of large language models in medicine: Progress, application, and challenge. 2023arXiv preprint</p>
<p>Anomalyclip: Object-agnostic prompt learning for zero-shot anomaly detection. Qihang Zhou, Guansong Pang, Yu Tian, Shibo He, Jiming Chen, arXiv:2310.18961202356arXiv preprint</p>
<p>Long-term follow-up for ectopic acth-secreting pituitary adenoma in a single tertiary medical center and a literature review. Jianyu Zhu, Lin Lu, Yong Yao, Shi Chen, Wei Li, Hui You, Feng Feng, Ming Feng, Yi Zhang, Zhicheng Wang, Pituitary. 2312020</p>
<p>Suprasellar pituitary adenomas: a 10-year experience in a single tertiary medical center and a literature review. Jianyu Zhu, Zhicheng Wang, Yi Zhang, Jie Liu, Xiaoxu Li, Kan Deng, Lin Lu, Yong Yao, Pituitary. 232020</p>
<p>Xanthomatous hypophysitis: a case report and comprehensive literature review. Jianyu Zhu, Zhicheng Wang, Wenze Wang, Jinghua Fan, Yi Zhang, Xiaoxu Li, Jie Liu, Shenzhong Jiang, Kan Deng, Lian Duan, Frontiers in Endocrinology. 1217356552021</p>
<p>Learning image representations for anomaly detection: application to discovery of histological alterations in drug development. I Zingman, Medical Image Analysis. 9292024</p>            </div>
        </div>

    </div>
</body>
</html>