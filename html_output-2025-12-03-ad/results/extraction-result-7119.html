<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7119 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7119</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7119</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-133.html">extraction-schema-133</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <p><strong>Paper ID:</strong> paper-a7c5fce05b676cba2af8c489e7c7691cf6c1997b</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/a7c5fce05b676cba2af8c489e7c7691cf6c1997b" target="_blank">Grounding emotion in situated conceptualization</a></p>
                <p><strong>Paper Venue:</strong> Neuropsychologia</p>
                <p><strong>Paper TL;DR:</strong> A neuroimaging experiment tested two core hypotheses of the Conceptual Act Theory of Emotion: different situated conceptualizations produce different forms of the same emotion in different situations, and the composition of a situated conceptualization emerges from shared multimodal circuitry distributed across the brain that produces emotional states generally.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7119.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7119.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Grounded Cognition</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Grounded Theory of Concepts / Grounded Cognition (Barsalou et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A theoretical framework proposing that concepts are grounded in the brain's modal systems for perception, action, and internal states, and that conceptual representations are multimodal, situated, and arise from the same sensorimotor/interoceptive systems that process instances of those concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Grounded Cognition</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>embodied simulation / multimodal distributed representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual knowledge is functionally represented as distributed, modality-specific activity patterns in perceptual, motor, and interoceptive systems (and their associated multimodal hubs); concepts are instantiated as reactivations (simulations) of the sensorimotor/interoceptive states that accompanied past instances and are embedded within situational context networks.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Accounts for context-dependent conceptual activation, supports perceptual/motor influences on conceptual processing, explains why concepts trigger action and bodily states, and predicts that conceptual representations will recruit the same neural systems used to perceive/act/interocept during concept use.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>fMRI study (this paper) plus cited behavioral and neuroimaging literature</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>Situation listening with immersion + concept-word rating in event-related fMRI with catch-trial separation of situation vs. concept periods</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Concept-related activations were distributed across modality-specific and multimodal systems and depended on the preceding situational context, consistent with concepts being instantiated via multimodal simulations rather than stored amodal symbols.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>No direct contradictory results reported in this study; authors note variability across emotion markers and lack of one-to-one brain–emotion mapping (cited meta-analyses) which they interpret as supportive rather than contradictory. The paper does not report findings that directly falsify grounded claims.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Wilson-Mendenhall, Barrett, Simmons, & Barsalou (2011)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Grounding emotion in situated conceptualization', 'publication_date_yy_mm': '2011-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7119.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7119.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Conceptual Act Theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Conceptual Act Theory of Emotion (Barrett et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A theory proposing that emotions are constructed by situated conceptualizations: conceptual acts that use multimodal conceptual knowledge to categorize ongoing changes in core affect, interoception, and perception, thereby producing discrete emotion experiences.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Conceptual Act Theory of Emotion</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>relational/compositional multimodal representation (embodied simulation)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Emotion concepts are abstract, relational situated conceptualizations that integrate multimodal inputs (setting, agents, actions, interoception, mentalizing) and are composed online from distributed neural circuitry; the activation of a situated conceptualization constitutes the emotional episode (a 'conceptual act').</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains instance-to-instance variability of emotion expressions and neural activations, predicts that the same emotion category can have different neural/behavioral signatures depending on situational composition, and claims emotions arise from conceptually categorizing core affect and bodily signals.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>fMRI experiment (this paper); cited meta-analyses and lesion/stimulation/animal studies</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>Training on situation types (physical danger vs social evaluation) followed by event-related fMRI where subjects immerse in a situation then rate ease of experiencing a target concept (anger/fear/observe/plan); catch trials separate situation vs. concept periods.</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Different neural patterns for the same emotion concept (fear/anger) depending on preceding situation type; composed situated conceptualizations recruited distributed multimodal circuitry (overlap across emotions plus situation-specific recruitment), supporting the theory's predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Authors acknowledge that some subcortical circuits (e.g., PAG) are involved in certain behavioral adaptations but argue these circuits are not emotion-category-specific; no direct contradictory empirical finding reported in this dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Wilson-Mendenhall, Barrett, Simmons, & Barsalou (2011)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Grounding emotion in situated conceptualization', 'publication_date_yy_mm': '2011-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7119.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7119.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Situated Conceptualization</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Situated Conceptualization (compositional instances of concepts)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The representational format posited whereby a concept on a specific occasion is represented as an integrated network of background concepts (setting, agents, actions, interoception) forming a situation-specific instantiation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Situated Conceptualizations</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>relational network / compositional multimodal representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Functionally, a situated conceptualization is a transient, composed network of multimodal component activations (perceptual, motor, interoceptive, memory, language) that together represent an instance of a concept tailored to current contextual demands.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Accounts for contextual variability of concept instantiations, explains how concepts guide perception/action/interoception, and predicts that different situational compositions will recruit different neural subsystems even for the same conceptual label.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>fMRI (this experiment) and behavioral training/imagery procedures described in the paper</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>Immersive auditory situation reinstatement then concept-judgment in fMRI (catch-trial design to isolate concept-period activity); main- and interaction-effects analysis to partition concept vs situation contributions.</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Situated conceptualizations for anger and fear comprised both shared (concept main effects) and situation-specific (situation main effects and interactions) neural components, indicating that concept instantiation is compositional and context-dependent.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>None reported in this dataset; authors emphasize dynamical composition rather than fixed cores.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Wilson-Mendenhall, Barrett, Simmons, & Barsalou (2011)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Grounding emotion in situated conceptualization', 'publication_date_yy_mm': '2011-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7119.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e7119.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Neural Reference Space</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural Reference Space / Distributed Neural Circuitry for Emotion</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A distributed set of brain regions (a neural workspace) whose combinations of activations dynamically produce emotional states rather than a one-to-one mapping between emotion categories and specialized modules.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Neural Reference Space (distributed circuitry)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>high‑dimensional distributed activation patterns / assembly-based representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Emotions are implemented by combinations of activations across a distributed neural network (including insula, medial prefrontal, orbitofrontal, temporal pole, sensory, motor regions, etc.); each emotion instance corresponds to a situation-specific neural assembly drawn from this reference space.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains overlap of neural activations across different emotion categories, accounts for variability in physiological and behavioral markers, and predicts overlapping recruitment of general-purpose systems (attention, memory, language) in emotion.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>Meta-analyses cited (Kober et al., Lindquist et al., Wager et al.) and the present fMRI experiment</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>Meta-analysis of neuroimaging studies; event-related fMRI with situation × concept factorial analysis (this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Observed widespread overlap in areas active across emotions and situation-dependent recruitment of regions (e.g., parahippocampal gyrus for physical danger; medial PFC for social evaluation), consistent with a distributed reference space rather than discrete emotion modules.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Some subcortical circuits (e.g., PAG) are consistently engaged in particular defensive behaviors, but authors argue these do not map one-to-one onto emotion categories.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Wilson-Mendenhall, Barrett, Simmons, & Barsalou (2011)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Grounding emotion in situated conceptualization', 'publication_date_yy_mm': '2011-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7119.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e7119.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Amodal Symbolic / Basic Emotion</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Amodal Symbolic and Basic Emotion Approaches (prototype/module views)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Contrasted theoretical approaches that posit emotion concepts as amodal, symbol-like entities or that emotions are innate modules producing stereotyped responses to triggers.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Amodal Symbolic / Basic Emotion Theories</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>symbolic / modular</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>These views functionally represent emotions as discrete, possibly innate modules or amodal symbols with a fixed core of content and stereotyped response profiles that are triggered by relevant external conditions.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Predicts consistent physiological/behavioral/neural signatures for each basic emotion and minimal context-dependence; accounts for universality claims and rapid emotion elicitation.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>Mentioned in the introduction (historical theories); contrasted with current data</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>Varied (behavioral observation, cross-cultural studies, lesion/electrophysiology cited historically)</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Authors report that empirical reviews/meta-analyses show substantial variability in markers across instances and overlap in brain activations, challenging strict module/amodal-symbol accounts.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>This paper and cited meta-analyses report inconsistent emotion-specific signatures and overlapping neural activations across emotions, arguing against strict modular/amodal-symbol representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Wilson-Mendenhall, Barrett, Simmons, & Barsalou (2011)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Grounding emotion in situated conceptualization', 'publication_date_yy_mm': '2011-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7119.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e7119.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Exemplar Theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Exemplar-based Representation (memory of instances)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A family of representational accounts asserting that categories are represented by stored memory traces of individual exemplars rather than abstract cores or prototypes.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Exemplar Theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>memory-based collection of instances (sparse high-dimensional set)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual knowledge is functionally represented as collections of episodic/situated exemplars in memory; categorization and conceptual behavior arise from similarity-based retrieval and comparison to these stored instances.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains graded category membership, context effects, and classification behavior without requiring abstracted prototypes; can predict classification performance from similarity to exemplars.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>Mentioned as background theoretical work (cited behavioral literature)</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>Behavioral categorization and computational modeling studies cited in background</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Authors adopt exemplar-like view for emotions: emotion concepts are represented by loose collections of situated exemplars (family resemblance), consistent with observed variability across emotion instances.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Authors note limited abstractions may occur but no evidence of rigid conceptual cores; no explicit contradictory empirical evidence presented in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Wilson-Mendenhall, Barrett, Simmons, & Barsalou (2011)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Grounding emotion in situated conceptualization', 'publication_date_yy_mm': '2011-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7119.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e7119.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Family Resemblance / Radial Categories</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Family Resemblance / Radial Category Representations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A representational characterization arguing that categories lack necessary-and-sufficient feature sets and are organized by overlapping similarity chains (family resemblance) or multiple transformed chains (radial structure).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Family Resemblance / Radial Category Models</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>similarity-structured distributed representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Functionally, categorical membership emerges from graded similarity relations among exemplars; concepts are not single-core feature lists but networks of overlapping features and relations producing prototype-like behavior as emergent.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains absence of invariant core properties, graded membership, and variability across category instances including emotions.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>Behavioral literature cited and used to interpret emotion variability in the current fMRI results</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>Behavioral categorization work cited; applied here to interpret neuroimaging evidence of heterogeneous activations for emotion instances.</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Authors argue emotion categories conform to family resemblance/radial structure; fMRI shows many distinct neural assemblies for instances of the same emotion, consistent with this representational format.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>None reported in this paper; authors note people's tendency to mistakenly infer cores but empirical data argue against them.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Wilson-Mendenhall, Barrett, Simmons, & Barsalou (2011)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Grounding emotion in situated conceptualization', 'publication_date_yy_mm': '2011-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7119.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e7119.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Pattern Completion / Simulation Mechanism</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Pattern Completion Mechanism for Conceptual Acts</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A proposed neural mechanism by which partial activation of multimodal concept networks triggers reactivation (pattern completion) of associated perceptual, motor, and interoceptive states to produce situated conceptualizations and consequent emotional states.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Pattern Completion / Simulation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>dynamical reactivation (attractor/pattern completion in distributed networks)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Functionally, partial inputs (e.g., core affect or situational cues) cue stored multimodal assemblies which, via pattern completion, reactivate component modalities (interoception, action plans, percepts) to compose a situated conceptualization that drives behavior and subjective experience.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains rapid, automatic generation of embodied aspects of concepts and emotions, the ability of conceptualization to change core affect and bodily states, and how stored and composed conceptualizations interact.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>Theoretical mechanism described in this paper and instantiated by observed fMRI compositional patterns</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>Interpretation of fMRI situation × concept interaction patterns and temporal separation of situation vs concept periods using catch trials</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Situational influences on concept-period activations (including components not active during situation period) indicate online composition and pattern completion consistent with this mechanism.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>No direct counterevidence in this dataset; mechanism remains a theoretical interpretation of observed dynamical activation patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Wilson-Mendenhall, Barrett, Simmons, & Barsalou (2011)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Grounding emotion in situated conceptualization', 'publication_date_yy_mm': '2011-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7119",
    "paper_id": "paper-a7c5fce05b676cba2af8c489e7c7691cf6c1997b",
    "extraction_schema_id": "extraction-schema-133",
    "extracted_data": [
        {
            "name_short": "Grounded Cognition",
            "name_full": "Grounded Theory of Concepts / Grounded Cognition (Barsalou et al.)",
            "brief_description": "A theoretical framework proposing that concepts are grounded in the brain's modal systems for perception, action, and internal states, and that conceptual representations are multimodal, situated, and arise from the same sensorimotor/interoceptive systems that process instances of those concepts.",
            "citation_title": "here",
            "mention_or_use": "use",
            "theory_name": "Grounded Cognition",
            "theory_type": "embodied simulation / multimodal distributed representation",
            "theory_description": "Conceptual knowledge is functionally represented as distributed, modality-specific activity patterns in perceptual, motor, and interoceptive systems (and their associated multimodal hubs); concepts are instantiated as reactivations (simulations) of the sensorimotor/interoceptive states that accompanied past instances and are embedded within situational context networks.",
            "functional_claims": "Accounts for context-dependent conceptual activation, supports perceptual/motor influences on conceptual processing, explains why concepts trigger action and bodily states, and predicts that conceptual representations will recruit the same neural systems used to perceive/act/interocept during concept use.",
            "evidence_source": "fMRI study (this paper) plus cited behavioral and neuroimaging literature",
            "experimental_paradigm": "Situation listening with immersion + concept-word rating in event-related fMRI with catch-trial separation of situation vs. concept periods",
            "key_result": "Concept-related activations were distributed across modality-specific and multimodal systems and depended on the preceding situational context, consistent with concepts being instantiated via multimodal simulations rather than stored amodal symbols.",
            "supports_theory": true,
            "counter_evidence": "No direct contradictory results reported in this study; authors note variability across emotion markers and lack of one-to-one brain–emotion mapping (cited meta-analyses) which they interpret as supportive rather than contradictory. The paper does not report findings that directly falsify grounded claims.",
            "citation": "Wilson-Mendenhall, Barrett, Simmons, & Barsalou (2011)",
            "uuid": "e7119.0",
            "source_info": {
                "paper_title": "Grounding emotion in situated conceptualization",
                "publication_date_yy_mm": "2011-04"
            }
        },
        {
            "name_short": "Conceptual Act Theory",
            "name_full": "Conceptual Act Theory of Emotion (Barrett et al.)",
            "brief_description": "A theory proposing that emotions are constructed by situated conceptualizations: conceptual acts that use multimodal conceptual knowledge to categorize ongoing changes in core affect, interoception, and perception, thereby producing discrete emotion experiences.",
            "citation_title": "here",
            "mention_or_use": "use",
            "theory_name": "Conceptual Act Theory of Emotion",
            "theory_type": "relational/compositional multimodal representation (embodied simulation)",
            "theory_description": "Emotion concepts are abstract, relational situated conceptualizations that integrate multimodal inputs (setting, agents, actions, interoception, mentalizing) and are composed online from distributed neural circuitry; the activation of a situated conceptualization constitutes the emotional episode (a 'conceptual act').",
            "functional_claims": "Explains instance-to-instance variability of emotion expressions and neural activations, predicts that the same emotion category can have different neural/behavioral signatures depending on situational composition, and claims emotions arise from conceptually categorizing core affect and bodily signals.",
            "evidence_source": "fMRI experiment (this paper); cited meta-analyses and lesion/stimulation/animal studies",
            "experimental_paradigm": "Training on situation types (physical danger vs social evaluation) followed by event-related fMRI where subjects immerse in a situation then rate ease of experiencing a target concept (anger/fear/observe/plan); catch trials separate situation vs. concept periods.",
            "key_result": "Different neural patterns for the same emotion concept (fear/anger) depending on preceding situation type; composed situated conceptualizations recruited distributed multimodal circuitry (overlap across emotions plus situation-specific recruitment), supporting the theory's predictions.",
            "supports_theory": true,
            "counter_evidence": "Authors acknowledge that some subcortical circuits (e.g., PAG) are involved in certain behavioral adaptations but argue these circuits are not emotion-category-specific; no direct contradictory empirical finding reported in this dataset.",
            "citation": "Wilson-Mendenhall, Barrett, Simmons, & Barsalou (2011)",
            "uuid": "e7119.1",
            "source_info": {
                "paper_title": "Grounding emotion in situated conceptualization",
                "publication_date_yy_mm": "2011-04"
            }
        },
        {
            "name_short": "Situated Conceptualization",
            "name_full": "Situated Conceptualization (compositional instances of concepts)",
            "brief_description": "The representational format posited whereby a concept on a specific occasion is represented as an integrated network of background concepts (setting, agents, actions, interoception) forming a situation-specific instantiation.",
            "citation_title": "here",
            "mention_or_use": "use",
            "theory_name": "Situated Conceptualizations",
            "theory_type": "relational network / compositional multimodal representation",
            "theory_description": "Functionally, a situated conceptualization is a transient, composed network of multimodal component activations (perceptual, motor, interoceptive, memory, language) that together represent an instance of a concept tailored to current contextual demands.",
            "functional_claims": "Accounts for contextual variability of concept instantiations, explains how concepts guide perception/action/interoception, and predicts that different situational compositions will recruit different neural subsystems even for the same conceptual label.",
            "evidence_source": "fMRI (this experiment) and behavioral training/imagery procedures described in the paper",
            "experimental_paradigm": "Immersive auditory situation reinstatement then concept-judgment in fMRI (catch-trial design to isolate concept-period activity); main- and interaction-effects analysis to partition concept vs situation contributions.",
            "key_result": "Situated conceptualizations for anger and fear comprised both shared (concept main effects) and situation-specific (situation main effects and interactions) neural components, indicating that concept instantiation is compositional and context-dependent.",
            "supports_theory": true,
            "counter_evidence": "None reported in this dataset; authors emphasize dynamical composition rather than fixed cores.",
            "citation": "Wilson-Mendenhall, Barrett, Simmons, & Barsalou (2011)",
            "uuid": "e7119.2",
            "source_info": {
                "paper_title": "Grounding emotion in situated conceptualization",
                "publication_date_yy_mm": "2011-04"
            }
        },
        {
            "name_short": "Neural Reference Space",
            "name_full": "Neural Reference Space / Distributed Neural Circuitry for Emotion",
            "brief_description": "A distributed set of brain regions (a neural workspace) whose combinations of activations dynamically produce emotional states rather than a one-to-one mapping between emotion categories and specialized modules.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_name": "Neural Reference Space (distributed circuitry)",
            "theory_type": "high‑dimensional distributed activation patterns / assembly-based representation",
            "theory_description": "Emotions are implemented by combinations of activations across a distributed neural network (including insula, medial prefrontal, orbitofrontal, temporal pole, sensory, motor regions, etc.); each emotion instance corresponds to a situation-specific neural assembly drawn from this reference space.",
            "functional_claims": "Explains overlap of neural activations across different emotion categories, accounts for variability in physiological and behavioral markers, and predicts overlapping recruitment of general-purpose systems (attention, memory, language) in emotion.",
            "evidence_source": "Meta-analyses cited (Kober et al., Lindquist et al., Wager et al.) and the present fMRI experiment",
            "experimental_paradigm": "Meta-analysis of neuroimaging studies; event-related fMRI with situation × concept factorial analysis (this paper)",
            "key_result": "Observed widespread overlap in areas active across emotions and situation-dependent recruitment of regions (e.g., parahippocampal gyrus for physical danger; medial PFC for social evaluation), consistent with a distributed reference space rather than discrete emotion modules.",
            "supports_theory": true,
            "counter_evidence": "Some subcortical circuits (e.g., PAG) are consistently engaged in particular defensive behaviors, but authors argue these do not map one-to-one onto emotion categories.",
            "citation": "Wilson-Mendenhall, Barrett, Simmons, & Barsalou (2011)",
            "uuid": "e7119.3",
            "source_info": {
                "paper_title": "Grounding emotion in situated conceptualization",
                "publication_date_yy_mm": "2011-04"
            }
        },
        {
            "name_short": "Amodal Symbolic / Basic Emotion",
            "name_full": "Amodal Symbolic and Basic Emotion Approaches (prototype/module views)",
            "brief_description": "Contrasted theoretical approaches that posit emotion concepts as amodal, symbol-like entities or that emotions are innate modules producing stereotyped responses to triggers.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_name": "Amodal Symbolic / Basic Emotion Theories",
            "theory_type": "symbolic / modular",
            "theory_description": "These views functionally represent emotions as discrete, possibly innate modules or amodal symbols with a fixed core of content and stereotyped response profiles that are triggered by relevant external conditions.",
            "functional_claims": "Predicts consistent physiological/behavioral/neural signatures for each basic emotion and minimal context-dependence; accounts for universality claims and rapid emotion elicitation.",
            "evidence_source": "Mentioned in the introduction (historical theories); contrasted with current data",
            "experimental_paradigm": "Varied (behavioral observation, cross-cultural studies, lesion/electrophysiology cited historically)",
            "key_result": "Authors report that empirical reviews/meta-analyses show substantial variability in markers across instances and overlap in brain activations, challenging strict module/amodal-symbol accounts.",
            "supports_theory": false,
            "counter_evidence": "This paper and cited meta-analyses report inconsistent emotion-specific signatures and overlapping neural activations across emotions, arguing against strict modular/amodal-symbol representations.",
            "citation": "Wilson-Mendenhall, Barrett, Simmons, & Barsalou (2011)",
            "uuid": "e7119.4",
            "source_info": {
                "paper_title": "Grounding emotion in situated conceptualization",
                "publication_date_yy_mm": "2011-04"
            }
        },
        {
            "name_short": "Exemplar Theory",
            "name_full": "Exemplar-based Representation (memory of instances)",
            "brief_description": "A family of representational accounts asserting that categories are represented by stored memory traces of individual exemplars rather than abstract cores or prototypes.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_name": "Exemplar Theory",
            "theory_type": "memory-based collection of instances (sparse high-dimensional set)",
            "theory_description": "Conceptual knowledge is functionally represented as collections of episodic/situated exemplars in memory; categorization and conceptual behavior arise from similarity-based retrieval and comparison to these stored instances.",
            "functional_claims": "Explains graded category membership, context effects, and classification behavior without requiring abstracted prototypes; can predict classification performance from similarity to exemplars.",
            "evidence_source": "Mentioned as background theoretical work (cited behavioral literature)",
            "experimental_paradigm": "Behavioral categorization and computational modeling studies cited in background",
            "key_result": "Authors adopt exemplar-like view for emotions: emotion concepts are represented by loose collections of situated exemplars (family resemblance), consistent with observed variability across emotion instances.",
            "supports_theory": true,
            "counter_evidence": "Authors note limited abstractions may occur but no evidence of rigid conceptual cores; no explicit contradictory empirical evidence presented in this paper.",
            "citation": "Wilson-Mendenhall, Barrett, Simmons, & Barsalou (2011)",
            "uuid": "e7119.5",
            "source_info": {
                "paper_title": "Grounding emotion in situated conceptualization",
                "publication_date_yy_mm": "2011-04"
            }
        },
        {
            "name_short": "Family Resemblance / Radial Categories",
            "name_full": "Family Resemblance / Radial Category Representations",
            "brief_description": "A representational characterization arguing that categories lack necessary-and-sufficient feature sets and are organized by overlapping similarity chains (family resemblance) or multiple transformed chains (radial structure).",
            "citation_title": "",
            "mention_or_use": "use",
            "theory_name": "Family Resemblance / Radial Category Models",
            "theory_type": "similarity-structured distributed representation",
            "theory_description": "Functionally, categorical membership emerges from graded similarity relations among exemplars; concepts are not single-core feature lists but networks of overlapping features and relations producing prototype-like behavior as emergent.",
            "functional_claims": "Explains absence of invariant core properties, graded membership, and variability across category instances including emotions.",
            "evidence_source": "Behavioral literature cited and used to interpret emotion variability in the current fMRI results",
            "experimental_paradigm": "Behavioral categorization work cited; applied here to interpret neuroimaging evidence of heterogeneous activations for emotion instances.",
            "key_result": "Authors argue emotion categories conform to family resemblance/radial structure; fMRI shows many distinct neural assemblies for instances of the same emotion, consistent with this representational format.",
            "supports_theory": true,
            "counter_evidence": "None reported in this paper; authors note people's tendency to mistakenly infer cores but empirical data argue against them.",
            "citation": "Wilson-Mendenhall, Barrett, Simmons, & Barsalou (2011)",
            "uuid": "e7119.6",
            "source_info": {
                "paper_title": "Grounding emotion in situated conceptualization",
                "publication_date_yy_mm": "2011-04"
            }
        },
        {
            "name_short": "Pattern Completion / Simulation Mechanism",
            "name_full": "Pattern Completion Mechanism for Conceptual Acts",
            "brief_description": "A proposed neural mechanism by which partial activation of multimodal concept networks triggers reactivation (pattern completion) of associated perceptual, motor, and interoceptive states to produce situated conceptualizations and consequent emotional states.",
            "citation_title": "here",
            "mention_or_use": "use",
            "theory_name": "Pattern Completion / Simulation",
            "theory_type": "dynamical reactivation (attractor/pattern completion in distributed networks)",
            "theory_description": "Functionally, partial inputs (e.g., core affect or situational cues) cue stored multimodal assemblies which, via pattern completion, reactivate component modalities (interoception, action plans, percepts) to compose a situated conceptualization that drives behavior and subjective experience.",
            "functional_claims": "Explains rapid, automatic generation of embodied aspects of concepts and emotions, the ability of conceptualization to change core affect and bodily states, and how stored and composed conceptualizations interact.",
            "evidence_source": "Theoretical mechanism described in this paper and instantiated by observed fMRI compositional patterns",
            "experimental_paradigm": "Interpretation of fMRI situation × concept interaction patterns and temporal separation of situation vs concept periods using catch trials",
            "key_result": "Situational influences on concept-period activations (including components not active during situation period) indicate online composition and pattern completion consistent with this mechanism.",
            "supports_theory": true,
            "counter_evidence": "No direct counterevidence in this dataset; mechanism remains a theoretical interpretation of observed dynamical activation patterns.",
            "citation": "Wilson-Mendenhall, Barrett, Simmons, & Barsalou (2011)",
            "uuid": "e7119.7",
            "source_info": {
                "paper_title": "Grounding emotion in situated conceptualization",
                "publication_date_yy_mm": "2011-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [],
    "cost": 0.014291749999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>NIH Public Access</h1>
<p>Author Manuscript
Neuropsychologia. Author manuscript; available in PMC 2012 April 1.
Published in final edited form as:
Neuropsychologia. 2011 April ; 49(5): 1105-1127. doi:10.1016/j.neuropsychologia.2010.12.032.</p>
<h2>Grounding Emotion in Situated Conceptualization</h2>
<p>Christine D. Wilson-Mendenhall,<br>Emory University<br>Lisa Feldman Barrett,<br>Northeastern University<br>W. Kyle Simmons, and<br>The Laureate Institute for Brain Research<br>Lawrence W. Barsalou<br>Emory University</p>
<h4>Abstract</h4>
<p>According to the Conceptual Act Theory of Emotion, the situated conceptualization used to construe a situation determines the emotion experienced. A neuroimaging experiment tested two core hypotheses of this theory: (1) different situated conceptualizations produce different forms of the same emotion in different situations, (2) the composition of a situated conceptualization emerges from shared multimodal circuitry distributed across the brain that produces emotional states generally. To test these hypotheses, the situation in which participants experienced an emotion was manipulated. On each trial, participants immersed themselves in a physical danger or social evaluation situation and then experienced fear or anger. According to Hypothesis 1, the brain activations for the same emotion should differ as a function of the preceding situation (after removing activations that arose while constructing the situation). According to Hypothesis 2, the critical activations should reflect conceptual processing relevant to the emotion in the current situation, drawn from shared multimodal circuitry underlying emotion. The results supported these predictions and demonstrated the compositional process that produces situated conceptualizations dynamically.</p>
<p>Until recently, conceptualization has played a relatively peripheral role in theories of emotion (but see Fehr \&amp; Russell 1984; Russell, 1991; Russell \&amp; Fehr, 1994). In basic emotion approaches (e.g., Allport, 1924; Ekman, 1972; Irard, 1971; MacDougall, 1928/1908; Panksepp, 1998; Tomkins, 1962, 1963), the central hypotheses are that emotions reflect an inborn instinct, and that the mere presence of relevant external conditions triggers evolved brain mechanisms in a stereotyped and obligatory way (e.g., a snake triggers the fear circuit; Ohman, Carlsson, Lundqvist, \&amp; Ingvar, 2007; Ohman \&amp; Mineka, 2001). In appraisal approaches to emotion (e.g., Arnold, 1960a,b; Ellsworth \&amp; Scherer, 2003; Frijda, 1986; Lazarus, 1991; Roseman, 1991), the central hypotheses are that emotions arise from a meaning analysis of the situation in terms of goals, needs, or concerns, and that these conceptualizations of external situational conditions elicit basic emotions independent of</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>any further conceptual processing. In both basic emotion approaches, emotions exist independently of human concepts for them. The cognitive system might conceptually represent what an emotion is and what is likely to occur when one is elicited, but these conceptualizations do not play central roles in emotion itself.</p>
<p>Recent theoretical developments, however, give conceptualization a central role in the construction of emotional episodes (Barrett, 2006a, 2009a). According to this approach, conceptualizing a situation in a particular way causes it to be experienced as an emotion (where by situation we mean not only an environmental setting and the physical entities and agents it contains, but also the dynamic actions that agents perform, and the events, interoceptive sensations, and mentalizing they experience). As the brain represents successive situations one after another, conceptual interpretation of each situationsometimes taking the form of an emotion-creates a unified, meaningful representation of subjective experience, cognition, and the body in context, and then controls subsequent experience, cognition, and action.</p>
<p>In this article, we begin by presenting a grounded theory of the conceptual system that underlies our account of how conceptualization produces emotion. The theory's central assumptions are: (1) a concept is grounded in the systems for perception, action, and internal states that process its instances; (2) the situated conceptualization that represents a concept on a specific occasion emerges from a network of concepts to represent the concept coherently in the current situation; (3) situated conceptualizations represent abstract concepts, including emotion concepts; (4) once active, situated conceptualizations produce subsequent actions, internal states, and perceptual construals. After laying this theoretical groundwork, we present the Conceptual Act Theory of Emotion in which situated conceptualizations for emotion concepts play the central role in producing emotion. Finally, we present an experiment that tests two key hypotheses of Conceptual Act Theory: (1) different situated conceptualizations represent an emotion concept (e.g., fear) in different situations; and (2) the composition of situated conceptualizations reflects diverse contributions from distributed neural circuitry that produces emotional states dynamically.</p>
<h1>A Grounded Theory of the Human Conceptual System</h1>
<p>In this section, we summarize a theory of concepts developed elsewhere (e.g., Barsalou, 1999, 2003a,b, 2005a,b, 2008a,b,c; Simmons \&amp; Barsalou, 2003). Specifically, this theory assumes that concepts are grounded in situations, the body, and the brain's modal systems for perception, action, and internal states ${ }^{1}$ (e.g., Anderson, in press; Martin, 2001, 2007; Damasio, 1989; Meyer \&amp; Damasio, 2009). We focus on non-emotion concepts initially to illustrate properties of the human conceptual system. In the subsequent section, we extend these properties to emotion concepts in the Conceptual Act Theory of Emotion. Much detail will be omitted from these accounts that can be found in the articles referenced (and especially in Barrett, 2006a; Barrett, Barsalou, Lindquist, \&amp; Wilson-Mendenhall, 2010).</p>
<p>Concepts-A concept aggregates information about category instances into some sort of integrated representation (e.g., Barsalou, 2003a, 2005a; Barsalou \&amp; Hale, 1993; Murphy, 2002). The concept of car, for example, aggregates diverse information about cars into a loosely organized representation that includes properties (e.g., engine), relations (e.g., drivers operate cars), prototypes (e.g., the typical car is a sedan), rules (e.g., for something to</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>be a car, it must use an engine that drives four wheels to transport a small number of people along a road), and exemplars (e.g., instances of sedans, coupes, station wagons, etc.). ${ }^{2}$</p>
<p>Concepts develop for aspects of experience that are relevant repeatedly across situations. Because cars are a frequently relevant aspect of experience, a concept develops in memory to represent them. Concepts similarly develop for other diverse aspects of human experience, including objects, agents, and settings in physical situations (e.g., keys, mechanics, garage). Additionally, concepts develop to represent the behavior of objects, agents, and settings (e.g., skidding, driving, bustling). From simpler concepts, more complex concepts emerge for events (e.g., trip). Concepts similarly develop for a wide variety of internal states including interoceptions and mentalizing (e.g., thirst, fatigue, doubt), as well as for the properties and relations that describe instances of concepts (e.g., blue, slow, intense, above, after, cause, intend). Although concepts reflect experience to a considerable extent, they undoubtedly have biological bases that scaffold learning (Barsalou, 1999, 2008a; Carey, 2009; Rips, 2010; Simmons \&amp; Barsalou, 2003).</p>
<p>Theory and research strongly suggest that concepts do not have conceptual cores, namely, conceptual content that is necessary and sufficient for membership in the associated category. In a famous philosophical argument, Wittgenstein's (1953) concluded that a conceptual core cannot be found for the category of games (e.g., no property is true of all category members). Since then, researchers have similarly argued that natural categories do not typically have conceptual cores. Instead, loosely distributed similarity relations between category members-taking the form of a family resemblance or radial category-appear to structure most categories (e.g., Lakoff, 1987; Rosch \&amp; Mervis, 1975). ${ }^{3}$ Nevertheless, people often believe mistakenly that categories do have cores, even when clear exceptions exist (e.g., Brooks \&amp; Hannah, 2006), perhaps because a word for the category that always takes the same form implies that a stable conceptual core analogously represents its meaning (e.g., Barsalou, 1989; James, 1950/1890). Theories of psychological essentialism similarly note people's (often unjustified) propensity for creating conceptual cores (e.g., Gelman, 2003).</p>
<p>Exemplar theories of categorization further illustrate that loose collections of memories for category members can produce sophisticated classification behavior, demonstrating that abstractions for prototypes and rules are not necessary (e.g., Medin \&amp; Schaffer, 1978; Nosofksy, 1984). Neural net systems similarly demonstrate that only loose statistical coherence is necessary for sophisticated categorization (e.g., McClelland \&amp; Rumelhart, 1985). To the extent that abstraction does occur for a category, it may only occur partially across small sets of category instances (e.g., Medin \&amp; Ross, 1989; Spalding \&amp; Ross, 1994); it may primarily reflect the abstraction of non-defining properties and relations that can be used to describe category members in a dynamcial manner (e.g., Barsalou, 2003a, 2005a); it may reflect online abstraction at retrieval, rather than stored abstractions in memory (e.g., Hintzman, 1986).</p>
<p>The absence of conceptual cores will play a central role in our account of emotion concepts. From hereon, our treatment of concepts assumes that they do not have cores but are instead represented by loose collections of situated exemplars, accompanied by the various forms of limited abstraction just noted.</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Once concepts become established in memory, they play central roles throughout cognition, supporting perception, categorization, inference, and many other processes (e.g., Barsalou, 2003b; Murphy, 2002). As people experience a situation, they categorize the agents, objects, setting, behaviors, events, properties, relations, bodily states, mental states, and so forth that are present. As some aspect of experience is perceived, it projects onto all concepts in parallel, with concepts competing to categorize the aspect, with the best-fitting concept winning (e.g., McClelland \&amp; Rumelhart, 1981). Once an entity has been categorized, categorical inferences follow, including inferences about how the entity is likely to behave, how one can best interact with the entity, the likely value to be obtained from interacting with the entity, and so forth. Such inferences result from accessing category knowledge associated with the concept used to categorize the current instance, and then generalizing this knowledge to the instance.</p>
<p>Multiple modalities underlie concepts-Concepts originate and operate in the context of continuous situated activity (Barsalou, 2003b, 2005b, 2008c; Barsalou, Breazeal, \&amp; Smith, 2007; Yeh \&amp; Barsalou, 2006). As situated activity unfolds, numerous modalities and systems that process perception, action, and internal states respond continually (e.g., vision, audition, motor planning and execution, interoception, mentalizing, attention, reward, affect, executive processing, language, memory, reasoning). Depending on the concept, a particular profile of modalities and systems is more or less relevant (e.g., Cree \&amp; McRae, 2003). For example, the modality of audition is often relevant for musical instruments but not for fruit, whereas the modalities of taste and smell are often relevant for fruit but not for musical instruments (which is not to say that audition is unimportant for representing a crunchy apple or that smell is irrelevant for representing an old wooden guitar). In general, the informational content of a concept can be viewed as a collection of the multimodal information that has been experienced and processed for its instances. Depending on the particular modalities relevant, the resulting profile of activity becomes stored in distributed neural circuitry that processes the concept, thereby creating a multimodal representation of the relevant processing that typically occurs.</p>
<p>Extensive evidence now exists that different kinds of concepts emerge from different multimodal systems in the brain (cf. McClelland, 2010). Depending on the modalities relevant for processing a concept's instances, particular modal areas of the brain store information about the category and can later represent the category in the absence of actual instances. Martin (2001, 2007), for example, has shown that different multimodal profiles represent living vs. non-living things. Other research has similarly established the multimodal profiles that represent the self and others (e.g., Northoff et al., 2006; Van Overwalle, 2009; cf. Legrande \&amp; Ruby, 2009), people, buildings, and tools (e.g., Simmons, Reddish, Bellgowan, \&amp; Martin, 2010), the external world vs. internal states (e.g., Golland, Golland, Bentin, \&amp; Malach, 2008), and so forth.</p>
<p>Situated conceptualizations-Concepts are rarely represented in a vacuum. When the concept for car becomes active, it is not represented in isolation, floating in space, but is instead represented in a meaningful background situation (e.g., Barsalou, 2003b, 2005b, 2008c; Barsalou, Niedenthal, Barbey, \&amp; Ruppert, 2003). A car, for example, might be represented in a garage, parking lot, or gas station, or on a dirt road or highway. Many empirical studies demonstrate the extensive presence of situational information as people represent and use concepts (e.g., Bar, 2004; Barsalou \&amp; Wiemer-Hastings, 2005; Chaigneau, Barsalou, \&amp; Zamani, 2009; Wu \&amp; Barsalou, 2009; for a review, see Yeh \&amp; Barsalou, 2006).</p>
<p>We refer to the representation of a concept in a background situation as a situated conceptualization. Typically, situated conceptualizations include a setting, agents, objects, behaviors, events, and internal states, each represented by relevant concepts. Thus, the</p>
<p>representation of a car on a particular occasion exists within a network of background concepts that represent elements of the entire situation. Furthermore, tremendous diversity exists in the particular background concepts that situate a concept on different occasions. Rather than the concept being represented in a rigid manner across situations, it is represented in widely varying sets of background concepts that contextualize it in each situation.</p>
<p>From the perspective of grounded cognition, situated conceptualizations are also responsible for producing the action, internal states, and perceptual construals that underlie goal-related activity in the current situation. Because modalities for action, internals states, and perceptual construals are typically active when a concept is learned, situated conceptualizations generate activity in these systems as they become active on later occasions. On activating the concept for apple, a situated conceptualization might activate representations of actions for eating the apple, representations of internal states such as satiation and pleasure, and perceptual construals that distort taste toward the typical taste of an apple (e.g., Goldstone, 1995; Hansen, Olkkonen, Walter, Gegenfurtner, 2006). Not only does apple represent instances of the concept, it also controls interactions with instances and predicts the resultant events.</p>
<p>In Barrett et al. (2010), we further proposed a distinction between concepts that have situated conceptualizations as backgrounds vs. concepts that are situated conceptualizations. In general, concrete concepts such as chair refer to part of a situation and are contextualized when surrounding background concepts represent the remainder of a situation in a situated conceptualization (e.g., concepts for living room, sitting, feeling comfortable). Conversely, abstract concepts such as convince typically refer to an entire situation, not just to part of one, such that an entire situated conceptualization represents them. Convince, for example, integrates an agent, other people, an idea, communicative acts, and possible changes in belief, all organized with a variety of relations, such as the relation of one person having an idea, talking with another, conveying the idea to the other, attempting to change a belief, and so forth (Wilson-Mendenhall, Simmons, Martin, \&amp; Barsalou, 2010). In other words, abstract concepts like convince are relational structures that integrate many different concepts in a situated conceptualization.</p>
<p>Finally, we assume that many situated conceptualizations are associated with a given concept, reflecting the variety of situations in which it is experienced (Barsalou, 2003b, 2008c). For convince, different situated conceptualizations represent convincing a friend, parent, policeman, mugger, audience, and so forth. In each situation, the respective conceptualization supports situated interaction in the relevant situation. Rather than the category having a conceptual core, a set of situated exemplars represents it that exhibit family resemblance and radial structure, accompanied by limited abstractions.</p>
<h1>The Conceptual Act Theory of Emotion</h1>
<p>In the Conceptual Act Theory of Emotion, we propose that emotion concepts are abstract concepts that work in fundamentally the same as way as other kinds of abstract concepts. Like other abstract concepts, emotion concepts aggregate diverse information within an instance, referring to an entire situation, not just to part of one. Like other abstract concepts, emotion concepts support categorization and inference, and also control subsequent action, internal states, and perceptual construals. Like other concepts, emotion concepts do not have conceptual cores but are represented by loose collections of situated conceptualizations. In this section, we first address the role of situated conceptualizations in representing emotion, and then address multimodal contributions to emotion concepts. Finally we address the roles of emotion concepts in producing the conceptual acts that generate emotion. Further detail on this account can be found in Barrett (2006a) and Barrett et al. (2010).</p>
<p>Situated conceptualizations represent emotion concepts—A key assumption of our theoretical approach is that emotion concepts, like other abstract concepts (e.g. convince), refer to entire situations, and thereby represent settings, agents, objects, actions, events, interoceptions, and mentalizing. In other words, an emotion concept is a relational structure that integrates multiple parts of an experienced situation.</p>
<p>We further assume that a specific emotion concept contains a large set of situated conceptualizations that produce emotion in many different kinds of situations, with each situated conceptualization producing a different form of the emotion. Consider one possible situated conceptualization associated with fear, where a runner becomes lost on a wooded trail at dusk. In this situated conceptualization, concepts for forest, night, animals, thirst, confusion, and many others become integrated meaningfully to represent fear, including the associated internal experience and potential actions. Consider another possible situated conceptualization associated with fear, where someone is unprepared to give an important presentation at work. In this situated conceptualization, a different set of concepts represents the situation, including presentation, speaking, audience, supervisor, and many others. Again, the integrated representation of diverse concepts into a situated conceptualization constitutes an instance of fear, including associated internal experience and action.</p>
<p>From this perspective, fear cannot be understood independently of an agent conceptualizing his- or herself in a particular situation. This is not a new insight about emotion but one that emerged in the first half of the 20th century, appearing, for example, in the writings of William James (1994/1894, p. 206). Fear can look and feel quite differently in different instances. When you fear a flying cockroach, you might grab a magazine and swat it; when you fear disappointing a love one, you might think of other ways to make them feel good about you; when you fear a mysterious noise late at night, you might freeze and listen; when you fear giving a presentation, you might ruminate about audience reactions or over-prepare; when you fear getting a flu shot, you might cringe anticipating the pain; when you fear hurting a friend's feelings, you might tell a white lie. Sometimes you will approach in fear, and sometimes you will avoid. Sometimes your heart rate will go up, and sometimes it will go down. Whatever the situation demands.</p>
<p>The presence of diverse situated conceptualizations for an emotion explains the Emotion Paradox (Barrett, 2006a,b; Barrett, Lindquist et al. 2007). If, as basic emotion theorists assume, an emotion like fear is associated with a module that always executes in the same manner to produce the same stereotyped cascade of responses, then why do the neural and bodily states associated with fear show tremendous variability across instances (for reviews of this variability, see Barrett, 2006b; Barrett, Lindquist et al. 2007; for a discussion see Barrett, 2009a)? Situated conceptualizations offer a natural account of this variability: If different situated conceptualizations represent the same emotion category, then differences among them across all the modalities and systems that process settings, actions, and internal states are likely to produce considerable variability in facial actions, heart rate patterns, breathing patterns, and neural activations. Furthermore, because there is not one bodily signature for each emotion, the same body state across different situations can be conceptualized as different emotions, depending on the situated conceptualization active to interpret it (cf. Dunlap, 1932).</p>
<p>Finally, as described earlier for concepts in general, we assume that the situated conceptualizations representing an emotion bear loose similarity relations to one another, as in a family resemblance or radial category. To the extent that abstractions exist for an emotion, they are not core properties but instead represent relevant information within particular situations, or non-defining properties used to describe the emotion across situations. The low consistency of emotion markers-facial actions, heartrate, breathing,</p>
<p>skin conductance, action, and neural activity—across reviews and meta-analyses support the lack of core conceptual content for emotions (e.g., Barrett, 2006b; Barrett, Lindquist, et al., 2007; Kober, Barrett et al., 2008; Lindquist et al., submitted; Wager, Barrett, et al., 2008), implying that loose collections of exemplars represent emotions instead (Barrett, 2006a; Fehr \&amp; Russell, 1984; Russell, 1991; Russell \&amp; Fehr, 1994).</p>
<p>Composed vs. stored situated conceptualizations-So far we have focused on situated conceptualizations stored in memory that represent concepts, including emotion concepts. We further assume, however, that novel situated conceptualizations are composed online, tailored to the current situation (e.g., Hoenig, Sim, Bochev, Herrnberger, \&amp; Kiefer, 2008). Again, imagine being unprepared for a presentation at work and experiencing fear. If similar experiences have occurred previously, then a situated conceptualization that represents them might be retrieved to generate inferences about the current situation and guide behavior. If, however, the current situation is not exactly like any of these previous situations, the situated conceptualization retrieved may be adapted somewhat, incorporating important information from the situation, and retrieving further elaborative information from memory to integrate all the active information coherently. As a result, a novel situated conceptualization is composed online, different from other situated conceptualizations stored in memory for fear. In turn, the composed conceptualization becomes stored with fear, augmenting its stored collection of situated conceptualizations.</p>
<p>As this example illustrates, we assume that situated conceptualizations exist in two forms. On the one hand, memories of previous situated conceptualizations represent a concept in memory. On the other hand, new conceptualizations are composed online that combine a stored conceptualization with information about the current situation and other information in memory needed to integrate them. This relation between stored and composed conceptualizations will be central in drawing predictions for the experiment later and for explaining its results.</p>
<p>Multiple modalities and systems represent emotion concepts-Like all concepts, emotion concepts originate and operate in the context of continuous situated activity, with situations typically including a physical setting, agents, objects, and actions in the world, interoceptive sensations from the body, and mentalizing related to prospective and retrospective thought. Over the course of situated activity, numerous modalities and systems in the brain and body respond continually to represent the situation, including exteroceptive perception, interoception, core affect (valuation and salience processes that underlie experiences of pleasure/displeasure and arousal), attention, categorization, executive processing, episodic memory, action, language, reasoning, and so forth.</p>
<p>Meta-analyses of emotion research support the hypothesis that multiple modalities and systems are engaged during the experience and perception of emotion (Kober, Barrett et al., 2008; Lindquist et al., submitted; Wager, Barrett, et al., 2008). Furthermore, diverse studies on animals, patients with brain damage, electrical brain stimulation, and brain imaging clearly show that different emotion categories do not correspond consistently and specifically to distinct brain modules (for reviews, see Barrett, 2006b, 2009a; Barrett et al., 2007). For example, subcortical circuits involving the periaqueductal gray (PAG) underlie individual behavioral adaptations for freezing, defensive aggression, and withdrawal, respectively (Bandler, Keay, Floyd, \&amp; Price, 2000; Bandler \&amp; Shipley, 1994), and an increase in PAG activity is evident in a meta-analytic summary of neuroimaging studies on emotion (Kober et al., 2008). Notably, however, these circuits do not correspond to particular emotion categories in a one-to-one fashion (Barrett, 2009a; Barrett et al., 2007). Even rats display various combinations of freezing, defensive aggression, and withdrawal when faced with a threat assumed to produce a fear state, varying with the situational</p>
<p>context (Bouton, 2005; Fanselow, 1994; Iwata \&amp; LeDoux, 1988; Reynolds \&amp; Berridge, 2002; Vazdarjanova \&amp; McGaugh, 1998; cf. Barrett, 2009a).</p>
<p>Rather than there being a unique module in sub-cortical brain areas for an emotion like fear, emotions appear to result from distributed circuitry throughout the brain that implements perception, action, interoception, core affect, attention, executive processing, memory, language, reasoning, and so forth. Indeed previous meta-analyses of brain areas active for emotion across various tasks have consistently found that distributed circuitry referred to as a "neural reference space" or a "neural work space" produces emotion (Barrett, 2009b; Barrett, Mesquita et al., 2007; Lindquist et al., submitted ). Within this distributed circuitry, diverse brain states for a given emotion arise, each corresponding to a different situated conceptualization. Rather than a discrete module implementing an emotion, distributed circuitry across the emotion reference space produces an infinite number of situationspecific neural assemblies. Furthermore, the assemblies associated with the instance of one emotion category are not functionally specific, given that they can overlap considerably with assemblies for instances of other emotions.</p>
<p>Within the distributed neural circuitry that produces emotion, the particular processing areas critical for a specific emotion concept are typically active across multiple emotions, and also for basic cognitive processes (e.g., Duncan \&amp; Barrett, 2007; for a similar view, see Pessoa, 2008). As demonstrated by a recent meta-analysis of the neuroimaging literature (with both methodological and statistical advantages over previous meta-analyses; Wager et al., 2007), the brain areas active during both the perception and the experience of anger, disgust, happiness, sadness, and fear exhibited substantial overlap (Lindquist et al., submitted). All emotion states except the experience of fear (but including the perception of fear) were associated with significant increases in amygdala activation, consistent with the idea that the amygdala is important for representing anything with motivational relevance, particularly if uncertainty is present. Similarly, most emotions were associated with significant activation in anterior insula, likely because this part of the insula is particularly important for representing affective feelings in awareness (Craig 2002, 2009). Dorsomedial prefrontal areas were also active across emotions, because representing self and others is often important (Mitchell, 2009a; Northoff et al., 2006; Van Overwalle, 2009). Similarly, orbitofrontal cortex was active across emotions to represent affect and expected outcomes in a context-sensitive manner (Kringelbach \&amp; Rolls, 2004; Schoenbaum \&amp; Esber, 2010), as were a host of other areas typically involved in language, executive attention, and social processing (e.g., lateral prefrontal cortex, the temporal poles, and temporo-parietal junction). Of course, we are not claiming that there are no differences how the brain implements different examplars for an emotion concept. The brain state for a situated conceptualization of fear can be distinguished from one for anger, or even a different situated conceptualization for fear, given that each situated conceptualization reflects a different pattern across modalities. Instead, the claim is that all emotions draw on shared distributed circuitry throughout the brain, with each situated conceptualization representing a different pattern in neural space.</p>
<p>In general, the distributed circuitry that produces a specific instance of emotion can be viewed as the set of brain areas required for processing the information that is currently relevant. As described earlier for concepts in general, the modalities that become active to represent a concept reflect the relevant information that must be processed (e.g., Cree \&amp; McRae, 2003; Martin, 2001, 2007; Northoff et al., 2006; Van Overwalle, 2009; Simmons et al., 2010; Golland, et al., 2008). To the extent that different instances of the same emotion require the processing of different information, they should draw on different brain regions. To the extent that instances of the two different emotions require processing similar information, they should draw on similar brain regions.</p>
<p>Conceptual acts produce emotion during situated activity—Because emotions occur in the context of situated activity, multiple systems in the brain and body represent this activity continually, including systems that underlie perception, action, attention, executive control, core affect, interoception, episodic memory, language, and mentalizing. As these systems respond continually to represent and control situated activity, conceptual acts occur periodically that classify certain patterns of multimodal activity as emotions. Initially, a stored situated conceptualization for an emotion concept classifies a complex distributed pattern of activity as an instance, which is then elaborated with situationallyrelevant information to compose an online conceptualization. Within milliseconds, via pattern completion mechanisms, the resulting situated conceptualization has the potential to change core affect and other bodily responses associated with the emotion, along with relevant actions and perceptual construals. Most importantly, the situated conceptualization determines the emotion experienced-what we mean by a conceptual act. Because the conceptualization is grounded in modalities for perception, action, and internal states, and because it controls these modalities, emotion emerges from its activation-the conceptualization does not merely describe the emotion symbolically. Importantly, we assume that these conceptual acts are typically not conscious deliberate events, but are often unconscious and relatively automatic, analogous to how perception, action, and cognition often proceed unconsciously (Barrett, 2006a; Barrett et al. 2010), although they are likely not free from the influences of executive attention (Barrett et al., 2004; Lindquist \&amp; Barrett, 2008). ${ }^{4}$</p>
<p>Initiation and control of bodily states, action, and perceptual construal—As a situated conceptualization for an emotion concept is composed online, it produces a variety of responses via pattern completion inferences. Although a person is always in some state of core affect (pleasure or displeasure with some degree of arousal; Barrett, 2006a; Barrett \&amp; Bliss-Moreau, 2009; Russell \&amp; Barrett, 1999), a situated conceptualization has the capacity to shift core affect toward a state typically experienced during emotion episodes for a particular kind of situation. Along with core affect, the situated conceptualization produces related changes in bodily states, such as muscle tension and visceral activity. Additionally, the situated conceptualization may initiate relevant actions that are typically associated with the emotion in this situation, with core affect and bodily states often motivating and energizing these actions. Finally, the situated conceptualization may produce perceptual construals of the current situation, biasing and distorting perception toward typical experiences associated with the respective type of situation. Importantly, because many situated conceptualizations can represent a particular emotion concept, each is likely to produce different pattern completion inferences across bodily states, action, and perceptual construal, leading to a wide variety of emotional responses.</p>
<p>Again consider situated conceptualizations for fear. If someone experiences becoming lost in the woods at night, a relevant situated conceptualization for fear becomes active. As a result, core affect might shift into feelings of strong negative valence, which initially encourage freezing behavior but that then increase arousal significantly, thereby energizing subsequent actions, such as searching memory and the environment for the correct route. During this evolving process, noises in the forest may be construed perceptually as ominous and threatening. Analogously, as someone stumbles through a work presentation</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>unprepared, a situated conceptualization for fear in this situation becomes active. As a result, core affect might shift info feelings of negative valence, suggesting that a problem has just arisen, and it might increase arousal, thereby energizing the executive system to generate a compensatory strategy. The situated conceptualization may further engage the attentional system to focus on the supervisor, and to inhibit the motor system from performing further actions unless absolutely necessary. At the same time, the supervisor's facial actions may be construed perceptually as conveying intense disappointment. As these examples illustrate, when a situated conceptualization stored with an emotion concept becomes active, it has multiple concrete effects on perception, action, and internal states. It produces the emotion.</p>
<h1>Overview and Predictions</h1>
<p>We present a neuroimaging experiment that tests the core hypotheses about emotion concepts in the Conceptual Act Theory of Emotion. Specifically, the experiment assessed Conceptual Act Theory's hypotheses that different situated conceptualizations represent the same emotion when it is experienced in different situations, and that the composition of a situated conceptualization reflects contributions from diverse sources of information in the distributed neural circuitry that produces emotion.</p>
<p>Experiment overview-In an initial training phase, participants became familiar with two situation types. Importantly, these situations were constructed so that a participant could experience either anger or fear within the context created. One situation type was associated with physical danger brought on by one's own carelessness. On becoming lost during a spontaneous run in the woods at dusk, for example, one could fear bodily harm (e.g., starvation or animal predators) or experience anger directed toward oneself (e.g., for running at night or not being familiar with the route). The other situation type was associated with social evaluation in unfair circumstances. For example, on being unprepared for a work presentation because others on the team did not contribute, one could fear critical judgment (e.g., from a supervisor) or experience anger directed towards others (e.g., at co-workers). Table 1 presents additional examples of these two situation types. On two separate days before the critical scans, participants listened to situations of each type and rated each situation for familiarity, imagery, and their ability to "be there" (i.e., immerse oneself in the situation). As participants listened to a situation, they were instructed to immerse themselves in it as deeply as possible. Descriptions of the situations were written from the first person perspective and contained various details designed to induce immersion. ${ }^{5}$</p>
<p>The training versions of the situations were longer in duration than was optimal for use in a scanner. For this reason, shorter core versions were written that captured the central components of the longer full versions. Table 1 presents examples. During training, participants were told about the relation between the full and core version of each situation, and practiced generating the full version while listening to the core version. This ensured that participants were prepared to imagine the full version of each situation as they listened to the core version later in the scanner.</p>
<p>On critical trials during scanning, participants first listened to one of 30 physical danger or to one of 30 social evaluation core situations mixed randomly together. Following the situation, participants heard the word for one of four concepts, again mixed randomly:</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>anger, fear, observe, or plan. Participants' task on hearing the concept word was to rate how easily they experienced the concept in the given situation. This method was designed so that participants would first immerse themselves in the situation, and then later conceptualize this situated activity as an instance of anger, fear, observe, or plan. Of primary interest was to examine if, as the theory predicts, different patterns of brain activity occurred when an emotion (fear or anger) was conceptualized in two different types of situations. Again, all situations were developed so that any of the concepts could be experienced in the context of the situation, especially fear and anger. The two non-emotion abstract concepts were included for comparison purposes (observe and plan). ${ }^{6}$</p>
<p>Each of the four concepts was presented after each of the 30 physical danger situations and each of the 30 social evaluation situations. To test our hypotheses, it was essential to separate activation during the period when participants processed the concept from the preceding period when participants processed the situation. Because each concept immediately followed a situation after a short non-varying interval, we used a catch trial methodology to separate activations for the situation and concept (Ollinger, Corbetta, \&amp; Shulman, 2001; Ollinger, Shulman, \&amp; Corbetta, 2001). Thus, the experiment contained eight critical types of events: anger, fear, observe, or plan experienced in physical danger situations and anger, fear, observe, or plan experienced in social evaluation situations. ${ }^{7}$</p>
<p>Predictions-The brain activations that occurred as participants processed the concepts, with activations for the preceding situations removed, were submitted to a Situation Type (physical or social) X Concept (anger, fear, observe, plan) group ANOVA. Taking a factorial ANOVA approach here allowed us to address two general issues. First, it allowed us to establish the different brain regions that composed the situated conceptualizations for an emotion. Second, it allowed us to assess similarities and differences in situated conceptualizations for the same emotion across physical danger and social evaluation situations. ${ }^{8}$</p>
<p>More specifically, taking a factorial ANOVA approach allowed us to establish how three sources of information composed the two situated conceptualizations for a given emotion. First, concept main effects represented contributions from an emotion concept to a situated conceptualization (where concept main effects were brain areas active for a concept consistently across both types of situations; e.g., activations associated with fear). It is essential to note that concept main effects are units of analysis, not theoretical constructs. A concept main effect is not the activation of a core concept for an emotion, but is simply information active for a concept across physical and social situations. Following our earlier discussion, we assume that the content of a concept main effect is the activation of one or more stored situated conceptualizations that are contributing to the composition of an online situated conceptualization. From hereon, when we use "concept main effect," we simply mean the unit of analysis that captures the brain activations common across both situation types for a concept, nothing more.</p>
<p><sup id="fnref6:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Second, situation main effects represented contributions from situation knowledge to a situated conceptualization (where situation main effects were brain areas active for a situation type consistently across all four concepts; e.g., activations associated with physical danger situations). Again, a situation main effect is not a theoretical construct implying core knowledge about a situation, but simply a unit of analysis that establishes common activations across concepts within a situation.</p>
<p>Third, concept X situation interactions represented information in a situated conceptualization that reflected experiencing a particular concept in a specific situation (where interactions were brain areas more active for one or more situation-concept combinations than for others; e.g., activations for fear in physical danger situations). Again, interaction effects are simply units of analysis that capture activations reflecting both the concept and situation.</p>
<p>Establishing these three units of analysis allowed us to assess how information from emotion concepts and situated knowledge compose different situated conceptualizations for the same emotion. We begin with a preliminary hypothesis that motivates our two critical hypotheses:</p>
<p>Preliminary hypothesis-The brain areas active for a situated conceptualization that produces an emotion should reflect the neural systems required for processing relevant information in the situation. If mental states are relevant, regions of medial prefrontal cortex should become active. If interoceptive or evaluative information is relevant, regions of insula and orbitral frontal cortex should become active. If visual or auditory information is relevant, regions of visual and auditory cortex should become active. In general, when two situated conceptualizations require processing similar information, they should recruit similar neural systems; when they require processing different information, they should recruit different neural systems. Two more specific hypotheses follow from the preliminary hypothesis.</p>
<p>Hypothesis 1-Different situated conceptualizations should produce different forms of a given emotion in different situations. Another way of stating this prediction is that constant, relatively unique modules should not produce the same emotion in different situations. Specifically, we predicted that experiencing emotions in physical danger situations-where harm to the body could occur-would recruit brain regions that process the environment (e.g., parahippocampal gyrus), action in the environment (e.g., motor and parietal regions), and bodily states (e.g., insula). Conversely, we predicted that experiencing emotions in social evaluation situations where negative evaluations could occur would recruit brain regions that evaluate social situations (e.g., medial prefrontal and orbitofrontal cortices) and that represent relevant social information about individuals (e.g., temporal poles).</p>
<p>Hypothesis 2-Our second hypothesis was that that the composition of a situated conceptualization for an emotion would draw on contributions from different sources of information in the distributed neural circuitry that produces emotion. Specifically, we predicted that a situated conceptualization would be composed of information stored with the emotion concept (concept main effects), information stored with knowledge about the situation (situation main effects), and information specific to experiencing the emotion concept in the situation (interaction effects). We further predicted that these different compositional elements of situated conceptualizations would generally draw on common neural circuitry distributed throughout the brain that produces emotions dynamically (following the meta-analyses in Barrett, 2009b; Barrett, Mesquita et al., 2007; Lindquist et al., submitted). Specifically, we predicted that fear and anger would draw on areas associated with mentalizing and interoception (e.g., medial prefrontal and orbital frontal cortices, insula). Similarly, if an emotion required action in the world, such as retaliation</p>
<p>during social anger or avoidance during physical fear, areas that process action and space would become active (e.g., motor and parietal areas). We similarly predicted that areas relevant to processing the non-affective abstract concepts of observe and plan would draw on brain areas that process relevant information. Specifically, we predicted that observe would draw on perceptual systems that monitor the environment (e.g., visual and auditory cortices), whereas plan would draw on the executive system (e.g., inferior frontal gyrus, lateral prefrontal cortex). We further predicted that plan, even though it is a non-affective concept, would also draw on regions involved in mentalizing, similar to anger and fear, because mentalizing is central for planning intentional actions.</p>
<h1>Method</h1>
<h2>Design and Participants</h2>
<p>The experiment contained two training sessions and an fMRI scanning session. The first training session occurred 24 to 48 hours before the second training session, followed immediately by the scan. In the scanning session, participants received 240 complete trials that each contained a physical danger situation or a social evaluation situation followed immediately by one of the four concepts. Participants also received 120 catch trials containing only a situation, which enabled separation of the situation and concepts in the complete trials (Ollinger et al., 2001; Ollinger et al., 2001). The catch trials constituted 33\% of the total trials, a proportion in the recommended range for an effective catch trial design (Ollinger et al., 2001). The 360 complete and catch trials were randomly intermixed in an event-related design, with random ISIs intervening that ranged from 0 to 12 sec in increments of 3 sec (obtained from optseq2 ${ }^{9}$ ).</p>
<p>Two variables-situation type and concept-were implemented in a complete repeatedmeasures design. The 60 situations that participants received in the critical scanning session described either a physical danger or social evaluation situation ( 30 each). The concepts that participants received included two emotion concepts (anger and fear) and two non-emotion concepts (observe and plan). Each situation was followed once by each concept, for a total of 240 complete trials ( 60 situations followed by 4 concepts). Each of the 60 situations also occurred twice as a catch trial, for a total of 120 catch trials.</p>
<p>Twenty right-handed, native-English speakers from the Emory community, ranging in age from 20 to 33 ( 10 female), participated in the experiment. Six additional participants were dropped due to problems with audio equipment ( 3 participants) or excessive head motion in the scanner. Participants received $\$ 100$ in compensation, along with anatomical images of their brain.</p>
<h2>Materials</h2>
<p>The 66 situations developed for the experiment described 33 physical danger situations and 33 social evaluation situations. The critical training and scanning sessions used 30 situations of each type; the practice session just before the scan used 3 other situations of each type. Each situation was designed so that each of the four concepts could be plausibly experienced in it (i.e., anger, fear, observe, plan).</p>
<p>A full and core form of each situation was constructed, the latter being a subset of the former. The full form served to provide a rich, detailed, and affectively compelling description of a situation. The core form served to minimize presentation time in the scanner, so that the number of necessary trials could be completed in the time available. As</p>
<p><sup id="fnref7:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>described shortly, participants practiced reinstating the full form of a situation when receiving its core form during the training sessions, so that they would be prepared to also reinstate the full forms during the scanning session when they received the core forms. Table 1 presented earlier provides examples of the full and core situations.</p>
<p>Each full and core situation described an emotional situation from first-person perspective, such that the participant could immerse him- or herself in it. In all physical danger situations, the immersed participant was the only person present, and was responsible for creating the threat of bodily harm, such that anger was directed toward the self and fear involved imminent physical danger. In all social evaluation situations, other people were present, and one of them was responsible for putting the immersed participant in a risky or difficult social situation, such that anger was directed toward someone else and fear involved the threat of being critically (and negatively) evaluated by another. Templates that were used to construct the full and core situations are described in the Supplemental Materials.</p>
<p>CD quality audio recordings were created for the full and core versions of each situation, spoken by an adult woman with a slight northeastern accent. The prosody in the recordings expressed slight emotion, so that the situations did not seem strangely neutral. ${ }^{10}$ The four concepts were recorded similarly. Each core situation lasted about 8 sec or slightly less.</p>
<h1>Procedure</h1>
<p>In the first training session, participants provided informed consent and were screened for any potential problems that could arise during an MRI scan. Participants had no history of psychiatric illness and were not currently taking any psychotropic medication. Participants then received an overview of the experiment and of the first day's training session, using an additional example of a physical danger situation not used in the practice or critical trials. The relation of the full to the core situations was described, and participants were encouraged to reinstate the full situations whenever they heard the core situations. Participants were also encouraged to immerse themselves in all situations from the firstperson perspective, to construct mental imagery of the situation as if it were actually happening, and to experience it in as much vivid detail as possible.</p>
<p>Participants then listened over computer headphones to the full versions of the 66 situations that they would later receive on the practice trials and in the critical scan 24-48 hours later, with the physical danger and social evaluation situation types randomly intermixed. ${ }^{11}$ After hearing each full situation, participants provided three judgments about familiarity and prior experiences, prompted by questions and response scales on the screen. After taking a break, participants listened to the 66 core versions of the situations, again over computer headphones and randomly intermixed. While listening to each core situation, participants were instructed to reinstate the full version that they had heard earlier, immersing themselves fully into the respective situation as it became enriched and developed from memory. One example of a physical situation that did not appear in the later practice and critical trials was again used to instruct the participant. After hearing each core situation over the headphones, participants rated the vividness of the imagery that they experienced immersed in the situation. This task encouraged the participants to develop rich imagery from the core version. For details on the ratings provided during the training, see the Supplemental Materials.</p>
<p><sup id="fnref8:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>As the first training session ended, participants received an overview of the next training session, and of the critical scanning session. Besides being told what to expect in the scanner, participants were instructed to remain still during the scan, emphasizing that even minor movements could prevent using their data. Overall, the initial training session lasted about 2 hours.</p>
<p>In the second training session, participants first listened to the 66 full situations to be used in the practice and critical scans, and then rated how much they were able to immerse themselves in each situation, again hearing the situations over computer headphones and in a random order (see Supplemental Materials for details). The full situations were presented again at this point to ensure that participants were reacquainted with all the details before hearing the core versions later in the scanner. This first phase of the second training session lasted about 1 hour.</p>
<p>Participants were then instructed on the task that they would perform in the scanner and performed a run of practice trials. On each complete trial, participants were told that they would hear the core version of a situation, receive one of four words for a concept (anger, fear, observe, plan), and judge how easy it was to experience the concept in the context of the situation. The core situation was presented auditorily at the onset of a 9 sec period, lasting no more than 8 sec . The concept was then presented auditorily at the onset of a 3 sec period, and participants responded as soon as ready, indicating how easy it was to experience the concept in the context of the situation. To make their judgments, participants pressed one of three buttons on a button box for not easy, somewhat easy, and very easy. Participants were also told that there would be catch trials containing situations and no concepts, and that they were not to respond on these trials. During the practice trials, participants used an E-Prime button box to practice making responses. In the scanner, participants used a Current Designs fiber optic button box designed for high magnetic field environments. To make responses, participants held the response box in their right hand and used their thumb to press the three response buttons.</p>
<p>At the beginning of the practice trials, participants heard the same short instruction that they would hear before every run in the scanner: "Please close your eyes. Listen to each situation and experience being there vividly. If a word follows, rate how easy it was to have that experience in the situation." Participants performed a practice run equal in length to the runs that they would perform in the scanner (for further details see the Supplemental Materials). Following the practice run, the experimenter and the participant walked 5 min across campus to the scanner. Once settled safely and comfortably in the scanner, an initial anatomical scan was performed, followed by the 10 critical functional runs, and finally a second anatomical scan. Prior to beginning each functional run, participants heard the same short instruction from the practice run over noise-muffling headphones.</p>
<p>In each of the 10 functional runs, participants received 24 complete trials and 12 catch trials. Both types of trials (complete and catch) were randomly inter-mixed. On a given trial, participants could not predict whether a complete or catch trial was coming, a necessary condition for an effective catch trial design (Ollinger et al., 2001). Participants also could not predict the type of situation or the concept that would appear. Random ISI occurred between trials, as in the critical experiment, ranging from 0 to 12 sec (in increments of 3 sec ), with an average ISI of 4.5 sec . Across trials, physical danger and social evaluation situation types each occurred 18 times, and each of the 4 concepts (anger, fear, observe, plan) occurred 6 times, equally often with physical danger and social evaluation situations. Across complete trials, the 8 combinations defined by situation type (2) X concept (4) design occurred 3 times each. Across catch trials, each situation type occurred 6 times. A given situation was never repeated with a run; the 6 presentations of the same situation were</p>
<p>distributed randomly across the 10 runs. Participants took a short break between each of the 8 min 3 sec runs. Total time in the scanner was a little over 1.5 hours.</p>
<h1>Image Acquisition</h1>
<p>The neuroimaging data were collected in the Biomedical Imaging Technology Center at Emory University on a research-dedicated 3T Siemens Trio scanner. In each functional run, $163 \mathrm{~T} 2^{*}$-weighted echo planar image volumes depicting BOLD contrast were collected using a Siemens 12-channel head coil and parallel imaging with an iPAT acceleration factor of 2. Each volume was collected using a scan sequence that had the following parameters: 56 contiguous 2 mm slices in the axial plane, interleaved slice acquisition, $\mathrm{TR}=3000 \mathrm{~ms}$, $\mathrm{TE}=30 \mathrm{~ms}$, flip angle $=90^{\circ}$, bandwidth $=2442 \mathrm{~Hz} / \mathrm{Px}, \mathrm{FOV}=220 \mathrm{~mm}$, matrix $=64$, voxel size $=3.44 \mathrm{~mm} \times 3.44 \mathrm{~mm} \times 2 \mathrm{~mm}$. This scanning sequence was selected after testing a variety of sequences for susceptibility artifacts in orbitofrontal cortex, amygdala, and the temporal poles. We selected this sequence not only because it minimized susceptibility artifacts by using thin slices and parallel imaging, but also because using 3.44 mm in the XY dimensions yielded a voxel volume large enough to produce a satisfactory temporal signal-to-noise ratio.</p>
<p>In each of the two anatomical runs, 176 T1-weighted volumes were collected using a high resolution MPRAGE scan sequence that had the following parameters: 192 contiguous slices in the sagittal plane, single-shot acquisition, $\mathrm{TR}=2300 \mathrm{~ms}, \mathrm{TE}=4 \mathrm{~ms}$, flip angle $=8^{\circ}, \mathrm{FOV}$ $=256 \mathrm{~mm}$, matrix $=256$, bandwidth $=130 \mathrm{~Hz} / \mathrm{Px}$, voxel size $=1 \mathrm{~mm} \times 1 \mathrm{~mm} \times 1 \mathrm{~mm}$.</p>
<h2>Image Preprocessing and Analysis</h2>
<p>Image preprocessing and statistical analysis were conducted in AFNI. ${ }^{12}$ The first anatomical scan was registered to the second, and the average of the two scans computed to create a single high-quality anatomical scan. Initial preprocessing steps of the functional data included slice time correction and motion correction in which all volumes were registered spatially to a volume within the last functional run. A volume in the last run was selected as the registration base because it was collected closest in time to the second anatomical scan, which facilitated later alignment of the functional and anatomical data. ${ }^{13}$ The functional data were smoothed using an isotropic 6 mm full-width half-maximum Gaussian kernel. Voxels outside the brain were removed from further analysis, as were high-variability lowintensity voxels likely to be shifting in and out of the brain due to minor head motion. Finally, the signal intensities in each volume were divided by the mean signal value for the respective run and multiplied by 100 to produce percent signal change from the run mean. All later analyses were performed on these percent signal change data.</p>
<p>The averaged anatomical scan was corrected for non-uniformity in image intensity, skullstripped, and then aligned with the functional data. The resulting aligned anatomical dataset was warped to Talairach space using an automated procedure employing the TT_N27 template.</p>
<p>Regression analysis was performed at the individual level using a canonical, fixed-shape Gamma function to model the hemodynamic response. To assess the effect of the situation manipulation on the same concept, two conditions were constructed for the concept, one when it was preceded by physical situations, and one when it was preceded by social situations. Thus betas were calculated from event onsets for 10 conditions: 2 types of</p>
<p><sup id="fnref9:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>situation conditions (physical, social) and 8 concept conditions (physical-anger, socialanger, physical-fear, social-fear, physical-observe, social-observe, physical-plan, socialplan). ${ }^{14}$ Because the situation presentations were 9 sec in length ( 3 TRs), the Gamma function was convolved with a boxcar function for the entire duration. In contrast, the 3 sec concept periods were modeled as events. Six regressors obtained from volume registration during preprocessing were included to remove any residual signal changes correlated with movement (translation in the $\mathrm{X}, \mathrm{Y}$, and Z planes; rotation around the $\mathrm{X}, \mathrm{Y}$, and Z axes). Scanner drift was removed by finding the best-fitting polynomial function correlated with time in the preprocessed time course data.</p>
<p>As described earlier, the catch trial design used allowed us to separate activations for the situations from activations for the subsequent concepts that followed immediately without random jitter. The two situation conditions were modeled by creating regressors that included situation blocks from both complete trials and from catch trials. Including situations blocks from both trial types in one regressor made it possible to mathematically separate each situation from the subsequent concept conditions. Thus, activations from the preceding situation blocks were not included in the activations for the eight concept conditions, having been removed by separating out the two situation conditions.</p>
<p>The betas for the 8 concept conditions from each participant's regression were warped to Talairach space in preparation for group analyses. Each participant's betas for the concept conditions were then submitted to a repeated-measures ANOVA at the group level with the fully-crossed factors of situation type (physical, social) and concept (anger, fear, observe, plan). A voxel-wise significance level of $p&lt;.005$ with a spatial extent threshold of $971 \mathrm{~mm}^{3}$ (41 functional voxels) was used to threshold the resulting main effect and interaction $F$ maps, yielding a whole-brain threshold of $p&lt;.05$ corrected for multiple comparisons. The spatial extent threshold was established using Alphasim in AFNI, which runs Monte Carlo simulations to estimate extent thresholds needed to exceed cluster sizes of false positives at a given voxel-wise threshold. Further aspects of the analysis procedures will be described as relevant results are presented.</p>
<h1>Results</h1>
<p>As described earlier, we used a factorial ANOVA to establish contributions to the situated conceptualizations constructed when the participant experienced a concept (anger, fear, observe, or plan) in the context of situation type (physical danger or social evaluation). Initially, we report activations from the ANOVA for the two main effects and their interaction. We then integrate activations across the main effects and interaction to establish the situated conceptualizations for each concept in physical danger and social evaluation situations. Reorganizing the results this way allowed us to examine in detail the overlap vs. differences between the two situated conceptualizations for a given concept. The behavioral data and their relation to the BOLD data had minimal relation to the critical ANOVA results, and are thus reported in the Supplemental Materials.</p>
<h2>Results from the Concept X Situation ANOVA</h2>
<p>Four types of effects from the ANOVA are reported next: (1) clusters that only exhibited a concept main effect, (2) clusters that only exhibited a situation main effect, (3) clusters that exhibited both a concept and a situation main effect, and (4) clusters that exhibited an interaction between a concept and a situation. Overlap in effect types was addressed in the</p>
<p><sup id="fnref10:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>following manner. First, any cluster exhibiting a main effect and interaction is reported as an interaction cluster only, not as a main effect cluster, because an interaction best describes the pattern of activations across conditions. ${ }^{15}$ Second, as stated above, any cluster in which both main effects occurred is reported as a combined main effect cluster. Thus, each cluster reported for the ANOVA is exclusively one of the four effect types listed above, with no cluster repeating across multiple types. Although clusters exhibiting different effect types sometimes occurred adjacent to one another in the same general brain region, the clusters reported do not overlap spatially. The masking procedures used to isolate the four effect types are described in the Supplemental Materials.</p>
<p>Because an $F$ was associated each cluster that showed a significant effect type, this statistic did not indicate which conditions were differentially active to produce the effect (main effect or interaction). To characterize the differences driving an effect type, we extracted mean percent signal change for the relevant conditions, and then assessed pairwise differences between them.</p>
<p>Several original clusters observed in the main effect and interaction maps were very large, extending across many anatomical regions that serve diverse functions. These clusters are shown in Figure 1. To interpret mean signal change for a large cluster meaningfully, we divided it into smaller sub-clusters, thereby making it possible to contrast conditions in functionally meaningful brain regions. To define meaningful sub-clusters within a large original cluster, we used Brodmann Area (BA) masks from the AFNI Talairach Atlas. The complete procedure used to determine regional sub-clusters within the original large clusters is described in the Supplemental Materials. Whenever a sub-cluster was extracted using a BA mask for an effect type, its BA number is bolded in Tables 2-5. In some cases, it was more appropriate to use a defined anatomical region as a mask instead of a BA (e.g., for the insula, parahippocampal gyrus). Whenever a sub-cluster was extracted using an anatomically defined region, the word 'tal' is bolded instead of the BA number in the respective table. In the tables to follow, sub-clusters extracted from the same large cluster are shown adjacently, grouped by a contiguous gray or a white background.</p>
<p>Concept main effects-Essentially, a concept main effect indicated whether different brain areas were systematically associated with each concept (anger, fear, observe, plan), across the two types of situations assessed here (physical, social). Any cluster that exhibited greater activity for one concept over another exhibited this dominance across both situation types, statistically speaking. If, for example, a cluster showed a main effect for anger relative to the other three concepts, it tended to show this dominance across both physical danger and social evaluation situations. If this dominance did not hold systematically across situations, then the cluster instead exhibited an interaction effect, as described later. Figure 1A illustrates concept main effect clusters.</p>
<p>As described earlier, a concept main effect is a unit of analysis, not a theoretical construct. Again, we do not assume that concept main effects reflect conceptual cores common across situations. Instead, we assume that a diverse collection of situated conceptualizations represents a concept, together with minimal abstractions. From this perspective, a concept main effect simply indicates that some of this diverse content was retrieved across both physical and social situations in this experiment. It does not follow at all the content of a concept main effect reflects core content for a concept, or that any core content exists.</p>
<p><sup id="fnref11:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Because an $F$ was associated with each cluster that showed a significant concept effect, this statistic did not indicate which specific concepts were more active than others. To make this determination, the betas for individual subjects within each cluster were extracted for each concept, and the cluster was associated with any concept(s) significantly more active than the least active concept ( $p&lt;.05$ ). These classifications exhibited a variety of patterns across clusters. If, for example, anger was more active in a cluster than fear, observe, and plan (which did not differ), then the cluster was classified as an anger cluster. Alternatively, if anger, fear, and plan were all more active in a cluster than observe, then the cluster was classified as an anger, fear, and plan cluster. The right-most columns of Table 2 use a plus sign (+) to indicate any concept that was more active than the least active concept.</p>
<p>In addition, when activity in a cluster was significantly greater for one concept than for all others, it was assigned a larger plus sign $(+)$ to indicate that it could be distinguished statistically as significantly more active than all other concepts (see Table 2). If, for example, anger, fear and plan were more active in a cluster than observe, but anger was also more active than fear and plan, then a larger plus sign indicated that anger was more active than the other three concepts.</p>
<p>As Table 2 illustrates, three main types of patterns emerged for clusters that exhibited a concept main effect: (1) clusters active during anger, fear, and plan, (2) clusters active during observe and plan, (3) clusters active during observe alone. Clusters in lateral and medial orbitofrontal cortex, medial prefrontal cortex extending up into the supplementary motor area, ${ }^{16}$ and dorsal anterior cingulate were active during anger, fear, and plan. The temporal poles were also active during anger, fear, and plan bilaterally. Among these clusters, only the medial orbitofrontal and adjacent ventromedial prefrontal regions showed a profile in which one of the emotion concepts, anger, was significantly greater than all the other concepts. In these two clusters, fear and plan showed greater activity than observe, and anger showed greater activity than fear, plan, and observe.</p>
<p>Clusters active during observe and plan were primarily located in more posterior, leftlateralized motor and visual areas. Specifically, left premotor cortex, mid-cingulate, left middle temporal gyrus, left inferior temporal gyrus, left parahippocampal gyrus, left extrastriate visual areas, and left precuneus ${ }^{17}$ were more active during observe and plan. Bilateral superior temporal regions, bilateral posterior regions of the insula, and right inferior parietal cortex were also more active during observe and plan. Right middle temporal gyrus showed a unique pattern, active during observe and plan, as well as during anger.</p>
<p>Clusters only active during observe tended to occur in right-lateralized visual areas. Specifically, right extrastriate occipital regions, right precuneus, right middle and inferior temporal gyrus, and left fusiform gyrus were only active during observe. Activations also occurred during observe in angular gyrus/temporal-parietal junction bilaterally and left inferior parietal cortex.</p>
<p><sup id="fnref12:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Situation main effects—A situation main effect indicated that an activation during anger, fear, plan, and observe was systematically associated the situation type preceding it (physical danger or social evaluation). Because activations from the situations themselves were removed using the catch trial procedure described earlier, these activations reflect situational influences on the subsequent concept events. Figure 1B illustrates these clusters. Importantly, any cluster that exhibited greater activity for one situation type in a situation main effect exhibited this dominance across all four concepts, statistically speaking. If, for example, a cluster showed a main effect in the physical danger situation type relative to social evaluation situation type, it tended to show this dominance across all four concepts (anger, fear, observe, plan). If this dominance did not hold systematically across all concepts, then the cluster instead exhibited an interaction effect, as described later. Because an $F$ was associated with each cluster that showed a significant situation effect, this statistic did not indicate whether the cluster was more active for all concepts following physical danger or social evaluation situation types. To make this determination, the betas for individual subjects within each significant cluster were extracted to determine if they were significantly more active in physical danger or social evaluation situations ( $p&lt;.05$ ). If, for example, a cluster showed significantly higher activation during physical danger situations than during social evaluation situations, it was classified as a physical danger cluster, meaning that the respective brain area was more active when experiencing all concepts in the context of the physical danger situations. The rightmost columns of Table 3 use a plus sign $(+)$ to indicate these classifications.</p>
<p>As Table 3 illustrates, bilateral parahippocampal gyrus and mid-cingulate, extending up into the paracentral lobule, were active for all concepts following physical danger situations, significantly more so than when the same concepts followed social evaluation situations. In contrast, significantly more activation was observed in ventromedial prefrontal cortex and early visual areas when the concepts were experienced following social evaluation situations than following physical danger situations.</p>
<p>In the Supplemental Materials, we describe situation effects in parahippocampal gyrus and visual cortex that only occurred during the concept period, not during the situation period. These situation effects demonstrate that the compositional process producing emotional states is dynamical in the sense that situation effects not present initially during the situations can emerge later during the concepts.</p>
<p>Overlapping concept and situation main effects—Table 4 shows the clusters in which additive main effects were observed for both a concept and a situation. Figure 1C illustrates these clusters. One cluster in dorsomedial prefrontal cortex was more active during all concepts in social evaluation situations relative to physical danger situations, and was also more active during anger, fear, and plan than observe (across situation types). The other region active in both a situation and a concept main effect was located in right superior temporal gyrus. This region was more active during all concepts in physical danger than social evaluation situations, and was also more active during plan and observe (across situation types).</p>
<p>Interaction effects—Whenever the eight concept conditions—physical-anger, socialanger, physical-fear, social-fear, physical-observe, social-observe, physical-plan, social-plan-differed significantly from one another in some way that did not constitute a main effect, an interaction resulted. Figure 1D shows these clusters. Because an $F$ was associated with every cluster that exhibited an interaction, the betas for individual subjects within each significant cluster were extracted for each of the eight situation-concept conditions, and the cluster was associated with any situation-concept condition(s) significantly more active than the least active condition ( $p&lt;.05$ ). These classifications exhibited many different patterns</p>
<p>across clusters, as shown by the plus sign (+) indicators in Table 5. In these interaction clusters, no one condition was ever significantly more active than all the others.</p>
<p>As Table 5 illustrates, interaction clusters were located primarily in lateral regions of left prefrontal cortex and bilateral temporal and parietal cortex. In the left hemisphere, dorsolateral prefrontal cortex, inferior frontal gyrus, orbitofrontal cortex, posterior insula, temporal pole, superior temporal gyrus, and inferior parietal cortex showed significant interaction effects. In the right hemisphere, interaction effects were observed in posterior insula, superior temporal gyrus, and inferior parietal cortex. The only more medial activation was a cluster in the precuneus, with all other clusters being relatively lateral.</p>
<h1>Establishing the Composition of Situated Conceptualizations</h1>
<p>In the previous section, Tables 2, 3, 4, and 5 presented activations observed in situation main effects, concept main effects, both main effects, and interaction effects. In this section, we reorganize these same results to achieve two additional goals: (1) Compile all the active clusters for a particular concept across effect types, (2) Assess the extent to which these clusters occurred in one or both situations types. Tables 6 and 7 reorganize the earler results for fear and anger. Supplemental Tables 2 and 3 reogranize them for plan and observe. Each table establishes the situated conceptualizations for a concept in physical danger and social evaluation situations. As will be seen, each situated conceptualization contains clusters exhibiting concept main effects, situation main effects, both main effects, and interaction effects. As will also be seen, some of the clusters in each situated conceptualization are common to both situations, whereas other clusters are unique to one situation.</p>
<p>In the right-most column of each table, a plus sign (+) indicates whether a cluster was active in physical situations, social situations, or both. As each table for a concept illustrates, clusters exhibiting a concept main effect indicate that a brain region was active in both situated conceptualizations. In contrast, clusters exhibiting a situation main effect indicate that a brain region was active in only one of the situated conceptualizations. Interaction clusters, on the other hand, could exhibit patterns in which a brain region was active in both situated conceptualizations or only in one situated conceptualization (because the interaction was computed across all situation-concept conditions). Finally, clusters exhibiting both main effects took one of two forms. For some clusters, the concept exhibited both a situation effect in one situation (indicated by + ) and was simultaneously more active than at least one other concept across both situations (indicated by + in the other situation). For other clusters, the concept only exhibited a situation main effect (indicated by + ), and was not more significant than the least active concept (indicated by a blank in the other situation), with another concept being responsible for the simultaneous concept effect.</p>
<p>Table 6 compiles clusters across effect types that were active during anger in physical situations, social situations, or both situations. As Table 6 illustrates, roughly half the clusters occurred for both situation types, whereas half occurred only for physical danger situations or only for social evaluation situations. Table 7 compiles clusters across effect types that were active during fear in physical danger situations, social evaluation situations, or both situations. As can be seen, roughly one third of these clusters occurred for both situation types, whereas the large majority occurred only for physical danger situations or for social evaluation situations.</p>
<p>Supplemental Tables 2 and 3 in the Supplemental Materials compile the effect types for observe and plan, respectively. The situationally unique activations for these abstract concepts were not as extensive as those for the emotion concepts. Nevertheless, there were several regions exhibiting situation main effects and interactions that were unique in the situated conceptualizations for these concepts.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{16}$ The betas extracted for the medial prefrontal/SMA sub-cluster were obtained using the BA 6 mask. BA 6 also covered a separate cluster in left premotor cortex that was active in the concept main effect (see Table 3). The medial prefrontal/SMA activation profile shown in Table 3 resulted from averaging only voxels in the medial prefrontal/SMA region within the BA 6 mask. This profile was clearly different from the pattern in left premotor cortex, which was not masked with a BA because it was not part of a large activation cluster initially.
${ }^{17}$ Precuneus activations in the concept main effect were separate sub-clusters in the left and right hemisphere, and are thus referred to as left precuneus and right precuneus. The precuneus activation in an interaction effect was more medial, a continuous cluster of activation across both hemispheres. In this case, no hemisphere is specified to indicate the medial nature of the activation.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref6:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref7:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref8:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref9:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref10:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref11:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref12:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>