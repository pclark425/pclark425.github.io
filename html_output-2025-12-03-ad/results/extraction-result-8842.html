<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8842 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8842</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8842</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-154.html">extraction-schema-154</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated on strict logical reasoning tasks, including details about the models, the logical reasoning tasks or benchmarks, the methods or approaches used to improve logical reasoning, the performance or results, comparisons to baselines or ablations, and any reported limitations or failure cases.</div>
                <p><strong>Paper ID:</strong> paper-c5943bc4b22a63f595cb1c2823a449e03aad4787</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/c5943bc4b22a63f595cb1c2823a449e03aad4787" target="_blank">AR-LSAT: Investigating Analytical Reasoning of Text</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> It is found that the Transformer-based models struggle to solve this task as their performance is close to random guess and ARM achieves better performance by leveraging symbolic knowledge and interpretable reasoning steps.</p>
                <p><strong>Paper Abstract:</strong> Analytical reasoning is an essential and challenging task that requires a system to analyze a scenario involving a set of particular circumstances and perform reasoning over it to make conclusions. In this paper, we study the challenge of analytical reasoning of text and introduce a new dataset consisting of questions from the Law School Admission Test from 1991 to 2016. We analyze what knowledge understanding and reasoning abilities are required to do well on this task. Furthermore, to address this reasoning challenge, we design two different baselines: (1) a Transformer-based method which leverages the state-of-the-art pre-trained language models and (2) Analytical Reasoning Machine (ARM), a logical-level reasoning framework extracting symbolic knowledge (e.g, participants, facts, logical functions) to deduce legitimate solutions. In our experiments, we find that the Transformer-based models struggle to solve this task as their performance is close to random guess and ARM achieves better performance by leveraging symbolic knowledge and interpretable reasoning steps. Results show that both methods still lag far behind human performance, which leave further space for future research.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8842.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8842.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated on strict logical reasoning tasks, including details about the models, the logical reasoning tasks or benchmarks, the methods or approaches used to improve logical reasoning, the performance or results, comparisons to baselines or ablations, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Transformer-based LMs</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Transformer-based pre-trained language models (BERT / XLNet / RoBERTa / ALBERT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A set of state-of-the-art pre-trained Transformer language models fine-tuned as multiple-choice classifiers on the AR-LSAT analytical reasoning benchmark; used as a representative neural baseline to evaluate strict logical/analytical reasoning abilities.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BERT, XLNet, RoBERTa, ALBERT (as fine-tuned classifiers)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Pre-trained Transformer encoder (or Transformer-based) language models adapted to multiple-choice classification by concatenating passage, question and an option and fine-tuning the model plus a small MLP. Appendix D in the paper gives brief training-corpus descriptions: BERT pre-trained on BooksCorpus and Wikipedia; XLNet pre-trained on BooksCorpus, Wikipedia, Giga5, ClueWeb2012-B and Common Crawl; RoBERTa trained on a larger corpus/optimized training; ALBERT uses parameter-reduction techniques for large-scale pretraining.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>AR-LSAT (Analytical reasoning from LSAT)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>A strict logical/analytical-reasoning multiple-choice benchmark constructed from LSAT analytical reasoning sections (1991–2016), containing ordering, grouping and assignment games that require extracting participants, facts and natural-language rules, translating rules into logical constraints, and performing explicit deduction (question types include 'must be true/false', 'could be true/false', 'acceptable solution', calculation, substitution, etc.).</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Fine-tuning the pre-trained Transformer models as multiple-choice classifiers: input format [CLS] passage [SEP] question + candidate option; final hidden representation fed to an MLP and trained with cross-entropy on labeled AR-LSAT answers. (This paper also describes that transformer outputs are compared against a symbolic ARM approach.)</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Reported accuracies on AR-LSAT: BERT — Dev 23.4%, Test 21.4%; XLNet — Dev 23.8%, Test 22.5%; RoBERTa — Dev 24.2%, Test 23.1%; ALBERT — Dev 24.4%, Test 23.0%. Random guess baseline = 20.0%; human (undergraduate non-LSAT-trained) ≈ 59.7%.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>All four Transformer-based models perform only slightly above random (≈20%) and substantially below human performance (≈59.7%). ARM (the paper's symbolic/neuro-symbolic system) outperforms the Transformers (ARM: Dev 34.2%, Test 30.9%) but still lags far behind humans.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>The paper reports that these pre-trained Transformer models 'struggle to perform deep reasoning beyond shallow-level semantic understanding' and achieve accuracy close to random, indicating failures on strict symbolic/analytical operations required by AR-LSAT. The authors attribute this to inability to (a) extract and represent participants, positions and compositional logical constraints reliably from rules, and (b) perform explicit multi-step deductive reasoning; they cite Talmor et al. (2020) as reporting similar failures on symbolic tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>insights_or_conclusions</strong></td>
                            <td>The paper concludes that current pre-trained Transformer LMs, when fine-tuned naively for selection, are insufficient for strict logical/analytical reasoning tasks like AR-LSAT; it suggests that extracting machine-understandable logical functions and integrating explicit symbolic deduction (neuro-symbolic approaches) are promising directions, and that better function extraction and inference engines are needed to handle complex rule semantics and uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AR-LSAT: Investigating Analytical Reasoning of Text', 'publication_date_yy_mm': '2021-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8842.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8842.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being evaluated on strict logical reasoning tasks, including details about the models, the logical reasoning tasks or benchmarks, the methods or approaches used to improve logical reasoning, the performance or results, comparisons to baselines or ablations, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ARM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Analytical Reasoning Machine (ARM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A logical-level, interpretable neuro-symbolic framework introduced in this paper that extracts symbolic arguments and logical constraint functions from AR-LSAT passages and performs explicit tree-based deduction to produce legitimate assignments and answer multiple-choice questions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Analytical Reasoning Machine (ARM)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A pipeline that (1) extracts participants, positions, facts and rules (using NER and pattern matching), (2) maps natural-language rules to a predefined set of logical functions (Relational, Compositional, Counting) via symbolic parsing plus a RoBERTa-based neural semantic parser, (3) performs tree-based deduction of all legitimate assignments that satisfy the constraints, and (4) matches options against legitimate assignments via assignment-based and function-based scoring.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>AR-LSAT (Analytical reasoning from LSAT)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Same AR-LSAT benchmark: realistic LSAT analytical reasoning questions requiring conversion of natural-language constraints to logical constraints and explicit deduction over assignments (ordering, grouping, assignment games; question types: must/could be true, acceptable solution, etc.).</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_approach</strong></td>
                            <td>Neuro-symbolic pipeline: symbolic trigger-word parsing to propose relational/compositional/counting functions; a RoBERTa-based semantic parser trained on automatically constructed function labels to improve coverage; NER for argument extraction; a tree-based constructive search that generates and filters assignments by executing logical function executors; final option matching via assignment/function-based scoring.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>ARM achieves Dev accuracy 34.2% and Test accuracy 30.9% on AR-LSAT (outperforming all Transformer baselines but well below human performance ≈59.7%). Argument-extraction metrics on dev: Participants extraction Acc 96.17%, Recall 92.88%; Positions extraction Acc 84.42%, Recall 85.79%.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>ARM outperforms fine-tuned Transformer models (which are near-random) and random guess (20.0%), but still substantially underperforms humans. The paper treats ARM as a stronger, more interpretable baseline compared to pure neural models.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failures</strong></td>
                            <td>Reported failure modes include: (1) incompleteness of the predefined logical function set (complex semantics not covered, e.g., 'At least' needs AtLeastNum), (2) errors in participant/position extraction (NER and pattern matching failures), and (3) failures due to lack of commonsense knowledge mapping (e.g., mapping 'morning' to specific times). The authors also note ARM remains far below human performance, indicating remaining challenges in both parsing and inference.</td>
                        </tr>
                        <tr>
                            <td><strong>insights_or_conclusions</strong></td>
                            <td>The authors conclude that explicit symbolic representation of rules and an inference engine that can execute logical functions are beneficial for strict logical reasoning; however, improved function extraction (with little/no supervision), richer function coverage, integration of commonsense mappings, and better inference engines (and hybrid neural-symbolic integration) are necessary future directions to close the gap to human performance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AR-LSAT: Investigating Analytical Reasoning of Text', 'publication_date_yy_mm': '2021-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>LogiQA: A challenge dataset for machine reading comprehension with logical reasoning <em>(Rating: 2)</em></li>
                <li>ReClor: A reading comprehension dataset requiring logical reasoning <em>(Rating: 2)</em></li>
                <li>olmpics-on what language model pre-training captures <em>(Rating: 2)</em></li>
                <li>Neural symbolic machines: Learning semantic parsers on freebase with weak supervision <em>(Rating: 1)</em></li>
                <li>Neural-symbolic machines: Learning semantic parsers on freebase with weak supervision <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8842",
    "paper_id": "paper-c5943bc4b22a63f595cb1c2823a449e03aad4787",
    "extraction_schema_id": "extraction-schema-154",
    "extracted_data": [
        {
            "name_short": "Transformer-based LMs",
            "name_full": "Transformer-based pre-trained language models (BERT / XLNet / RoBERTa / ALBERT)",
            "brief_description": "A set of state-of-the-art pre-trained Transformer language models fine-tuned as multiple-choice classifiers on the AR-LSAT analytical reasoning benchmark; used as a representative neural baseline to evaluate strict logical/analytical reasoning abilities.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "BERT, XLNet, RoBERTa, ALBERT (as fine-tuned classifiers)",
            "model_description": "Pre-trained Transformer encoder (or Transformer-based) language models adapted to multiple-choice classification by concatenating passage, question and an option and fine-tuning the model plus a small MLP. Appendix D in the paper gives brief training-corpus descriptions: BERT pre-trained on BooksCorpus and Wikipedia; XLNet pre-trained on BooksCorpus, Wikipedia, Giga5, ClueWeb2012-B and Common Crawl; RoBERTa trained on a larger corpus/optimized training; ALBERT uses parameter-reduction techniques for large-scale pretraining.",
            "model_size": null,
            "reasoning_task_name": "AR-LSAT (Analytical reasoning from LSAT)",
            "reasoning_task_description": "A strict logical/analytical-reasoning multiple-choice benchmark constructed from LSAT analytical reasoning sections (1991–2016), containing ordering, grouping and assignment games that require extracting participants, facts and natural-language rules, translating rules into logical constraints, and performing explicit deduction (question types include 'must be true/false', 'could be true/false', 'acceptable solution', calculation, substitution, etc.).",
            "method_or_approach": "Fine-tuning the pre-trained Transformer models as multiple-choice classifiers: input format [CLS] passage [SEP] question + candidate option; final hidden representation fed to an MLP and trained with cross-entropy on labeled AR-LSAT answers. (This paper also describes that transformer outputs are compared against a symbolic ARM approach.)",
            "performance": "Reported accuracies on AR-LSAT: BERT — Dev 23.4%, Test 21.4%; XLNet — Dev 23.8%, Test 22.5%; RoBERTa — Dev 24.2%, Test 23.1%; ALBERT — Dev 24.4%, Test 23.0%. Random guess baseline = 20.0%; human (undergraduate non-LSAT-trained) ≈ 59.7%.",
            "baseline_comparison": "All four Transformer-based models perform only slightly above random (≈20%) and substantially below human performance (≈59.7%). ARM (the paper's symbolic/neuro-symbolic system) outperforms the Transformers (ARM: Dev 34.2%, Test 30.9%) but still lags far behind humans.",
            "limitations_or_failures": "The paper reports that these pre-trained Transformer models 'struggle to perform deep reasoning beyond shallow-level semantic understanding' and achieve accuracy close to random, indicating failures on strict symbolic/analytical operations required by AR-LSAT. The authors attribute this to inability to (a) extract and represent participants, positions and compositional logical constraints reliably from rules, and (b) perform explicit multi-step deductive reasoning; they cite Talmor et al. (2020) as reporting similar failures on symbolic tasks.",
            "insights_or_conclusions": "The paper concludes that current pre-trained Transformer LMs, when fine-tuned naively for selection, are insufficient for strict logical/analytical reasoning tasks like AR-LSAT; it suggests that extracting machine-understandable logical functions and integrating explicit symbolic deduction (neuro-symbolic approaches) are promising directions, and that better function extraction and inference engines are needed to handle complex rule semantics and uncertainty.",
            "uuid": "e8842.0",
            "source_info": {
                "paper_title": "AR-LSAT: Investigating Analytical Reasoning of Text",
                "publication_date_yy_mm": "2021-04"
            }
        },
        {
            "name_short": "ARM",
            "name_full": "Analytical Reasoning Machine (ARM)",
            "brief_description": "A logical-level, interpretable neuro-symbolic framework introduced in this paper that extracts symbolic arguments and logical constraint functions from AR-LSAT passages and performs explicit tree-based deduction to produce legitimate assignments and answer multiple-choice questions.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Analytical Reasoning Machine (ARM)",
            "model_description": "A pipeline that (1) extracts participants, positions, facts and rules (using NER and pattern matching), (2) maps natural-language rules to a predefined set of logical functions (Relational, Compositional, Counting) via symbolic parsing plus a RoBERTa-based neural semantic parser, (3) performs tree-based deduction of all legitimate assignments that satisfy the constraints, and (4) matches options against legitimate assignments via assignment-based and function-based scoring.",
            "model_size": null,
            "reasoning_task_name": "AR-LSAT (Analytical reasoning from LSAT)",
            "reasoning_task_description": "Same AR-LSAT benchmark: realistic LSAT analytical reasoning questions requiring conversion of natural-language constraints to logical constraints and explicit deduction over assignments (ordering, grouping, assignment games; question types: must/could be true, acceptable solution, etc.).",
            "method_or_approach": "Neuro-symbolic pipeline: symbolic trigger-word parsing to propose relational/compositional/counting functions; a RoBERTa-based semantic parser trained on automatically constructed function labels to improve coverage; NER for argument extraction; a tree-based constructive search that generates and filters assignments by executing logical function executors; final option matching via assignment/function-based scoring.",
            "performance": "ARM achieves Dev accuracy 34.2% and Test accuracy 30.9% on AR-LSAT (outperforming all Transformer baselines but well below human performance ≈59.7%). Argument-extraction metrics on dev: Participants extraction Acc 96.17%, Recall 92.88%; Positions extraction Acc 84.42%, Recall 85.79%.",
            "baseline_comparison": "ARM outperforms fine-tuned Transformer models (which are near-random) and random guess (20.0%), but still substantially underperforms humans. The paper treats ARM as a stronger, more interpretable baseline compared to pure neural models.",
            "limitations_or_failures": "Reported failure modes include: (1) incompleteness of the predefined logical function set (complex semantics not covered, e.g., 'At least' needs AtLeastNum), (2) errors in participant/position extraction (NER and pattern matching failures), and (3) failures due to lack of commonsense knowledge mapping (e.g., mapping 'morning' to specific times). The authors also note ARM remains far below human performance, indicating remaining challenges in both parsing and inference.",
            "insights_or_conclusions": "The authors conclude that explicit symbolic representation of rules and an inference engine that can execute logical functions are beneficial for strict logical reasoning; however, improved function extraction (with little/no supervision), richer function coverage, integration of commonsense mappings, and better inference engines (and hybrid neural-symbolic integration) are necessary future directions to close the gap to human performance.",
            "uuid": "e8842.1",
            "source_info": {
                "paper_title": "AR-LSAT: Investigating Analytical Reasoning of Text",
                "publication_date_yy_mm": "2021-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "LogiQA: A challenge dataset for machine reading comprehension with logical reasoning",
            "rating": 2
        },
        {
            "paper_title": "ReClor: A reading comprehension dataset requiring logical reasoning",
            "rating": 2
        },
        {
            "paper_title": "olmpics-on what language model pre-training captures",
            "rating": 2
        },
        {
            "paper_title": "Neural symbolic machines: Learning semantic parsers on freebase with weak supervision",
            "rating": 1
        },
        {
            "paper_title": "Neural-symbolic machines: Learning semantic parsers on freebase with weak supervision",
            "rating": 1
        }
    ],
    "cost": 0.0120185,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>AR-LSAT: Investigating Analytical Reasoning of Text</h1>
<p>Wanjun Zhong ${ }^{1 <em>}$, Siyuan Wang ${ }^{3 </em>}$, Duyu Tang ${ }^{2}$, Zenan Xu ${ }^{1 <em>}$, Daya Guo ${ }^{1 </em>}$ Yining Chen ${ }^{2}$, Jiahai Wang ${ }^{1}$, Jian Yin ${ }^{1}$, Ming Zhou ${ }^{4}$ and Nan Duan ${ }^{2}$<br>${ }^{1}$ The School of Data and Computer Science, Sun Yat-sen University.<br>${ }^{2}$ Microsoft Research ${ }^{3}$ Fudan University, China ${ }^{4}$ SINOVATION VENTURES<br>{zhongwj25, xuzn, guody5}@mail2.sysu.edu.cn<br>{wangjiah@mail,issjyin@mail}.sysu.edu.cn<br>{dutang, nanduan, yining.chen}@microsoft.com<br>wangsy18@fudan.edu.cn; zhouming@chuangxin.com</p>
<h4>Abstract</h4>
<p>Analytical reasoning is an essential and challenging task that requires a system to analyze a scenario involving a set of particular circumstances and perform reasoning over it to make conclusions. In this paper, we study the challenge of analytical reasoning of text and introduce a new dataset consisting of questions from the Law School Admission Test from 1991 to 2016. We analyze what knowledge understanding and reasoning abilities are required to do well on this task. Furthermore, to address this reasoning challenge, we design two different baselines: (1) a Transformer-based method which leverages the state-of-the-art pre-trained language models and (2) Analytical Reasoning Machine (ARM), a logical-level reasoning framework extracting symbolic knowledge (e.g, participants, facts, logical functions) to deduce legitimate solutions. In our experiments, we find that the Transformer-based models struggle to solve this task as their performance is close to random guess and ARM achieves better performance by leveraging symbolic knowledge and interpretable reasoning steps. Results show that both methods still lag far behind human performance, which leave further space for future research. ${ }^{1}$</p>
<h2>1 Introduction</h2>
<p>Analytical reasoning assesses the problem-solving ability to understand knowledge (e.g., participants, facts, rules), and reasoning over that knowledge to determine a solution. Analytical reasoning is known to involved when doing everyday tasks, and engages high-level cognitive mechanisms of humans (Williams et al., 2019). Although</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>[Grouping Game] Passage:
Seven directors -A, B, C, D, E, F, and G- serves on the X committee or the Y committee.</p>
<p>If A serves on X, then B serves on Y. R-1
If C serves on X, then D and E serve on Y. R-2
F serves on a different committee with G. R-3
E serves on a different committee with A. R-4
If G serves on X, so does B. R-5 Rules
Question:
$D D$ and $F$ both serve on the $X$ committee. Fact then which one of the following could be true?
Options:
A. A and C both serve on the X committee. (C on $X) \&amp;(D$ on $X)$ confict with R-2
B. A and E both serve on the Y committee. $(A$ on $Y) \&amp;(E$ on $Y)$ confict with R-4
C. B and G both serve on the X committee. (G on $X) \&amp;(F$ on $X)$ confict with R-3
D. C and E both serve on the Y committee. $\sqrt{ }$
E. G and E both serve on the X committee. (G on $X) \&amp;(F$ on $X)$ confict with R-3
$\overline{\text { Participants }} \quad$ Positions Fact
$(A, B, C, D, E, F, G) \quad(X, Y) \quad(D$ on $X) \&amp;(F$ on $X)$
Rules to Logical Expressions
R-1: $A$ on $X \rightarrow B$ on $Y$
R-2: $C$ on $X \rightarrow(D$ on $Y) \&amp;(E$ on $Y)$
R-3: Position of $F \neq$ Position of $G$
R-4: Position of $E \neq$ Position of $A$
R-5: $G$ on $X \rightarrow B$ on $X$
Figure 1: An example of the required reasoning process to do well on the AR task. The input is a passage, a question and multiple options, and the output is the most plausible answer.</p>
<p>Transformer-based pre-trained language models including BERT (Devlin et al., 2018), GPT-2 (Radford et al., 2019) and RoBERTa (Liu et al., 2019) have achieved state-of-the-art performance on a variety of NLP tasks, they still struggle to perform deep reasoning beyond shallow-level semantic understanding of literal clues. For example, Talmor et al. (2020) show that pre-trained models fail on half of eight reasoning tasks that require symbolic operations. We hope to challenge current systems and take a step towards analytical reasoning.</p>
<p>In this paper, we study the challenge of analyt-</p>
<p>ical reasoning (AR). We introduce a new dataset AR-LSAT from the Law School Admission Test ${ }^{2}$ (LSAT) from 1991 to 2016. to facilitate research on this area. An example of analytical reasoning in LSAT is given in Figure 1, whose task is to separate participants (i.e., $A, B$, etc.) into two positions (i.e., $X$ committee and $Y$ committee) under certain constraints. Solving the problem requires a system to understand the knowledge in the context including participants, positions, rules expressed in natural language (e.g., "If $G$ serves on $X$, so does $B$ ") and facts (e.g., " $D$ and $F$ both serve on the $X$ committee"). Then, it needs to deduct logical expressions (e.g., " $G$ on $X \rightarrow B$ on $X$ ") from the rules, and draw inference before making conclusions.</p>
<p>In this paper, we analyze the knowledge understanding and reasoning ability required for solving this task and present two base approaches for this challenge: (1) Transformer-based approach that applies pretrained language models to encode the input context into distributed representation for classification. (2) Analytical Reasoning Machine (ARM), a logical-level framework that first extracts symbolic knowledge (i.e., participants, rules, facts) from the context, and further maps them into executable logical functions (e.g., "IfThen", "Before") to assess whether a solution can satisfy mentioned rules and then deduce legitimate solutions for making prediction. This framework sheds a light on the logical-level reasoning procedure required for this task, and each step can be further developed in future for better performance or expandability.</p>
<p>Experiments show that the Transformer-based approach struggles to learn this task, which indicates that this task is very challenging for current models as it requires the complex reasoning ability far beyond implicit reasoning over the literal clues. ARM performs relatively better than the Transformer-based approach with higher accuracy and better interpretability. The performance of both approaches lag far behind human performance, which leaves a huge space for further research.</p>
<p>The contributions of our paper are two-fold.</p>
<ul>
<li>We introduce a new dataset AR-LSAT to facilitate research on analytical reasoning.</li>
<li>We present two approaches for this task: a Transformer-based approach and a logicallevel reasoning framework that utilizes symbolic knowledge to perform reasoning.</li>
</ul>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h2>2 Related Works</h2>
<p>There is an increasing trend on machine reasoning research in recent years. The reasoning ability investigated are partitioned into several major aspects, including (1) logical reasoning; (2) commonsense reasoning; (3) mathematical reasoning and (4) multi-hop reasoning.</p>
<p>Logical Reasoning The task of Natural Language Inference (NLI) (Dagan et al., 2005; Bowman et al., 2015; Wang et al., 2018; Williams et al., 2018; Welleck et al., 2018; Khot et al., 2018; Nie et al., 2019; Bhagavatula et al., 2019; Liu et al., 2020a) requires the models to detect the logical entailment relationship of two sentences. There have been Machine Reading Comprehension (MRC) datasets (Rajpurkar et al., 2016; Welbl et al., 2017; Yang et al., 2018a; Huang et al., 2019b) that examine the ability of logical reasoning. LogiQA (Liu et al., 2020b) and ReClor (Yu et al., 2020) are sourced from examination in realistic scenario and examine a range of logical reasoning skills.</p>
<p>Commonsense Reasoning There are many recent benchmarks that assess the commonsense reasoning capabilities from different aspects, like social (Rashkin et al., 2018), physics (Talmor et al., 2018; Zellers et al., 2019), or temporal (Zhou et al., 2019). There exist several MRC datasets that require commonsense knowledge (Ostermann et al., 2018; Zhang et al., 2018; Huang et al., 2019a).</p>
<p>Mathematical Reasoning There are many existing datasets (Kushman et al., 2014; Hosseini et al., 2014; Koncel-Kedziorski et al., 2015; Clark et al., 2016; Ling et al., 2017) focus on mathematical word problems. Ling et al. (2017) builds a dataset that encourages generating answer rationales beyond simply selecting the correct answer. DROP (Dua et al., 2019) is a benchmark MRC dataset requiring mathematical reasoning. Saxton et al. (2019) focuses on algebraic generalization.</p>
<p>Multi-hop Reasoning Multi-hop reasoning over textual data (Talmor and Berant, 2018; Welbl et al., 2018; Yang et al., 2018b; Inoue et al., 2020) require a model to reason over multiple paragraphs before making prediction.</p>
<p>To the best of our knowledge, there has not an existing benchmark dataset that completely focuses on the analytical reasoning over textual data. We introduce a new dataset to fill this gap and to foster research on this area.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Ordering Game] Passage</th>
<th style="text-align: center;">Options</th>
<th style="text-align: center;">Participants</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">A professor must determine the order in which five of her students -</td>
<td style="text-align: center;">A. Ginny, Fernando, Hakim, Kevin, Juanita $+\mathrm{B}-2$</td>
<td style="text-align: center;">(Fernando, Ginny, Hakim, Juanita, Kevin)</td>
</tr>
<tr>
<td style="text-align: center;">Fernando, Ginny, Hakim, Juanita, and Kevin- will perform in a recital.</td>
<td style="text-align: center;">B. Ginny, Juanita, Kevin, Hakim, Fernando $+\mathrm{B}-2$</td>
<td style="text-align: center;">Rules to Logical Expressions</td>
</tr>
<tr>
<td style="text-align: center;">Ginny perform earlier than Fernando. B-1</td>
<td style="text-align: center;">C. Ginny, Kevin, Hakim, Juanita, Fernando $+\mathrm{B}-3$</td>
<td style="text-align: center;">B-1: Pos. of Ginny $&lt;$ Pos. of Fernando</td>
</tr>
<tr>
<td style="text-align: center;">Kevin perform earlier than Hakim and Juanita. B-2</td>
<td style="text-align: center;">D. Kevin, Ginny, Juanita, Fernando, Hakim $&lt;$</td>
<td style="text-align: center;">B-2: (Pos. of Kevin $&lt;$ Pos. of Hakim) \&amp;</td>
</tr>
<tr>
<td style="text-align: center;">Hakim perform either immediately before or immediately after Fernando. B-3</td>
<td style="text-align: center;">E. Kevin, Juanita, Fernando, Hakim, Ginny $+\mathrm{B}-1$</td>
<td style="text-align: center;">(Pos. of Kevin $&lt;$ Pos. of Juanita)</td>
</tr>
<tr>
<td style="text-align: center;">Question</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">B-1: (Pos. of Hakim $=$ Pos. of Fernando +1$)$</td>
</tr>
<tr>
<td style="text-align: center;">Which one of the following could be the order the students perform?</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">(Pos. of Hakim $=$ Pos. of Fernando -1$)$</td>
</tr>
<tr>
<td style="text-align: center;">[Assignment Game] Passage</td>
<td style="text-align: center;">Options</td>
<td style="text-align: center;">Participants</td>
</tr>
<tr>
<td style="text-align: center;">Five cashiers-Adams, Bates, Cox, Drake, and Edwards-each of whom works alone on exactly one day. Monday through Friday</td>
<td style="text-align: center;">A. Edwards, Bates, Adams, Drake, Cox $+\mathrm{B}-1$</td>
<td style="text-align: center;">(Adams, Bates, Cox, Drake, Edwards)</td>
</tr>
<tr>
<td style="text-align: center;">Adams will work only on Tuesday or Thursday. B-1</td>
<td style="text-align: center;">B. Drake, Adams, Bates, Edwards, Cox $+\mathrm{B}-2$</td>
<td style="text-align: center;">Positions</td>
</tr>
<tr>
<td style="text-align: center;">Bates will not work on Monday or Wednesday. B-3</td>
<td style="text-align: center;">C. Edwards, Adams, Cox, Bates, Drake $+\mathrm{F}-1$</td>
<td style="text-align: center;">(Mon.,Tues.,Wed., Thur.,Fri.)</td>
</tr>
<tr>
<td style="text-align: center;">Cox works on Friday. F-1</td>
<td style="text-align: center;">D. Edwards, Adams, Drake, Bates, Cox $+$</td>
<td style="text-align: center;">Rules to Logical Expressions</td>
</tr>
<tr>
<td style="text-align: center;">Edwards don't work next to Drake B-3</td>
<td style="text-align: center;">E. Drake, Edwards, Bates, Adams, Cox $+\mathrm{B}-3$</td>
<td style="text-align: center;">B-1: Adams on Tues. [Adams on Thur.</td>
</tr>
<tr>
<td style="text-align: center;">Question</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">B-2: $\neg$ (Bates on Mon. [Bates on Wed. $)$</td>
</tr>
<tr>
<td style="text-align: center;">Which one of the following is a possible work schedule?</td>
<td style="text-align: center;">Fact</td>
<td style="text-align: center;">R-3: Pos. of Edwards $\neq$ Pos. of Drake +1</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Cox on Fri.</td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>Figure 2: Examples of ordering game and assignment game in AR task. Facts and Rules are highlighted in orange and blue, respectively. Example of grouping game is shown in Figure 1. $\times$ indicates conflict.</p>
<h2>3 Task and Dataset</h2>
<p>In this section, we describe the task of analytical reasoning, introduce the dataset AR-LSAT we collected from the Law School Admission Test and make analysis about the required reasoning skills.</p>
<h3>3.1 Task: Analytical Reasoning of Text</h3>
<p>Taking a passage, a question, and multiple options as the input, a system is required to select the most plausible answer as the output. Each passage describes a reasoning game belonging to various types. According to Kolby (2016), there are three dominant game types in LSAT: ordering games, grouping games, and assignment games, which are described as follows and examples are given in Figures 1 and 2:</p>
<ul>
<li>Ordering games are to order participants based on given facts and rules.</li>
<li>Grouping games are to separate participants into groups with given facts and rules.</li>
<li>Assignment games are to assign characteristics to the participants with given rules, like assigning schedules for people.</li>
</ul>
<h3>3.2 Dataset Collection: AR-LSAT</h3>
<p>We collect data from nearly 90 LSAT exams from 1991 to 2016 and select questions from the analytical reasoning part to construct the dataset, and name it AR-LSAT. Each exam in LSAT consists of 101 multiple choice questions, 24 of which are AR questions. We finally leave up the questions with 5 answer options.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Number of questions</th>
<th style="text-align: left;">2,046</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Average length of passages</td>
<td style="text-align: left;">99.3</td>
</tr>
<tr>
<td style="text-align: left;">Average length of questions</td>
<td style="text-align: left;">19.1</td>
</tr>
<tr>
<td style="text-align: left;">Average length of answers</td>
<td style="text-align: left;">6</td>
</tr>
<tr>
<td style="text-align: left;">Number of options</td>
<td style="text-align: left;">5</td>
</tr>
<tr>
<td style="text-align: left;">Ratio of ordering game</td>
<td style="text-align: left;">$42.5 \%$</td>
</tr>
<tr>
<td style="text-align: left;">Ratio of grouping game</td>
<td style="text-align: left;">$38.75 \%$</td>
</tr>
<tr>
<td style="text-align: left;">Ratio of assignment game</td>
<td style="text-align: left;">$18.75 \%$</td>
</tr>
</tbody>
</table>
<p>Table 1: Data statistics of AR-LSAT dataset.</p>
<h3>3.3 Data Analysis</h3>
<p>As mentioned above, the questions of AR-LSAT come from exams in realistic scenario. Each passage describes a reasoning game belongs to three dominant type: (1) ordering game, (2) grouping game and (3) assignment game. We manually analyze and summarize the ratio of each type of reasoning game in AR-LSAT. The corresponding data statistics and ratios are shown in Table 1. Moreover, the questions in AR-LSAT are further challenging as them require the system to have different kinds of reasoning skills. We manually categorize and analyze question types that are common in AR-LSAT dataset. The detailed description of question types is shown in Table 2. We also notice that the three most common question types: "acceptable solution", "could be true/false" and "must be true/false" associate with most of the passages. There also exist challenging questions, like "calculation" and "substitution" problems. The examples of question types are given in Appendix C.</p>
<h3>3.4 Challenges</h3>
<p>In this part, we point out the reasoning ability required for solving AR questions, and put forward</p>
<table>
<thead>
<tr>
<th>Question Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Acceptable solution (15.6%)</td>
<td>identify a feasible solution that can satisfy all the rules</td>
</tr>
<tr>
<td>Complete list (3.5%)</td>
<td>identify a complete and accurate list of participants under given condition</td>
</tr>
<tr>
<td>Could be true/false (26.8%)</td>
<td>select answer that could be true/false under given condition</td>
</tr>
<tr>
<td>Must be true/false (26.4%)</td>
<td>select answer that must be true/false under given condition</td>
</tr>
<tr>
<td>Negation (14.7%)</td>
<td>questions that contain negation</td>
</tr>
<tr>
<td>Substitution (4.3%)</td>
<td>identify a new rule that can substitute one of the old rules for the desiring result</td>
</tr>
<tr>
<td>Condition for determined solution (3.5%)</td>
<td>identify a new rule so that the feasible solution is determined</td>
</tr>
<tr>
<td>Calculation (3%)</td>
<td>calculate possible participants in a group</td>
</tr>
<tr>
<td>Earliest/latest position (1.3%)</td>
<td>identify the earliest/latest position that a specific participant can be assigned to</td>
</tr>
<tr>
<td>Maximum/minimum members (1.3%)</td>
<td>identify the possible maximum/minimum number of participants in a specific group</td>
</tr>
</tbody>
</table>
<p>Table 2: The ratio and description of each question type in the test set of the AR-LSAT dataset.
the challenges that systems should face. As we can observe from the examples in Figure 1 and Figure 2, solving AR questions needs systems to understand the complex scenario and perform reasoning over it, and has no special needs for external knowledge. In conclusion, AR questions test a range of reasoning skills:</p>
<p>1) Comprehending the knowledge including participants of events, facts, and rules described in the context.
2) Extracting machine-understandable logical functions (expressions) from the rules. For example, the rule "If A serves on $X$, then $B$ serves on $Y$." needs to be transferred as logical expression " $A$ on $X \rightarrow B$ on $Y$ ",
3) Making deductions to derive legitimate solutions that satisfy extracted logical functions.
4) Selecting the answer that satisfies all the rules with the deducted legitimate solutions. In the examples, a system should eliminate options that conflict with rules and select the option that accords with legitimate solutions.</p>
<p>Therefore, this task requires the machine to perform explicit complex reasoning, far beyond just understanding the literal clues presented in the text.</p>
<h2>4 Approaches</h2>
<p>In this section, we describe our two base approaches: (1) Transformer-based approach and (2) Analytical Reasoning Machine (ARM).</p>
<h3>4.1 Transformer-based Approach</h3>
<p>In this approach, we view the analytical reasoning challenge as a multiple-choice question answering problem. We employ state-of-theart pre-trained Transformer-based language models (i.e., BERT (Devlin et al., 2018), XLNet (Yang et al., 2019), RoBERTa (Liu et al.,</p>
<p>2019), and ALBERT (Lan et al., 2019)) for classification as they achieve impressive performance on a wide variety of tasks. Specifically, we take the concatenated sequence $X=$ ${[C L S]$, passage, $[S E P]$, question, option $}$ as the input, where $[C L S]$ is the ending special token and $[S E P]$ is used to split two types of input. The representation of the sequence $H=$ $f_{\text {Transformer }}(X)$ is further fed into a two-layer perceptron $f_{M L P}$ for classification $p_{\theta}(X)=$ $\sigma\left(f_{M L P}(H)\right)$, where $\sigma$ is an activation function. The model parameters $\theta$ of the Transformer and MLP layer are fine-tuned with cross-entropy loss on the training set.</p>
<h3>4.2 Analytical Reasoning Machine (ARM)</h3>
<p>In this part, we describe the logical-level framework, Analytical Reasoning Machine (ARM), which extracts symbolic knowledge from the context and perform reasoning over the knowledge to draw conclusions. Figure 3 gives an overview of the ARM framework. We propose to break down the reasoning process into four stages: (1) extracting arguments (i.e., the participants, positions, facts and rules) from the context (§ 4.2.1); (2) interpreting rules into a set of logical constraint functions, whose arguments are selected from participants and positions (§ 4.2.2); (3) reasoning with the logical functions and finally generating a group of legitimate assignments (solutions) that satisfy all the rules (§ 4.2.3); (4) selecting the most plausible option by matching the legitimate assignments and options (§ 4.2.4).</p>
<p>ARM sheds a light on the logical-level reasoning procedure for analytical reasoning and each procedure can be further developed for both performance and expandability.</p>
<h3>4.2.1 Arguments Extraction</h3>
<p>In order to understand the context and formalize the problem, the first step is to extract the par-</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 3: An overview of our approach. The original example is given in Figure 1. It extracts arguments from the context (§ 4.2.1). Then it extracts logical functions from rules (§ 4.2.2). Afterwards, it conducts deduction to find legitimate assignments (§ 4.2.3). Lastly, it matches the options and legitimate assignments for prediction (§ 4.2.4).</p>
<p><strong>Ticipants, positions, facts and rules expressed in natural language</strong> from the passage and hypothesis of the question. An <strong>assignment</strong> represents a solution that assigns participants to positions, and has a group of values of three possible states: (<em>True</em>, <em>False</em>, <em>Unknown</em>) representing whether a participant is assigned to a position. The <strong>rules</strong> describe the constraints of assignments while the <strong>facts</strong> describe determined initial assignments explicitly mentioned in the context. We take the example in Figure 3 as a running example to show the extracted participants, positions, facts and rules.</p>
<p>Specifically, we extract the entities with a neural Named Entity Recognition (NER) model <em>Peters et al. (2017)</em> and group the extracted entities into participants or positions. Rules and facts are identified by whether a sentence mentions determined assignment. We parse groups of entities that appear together in the leading sentence of the passage as groups of participants or positions, where participants always appear before positions.</p>
<h3>4.2.2 Logical Function Extraction</h3>
<p>We introduce a set of predefined logical functions to express the constraints in the rules, which is the foundation of the reasoning process. A function consists of arguments and an executor, whose input is an assignment and the output is a <em>Bool</em> value indicates whether the assignment satisfies the constraint. The detailed definition of each function is listed in Appendix B. As the fragment shown in Table 3, the logical functions include the following basic types:</p>
<p><strong>Relational Function</strong> The relational functions, whose arguments involve participants or positions, represent the constraints of the relationship between them. For example, the function <em>Before</em>(<em>Ginny</em>, <em>Fernando</em>) indicates that <em>Ginny</em> should be in the position before <em>Fernando</em> in the ordering game. <em>To</em>(<em>A, X</em>) indicates that participant <em>A</em> should be assigned to position <em>X</em>.</p>
<p><strong>Compositional Function</strong> A compositional function expresses the relationship between two sets of functions, like the conditional rule (<em>if-then</em> rule) and the <em>if-and-only-if</em> rule. The arguments of compositional functions involve two sets of sub-functions. For example, the rule "<em>If A serves on the X, then B serves on the Y.</em>" should be expressed as <em>IfThen</em>({<em>To</em>(<em>A, X</em>)},{<em>To</em>(<em>B, Y</em>)}).</p>
<p><strong>Counting Function</strong> The counting functions focus on the calculation problem of participants under specific constraints. The arguments of counting functions involve a participant and a number. For example, <em>LastPos</em>(<em>A, 3</em>) checks whether the participant <em>A</em> is assigned to the last 3 positions.</p>
<p>Based on the extracted arguments, we formalize the rules into logical functions. One straightforward way is to design a symbolic parsing method. For each function, we follow NSM <em>Liang et al. (2016)</em> that uses trigger words to match a potential function. For example, the function <em>Before</em> can be triggered by words "<em>before</em>" and "<em>earlier</em>". Then we select arguments (i.e., participants, positions, and numbers) based on their relative positions to the trigger word. The relational and counting functions can be constituted into compositional functions based on predefined grammar patterns. For example, for the grammar pattern "<em>If P, then Q</em>", Each function is grouped into the function set <em>F</em><sup>1</sup> if it occurs in <em>P</em>, or the function set <em>F</em><sup>2</sup> if it occurs in <em>Q</em>. <em>F</em><sup>1</sup> and <em>F</em><sup>2</sup> are taken as the arguments of the function <em>IfThen</em>.</p>
<p>Furthermore, to handle the uncertain cases and improve the coverage of extracted functions, we build a neural semantic parsing model based on a pre-trained language model RoBERTa <em>Liu et al. (2019)</em>. It takes the sentence and two parsed ar-</p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Function</th>
<th>Args</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Relational Functions</td>
<td>Before/After</td>
<td>participant_{1} participant_{2}</td>
<td>Whether participant_{1} is in the position before/after participant_{2}.</td>
</tr>
<tr>
<td></td>
<td>Same/Different</td>
<td></td>
<td>Whether participant_{1} is in the same/different position with participant_{2}.</td>
</tr>
<tr>
<td></td>
<td>To</td>
<td>participant_{1} position_{1}</td>
<td>Whether participant_{1} is assigned to position_{1}.</td>
</tr>
<tr>
<td>Compositional Functions</td>
<td>IfThen</td>
<td>function set $F_{1}$ function set $F_{2}$</td>
<td>If functions in $F_{1}$ satisfied, then functions in $F_{2}$ satisfied.</td>
</tr>
<tr>
<td>Counting Functions</td>
<td>FirstPos/LastPos</td>
<td>participant_{1}, number $m$</td>
<td>Whether participant_{1} is assigned to the first/last $m$ positions.</td>
</tr>
</tbody>
</table>
<p>Table 3: A fragment of the logical constraint function definition.
guments in the sentence as the input and predicts their potential function type. Specifically, given a rule as the input $X$, we follow Xu et al. (2020) and modify the input by adding special tokens "@" and " $#$ " before and after the first and second parsed arguments respectively. Then we encode sentence X with RoBERTa model as follows:</p>
<p>$$
H=\operatorname{RoBERTa}(X)
$$</p>
<p>Afterwards, we take the representation of the first "@" and "#" for classification.</p>
<p>$$
\text { function }=\operatorname{argmax}\left(\text { classifier }\left(\left[H^{\mathbb{Q}} ; H^{#}\right]\right)\right)
$$</p>
<p>where [;] denotes concatenation, and the classifier is a linear layer followed by a softmax function., and $p$ is the possibilities distribution over class number. Since there is no annotated data of corresponding logical functions, we need to construct the training data automatically. The training data consist of (1) positive instances: all the {input: (rule, arguments); label: function} pairs that extracted by the symbolic parsing method from the training set; (2) negative instances: the same number of instances that have arguments with no function related.</p>
<h3>4.2.3 Legitimate Assignments Deduction</h3>
<p>Given the extracted logical constraint functions and the initial assignment, we conduct reasoning to find the legitimate assignments that satisfy all the constraints. The process is formulated into a tree-based reasoning algorithm. As shown in Figure 4, each node in a tree corresponds to an assignment and each edge indicates a logical function. A node $v$ with path $\left{e_{0}, e_{1}, \ldots, e_{i}\right}$ from the root indicates that its assignment satisfies functions $\left{f_{0}, f_{1}, \ldots, f_{i}\right}$. Suppose we have $n$ constraint functions, we need to find all the leaf nodes with depth $n$. These leaf nodes satisfy all the functions and thus become legitimate assignments.</p>
<p>Function $f_{0}$
$f_{0}=I f \operatorname{Then}({\operatorname{To}(A, X)},{\operatorname{To}(B, Y)})$</p>
<h2>Assignment Generation</h2>
<p>Initial assignment $a_{0}$</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">A</th>
<th style="text-align: center;">B</th>
<th style="text-align: center;">C</th>
<th style="text-align: center;">D</th>
<th style="text-align: center;">E</th>
<th style="text-align: center;">F</th>
<th style="text-align: center;">G</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">X</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">T</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">T</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">Y</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">F</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">F</td>
<td style="text-align: center;">-</td>
</tr>
</tbody>
</table>
<p>(1) Generate possible assignments
(2) Function Execution to find conflict
$a_{1} \quad$|  | A | B | C | D | E | F | G |  | A | B | C | D | E | F | G | $a_{3}$ |
| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
| X | F | T | - | T | - | T | - | X | T | F | - | T | - | T | - |  |
| Y | T | F | - | F | - | F | - | Y | F | T | - | F | - | F | - |  |</p>
<p>$a_{2} \quad$|  | A | B | C | D | E | F | G |  | A | B | C | D | E | F | G | $a_{4}$ |
| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
| X | F | F | - | T | - | T | - | X | T | T | - | 1 | - | T | - |  |
| Y | T | T | - | F | - | F | - | Y | F | F | - | F | - | F | - |  |</p>
<p>Conflict with $f_{0}$
Reasoning Tree Extension
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 4: An example of the reasoning process. Newly added participants in $f_{0}$ are highlighted. (1) and (2) conducted recursively until depth $=n .(T / F /-)=$ (True/False/Unknown)</p>
<p>Therefore, we introduce how to construct the complete reasoning tree by the following steps:</p>
<p>1) Firstly, we start with the root, which is the certain initial assignment decided by facts. For the function $f_{0}$, we generate all possible assignments related to newly added arguments in $f_{0}$. As shown in the example in Figure 4, for the function $\operatorname{IfThen}(\operatorname{To}(A, X), \operatorname{To}(B, Y))$, we generate all possible assignments related to the new participants $A$ and $B$.
2) We execute $f_{0}$ to find all the legitimate assignments that satisfy $f_{0}$ as a group of children of the root. In the same example, we keep the assignments that meets</p>
<p>$\operatorname{IfThen}(\operatorname{To}(A, X), \operatorname{To}(B, Y))$.
3) Then we select each child as a new root and select function $f_{1}$ for further extension of the reasoning tree.</p>
<p>These processes are recursively conducted until depth $n$, which means that all the functions are used to construct the reasoning tree. The tree-based manner reduces the computational complexity and can be further accelerated by ranking the functions. The procedure is summarized into pseudo-code in Appendix A. Therefore, this algorithm has advantages of performing explicit interpretable reasoning over the extracted functions.</p>
<h3>4.2.4 Answer Selection</h3>
<p>Previous steps understand the passage and the question. In this part, we introduce how to analyze the options, and match the options with the deducted legitimate assignments beyond word-level for making a final prediction. Specifically, we can derive two types of information from an option:</p>
<p>1) Assignment-based option indicates an assignment. For example, "A and C both serve on the X committee" can be interpreted as: ${(A, X)=\operatorname{True} ;(C, X)=\operatorname{True}}$. For this type, we match the parsed option assignment with all the legitimate assignments and calculate an assignment-based matching score.
2) Function-based option indicates an option representing a logical function, like "The sedan is serviced earlier in the week than the roadster", which can be parsed into the function "Before(sedan, roadster)". We execute the option-based function on the legitimate assignments to find the satisfiable option and calculate a function-based matching score.</p>
<p>These two types of scores are combined for making a conclusion. The question types and score calculating methods are summarized in the Appendix C.</p>
<h2>5 Experiments</h2>
<p>In this section, we focus on evaluating the presented methods on AR-LSAT. We split the data into $($ train $/ d e v . /$ test $)=(1,585 / 231 / 230)$. We also hold out a small test set for human evaluation. Moreover, case study illustrates the reasoning process of the ARM method by an explicit example. Lastly, we make error analysis to point out challenges in this task.</p>
<h3>5.1 Model Comparison</h3>
<p>Human Performance Since the dataset is based on a test designed for undergraduate students, we select nearly 100 instances in the AR-LSAT dataset and ask 10 undergraduate college students majoring in literature, commerce and law to answer these questions. In order to prevent the training bias, we select students who have not received LSAT professional training before. We take their averaged performance as human performance and report it in Table 5.</p>
<p>Transformer-based Methods We take various powerful Transformer-based pre-trained language models, including BERT (Devlin et al., 2018), XLNet (Yang et al., 2019), RoBERTa (Liu et al., 2019), and the recent ALBERT (Lan et al., 2019)), as the backbones of the Transformer-based methods and investigate their performance on the AR-LSAT dataset. The implementation details of these models are given in Appendix D.</p>
<p>ARM To evaluate the performance of arguments extraction, we manually annotate the correct participants and positions in the development set as labels and report the accuracy and recall of in Table 4. For function extraction, we define a API set to include roughly 20 types of logical functions like Before, After, To, IfThen and realize their executors. The detailed definition of functions can be found in Appendix B.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">Acc. (\%)</th>
<th style="text-align: center;">Recall (\%)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Participants</td>
<td style="text-align: center;">96.17</td>
<td style="text-align: center;">92.88</td>
</tr>
<tr>
<td style="text-align: left;">Positions</td>
<td style="text-align: center;">84.42</td>
<td style="text-align: center;">85.79</td>
</tr>
</tbody>
</table>
<p>Table 4: Performance of extraction of participants and positions on the development set.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Methods</th>
<th style="text-align: center;">Dev. <br> Acc (\%)</th>
<th style="text-align: center;">Test <br> Acc (\%)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Human Performance</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">$59.7 \%$</td>
</tr>
<tr>
<td style="text-align: left;">Random Guess</td>
<td style="text-align: center;">$20.0 \%$</td>
<td style="text-align: center;">$20.0 \%$</td>
</tr>
<tr>
<td style="text-align: left;">BERT</td>
<td style="text-align: center;">$23.4 \%$</td>
<td style="text-align: center;">$21.4 \%$</td>
</tr>
<tr>
<td style="text-align: left;">XLNet</td>
<td style="text-align: center;">$23.8 \%$</td>
<td style="text-align: center;">$22.5 \%$</td>
</tr>
<tr>
<td style="text-align: left;">RoBERTa</td>
<td style="text-align: center;">$24.2 \%$</td>
<td style="text-align: center;">$23.1 \%$</td>
</tr>
<tr>
<td style="text-align: left;">ALBERT</td>
<td style="text-align: center;">$24.4 \%$</td>
<td style="text-align: center;">$23.0 \%$</td>
</tr>
<tr>
<td style="text-align: left;">ARM</td>
<td style="text-align: center;">$34.2 \%$</td>
<td style="text-align: center;">$30.9 \%$</td>
</tr>
</tbody>
</table>
<p>Table 5: The performance on the AR-LSAT dataset.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Passage: A professor must determine the order in which five of her students - Fernando, Ginny, Hakim, Juanita, and Kevin - will perform in an upcoming piano recital. Each student performs one piece, and no two performances overlap. The following constraints apply: Ginny must perform earlier than Fernando. Kevin must perform earlier than Hakim and Juanita. Hakim must perform either immediately before or immediately after Fernando.</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Question: If Juanita performs earlier than Ginny, then which one of the following could be true?</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Options: $(A)$ Fernando performs fourth. $\sqrt{ }(B)$ Ginny performs second. $(C)$ Hakim performs third. $(D)$ Juanita performs third. $(E)$ Kevin performs second</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Participants \&amp; Positions</td>
<td style="text-align: center;">Fernando, Ginny, Hakim, Juanita, Kevin</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">first, second, third, fourth, fifth</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Rules \&amp; Functions</td>
<td style="text-align: center;">(1) Ginny must perform earlier than Fernando. <br> (2) Kevin must perform earlier than Hakim and Juanita. <br> (3) Hakim must perform either immediately before or <br> immediately after Fernando. <br> (4) Juanita performs earlier than Ginny</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">(1) Before (Ginny, Fernando) <br> (2) And ([Before (Kevin, Hakim]), [Before (Kevin, Juanita)]) <br> (3) Or ([Next (Hakim, Fernando)], [Last (Hakim, Fernando)]) <br> (4) Before (Juanita, Ginny)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Legal Assignments</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$y^{\text {of }}$</td>
<td style="text-align: center;">$y^{\text {of }}$</td>
<td style="text-align: center;">$y^{\text {of }}$</td>
<td style="text-align: center;">$y^{\text {of }}$</td>
<td style="text-align: center;">$y^{\text {of }}$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">$y^{\text {of }}$</td>
<td style="text-align: center;">$y^{\text {of }}$</td>
<td style="text-align: center;">$y^{\text {of }}$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Fernando</td>
<td style="text-align: center;">F</td>
<td style="text-align: center;">F</td>
<td style="text-align: center;">F</td>
<td style="text-align: center;">T</td>
<td style="text-align: center;">F</td>
<td style="text-align: center;">Fernando</td>
<td style="text-align: center;">F</td>
<td style="text-align: center;">F</td>
<td style="text-align: center;">F</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Ginny</td>
<td style="text-align: center;">F</td>
<td style="text-align: center;">F</td>
<td style="text-align: center;">T</td>
<td style="text-align: center;">F</td>
<td style="text-align: center;">F</td>
<td style="text-align: center;">Ginny</td>
<td style="text-align: center;">F</td>
<td style="text-align: center;">F</td>
<td style="text-align: center;">T</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Hakim</td>
<td style="text-align: center;">F</td>
<td style="text-align: center;">F</td>
<td style="text-align: center;">F</td>
<td style="text-align: center;">F</td>
<td style="text-align: center;">T</td>
<td style="text-align: center;">Hakim</td>
<td style="text-align: center;">F</td>
<td style="text-align: center;">F</td>
<td style="text-align: center;">F</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Juanita</td>
<td style="text-align: center;">F</td>
<td style="text-align: center;">T</td>
<td style="text-align: center;">F</td>
<td style="text-align: center;">F</td>
<td style="text-align: center;">F</td>
<td style="text-align: center;">Juanita</td>
<td style="text-align: center;">F</td>
<td style="text-align: center;">T</td>
<td style="text-align: center;">F</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Kevin</td>
<td style="text-align: center;">T</td>
<td style="text-align: center;">F</td>
<td style="text-align: center;">F</td>
<td style="text-align: center;">F</td>
<td style="text-align: center;">F</td>
<td style="text-align: center;">Kevin</td>
<td style="text-align: center;">T</td>
<td style="text-align: center;">F</td>
<td style="text-align: center;">F</td>
</tr>
<tr>
<td style="text-align: center;">Option Scores</td>
<td style="text-align: center;">(A) $1(B)-1(C)-1(D)-1(E)-1$</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>Figure 5: A case study on the AR-LSAT dataset. Our system correctly extracts participants, positions, and rules from the context. Afterwards, it interprets rules into logical functions. After deduction, our system finds legitimate assignments and makes the correct prediction. Rules are highlighted in blue.</p>
<p>Results In Table 5, we report the performance of different methods and human performance on the development and test set. Firstly, we observe that the Transformer-based models struggle to do well on this task, and achieve close performance with random guess. This observation indicates that analytical reasoning is extremely challenging for current neural pre-trained language models as it requires the ability of complex reasoning. In addition, ARM with context understanding and explicit reasoning process outperforms Transformer-based method with $34.2 \%$ accuracy on the development set and $30.9 \%$ accuracy on the test set. It is also noticed that the performance of both our system and baselines are still far from human performance, leaving significant opportunities for further exploration.</p>
<h3>5.2 Case Study</h3>
<p>We present a case study in Figure 5 to illustrate the reasoning process of the ARM framework with interpretable results. ARM extracts correct arguments from the context, and interprets the rules into logical constraint functions. Afterwards, it performs deduction to find legitimate solutions. Lastly, it matches the options with the legitimate solutions and calculates a score for each option. Option $A$ achieves the highest score because it accords with legitimate assignments. This analysis demonstrates that ARM has better explicit interpretable reasoning ability.</p>
<h3>5.3 Error Analysis</h3>
<p>We randomly select 50 instances that are wrongly predicted by ARM from the development set and manually summarize the major error types.</p>
<p>The dominant error type is that some rules with complex semantics are not covered by current constraint logical function set. For example, given a rule "Each crew member does at least one task during the installation." , we should map "At least" to function AtLeastNum.</p>
<p>The second type of errors is caused by failing to extract correct participants or positions by the NER model and predefined matching pattern.</p>
<p>The third error type is caused by the lack of basic commonsense knowledge, which is required for understanding the concept in the rules. For example, when a passage mentioned "Six entertainers should be scheduled at 9:00 A.M., 2:00 P.M., etc" and the rule is "Some participants should be scheduled in the morning.", the system fails to match the morning with a specific time zone.</p>
<h3>5.4 Discussion</h3>
<p>We would like to further highlight important directions to facilitate research on analytical reasoning.</p>
<p>One of the major challenges lies in deep understanding of the knowledge in the context, like parsing the rules into logically equivalent symbolic functions. Deriving machine-understandable functions from natural language is an essential step towards deeper understanding and reasoning. Although supervised semantic parsing has achieved</p>
<p>promising progress in recent years, obtaining complete human-annotated logical functions is impractical for this task. Therefore, further study can focus on function extraction with no annotated functions or small amount of annotated functions.</p>
<p>Furthermore, a better inference engine built upon logical functions is also essential because AR questions require deeper reasoning abilities far beyond just understanding the literal clues. Standard symbolic systems like expert systems can provide explicit reasoning, but they are difficult to deal with uncertainty in data. Although neural-based methods are more flexible at dealing with uncertainty, they still struggle to perform interpretable and explicit reasoning. It is promising to better integrate neural and symbolic systems to improve this task with deeper reasoning ability.</p>
<h2>6 Conclusion</h2>
<p>In this paper, we study the challenging task of analytical reasoning and introduce a dataset AR-LSAT to facilitate research on analytical reasoning. We analyze the knowledge understanding and reasoning ability required for this task and present two basic approaches: a Transformer-based approach and a logical-level reasoning framework, named Analytical Reasoning Machine (ARM). ARM extracts symbolic knowledge, including participants, facts and rules mentioned in the context and extract logical functions from the rules. Afterwards, it performs deep reasoning to find all the legitimate solutions to the problem posed and finally makes a prediction. ARM sheds a light on the reasoning procedure for analytical reasoning, and each component can be further developed. Experiments show that this task is very challenging for current Transformer-based pre-trained language models and ARM outperforms them with better performance and interpretability. Further discussions are made to shed light on important future directions.</p>
<h2>References</h2>
<p>Chandra Bhagavatula, Ronan Le Bras, Chaitanya Malaviya, Keisuke Sakaguchi, Ari Holtzman, Hannah Rashkin, Doug Downey, Scott Wen tau Yih, and Yejin Choi. 2019. Abductive commonsense reasoning.</p>
<p>Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning. 2015. A large annotated corpus for learning natural language inference.</p>
<p>In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics.</p>
<p>Peter Clark, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord, Peter Turney, and Daniel Khashabi. 2016. Combining retrieval, statistics, and inference to answer elementary science questions. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 30.</p>
<p>Ido Dagan, Oren Glickman, and Bernardo Magnini. 2005. The pascal recognising textual entailment challenge. pages 177-190.</p>
<p>Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.</p>
<p>Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, and Matt Gardner. 2019. Drop: A reading comprehension benchmark requiring discrete reasoning over paragraphs. arXiv preprint arXiv:1903.00161.</p>
<p>Felix A Gers, Jürgen Schmidhuber, and Fred Cummins. 1999. Learning to forget: Continual prediction with lstm.</p>
<p>Mohammad Javad Hosseini, Hannaneh Hajishirzi, Oren Etzioni, and Nate Kushman. 2014. Learning to solve arithmetic word problems with verb categorization. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 523-533.</p>
<p>Lifu Huang, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. 2019a. Cosmos qa: Machine reading comprehension with contextual commonsense reasoning. arXiv preprint arXiv:1909.00277.</p>
<p>Lifu Huang, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. 2019b. Cosmos QA: Machine reading comprehension with contextual commonsense reasoning. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 2391-2401, Hong Kong, China. Association for Computational Linguistics.</p>
<p>Naoya Inoue, Pontus Stenetorp, and Kentaro Inui. 2020. R4C: A benchmark for evaluating RC systems to get the right answer for the right reason. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 6740-6750, Online. Association for Computational Linguistics.</p>
<p>Tushar Khot, Ashish Sabharwal, and Peter Clark. 2018. SciTail: A textual entailment dataset from science question answering. In AAAI.</p>
<p>Jeff Kolby. 2016. Master The LSAT: Includes 4 Official LSATs! (Nova's Master the LSAT). Nova Press (August 17, 2016).</p>
<p>Rik Koncel-Kedziorski, Hannaneh Hajishirzi, Ashish Sabharwal, Oren Etzioni, and Siena Dumas Ang. 2015. Parsing algebraic word problems into equations. Transactions of the Association for Computational Linguistics, 3:585-597.</p>
<p>Nate Kushman, Yoav Artzi, Luke Zettlemoyer, and Regina Barzilay. 2014. Learning to automatically solve algebra word problems. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 271-281.</p>
<p>Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and Radu Soricut. 2019. Albert: A lite bert for self-supervised learning of language representations. arXiv preprint arXiv:1909.11942.</p>
<p>Chen Liang, Jonathan Berant, Quoc Le, Kenneth D Forbus, and Ni Lao. 2016. Neural symbolic machines: Learning semantic parsers on freebase with weak supervision. arXiv preprint arXiv:1611.00020.</p>
<p>Wang Ling, Dani Yogatama, Chris Dyer, and Phil Blunsom. 2017. Program induction by rationale generation: Learning to solve and explain algebraic word problems. arXiv preprint arXiv:1705.04146.</p>
<p>Hanmeng Liu, Leyang Cui, Jian Liu, and Yue Zhang. 2020a. Natural language inference in contextinvestigating contextual reasoning over long texts. arXiv preprint arXiv:2011.04864.</p>
<p>Jian Liu, Leyang Cui, Hanmeng Liu, Dandan Huang, Yile Wang, and Yue Zhang. 2020b. Logiqa: A challenge dataset for machine reading comprehension with logical reasoning. Proceedings of the TwentyNinth International Joint Conference on Artificial Intelligence.</p>
<p>Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692.</p>
<p>Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston, and Douwe Kiela. 2019. Adversarial nli: A new benchmark for natural language understanding. ArXiv, abs/1910.14599.</p>
<p>Simon Ostermann, Michael Roth, Ashutosh Modi, Stefan Thater, and Manfred Pinkal. 2018. Semeval2018 task 11: Machine comprehension using commonsense knowledge. In Proceedings of the 12th International Workshop on semantic evaluation, pages $747-757$.</p>
<p>Jeffrey Pennington, Richard Socher, and Christopher Manning. 2014. GloVe: Global vectors for word representation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1532-1543, Doha, Qatar. Association for Computational Linguistics.</p>
<p>Matthew E Peters, Waleed Ammar, Chandra Bhagavatula, and Russell Power. 2017. Semi-supervised sequence tagging with bidirectional language models. arXiv preprint arXiv:1705.00108.</p>
<p>Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9.</p>
<p>Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. Squad: 100,000+ questions for machine comprehension of text. arXiv preprint arXiv:1606.05250.</p>
<p>Hannah Rashkin, Maarten Sap, Emily Allaway, Noah A Smith, and Yejin Choi. 2018. Event2mind: Commonsense inference on events, intents, and reactions. arXiv preprint arXiv:1805.06939.</p>
<p>David Saxton, Edward Grefenstette, Felix Hill, and Pushmeet Kohli. 2019. Analysing mathematical reasoning abilities of neural models. arXiv preprint arXiv:1904.01557.</p>
<p>Alon Talmor and Jonathan Berant. 2018. The web as a knowledge-base for answering complex questions. In NAACL-HLT.</p>
<p>Alon Talmor, Yanai Elazar, Yoav Goldberg, and Jonathan Berant. 2020. olmpics-on what language model pre-training captures. Transactions of the Association for Computational Linguistics, 8:743-758.</p>
<p>Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. 2018. Commonsenseqa: A question answering challenge targeting commonsense knowledge. arXiv preprint arXiv:1811.00937.</p>
<p>Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R. Bowman. 2018. GLUE: A multi-task benchmark and analysis platform for natural language understanding. CoRR, abs/1804.07461.</p>
<p>Johannes Welbl, Pontus Stenetorp, and Sebastian Riedel. 2017. Constructing datasets for multi-hop reading comprehension across documents.</p>
<p>Johannes Welbl, Pontus Stenetorp, and Sebastian Riedel. 2018. Constructing datasets for multi-hop reading comprehension across documents. Transactions of the Association for Computational Linguistics, 6:287-302.</p>
<p>Sean Welleck, Jason Weston, Arthur Szlam, and Kyunghyun Cho. 2018. Dialogue natural language inference.</p>
<p>Adina Williams, Nikita Nangia, and Samuel Bowman. 2018. A broad-coverage challenge corpus for sentence understanding through inference. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 1112-1122, New Orleans,</p>
<p>Louisiana. Association for Computational Linguistics.</p>
<p>Chad C Williams, Mitchel Kappen, Cameron D Hassall, Bruce Wright, and Olave E Krigolson. 2019. Thinking theta and alpha: Mechanisms of intuitive and analytical reasoning. NeuroImage, 189:574580 .</p>
<p>Zenan Xu, Daya Guo, Duyu Tang, Qinliang Su, Linjun Shou, Ming Gong, Wanjun Zhong, Xiaojun Quan, Nan Duan, and Daxin Jiang. 2020. Syntax-enhanced pre-trained model. arXiv preprint arXiv:2012.14116.</p>
<p>Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ R Salakhutdinov, and Quoc V Le. 2019. Xlnet: Generalized autoregressive pretraining for language understanding. In Advances in neural information processing systems, pages 5753-5763.</p>
<p>Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhutdinov, and Christopher D. Manning. 2018a. Hotpotqa: A dataset for diverse, explainable multi-hop question answering. Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing.</p>
<p>Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W Cohen, Ruslan Salakhutdinov, and Christopher D Manning. 2018b. Hotpotqa: A dataset for diverse, explainable multi-hop question answering. arXiv preprint arXiv:1809.09600.</p>
<p>Weihao Yu, Zihang Jiang, Yanfei Dong, and Jiashi Feng. 2020. Reclor: A reading comprehension dataset requiring logical reasoning. arXiv preprint arXiv:2002.04326.</p>
<p>Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi. 2019. Hellaswag: Can a machine really finish your sentence? arXiv preprint arXiv:1905.07830.</p>
<p>Sheng Zhang, Xiaodong Liu, Jingjing Liu, Jianfeng Gao, Kevin Duh, and Benjamin Van Durme. 2018. Record: Bridging the gap between human and machine commonsense reading comprehension. arXiv preprint arXiv:1810.12885.</p>
<p>Ben Zhou, Daniel Khashabi, Qiang Ning, and Dan Roth. 2019. " going on a vacation" takes longer than" going for a walk": A study of temporal commonsense understanding. arXiv preprint arXiv:1909.03065.</p>
<h2>A Pseudo-code of Legitimate Assignments Deduction</h2>
<div class="codehilite"><pre><span></span><code><span class="nl">Require</span><span class="p">:</span><span class="w"> </span><span class="n">A</span><span class="w"> </span><span class="k">set</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="k">constraint</span><span class="w"> </span><span class="n">functions</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="n">F</span><span class="o">=</span><span class="err">\</span><span class="nf">left</span><span class="err">\{</span><span class="n">f_</span><span class="err">{</span><span class="mi">0</span><span class="err">}</span><span class="p">,</span><span class="w"> </span><span class="n">f_</span><span class="err">{</span><span class="mi">1</span><span class="err">}</span><span class="p">,</span><span class="w"> </span><span class="err">\</span><span class="n">ldots</span><span class="p">,</span><span class="w"> </span><span class="n">f_</span><span class="err">{</span><span class="n">n</span><span class="err">}\</span><span class="nf">right</span><span class="err">\}\</span><span class="p">)</span>
<span class="w">    </span><span class="ow">and</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="n">initial</span><span class="w"> </span><span class="n">assignment</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="n">a_</span><span class="err">{</span><span class="mi">0</span><span class="err">}\</span><span class="p">)</span>
<span class="w">    </span><span class="k">function</span><span class="w"> </span><span class="n">CONSTRUCTTREE</span><span class="p">(</span><span class="n">node</span><span class="p">,</span><span class="n">functions</span><span class="p">,</span><span class="k">depth</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="k">depth</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="o">==</span><span class="n">n</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="k">then</span><span class="err">:</span>
<span class="w">            </span><span class="k">return</span>
<span class="w">        </span><span class="k">end</span><span class="w"> </span><span class="k">if</span>
<span class="w">        </span><span class="k">function</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="o">=</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="n">functions</span><span class="o">[</span><span class="n">depth</span><span class="o">]</span>
<span class="w">        </span><span class="n">old_pars</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">node</span><span class="p">.</span><span class="n">participants</span>
<span class="w">        </span><span class="n">old_assign</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">node</span><span class="p">.</span><span class="n">assignment</span>
<span class="w">        </span><span class="n">new_pars</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">find_new_participant</span><span class="p">(</span><span class="k">function</span><span class="p">,</span><span class="w"> </span><span class="n">old_pars</span><span class="p">)</span>
<span class="w">        </span><span class="n">all_assign</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">gen_all_assign</span><span class="p">(</span><span class="n">old_assign</span><span class="p">,</span><span class="w"> </span><span class="n">new_pars</span><span class="p">)</span>
<span class="w">        </span><span class="n">satisfied</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">find_satisfied</span><span class="p">(</span><span class="n">all_assign</span><span class="p">,</span><span class="w"> </span><span class="k">function</span><span class="p">)</span>
<span class="w">        </span><span class="k">depth</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="o">=</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="k">depth</span><span class="w"> </span><span class="o">+</span><span class="mi">1</span>
<span class="w">        </span><span class="n">children</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">update_notes</span><span class="p">(</span><span class="n">node</span><span class="p">,</span><span class="w"> </span><span class="n">satisfied</span><span class="p">,</span><span class="w"> </span><span class="n">new_pars</span><span class="p">)</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">child</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">children</span><span class="w"> </span><span class="n">do</span>
<span class="w">            </span><span class="n">CONSTRUCTTREE</span><span class="p">(</span><span class="n">child</span><span class="p">,</span><span class="w"> </span><span class="n">functions</span><span class="p">,</span><span class="w"> </span><span class="k">depth</span><span class="p">,</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="n">n</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="p">)</span>
<span class="w">        </span><span class="k">end</span><span class="w"> </span><span class="k">for</span>
<span class="w">    </span><span class="k">end</span><span class="w"> </span><span class="k">function</span>
<span class="w">    </span><span class="err">\</span><span class="p">(</span><span class="mi">17</span><span class="err">:</span><span class="w"> </span><span class="err">\</span><span class="n">operatorname</span><span class="err">{</span><span class="n">root</span><span class="err">}</span><span class="o">=</span><span class="err">\</span><span class="n">operatorname</span><span class="err">{</span><span class="n">Node</span><span class="err">}\</span><span class="nf">left</span><span class="p">(</span><span class="n">a_</span><span class="err">{</span><span class="mi">0</span><span class="err">}\</span><span class="nf">right</span><span class="p">)</span><span class="err">\</span><span class="p">)</span>
<span class="w">    </span><span class="err">\</span><span class="p">(</span><span class="mi">18</span><span class="err">:</span><span class="w"> </span><span class="err">\</span><span class="n">operatorname</span><span class="err">{</span><span class="k">depth</span><span class="err">}</span><span class="o">=</span><span class="mi">0</span><span class="err">\</span><span class="p">)</span>
<span class="w">    </span><span class="err">\</span><span class="p">(</span><span class="mi">19</span><span class="err">:</span><span class="w"> </span><span class="n">n</span><span class="o">=</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="n">length</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="n">F</span><span class="err">\</span><span class="p">)</span>
<span class="w">    </span><span class="mi">20</span><span class="err">:</span><span class="w"> </span><span class="n">complete_tree</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CONSTRUCTTREE</span><span class="p">(</span><span class="n">root</span><span class="p">,</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="n">F</span><span class="err">\</span><span class="p">),</span><span class="w"> </span><span class="k">depth</span><span class="p">,</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="n">n</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="p">)</span>
<span class="w">    </span><span class="mi">21</span><span class="err">:</span><span class="w"> </span><span class="n">legitimate</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="o">=</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="n">nodes</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">complete_tree</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="k">depth</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="n">n</span><span class="err">\</span><span class="p">)</span>
<span class="w">    </span><span class="mi">22</span><span class="err">:</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">legitimate</span>
</code></pre></div>

<h2>B Function Definition</h2>
<p>In this part, we present the detailed description and trigger words for each logical constraint functions in Table 7.</p>
<h2>C Question Type</h2>
<p>In this part, we list common question types in the AR-LSAT datasets and give examples in Table 6. We further introduce how we calculate a score for dominant question type with a group of legitimate assignments.</p>
<p>1) Must be true/false: this question type needs to select answer that must be true in all the assignments. We match all the assignments with the option. If one option accords/conflicts with one assignment, the single matching score will be $1 /-1$, otherwise the score will be 0 . We then calculate the sum of all the matching scores as the final score.
2) Could be true/false: this question type needs to select answer that could be true in one of the legitimate assignments. We match all the assignments with the option. If one option accords/conflicts with one assignment, the single matching score will be $1 /-1$, otherwise the score will be 0 . We then calculate the maximum matching scores as the final score. The</p>
<table>
<thead>
<tr>
<th>Question Type</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>Acceptable solution</td>
<td>Which one of the following could be the schedule of the students’ reports?</td>
</tr>
<tr>
<td>Complete list</td>
<td>Which one of the following could be a complete and accurate list of the books placed on the bottom shelf?</td>
</tr>
<tr>
<td>Could be true/false with condition</td>
<td>If Himalayans are not featured on day 7. which one of the following could be true?</td>
</tr>
<tr>
<td>Must be true/false with condition</td>
<td>If Theresa tests G on the second day. then which one of the following must be true?</td>
</tr>
<tr>
<td>Negation</td>
<td>P CANNOT be performed at?</td>
</tr>
<tr>
<td>Substitution</td>
<td>Which one of the following. if substituted for the condition that Waite’s audition must take place earlier than the two recorded auditions. would have the same effect in determining the order of the auditions?</td>
</tr>
<tr>
<td>Condition for unique solution</td>
<td>The assignment of parking spaces to each of the new employees is fully and uniquely determined if which one of the following is true?</td>
</tr>
<tr>
<td>Calculation</td>
<td>How many of the students are there who could be the one assigned to 1921?</td>
</tr>
<tr>
<td>Earliest/latest position</td>
<td>If Zircon performs in an earlier slot than Yardsign. which one of the following is the earliest slot in which Wellspring could perform?</td>
</tr>
<tr>
<td>Maximum/minimum members</td>
<td>What is the minimum number of solos in which Wayne performs a traditional piece?</td>
</tr>
</tbody>
</table>
<p>Table 6: Question types of AR-LSAT dataset.</p>
<p><em>Acceptable solution</em> question type also use this method to calculate score.</p>
<p>3) <strong>Maximum number of participants in a position</strong>: this question type needs to calculate the maximum possible number of participants in a specified position (group). We calculate the maximum number of participants in all the legitimate assignments and calculate the absolute difference with the number in the option as the final score.</p>
<p>4) <strong>Find the earliest position of a participant</strong>: this question type needs to calculate the earliest possible position of a specific participant. We calculate the index of the earliest position of the participant in all the legitimate assignments and calculate the absolute difference with the number in the option as the final score.</p>
<p>5) <strong>Count the number of possible positions that a participant can be assigned in</strong>: for this question type, we count all the non-repetitive assignments of the specific participant and calculate the absolute difference with the number in the option as the final score.</p>
<h2>D Baseline Models</h2>
<h3>D.1 Descriptions</h3>
<ul>
<li><strong>LSTM</strong> (Gers et al., 1999) is a classical RNN-based model. We apply Bi-LSTM with GloVE (Pennington et al., 2014) embedding.</li>
<li><strong>BERT</strong> (Devlin et al., 2018) is a transformer-based model pre-trained on BooksCorpus and Wikipedia with two unsupervised learning task: Masked LM and Nest Sentence Prediction.</li>
<li><strong>XLNet</strong> (Yang et al., 2019) is also a transformer-based model, pre-trained on BooksCorpus, Wikipedia, Giga5, ClueWeb 2012-B and Common Crawl with Permutation Language Modeling.</li>
<li><strong>RoBERTa</strong> (Liu et al., 2019) is a transformer-based model with the same model structure as BERT but trained on a larger corpus and on a different training setting.</li>
<li><strong>ALBERT</strong> (Lan et al., 2019) is a most recent transformer-based pre-trained model. ALBERT uses parameter-reduction techniques that support large-scale configurations.</li>
</ul>
<h3>D.2 Implementation Details</h3>
<p>For all the baselines, we employ cross-entropy loss as the loss function and select AdamW as the optimizer for model training/fine-tuning. These baselines add a simple classification layer on the top of them and take the the last hidden state as the input. For all the Transformer-based models, we employ base model as the backbone.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Type</th>
<th style="text-align: center;">Function</th>
<th style="text-align: center;">Arguments</th>
<th style="text-align: center;">Description</th>
<th style="text-align: center;">Trigger Words</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Relational <br> Functions</td>
<td style="text-align: center;">Before</td>
<td style="text-align: center;">participant 1 participant 2</td>
<td style="text-align: center;">whether participant 1 is in the position before participant 2</td>
<td style="text-align: center;">before, above, precede, earlier</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">After</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">whether participant 1 is in the position after participant 2</td>
<td style="text-align: center;">after, larger, higher bigger, older</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Last</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">whether participant 1 is in the last position of participant 2</td>
<td style="text-align: center;">immediately before, last</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Next</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">whether participant 1 is next to participant 2</td>
<td style="text-align: center;">immediately after, next</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Adjacent</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">whether participant 1 is neighboring to participant 2</td>
<td style="text-align: center;">neighboring, adjacent</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Different</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">whether participant 1 in the different position with participant 2</td>
<td style="text-align: center;">different</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Same</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">whether the first participant in the same position with the second participant</td>
<td style="text-align: center;">same, also</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">BeforeEqual</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">whether participant 1 before or equals to the position of participant 2</td>
<td style="text-align: center;">no later</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">AfterEqual</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">whether participant 1 after or equals to the position of participant 2</td>
<td style="text-align: center;">no earlier</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">To</td>
<td style="text-align: center;">participant position</td>
<td style="text-align: center;">Whether the participant is assigned to the position</td>
<td style="text-align: center;">to, on, give, in</td>
</tr>
<tr>
<td style="text-align: center;">Compos. <br> Functions</td>
<td style="text-align: center;">IfThen</td>
<td style="text-align: center;">function set 1 function set 2</td>
<td style="text-align: center;">If rules in rule set 1 satisfied, then rules in rule set 2 satisfied</td>
<td style="text-align: center;">If... then, If ... , ...</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">IFF</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Rules in rule set 1 satisfied if and only if rules in rule set 2 satisfied</td>
<td style="text-align: center;">if and only if</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">And</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Rules in rule set 1 satisfied and rules in the rule set 2 satisfied</td>
<td style="text-align: center;">and</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Or</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Rules in rule set 1 satisfied or rules in rule set 2 satisfied</td>
<td style="text-align: center;">or</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Unless</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Rules in rule set 1 satisfied unless rules in rule set 2 satisfied</td>
<td style="text-align: center;">unless</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Neither</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Neither rules in rule set 1 satisfied nor rules in rule set 2 satisfied</td>
<td style="text-align: center;">Neither ... nor ...</td>
</tr>
<tr>
<td style="text-align: center;">Counting <br> Functions</td>
<td style="text-align: center;">FirstPos</td>
<td style="text-align: center;">participant number</td>
<td style="text-align: center;">Whether the participant is in the last (number) positions</td>
<td style="text-align: center;">one of the <br> last (number)</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">LastPos</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Whether the participant is in the first (number) positions</td>
<td style="text-align: center;">one of the first (number)</td>
</tr>
</tbody>
</table>
<p>Table 7: Detailed function descriptions and corresponding trigger words</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{2}$ https://en.wikipedia.org/wiki/Law_ School_Admission_Test&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>