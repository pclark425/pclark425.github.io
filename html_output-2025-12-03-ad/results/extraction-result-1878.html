<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1878 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1878</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1878</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-36.html">extraction-schema-36</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that use computational or proxy metrics to make predictions or discoveries, and how those predictions compare to experimental or ground-truth validation results.</div>
                <p><strong>Paper ID:</strong> paper-279227829</p>
                <p><strong>Paper Title:</strong> AI-Driven Drug Discovery: A Comprehensive Review</p>
                <p><strong>Paper Abstract:</strong> Artificial intelligence (AI) and machine learning (ML) offer transformative potential to address the persistent challenges of traditional drug discovery, characterized by high costs, lengthy timelines, and low success rates. This comprehensive review critically analyzes recent advancements (2019–2024) in AI/ML methodologies across the entire drug discovery pipeline, from target identification to clinical development. We examine diverse AI techniques, including deep learning, graph neural networks, and transformers, focusing on their application in key areas such as target identification, lead discovery, hit optimization, and preclinical safety assessment. Our in-depth comparative analysis highlights the advantages, limitations, and practical challenges associated with different AI approaches, emphasizing critical factors for successful implementation such as data quality, model validation, and ethical considerations. The review synthesizes current applications, identifies persistent gapsparticularly in data accessibility, interpretability, and clinical translationand proposes future directions to unlock the full potential of AI in creating safer, more effective, and accessible medicines. By emphasizing transparent methodologies, robust validation, and ethical frameworks, this review aims to guide the responsible and impactful integration of AI into pharmaceutical research and development.</p>
                <p><strong>Cost:</strong> 0.026</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1878.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1878.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that use computational or proxy metrics to make predictions or discoveries, and how those predictions compare to experimental or ground-truth validation results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Multi-fidelity GNN Transfer Learning (Buterez et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Transfer learning with graph neural networks for improved molecular property prediction in the multi-fidelity setting</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A GNN-based transfer-learning framework that integrates low-fidelity primary HTS (proxy) data with sparse high-fidelity confirmatory assay data to improve molecular property prediction and virtual screening performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Transfer learning with graph neural networks for improved molecular property prediction in the multi-fidelity setting.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>GNN transfer-learning multi-fidelity framework</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>drug discovery / high-throughput screening</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_name</strong></td>
                            <td>Primary HTS activity readouts (low-fidelity assay measurements used as a proxy for confirmatory potency/activity)</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_type</strong></td>
                            <td>multifidelity data-driven ML model (transfer learning across fidelity levels)</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_description</strong></td>
                            <td>Primary high-throughput screening (HTS) measurements (large-scale, noisy single-concentration or surrogate readouts) are used as low-fidelity training data; a Graph Neural Network is pretrained or transfer-fine-tuned on these data then adapted to predict high-fidelity confirmatory assay endpoints (dose–response, IC50/Ki) from sparse labels.</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_metric_name</strong></td>
                            <td>High-fidelity confirmatory HTS assay results (dose–response potency measurements, e.g., IC50/Ki)</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_validation_method</strong></td>
                            <td>Comparison to confirmatory assay labels compiled in benchmark data sets (computational evaluation of predictions vs experimental confirmatory assay results in multifidelity benchmarks like MF-PCBA)</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_performance</strong></td>
                            <td>Review states transfer learning with GNNs improves molecular property prediction when integrating multifidelity data but does not report numeric metrics in the review text.</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_performance</strong></td>
                            <td>Not reported in the review (benchmarks use confirmatory labels for evaluation but numeric ground-truth performance values are not provided here).</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_gap_measurement</strong></td>
                            <td>Not quantified in the review; discussion is qualitative (noisy primary screens vs. sparse confirmatory labels).</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_both_proxy_and_ground_truth</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performed</strong></td>
                            <td>computational benchmark using multifidelity datasets (primary → confirmatory assay labels)</td>
                        </tr>
                        <tr>
                            <td><strong>number_predictions_made</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_experimentally_validated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_novelty</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>extrapolation_distance</strong></td>
                            <td>Not quantified; method explicitly targets extrapolation from wide low-fidelity chemical space to sparser high-fidelity labels</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_bias_correction</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_bias_correction_method</strong></td>
                            <td>Transfer learning / multifidelity learning that leverages representations learned from low-fidelity primary HTS to improve predictions on high-fidelity confirmatory assays (benchmarked on MF-PCBA).</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Review notes primary HTS is inexpensive and confirmatory assays are higher-cost, but provides no quantitative cost/time figures.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>emerging ML methodology with dedicated multifidelity benchmarks</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_failure_modes</strong></td>
                            <td>Noisy primary screening data can produce many false positives; lack of experimental controls in primary screens can reduce translation to confirmatory assays (discussed qualitatively).</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_calibration</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>multiple_proxy_types</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cascade</strong></td>
                            <td>computational multifidelity cascade (primary HTS proxy → confirmatory assay labels); no in vitro/in vivo cascade reported in review for this work.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Review states transfer-learning approaches improve over single-fidelity models in practice but does not give quantitative baselines in the text.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_factors</strong></td>
                            <td>HTS assay noise, assay protocol heterogeneity, and chemical-space coverage differences between primary and confirmatory screens.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1878.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1878.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that use computational or proxy metrics to make predictions or discoveries, and how those predictions compare to experimental or ground-truth validation results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RWGNN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Random Walk Guided Graph Neural Network</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A GNN variant integrating random-walk-derived features with graph convolutions to predict drug–target interactions, especially for distant interactions in heterogeneous graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Predicting Distant Drug-Target Interactions via a Random Walk Guided Graph Neural Network.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Random Walk Guided Graph Neural Network (RWGNN)</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>drug–target interaction prediction (computational)</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_name</strong></td>
                            <td>Predicted drug–target interaction score evaluated by AUC on benchmark DTI datasets (focus on DTIs ≥ 3 hops)</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_type</strong></td>
                            <td>data-driven ML model (graph neural network variant)</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_description</strong></td>
                            <td>Combines random-walk profile features with graph convolution layers to produce node embeddings and predict interaction probabilities; benchmarked using area-under-ROC on curated DTI datasets, with special evaluation on distant (≥3-hop) interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_metric_name</strong></td>
                            <td>Curated DTI labels in benchmark datasets (database-derived experimental interaction annotations)</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_validation_method</strong></td>
                            <td>Evaluation against benchmark dataset labels (computational benchmark), not wet-lab validation reported in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_performance</strong></td>
                            <td>AUC = 0.957 reported in the review for predicting DTIs ≥ 3 hops away (benchmark performance).</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>explicit_gap_measurement</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_both_proxy_and_ground_truth</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performed</strong></td>
                            <td>computational benchmark evaluation only (no experimental follow-up described in review).</td>
                        </tr>
                        <tr>
                            <td><strong>number_predictions_made</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_experimentally_validated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_novelty</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>extrapolation_distance</strong></td>
                            <td>Explicitly evaluated on long-range DTIs (≥3 hops) indicating assessment of prediction beyond local neighborhoods, but no quantitative extrapolation-distance metric provided.</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_bias_correction</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>proxy_bias_correction_method</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>emerging GNN architectures for DTI tasks</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_failure_modes</strong></td>
                            <td>Review notes general dataset/benchmark limitations for graph-based DTI tasks (e.g., biases from data sparsity and graph distance) though not specific failure cases for RWGNN are quantified.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_calibration</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>multiple_proxy_types</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cascade</strong></td>
                            <td>None beyond computational benchmarking</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Reported to outperform standard GCN baselines on distant-DTI benchmark tasks (exact baseline numbers not provided in the review).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_factors</strong></td>
                            <td>Graph topology (path length), sparsity of distant DTIs, and curation biases in interaction databases.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1878.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1878.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that use computational or proxy metrics to make predictions or discoveries, and how those predictions compare to experimental or ground-truth validation results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MSGNN-DTA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MSGNN-DTA (Multi-scale topological feature fusion based on graph neural networks for drug–target binding affinity prediction)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-scale GNN that fuses atom-, motif-, and protein-level graphs to predict binding affinity; evaluated on common affinity benchmarks and used in an in-silico virtual screening case study.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Msgnn-dta: Multi-scale topological feature fusion based on graph neural networks for drug-target binding affinity prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>MSGNN-DTA multi-scale GNN</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>binding affinity prediction / virtual screening</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_name</strong></td>
                            <td>Predicted binding affinity (evaluated as RMSE on the KIBA benchmark)</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_type</strong></td>
                            <td>data-driven ML model (graph neural networks)</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_description</strong></td>
                            <td>Constructs multiple graph representations at atom, motif, and protein levels with gated skip connections to predict continuous binding-affinity labels; performance measured on standard computational benchmarks such as KIBA (RMSE).</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_metric_name</strong></td>
                            <td>Experimental binding affinity values compiled in the KIBA benchmark</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_validation_method</strong></td>
                            <td>Benchmark comparison to curated experimental affinity labels (computational evaluation); review also notes a virtual screening case study involving an FDA-approved drug but does not report wet-lab validation.</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_performance</strong></td>
                            <td>RMSE = 1.237 on the KIBA benchmark (reported in the review).</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>explicit_gap_measurement</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_both_proxy_and_ground_truth</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performed</strong></td>
                            <td>computational benchmarking and an in-silico case study (no experimental wet-lab validation reported in the review for this model).</td>
                        </tr>
                        <tr>
                            <td><strong>number_predictions_made</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_experimentally_validated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_novelty</strong></td>
                            <td>Review describes 'practical utility' in a virtual screening case study but does not classify novelty quantitatively.</td>
                        </tr>
                        <tr>
                            <td><strong>extrapolation_distance</strong></td>
                            <td>Not discussed quantitatively in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_bias_correction</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>proxy_bias_correction_method</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>emerging GNN approaches for affinity prediction</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_failure_modes</strong></td>
                            <td>Limitations include bias to known chemical space and reliance on benchmarked protein conformations; review emphasizes translation limits to in vivo settings.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_calibration</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>multiple_proxy_types</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cascade</strong></td>
                            <td>computational benchmarking → in-silico virtual screening case study (no in vitro/in vivo cascade reported in review).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Reported as robust on KIBA with the given RMSE; direct numerical comparisons to competing models are not provided in the review text.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_factors</strong></td>
                            <td>Dependence on available structural/topological protein representations and the chemical space covered by training/test benchmarks.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1878.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1878.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that use computational or proxy metrics to make predictions or discoveries, and how those predictions compare to experimental or ground-truth validation results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LEP-AD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LEP-AD: Language Embedding of Proteins and Attention to Drugs</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid framework that uses large protein language-model embeddings (ESM-2) combined with graph convolutional networks to predict binding affinity, leveraging sequence-derived embeddings as a proxy for structural information.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>LEP-AD: Language Embedding of Proteins and Attention to Drugs predicts drug target interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>LEP-AD (ESM-2 protein embeddings + GCNs)</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>binding affinity prediction / DTI</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_name</strong></td>
                            <td>Predicted binding affinity / interaction accuracy measured on benchmarks (accuracy improvement reported vs AlphaFold2-integrated models)</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_type</strong></td>
                            <td>hybrid data-driven ML (transformer protein embeddings + GCN)</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_description</strong></td>
                            <td>Uses protein sequence embeddings from large transformer protein models (ESM-2) as input features to a GCN-based predictor; the transformer embeddings act as a proxy for structural/functional protein information.</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_metric_name</strong></td>
                            <td>Benchmark binding-affinity or interaction labels derived from experimental data</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_validation_method</strong></td>
                            <td>Computational benchmark comparisons to alternative approaches (review reports a 15% accuracy improvement vs AlphaFold2-integrated models).</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_performance</strong></td>
                            <td>Reported as a 15% accuracy improvement over AlphaFold2-integrated models in binding-affinity / interaction prediction (reported in the review).</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>explicit_gap_measurement</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_both_proxy_and_ground_truth</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performed</strong></td>
                            <td>computational benchmarking against datasets with experimental labels (no prospective wet-lab validation reported in review).</td>
                        </tr>
                        <tr>
                            <td><strong>number_predictions_made</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_experimentally_validated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_novelty</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>extrapolation_distance</strong></td>
                            <td>Not described quantitatively in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_bias_correction</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>proxy_bias_correction_method</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>emerging hybrid sequence-structure ML methods</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_failure_modes</strong></td>
                            <td>Potential mismatch between sequence-derived embeddings and actual conformational dynamics; review notes general limitations in structural/topology knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_calibration</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>multiple_proxy_types</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cascade</strong></td>
                            <td>computational benchmarking only (as described in the review).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Quantified as ~15% accuracy improvement over a baseline (AlphaFold2-integrated model) per the review; further baseline metrics not provided.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_factors</strong></td>
                            <td>Quality of protein sequence embeddings and relation to true structural/functional properties; bias from pretraining data for language models.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1878.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1878.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that use computational or proxy metrics to make predictions or discoveries, and how those predictions compare to experimental or ground-truth validation results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DiffDock</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DiffDock: Diffusion steps, twists, and turns for molecular docking</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A generative diffusion-model approach to molecular docking that learns a distribution over plausible ligand poses, enabling representation of pose uncertainty and multiple binding modes and showing improved docking benchmark performance over regression/search-based methods.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Diffdock: Diffusion steps, twists, and turns for molecular docking.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>DiffDock (diffusion generative docking model)</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>structure-based drug design / molecular docking</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_name</strong></td>
                            <td>Predicted ligand binding poses and docking accuracy relative to experimentally-determined poses (benchmark docking metrics)</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_type</strong></td>
                            <td>generative ML model (diffusion-based generative approach)</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_description</strong></td>
                            <td>Recasts docking as a generative modeling task: a diffusion model is trained to sample plausible ligand poses conditioned on protein targets, thereby modeling distributions of binding modes rather than predicting a single pose via regression or search algorithms.</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_metric_name</strong></td>
                            <td>Experimentally-determined ligand binding poses (e.g., X-ray/cryo-EM crystallographic poses used in docking benchmarks)</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_validation_method</strong></td>
                            <td>Comparison of sampled poses to experimentally determined structures in docking benchmarks (computational benchmark comparisons to standard docking methods).</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_performance</strong></td>
                            <td>Review states DiffDock surpasses traditional regression-or search-based docking methods on benchmark docking metrics but does not list numeric values in the review text.</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>explicit_gap_measurement</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_both_proxy_and_ground_truth</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performed</strong></td>
                            <td>computational benchmark comparisons to experimental structures (no prospective experimental wet-lab validations reported in review).</td>
                        </tr>
                        <tr>
                            <td><strong>number_predictions_made</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_experimentally_validated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_novelty</strong></td>
                            <td>Characterized as a paradigm shift in docking (generative approach) but no quantitative novelty metric reported.</td>
                        </tr>
                        <tr>
                            <td><strong>extrapolation_distance</strong></td>
                            <td>Not detailed quantitatively; model aims to capture multiple plausible poses beyond single-pose assumptions.</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_bias_correction</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>proxy_bias_correction_method</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>emerging generative ML approaches for docking</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_failure_modes</strong></td>
                            <td>Traditional docking failure modes enumerated in review (rigid protein models, limited dynamics); DiffDock aims to mitigate single-pose limitations but review does not detail remaining failure cases.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_calibration</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>multiple_proxy_types</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cascade</strong></td>
                            <td>computational docking benchmarks (no further experimental cascade described in review).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Reported to outperform traditional docking on benchmark metrics; numerical baseline comparisons not provided in the review text.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_factors</strong></td>
                            <td>Protein conformational dynamics, multiple binding modes, and limitations of single-pose regression approaches.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1878.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1878.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that use computational or proxy metrics to make predictions or discoveries, and how those predictions compare to experimental or ground-truth validation results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChemBERTa / ProtBert</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChemBERTa and ProtBert Transformer-based molecular and protein embeddings</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Transformer-based pretrained embeddings for molecules (ChemBERTa) and proteins (ProtBert) used as features for downstream prediction tasks such as DTI and toxicity, providing transfer-learning gains over classical fingerprint features.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Transformer-based pretrained embeddings (ChemBERTa for molecules; ProtBert for proteins)</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>molecular property prediction / toxicity prediction / DTI</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_name</strong></td>
                            <td>Predicted DTI (AUC) and toxicity (ROC-AUC) on benchmark datasets</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_type</strong></td>
                            <td>data-driven ML model (transformer embeddings / transfer learning)</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_description</strong></td>
                            <td>Pretrained transformer encoders produce contextual embeddings (for SMILES/molecular tokens or protein sequences) used as input to downstream classifiers/regressors for tasks like DTI and toxicity prediction; performance measured by AUC/ROC-AUC vs fingerprint baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_metric_name</strong></td>
                            <td>Benchmark experimental labels for DTI and toxicity outcomes (assay-derived labels used as ground truth in datasets)</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_validation_method</strong></td>
                            <td>Computational benchmarking against datasets containing experimental assay labels (no additional wet-lab follow-up described in the review).</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_performance</strong></td>
                            <td>Reported in the review: AUC = 0.973 for DTI prediction (ChemBERTa/ProtBert context) and a 2–4% improvement in ROC-AUC for toxicity prediction compared to fingerprint-based methods.</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>explicit_gap_measurement</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_both_proxy_and_ground_truth</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performed</strong></td>
                            <td>computational benchmarking using labeled datasets (no prospective experimental validation reported in the review).</td>
                        </tr>
                        <tr>
                            <td><strong>number_predictions_made</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_experimentally_validated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_novelty</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>extrapolation_distance</strong></td>
                            <td>Not discussed quantitatively; review highlights language/representation bias as a limitation affecting translation.</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_bias_correction</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>proxy_bias_correction_method</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>emerging transfer-learning application in chemistry/biophysics</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_failure_modes</strong></td>
                            <td>Language- and data-source-induced biases, limited capability to capture clinical context from literature-only pretraining (discussed qualitatively).</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_calibration</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>multiple_proxy_types</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cascade</strong></td>
                            <td>computational benchmarking only</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>2–4% ROC-AUC improvement over fingerprint-based methods for toxicity; AUC=0.973 reported for DTI predictions in review context.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_factors</strong></td>
                            <td>Variability and bias in source datasets, and representational limits of sequence/SMILES encodings for complex biological phenomena.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1878.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e1878.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that use computational or proxy metrics to make predictions or discoveries, and how those predictions compare to experimental or ground-truth validation results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Aleksić ADMET study (Boehringer Ingelheim)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ADMET predictability at Boehringer Ingelheim: state-of-the-art, and do bigger datasets or algorithms make a difference?</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An industry study comparing ADMET predictability across algorithm classes and dataset scales, finding that for some ADMET endpoints simpler algorithms can match or outperform complex deep-learning approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>ADMET predictability at Boehringer Ingelheim: state-of-the-art, and do bigger datasets or algorithms make a difference?</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Various ADMET prediction models (classical ML and deep learning) evaluated on in-house experimental ADMET data</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>ADMET prediction / preclinical pharmacokinetics and toxicology</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_name</strong></td>
                            <td>Predicted ADMET endpoints (e.g., solubility, metabolic stability, toxicity proxies) evaluated by standard ML metrics against experimental ADMET labels</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_type</strong></td>
                            <td>data-driven ML models (classical ML like RF/SVM and deep learning models)</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_description</strong></td>
                            <td>Models trained on proprietary experimental ADMET measurements, evaluated on held-out experimental labels to assess predictive performance of different algorithm classes and dataset-size effects.</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_metric_name</strong></td>
                            <td>Experimental ADMET measurements generated by in-house assays (Boehringer Ingelheim laboratory data)</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_validation_method</strong></td>
                            <td>Direct comparison of model predictions to experimental ADMET values (internal benchmark/evaluation described in the referenced study and summarized in the review).</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_performance</strong></td>
                            <td>Review summarizes that complex deep-learning models do not always outperform simpler methods on certain ADMET endpoints; no numeric performance values are given in the review text.</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>explicit_gap_measurement</strong></td>
                            <td>Review notes comparative performance differences qualitatively (simpler algorithms sometimes comparable or superior), but does not quantify the proxy-to-ground-truth gap.</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_both_proxy_and_ground_truth</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_performed</strong></td>
                            <td>computational model evaluation against in-house experimental ADMET data (internal benchmarking).</td>
                        </tr>
                        <tr>
                            <td><strong>number_predictions_made</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_experimentally_validated</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_novelty</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>extrapolation_distance</strong></td>
                            <td>Not discussed in the review summary.</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_bias_correction</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>proxy_bias_correction_method</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>relatively well-established for certain ADMET endpoints, but outcome-dependent</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_failure_modes</strong></td>
                            <td>Performance depends strongly on endpoint, dataset size/quality, and assay heterogeneity; review highlights endpoint-specific challenges rather than categorical failures.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_calibration</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>multiple_proxy_types</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cascade</strong></td>
                            <td>Model predictions evaluated directly against experimental in-house ADMET measurements (computational → experimental labels used for benchmarking).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Review reports simpler baseline algorithms sometimes match or exceed deep-learning performance for some endpoints, but does not provide numerical comparisons in the text.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_factors</strong></td>
                            <td>ADMET complexity, assay variability, endpoint-specific data sparsity, and experimental measurement noise.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Transfer learning with graph neural networks for improved molecular property prediction in the multi-fidelity setting. <em>(Rating: 2)</em></li>
                <li>mf-pcba: Multifidelity high-throughput screening benchmarks for drug discovery and machine learning. <em>(Rating: 2)</em></li>
                <li>Predicting Distant Drug-Target Interactions via a Random Walk Guided Graph Neural Network. <em>(Rating: 2)</em></li>
                <li>Msgnn-dta: Multi-scale topological feature fusion based on graph neural networks for drug-target binding affinity prediction. <em>(Rating: 2)</em></li>
                <li>Diffdock: Diffusion steps, twists, and turns for molecular docking. <em>(Rating: 2)</em></li>
                <li>ADMET predictability at Boehringer Ingelheim: state-of-the-art, and do bigger datasets or algorithms make a difference? <em>(Rating: 2)</em></li>
                <li>LIT-PCBA: an unbiased data set for machine learning and virtual screening. <em>(Rating: 1)</em></li>
                <li>LEP-AD: Language Embedding of Proteins and Attention to Drugs predicts drug target interactions. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1878",
    "paper_id": "paper-279227829",
    "extraction_schema_id": "extraction-schema-36",
    "extracted_data": [
        {
            "name_short": "Multi-fidelity GNN Transfer Learning (Buterez et al.)",
            "name_full": "Transfer learning with graph neural networks for improved molecular property prediction in the multi-fidelity setting",
            "brief_description": "A GNN-based transfer-learning framework that integrates low-fidelity primary HTS (proxy) data with sparse high-fidelity confirmatory assay data to improve molecular property prediction and virtual screening performance.",
            "citation_title": "Transfer learning with graph neural networks for improved molecular property prediction in the multi-fidelity setting.",
            "mention_or_use": "mention",
            "system_name": "GNN transfer-learning multi-fidelity framework",
            "domain": "drug discovery / high-throughput screening",
            "proxy_metric_name": "Primary HTS activity readouts (low-fidelity assay measurements used as a proxy for confirmatory potency/activity)",
            "proxy_metric_type": "multifidelity data-driven ML model (transfer learning across fidelity levels)",
            "proxy_metric_description": "Primary high-throughput screening (HTS) measurements (large-scale, noisy single-concentration or surrogate readouts) are used as low-fidelity training data; a Graph Neural Network is pretrained or transfer-fine-tuned on these data then adapted to predict high-fidelity confirmatory assay endpoints (dose–response, IC50/Ki) from sparse labels.",
            "ground_truth_metric_name": "High-fidelity confirmatory HTS assay results (dose–response potency measurements, e.g., IC50/Ki)",
            "ground_truth_validation_method": "Comparison to confirmatory assay labels compiled in benchmark data sets (computational evaluation of predictions vs experimental confirmatory assay results in multifidelity benchmarks like MF-PCBA)",
            "proxy_performance": "Review states transfer learning with GNNs improves molecular property prediction when integrating multifidelity data but does not report numeric metrics in the review text.",
            "ground_truth_performance": "Not reported in the review (benchmarks use confirmatory labels for evaluation but numeric ground-truth performance values are not provided here).",
            "explicit_gap_measurement": "Not quantified in the review; discussion is qualitative (noisy primary screens vs. sparse confirmatory labels).",
            "false_positive_rate": null,
            "false_negative_rate": null,
            "has_both_proxy_and_ground_truth": true,
            "validation_performed": "computational benchmark using multifidelity datasets (primary → confirmatory assay labels)",
            "number_predictions_made": null,
            "number_experimentally_validated": null,
            "discovery_novelty": null,
            "extrapolation_distance": "Not quantified; method explicitly targets extrapolation from wide low-fidelity chemical space to sparser high-fidelity labels",
            "proxy_bias_correction": true,
            "proxy_bias_correction_method": "Transfer learning / multifidelity learning that leverages representations learned from low-fidelity primary HTS to improve predictions on high-fidelity confirmatory assays (benchmarked on MF-PCBA).",
            "validation_cost_time": "Review notes primary HTS is inexpensive and confirmatory assays are higher-cost, but provides no quantitative cost/time figures.",
            "domain_maturity": "emerging ML methodology with dedicated multifidelity benchmarks",
            "proxy_failure_modes": "Noisy primary screening data can produce many false positives; lack of experimental controls in primary screens can reduce translation to confirmatory assays (discussed qualitatively).",
            "uncertainty_quantification": null,
            "uncertainty_calibration": null,
            "multiple_proxy_types": true,
            "validation_cascade": "computational multifidelity cascade (primary HTS proxy → confirmatory assay labels); no in vitro/in vivo cascade reported in review for this work.",
            "comparison_to_baseline": "Review states transfer-learning approaches improve over single-fidelity models in practice but does not give quantitative baselines in the text.",
            "domain_specific_factors": "HTS assay noise, assay protocol heterogeneity, and chemical-space coverage differences between primary and confirmatory screens.",
            "uuid": "e1878.0"
        },
        {
            "name_short": "RWGNN",
            "name_full": "Random Walk Guided Graph Neural Network",
            "brief_description": "A GNN variant integrating random-walk-derived features with graph convolutions to predict drug–target interactions, especially for distant interactions in heterogeneous graphs.",
            "citation_title": "Predicting Distant Drug-Target Interactions via a Random Walk Guided Graph Neural Network.",
            "mention_or_use": "mention",
            "system_name": "Random Walk Guided Graph Neural Network (RWGNN)",
            "domain": "drug–target interaction prediction (computational)",
            "proxy_metric_name": "Predicted drug–target interaction score evaluated by AUC on benchmark DTI datasets (focus on DTIs ≥ 3 hops)",
            "proxy_metric_type": "data-driven ML model (graph neural network variant)",
            "proxy_metric_description": "Combines random-walk profile features with graph convolution layers to produce node embeddings and predict interaction probabilities; benchmarked using area-under-ROC on curated DTI datasets, with special evaluation on distant (≥3-hop) interactions.",
            "ground_truth_metric_name": "Curated DTI labels in benchmark datasets (database-derived experimental interaction annotations)",
            "ground_truth_validation_method": "Evaluation against benchmark dataset labels (computational benchmark), not wet-lab validation reported in the review.",
            "proxy_performance": "AUC = 0.957 reported in the review for predicting DTIs ≥ 3 hops away (benchmark performance).",
            "ground_truth_performance": null,
            "explicit_gap_measurement": null,
            "false_positive_rate": null,
            "false_negative_rate": null,
            "has_both_proxy_and_ground_truth": false,
            "validation_performed": "computational benchmark evaluation only (no experimental follow-up described in review).",
            "number_predictions_made": null,
            "number_experimentally_validated": null,
            "discovery_novelty": null,
            "extrapolation_distance": "Explicitly evaluated on long-range DTIs (≥3 hops) indicating assessment of prediction beyond local neighborhoods, but no quantitative extrapolation-distance metric provided.",
            "proxy_bias_correction": null,
            "proxy_bias_correction_method": "",
            "validation_cost_time": null,
            "domain_maturity": "emerging GNN architectures for DTI tasks",
            "proxy_failure_modes": "Review notes general dataset/benchmark limitations for graph-based DTI tasks (e.g., biases from data sparsity and graph distance) though not specific failure cases for RWGNN are quantified.",
            "uncertainty_quantification": null,
            "uncertainty_calibration": null,
            "multiple_proxy_types": false,
            "validation_cascade": "None beyond computational benchmarking",
            "comparison_to_baseline": "Reported to outperform standard GCN baselines on distant-DTI benchmark tasks (exact baseline numbers not provided in the review).",
            "domain_specific_factors": "Graph topology (path length), sparsity of distant DTIs, and curation biases in interaction databases.",
            "uuid": "e1878.1"
        },
        {
            "name_short": "MSGNN-DTA",
            "name_full": "MSGNN-DTA (Multi-scale topological feature fusion based on graph neural networks for drug–target binding affinity prediction)",
            "brief_description": "A multi-scale GNN that fuses atom-, motif-, and protein-level graphs to predict binding affinity; evaluated on common affinity benchmarks and used in an in-silico virtual screening case study.",
            "citation_title": "Msgnn-dta: Multi-scale topological feature fusion based on graph neural networks for drug-target binding affinity prediction.",
            "mention_or_use": "mention",
            "system_name": "MSGNN-DTA multi-scale GNN",
            "domain": "binding affinity prediction / virtual screening",
            "proxy_metric_name": "Predicted binding affinity (evaluated as RMSE on the KIBA benchmark)",
            "proxy_metric_type": "data-driven ML model (graph neural networks)",
            "proxy_metric_description": "Constructs multiple graph representations at atom, motif, and protein levels with gated skip connections to predict continuous binding-affinity labels; performance measured on standard computational benchmarks such as KIBA (RMSE).",
            "ground_truth_metric_name": "Experimental binding affinity values compiled in the KIBA benchmark",
            "ground_truth_validation_method": "Benchmark comparison to curated experimental affinity labels (computational evaluation); review also notes a virtual screening case study involving an FDA-approved drug but does not report wet-lab validation.",
            "proxy_performance": "RMSE = 1.237 on the KIBA benchmark (reported in the review).",
            "ground_truth_performance": null,
            "explicit_gap_measurement": null,
            "false_positive_rate": null,
            "false_negative_rate": null,
            "has_both_proxy_and_ground_truth": false,
            "validation_performed": "computational benchmarking and an in-silico case study (no experimental wet-lab validation reported in the review for this model).",
            "number_predictions_made": null,
            "number_experimentally_validated": null,
            "discovery_novelty": "Review describes 'practical utility' in a virtual screening case study but does not classify novelty quantitatively.",
            "extrapolation_distance": "Not discussed quantitatively in the review.",
            "proxy_bias_correction": null,
            "proxy_bias_correction_method": "",
            "validation_cost_time": null,
            "domain_maturity": "emerging GNN approaches for affinity prediction",
            "proxy_failure_modes": "Limitations include bias to known chemical space and reliance on benchmarked protein conformations; review emphasizes translation limits to in vivo settings.",
            "uncertainty_quantification": null,
            "uncertainty_calibration": null,
            "multiple_proxy_types": false,
            "validation_cascade": "computational benchmarking → in-silico virtual screening case study (no in vitro/in vivo cascade reported in review).",
            "comparison_to_baseline": "Reported as robust on KIBA with the given RMSE; direct numerical comparisons to competing models are not provided in the review text.",
            "domain_specific_factors": "Dependence on available structural/topological protein representations and the chemical space covered by training/test benchmarks.",
            "uuid": "e1878.2"
        },
        {
            "name_short": "LEP-AD",
            "name_full": "LEP-AD: Language Embedding of Proteins and Attention to Drugs",
            "brief_description": "A hybrid framework that uses large protein language-model embeddings (ESM-2) combined with graph convolutional networks to predict binding affinity, leveraging sequence-derived embeddings as a proxy for structural information.",
            "citation_title": "LEP-AD: Language Embedding of Proteins and Attention to Drugs predicts drug target interactions.",
            "mention_or_use": "mention",
            "system_name": "LEP-AD (ESM-2 protein embeddings + GCNs)",
            "domain": "binding affinity prediction / DTI",
            "proxy_metric_name": "Predicted binding affinity / interaction accuracy measured on benchmarks (accuracy improvement reported vs AlphaFold2-integrated models)",
            "proxy_metric_type": "hybrid data-driven ML (transformer protein embeddings + GCN)",
            "proxy_metric_description": "Uses protein sequence embeddings from large transformer protein models (ESM-2) as input features to a GCN-based predictor; the transformer embeddings act as a proxy for structural/functional protein information.",
            "ground_truth_metric_name": "Benchmark binding-affinity or interaction labels derived from experimental data",
            "ground_truth_validation_method": "Computational benchmark comparisons to alternative approaches (review reports a 15% accuracy improvement vs AlphaFold2-integrated models).",
            "proxy_performance": "Reported as a 15% accuracy improvement over AlphaFold2-integrated models in binding-affinity / interaction prediction (reported in the review).",
            "ground_truth_performance": null,
            "explicit_gap_measurement": null,
            "false_positive_rate": null,
            "false_negative_rate": null,
            "has_both_proxy_and_ground_truth": false,
            "validation_performed": "computational benchmarking against datasets with experimental labels (no prospective wet-lab validation reported in review).",
            "number_predictions_made": null,
            "number_experimentally_validated": null,
            "discovery_novelty": null,
            "extrapolation_distance": "Not described quantitatively in the review.",
            "proxy_bias_correction": null,
            "proxy_bias_correction_method": "",
            "validation_cost_time": null,
            "domain_maturity": "emerging hybrid sequence-structure ML methods",
            "proxy_failure_modes": "Potential mismatch between sequence-derived embeddings and actual conformational dynamics; review notes general limitations in structural/topology knowledge.",
            "uncertainty_quantification": null,
            "uncertainty_calibration": null,
            "multiple_proxy_types": false,
            "validation_cascade": "computational benchmarking only (as described in the review).",
            "comparison_to_baseline": "Quantified as ~15% accuracy improvement over a baseline (AlphaFold2-integrated model) per the review; further baseline metrics not provided.",
            "domain_specific_factors": "Quality of protein sequence embeddings and relation to true structural/functional properties; bias from pretraining data for language models.",
            "uuid": "e1878.3"
        },
        {
            "name_short": "DiffDock",
            "name_full": "DiffDock: Diffusion steps, twists, and turns for molecular docking",
            "brief_description": "A generative diffusion-model approach to molecular docking that learns a distribution over plausible ligand poses, enabling representation of pose uncertainty and multiple binding modes and showing improved docking benchmark performance over regression/search-based methods.",
            "citation_title": "Diffdock: Diffusion steps, twists, and turns for molecular docking.",
            "mention_or_use": "mention",
            "system_name": "DiffDock (diffusion generative docking model)",
            "domain": "structure-based drug design / molecular docking",
            "proxy_metric_name": "Predicted ligand binding poses and docking accuracy relative to experimentally-determined poses (benchmark docking metrics)",
            "proxy_metric_type": "generative ML model (diffusion-based generative approach)",
            "proxy_metric_description": "Recasts docking as a generative modeling task: a diffusion model is trained to sample plausible ligand poses conditioned on protein targets, thereby modeling distributions of binding modes rather than predicting a single pose via regression or search algorithms.",
            "ground_truth_metric_name": "Experimentally-determined ligand binding poses (e.g., X-ray/cryo-EM crystallographic poses used in docking benchmarks)",
            "ground_truth_validation_method": "Comparison of sampled poses to experimentally determined structures in docking benchmarks (computational benchmark comparisons to standard docking methods).",
            "proxy_performance": "Review states DiffDock surpasses traditional regression-or search-based docking methods on benchmark docking metrics but does not list numeric values in the review text.",
            "ground_truth_performance": null,
            "explicit_gap_measurement": null,
            "false_positive_rate": null,
            "false_negative_rate": null,
            "has_both_proxy_and_ground_truth": false,
            "validation_performed": "computational benchmark comparisons to experimental structures (no prospective experimental wet-lab validations reported in review).",
            "number_predictions_made": null,
            "number_experimentally_validated": null,
            "discovery_novelty": "Characterized as a paradigm shift in docking (generative approach) but no quantitative novelty metric reported.",
            "extrapolation_distance": "Not detailed quantitatively; model aims to capture multiple plausible poses beyond single-pose assumptions.",
            "proxy_bias_correction": null,
            "proxy_bias_correction_method": "",
            "validation_cost_time": null,
            "domain_maturity": "emerging generative ML approaches for docking",
            "proxy_failure_modes": "Traditional docking failure modes enumerated in review (rigid protein models, limited dynamics); DiffDock aims to mitigate single-pose limitations but review does not detail remaining failure cases.",
            "uncertainty_quantification": null,
            "uncertainty_calibration": null,
            "multiple_proxy_types": false,
            "validation_cascade": "computational docking benchmarks (no further experimental cascade described in review).",
            "comparison_to_baseline": "Reported to outperform traditional docking on benchmark metrics; numerical baseline comparisons not provided in the review text.",
            "domain_specific_factors": "Protein conformational dynamics, multiple binding modes, and limitations of single-pose regression approaches.",
            "uuid": "e1878.4"
        },
        {
            "name_short": "ChemBERTa / ProtBert",
            "name_full": "ChemBERTa and ProtBert Transformer-based molecular and protein embeddings",
            "brief_description": "Transformer-based pretrained embeddings for molecules (ChemBERTa) and proteins (ProtBert) used as features for downstream prediction tasks such as DTI and toxicity, providing transfer-learning gains over classical fingerprint features.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Transformer-based pretrained embeddings (ChemBERTa for molecules; ProtBert for proteins)",
            "domain": "molecular property prediction / toxicity prediction / DTI",
            "proxy_metric_name": "Predicted DTI (AUC) and toxicity (ROC-AUC) on benchmark datasets",
            "proxy_metric_type": "data-driven ML model (transformer embeddings / transfer learning)",
            "proxy_metric_description": "Pretrained transformer encoders produce contextual embeddings (for SMILES/molecular tokens or protein sequences) used as input to downstream classifiers/regressors for tasks like DTI and toxicity prediction; performance measured by AUC/ROC-AUC vs fingerprint baselines.",
            "ground_truth_metric_name": "Benchmark experimental labels for DTI and toxicity outcomes (assay-derived labels used as ground truth in datasets)",
            "ground_truth_validation_method": "Computational benchmarking against datasets containing experimental assay labels (no additional wet-lab follow-up described in the review).",
            "proxy_performance": "Reported in the review: AUC = 0.973 for DTI prediction (ChemBERTa/ProtBert context) and a 2–4% improvement in ROC-AUC for toxicity prediction compared to fingerprint-based methods.",
            "ground_truth_performance": null,
            "explicit_gap_measurement": null,
            "false_positive_rate": null,
            "false_negative_rate": null,
            "has_both_proxy_and_ground_truth": false,
            "validation_performed": "computational benchmarking using labeled datasets (no prospective experimental validation reported in the review).",
            "number_predictions_made": null,
            "number_experimentally_validated": null,
            "discovery_novelty": null,
            "extrapolation_distance": "Not discussed quantitatively; review highlights language/representation bias as a limitation affecting translation.",
            "proxy_bias_correction": null,
            "proxy_bias_correction_method": "",
            "validation_cost_time": null,
            "domain_maturity": "emerging transfer-learning application in chemistry/biophysics",
            "proxy_failure_modes": "Language- and data-source-induced biases, limited capability to capture clinical context from literature-only pretraining (discussed qualitatively).",
            "uncertainty_quantification": null,
            "uncertainty_calibration": null,
            "multiple_proxy_types": false,
            "validation_cascade": "computational benchmarking only",
            "comparison_to_baseline": "2–4% ROC-AUC improvement over fingerprint-based methods for toxicity; AUC=0.973 reported for DTI predictions in review context.",
            "domain_specific_factors": "Variability and bias in source datasets, and representational limits of sequence/SMILES encodings for complex biological phenomena.",
            "uuid": "e1878.5"
        },
        {
            "name_short": "Aleksić ADMET study (Boehringer Ingelheim)",
            "name_full": "ADMET predictability at Boehringer Ingelheim: state-of-the-art, and do bigger datasets or algorithms make a difference?",
            "brief_description": "An industry study comparing ADMET predictability across algorithm classes and dataset scales, finding that for some ADMET endpoints simpler algorithms can match or outperform complex deep-learning approaches.",
            "citation_title": "ADMET predictability at Boehringer Ingelheim: state-of-the-art, and do bigger datasets or algorithms make a difference?",
            "mention_or_use": "mention",
            "system_name": "Various ADMET prediction models (classical ML and deep learning) evaluated on in-house experimental ADMET data",
            "domain": "ADMET prediction / preclinical pharmacokinetics and toxicology",
            "proxy_metric_name": "Predicted ADMET endpoints (e.g., solubility, metabolic stability, toxicity proxies) evaluated by standard ML metrics against experimental ADMET labels",
            "proxy_metric_type": "data-driven ML models (classical ML like RF/SVM and deep learning models)",
            "proxy_metric_description": "Models trained on proprietary experimental ADMET measurements, evaluated on held-out experimental labels to assess predictive performance of different algorithm classes and dataset-size effects.",
            "ground_truth_metric_name": "Experimental ADMET measurements generated by in-house assays (Boehringer Ingelheim laboratory data)",
            "ground_truth_validation_method": "Direct comparison of model predictions to experimental ADMET values (internal benchmark/evaluation described in the referenced study and summarized in the review).",
            "proxy_performance": "Review summarizes that complex deep-learning models do not always outperform simpler methods on certain ADMET endpoints; no numeric performance values are given in the review text.",
            "ground_truth_performance": null,
            "explicit_gap_measurement": "Review notes comparative performance differences qualitatively (simpler algorithms sometimes comparable or superior), but does not quantify the proxy-to-ground-truth gap.",
            "false_positive_rate": null,
            "false_negative_rate": null,
            "has_both_proxy_and_ground_truth": true,
            "validation_performed": "computational model evaluation against in-house experimental ADMET data (internal benchmarking).",
            "number_predictions_made": null,
            "number_experimentally_validated": null,
            "discovery_novelty": null,
            "extrapolation_distance": "Not discussed in the review summary.",
            "proxy_bias_correction": null,
            "proxy_bias_correction_method": "",
            "validation_cost_time": null,
            "domain_maturity": "relatively well-established for certain ADMET endpoints, but outcome-dependent",
            "proxy_failure_modes": "Performance depends strongly on endpoint, dataset size/quality, and assay heterogeneity; review highlights endpoint-specific challenges rather than categorical failures.",
            "uncertainty_quantification": null,
            "uncertainty_calibration": null,
            "multiple_proxy_types": false,
            "validation_cascade": "Model predictions evaluated directly against experimental in-house ADMET measurements (computational → experimental labels used for benchmarking).",
            "comparison_to_baseline": "Review reports simpler baseline algorithms sometimes match or exceed deep-learning performance for some endpoints, but does not provide numerical comparisons in the text.",
            "domain_specific_factors": "ADMET complexity, assay variability, endpoint-specific data sparsity, and experimental measurement noise.",
            "uuid": "e1878.6"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Transfer learning with graph neural networks for improved molecular property prediction in the multi-fidelity setting.",
            "rating": 2
        },
        {
            "paper_title": "mf-pcba: Multifidelity high-throughput screening benchmarks for drug discovery and machine learning.",
            "rating": 2
        },
        {
            "paper_title": "Predicting Distant Drug-Target Interactions via a Random Walk Guided Graph Neural Network.",
            "rating": 2
        },
        {
            "paper_title": "Msgnn-dta: Multi-scale topological feature fusion based on graph neural networks for drug-target binding affinity prediction.",
            "rating": 2
        },
        {
            "paper_title": "Diffdock: Diffusion steps, twists, and turns for molecular docking.",
            "rating": 2
        },
        {
            "paper_title": "ADMET predictability at Boehringer Ingelheim: state-of-the-art, and do bigger datasets or algorithms make a difference?",
            "rating": 2
        },
        {
            "paper_title": "LIT-PCBA: an unbiased data set for machine learning and virtual screening.",
            "rating": 1
        },
        {
            "paper_title": "LEP-AD: Language Embedding of Proteins and Attention to Drugs predicts drug target interactions.",
            "rating": 1
        }
    ],
    "cost": 0.02593675,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>AI-Driven Drug Discovery: A Comprehensive Review
June 6, 2025</p>
<p>Fábio J N Ferreira 
Agnaldo S Carneiro 
Omega Acs 
AI-Driven Drug Discovery: A Comprehensive Review
June 6, 20252980E9AA2257551FCD62CEE7E87CC10D10.1021/acsomega.5c00549Received: January 21, 2025 Revised: April 28, 2025 Accepted: May 9, 2025artificial intelligence""machine learning""deep learning""neural networks""AI algorithms""AI""ML""DL" Drug Discovery "drug discovery""drug development""pharmaceutical research""target identification""hit identification""lead optimization""virtual screening""drug repurposing""cheminformatics""ADME""toxicology prediction""clinical trials design""de novo drug design""high-throughput screening" Drug Discovery (General) "pharmaceutical sciences""medicinal chemistry""in silico drug design""in silico" Target and Data Set Terms "transcriptomics""genomics""proteomics""biological networks""disease targets""biomarkers""target validation""bioactivity""ligand binding" Relevant Methodologies "convolutional neural networks""graph neural networks""transformer neural networks""generative AI" Relevant Concepts "model evaluation""bias assessment""explainable AI""data accessibility""ethics"
Artificial intelligence (AI) and machine learning (ML) offer transformative potential to address the persistent challenges of traditional drug discovery, characterized by high costs, lengthy timelines, and low success rates.This comprehensive review critically analyzes recent advancements (2019−2024) in AI/ML methodologies across the entire drug discovery pipeline, from target identification to clinical development.We examine diverse AI techniques, including deep learning, graph neural networks, and transformers, focusing on their application in key areas such as target identification, lead discovery, hit optimization, and preclinical safety assessment.Our in-depth comparative analysis highlights the advantages, limitations, and practical challenges associated with different AI approaches, emphasizing critical factors for successful implementation such as data quality, model validation, and ethical considerations.The review synthesizes current applications, identifies persistent gaps�particularly in data accessibility, interpretability, and clinical translation�and proposes future directions to unlock the full potential of AI in creating safer, more effective, and accessible medicines.By emphasizing transparent methodologies, robust validation, and ethical frameworks, this review aims to guide the responsible and impactful integration of AI into pharmaceutical research and development.</p>
<p>INTRODUCTION</p>
<p>−3 This is mainly due to the sequential nature of its stages, involving target identification, hit discovery, lead optimization, preclinical testing, and lengthy clinical trials that all require vast resources and validation.Critically, the process suffers from a low success rate, as only approximately 10% of drugs that enter clinical trials ultimately achieve regulatory approval, often exacerbated by high attrition rates 2,4 from safety concerns and a lack of efficacy.Further, high-throughput screening (HTS), a common method, yields only a 2.5% hit rate, which further lengthens timelines, increases cost, and wastes resources. 5hese challenges demand more efficient methods, where artificial intelligence (AI) and machine learning (ML) offer a promising path toward increased efficiency and success rates in drug development, providing the pharmaceutical industry with a solution with AI/ML implementation to correct limitations while also opening up novel opportunities using new model implementations based on AI parameters. 61.Objectives of the Review.This literature review critically analyzes AI/ML applications in drug discovery by (1)  summarizing current AI/ML utilization and highlighting methodologies that impact current paradigms; (2) identifying key AI/ML techniques and their implementation parameters across different drug development steps; (3) assessing the impact of those methods, addressing their limitations/ challenges, and showing new paths for optimizations; and (4) evaluating new trends as large language model implementations in the context of ethics, bias, data access, and regulatory parameters.While numerous reviews have explored AI applications in drug discovery, this comprehensive review distinguishes itself by its in-depth comparative analysis of AI The database search was performed until December 24, 2024, encompassing studies from January 1, 2019, to capture more recent advances in the field.</p>
<p>Inclusion and Exclusion</p>
<p>Criteria.This review encompassed peer-reviewed full research articles focused on AI/ML methodologies in small molecule drug discovery as the primary focus, supplemented by select high-impact metaanalyses, reviews, and key data sets.Included studies presented AI-driven methodologies in areas such as target identification, lead optimization, ADMET/toxicity prediction, clinical studies, and drug repurposing, emphasizing implementation models with parameters validating scientific and biological relevance.Articles utilizing in silico or hybrid theoretical/computational methods and models, particularly those centered on data and model analyses with AI, were prioritized, while excluding studies primarily focused on robotic automation or screening lacking clear AI model descriptions or end point translation.</p>
<p>Conversely, opinion pieces, editorials, letters without empirical data, and abstract-only publications (without accompanying full-text publications) were generally excluded (with few limited exceptions when data was highly relevant and needed for critical discussion).However, in recognition of the rapid pace of advancements in AI/ML and the potential for timely dissemination of important findings via preprint servers, highly relevant preprint articles, particularly those from reputable sources such as arXiv, and directly pertinent to the review's scope, were considered for inclusion on a case-by-case basis, if they offered significant and validated insights not yet available in peer-reviewed literature.This exception aimed to ensure the review captured the most cutting-edge developments in this dynamic field, without compromising overall rigor and focus on robust scientific findings.Also excluded were reports discussing general AI without focused ML implementation parameters in pharmaceuticals, and studies with limited data sets derived from case studies or small patient groups.Non-English language publications and studies focused solely on automation without direct AI integration were also omitted from this review.Duplicates were resolved using EndNote and manual review, prioritizing higher-impact publications with clearer data and methods to represent each unique model and to ensure comprehensive data synthesis.</p>
<p>Study Selection Process. 2.3.1. Citation Management.</p>
<p>Citations from database search results were cataloged with EndNote (version X20).Duplicates were removed first via software and also by manually reviewing each selected article.Relevant articles were tracked during selection.New reports found outside the core search were tracked by being manually introduced to the data set to avoid overlooking or not finding any important contributions that were discovered while building up the search database for evaluation purposes.</p>
<p>Article Identification and PRISMA Flow Diagram.</p>
<p>A PRISMA 2020 diagram (see Figure 1) was generated based on the inclusion-exclusion protocol.The steps involved were: identification of all articles from previously selected database; screening, where data was assessed using titles/abstract and inclusion/exclusion criteria (as described in Sections 2.2 and 2.3) based on PICO framework; eligibility analysis to access to methodology and main results by reading the full document text; publications included for synthesis for results assessment and final analyses.</p>
<p>Screening Process.</p>
<p>A lead author performed initial screening (title, abstract).All studies that passed screening were also assessed in full for inclusion by the same researcher and verified with a coauthor, including methodology assessments to avoid overlooking or data implementation errors.All reasons and limitations were clearly noted and saved for full transparency (as stated during data access).</p>
<p>THEORETICAL FRAMEWORK</p>
<p>This section establishes the theoretical foundation and historical background for AI in drug discovery, emphasizing the evolution of modern algorithms and models, their applicability, key researchers/institutions influencing the field, and related ethical/regulatory implications, setting the stage for a detailed data synthesis that follows in subsequent sections.</p>
<p>3.1.Historical Evolution of AI in Drug Discovery.The history of Artificial Intelligence (AI) in drug discovery begins with early computational methods in the 1960s and 1970s where computer-aided drug design (CADD) emerged to improve efficiency.Initial approaches involved quantitative structure− activity relationship (QSAR) models, using statistics to correlate chemical structure and biological activity, laying the foundation for more advanced techniques and showing that algorithms could be a tool for drug development and design. 7n the 1980s and 1990s, alongside increasing computational power enabling molecular docking and virtual screening, ML Figure 1.Stages followed for this literature review included an initial search data collection and duplicate removal step using specific databases, followed by a title and abstract review that was performed using predefined inclusion and exclusion parameters, as well as all methodology for full article assessment/classification for data synthesis from published reports (utilizing a PICO framework based data implementation strategy for robust data validation).methods began to emerge as valuable tools in drug discovery, particularly in the realm of QSARs.Early QSAR approaches, evolving from methods like Hansch analysis 8 that used statistical linear models, started to incorporate machine learning algorithms such as Random Forests 9 and Support Vector Machines (SVMs) 10 to model complex relationships between molecular structure and biological activity using industrial data sets.These methods marked a shift from purely statistical correlations toward more sophisticated, data-driven approaches for drug design and prediction. 11ith ML, algorithms were implemented to process larger data sets, further improving AI analysis power to select potential candidates for drug testing.Finally in the early 2000s, deep learning (DL) algorithms enabled more complex data models (with complex data structures), which led to an enhanced ability to analyze complex relationships between chemical/biological information in a data-driven approach based on high throughput/multi parameter analyses while modeling and assessing drug−target interactions and improving screening methods based on AI parameters. 12These new AI-based parameters allow more detailed analysis of data for complex pharmaceutical questions in preclinical/clinical phases.Current AI approaches highlight the use of pattern analysis over vast amounts of diverse data set information and are applicable through all steps of the drug discovery pipeline.AI is also considered a powerful instrument to reduce bottlenecks in preclinical and clinical phases. 13The recent advances in artificial intelligence are catalyzing a paradigm shift in the pharmaceutical industry.AI-based methods are now routinely deployed in laboratories worldwide to automate and optimize experimental workflows, driving a scientific revolution in drug discovery.By integrating large, multidisciplinary data sets�including molecular structures, disease-progression metrics, treatment modalities, and patient-outcome records�these approaches enable the development of novel therapeutics beyond traditional compound-centric design strategies.</p>
<p>3.2.Core AI/ML Paradigms and Their Applicability.The range of AI/ML tools utilized in drug discovery encompasses a spectrum of methodologies, from classic to cutting-edge, each with distinct advantages, limitations, and varying use in distinct drug development stages.The landscape of AI/ML tools for drug discovery is increasingly dominated by Graph Neural Networks (GNNs) and Transformer architectures.These modern methodologies have demonstrated remarkable success in learning complex molecular representations and achieving state-of-the-art performance on a variety of crucial drug discovery tasks.While classical ML methods retain value for certain applications, GNNs and Transformers represent the cutting edge in capturing intricate structural and relational information essential for advanced drug design and prediction.While initial graph transformers relied heavily on specialized encodings, newer approaches are exploring alternative paradigms.For instance, Edge-Set Attention (ESA) treats graphs purely as sets of edges and leverages interleaved masked and standard attention mechanisms, demonstrating strong performance without complex positional or structural encodings. 14.2.1.Graph Neural Networks (GNNs) in Molecular Modeling.GNNs have emerged as particularly powerful tools in molecular modeling due to their ability to directly learn from the graph-based structure of molecules, capturing complex relationships between atoms and bonds.To illustrate the architecture of a GravNet 15 block within a GNN, see Figure 2.</p>
<p>Architectures like Graph Convolutional Networks (GCNs) 16 and Graph Attention Networks (GATs) 17 and newer variants like Principal Neighborhood Aggregation (PNA) 18 have shown exceptional performance on key molecular data sets.For instance, state-of-the-art GNN models have achieved impressive results on benchmarks like MoleculeNet, 19 demonstrating strong performance on data sets like ESOL 20,21 (solubility prediction) and FreeSolv 22 (hydration free energy prediction).Furthermore, models benchmarked on data sets like DOCK-STRING targets 23 (e.g., PGR, F2, KIT targets) highlight the capacity of GNNs to capture complex protein−ligand interactions relevant to drug discovery.</p>
<p>Recent benchmarking studies further emphasize the crucial role of architectural choices in GNN performance.For example, Groẗschla et al. 24 conducted a comprehensive analysis of positional encodings across diverse GNN architectures, including Graph Transformers, revealing valuable insights into the impact of positional encodings on model performance.Their findings, derived from extensive benchmarking across data sets like GNN BENCHMARKING 25 and LRGB, 26 highlight the importance of carefully selecting positional encodings to optimize GNN performance and demonstrate that different positional encodings can lead to significant variations in results depending on the data set and task.Such studies underscore the ongoing efforts to optimize GNN architectures and guide practical model selection in drug discovery and beyond.(ii) the key capabilities of GNNs, namely, direct learning from the graph structure and capturing complex relationships; (iii) the representation of molecular structure as a graph comprising atoms and bonds; and (iv) the integration of specific architectural blocks, such as GravNet, within the GNN framework.and adaptations of Transformers specifically tailored for graph data, such as Graph Transformers, 28 have shown promise on tasks like PCQM4Mv2 (quantum chemistry property prediction) and in predicting peptide properties on the LRGB-Peptides data set. 26Ongoing research explores the optimal integration of Transformers with graph-based methods to leverage the strengths of both architectures for molecular representation learning.</p>
<p>Classical ML techniques, like Decision Trees 29 and the more robust Random Forest, 30 offer accessible data visualization.Support Vector Machines (SVMs) excel at strong data classifications, while K-Nearest Neighbors (KNN) provides a simpler starting point for basic classification problems. 31,32Deep learning (DL), representing models beyond GNNs and Transformers and utilizing complex artificial neural networks, enables advanced data analysis for feature identification, structural and molecular property prediction, and parameter optimization, particularly with large data sets, facilitating the creation of potent drug−target models. 33Reinforcement learning (RL) is employed in systems requiring sequential data evaluation and feedback-driven outcome optimization. 34ll methods present specific capabilities in data implementation depending on the design goal or data evaluation criteria/types used by each different parameter selection during study implementation.</p>
<p>The choice of AI/ML method is intrinsically linked to the design goal, data characteristics, and evaluation criteria defined by parameter selection in each study.Model validation is crucial for study validity, as data quality directly impacts bias, and a limited understanding of DL may result in interpretability issues that need robust methodology to make real data validations during complex analyses. 35,36The architecture of ML models, encompassing the methods discussed above (GNNs, CNNs, Transformers, etc.) is paramount for effective model evaluation.Methodological choices, therefore, strongly depend on data set structure, parameters, study design, available computational resources, and institutional expertise.</p>
<p>Selecting appropriate AI methods in drug discovery hinges on aligning the chosen approach with the specific evaluation stage and ensuring clinically relevant and interpretable results. 13,37lassical ML remains effective in early stage target selection.Deep learning, including GNNs and Transformers, facilitates complex modeling and target/drug prioritization.Network implementations are valuable for analyzing drug interaction data and analyses, particularly from complex, highly interconnected data sets mirroring biological systems.Method selection is further influenced by the availability of resources, training in AI programming and mathematics, and the specific demands of experimental approaches.</p>
<p>Ethical and Regulatory</p>
<p>Considerations.The growing integration of AI and ML in drug development necessitates proactive management of ethical and regulatory challenges to ensure safe applications.Data bias represents a primary concern, potentially skewing model predictions, exacerbating demographic inequities, and demanding enhanced data parameters and rigorous testing protocols.Robust model validation is also critical for predictability and real-world applicability, requiring well-established models and effective bias control.Transparency in data sets and implementation parameters is equally essential to overcome "black box" limitations, foster trust in AI-derived results, and guarantee patient benefit.In response, regulatory bodies like the FDA and EMA are actively developing AI safety parameters and promoting diverse population validation, informed by detailed regulatory guidelines for robust, ethical AI technologies.−40</p>
<p>REVIEW OF FINDINGS AND DISCUSSIONS</p>
<p>This section synthesizes the review's findings based on different AI-based methodology applications within core steps of pharmaceutical research.In all subsections, model limitations, biases, and validation parameters will also be evaluated for their impact in all phases.We will discuss each specific type of AI implementation based on information extracted from previous reports, while evaluating the opportunities and future perspectives that emerge from those analyses, such as an integrated and core evaluation for model effectiveness.• NLP: Using vast textual data sets from published scientific and pharmaceutical documentation is key to implementing powerful AI-driven methodology and frameworks using Named Entity Recognition, Relationship Extraction, and model based statistical evaluation.The process starts by a careful extraction of raw unstructured data (from scientific texts), that can then be processed to extract specific molecular/biological interactions using named entity recognizers for the identification of specific drugs, genes, and proteins such as a base.Implementation also focuses on network development based on these data to perform predictive analytics and novel drug discovery through pathway mapping and novel target identifications.• Network Pharmacology: Using graph-theoretical concepts alongside AI allows for more precise target discovery that uses not just single aspects (or just structure) but system-based evaluations with interrelations using multiple types of data outputs.Key aspects use network maps of protein−protein interaction, pathways (KEGG/GO), and genomic data sets that are combined with a Graph Neural Networks (GNNs) for better selection of strategic targets that influence large portions of cellular pathways based on a complete topological map, but this has the potential for biases if specific mechanisms or molecules are underrepresented in the known public databases, or with limitations in evaluations of parameters or data sets not used by original implemented models. 51</p>
<p>Model Architectures Applied in Target Identification.</p>
<p>For target identification, diverse model architectures are employed depending on the data source and desired output.For text processing of literature and biological databases, Transformer-based architectures, particularly adaptations of BERT, are increasingly prevalent.These models leverage selfattention mechanisms to effectively capture long-range dependencies within textual data, crucial for understanding complex biological contexts. 27For instance, Mol-BERT, a BERT architecture pretrained on 4 million unlabeled drug molecules, creates contextualized embeddings that capture latent chemical rules beneficial for target identification and downstream tasks.Parameter considerations for Transformers often include the number of layers (e.g., a 12-layer architecture in Mol-BERT), attention heads (e.g., multihead attention with 8−12 heads), and embedding dimensions (e.g., 768-dimensional embeddings in Mol-BERT). 27,52−54 Random Walk Guided GNN (RWGNN), for example, integrates random walk profiles with graph convolutions to predict distant drug−target interactions, achieving an AUC of 0.957 for DTIs ≥ 3 hops away, outperforming standard GCNs. 55Another architecture, DTI-HETA, constructs heterogeneous graphs integrating drug, target, and known DTI data and uses GAT layers to learn node embeddings, achieving state-of-the-art performance in DTI prediction. 53Multilayer perceptron (MLP) models and classical algorithms also remain relevant, especially for simpler data sets or initial exploratory analyses in target prioritization.</p>
<p>Recent advancements continue to refine AI-driven DTI prediction with sophisticated model architectures.For example, Wei et al. 56 recently proposed EADTN, an efficient deep model ensemble framework leveraging a novel feature adaptation technique and clustering-enhanced fine-tuning to improve the accuracy and efficiency of DTI prediction.This work underscores the ongoing innovation in model design within the field.</p>
<p>Model Evaluation Criteria for Target Identification. Evaluations of model performance use accuracy values</p>
<p>(sensitivity/specificity data, AUC and F1 scores for better handling bias data set implementation).Model design parameters (including pre/post processing steps for data sets, hyperparameter and design evaluations, and algorithm characteristics) are tested using k-fold validation (for stability and generalizability assessment across diverse/new data implementations) while reporting performance across diverse, validation, and original data sets, in original reports to test all performancebased validation results.Data sets with full translatable access also indicate better methodologies with robust models that provide higher scientific translatability/implementation. 57.1.4.Advantages, Disadvantages, Limitations and Opportunities.The previous parameters and data information provide the following insights on key limitations, advantages, and opportunity areas: NLP offers high speed, large data handling capacity for target identification, but may require more detailed interpretation protocols based on context/data variations, limiting its implementation when the data are complex or are far from a previously documented scientific study (with the use of open language or more colloquial settings).Omics methods produce excellent high throughput/ multi parametric evaluations of data sets allowing complex drug−target pathway interpretations; however, it faces problems due to biases from source, methodology, and type of data collected by laboratories (that lack direct standardization across institutions), making clinical implementations highly variable when transferring data from one source to another.Thus, new implementation models must consider clinical aspects to produce validated therapeutic models.In contrast to these inherent challenges in Omics data standardization, initiatives like the MF-PCBA data set 58 actively promote data standardization and accessibility within the HTS domain, offering a valuable resource for developing and benchmarking AI methodologies for drug discovery; Molecular Similarity prioritizes drug design and lead-identification by quickly screening compound libraries, but it is limited to the chemical space from available information in databases and might miss compounds with more novel chemical properties and parameters for higher activity.Finally, Network Pharmacology tools generate an integration strategy and large perspective based analysis of disease targets that requires more standardized data integration parameters.They highlight systemic interactions and molecular/pathway relationships that guide novel biological understanding, yet they need strong models to test for those specific network interaction parameters to establish new hypotheses beyond those used by common and limited single drug−target approaches that are still heavily tested for novel compound development.Implementation of better methodologies for data transparency and bias control is a main path for future improvements across the board.</p>
<p>4.2.Theme 2: AI Methodologies for Lead Discovery, Optimization, and Hit Identification.AI models provide several methodologies for improving all drug-candidate related parameters and increasing efficacy with targeted approaches, which include: enhancing high-throughput screenings, generating structure-based molecule design approaches for better molecular interactions and properties, and repurposing available drug data by exploring new parameters.AI tools based on data models and algorithm designs provide more rational ways to approach all phases involved in complex parameters assessments for selecting high value pharmaceutical/medical entities in an efficient manner.</p>
<p>AI Methodologies and Algorithmic</p>
<p>Designs.AIenhanced High-Throughput Screening (HTS) increasingly integrates neural networks, often employing CNN or RNNbased layers for rapid data extraction and analysis from highcontent imaging assays.Furthermore, contemporary AI-driven HTS methodologies are leveraging transfer learning to effectively incorporate the inherent multifidelity of HTS data.Traditional HTS funnels generate data across tiers, from largescale, lower-fidelity primary screens to smaller, high-fidelity confirmatory assays.Recent research, as exemplified by Buterez et al., 58 underscores the efficacy of transfer learning, particularly with Graph Neural Networks (GNNs), in enhancing molecular property prediction through the strategic integration of these multifidelity HTS data modalities.This approach acknowledges that primary screening data, while noisier, encompasses a vast chemical space, offering a valuable, inexpensive proxy to guide predictions on sparse, high-fidelity confirmatory screen data.Data sets like MF-PCBA, 59 introduced by Buterez et al. to benchmark such methods, provide a publicly available collection of standardized multifidelity HTS data, facilitating the development and evaluation of AI/ML models that effectively utilize multitiered experimental information.</p>
<p>Virtual screening utilizes diverse AI algorithms, including deep learning models and GNNs, to prioritize candidate molecules based on predicted properties.MSGNN-DTA, for example, combines atom-, motif-, and protein-level graphs with gated skip-connections for robust binding affinity prediction, achieving a low RMSE of 1.237 on the KIBA benchmark and demonstrating practical utility in virtual screening acceleration through an FDA-approved drug case study. 59tructure-Based Drug Design (SBDD) with AI is increasingly leveraging Transformer architectures alongside GNNs, particularly for protein sequence analysis and binding site compatibility prediction.The LEP-AD framework, combining ESM-2 protein embeddings (derived from Transformer models pretrained on UniRef50) with GCNs, demonstrates state-of-theart binding affinity prediction, achieving a 15% accuracy improvement over AlphaFold2-integrated models, highlighting the power of sequence-based embeddings. 60Furthermore, innovative approaches like DIFFDOCK, 61 introduced by Corso et al., are revolutionizing SBDD.DiffDock reframes molecular docking as a generative modeling task employing diffusion models, shifting from regression-based pose prediction to learning the distribution of plausible ligand poses.This paradigm shift enables more nuanced representation of inherent uncertainty in molecular docking and the capture of multiple, distinct binding modes, surpassing the limitations of single-pose regression methods.Molecular docking, a cornerstone of SBDD and virtual screening, has thus witnessed transformative AIdriven advancements beyond traditional scoring functions and search algorithms.</p>
<p>AI-driven drug repurposing utilizes various machine learning methodologies, often employing supervised learning models like Random Forest or Support Vector Machines (SVMs) trained on drug activity data.More advanced approaches, like metalearning frameworks such as Meta-GAT, are being explored to address data scarcity in repurposing by leveraging transfer learning methodologies across diverse drug and disease contexts, aiming to improve prediction accuracy, especially in low-data regimes. 62Large Language Models (LLMs) are also emerging as promising tools for drug repurposing.Frameworks like DrugReAlign, developed by Wei et al., 56 demonstrate that LLMs, when combined with multisource prompting, can effectively utilize vast knowledge bases to identify potential drug repurposing opportunities and mitigate challenges such as 'hallucinations' through incorporating multisource information and spatial interaction data.</p>
<p>Results from Published Studies.</p>
<p>Studies show how AI enhances virtual HTS performance with speed and cost reductions while providing better evaluation for compounds by implementing specific data mining to allow selection of those that traditional screening methods were not fully optimized to discover; furthermore, AI leads to finding unique structures/ compounds that were not previously evaluated or even tested using prior methods, while also showing improvement in potency and binding for target specificity in all model design implementation during new chemical and therapeutic compound and method development; AI-driven drug repurposing offers solutions that are fast/easily implemented when compared to more traditional drug discovery and have a larger applicability for high demand, unexplored therapeutic pathways.</p>
<p>4.2.3.Model Limitations and Future Avenues.Current methods that are highly dependent on HTS data sets have implementation problems when there are not proper controls for all variables for the system to accurately mimic in vivo parameters, and they also present limitations for understanding protein interactions (since they are based mostly on screening with low biological system complexity or when using oversimplified testing conditions).Implementations that focus on structural based drug design have parameters limited by what is known about protein topology with bias relating to publicly known protein conformations (rigid models or limited dynamics representations) with difficulties that translate into the selection of limited or predefined chemical structures.Implementation bias comes from relying on data already reported, while overlooking areas outside explored/reported experimental data ranges that also have influence on how new drugs/scaffolds are developed (and therefore must be tested using new data implementations or parameters).Drug repurposing studies are also affected by the quality of data implementation, and the capacity to generate results for a specific target is affected by limitations of validation data sets for both previous or future use case implementations while also neglecting parameters that control clinical responses, or patient demographics (due to poor data set evaluations/implementation and use of inadequate methodology to validate new drug applications in repurposing strategies).It is necessary, therefore, to move from the current focus on "structural analysis and virtual assays" into models with multiple validation parameters including real in vivo models and clinical end point data parameters to make translation and implementation parameters reliable for drug design development and pharmaceutical innovations.</p>
<p>4.3.Theme 3: AI in ADMET, Toxicology, and Clinical Development.AI has become also very influential in evaluating parameters on how new drug candidates can show more safety, efficacy, better toxicity, and pharmacological responses within biological settings while also predicting clinical implementation in humanized models.The power of new datadriven AI models in ADMET/toxicity predictions allows not only streamlining the processes of preclinical trials, but also offering key data that are related to toxicity prediction, and parameters related to drug behaviors using multifactorial biological analysis to reduce costs/time while improving the success of pharmaceutical translation into clinical implementation, allowing safer testing parameters and more reliable model implementations.AI is also used during clinical phases to select better patients (or disease subtypes that benefit from that molecule) with reduced bias and less testing periods for achieving clinical goals that can benefit the whole clinical study so it can be more precise and robust based on the new AI tools and methodological frameworks.</p>
<p>AI in Predictive Toxicology and Pharmacokinetics</p>
<p>. AI excels at predictive toxicology and pharmacokinetics by leveraging diverse data and sophisticated architectures.For solubility and toxicity prediction, Transformer-based models, like those utilizing ChemBERTa and ProtBert embeddings, analyze molecular features to optimize drug properties, reducing preclinical attrition. 27,60ChemBERTa &amp; ProtBert achieved an AUC of 0.973 on DTI prediction and demonstrated a 2−4% improvement in ROC-AUC over fingerprint-based methods for toxicity prediction, showcasing the value of transfer learning.For metabolic stability prediction, ProtBert embeddings have been successfully used to predict drug−enzyme interactions (e.g., CYP450), guiding structural modifications to avoid off-target effects.</p>
<p>In physiologically based pharmacokinetic (PBPK) modeling, GNNs enhance predictions by modeling tissue-specific partitioning coefficients. For dose optimization, GNNs are utilized to model pharmacokinetic parameters.GNN-based models can predict parameters like drug half-life, enabling optimized dosing regimens, although ongoing clinical validation is essential to fully realize this potential. 65o provide a clearer picture of the diverse AI methodologies and their demonstrated capabilities across various stages of drug development, Table 2 summarizes key examples of model architectures discussed in this review.This table highlights specific AI techniques, such as GNNs and Transformers, along with representative model names, typical parameter settings used in their implementations, and concrete examples of their application within drug discovery.Notably, it also includes performance metrics, like AUC and RMSE, where available from the referenced literature, offering a quantitative perspective on the efficacy of these AI approaches.When considering AI's role in clinical trial design and development, as discussed in this section, and more broadly across ADMET, toxicology, and preclinical stages (Theme 3), Table 2 serves as a valuable reference, illustrating the tangible progress and varied architectures being employed to enhance drug discovery and development pipelines.</p>
<p>4.3.3.Advantages, Limitations, and Opportunities.AI implementation (via ML/DL) speeds up safety evaluation protocols, reduces reliance on costly/time-consuming animal testing, while also generating more targeted predictions with real data validation during the drug development process (based on parameters previously mentioned above). 35Further, AI applications based on AI driven algorithms facilitate the selection and stratification of patients based on multiple bioclinical/genetic parameters to evaluate and highlight those patients with the greatest chance of positive response, with overall more efficient use of financial resources with shorter implementation protocols in studies to generate more quality results by utilizing large, diverse data sets from real-world clinical observations with a higher degree of clinical implementation relevance and translatable parameters.Implementations are highly biased with limited models that do not access real in vivo When models fail or yield unexpected results, their lack of interpretability makes diagnosing the root cause and extracting actionable insights for iterative design exceedingly difficult, slowing optimization cycles.This opacity also undermines trust and broader adoption by medicinal chemists and pharmacologists, who require clear rationales behind AI predictions to confidently integrate these tools into their decision-making processes.implicitly acknowledges this by seeking more efficient and accessible models, addressing the computational and expertise barriers is critical for democratizing AI's benefits in drug discovery.4.4.1.Challenges in Practical Implementation.Translating the promise of AI-driven drug discovery from research laboratories to routine practical application in the pharmaceutical industry presents a distinct set of challenges.While AI/ML models demonstrate impressive performance in controlled research settings, several hurdles remain for wider, seamless integration into established drug development workflows:</p>
<p>• Integration with Existing Infrastructure and Workflows: The seamless integration of AI/ML tools into existing pharmaceutical R&amp;D infrastructure and established workflows remains a complex undertaking.Many pharmaceutical companies face the challenge of retrofitting AI solutions into legacy systems and adapting established experimental and data management processes to effectively leverage AI insights.This requires significant investment in infrastructure upgrades, data harmonization efforts, and the development of user-friendly interfaces that can be readily adopted by non-AI specialist scientists.• Validation and Regulatory Acceptance: While scientific validation is a cornerstone of AI research, gaining regulatory acceptance for AI-driven drug discovery outputs presents a novel and evolving challenge.Regulatory agencies like the FDA and EMA are actively working to establish clear guidelines and validation parameters for AI/ML models used in drug development.However, standardized validation metrics, interpretability requirements for regulatory submissions, and clear pathways for demonstrating the reliability and robustness of AI-driven evidence are still under development.</p>
<p>Bridging the gap between academic validation and the rigorous evidentiary standards required for regulatory approval is crucial for the widespread adoption of AI in practical drug development.4.5.1.General Comparison and Performance Nuances.All AI/ML methods discussed perform well in specific aspects of drug discovery, offering improvements in speed, selectivity, specificity, and therapeutic potential.AI also enables more datadriven approaches in research, shifting away from purely expertise-based hypothesis generation in clinical study design and other areas.However, it is crucial to acknowledge that their superior complexity does not always translate to drastically better performance compared to classical Machine Learning methods like Random Forests and Support Vector Machines, especially in certain chemical modeling tasks.This nuanced perspective is supported by studies like Aleksićet al. 70 who, in their ADMET predictability study, observed that simpler algorithms can sometimes achieve comparable or even superior performance to more complex deep learning models on certain ADMET end points.Similarly, Groẗschla et al. 24 in their benchmarking of positional encodings for GNNs and Transformers, highlight that, while modern architectures offer significant advancements, careful hyperparameter tuning and appropriate feature engineering for simpler models can sometimes yield surprisingly competitive results.</p>
<p>This suggests that, while GNNs and Transformers excel at capturing complex, nonlinear relationships in molecular data, the benefit of this complexity must be carefully weighed against factors such as data set size, data quality, and the specific task.In comparing GNNs and Transformers, recent work like Edge-Set Attention (ESA) suggests that purely attention-based, edgecentric approaches can potentially achieve state-of-the-art performance with potentially greater simplicity and scalability compared to encoding-heavy graph transformers, while also outperforming strong GNN baselines on many tasks. 14For certain drug discovery tasks, especially those with limited data sets or where interpretability is paramount, simpler, more transparent models may offer a pragmatic and effective alternative, while for tasks demanding high accuracy and the ability to learn from large, complex data sets, modern architectures like GNNs and Transformers remain at the forefront.</p>
<p>However, many methods, both classical and modern AI, still require substantial human expertise for complex scientific analyses, implementation protocol design for future data, and nuanced interpretation of results for therapeutic applications.AI has undeniably enhanced speed and selectivity across drug discovery, offering methodologies for improved target specificity and therapeutic effect potential, while also reducing resource expenditure and adapting research paradigms toward datadriven approaches rather than solely expertise-based hypotheses in clinical study design.AI applications, however, often lack robust evaluation of drug candidate behavior in diverse patient populations, sometimes focusing disproportionately on highthroughput screenings rather than addressing high data variability in individual patient responses.This variability, stemming from diverse social, biological, and clinical parameters, can limit the generalizability of models and their applicability across all patient subpopulations.Therefore, integrating clinical/translational validation as an essential parameter in future AI-driven drug discovery studies is paramount.Moving beyond solely in silico evaluations as core implementation data and emphasizing real-world clinical parameters are key to further refining method evaluation and design in current AI drug pipelines.</p>
<p>CONCLUSION</p>
<p>This review has explored the transformative potential of Artificial Intelligence (AI) and Machine Learning (ML) in drug discovery, while also acknowledging the critical challenges, complexities, and ethical issues that need to be solved to promote safe implementation with a focus on robust and valid AI models that must become ethical, accessible, valid, and useful for all patient populations in therapeutic pharmaceutical design pipelines.AI/ML integration streamlined the drug development pathway, speeding up and improving lead molecule/target identification by accelerating HTS methods, using innovative molecule designs, and also showing potential for safer drugs by using bio/data and biomodel implementations for evaluation, which allow repurposing of existing drugs based on known data with a new understanding of disease mechanisms by implementing parameters that did not exist during their first implementation.AI model/implementation parameters have indeed enhanced and optimized efficiency throughout the process while opening new scientific directions, providing also validation parameters that promote clinical/biological results while improving drug safety and decreasing development time or resources.• Multimodal Data Integration: Integrating multimodal inputs�including bioassay measurements, validated clinical end points, and diverse in vivo or animal model results�ensures that model outputs reflect complex biological and physiological contexts rather than simplified computational abstractions.Emphasizing patient-centered metrics (e.g., pharmacodynamic responses and toxicity profiles) across broad popula-tions�including rare, underrepresented, and hard-toreach subgroups�enhances the robustness, generalizability, and real-world applicability of AI-driven predictions.</p>
<p>• Translational Data for Clinical Parameters: Incorporating in vivo data�from cell-based assays and animal studies to real-time patient measurements�into AI model development is critical for clinical relevance.Models trained exclusively on in vitro or purely computational data often fail to predict patient-level outcomes; therefore, pipelines that integrate clinically relevant end points under rigorous safety and ethical protocols are essential to validate performance in real-world settings.Moreover, assessing scalability, ensuring compatibility with limited-infrastructure environments, and democratizing data access will facilitate equitable deployment of AI-guided drug discovery and support the creation of targeted therapies for diverse populations.</p>
<p>Closing Statement.</p>
<p>Artificial intelligence and machine learning are now central to pharmaceutical innovation, demonstrably accelerating processes, reducing costs, and shortening timelines in drug development.This review underscores that realizing AI's transformative potential hinges on stringent, ethically grounded validation methodologies.While AI tools promise better, safer, faster, and more accessible medicines by moving beyond theoretical parameters, achieving this requires clear standardization, regulations prioritizing scientific validity with interpretable outputs, and rigorous mitigation of model biases through ethical principles and data integrity.This review contributes to this crucial evolution by providing an in-depth comparative analysis of AI methodologies across the drug discovery pipeline, from target identification to clinical development, with a particular emphasis on practical challenges and future directions and on its critical evaluation of the integration of diverse data types and model architectures, offering a nuanced perspective on their strengths and limitations.Promoting interdisciplinary collaboration and transparency, we can ensure AI's benefits are fully realized responsibly, creating safe, effective, and accessible medicines for a diverse global population, built upon the core foundations of ethical practice, robust validation, and technological accessibility.</p>
<p>2 . 4 .
24
Quality Assessment/Risk of Bias.Recognizing the limitations of standardized checklists for the rapidly evolving field of AI/ML in pharmaceutical science, this review prioritized scientific transparency for quality assessment over predefined questionnaires.The evaluation focused on methodological rigor and translatability, specifically targeting studies with (a) clear parameter implementation; (b) scientifically sound, translatable models robustly assessed using open data sets/code; and (c) explicit discussions of biases and limitations.Key quality parameters included: (a) translatability of methods and data; (b) clarity of methodological steps and parameter implementation details (data set usage, code/model accessibility); and (c) thorough analysis of inherent limitations/biases in study design, implementation, and evaluation, favoring reproducible results with high testability.This emphasis on core scientific components throughout the evaluation process aimed to mitigate bias and ensure an accurate assessment of each publication.</p>
<p>Figure 2 .
2
Figure 2. Schematic overview of the application of Graph Neural Networks (GNNs) in molecular modeling.The figure highlights: (i) the application domain;(ii) the key capabilities of GNNs, namely, direct learning from the graph structure and capturing complex relationships; (iii) the representation of molecular structure as a graph comprising atoms and bonds; and (iv) the integration of specific architectural blocks, such as GravNet, within the GNN framework.</p>
<p>4 . 1 .
41
Theme 1: Methodologies Used for Drug−Target Identification.AI-based tools have enabled faster and more robust ways for researchers to identify drug targets, previously overlooked using classical methods in scientific knowledge and biological/chemical data set interpretations.NLP (Natural Language Processing), AI for Omics Data Analysis, Molecular Similarity, and Network Pharmacology approaches are assessed for benefits, as well as areas needing further exploration in their respective methods of data interpretations based on what has been shown in recent reports.4.1.1.AI Methodologies for Target Identification in Drug Discovery.</p>
<p>Carneiro − Universidade Federal do Pará, Belém, Pará 66075-110, Brazil; Email: agnaldosc@ufpa.br</p>
<p>27ansformer architectures, initially revolutionizing Natural Language Processing, are now making significant inroads into molecular machine learning.Their ability to model long-range dependencies and complex contextual relationships through attention mechanisms is highly valuable for capturing nuanced molecular properties and interactions.Models like Mol-BERT27</p>
<p>3.2.2.Transformer Architectures in Molecular Modeling.</p>
<p>41−44Although data are accessible through public databases, current NLP AI methods lack capabilities for proper evaluations on biases introduced by language representation or text source variability (which often only include scientific results with a more specific context than clinical practice), and context recognition remains such as one of the key limiting steps to translate AI discoveries into real life solutions that are based on more than only text-driven implementations.•AI in Omics Data Analysis: AI and ML models provide robust approaches for processing complex data generated in genomics, transcriptomics, and proteomics.data,uncoveringassociations with diseases and facilitating predictive evaluations and biomarker identification.45−47Furthervalidationinvolves cross-linking with known pathways to add to their scientific validation value.Limitations for data sets come from variability in source parameters and from a lack of clear/standardized methodologies.Data sets with complex and noisy values are common in omics areas of science, and AI interpretation needs strong experimental parameters to translate model parameters to biological/ clinical settings to fully realize its high data mining implementation (if done correctly).•Molecular Similarity: AI tools leverage chemical data using methods such as Tanimoto Coefficients or cosine similarity coupled with the implementation of descriptors or molecular fingerprints to identify relevant components relating molecules to previously known drug ligands based on structure similarity and ligand−receptor complex interactions.</p>
<p>49,50zing both supervised and unsupervised learning techniques, these models effectively handle large, high-dimensional data sets that traditional methods struggle to analyze.During model implementation, data sets typically undergo preprocessing steps to eliminate biases and redundancies while emphasizing statistically significant features.Unsupervised methods focus on identifying patterns and groupings within the48Further models, built upon deep learning approaches (like Graph Neural Networks), use more complex features to model ligand interactions or can test new chemical regions for specific properties, thus creating a system that implements models with high precision but also a potential bias of limiting selection based only on well explored molecular regions.Also, model implementation needs high quality information about data set structure (which is publicly accessible in databases such as PUBChem, ZINC, and ChEMBL) that becomes a bottleneck when specific chemical compounds and/or novel structures are being screened using new data sets outside available open data sets, since model reliability will be tested more extensively against familiar chemical space.49,50</p>
<p>Table 2 .
2
Examples of AI Model Architectures and Performance in Drug Discovery Despite the undeniable benefits and expanding possibilities of AI/ML across various facets of drug development and therapeutic applications, it is crucial to acknowledge the inherent methodological and technical biases that can currently limit their broader, real-world applications.Common concerns broadly fall into areas of data collection, method design, implementation workflow, and the crucial translation of AI insights into tangible clinical and biological results.
Graph Neural Networks (GNNs)Transformer ArchitecturesMeta-LearningExampleGCNs, GATs, RWGNN, DTI-HETA,BERT, Mol-BERT, LEP-AD, Transformer-BERTMeta-GATArchitectures/MSGNN-DTAModelsTypical ParameterLayers (multiple), Attention Heads (inLayers (e.g., 12), Attention Heads (e.g., 8−12), EmbeddingBilevel Optimization, Pretraining TasksSettingsGATs), Embedding Dimensions (e.g., 768)Dimensions (e.g., 768), Pretraining Data (e.g., SMILES)(e.g., molecular property prediction)(Examples)Example ApplicationTarget Identification, DTI Prediction,Target Identification, Molecular Property Prediction, ToxicityDTI Prediction in Low-Data Scenariosin Drug DiscoveryBinding Affinity Prediction, DosePrediction, Binding Affinity PredictionOptimizationPerformance MetricAUC (e.g., 0.957 for RWGNN), RMSE (e.g.,AUC (e.g., 0.973 for ChemBERTa), ROC-AUCROC-AUC (above 0.85)(Example)1.237 for MSGNN-DTA)improvements (e.g., 2−4%)Example Data SetsDOCKSTRING, ExCAPE, BindingDBQMugs, ChEMBL, ZINCLIT-PCBA (for unbiased benchmarks)
66Addressing these data limitations is a focus of current research, resulting in the development of novel benchmark data sets designed to mitigate specific challenges.For example, LIT-PCBA66was specifically created to address the issue of hidden molecular biases in existing data sets, providing an 'unbiased' resource for</p>
<p>Interpretability and Transparency of Implementation Methods: Methods that implement "blackbox" parameters present interpretation limits in how AI arrives at certain conclusions.More emphasis on "white box" implementations with models that have interpretable outputs using methods such as XAI (explainable AI) should be prioritized for broader implementation and method validation and are vital to achieve proper translation of model-driven outputs to new knowledge that promotes confidence in novel AI-driven drug pipelines in medical areas.• In vivo and clinical implementation: Enhanced implementation parameters for complex, data-driven assessments�focusing on real-world application in preclinical studies and clinical trials to validate in vitro assays and model parameters�are needed to ensure performance outside computational simulations and to assess robustness and translatability through rigorous validation benchmarks.Moreover, model performance metrics must incorporate in vivo validation to capture not only binding affinities and potency in controlled assays, but also to predict real-life applicability and patientspecific responses within a multisystem biological context that includes human components.Finally, AI-driven data sets integrating preclinical validation results, patientspecific parameters, and therapeutic outcomes are vital for rigorously testing methods and developing more precisely targeted pharmaceutical protocols.5.3.Future Research Directions.Given the aforementioned gaps, areas for research should include: • Data Standardization: The creation of publicly available, open-source platforms with well-defined parameters and documentation should be encouraged and supported by governing and research institutions.Such platforms promote the sharing of high-quality, consistent data sets that adhere to standards for data validation, methodological transparency, and accessibility�including multilingual support to ensure equitable data access.Initiatives like LIT-PCBA, MF-PCBA, DOCKSTRING, and QMugs exemplify the critical impact of standardization in AIdriven drug discovery.Future efforts must continue to prioritize data quality and robustness, clear documentation, and open methodologies to accelerate progress across diverse research settings.• Advanced Docking Methodologies: Continued exploration of generative modeling�particularly for molecular docking�is poised to drive the next wave of AI-driven lead discovery.Approaches like DiffDock, which reconceptualizes docking as a generative diffusion process, have demonstrated superior accuracy and an ability to capture intricate protein−ligand interaction features compared to traditional regression-or search-based methods.Future work should expand these generative docking frameworks, focusing on enhancements in precision, computational efficiency, and seamless integration with broader AI-driven drug-discovery pipelines.• Explainable AI (XAI): Continued research into explainable AI is essential for rendering model outputs transparent�showing how specific predictions are derived, identifying limitations before data deployment, and uncovering novel associations that require external or multisystem validation.Translating "black-box" outputs into interpretable components will enhance methodological understanding among scientific specialists and empower policymakers and other stakeholders with clearer insights into AI-driven discoveries.
that have transparency, robust implementation with real in vitro testing data sets, and that also use validation resultsof such meticulously curated and openly accessible data sets are crucial for advancing the field.are better indicators of proper validation of AI methods to(1)translate model and data into clinical implementationparameters. Ethical parameters (including clear state-ments on methodology implementation, code access, andopen data set or robust data evaluations/accessibility)must be the core focus while selecting models that have agreater potential to influence how new drugs are madebased on transparent methodologies that are under-standable by diverse scientific communities in drugimplementation.• Ethical and Regulatory Considerations: Implementa-tion must consider all parameters that prevent biases orlimitations caused by oversimplifying model implementa-tion or methodology implementation through ethicalevaluations based on design parameters to promotetransparency, accountability, and a strong foundation onrobust data selection/implementation methodologiesthat can create methods for all pharmaceutical develop-ment processes that must also be compatible with diverseand variable patient populations/clinical conditions andnot favor single-point parameter analysis. New regulatoryframeworks are needed to improve methods for all areasof pharmaceutical development based on AI usage.• Future Directions: The need to implement XAImethods/models is high, as well as the exploration andfurther development of multimodal data integrationparameters and methods. Validations based on in vivo/clinical settings are critical to improve the accuracy of the design and model reliability/translatability (for methods). Clear methodologies are a key component of reliable scientific information that has better ethical translatable designs that create tools useful for diverse applications to all types of users across varied settings. 5.2. Identified Gaps. Key limitations identified across5.1. Summary of Key Points. Key insights obtained through this analysis include: • Transformative Potential of AI/ML: AI/ML demon-strates a strong capacity for tackling persistent limitations in traditional drug discovery with AI methods designed for different objectives. Data validation with different tools and AI model designs also allows exploration ofvarious reports reviewed highlighted the following needs:more parameters, as well as better methods selection with• Accessibility to Curated Data and Addressing Bias: Proprietary or highly limited data sets create inequalities in access and biases in implementations and model outcomes due to the use of limited samples; lack of data transparency and diversity representation limit AI efficacy. Clear methodology for bias control, evaluationhigher performance in lead compound selections in model implementation strategies for scientific research. The main challenge involves data bias that often favors only known data set results over the vast potential for drug design using previously unexplored pathways. • Diverse AI/ML Methodologies: A growing number offrom different perspectives in the data set parameter, asAI methods are being implemented for variouswell as source information (from data providers, studypharmaceutical goals in target evaluations, lead optimiza-design, patient populations, etc.) is key for new methods.tion, and other safety/efficacy tests. Those methods useImplementation should prioritize data set sources that aredifferent mathematical/algorithmic approaches, withreadily available and open source or for those whichmethods and implementation designed according to themethods for data set design or model evaluations can betype of data sets or data goals for the specific stages ofopenly checked and analyzed to test their translatablepharmaceutical research (with implementation rangingabilities with proper peer evaluation strategies. However,from CNNs and GNNs to Transformers and othersignificant progress is being made in creating publiclymethods for dimensionality reduction). New designs andavailable, high-quality data sets specifically designed toadaptations of classical models must be encouraged sinceaddress these challenges. Resources such as LIT-PCBAthese methods have low computational barriers or designdirectly target bias reduction in virtual screening bench-parameters.marks, MF-PCBA provides multifidelity HTS data to• Emphasis on Data and Validation: Models that showimprove representation of experimental complexities,translatable results are often related to better data setDOCKSTRING offers a standardized and accessiblevalidation, also with proper use of benchmarks parame-docking benchmark, and QMugs expands the chemicalters. Implementation must include quality data evalua-space and property coverage for quantum machinetions from independent researchers with different view-learning. Continued development and broader adoptionpoints (and data set implementations). Those methods
https://doi.org/10.1021/acsomega.5c00549 ACS Omega 2025, 10, 23889−23903
AuthorFábio J. N. Ferreira − Universidade Federal do Pará, Belém, Pará 66075-110, Brazil; orcid.org/0000-0001-7251-8026Complete contact information is available at: https://pubs.acs.org/10.1021/acsomega.5c00549FundingThe Article Processing Charge for the publication of this research was funded by the Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior (CAPES), Brazil (ROR identifier: 00x0ma614).NotesThe authors declare no competing financial interest.■ ACKNOWLEDGMENTSThe authors thank Professor Agnaldo S. Carneiro for his consistent support and valuable guidance during the preparation of this review.His expertise and encouragement were greatly appreciated throughout this project.The authors also acknowledge the Coordenacaõ de Aperfeicoamento de Pessoal de Nível Superior (CAPES) for their support.
Drug repurposing for viral cancers: A paradigm of machine learning, deep learning, and virtual screening-based approaches. F Ahmed, I S Kang, K H Kim, A Asif, C S A Rahim, A Samantasinghar, F H Memon, K H Choi, 10.1002/jmv.28693No. e28693Journal of Medical Virology. 20234</p>
<p>Applications of Machine Learning in Drug Discovery I: Target Discovery and Small Molecule Drug Design. J Cassidy, Artificial Intelligence in Oncology Drug Discovery and Development. J Cassidy, B Taylor, IntechOpen2020</p>
<p>Computational drug discovery. S.-S Ou-Yang, J.-Y Lu, X.-Q Kong, Z Liang, C -J.; Luo, H Jiang, 10.1038/aps.2012.109Acta Pharmacologica Sinica. 3392012</p>
<p>Application of Cancer Organoid Model for Drug Screening and Personalized Therapy. J Kondo, M Inoue, 10.3390/cells8050470Cells. 854702019</p>
<p>ChemPrint: An AI-Driven Framework for Enhanced Drug Discovery. T J Umansky, V A Woods, S M Russell, D M Smith, D J Haders, 10.1101/2024.03.22.5863142024586314</p>
<p>Drug Repurposing Strategy (DRS): Emerging Approach to Identify Potential Therapeutics for Treatment of Novel Coronavirus Infection. B M Sahoo, B V V Ravi Kumar, J Sruti, M K Mahapatra, B K Banik, P Borah, 10.3389/fmolb.2021.628144?urlappend=%3Fref%3DPDF&amp;jav=VoR&amp;rel=cite-asFrontiers in Molecular Biosciences. 2021</p>
<p>From data to knowledge: A mini-review on molecular network modeling and analysis for therapeutic target discovery. M Ozen, E S Emamian, A Abdi, 10.33696/Pharmacol.4.043Archives of Pharmacology and Therapeutics. 20231</p>
<p>Use of Support Vector Machine in Pattern Classification: Application to QSAR Studies. R Czerminśki, A Yasri, D Hartsough, 10.1002/1521-3838(200110)20:3&lt;227::AID-QSAR227&gt;3.0.CO;2-YQuantitative Structure-Activity Relationships. 2032001</p>
<p>Random Forest: A Classification and Regression Tool for Compound Classification and QSAR Modeling. V Svetnik, A Liaw, C Tong, J C Culberson, R P Sheridan, B P Feuston, 10.1021/ci034160g?urlappend=%3Fref%3DPDF&amp;jav=VoR&amp;rel=cite-asJ. Chem. Inf. Comput. Sci. 4362003. 1947−1958</p>
<p>Drug design by machine learning: support vector machines for pharmaceutical data analysis. R Burbidge, M Trotter, B Buxton, S Holden, 10.1016/S0097-8485(01)00094-8Computers &amp; Chemistry. 2612001</p>
<p>Discovery of senolytics using machine learning. V Smer-Barreto, A Quintanilla, R J R Elliott, J C Dawson, J Sun, V M Campa, A ́ Lorente-Macías, A Unciti-Broceta, N O Carragher, J C Acosta, 10.1038/s41467-023-39120-1Nat. Commun. 202313445</p>
<p>Evaluation of the Effectiveness of Herbal Components Based on Their Regulatory Signature on Carcinogenic Cancer Cells. F Esmaeili, T Lohrasebi, M Mohammadi-Dehcheshmeh, E Ebrahimie, 10.3390/cells10113139Cells. 2021113139</p>
<p>. V O Gawriljuk, P P K Zin, A C Puhl, K M Zorn, D Foil, </p>
<p>H Lane, T R Hurst, B Tavella, T A Costa, F T M Lakshmanane, P , 10.1021/acs.jcim.1c00683?urlappend=%3Fref%3DPDF&amp;jav=VoR&amp;rel=cite-asMachine Learning Models Identify Inhibitors of SARS-CoV-2. </p>
<p>. J. Chem. Inf. Model. 20219</p>
<p>An end-to-end attention-based approach for learning on graphs. D Buterez, J P Janet, D Oglic, P Lio, 10.48550/arXiv.2402.10793?urlappend=%3Fref%3DPDF&amp;jav=VoR&amp;rel=cite-as2024</p>
<p>Photon Reconstruction in the Belle II Calorimeter Using Graph Neural Networks. Computing and Software for Big Science. F Wemmer, I Haide, J Eppelt, T Ferber, A Beaubien, P Branchini, M Campajola, C Cecchi, P Cheema, G De Nardo, 10.1007/s41781-023-00105-w2023713</p>
<p>Explaining graph convolutional network predictions for clinicians�An explainable AI approach to Alzheimer's disease classification. S Tekkesinoglu, S Pudas, 10.3389/frai.2023.1334613?urlappend=%3Fref%3DPDF&amp;jav=VoR&amp;rel=cite-asFrontiers in Artificial Intelligence. 2024</p>
<p>Graph attention networks. P Velicǩovic, G Cucurull, A Casanova, A Romero, P Lio, Y Bengio, 2017</p>
<p>Principal neighbourhood aggregation for graph nets. G Corso, L Cavalleri, D Beaini, P Lio, P Velicǩovic, 2020. 13260−1327133Advances in neural information processing systems</p>
<p>MoleculeNet: a benchmark for molecular machine learning. Z Wu, B Ramsundar, E N Feinberg, J Gomes, C Geniesse, A S Pappu, K Leswing, V Pande, 10.1039/C7SC02664AChemical Science. 922018</p>
<p>ESOL: estimating aqueous solubility directly from molecular structure. J S Delaney, 10.1021/ci034243x?urlappend=%3Fref%3DPDF&amp;jav=VoR&amp;rel=cite-asJ. Chem. Inf. Comput. Sci. 4432004</p>
<p>Pushing the limits of solubility prediction via quality-oriented data selection. M C Sorkun, J M V A Koelman, S Er, 10.1016/j.isci.2020.101961202124101961</p>
<p>FreeSolv: a database of experimental and calculated hydration free energies, with input files. D L Mobley, J P Guthrie, 10.1007/s10822-014-9747-xJ. Comput. Aided Mol. Des. 2872014</p>
<p>Easy Molecular Docking Yields Better Benchmarks for Ligand Design. M García-Ortegón, G N C Simm, A J Tripp, J M Hernández-Lobato, A Bender, S Bacallado, Dockstring, 10.1021/acs.jcim.1c01334?urlappend=%3Fref%3DPDF&amp;jav=VoR&amp;rel=cite-asJ. Chem. Inf. Model. 202215</p>
<p>Benchmarking Positional Encodings for GNNs and Graph Transformers. F Grötschla, J Xie, R Wattenhofer, 10.48550/arXiv.2411.12732?urlappend=%3Fref%3DPDF&amp;jav=VoR&amp;rel=cite-as2024</p>
<p>Benchmarking graph neural networks. V P Dwivedi, C K Joshi, A T Luu, T Laurent, Y Bengio, X Bresson, J. Mach. Learn. Res. 2412023</p>
<p>Long Range Graph Benchmark. V P Dwivedi, L Rampásěk, M Galkin, A Parviz, G Wolf, A T Luu, D Beaini, 10.5555/3600270.3601892?urlappend=%3Fref%3DPDF&amp;jav=VoR&amp;rel=cite-asAdvances in Neural Information Processing Systems, Virtual, 2022/11/28; Neural Information Processing Systems Foundation. 20223514</p>
<p>Mol-BERT: An Effective Molecular Representation with BERT for Molecular Property Prediction. J Li, X Jiang, 10.1155/2021/7181815Wireless Communications and Mobile Computing 2021. 20217181815</p>
<p>Do Transformers Really Perform Badly for Graph Representation?. C Ying, T Cai, S Luo, S Zheng, G Ke, D He, Y Shen, T.-Y Liu, Advances in Neural Information Processing Systems. NeurIPS 2021342021</p>
<p>Artificial intelligence and machine learningaided drug discovery in central nervous system diseases: State-of-thearts and future directions. S Vatansever, A Schlessinger, D Wacker, H Kaniskan, ̈ Jin, J Zhou, M.-M Zhang, B , 10.1002/med.21764Medicinal Research Reviews. 20213</p>
<p>How artificial intelligence enables modeling and simulation of biological networks to accelerate drug discovery. M Dinuzzo, 10.3389/fddsv.2022.1019706?urlappend=%3Fref%3DPDF&amp;jav=VoR&amp;rel=cite-asFrontiers in Drug Discovery. 2022</p>
<p>An empirical study to accelerate machine learning and artificial intelligence adoption in pharmaceutical manufacturing organizations. A B Pazhayattil, G Konyu-Fogel, 10.1177/17411343221151109Journal of Generic Medicines. 1922023</p>
<p>Transformation of Drug Discovery towards Artificial Intelligence: An in Silico Approach. R Srivastava, Density Functional Theory -Recent Advances, New Perspectives and Applications; Glossman-Mitnik, D. IntechOpen2021</p>
<p>. M J Lamberti, M Wilkinson, B A Donzanti, G Wohlhieter, </p>
<p>A Study on the Application and Use of Artificial Intelligence to Support Drug Development. E Parikh, S Wilkins, R G Getz, K , 10.1016/j.clinthera.2019.05.018Clinical Therapeutics. 4182019</p>
<p>The role of AI in transforming auditing practices: A global perspective review. O Odeyemi, K F Awonuga, N Z Mhlongo, N L Ndubuisi, F O Olatoye, A I Daraojimba, 10.30574/wjarr.2024.21.2.0460World Journal of Advanced Research and Reviews. 20242</p>
<p>Revolutionizing Drug Discovery: A Comprehensive Review of AI Applications. R Dhudum, A Ganeshpurkar, A Pawar, 10.3390/ddc3010009Drugs and Drug Candidates. 20241</p>
<p>From Data to Compliance: The Role of AI/ML in Optimizing Regulatory Reporting Processes. R Tillu, M Muthusubramanian, V Periyasamy, 10.60087/jklst.vol2.n3.p391Journal of Knowledge Learning and Science Technology. 20243</p>
<p>Covid-19 and Artificial Intelligence: Genome sequencing, drug development and vaccine discovery. S Abubaker Bagabir, N K Ibrahim, H Abubaker Bagabir, R Hashem Ateeq, 10.1016/j.jiph.2022.01.011Journal of Infection and Public Health. 20222</p>
<p>Understanding the performance of knowledge graph embeddings in drug discovery. S Bonner, I P Barrett, C Ye, R Swiers, O Engkvist, C T Hoyt, W L Hamilton, 10.1016/j.ailsci.2022.100036Artificial Intelligence in the Life Sciences. 20222100036</p>
<p>Artificial intelligence for neurodegenerative experimental models. S J Marzi, B M Schilder, A Nott, C S Frigerio, S Willaime-Morawek, M Bucholc, D P Hanger, C James, P A Lewis, I Lourida, 10.1002/alz.13479202319Alzheimer's &amp; Dementia</p>
<p>Optimization of cell viability assays to improve replicability and reproducibility of cancer drug sensitivity screens. P Larsson, H Engqvist, J Biermann, E Werner Rönnerman, E Forssell-Aronsson, A Kovács, P Karlsson, K Helou, T Z Parris, 10.1038/s41598-020-62848-5Sci. Rep. 1012020</p>
<p>Explainable Artificial Intelligence for Drug Discovery and Development: A Comprehensive Survey. R Alizadehsani, S S Oyelere, S Hussain, S K Jagatheesaperumal, R R Calixto, M Rahouti, M Roshanzamir, V H De Albuquerque, 10.1109/ACCESS.2024.3373195IEEE Access. 122024</p>
<p>. L K Vora, A D Gholap, K Jetha, R R S Thakur, H Solanki, </p>
<p>Artificial Intelligence in Pharmaceutical Technology and Drug Delivery Design. K Chavda, V P , 10.3390/pharmaceutics15071916Pharmaceutics. 202371916</p>
<p>Decoding Tomorrow's Biotechnology: AI and Machine Learning Unveiled. V P Thikare, P S Pathak, 10.22214/ijraset.2024.58430International Journal of Research in Applied Science &amp; Engineering Technology. 20242</p>
<p>Application of Computational Biology and Artificial Intelligence in Drug Design. Y Zhang, M Luo, P Wu, S Wu, T.-Y Lee, C Bai, 10.3390/ijms232113568International Journal of Molecular Sciences. 20222113568</p>
<p>A multiomics approach to heterogeneity in Alzheimer's disease: focused review and roadmap. A Badhwar, G P Mcfall, S Sapkota, S E Black, H Chertkow, S Duchesne, M Masellis, L Li, R A Dixon, P Bellec, 10.1093/brain/awz384Brain. 20205</p>
<p>Challenges in the integration of omics and non-omics data. E López De Maturana, L Alonso, P Alarcón, I A Martín-Antoniano, S Pineda, L Piorno, M L Calle, N Malats, 10.3390/genes10030238Genes. 1032382019</p>
<p>Integrated omics: tools, advances and future approaches. B B Misra, C Langefeld, M Olivier, L A Cox, 10.1530/JME-18-0055Journal of molecular endocrinology. 6212019</p>
<p>Similarity-based methods and machine learning approaches for target prediction in early drug discovery: performance and scope. N Mathai, J Kirchmair, 10.3390/ijms21103585International Journal of Molecular Sciences. 1035852020</p>
<p>Large-Scale Parameter Estimation for Crystal Structure Prediction. Part 1: Dataset, Methodology, and Implementation. D Bowskill, B Tan, A Keates, I Sugden, C Adjiman, C Pantelides, 10.1021/acs.jctc.4c01091?urlappend=%3Fref%3DPDF&amp;jav=VoR&amp;rel=cite-asJ. Chem. Theory Comput. 20222024</p>
<p>Molecular Classification with Graph Convolutional Networks: Exploring the MUTAG Dataset for Mutagenicity Prediction. L Pathak, K Desai, C Kela, T Patel, 10.38124//ijisrt/IJISRT24AUG1084International Journal of Innovative Science and Research Technology. IJISRT) 2024, 2545−2550</p>
<p>Knowledge mapping of graph neural networks for drug discovery: a bibliometric and visualized analysis. R Yao, Z Shen, X Xu, G Ling, R Xiang, T Song, F Zhai, Y Zhai, 10.3389/fphar.2024.1393415Frontiers in Pharmacology. 1513934152024</p>
<p>Identifying drug-target interactions based on graph convolutional network and deep neural network. T Zhao, Y Hu, L R Valsdottir, T Zang, J Peng, 10.1093/bib/bbaa044Briefings in bioinformatics. 20212</p>
<p>DTI-HETA: prediction of drug-target interactions based on GCN and GAT on heterogeneous graph. K Shao, Y Zhang, Y Wen, Z Zhang, S He, X Bo, 10.1093/bib/bbac109Briefings in Bioinformatics. 20223109</p>
<p>DTIGCCN: Prediction of drug-target interactions based on GCN and CNN. K Shao, Z Zhang, S He, X Bo, 2020 IEEE 32nd International Conference on Tools with Artificial Intelligence. ICTAI)</p>
<p>. IEEE. 3422020</p>
<p>Predicting Distant Drug-Target Interactions via a Random Walk Guided Graph Neural Network. X Jin, M Xie, Y Huang, M Liu, D Kong, Y Xuan, Y Kuang, IEEE International Conference on Bioinformatics and Biomedicine (BIBM). 15412024. 2024IEEE</p>
<p>DrugReAlign: a multisource prompt framework for drug repurposing based on large language models. J Wei, L Zhuo, X Fu, X Zeng, L Wang, Q Zou, D Cao, 10.1186/s12915-024-02028-3BMC biology. 20241226</p>
<p>Evaluation metrics and statistical tests for machine learning. O Rainio, J Teuho, R Klén, 10.1038/s41598-024-56706-xSci. Rep. 202416086</p>
<p>Transfer learning with graph neural networks for improved molecular property prediction in the multi-fidelity setting. D Buterez, J P Janet, S J Kiddle, D Oglic, P Lió, 10.1038/s41467-024-45566-8Nat. Commun. 202411517</p>
<p>Mf-pcba: Multifidelity high-throughput screening benchmarks for drug discovery and machine learning. D Buterez, J P Janet, S J Kiddle, P Lio, 10.1021/acs.jcim.2c01569?urlappend=%3Fref%3DPDF&amp;jav=VoR&amp;rel=cite-asJ. Chem. Inf. Model. 20239</p>
<p>. A Daga, S A Khan, D G Cabrero, R Hoehndorf, N Kiani, </p>
<p>LEP-AD: Language Embedding of Proteins and Attention to Drugs predicts drug target interactions. A Tegnér, J , bioRxiv. 2023, 2023.2003.2014.532563</p>
<p>Diffdock: Diffusion steps, twists, and turns for molecular docking. G Corso, H Stärk, B Jing, R Barzilay, T Jaakkola, Machine Learning for Structural Biology Workshop. 2022</p>
<p>A unified drug-target interaction prediction framework based on knowledge graph and recommendation system. Q Ye, C.-Y Hsieh, Z Yang, Y Kang, J Chen, D Cao, S He, T Hou, 10.1038/s41467-021-27137-3Nat. Commun. 202116775</p>
<p>ToxAIcology -The evolving role of artificial intelligence in advancing toxicology and modernizing regulatory science. ALTEX -Alternatives to animal experimentation. T Hartung, 10.14573/altex.2309191202340</p>
<p>SMGCN: Multiple Similarity and Multiple Kernel Fusion Based Graph Convolutional Neural Network for Drug-Target Interactions Prediction. W Wang, M Yu, B Sun, J Li, D Liu, H Zhang, X Wang, Y Zhou, 10.1109/TCBB.2023.3339645IEEE/ACM Transactions on Computational Biology and Bioinformatics. 20241</p>
<p>Msgnn-dta: Multi-scale topological feature fusion based on graph neural networks for drug-target binding affinity prediction. S Wang, X Song, Y Zhang, K Zhang, Y Liu, C Ren, S Pang, 10.3390/ijms24098326International Journal of Molecular Sciences. 202398326</p>
<p>LIT-PCBA: an unbiased data set for machine learning and virtual screening. V.-K Tran-Nguyen, C Jacquemard, D Rognan, 10.1021/acs.jcim.0c00155?urlappend=%3Fref%3DPDF&amp;jav=VoR&amp;rel=cite-asJ. Chem. Inf. Model. 6092020</p>
<p>QMugs, quantum mechanical properties of drug-like molecules. C Isert, K Atz, J Jiménez-Luna, G Schneider, 10.1038/s41597-022-01390-7Scientific Data. 20221273</p>
<p>Joint deep autoencoder and subgraph augmentation for inferring microbial responses to drugs. Z Zhou, L Zhuo, X Fu, Q Zou, 10.1093/bib/bbad483Briefings in Bioinformatics. 20231483</p>
<p>Efficient deep model ensemble framework for drug-target interaction prediction. J Wei, Y Zhu, L Zhuo, Y Liu, X Fu, F Li, 10.1021/acs.jpclett.4c01509?urlappend=%3Fref%3DPDF&amp;jav=VoR&amp;rel=cite-asJ. Phys. Chem. Lett. 202430</p>
<p>ADMET predictability at Boehringer Ingelheim: state-of-the-art, and do bigger datasets or algorithms make a difference?. S Aleksic, D Seeliger, J Brown, 10.1002/minf.202100113Molecular Informatics. 202222100113</p>            </div>
        </div>

    </div>
</body>
</html>