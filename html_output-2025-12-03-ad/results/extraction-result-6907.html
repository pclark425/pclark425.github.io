<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6907 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6907</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6907</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-133.html">extraction-schema-133</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <p><strong>Paper ID:</strong> paper-15077614</p>
                <p><strong>Paper Title:</strong> The neurobiology of semantic memory</p>
                <p><strong>Paper Abstract:</strong> Semantic memory includes all acquired knowledge about the world and is the basis for nearly all human activity, yet its neurobiological foundation is only now becoming clear. Recent neuroimaging studies demonstrate two striking results: the participation of modality-speciﬁc sensory, motor, and emotion systems in language comprehension</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6907.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6907.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Embodied cognition</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Embodied (or situated) cognition / simulation view</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Theory that conceptual knowledge is at least partly represented by reactivation or partial simulation of sensory, motor and affective neural systems that were engaged during original experience; comprehension involves modality-specific neural activity.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Perceptual symbol systems</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Embodied Cognition / Simulation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>embodied simulation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are represented via modality-specific neural ensembles (sensory, motor, affective) and retrieval involves partial reactivation (simulation) of those ensembles; representations are isomorphic with perceptual/motor input to varying degrees.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains modality-specific semantic effects (e.g., action words activate motor regions), provides a biologically plausible mechanism for concept learning by generalization across exemplars, and accounts for conceptual grounding in sensorimotor experience.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>fMRI, PET, TMS, lesion/patient studies, EEG/MEG timing studies, meta-analysis</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>Language comprehension contrasts (action vs non-action words), word vs pseudoword, semantic decision vs phonological decision, TMS disruption during action-word tasks, patient studies of motor system damage, MEG/EEG timing measures</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Multiple imaging studies show modality-specific activation during language comprehension (action, motion, color, auditory, olfactory, gustatory, emotion); TMS and patient studies show impairment for action-word processing after motor-system perturbation/disease; early motor activation (≈150–200 ms) suggests involvement in early semantic access.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Activations could be epiphenomenal or post-comprehension imagery, and some patient data show only subtle conceptual deficits after modality-specific impairment; strong versions (sensory areas alone sufficient) are challenged.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Binder & Desai (2011)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The neurobiology of semantic memory', 'publication_date_yy_mm': '2011-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6907.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6907.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Strong embodiment</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Strong embodiment (perceptual = conceptual system)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A radical version of embodied theory that claims perceptual systems themselves are the conceptual system, i.e., conceptual processing is carried out by the same neural substrates as perception.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Perceptual symbol systems</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Strong Embodiment</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>embodied simulation (strong)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Argues there is no separate, amodal conceptual layer: conceptual processing is identical to perceptual/motor processing carried out in primary and secondary modal cortices.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Predicts that damage to perceptual/motor systems should cause catastrophic loss of corresponding conceptual knowledge and that modality-specific cortex is necessary and sufficient for concept representation.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>Lesion/patient studies, TMS, neuroimaging temporal dynamics</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>Comparisons of conceptual performance in patients with sensory/motor lesions; TMS to motor cortex during action-word tasks; fMRI/MEG timing of activation</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Patient and TMS evidence shows modality-specific systems contribute to comprehension but conceptual deficits after modality damage are typically subtle rather than catastrophic; temporal dynamics show early but not exclusive modal activation.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Semantic deficits after sensory/motor impairment are usually partial/subtle; lesions in temporal and inferior parietal heteromodal cortex produce multimodal semantic loss (semantic dementia), inconsistent with strict strong embodiment.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Binder & Desai (2011)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The neurobiology of semantic memory', 'publication_date_yy_mm': '2011-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6907.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6907.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Amodal / Disembodied symbolic models</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Disembodied amodal symbolic models (classical symbolic representation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Theoretical tradition (e.g., computational-symbolic approaches) that conceptual knowledge is stored as amodal, language-like symbols separate from perceptual/motor systems.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Computation and cognition: toward a foundation for cognitive science</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Amodal Symbolic Representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>symbolic (amodal)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are represented as abstract, amodal symbols or tokens (semantic networks, feature lists, ontologies) manipulated independently of sensory-motor representations.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Accounts for flexible, combinatorial manipulation of concepts and supports architectures for general reasoning and language processing; predicts conceptual operations can proceed without modal simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>Computational models, behavioral data, AI systems; contrasted with neuroimaging and patient data in review</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>N/A within this review (historical/theoretical contrast); empirical contrasts include tasks that should not require modal simulation (rapid, abstract language comprehension)</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Extensive modality-specific activation during many semantic tasks is inconsistent with a pure amodal-symbolic model; however, purely symbolic models have explanatory power for abstract combinatorial capacities.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Neuroimaging and lesion data show involvement of sensory-motor and heteromodal cortical areas in semantic tasks, which contradicts strict separation of perception and conceptual representation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Binder & Desai (2011)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The neurobiology of semantic memory', 'publication_date_yy_mm': '2011-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6907.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6907.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Perceptual symbol systems</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Perceptual Symbol Systems (Barsalou)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Proposal that conceptual representations are grounded in perceptual modality systems and consist of modality-specific 'perceptual symbols' that can be recombined and simulated during cognition.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Perceptual symbol systems</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Perceptual Symbol Systems</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>embodied simulation / feature-based</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual knowledge consists of distributed modality-specific representations (perceptual symbols) formed from sensory-motor experience; higher-level concepts emerge from recombination of these modal symbols.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains grounded semantic effects, conceptual combination, and mental imagery; predicts modality-specific activation during concept retrieval and graded abstraction with familiarity/context.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>Behavioral experiments, neuroimaging, lesion data (cited in review)</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>Language comprehension tasks, imagery tasks, semantic feature verification, fMRI contrasts</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Neuroimaging meta-analysis and modality-specific activations are consistent with Barsalou's idea of perceptual-symbol-based concepts; engagement varies with context and familiarity.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Does not by itself specify role of heteromodal cortex/hubs; strong versions conflating perception and concept are challenged by multimodal lesions producing amodal deficits.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Binder & Desai (2011)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The neurobiology of semantic memory', 'publication_date_yy_mm': '2011-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6907.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e6907.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Damasio convergence zones</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Convergence zone model (Damasio's local convergence zones)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Model whereby distributed modality-specific representations are bound by convergence zones that index and reinstantiate patterns across modalities to support recall and recognition.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Time-locked multiregional retroactivation: a systems-level proposal for the neural substrates of recall and recognition</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Convergence Zone Model</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>convergence / binding network (embodied hybrid)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Local convergence zones receive and coordinate inputs from modality-specific systems and mediate reactivation/association across modalities, enabling reconstruction of perceptual and conceptual content.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains how distributed sensory-motor traces can be flexibly retrieved and combined to form conceptual content; supports episodic recall and multimodal concept retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>Neuroanatomical connectivity data, lesion studies, functional imaging meta-analyses</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>Neuroimaging general semantic contrasts, lesion correlation with semantic deficits, anatomical mapping</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Large heteromodal cortical regions (inferior parietal, lateral and ventral temporal cortex) sit at confluences of modal streams and show reliable semantic activation consistent with being convergence zones.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Precise loci and hierarchical relations among convergence zones are debated (e.g., role of temporal pole); some proponents of amodal hubs argue for distinct amodal representations rather than distributed convergence.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Binder & Desai (2011)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The neurobiology of semantic memory', 'publication_date_yy_mm': '2011-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6907.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e6907.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hub-and-spoke</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hub-and-spoke model (Patterson, Rogers, Lambon Ralph et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Hybrid model positing modality-specific 'spokes' (sensory-motor representations) connected to an amodal central 'hub' (often proposed in anterior temporal lobe) that integrates information to form coherent concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Where do you know what you know? The representation of semantic knowledge in the human brain</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Hub-and-Spoke Model</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>hybrid: amodal hub + modal spokes</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Semantic memory arises from interaction between distributed modality-specific stores (spokes) and a transmodal amodal hub that abstracts and integrates across modalities to form generalized concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Accounts for multimodal semantic deficits (e.g., semantic dementia) by hub damage, explains category-general impairment and supports cross-modal generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>Patient studies (semantic dementia), voxel-based morphometry, computational PDP models, neuroimaging</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>Lesion/atrophy correlation with multimodal semantic performance, semantic tasks across modalities, rTMS to anterior temporal lobe</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Semantic dementia patients with anterior temporal atrophy show multimodal semantic loss consistent with a hub role; however, meta-analysis shows multimodal convergence across broader temporal and inferior parietal regions, not limited to temporal pole.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Binder & Desai argue temporal pole is not sole hub — heteromodal convergence zones are distributed across lateral/ventral temporal and inferior parietal cortex; inferior parietal involvement is under-emphasized in some hub accounts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Binder & Desai (2011)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The neurobiology of semantic memory', 'publication_date_yy_mm': '2011-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6907.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e6907.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Temporal pole hub hypothesis</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Temporal pole as central amodal semantic hub (temporal pole hub hypothesis)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Specific variant of hub hypothesis positing the anterior temporal pole (TP) as the primary amodal convergence hub for semantic knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Where do you know what you know? The representation of semantic knowledge in the human brain</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Temporal Pole Hub Hypothesis</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>amodal hub</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Proposes that anterior temporal pole integrates multimodal inputs and serves as the principal amodal repository for conceptual knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Predicts maximal semantic deficits when TP is damaged and anatomical locus of highest-order conceptual abstraction in TP.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>Semantic dementia atrophy patterns, anatomical connectivity studies, lesion-behavior correlations</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>Voxel-based morphometry in semantic dementia, lesion mapping, comparisons of atrophy-severity vs semantic impairment</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Semantic dementia often shows severe TP atrophy, but Binder & Desai note broader ventral/lateral temporal involvement; correlations between atrophy and semantic deficits are often stronger in mid-temporal regions than TP.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Human temporal lobe organization differs from monkeys; visual cortex occupies less of human temporal lobe, and multimodal convergence likely extends across lateral/ventral temporal and inferior parietal areas; TP also heavily associated with emotion/social concepts rather than general hub function.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Binder & Desai (2011)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The neurobiology of semantic memory', 'publication_date_yy_mm': '2011-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6907.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e6907.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Embodied abstraction (Binder & Desai)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Embodied abstraction (progressive abstraction via heteromodal convergence)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Authors' proposed synthesis in which conceptual representation arises from multiple hierarchical levels of abstraction grounded in modality-specific systems and embodied via heteromodal convergence zones that store schematic supramodal representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Embodied Abstraction</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>hybrid: embodied simulation + supramodal abstraction</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual knowledge consists of a continuum from detailed modality-specific simulations to schematic, highly abstract supramodal representations in heteromodal cortex; access to levels depends on familiarity, context, and task demands.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Explains variable involvement of modality-specific regions (depth of simulation), supports rapid language comprehension via schematic supramodal representations, accounts for multimodal deficits in heteromodal lesion patients and embodiment effects in modal areas.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>fMRI meta-analysis (120 studies), patient studies (semantic dementia), TMS, EEG/MEG timing studies, anatomical connectivity evidence</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>General semantic contrasts (words vs pseudowords, semantic vs phonological tasks), modality-specific language tasks, lesion correlations, TMS disruption</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Meta-analysis shows reliable activation in heteromodal temporal and inferior parietal cortices for general semantic tasks, while modality-specific activations occur depending on semantic content and task — consistent with hierarchical embodied abstraction.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Precise nature and localization of supramodal representations (e.g., role of inferior parietal vs temporal lobe) require further specification and testing; necessity of modality-specific systems across tasks remains to be definitively proven.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Binder & Desai (2011)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The neurobiology of semantic memory', 'publication_date_yy_mm': '2011-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6907.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e6907.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Heteromodal / supramodal convergence zones</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Heteromodal (supramodal) convergence zones in lateral/ventral temporal and inferior parietal cortex</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Functional concept that anterior/lateral temporal and inferior parietal cortices act as convergence zones that store abstracted, schematic representations across modalities supporting supramodal conceptual operations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Heteromodal (Supramodal) Convergence Zones</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>supramodal representations / convergence network</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Regions at confluences of perceptual processing streams integrate modal inputs to form abstracted, modality-independent representations (supramodal) used for object recognition, category structure, language and scene construction.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Accounts for multimodal semantic retrieval, category-general deficits after heteromodal lesions, and rapid schematic conceptual access supporting language and prospection.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>Meta-analysis of functional imaging (120 studies), lesion/semantic dementia data, anatomical connectivity studies</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>General semantic contrasts, lesion-atrophy correlation with multimodal semantic impairment, fMRI activation likelihood estimation meta-analysis</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Meta-analysis reveals consistent activation across left lateral/ventral temporal and inferior parietal cortex in semantic tasks, matching areas implicated in semantic dementia and vascular lesions producing semantic impairments.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td>Debate remains over whether a single central hub (e.g., temporal pole) or distributed heteromodal network best explains amodal aspects of semantics; precise content types represented in AG vs temporal lobe are under-specified.</td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Binder & Desai (2011)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'The neurobiology of semantic memory', 'publication_date_yy_mm': '2011-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Perceptual symbol systems <em>(Rating: 2)</em></li>
                <li>Time-locked multiregional retroactivation: a systems-level proposal for the neural substrates of recall and recognition <em>(Rating: 2)</em></li>
                <li>Where do you know what you know? The representation of semantic knowledge in the human brain <em>(Rating: 2)</em></li>
                <li>Where is the semantic system? A critical review and meta-analysis of 120 functional neuroimaging studies <em>(Rating: 2)</em></li>
                <li>A critical look at the embodied cognition hypothesis and a new proposal for grounding conceptual content <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6907",
    "paper_id": "paper-15077614",
    "extraction_schema_id": "extraction-schema-133",
    "extracted_data": [
        {
            "name_short": "Embodied cognition",
            "name_full": "Embodied (or situated) cognition / simulation view",
            "brief_description": "Theory that conceptual knowledge is at least partly represented by reactivation or partial simulation of sensory, motor and affective neural systems that were engaged during original experience; comprehension involves modality-specific neural activity.",
            "citation_title": "Perceptual symbol systems",
            "mention_or_use": "use",
            "theory_name": "Embodied Cognition / Simulation",
            "theory_type": "embodied simulation",
            "theory_description": "Concepts are represented via modality-specific neural ensembles (sensory, motor, affective) and retrieval involves partial reactivation (simulation) of those ensembles; representations are isomorphic with perceptual/motor input to varying degrees.",
            "functional_claims": "Explains modality-specific semantic effects (e.g., action words activate motor regions), provides a biologically plausible mechanism for concept learning by generalization across exemplars, and accounts for conceptual grounding in sensorimotor experience.",
            "evidence_source": "fMRI, PET, TMS, lesion/patient studies, EEG/MEG timing studies, meta-analysis",
            "experimental_paradigm": "Language comprehension contrasts (action vs non-action words), word vs pseudoword, semantic decision vs phonological decision, TMS disruption during action-word tasks, patient studies of motor system damage, MEG/EEG timing measures",
            "key_result": "Multiple imaging studies show modality-specific activation during language comprehension (action, motion, color, auditory, olfactory, gustatory, emotion); TMS and patient studies show impairment for action-word processing after motor-system perturbation/disease; early motor activation (≈150–200 ms) suggests involvement in early semantic access.",
            "supports_theory": true,
            "counter_evidence": "Activations could be epiphenomenal or post-comprehension imagery, and some patient data show only subtle conceptual deficits after modality-specific impairment; strong versions (sensory areas alone sufficient) are challenged.",
            "citation": "Binder & Desai (2011)",
            "uuid": "e6907.0",
            "source_info": {
                "paper_title": "The neurobiology of semantic memory",
                "publication_date_yy_mm": "2011-11"
            }
        },
        {
            "name_short": "Strong embodiment",
            "name_full": "Strong embodiment (perceptual = conceptual system)",
            "brief_description": "A radical version of embodied theory that claims perceptual systems themselves are the conceptual system, i.e., conceptual processing is carried out by the same neural substrates as perception.",
            "citation_title": "Perceptual symbol systems",
            "mention_or_use": "mention",
            "theory_name": "Strong Embodiment",
            "theory_type": "embodied simulation (strong)",
            "theory_description": "Argues there is no separate, amodal conceptual layer: conceptual processing is identical to perceptual/motor processing carried out in primary and secondary modal cortices.",
            "functional_claims": "Predicts that damage to perceptual/motor systems should cause catastrophic loss of corresponding conceptual knowledge and that modality-specific cortex is necessary and sufficient for concept representation.",
            "evidence_source": "Lesion/patient studies, TMS, neuroimaging temporal dynamics",
            "experimental_paradigm": "Comparisons of conceptual performance in patients with sensory/motor lesions; TMS to motor cortex during action-word tasks; fMRI/MEG timing of activation",
            "key_result": "Patient and TMS evidence shows modality-specific systems contribute to comprehension but conceptual deficits after modality damage are typically subtle rather than catastrophic; temporal dynamics show early but not exclusive modal activation.",
            "supports_theory": false,
            "counter_evidence": "Semantic deficits after sensory/motor impairment are usually partial/subtle; lesions in temporal and inferior parietal heteromodal cortex produce multimodal semantic loss (semantic dementia), inconsistent with strict strong embodiment.",
            "citation": "Binder & Desai (2011)",
            "uuid": "e6907.1",
            "source_info": {
                "paper_title": "The neurobiology of semantic memory",
                "publication_date_yy_mm": "2011-11"
            }
        },
        {
            "name_short": "Amodal / Disembodied symbolic models",
            "name_full": "Disembodied amodal symbolic models (classical symbolic representation)",
            "brief_description": "Theoretical tradition (e.g., computational-symbolic approaches) that conceptual knowledge is stored as amodal, language-like symbols separate from perceptual/motor systems.",
            "citation_title": "Computation and cognition: toward a foundation for cognitive science",
            "mention_or_use": "mention",
            "theory_name": "Amodal Symbolic Representation",
            "theory_type": "symbolic (amodal)",
            "theory_description": "Concepts are represented as abstract, amodal symbols or tokens (semantic networks, feature lists, ontologies) manipulated independently of sensory-motor representations.",
            "functional_claims": "Accounts for flexible, combinatorial manipulation of concepts and supports architectures for general reasoning and language processing; predicts conceptual operations can proceed without modal simulations.",
            "evidence_source": "Computational models, behavioral data, AI systems; contrasted with neuroimaging and patient data in review",
            "experimental_paradigm": "N/A within this review (historical/theoretical contrast); empirical contrasts include tasks that should not require modal simulation (rapid, abstract language comprehension)",
            "key_result": "Extensive modality-specific activation during many semantic tasks is inconsistent with a pure amodal-symbolic model; however, purely symbolic models have explanatory power for abstract combinatorial capacities.",
            "supports_theory": false,
            "counter_evidence": "Neuroimaging and lesion data show involvement of sensory-motor and heteromodal cortical areas in semantic tasks, which contradicts strict separation of perception and conceptual representation.",
            "citation": "Binder & Desai (2011)",
            "uuid": "e6907.2",
            "source_info": {
                "paper_title": "The neurobiology of semantic memory",
                "publication_date_yy_mm": "2011-11"
            }
        },
        {
            "name_short": "Perceptual symbol systems",
            "name_full": "Perceptual Symbol Systems (Barsalou)",
            "brief_description": "Proposal that conceptual representations are grounded in perceptual modality systems and consist of modality-specific 'perceptual symbols' that can be recombined and simulated during cognition.",
            "citation_title": "Perceptual symbol systems",
            "mention_or_use": "mention",
            "theory_name": "Perceptual Symbol Systems",
            "theory_type": "embodied simulation / feature-based",
            "theory_description": "Conceptual knowledge consists of distributed modality-specific representations (perceptual symbols) formed from sensory-motor experience; higher-level concepts emerge from recombination of these modal symbols.",
            "functional_claims": "Explains grounded semantic effects, conceptual combination, and mental imagery; predicts modality-specific activation during concept retrieval and graded abstraction with familiarity/context.",
            "evidence_source": "Behavioral experiments, neuroimaging, lesion data (cited in review)",
            "experimental_paradigm": "Language comprehension tasks, imagery tasks, semantic feature verification, fMRI contrasts",
            "key_result": "Neuroimaging meta-analysis and modality-specific activations are consistent with Barsalou's idea of perceptual-symbol-based concepts; engagement varies with context and familiarity.",
            "supports_theory": true,
            "counter_evidence": "Does not by itself specify role of heteromodal cortex/hubs; strong versions conflating perception and concept are challenged by multimodal lesions producing amodal deficits.",
            "citation": "Binder & Desai (2011)",
            "uuid": "e6907.3",
            "source_info": {
                "paper_title": "The neurobiology of semantic memory",
                "publication_date_yy_mm": "2011-11"
            }
        },
        {
            "name_short": "Damasio convergence zones",
            "name_full": "Convergence zone model (Damasio's local convergence zones)",
            "brief_description": "Model whereby distributed modality-specific representations are bound by convergence zones that index and reinstantiate patterns across modalities to support recall and recognition.",
            "citation_title": "Time-locked multiregional retroactivation: a systems-level proposal for the neural substrates of recall and recognition",
            "mention_or_use": "use",
            "theory_name": "Convergence Zone Model",
            "theory_type": "convergence / binding network (embodied hybrid)",
            "theory_description": "Local convergence zones receive and coordinate inputs from modality-specific systems and mediate reactivation/association across modalities, enabling reconstruction of perceptual and conceptual content.",
            "functional_claims": "Explains how distributed sensory-motor traces can be flexibly retrieved and combined to form conceptual content; supports episodic recall and multimodal concept retrieval.",
            "evidence_source": "Neuroanatomical connectivity data, lesion studies, functional imaging meta-analyses",
            "experimental_paradigm": "Neuroimaging general semantic contrasts, lesion correlation with semantic deficits, anatomical mapping",
            "key_result": "Large heteromodal cortical regions (inferior parietal, lateral and ventral temporal cortex) sit at confluences of modal streams and show reliable semantic activation consistent with being convergence zones.",
            "supports_theory": true,
            "counter_evidence": "Precise loci and hierarchical relations among convergence zones are debated (e.g., role of temporal pole); some proponents of amodal hubs argue for distinct amodal representations rather than distributed convergence.",
            "citation": "Binder & Desai (2011)",
            "uuid": "e6907.4",
            "source_info": {
                "paper_title": "The neurobiology of semantic memory",
                "publication_date_yy_mm": "2011-11"
            }
        },
        {
            "name_short": "Hub-and-spoke",
            "name_full": "Hub-and-spoke model (Patterson, Rogers, Lambon Ralph et al.)",
            "brief_description": "Hybrid model positing modality-specific 'spokes' (sensory-motor representations) connected to an amodal central 'hub' (often proposed in anterior temporal lobe) that integrates information to form coherent concepts.",
            "citation_title": "Where do you know what you know? The representation of semantic knowledge in the human brain",
            "mention_or_use": "use",
            "theory_name": "Hub-and-Spoke Model",
            "theory_type": "hybrid: amodal hub + modal spokes",
            "theory_description": "Semantic memory arises from interaction between distributed modality-specific stores (spokes) and a transmodal amodal hub that abstracts and integrates across modalities to form generalized concepts.",
            "functional_claims": "Accounts for multimodal semantic deficits (e.g., semantic dementia) by hub damage, explains category-general impairment and supports cross-modal generalization.",
            "evidence_source": "Patient studies (semantic dementia), voxel-based morphometry, computational PDP models, neuroimaging",
            "experimental_paradigm": "Lesion/atrophy correlation with multimodal semantic performance, semantic tasks across modalities, rTMS to anterior temporal lobe",
            "key_result": "Semantic dementia patients with anterior temporal atrophy show multimodal semantic loss consistent with a hub role; however, meta-analysis shows multimodal convergence across broader temporal and inferior parietal regions, not limited to temporal pole.",
            "supports_theory": true,
            "counter_evidence": "Binder & Desai argue temporal pole is not sole hub — heteromodal convergence zones are distributed across lateral/ventral temporal and inferior parietal cortex; inferior parietal involvement is under-emphasized in some hub accounts.",
            "citation": "Binder & Desai (2011)",
            "uuid": "e6907.5",
            "source_info": {
                "paper_title": "The neurobiology of semantic memory",
                "publication_date_yy_mm": "2011-11"
            }
        },
        {
            "name_short": "Temporal pole hub hypothesis",
            "name_full": "Temporal pole as central amodal semantic hub (temporal pole hub hypothesis)",
            "brief_description": "Specific variant of hub hypothesis positing the anterior temporal pole (TP) as the primary amodal convergence hub for semantic knowledge.",
            "citation_title": "Where do you know what you know? The representation of semantic knowledge in the human brain",
            "mention_or_use": "mention",
            "theory_name": "Temporal Pole Hub Hypothesis",
            "theory_type": "amodal hub",
            "theory_description": "Proposes that anterior temporal pole integrates multimodal inputs and serves as the principal amodal repository for conceptual knowledge.",
            "functional_claims": "Predicts maximal semantic deficits when TP is damaged and anatomical locus of highest-order conceptual abstraction in TP.",
            "evidence_source": "Semantic dementia atrophy patterns, anatomical connectivity studies, lesion-behavior correlations",
            "experimental_paradigm": "Voxel-based morphometry in semantic dementia, lesion mapping, comparisons of atrophy-severity vs semantic impairment",
            "key_result": "Semantic dementia often shows severe TP atrophy, but Binder & Desai note broader ventral/lateral temporal involvement; correlations between atrophy and semantic deficits are often stronger in mid-temporal regions than TP.",
            "supports_theory": false,
            "counter_evidence": "Human temporal lobe organization differs from monkeys; visual cortex occupies less of human temporal lobe, and multimodal convergence likely extends across lateral/ventral temporal and inferior parietal areas; TP also heavily associated with emotion/social concepts rather than general hub function.",
            "citation": "Binder & Desai (2011)",
            "uuid": "e6907.6",
            "source_info": {
                "paper_title": "The neurobiology of semantic memory",
                "publication_date_yy_mm": "2011-11"
            }
        },
        {
            "name_short": "Embodied abstraction (Binder & Desai)",
            "name_full": "Embodied abstraction (progressive abstraction via heteromodal convergence)",
            "brief_description": "Authors' proposed synthesis in which conceptual representation arises from multiple hierarchical levels of abstraction grounded in modality-specific systems and embodied via heteromodal convergence zones that store schematic supramodal representations.",
            "citation_title": "here",
            "mention_or_use": "use",
            "theory_name": "Embodied Abstraction",
            "theory_type": "hybrid: embodied simulation + supramodal abstraction",
            "theory_description": "Conceptual knowledge consists of a continuum from detailed modality-specific simulations to schematic, highly abstract supramodal representations in heteromodal cortex; access to levels depends on familiarity, context, and task demands.",
            "functional_claims": "Explains variable involvement of modality-specific regions (depth of simulation), supports rapid language comprehension via schematic supramodal representations, accounts for multimodal deficits in heteromodal lesion patients and embodiment effects in modal areas.",
            "evidence_source": "fMRI meta-analysis (120 studies), patient studies (semantic dementia), TMS, EEG/MEG timing studies, anatomical connectivity evidence",
            "experimental_paradigm": "General semantic contrasts (words vs pseudowords, semantic vs phonological tasks), modality-specific language tasks, lesion correlations, TMS disruption",
            "key_result": "Meta-analysis shows reliable activation in heteromodal temporal and inferior parietal cortices for general semantic tasks, while modality-specific activations occur depending on semantic content and task — consistent with hierarchical embodied abstraction.",
            "supports_theory": true,
            "counter_evidence": "Precise nature and localization of supramodal representations (e.g., role of inferior parietal vs temporal lobe) require further specification and testing; necessity of modality-specific systems across tasks remains to be definitively proven.",
            "citation": "Binder & Desai (2011)",
            "uuid": "e6907.7",
            "source_info": {
                "paper_title": "The neurobiology of semantic memory",
                "publication_date_yy_mm": "2011-11"
            }
        },
        {
            "name_short": "Heteromodal / supramodal convergence zones",
            "name_full": "Heteromodal (supramodal) convergence zones in lateral/ventral temporal and inferior parietal cortex",
            "brief_description": "Functional concept that anterior/lateral temporal and inferior parietal cortices act as convergence zones that store abstracted, schematic representations across modalities supporting supramodal conceptual operations.",
            "citation_title": "here",
            "mention_or_use": "use",
            "theory_name": "Heteromodal (Supramodal) Convergence Zones",
            "theory_type": "supramodal representations / convergence network",
            "theory_description": "Regions at confluences of perceptual processing streams integrate modal inputs to form abstracted, modality-independent representations (supramodal) used for object recognition, category structure, language and scene construction.",
            "functional_claims": "Accounts for multimodal semantic retrieval, category-general deficits after heteromodal lesions, and rapid schematic conceptual access supporting language and prospection.",
            "evidence_source": "Meta-analysis of functional imaging (120 studies), lesion/semantic dementia data, anatomical connectivity studies",
            "experimental_paradigm": "General semantic contrasts, lesion-atrophy correlation with multimodal semantic impairment, fMRI activation likelihood estimation meta-analysis",
            "key_result": "Meta-analysis reveals consistent activation across left lateral/ventral temporal and inferior parietal cortex in semantic tasks, matching areas implicated in semantic dementia and vascular lesions producing semantic impairments.",
            "supports_theory": true,
            "counter_evidence": "Debate remains over whether a single central hub (e.g., temporal pole) or distributed heteromodal network best explains amodal aspects of semantics; precise content types represented in AG vs temporal lobe are under-specified.",
            "citation": "Binder & Desai (2011)",
            "uuid": "e6907.8",
            "source_info": {
                "paper_title": "The neurobiology of semantic memory",
                "publication_date_yy_mm": "2011-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Perceptual symbol systems",
            "rating": 2,
            "sanitized_title": "perceptual_symbol_systems"
        },
        {
            "paper_title": "Time-locked multiregional retroactivation: a systems-level proposal for the neural substrates of recall and recognition",
            "rating": 2,
            "sanitized_title": "timelocked_multiregional_retroactivation_a_systemslevel_proposal_for_the_neural_substrates_of_recall_and_recognition"
        },
        {
            "paper_title": "Where do you know what you know? The representation of semantic knowledge in the human brain",
            "rating": 2,
            "sanitized_title": "where_do_you_know_what_you_know_the_representation_of_semantic_knowledge_in_the_human_brain"
        },
        {
            "paper_title": "Where is the semantic system? A critical review and meta-analysis of 120 functional neuroimaging studies",
            "rating": 2,
            "sanitized_title": "where_is_the_semantic_system_a_critical_review_and_metaanalysis_of_120_functional_neuroimaging_studies"
        },
        {
            "paper_title": "A critical look at the embodied cognition hypothesis and a new proposal for grounding conceptual content",
            "rating": 2,
            "sanitized_title": "a_critical_look_at_the_embodied_cognition_hypothesis_and_a_new_proposal_for_grounding_conceptual_content"
        }
    ],
    "cost": 0.015378,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>The neurobiology of semantic memory</p>
<p>Jeffrey R Binder 
Department of Neurology
Medical College of Wisconsin
9200 W. Wisconsin Ave53226MilwaukeeWIUSA</p>
<p>Rutvik H Desai 
Department of Neurology
Medical College of Wisconsin
9200 W. Wisconsin Ave53226MilwaukeeWIUSA</p>
<p>The neurobiology of semantic memory
857B72073DEB54C2F45F7DFED871EA6210.1016/j.tics.2011.10.001
Semantic memory includes all acquired knowledge about the world and is the basis for nearly all human activity, yet its neurobiological foundation is only now becoming clear.Recent neuroimaging studies demonstrate two striking results: the participation of modality-specific sensory, motor, and emotion systems in language comprehension, and the existence of large brain regions that participate in comprehension tasks but are not modality-specific.These latter regions, which include the inferior parietal lobe and much of the temporal lobe, lie at convergences of multiple perceptual processing streams.These convergences enable increasingly abstract, supramodal representations of perceptual experience that support a variety of conceptual functions including object recognition, social cognition, language, and the remarkable human capacity to remember the past and imagine the future.The centrality of semantic memory in human behaviorHuman brains acquire and use concepts with such apparent ease that the neurobiology of this complex process seems almost to have been taken for granted.Although philosophers have puzzled for centuries over the nature of concepts [1], semantic memory (see Glossary) became a topic of formal study in cognitive science only relatively recently[2].This history is remarkable, given that semantic memory is one of our most defining human traits, encompassing all the declarative knowledge we acquire about the world.A short list of examples includes the names and physical attributes of all objects, the origin and history of objects, the names and attributes of actions, all abstract concepts and their names, knowledge of how people behave and why, opinions and beliefs, knowledge of historical events, knowledge of causes and effects, associations between concepts, categories and their bases, and on and on.Also remarkable is the variety of everyday cognitive activities that depend on this extensive store of knowledge.A common example is the recognition and use of objects, which has been the focus of much theoretical and empirical work on semantic memory[3][4][5][6][7].Recognition and use of objects, however, is a capacity shared by many non-human animals that interact with food sources, build simple structures, or use simple tools.More uniquely human is the ability to represent concepts in the form of language, which allows not only the spread of conceptual knowledge in an abstract symbolic form, but also a cognitive mechanism for the fluid and flexible manipulation, association, and combination of concepts[8,9].Thus humans use conceptual knowledge for much more than merely interacting with objects.All of human culture, including science, literature, social institutions, religion, and art, is constructed from conceptual knowledge.We do not reason, plan the future or remember the past without conceptual contentall of these activities depend on activation of concepts stored in semantic memory.Scientific study of human semantic memory processes has been limited in the past both by a relatively restricted focus on object knowledge and by an experimental tradition emphasizing stimulus-driven brain activity.Human</p>
<p>Glossary</p>
<p>Embodied cognition: in cognitive neuroscience, the general theory that perceptual and motor systems support conceptual knowledge, that is, that understanding or retrieving a concept involves some degree of sensory or motor simulation of the concept.A related term, situated cognition, refers to a more general perspective that emphasizes a central role of perception and action in cognition, rather than memory and memory retrieval.Heteromodal cortex: cortex that receives highly processed, multimodal input not dominated by any single modality; also called supramodal, multimodal, or polymodal.Modality-specific representations: information pertaining to a specific modality of experience and processed within the corresponding sensory, motor, or affective system.Modality-specific representations can include primary perceptual or motor information, as well as more complex or abstract representations that are nonetheless modal (e.g., extrastriate visual cortex, parabelt auditory cortex).Modal specificity refers to the representational format of the information.For example, knowledge about the sound a piano makes is modally auditory, whereas knowledge about the appearance of a piano is modally visual, and knowledge of the feeling of playing a piano is modally kinesthetic.Modal representations reflect relevant perceptual dimensions of the input, that is, they are analogs of the input.An auditory representation, for example, captures the spectrotemporal form and loudness of an input, whereas a visual representation codes visual dimensions such as visual form, size and color.Semantic memory: an individual's store of knowledge about the world.The content of semantic memory is abstracted from actual experience and is therefore said to be conceptual, that is, generalized and without reference to any specific experience.Memory for specific experiences is called episodic memory, although the content of episodic memory depends heavily on retrieval of conceptual knowledge.Remembering, for example, that one had coffee and eggs for breakfast requires retrieval of the concepts of coffee, eggs and breakfast.Episodic memory might be more properly seen as a particular kind of knowledge manipulation that creates spatial-temporal configurations of object and event concepts.Simulation: in cognitive neuroscience, the partial re-creation of a perceptual/ motor/affective experience or concept through partial reactivation of the neural ensembles originally activated by the experience or concept.Explicit mental imagery may require relatively detailed simulation of a particular experience, whereas tasks such as word comprehension may require only schematic simulations.Supramodal representations: information that does not pertain to a single modality of experience.Supramodal representations store information about cross-modal conjunctions, such as a particular combination of auditory and visual object attributes.Their existence is sometimes disputed, yet they provide a simple mechanism for a wide range of inferential capacities, such as knowing the visual appearance of a piano given only its sound and knowing about the conceptual similarity structures that define categories.Supramodal representations may also enable the rapid, schematic retrieval of semantic knowledge that characterizes natural language.Corresponding author: Binder, J.R. (jbinder@mcw.edu).</p>
<p>brains are occupied much of the day with reasoning, planning, and remembering.This highly conceptual activity need not be triggered by stimuli in the immediate environmentall of it can be done, and usually is, in the privacy of one's own mind.Together with recent insights gained from studies of patients with semantic memory loss, functional imaging data are rapidly converging on a new anatomical model of the brain systems involved in these processes.Given the centrality of semantic memory to human behavior and human culture, the significance of these discoveries can hardly be overstated.</p>
<p>In this article we propose a large-scale neural model of semantic processing that synthesizes multiple lines of empirical and theoretical work.Our core argument is that semantic memory consists of both modality-specific and supramodal representations, the latter supported by the gradual convergence of information throughout large regions of temporal and inferior parietal association cortex.These supramodal convergences support a variety of conceptual functions including object recognition, social cognition, language and the uniquely human capacity to construct mental simulations of the past and future.</p>
<p>Central issues in semantic processing</p>
<p>A major issue in the study of semantic memory concerns the nature of concept representations.Efforts in the last century to develop artificial intelligence focused on knowledge representation in the form of abstract symbols [10].This approach led to powerful new techniques for information representation and manipulation (e.g., semantic nets, feature lists, ontologies, schemata).Recent advances in this area used machine learning techniques together with massive verbal inputs to create a highly flexible, probabilistic symbolic network that can respond to general questions in a natural language format [11].Scientists interested in human brains, on the other hand, have long assumed that the brain represents concepts at least partly in the form of sensory and motor experiences.Nineteenthcentury neurologists, for example, pictured a widely distributed 'concept field' in the brain where visual, auditory, tactile, and motor 'images' associated with a concept were activated in the process of word comprehension [12,13].A major advantage of such a theory over a purely symbolic representation is that it provides a parsimonious and biologically plausible mechanism for conceptual learning.Over the course of many similar experiences with entities from the same category, an idealized sensory or motor representation of the entity develops by generalization across unique exemplars, and reactivation or 'simulation' of these modality-specific representations forms the basis of concept retrieval [14].</p>
<p>In addition to these issues concerning representation of information, questions arise about the mechanisms that control semantic information retrieval.Clearly not all knowledge associated with a concept is relevant in all contexts, thus mechanisms are needed for selecting or attending to task-relevant information [15,16].Some conceptual tasks also place strong demands on creativity, a term we use here to refer to flexible problem solving in the absence of strong constraining cues.Creative invention through technological innovation, art, and 'brainstorming' are uniquely human endeavors that require fluent conceptual retrieval and flexible association of ideas.Even everyday conversation requires a logical but relatively unconstrained flow of ideas, in which one topic leads to another through a series of associated concepts.This type of flexible association and combining of concepts, though ubiquitous in everyday life, has largely been overlooked in functional imaging studies, which tend to focus on highly constrained retrieval tasks involving recognition of words and objects.</p>
<p>Evidence for modality-specific simulation in comprehension</p>
<p>The idea that sensory and motor experiences form the basis of conceptual knowledge has a long history in philosophy, psychology, and neuroscience [1,3,12,13].In recent years, this proposal has gained new steam under the rubric of 'embodied' or 'situated' cognition, supported by numerous neuroimaging and behavioral studies.Some of the imaging studies showing modality-specific activations during language processing are summarized in Figure 1.A number of these address action concepts and show that processing action-related language activates brain regions involved in executing and planning actions.Motion, sound, color, olfaction, and gustatory concept processing have also been addressed, and also tend to show activation in or near regions that process these perceptual modalities (see legend, Figure 1).</p>
<p>Challenges to the embodiment view have also arisen.One objection is that activations observed in imaging experiments could be epiphenomenal and not causally related to comprehension [17].This hypothesis has been tested in patients with various forms of motor system damage.Initial results indicate a selective impairment for comprehending action verbs in patients with Parkinson's disease [18], progressive supranuclear palsy [19], apraxia [20], and motor neuron disease [21,22].Several studies employing transcranial magnetic stimulation to induce transient lesions in the primary motor cortex or inferior parietal lobe provide converging results [23][24][25][26][27][28].Thus, involvement of the motor system during action word processing contributes to comprehension and is not a mere by-product.A related argument is that the activations represent post-comprehension imagery.In studies using imaging methods with high temporal resolution, however, the activation of motor regions during action word processing appear to be rapid, approximately 150-200 ms from word onset [29][30][31][32], suggesting that it is part of early semantic access rather than a result of post-comprehension processes.These converging results provide compelling evidence that sensory-motor cortices play an essential role in conceptual representation.</p>
<p>Although it is often overlooked in reviews of embodied cognition, emotion is as much a modality of experience as sensory and motor processing [33].Words and concepts vary in the magnitude and specific type of emotional response they evoke, and these emotional responses are a large part of the meaning of many concepts.Purple dots in Figure 1 represent activation peaks from 14 imaging studies that examined activation as a function of the emotional content of words or phrases.There is a clear</p>
<p>Review</p>
<p>Trends in Cognitive Sciences November 2011, Vol.15,No. 11 preponderance of activations in the temporal pole (13 studies) and ventromedial prefrontal cortex (10 studies), both of which play a central role in emotion [34,35].Involvement of the temporal pole in high-level representation of emotion may also explain activation in this region associated with social concepts [36,37], which tend to have strong emotional valence.</p>
<p>Evidence for high level convergence zones</p>
<p>In addition to modality-specific simulations, we propose that the brain uses abstract, supramodal representations during conceptual tasks.One compelling argument for this view is that the human brain possesses large areas of cortex that are situated between modal sensory-motor systems and thus appear to function as information 'convergence zones' [14].These heteromodal areas include the inferior parietal cortex (angular and supramarginal gyri), large parts of the middle and inferior temporal gyri, and anterior portions of the fusiform gyrus [38].These areas have expanded disproportionately in the human brain relative to the monkey brain, 'taking over' much of the temporal lobe from the visual system [39].Advocates of a strictly embodied theory of conceptual processing have largely ignored these brain regions, yet they occupy a substantial proportion of the posterior cortex in humans.</p>
<p>A second body of evidence comes from patients with damage in the inferior and lateral temporal lobe, particularly patients with semantic dementia, a syndrome characterized by progressive temporal lobe atrophy and multimodal loss of semantic memory [40,41].These patients are unable to retrieve names of objects, categorize objects or judge their relative similarity, identify the correct color or sound of objects, or retrieve knowledge about actions associated with objects [42][43][44][45].Critically, the deficits do not appear to be category-specific [46] further evidence that the semantic impairment does not involve strongly modal representations.</p>
<p>A third large body of evidence comes from functional imaging studies that target general semantic rather than modality-specific semantic processes.For example, many imaging experiments have contrasted words against pseudowords, related against unrelated word pairs, meaningful against nonsensical sentences, and sentences against random word strings.In another type of general semantic contrast, a semantic task (e.g., a semantic decision) is contrasted with a phonological control task (e.g., rhyme decision).What is important to understand about all of these 'general' contrasts is that although they elicit differences in the degree of access to semantic information, they include no manipulation of modality-specific information.In the absence of systematic biases affecting stimulus selection, the activations resulting from these contrasts are unlikely to reflect modality-specific representations.</p>
<p>A quantitative meta-analysis of 120 of these studies was recently performed [47].Studies were included only if they satisfied strict criteria for a semantic contrast.Studies were excluded if the stimuli in the contrasting conditions
TRENDS in Cognitive Sciences L R R L Figure 1.
Modality-specific activation peaks during language comprehension.This figure displays sites of peak activation from 38 imaging studies that examined modalityspecific knowledge processing during language comprehension tasks.Peaks were mapped to a common spatial coordinate system and then to a representative brain surface.Action knowledge peaks (red) cluster in primary and secondary sensorimotor regions in the posterior frontal and anterior parietal lobes.Motion peaks (green) cluster in posterior inferolateral temporal regions near the visual motion processing pathway.Note that motion concepts, especially when elicited by action verbs, are difficult to distinguish from action concepts.Peaks near motion processing area MT/MST in four of the studies of action language are interpreted here as reflecting motion knowledge.Auditory peaks (yellow) occur in superior temporal and temporoparietal regions adjacent to auditory association cortex.Color peaks (blue) cluster in the fusiform gyrus just anterior to color-selective regions of extrastriate visual cortex.Olfactory peaks (pink) observed in one study were in olfactory areas (prepiriform cortex and amygdala).Gustatory peaks (orange) were observed in one study in the anterior orbital frontal cortex.Emotion peaks (purple) involve primarily anterior temporal, medial and orbital prefrontal, and posterior cingulate regions.Details regarding study selection and a list of the included studies are provided in supplementary material online.</p>
<p>were not matched on orthographic or phonological properties, or if the activations could be explained by differences in attention or working memory demands.Reliability of the activation sites reported in the studies was analyzed using a volume-based technique called activation likelihood estimation [48].</p>
<p>The results showed remarkable consistency across studies, with reliable activation throughout the left temporal and parietal heteromodal cortex (Figure 2).These locations are consistent with the location of pathological changes in semantic dementia, as well as with temporal and parietal vascular lesions causing semantic impairments [49][50][51][52][53].Other consistent sites of activation included the dorsomedial prefrontal cortex (superior frontal gyrus), ventromedial prefrontal cortex, inferior frontal gyrus, and the posterior cingulate gyrus and precuneus.The results offer compelling evidence for high-level convergence zones in the inferior parietal, lateral temporal, and ventral temporal cortex.These regions are far from primary sensory and motor cortices and appear to be involved in processing general rather than modality-specific semantic information.</p>
<p>Embodied abstraction in conceptual representation</p>
<p>Figure 3 illustrates several prominent theories that differ in the proposed level of separation between conceptual and perceptual representations.Models based on disembodied, symbolic conceptual representations [9,10] are often criticized on the grounds that such symbols are ultimately devoid of content [54].From an empirical standpoint, the extensive evidence for involvement of modality-specific sensory, action, and emotion systems during language comprehension is also inconsistent with such a model.Theories of perception and cognition vary in terms of the degree of separation between these processes.Disembodied models propose a complete separation, in which conceptual processing is based entirely on amodal, symbolic representations [9,10,17].Other theories propose that conceptual and perceptual representations are distinct and separate but interact closely so that amodal symbols can derive content from perceptual knowledge [7,14].In contrast to both of these theories, strong embodiment models posit that perceptual and conceptual processes are carried out by a single system [55,56].In contrast to all of these theories, the neuroanatomical evidence for multiple modality-specific systems gradually converging on a common semantic network suggests a process of 'embodied abstraction,' in which conceptual representation is embodied in multiple levels of abstraction from sensory, motor and affective input.The extent to which modalityspecific perceptual representations are activated during semantic tasks varies with concept familiarity, demand for perceptual information and degree of contextual support (see Box 1).</p>
<p>At the other end of the spectrum are 'strong embodiment' models in which perceptual and conceptual processes are carried out by the same (perceptual) system [55,56].These models are inconsistent with the evidence for modality-independent semantic networks reviewed above.Furthermore, conceptual deficits in patients with sensory-motor impairments, when present, tend to be subtle rather than catastrophic.In a recent study of aphasic patients [57], lesions in both sensorymotor and temporal regions were correlated with impairment in a picture-word matching task involving action words.This evidence is incompatible with a strong version of the embodiment account, in which sensorymotor regions are necessary and sufficient for conceptual representation.</p>
<p>Other theories propose that amodal representations derive their content from close interactions with modal perceptual systems [7,14].The purpose of amodal representations in these latter models is to bind and efficiently access information across modalities rather than to represent the information itself [58].The need for distinct amodal representations in such a model has been sharply questioned, however, as multimodal perceptual representations could fulfill the same role [55,56].</p>
<p>We suggest that the current evidence is most compatible with a view we term 'embodied abstraction,' briefly sketched here (see [59,60] for similar proposals).In this view, conceptual representation consists of multiple levels of abstraction from sensory, motor, and affective input.All levels are not automatically accessed or activated under all conditions.Rather, this access is subject to factors such as context, frequency, familiarity, and task demands.The top level contains schematic representations that are highly abstracted from detailed representations in the primary perceptual-motor systems.These representations are 'fleshed out' to varying degrees by sensory-motor-affective contributions in accordance with task demands.In highly familiar contexts, the schematic representations are sufficient for adequate and rapid processing.In novel contexts or when the task requires deeper processing, sensorymotor-affective systems make a greater contribution in fleshing out the representations (Box 1).</p>
<p>A neuroanatomical model of semantic processing Figure 4 outlines a neuroanatomical model of semantic memory consistent with a broad range of available data.Modality-specific representations (yellow areas in Figure 4), located near corresponding sensory, motor, and emotion networks, develop as a result of experience with entities and events in the external and internal Box 1. Variability in sensory-motor embodiment Modality-specific simulation provides a plausible mechanism for retrieval of concrete object concepts, but difficulties arise in considering abstract concepts.What sensory, motor, or emotional experience is reactivated in comprehending words such as 'abstract', 'concept', 'modality', and 'theory'?Another potential difficulty arises from the speed of spoken language, which is easily understood at rates of 3-4 words per second [82].It is far from clear that an extended sensory, motor, or emotional simulation of each word is possible at such speeds, or even necessary.Thus there is a strong rationale for considering theories that allow both sensorymotor-emotional simulation and manipulation of more abstract representations as a basis for conceptual processing, depending on the exigencies of a given task [59,60].At one end of this continuum are tasks that encourage simulation by explicitly requiring mental imagery of an object or event.At the other end are tasks requiring comprehension of rapidly presented, abstract verbal materials that evoke little or no mental simulation.Imagine, for example, that you are deciding which of two cars to buy.This task is likely to engage extended mental simulation of the sensory and motor experiences of examining and test-driving each car.In contrast, imagine hearing someone say, ''I don't really have any need or money for a car right now, so it's low on my priority list''.This statement is perfectly understandable and full of meaning, but how extensively must the sensory attributes of 'car' be simulated for full comprehension to occur, or simulation of words such as 'need', 'now', 'low', and 'priority'?Another factor that likely modulates 'depth' of simulation during language comprehension is the familiarity of an expression.Imagine that instead of the statement about a car, you hear, ''I don't really have any need or money for a llama right now, so it's low on my priority list''.Comprehending the word 'llama' is likely to require an extended visual simulation, and the unfamiliarity of the statement itself is likely to elicit a range of simulations involving possible uses for a llama.In general, the involvement of sensorymotor systems in language comprehension seems to change through a gradual abstraction process whereby relatively detailed simulations are needed for unfamiliar or infrequent concepts and these simulations become less detailed as familiarity and contextual support increases [83].A model of semantic processing in the human brain is shown, based on a broad range of pathological and functional neuroimaging data.Modality-specific sensory, action, and emotion systems (yellow regions) provide experiential input to high-level temporal and inferior parietal convergence zones (red regions) that store increasingly abstract representations of entity and event knowledge.Dorsomedial and inferior prefrontal cortices (blue regions) control the goal-directed activation and selection of the information stored in temporoparietal cortices.The posterior cingulate gyrus and adjacent precuneus (green region) may function as an interface between the semantic network and the hippocampal memory system, helping to encode meaningful events into episodic memory.A similar, somewhat less extensive semantic network exists in the right hemisphere, although the functional and anatomical differences between left and right brain semantic systems are still unclear.</p>
<p>Action</p>
<p>Sound</p>
<p>Visual motion</p>
<p>Color Emotion</p>
<p>TRENDS in Cognitive Sciences</p>
<p>environment.These representations code recurring spatial and temporal configurations of lower-level modal representations.Although depicted as somewhat modular, we view these systems as an interactive continuum of hierarchically ordered neural ensembles, supporting progressively more combinatorial and idealized representations.These systems correspond to Damasio's local convergence zones [14] and to Barsalou's unimodal perceptual symbol systems [55].In addition to bottom-up input in their associated modality, they receive a range of top-down input from other modal systems and from attention.They are modal in the sense that the information they represent is an analog of (i.e., isomorphic with) their bottom-up input [55].</p>
<p>These modal convergence zones then converge with each other in higher-level cortices located in the inferior parietal lobe and much of the ventral and lateral temporal lobe (red areas in Figure 4).One function of these high-level convergences is to bind representations from two or more modalities, such as the sound and visual appearance of an animal, or the visual representation and action knowledge associated with a hand tool [7,12,14,55].Such supramodal representations capture similarity structures that define categories, such as the collection of attributes that place 'pear' and 'light bulb' in different categories despite a superficial similarity of appearance, and 'pear' and 'pineapple' in the same category despite very different appearances [58].More generally, supramodal representations allow the efficient manipulation of abstract, schematic conceptual knowledge that characterizes natural language, social cognition, and other forms of highly creative thinking [59,60].</p>
<p>These modal and supramodal convergence zones store the actual content of semantic knowledge, whereas the prefrontal regions colored blue in Figure 4 control topdown activation and selection of the content in posterior stores (Box 2).The posterior cingulate gyrus and adjacent precuneus (green area in Figure 4) consistently show semantic effects in imaging experiments and have also been implicated in a wide variety of other processes, as discussed below.Given the strong reciprocal connections this region has with the hippocampal formation, it likely plays a role in encoding semantically and emotionally meaningful events in episodic memory [61], though its precise function remains a topic for future research.</p>
<p>Our view of semantic processing in posterior cortical regions is similar to the 'hub and spoke' model of Patterson, Rogers, Lambon Ralph, and colleagues [7,46,58] and to the convergence zone model of Damasio [14], but differs in two important respects.First, we do not believe the data support a central role for the temporal pole as the highest level in the convergence zone hierarchy (Box 3).As shown in Figures 2 and 4, multimodal convergence of information processing streams occurs throughout much of the lateral and ventral temporal cortex, as well as in the inferior parietal lobe, whereas the temporal pole receives strong affective input from the ventral frontal lobe and amygdala and is better characterized as a modal region for processing emotion and social concepts [34,36,37].Second, proponents of the hub and spoke model explicitly deny a role for the inferior parietal lobe in representation of semantic information [62].We believe that the anatomical and functional imaging evidence for semantic memory storage in the inferior parietal lobe is difficult to deny, even though the nature of the information represented in this region is still unclear (Box 4).</p>
<p>Social cognition, declarative memory retrieval, prospection, and the default mode</p>
<p>The network of brain regions we associate here with semantic processing has also been linked with more specific functions.Nearly all parts of the network have been implicated in aspects of social cognition, including theory-of-mind (processing of knowledge pertaining to mental states of other people), emotion processing, and knowledge of social concepts [36,37,[63][64][65][66][67].Much of the network has been implicated in retrieval of episodic and particularly autobiographical memories [68,69], leading to the hypothesis that these regions function to retrieve event memories through a process of 'scene construction'</p>
<p>Box 2. The role of the prefrontal cortex</p>
<p>Imaging studies identify reliable semantic processing effects in the left inferior frontal gyrus (IFG) and in a larger dorsomedial prefrontal region extending from the posterior middle frontal gyrus laterally to the superior frontal gyrus (SFG) medially (see blue areas in Figure 4).Numerous experiments indicate that the IFG is engaged when tasks require effortful selection of semantic information, as when many alternative responses are possible or lexical ambiguity gives rise to competing semantic representations [15,16,93,94].Consistent with prior reviews [95,96], the meta-analytical data presented here show more reliable activation of anterior and ventral aspects of the IFG (pars orbitalis and triangularis) in semantic studies compared to posterior IFG.</p>
<p>The role of dorsomedial prefrontal cortex in semantic processing has been much less studied, although this region has been a focus of attention in research on emotion processes, social cognition, selfreferential processing and the default mode [67,73,74,[97][98][99].Ischemic lesions to the left SFG cause transcortical motor aphasia, a syndrome characterized by sparse speech output [100,101].There is typically a striking disparity between cued and uncued speech production, in that patients can repeat words and name objects relatively normally, but are unable to generate lists of words within a category or invent non-formulaic responses in conversation.That is, patients perform well when a simple response is fully specified (a word to be repeated or object to be named) but poorly when a plan must be created for generating a response [102].This pattern suggests a specific deficit of self-initiated, self-guided retrieval of semantic information.The SFG lies between ventromedial prefrontal areas (rostral cingulate gyrus and medial orbitofrontal cortex) involved in emotion and reward and lateral prefrontal networks involved in cognitive control, and may act as an intermediary link between these processing systems.We propose that a key role of this region in semantic processing is to translate affective drive states into a coordinated plan for knowledge retrieval, that is, a plan for topdown activation of semantic fields relevant to the problem at hand.Damage to this region causes no loss of stored knowledge per se, but impairs the ability to access this knowledge for creative problem solving.As noted earlier, generating creative solutions in open-ended situationsincluding interpersonal conflicts, mechanical problems, future plans, even trivial conversational exchangesis a relatively common task in daily life and also appears to be a large component of the conscious 'resting' state.[70].The same scene construction processes have been proposed as the basis for 'prospection,' i.e., imagining future scenarios for the purpose of planning and goal attainment [71,72].Finally, the association of these regions with autobiographical, 'self-projection,' and selfreferential processes has led to suggestions that they are specifically involved in processing self knowledge [73,74].Several recent reviews and meta-analyses attest to the high degree of neuroanatomical overlap between the networks supporting these purportedly distinct processes [67,[75][76][77].</p>
<p>Given this overlap, it is logical to ask whether there is a process common to all of these cognitive functions.A model based on self-referential processing cannot easily explain activation of the same regions by theory-of-mind tasks, which by definition emphasize knowledge pertaining to others.The general process of mental scene construction is common to episodic memory retrieval, prospection, and many theory-of-mind tasks, but this model cannot explain the consistent activation of these regions by single word comprehension tasks, as shown above in Figure 2. Indeed, the contrasts analyzed in Figure 2 focused on general semantic knowledge (especially knowledge about object concepts) and did not emphasize episodic, autobiographical, social, emotional, self, or any other specific knowledge domain.</p>
<p>One process shared across semantic, social cognition, episodic memory, scene construction, and self-knowledge tasks is the retrieval of conceptual knowledge.The scene construction posited to underlie episodic memory retrieval and prospection refers to a partial, internal simulation of prior experience.But the construction of a scene requires content.The content of such a simulation is conceptual knowledge about particular entities, events, and relationships.The variety of this content is impressive, encompassing object, action, social, self, spatial, and</p>
<p>Box 4. The role of the inferior parietal cortex</p>
<p>The inferior parietal cortex lies at a confluence of visual, spatial, somatosensory and auditory processing streams.Human functional imaging studies implicate this region specifically in representational aspects of semantic memory.For example, the angular gyrus (AG) responds more strongly to words than to matched pseudowords [47], more to high-frequency than low-frequency words [103], more to concrete than abstract words [104] and more to meaningful than meaningless sentences [105].Thus the level of AG activation seems to reflect the amount of semantic information that can be successfully retrieved from a given input.</p>
<p>Whether the parietal and temporal convergence zones play distinct roles in representing meaning remains a topic for future research, although available evidence offers some intriguing clues.One clue comes from differences in the location and anatomical connectivity of these regions, which to some degree parallel well-established differences between the ventral and dorsal visual networks.The temporal lobe convergence zone receives heavy input from the ventral visual object identification network and from the auditory 'what' pathway [106], suggesting that its main role in semantic memory concerns conceptual representation of concrete objects.In contrast, the AG is bounded by dorsal attention networks that play a central role in spatial cognition, anterior parietal regions concerned with representation of action and posterior temporal regions supporting movement perception [107].This suggests that the AG may play a unique role in representation of event concepts.Semantic memory research has focused overwhelmingly on knowledge about static concrete entities (i.e., objects, object features, categories), yet much of human knowledge concerns events in which entities interact in space and time.For example, the concept 'birthday party' does not refer to a static entity but is instead defined by a configuration of entities (people, cake, candles, presents) and a series of events unfolding in time and space (lighting candles, singing, eating, opening presents).These spatial and temporal configurations define 'birthday party' and distinguish it from similar concepts like 'picnic' or 'office party' in the same way that sets of sensory and motor features distinguish one object from another.</p>
<p>This hypothesis is consistent with recent evidence showing involvement of the AG in retrieval of episodic memories and in understanding theory-of-mind stories.The content of both episodic memory and socially complex stories consists largely of events.Several other studies show specific involvement of the AG in processing temporal and spatial information in stories [108,109].</p>
<p>Box 3. The role of the temporal poles</p>
<p>Studies of patients with semantic dementia have drawn attention to the temporal pole (TP) and the proposal that it functions as a central 'hub' housing amodal semantic representations [7].Emphasis on the TP is also consistent with a longstanding view of this region as the zenith of a caudal-to-rostral convergence of information in the temporal lobe [14].There are, however, several reasons to question claims that the TP is the sole or principal focus of high-level information convergence.The concept of the TP as an anatomical convergence zone is based mainly on two sources of information: the caudal-rostral progression of information processing in the primate ventral visual system [84] and the convergence of massive multimodal inputs on anterior medial temporal regions, particularly perirhinal cortex [85,86].Although a caudal-rostral hierarchy of information complexity in the primate visual system is undeniable, the proportion of the temporal lobe devoted to unimodal visual processing is considerably less in the human than in the monkey brain [39].In contrast to the monkey visual system, which occupies ventral and lateral temporal cortex all the way to the temporal pole, the human visual system is largely confined to occipital cortex and posterior ventral temporal lobe.Apart from modal auditory cortex in the superior temporal gyrus, remaining regions in the human temporal lobe are not clearly modality-specific, therefore multimodal convergences are likely to occur along the entire length of the temporal lobe.The convergence of inputs on the anterior medial temporal lobe, though sometimes construed as serving a conceptual function [14], are more likely to represent input to the hippocampal system for the purpose of episodic memory encoding [87].</p>
<p>Pathological evidence regarding the TP is also somewhat ambiguous.Although atrophy in semantic dementia is typically most severe in the TP, the total area involved is usually much larger, including most of the ventral temporal cortex [88][89][90].Regions showing the strongest correlation between atrophy and semantic deficits are actually closer to the mid-temporal lobe than the TP [90,91].Finally, the TP, ventromedial prefrontal cortex and lateral orbitofrontal cortex constitute a tightly interconnected network [34,92] implicated in processing modality-specific emotional aspects of word meaning (see Figure 1).Considered together, these data suggest that the most anterior parts of the temporal lobe, including the TP and anteromedial temporal regions, are unlikely to be a critical hub for retrieval of multimodal semantic knowledge.</p>
<p>Review</p>
<p>Trends in Cognitive Sciences November 2011, Vol.15,No. 11 other domains, yet these types of content all share a common basis in sensory-motor experience, learning through generalization across individual exemplars, and progressive abstraction from perceptual detail.We propose that the essential function of the high-level convergence zone network is to store and retrieve this conceptual content, which is employed over a variety of domain-specific tasks.</p>
<p>This network of high-level convergence zones also overlaps extensively with the 'default mode network' of regions that show higher levels of activity during passive and 'resting' states than during attentional tasks [47,[74][75][76]78].The similarity between all of these networks lends strong support to proposals that 'resting' is a cognitively complex condition characterized by episodic and autobiographical memory retrieval, manipulation of semantic and social knowledge, creativity, problem solving, prospection, and planning [75,[78][79][80][81]. Several authors have emphasized the profound adaptive value of these processes, which not only enable the attainment of personal goals but are also responsible for all of human cultural and technological development [78,80,81].</p>
<p>Concluding remarks</p>
<p>This review proposes a large-scale brain model of semantic memory organization in the human brain based on synthesis of a large body of empirical imaging data with a modified embodiment theory of knowledge representation.In contrast to strong versions of embodiment theory, the data show that large areas of heteromodal cortex participate in semantic memory processes.The multimodal convergence of information toward these brain areas enables progressive abstraction of conceptual knowledge from perceptual experience, enabling rapid and flexible manipulation of this knowledge for language and other highly creative tasks.In contrast to models that identify the temporal pole as the principal site of this information convergence, the evidence suggests involvement of heteromodal regions throughout the temporal and the inferior parietal lobes.We hope this anatomical-functional model provides a useful framework for several future lines of research (Box 5).</p>
<p>Box 5. Questions for future research More data are needed to clarify the location of modality-specific conceptual networks.As shown in Figure 1, most of the work to date has focused on knowledge related to action, visual motion and emotion, with very little data on auditory, olfactory and gustatory concepts.Within the visual domain, more work is needed on the representation of specific types of information such as color, visual form, size and spatial knowledge.We propose here that the degree of activation in modality-specific perceptual systems during conceptual tasks varies with context.This more nuanced version of embodiment theory should be tested in future studies by controlled manipulation of variables such as stimulus familiarity, demands on speed and depth of processing requirements.The necessity of modality-specific systems for conceptual processing is a critical issue.Studies of patient groups with different types and degrees of modality-specific impairments, combined with TMS studies targeting primary and secondary sensory-motor cortices, with varying task demands, are needed to answer this question definitively.</p>
<p>Entities and events constitute two ontologically distinct categories of knowledge with distinct types of attributes, yet there has been little research to date exploring the neural correlates of this distinction.Our hypothesis that the temporal lobe is involved mainly in representation of object knowledge and the inferior parietal lobe in representation of event knowledge is both defeasible and testable.The role of posterior medial cortex (posterior cingulate gyrus and precuneus) in semantic processing remains unclear.Unraveling this mystery will likely require a combination of functional imaging, focal brain lesion, and nonhuman primate studies.The semantic memory network supports a variety of knowledge domains, including knowledge of self, theory of mind, social concepts, episodic and autobiographical memories, and knowledge of future hypothetical scenarios.Work to date suggests a large degree of overlap in the neural systems supporting these categories of knowledge, thus a major question for future research is whether these types of knowledge retrieval tasks uniquely or preferentially engage distinct components of the semantic network.</p>
<p>Figure 2 .Figure 3 .
23
Figure2.Meta-analysis of functional imaging studies of semantic processing.This figure displays brain regions reliably activated by general semantic processes, based on reported activation peaks from 120 independent functional imaging studies (p &lt;.05 corrected for family-wise error).The analysis method assigns a significance value to the degree of spatial overlap between the reported activation coordinates in a standard volume space.The figure shows selected sagittal sections in the left hemisphere; right hemisphere activations occurred in similar locations but were less extensive.AG = angular gyrus, FG = fusiform gyrus, IFG = inferior frontal gyrus, MTG = middle temporal gyrus, PC = posterior cingulate gyrus, SFG = superior frontal gyrus, SMG = supramarginal gyrus, VMPFC = ventromedial prefrontal cortex.Green lines indicate the Y and Z axes in standard space.Adapted from[47].</p>
<p>Figure 4 .
4
Figure 4.A neuroanatomical model of semantic processing.A model of semantic processing in the human brain is shown, based on a broad range of pathological and functional neuroimaging data.Modality-specific sensory, action, and emotion systems (yellow regions) provide experiential input to high-level temporal and inferior parietal convergence zones (red regions) that store increasingly abstract representations of entity and event knowledge.Dorsomedial and inferior prefrontal cortices (blue regions) control the goal-directed activation and selection of the information stored in temporoparietal cortices.The posterior cingulate gyrus and adjacent precuneus (green region) may function as an interface between the semantic network and the hippocampal memory system, helping to encode meaningful events into episodic memory.A similar, somewhat less extensive semantic network exists in the right hemisphere, although the functional and anatomical differences between left and right brain semantic systems are still unclear.</p>
<p>Trends in Cognitive Sciences November 2011, Vol. 15, No. 11
AcknowledgementsSupported by NIH grants R01 NS33576 and R01 DC010783.Thanks to Lisa Conant, Will Graves, Colin Humphries, Tim Rogers, and Mark Seidenberg for helpful discussions.Appendix A. Supplementary data Supplementary data associated with this article can be found, in the online version, at doi:10.1016/j.tics.2011.10.001.
An essay concerning human understanding. J Locke, 1690/1959Dover</p>
<p>Episodic and semantic memory. E Tulving, Organization of Memory. E Tulving, W Donaldson, Academic Press1972</p>
<p>Components of the mental lexicon. D A Allport, E Funnell, Philos. Trans. R. Soc. Lond. B. 2951981</p>
<p>Situated simulation in the human conceptual system. L W Barsalou, Lang. Cogn. Process. 182003</p>
<p>Neuropsychological and neuroimaging perspectives on conceptual knowledge: an introduction. A Martin, A Caramazza, Cogn. Neuropsychol. 202003</p>
<p>Neural systems behind word and concept retrieval. H Damasio, Cognition. 922004</p>
<p>Where do you know what you know? The representation of semantic knowledge in the human brain. K Patterson, Nat. Rev. Neurosci. 82007</p>
<p>. L S Vygotsky, Thought and language. 1962Wiley</p>
<p>Computation and cognition: toward a foundation for cognitive science. J Fodor, D , Z.W. 311975. 1984. 2010AI MagBuilding Watson: an overview of the DeepQA project</p>
<p>. C Wernicke, Der aphasische Symptomenkomplex, Cohn &amp; Weigert1874</p>
<p>On aphasia: a critical study. S Freud, 1891/1953International Universities Press</p>
<p>Time-locked multiregional retroactivation: a systems-level proposal for the neural substrates of recall and recognition. A R Damasio, Cognition. 331989</p>
<p>Role of left inferior prefrontal cortex in retrieval of semantic knowledge: a reevaluation. S L Thompson-Schill, Proc. Natl. Acad. Sci. U.S.A. 941997</p>
<p>Recovering meaning: left prefrontal cortex guides semantic retrieval. A D Wagner, Neuron. 312001</p>
<p>A critical look at the embodied cognition hypothesis and a new proposal for grounding conceptual content. B Z Mahon, A Caramazza, J. Physiol. (Paris). 1022008</p>
<p>Word processing in Parkinson's disease is impaired for action verbs but not for concrete nouns. V Boulenger, Neuropsychologia. 462008</p>
<p>Clinical, imaging and pathological correlates of a hereditary deficit in verb and action processing. T H Bak, Brain. 1292006</p>
<p>Knowledge of object manipulation and object function: dissociations in apraxic and nonapraxic subjects. L J Buxbaum, E M Saffran, Brain Lang. 822002</p>
<p>The effects of motor neurone disease on language: further evidence. T H Bak, J R Hodges, Brain Lang. 892004</p>
<p>Impaired action knowledge in amyotrophic lateral sclerosis. M Grossman, Neurology. 712008</p>
<p>All talk and no action: a transcranial magnetic stimulation study of motor cortex activation during action word production. M Oliveri, J. Cogn. Neurosci. 162004</p>
<p>Listening to action-related sentences modulates the activity of the motor system: a combined TMS and behavioral study. G Buccino, Brain Res. Cogn. Brain Res. 242005</p>
<p>Functional links between motor and language systems. F Pulvermuller, Eur. J. Neurosci. 212005</p>
<p>Processing abstract language modulates motor system activity. A M Glenberg, Q. J. Exp. Psychol. 612008</p>
<p>Category-specific versus category-general semantic impairment induced by transcranial magnetic stimulation. G Pobric, Curr. Biol. 202010</p>
<p>Different roles of lateral anterior temporal lobe and inferior parietal lobule in coding function and manipulation tool knowledge: evidence from an rTMS study. R Ishibashi, Neuropsychologia. 492011</p>
<p>Brain signatures of meaning access in action word recognition. F Pulvermuller, J. Cogn. Neurosci. 172005</p>
<p>Cross-talk between language processes and overt motor behavior in the first 200 msec of processing. V Boulenger, J. Cogn. Neurosci. 182006</p>
<p>Neural correlates of partial lexical activation. K P Revill, Proc. Natl. Acad. Sci. U.S.A. 1052008</p>
<p>Conceptual flexibility in the human brain: dynamic recruitment of semantic maps from visual, motor, and motion-related areas. K Hoenig, J. Cogn. Neurosci. 202008</p>
<p>Toward a theory of semantic representation. G Vigliocco, Lang. Cogn. 12009</p>
<p>The enigmatic temporal pole: a review of findings on social and emotional processing. I R Olson, Brain. 1302007</p>
<p>Emotional processing in anterior cingulate and medial prefrontal cortex. A Etkin, Trends Cogn. Sci. 152011</p>
<p>Social cognition and the anterior temporal lobes. L A Ross, I R Olson, Neuroimage. 492010</p>
<p>Social concepts are represented in the superior anterior temporal cortex. R Zahn, Proc. Natl. Acad. Sci. U.S.A. 1042007</p>
<p>Patterns in behavioral neuroanatomy: association areas, the limbic system, and hemispheric specialization. M Mesulam, Principles of Behavioral Neurology (Mesulam, M. F.A. Davis1985</p>
<p>Comparative mapping of higher visual areas in monkeys and humans. G A Orban, Trends Cogn. Sci. 82004</p>
<p>Semantic dementia: progressive fluent aphasia with temporal lobe atrophy. J R Hodges, Brain. 1151992</p>
<p>A voxel-based morphometry study of semantic dementia: Relationship between temporal lobe atrophy and semantic memory. C J Mummery, Ann. Neurol. 472000</p>
<p>Nonverbal semantic impairment in semantic dementia. S Bozeat, Neuropsychologia. 382000</p>
<p>The role of conceptual knowledge in object use: evidence from semantic dementia. J R Hodges, Brain. 1232000</p>
<p>When objects lose their meaning: what happens to their use?. S Bozeat, Cogn. Affect. Behav. Neurosci. 22002</p>
<p>Colour knowledge in semantic dementia: it is not all black and white. T T Rogers, Neuropsychologia. 452007</p>
<p>Neural basis of category-specific semantic deficits for living things: evidence from semantic dementia, HSVE and a neural network model. Lambon Ralph, M A , Brain. 1302007</p>
<p>Where is the semantic system? A critical review and meta-analysis of 120 functional neuroimaging studies. J R Binder, Cereb. Cortex. 192009</p>
<p>Meta-analysis of the functional neuroanatomy of single-word reading: method and validation. P E Turkeltaub, Neuroimage. 162002</p>
<p>Distributed anatomy of transcortical sensory aphasia. M P Alexander, Arch. Neurol. 461989</p>
<p>Neuroimaging contributions to the understanding of aphasia. H Damasio, Handbook of neuropsychology. F Boller, J Grafman, Elsevier1989</p>
<p>Delineation of single-word semantic comprehension deficits in aphasia, with anatomic correlation. J Hart, B Gordon, Ann. Neurol. 271990</p>
<p>On the status of object concepts in aphasia. H Chertkow, Brain Lang. 581997</p>
<p>Lesion analysis of the brain areas involved in language comprehension. N F Dronkers, Cognition. 922004</p>
<p>The symbol grounding problem. S Harnad, Phys. D. 421990</p>
<p>Perceptual symbol systems. L W Barsalou, Behav. Brain Sci. 221999</p>
<p>The brain's concepts: the role of the sensory-motor system in conceptual knowledge. V Gallese, G Lakoff, Cogn. Neuropsychol. 222005</p>
<p>What do brain lesions tell us about theories of embodied semantics and the human mirror neuron system?. A L Are ´valo, 10.1016/j.cortex.2010.06.001Cortex. in press</p>
<p>Semantic cognition: a parallel distributed processing approach. T T Rogers, J L Mcclelland, 2004MIT Press</p>
<p>On the need for embodied and dis-embodied cognition. G Dove, Front. Psychol. 12011article 242</p>
<p>Action in cognition: the case for language. L J Taylor, R A Zwaan, Lang. Cogn. 12009</p>
<p>Retrosplenial amnesia. E Valenstein, Brain. 1101987</p>
<p>Semantic impairment in stroke aphasia versus semantic dementia: a case-series comparison. E Jefferies, Lambon Ralph, M A , Brain. 1292006</p>
<p>Other minds in the brain: a functional imaging study of 'theory of mind' in story comprehension. P C Fletcher, Cognition. 571995</p>
<p>People thinking about thinking people: the role of the temporo-parietal junction in 'theory of mind. R Saxe, N Kanwisher, Neuroimage. 192003</p>
<p>Meeting of minds: the medial frontal cortex and social cognition. D M Amodio, C D Frith, Nat. Rev. Neurosci. 72006</p>
<p>Temporo-parietal junction activity in Theory-of-Mind tasks: falseness, beliefs, or attention. M Aichhorn, J. Cogn. Neurosci. 212009</p>
<p>Social cognition and the brain: a metaanalysis. Hum. Brain Mapp. F Van Overwalle, 200930</p>
<p>The functional neuroanatomy of autobiographical memory: A meta-analysis. E Svoboda, Neuropsychologia. 442006</p>
<p>Memory retrieval and the parietal cortex: a review of evidence from a dual-process perspective. K L Vilberg, M D Rugg, Neuropsychologia. 462008</p>
<p>Deconstructing episodic memory with construction. D Hassabis, E A Maguire, Trends Cogn. Sci. 112007</p>
<p>Remembering the past and imagining the future: common and distinct neural substrates during event construction and elaboration. D R Addis, Neuropsychologia. 452007</p>
<p>Solving future problems: default network and executive activity associated with goal-directed mental simulations. K D Gerlach, Neuroimage. 552011</p>
<p>Medial prefrontal cortex and selfreferential mental activity: relation to a default mode of brain function. D A Gusnard, Proc. Natl. Acad. Sci. U.S.A. 982001</p>
<p>Associations and dissociations between default and self-reference networks in the human brain. S Whitfield-Gabrieli, Neuroimage. 552011</p>
<p>The brain's default network: anatomy, function, and relevance to disease. R L Buckner, Ann. N. Y. Acad. Sci. 11242008</p>
<p>The common neural basis of autobiographical memory, prospection, navigation, theory of mind, and the default mode: a quantitative meta-analysis. R N Spreng, J. Cogn. Neurosci. 212009</p>
<p>Patterns of brain activity supporting autobiographical memory, prospection, and theory of mind, and their relationship to the default mode network. R N Spreng, C L Grady, J. Cogn. Neurosci. 222009</p>
<p>Conceptual processing during the conscious resting state: a functional MRI study. J R Binder, J. Cogn. Neurosci. 111999</p>
<p>Memory of the future: an essay on the temporal organization of conscious awareness. D H Ingvar, Hum. Neurobiol. 41985</p>
<p>Remembering the past: two facets of episodic memory explored with positron emission tomography. N C Andreasen, Am. J. Psychiatry. 1521995</p>
<p>The brain's default network and its adaptive role in internal mentation. J R Andrews-Hanna, 10.1177/1073858411403316Neuroscientist. 2011</p>
<p>Experimental phonetics: selected articles. G Fairbanks, 1966University of Illinois Press</p>
<p>The neural career of sensorimotor metaphors. R H Desai, J. Cogn. Neurosci. 232011</p>
<p>Distributed hierarchical processing in the primate cerebral cortex. D J Felleman, D C Van Essen, Cereb. Cortex. 11991</p>
<p>An anatomical study of converging sensory pathways within the cerebral cortex of the monkey. E G Jones, T S P Powell, Brain. 931970</p>
<p>The parahippocampal gyrus: new observations regarding its cortical connections in the monkey. G W Van Hoesen, Trends Neurosci. 51982</p>
<p>Memory and the hippocampus: a synthesis from findings with rats, monkeys, and humans. L R Squire, Psychol. Rev. 991992</p>
<p>Cognition and anatomy in three variants of primary progressive aphasia. M L Gorno-Tempini, Ann. Neurol. 552004</p>
<p>Patterns of cortical thinning in the language variants of frontotemporal lobar degeneration. J D Rohrer, Neurology. 722009</p>
<p>What the left and right anterior fusiform gyri tell us about semantic memory. M Mion, Brain. 1332010</p>
<p>The ventral and inferolateral aspects of the anterior temporal lobe are crucial in semantic memory:evidence from a novel direct comparison of distortion-corrected fMRI, rTMS, and semantic dementia. R J Binney, Cereb. Cortex. 202010</p>
<p>Differential connections of the temporal pole with the orbital and medial prefrontal networks in macaque monkeys. H Kondo, J. Comp. Neurol. 4652003</p>
<p>Dissociable controlled retrieval and generalized selection mechanisms in ventrolateral prefrontal cortex. D Badre, Neuron. 472005</p>
<p>The neural mechanisms of speech comprehension: fMRI studies of semantic ambiguity. J M Rodd, Cereb. Cortex. 152005</p>
<p>Phonology, semantics and the role of the left inferior prefrontal cortex. J A Fiez, Hum. Brain Mapp. 51997</p>
<p>Functional MRI of language: new approaches to understanding the cortical organization of semantic processing. S Y Bookheimer, Annu. Rev. Neurosci. 252002</p>
<p>Functional specialization within the anterior medial prefrontal cortex: a functional magnetic resonance imaging study with human subjects. S Zysset, Neurosci. Lett. 3352003</p>
<p>Medial prefrontal activity differentiates self from close others. T F Heatherton, Soc. Cogn. Affect. Neurosci. 12006</p>
<p>Dissociable medial prefrontal contributions to judgments of similar and dissimilar others. J P Mitchell, Neuron. 502006</p>
<p>The mechanism of 'dynamic aphasia. A R Luria, L S Tsvetkova, 19684</p>
<p>Frontal lobes and language. M P Alexander, Brain Lang. 371989</p>
<p>Dynamic aphasia: an inability to select between competing verbal responses?. G Robinson, Brain. 1211998</p>
<p>Neural systems for reading aloud: A multiparametric approach. W W Graves, Cereb. Cortex. 202010</p>
<p>Distinct brain systems for processing concrete and abstract concepts. J R Binder, J. Cogn. Neurosci. 172005</p>
<p>Time course of semantic processes during sentence comprehension: an fMRI study. C Humphries, Neuroimage. 362007</p>
<p>Mechanisms and streams for processing of 'what' and 'where' in auditory cortex. J P Rauschecker, B Tian, Proc. Natl. Acad. Sci. U.S.A. 972000</p>
<p>A new neural framework for visuospatial processing. D J Kravitz, Nat. Rev. Neurosci. 122011</p>
<p>Emotional and temporal aspects of situation model processing during text comprehension: An event-related fMRI study. E C Ferstl, J. Cogn. Neurosci. 172005</p>
<p>Time, space and emotion: fMRI reveals content-specific activation during text comprehension. E C Ferstl, D Y Von Cramon, Neurosci. Lett. 4272007</p>            </div>
        </div>

    </div>
</body>
</html>