<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3623 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3623</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3623</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-80.html">extraction-schema-80</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <p><strong>Paper ID:</strong> paper-de7839351ccd3b4d0ed9fe97a058adb2e967524c</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/de7839351ccd3b4d0ed9fe97a058adb2e967524c" target="_blank">Dual PECCS: a cognitive system for conceptual representation and categorization</a></p>
                <p><strong>Paper Venue:</strong> Journal of experimental and theoretical artificial intelligence (Print)</p>
                <p><strong>Paper TL;DR:</strong> An advanced version of Dual-PECCS, a cognitively-inspired knowledge representation and reasoning system aimed at extending the capabilities of artificial systems in conceptual categorization tasks, is presented and integrated and tested into two cognitive architectures, ACT-R and CLARION, implementing different assumptions on the underlying invariant structures governing human cognition.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3623.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3623.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Prototype theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Prototype theory (Rosch-style prototypical representations)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts are represented functionally as prototypes — summary or centroid representations capturing the 'best' or most typical features of a category; category membership and typicality are graded by distance from the prototype.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>prototype theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual knowledge is represented as prototypical summaries (centroids) of category members in a representational format where an instance's similarity (distance) to the prototype determines typicality and category assignments.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Rosch-style typicality effects and behavioral data showing graded category judgments; psychological studies where prototypes explain typicality effects; in this paper, prototype representations implemented in conceptual spaces successfully retrieve category labels for many linguistic descriptions and account for cases where humans activate prototypes for general descriptions.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Fails to account for cases where specific exemplars drive categorization (e.g., atypical but known instances); prototype-only models cannot capture rich individual-specific knowledge and some rapid learning of exceptions; in this paper, prototype retrieval was sometimes outcompeted by exemplar retrieval even when human subjects preferred prototypes.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Paper contrasts prototype theory with exemplar and classical (rule-based) theories: prototypes explain graded typicality and ease of similarity-based categorization, whereas exemplars explain exemplar-driven categorization and exceptions; prototypes are implemented in conceptual spaces (centroids) and contrasted with symbolic ontologies for deductive classification.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How to weigh contextual relevance of dimensions in prototype similarity computations (contextual weighting currently not implemented); resolving when prototypes vs. exemplars should be preferred (proxyfication errors show exemplars sometimes dominate for general descriptions).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Dual PECCS: a cognitive system for conceptual representation and categorization', 'publication_date_yy_mm': '2017-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3623.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3623.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Exemplar theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Exemplar theory (stored-exemplar representations)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts are represented as sets of stored individual exemplars; categorization is performed by similarity to remembered instances rather than to an abstracted prototype.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>exemplar theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual knowledge is represented as a memory of specific past instances (exemplars), and categorization is performed by computing similarity between the current stimulus and stored exemplars.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Behavioral findings where people categorize based on similarity to specific stored instances (e.g., when exemplars are familiar or salient); neural plausibility referenced (Squire & Knowlton); in the system, exemplar representations implemented as points in conceptual spaces frequently account for human responses and are favored when similar exemplars are available.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Computational scaling concerns (storing and comparing many exemplars); does not by itself capture abstract generalizations or necessary/sufficient structural knowledge; in the paper, exemplar over-selection produced proxyfication errors where exemplars were chosen even when human subjects activated prototypes for general descriptions.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Paper treats exemplar theory as complementary to prototype theory (heterogeneous hypothesis): exemplars explain fine-grained judgments and exceptions where prototypes fail; the Dual-PECCS system implements both and applies a preference for exemplars when a similar exemplar exists.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How to control exemplar vs. prototype preference across levels of abstraction; how to scale exemplar storage and similarity search; determining principled thresholds for when exemplars should override prototypes (current system uses a fixed threshold).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Dual PECCS: a cognitive system for conceptual representation and categorization', 'publication_date_yy_mm': '2017-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3623.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3623.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Classical theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Classical (Aristotelian) theory of concepts</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts are represented as sets defined by necessary and sufficient conditions (rule-like symbolic definitions), supporting monotonic, deductive categorization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>classical (Aristotelian) theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual knowledge is functionally represented as symbolic definitions composed of necessary and sufficient conditions; categorization follows deductive rule-application rather than similarity.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Appropriate for formally defined domains (e.g., geometric shapes) where clear definitional criteria yield correct deductive categorizations; in the paper, classical representations are encoded as Description Logic ontologies (OpenCyc) and supply reliable, rule-based checks.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Behavioral and empirical evidence shows many common-sense concepts lack necessary and sufficient features (Rosch); classical definitions cannot capture graded typicality and many natural category membership judgments; non-monotonic typicality reasoning in logical systems is computationally expensive and often intractable (cited Giordano et al., 2013).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Contrasted with prototype and exemplar approaches: classical theory supports Type 2 deductive processes while prototype/exemplar support Type 1 approximate, defeasible categorization; Dual-PECCS integrates both by using ontologies to check or correct typicality-driven candidates.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>Scalability and tractability of adding defeasible typicality to Description Logics; aligning symbolic ontologies with similarity-based representations (mapping OpenCyc to WordNet and conceptual spaces remains non-trivial and partial).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Dual PECCS: a cognitive system for conceptual representation and categorization', 'publication_date_yy_mm': '2017-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3623.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e3623.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Theory-theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Theory-theory (theory-like conceptual representations)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts are treated functionally as role-filling theoretical terms within domain-specific theories or mental micro-theories, emphasizing holistic and role-based individuation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>theory-theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual knowledge is represented as parts of domain 'theories' or micro-theories: concepts are individuated by the causal/explanatory roles they play within these theories rather than by feature lists or exemplars.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Explains certain inferential and explanatory patterns in conceptual behavior where background causal knowledge influences categorization and property ascription (not operationalized in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Paper notes theory-theory is more vaguely defined and computationally harder to treat compared to prototype/exemplar approaches; therefore it is not implemented in Dual-PECCS.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Mentioned as an alternative to prototype/exemplar views but not operationalized; authors explicitly exclude it from current implementation due to vagueness and computational difficulty.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How to formalize and computationally implement theory-like representations and micro-theories; integration with similarity-based systems remains open.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Dual PECCS: a cognitive system for conceptual representation and categorization', 'publication_date_yy_mm': '2017-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3623.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e3623.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Proxytype theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Proxytype theory (Prinz)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A functional account where concepts are not static but tokenized 'proxytypes' — elements of long-term representational networks that are activated ('tokenized') in working memory to stand for categories during processing.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>proxytype theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual knowledge is represented as elements of complex long-term networks (proxytypes) that are instantiated (tokenized) in working memory when needed, capturing the dynamic activation of concept-relevant information.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Explains activation and retrieval phenomena, aligns with working-memory/long-term-memory distinctions in neuroscience; inspired by Barsalou's work on situated conceptualization (cited).</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Original formulation depicted proxytypes as monolithic (prototype-like); lacks detailed specification of heterogeneity and mechanisms for selecting which parts of the long-term network to tokenise.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Proxytype theory provides a bridging, process-oriented view that can incorporate prototype, exemplar and classical information by viewing them as parts of the long-term network to be proxyfied; the paper extends this to 'heterogeneous proxytypes'.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How exactly different representational components are selected/contextually activated (proxyfication heuristics); how proxytype tokenization maps onto neural substrates remains underspecified.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Dual PECCS: a cognitive system for conceptual representation and categorization', 'publication_date_yy_mm': '2017-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3623.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e3623.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Heterogeneous proxytypes</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Heterogeneous proxytypes (Lieto-style)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A functional, implemented extension of proxytype theory positing that for each concept multiple heterogeneous representational bodies (prototypes, exemplars, classical info) coexist in long-term memory and can be selectively tokenized in working memory.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>heterogeneous proxytypes</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are represented by multiple co-existing representational components (prototype, exemplar, symbolic/classical) stored in long-term memory; processing selectively activates ('proxyfies') the representation(s) most relevant to the current stimulus and task.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Behavioral and neural evidence for multiple representational formats coexisting (cited studies e.g., Squire & Knowlton, Malt 1989); in this paper the Dual-PECCS implementation shows that combining prototypes and exemplars explains a variety of human categorization responses and aligns with dual-process reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Operationalizing which representation to proxyfy remains challenging: empirical proxyfication errors in the system (exemplar returned where humans preferred prototype) indicate the need for better selection heuristics; mapping and alignment across heterogeneous resources (conceptual spaces and ontologies) is partial and noisy.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Positions itself as a unifying/hybrid alternative to single-format theories by integrating prototype, exemplar and classical representations; it is explicitly implemented in Dual-PECCS and compared in behavior to human data.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How to determine context-sensitive activation (which subset of the long-term network to tokenise) and how to weight competing representations; scaling the approach and improving the mapping between heterogeneous KBs are open engineering and theoretical tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Dual PECCS: a cognitive system for conceptual representation and categorization', 'publication_date_yy_mm': '2017-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3623.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e3623.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Conceptual spaces</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Conceptual spaces (Gärdenfors)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A geometric, functional representational framework where concepts correspond to regions in a metric multidimensional space (domains/dimensions), with prototypes as centroids and exemplars as points; similarity is computed as distance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>conceptual spaces</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual knowledge is represented in a metric, multi-dimensional geometric space where quality dimensions and domains encode perceptual and conceptual features; concepts are convex regions, prototypes are centroids, and exemplars are specific points; similarity/typicality are functions of distance.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Explains graded typicality, similarity judgments, and affords straightforward geometric similarity computations; adopted in Dual-PECCS to encode both prototypes and exemplars and to compute similarity-based categorization (cosine, Euclidean/Manhattan metrics).</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Contextual weighting and tunable metrics are important for human similarity but are not fully handled in the present implementation; some conceptual content (e.g., abstract relational or theory-like knowledge) is hard to capture purely geometrically.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Used as the S1 representational substrate for prototype/exemplar processes and contrasted with symbolic ontologies used for S2 deductive processes; conceptual spaces provide graded similarity-based reasoning whereas ontologies provide rule-based monotonic reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>Present implementation lacks context-sensitive weighting of dimensions and tunable metrics; mapping conceptual-space entities to symbolic ontological classes (anchoring via WordNet) is partial and sometimes imprecise.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Dual PECCS: a cognitive system for conceptual representation and categorization', 'publication_date_yy_mm': '2017-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3623.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e3623.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Symbolic ontologies (DL)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Symbolic ontologies / Description Logics (classical symbolic representation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Functional-level symbolic representations where concepts are encoded as structured, logic-based classes (necessary/sufficient conditions) supporting monotonic deductive reasoning and consistency checking.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>symbolic ontological (Description Logics) representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual knowledge is represented as symbolic, structured logical formalisms (ontologies and Description Logics) encoding taxonomic relations and necessary/sufficient conditions; reasoning is explicit rule-based deduction and consistency checking.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Appropriate for formally definable categories and used in the paper for S2 consistency checks (OpenCyc used as the ontology); provides reliable taxonomic and definitional knowledge to correct approximate S1 categorizations.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Many common-sense concepts lack strict necessary/sufficient conditions; adding typicality/non-monotonic extensions to DLs is computationally expensive and impractical for large KBs; alignment with similarity-based representations requires nontrivial mapping (partial mapping success reported).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Contrasted with conceptual spaces/prototype/exemplar formats: symbolic ontologies provide precise deductive checks (Type 2), while conceptual spaces provide approximate similarity-based categorization (Type 1); Dual-PECCS uses ontologies to validate or reject S1 candidates.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>Mapping coverage between ontological classes (OpenCyc) and conceptual-space representations is incomplete; handling non-monotonic typicality in ontologies remains an open computational problem.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Dual PECCS: a cognitive system for conceptual representation and categorization', 'publication_date_yy_mm': '2017-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3623.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e3623.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Dual process theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Dual process theory of reasoning (Type 1 / Type 2)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A functional theory positing two qualitatively different cognitive systems: fast, automatic, associative Type 1 processes and slow, deliberative, rule-based Type 2 processes; applied here to mediate interactions between similarity-based and symbolic categorization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>dual process theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual processing is functionally governed by two interacting systems: Type 1 processes (fast, automatic, associative) implement prototype/exemplar similarity-based categorization; Type 2 processes (slow, deliberative) implement explicit symbolic/deductive checks using ontologies.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Cited psychological literature (Evans & Frankish; Kahneman) supporting existence of fast/slow processes; implemented in Dual-PECCS where S1 (conceptual spaces) proposes candidates and S2 (ontologies) validates them, reproducing human-like tradeoffs and errors observed in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Architectural incorporation varies (e.g., ACT-R not natively dual-process, requiring explicit engineering); interaction heuristics (e.g., order of S1 then S2, thresholds for rejection) are design choices that may affect behavior and need empirical grounding.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Provides the process-level scaffold for combining prototype/exemplar (Type 1) and classical symbolic (Type 2) representations; paper operationalizes the theory by executing S1 processes first and refining with S2, explicitly comparing outputs and inconsistencies.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>Precise mechanisms of S1–S2 negotiation, criteria for when S2 should override S1, and how to implement these in cognitive architectures remain open; observed proxyfication errors indicate more nuanced heuristics are needed.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Dual PECCS: a cognitive system for conceptual representation and categorization', 'publication_date_yy_mm': '2017-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Conceptual Spaces: The Geometry of Thought <em>(Rating: 2)</em></li>
                <li>The Psychology of Concepts: A Brief History <em>(Rating: 1)</em></li>
                <li>Where is the concept? Representations, processes and neural substrates <em>(Rating: 1)</em></li>
                <li>The Structure of Autobiographical Memory and Implications for Exemplar Models <em>(Rating: 1)</em></li>
                <li>Cognitive Architecture and Commonsense Reasoning: On the integration of Typicality and Symbolic Representations <em>(Rating: 1)</em></li>
                <li>Proxytypes and Tokenization: Prinz (2002) — The conceptual representation in the brain <em>(Rating: 2)</em></li>
                <li>On the Integration of Prototypes and Exemplars in Categorization (Malt, 1989) <em>(Rating: 2)</em></li>
                <li>Non-monotonic Extensions of Description Logics for Typicality (Giordano et al., 2013) <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3623",
    "paper_id": "paper-de7839351ccd3b4d0ed9fe97a058adb2e967524c",
    "extraction_schema_id": "extraction-schema-80",
    "extracted_data": [
        {
            "name_short": "Prototype theory",
            "name_full": "Prototype theory (Rosch-style prototypical representations)",
            "brief_description": "Concepts are represented functionally as prototypes — summary or centroid representations capturing the 'best' or most typical features of a category; category membership and typicality are graded by distance from the prototype.",
            "citation_title": "",
            "mention_or_use": "use",
            "theory_name": "prototype theory",
            "theory_description": "Conceptual knowledge is represented as prototypical summaries (centroids) of category members in a representational format where an instance's similarity (distance) to the prototype determines typicality and category assignments.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Rosch-style typicality effects and behavioral data showing graded category judgments; psychological studies where prototypes explain typicality effects; in this paper, prototype representations implemented in conceptual spaces successfully retrieve category labels for many linguistic descriptions and account for cases where humans activate prototypes for general descriptions.",
            "counter_evidence_or_challenges": "Fails to account for cases where specific exemplars drive categorization (e.g., atypical but known instances); prototype-only models cannot capture rich individual-specific knowledge and some rapid learning of exceptions; in this paper, prototype retrieval was sometimes outcompeted by exemplar retrieval even when human subjects preferred prototypes.",
            "comparison_to_other_theories": "Paper contrasts prototype theory with exemplar and classical (rule-based) theories: prototypes explain graded typicality and ease of similarity-based categorization, whereas exemplars explain exemplar-driven categorization and exceptions; prototypes are implemented in conceptual spaces (centroids) and contrasted with symbolic ontologies for deductive classification.",
            "notable_limitations_or_open_questions": "How to weigh contextual relevance of dimensions in prototype similarity computations (contextual weighting currently not implemented); resolving when prototypes vs. exemplars should be preferred (proxyfication errors show exemplars sometimes dominate for general descriptions).",
            "uuid": "e3623.0",
            "source_info": {
                "paper_title": "Dual PECCS: a cognitive system for conceptual representation and categorization",
                "publication_date_yy_mm": "2017-03"
            }
        },
        {
            "name_short": "Exemplar theory",
            "name_full": "Exemplar theory (stored-exemplar representations)",
            "brief_description": "Concepts are represented as sets of stored individual exemplars; categorization is performed by similarity to remembered instances rather than to an abstracted prototype.",
            "citation_title": "",
            "mention_or_use": "use",
            "theory_name": "exemplar theory",
            "theory_description": "Conceptual knowledge is represented as a memory of specific past instances (exemplars), and categorization is performed by computing similarity between the current stimulus and stored exemplars.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Behavioral findings where people categorize based on similarity to specific stored instances (e.g., when exemplars are familiar or salient); neural plausibility referenced (Squire & Knowlton); in the system, exemplar representations implemented as points in conceptual spaces frequently account for human responses and are favored when similar exemplars are available.",
            "counter_evidence_or_challenges": "Computational scaling concerns (storing and comparing many exemplars); does not by itself capture abstract generalizations or necessary/sufficient structural knowledge; in the paper, exemplar over-selection produced proxyfication errors where exemplars were chosen even when human subjects activated prototypes for general descriptions.",
            "comparison_to_other_theories": "Paper treats exemplar theory as complementary to prototype theory (heterogeneous hypothesis): exemplars explain fine-grained judgments and exceptions where prototypes fail; the Dual-PECCS system implements both and applies a preference for exemplars when a similar exemplar exists.",
            "notable_limitations_or_open_questions": "How to control exemplar vs. prototype preference across levels of abstraction; how to scale exemplar storage and similarity search; determining principled thresholds for when exemplars should override prototypes (current system uses a fixed threshold).",
            "uuid": "e3623.1",
            "source_info": {
                "paper_title": "Dual PECCS: a cognitive system for conceptual representation and categorization",
                "publication_date_yy_mm": "2017-03"
            }
        },
        {
            "name_short": "Classical theory",
            "name_full": "Classical (Aristotelian) theory of concepts",
            "brief_description": "Concepts are represented as sets defined by necessary and sufficient conditions (rule-like symbolic definitions), supporting monotonic, deductive categorization.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_name": "classical (Aristotelian) theory",
            "theory_description": "Conceptual knowledge is functionally represented as symbolic definitions composed of necessary and sufficient conditions; categorization follows deductive rule-application rather than similarity.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Appropriate for formally defined domains (e.g., geometric shapes) where clear definitional criteria yield correct deductive categorizations; in the paper, classical representations are encoded as Description Logic ontologies (OpenCyc) and supply reliable, rule-based checks.",
            "counter_evidence_or_challenges": "Behavioral and empirical evidence shows many common-sense concepts lack necessary and sufficient features (Rosch); classical definitions cannot capture graded typicality and many natural category membership judgments; non-monotonic typicality reasoning in logical systems is computationally expensive and often intractable (cited Giordano et al., 2013).",
            "comparison_to_other_theories": "Contrasted with prototype and exemplar approaches: classical theory supports Type 2 deductive processes while prototype/exemplar support Type 1 approximate, defeasible categorization; Dual-PECCS integrates both by using ontologies to check or correct typicality-driven candidates.",
            "notable_limitations_or_open_questions": "Scalability and tractability of adding defeasible typicality to Description Logics; aligning symbolic ontologies with similarity-based representations (mapping OpenCyc to WordNet and conceptual spaces remains non-trivial and partial).",
            "uuid": "e3623.2",
            "source_info": {
                "paper_title": "Dual PECCS: a cognitive system for conceptual representation and categorization",
                "publication_date_yy_mm": "2017-03"
            }
        },
        {
            "name_short": "Theory-theory",
            "name_full": "Theory-theory (theory-like conceptual representations)",
            "brief_description": "Concepts are treated functionally as role-filling theoretical terms within domain-specific theories or mental micro-theories, emphasizing holistic and role-based individuation.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_name": "theory-theory",
            "theory_description": "Conceptual knowledge is represented as parts of domain 'theories' or micro-theories: concepts are individuated by the causal/explanatory roles they play within these theories rather than by feature lists or exemplars.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Explains certain inferential and explanatory patterns in conceptual behavior where background causal knowledge influences categorization and property ascription (not operationalized in this paper).",
            "counter_evidence_or_challenges": "Paper notes theory-theory is more vaguely defined and computationally harder to treat compared to prototype/exemplar approaches; therefore it is not implemented in Dual-PECCS.",
            "comparison_to_other_theories": "Mentioned as an alternative to prototype/exemplar views but not operationalized; authors explicitly exclude it from current implementation due to vagueness and computational difficulty.",
            "notable_limitations_or_open_questions": "How to formalize and computationally implement theory-like representations and micro-theories; integration with similarity-based systems remains open.",
            "uuid": "e3623.3",
            "source_info": {
                "paper_title": "Dual PECCS: a cognitive system for conceptual representation and categorization",
                "publication_date_yy_mm": "2017-03"
            }
        },
        {
            "name_short": "Proxytype theory",
            "name_full": "Proxytype theory (Prinz)",
            "brief_description": "A functional account where concepts are not static but tokenized 'proxytypes' — elements of long-term representational networks that are activated ('tokenized') in working memory to stand for categories during processing.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_name": "proxytype theory",
            "theory_description": "Conceptual knowledge is represented as elements of complex long-term networks (proxytypes) that are instantiated (tokenized) in working memory when needed, capturing the dynamic activation of concept-relevant information.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Explains activation and retrieval phenomena, aligns with working-memory/long-term-memory distinctions in neuroscience; inspired by Barsalou's work on situated conceptualization (cited).",
            "counter_evidence_or_challenges": "Original formulation depicted proxytypes as monolithic (prototype-like); lacks detailed specification of heterogeneity and mechanisms for selecting which parts of the long-term network to tokenise.",
            "comparison_to_other_theories": "Proxytype theory provides a bridging, process-oriented view that can incorporate prototype, exemplar and classical information by viewing them as parts of the long-term network to be proxyfied; the paper extends this to 'heterogeneous proxytypes'.",
            "notable_limitations_or_open_questions": "How exactly different representational components are selected/contextually activated (proxyfication heuristics); how proxytype tokenization maps onto neural substrates remains underspecified.",
            "uuid": "e3623.4",
            "source_info": {
                "paper_title": "Dual PECCS: a cognitive system for conceptual representation and categorization",
                "publication_date_yy_mm": "2017-03"
            }
        },
        {
            "name_short": "Heterogeneous proxytypes",
            "name_full": "Heterogeneous proxytypes (Lieto-style)",
            "brief_description": "A functional, implemented extension of proxytype theory positing that for each concept multiple heterogeneous representational bodies (prototypes, exemplars, classical info) coexist in long-term memory and can be selectively tokenized in working memory.",
            "citation_title": "",
            "mention_or_use": "use",
            "theory_name": "heterogeneous proxytypes",
            "theory_description": "Concepts are represented by multiple co-existing representational components (prototype, exemplar, symbolic/classical) stored in long-term memory; processing selectively activates ('proxyfies') the representation(s) most relevant to the current stimulus and task.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Behavioral and neural evidence for multiple representational formats coexisting (cited studies e.g., Squire & Knowlton, Malt 1989); in this paper the Dual-PECCS implementation shows that combining prototypes and exemplars explains a variety of human categorization responses and aligns with dual-process reasoning.",
            "counter_evidence_or_challenges": "Operationalizing which representation to proxyfy remains challenging: empirical proxyfication errors in the system (exemplar returned where humans preferred prototype) indicate the need for better selection heuristics; mapping and alignment across heterogeneous resources (conceptual spaces and ontologies) is partial and noisy.",
            "comparison_to_other_theories": "Positions itself as a unifying/hybrid alternative to single-format theories by integrating prototype, exemplar and classical representations; it is explicitly implemented in Dual-PECCS and compared in behavior to human data.",
            "notable_limitations_or_open_questions": "How to determine context-sensitive activation (which subset of the long-term network to tokenise) and how to weight competing representations; scaling the approach and improving the mapping between heterogeneous KBs are open engineering and theoretical tasks.",
            "uuid": "e3623.5",
            "source_info": {
                "paper_title": "Dual PECCS: a cognitive system for conceptual representation and categorization",
                "publication_date_yy_mm": "2017-03"
            }
        },
        {
            "name_short": "Conceptual spaces",
            "name_full": "Conceptual spaces (Gärdenfors)",
            "brief_description": "A geometric, functional representational framework where concepts correspond to regions in a metric multidimensional space (domains/dimensions), with prototypes as centroids and exemplars as points; similarity is computed as distance.",
            "citation_title": "",
            "mention_or_use": "use",
            "theory_name": "conceptual spaces",
            "theory_description": "Conceptual knowledge is represented in a metric, multi-dimensional geometric space where quality dimensions and domains encode perceptual and conceptual features; concepts are convex regions, prototypes are centroids, and exemplars are specific points; similarity/typicality are functions of distance.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Explains graded typicality, similarity judgments, and affords straightforward geometric similarity computations; adopted in Dual-PECCS to encode both prototypes and exemplars and to compute similarity-based categorization (cosine, Euclidean/Manhattan metrics).",
            "counter_evidence_or_challenges": "Contextual weighting and tunable metrics are important for human similarity but are not fully handled in the present implementation; some conceptual content (e.g., abstract relational or theory-like knowledge) is hard to capture purely geometrically.",
            "comparison_to_other_theories": "Used as the S1 representational substrate for prototype/exemplar processes and contrasted with symbolic ontologies used for S2 deductive processes; conceptual spaces provide graded similarity-based reasoning whereas ontologies provide rule-based monotonic reasoning.",
            "notable_limitations_or_open_questions": "Present implementation lacks context-sensitive weighting of dimensions and tunable metrics; mapping conceptual-space entities to symbolic ontological classes (anchoring via WordNet) is partial and sometimes imprecise.",
            "uuid": "e3623.6",
            "source_info": {
                "paper_title": "Dual PECCS: a cognitive system for conceptual representation and categorization",
                "publication_date_yy_mm": "2017-03"
            }
        },
        {
            "name_short": "Symbolic ontologies (DL)",
            "name_full": "Symbolic ontologies / Description Logics (classical symbolic representation)",
            "brief_description": "Functional-level symbolic representations where concepts are encoded as structured, logic-based classes (necessary/sufficient conditions) supporting monotonic deductive reasoning and consistency checking.",
            "citation_title": "",
            "mention_or_use": "use",
            "theory_name": "symbolic ontological (Description Logics) representation",
            "theory_description": "Conceptual knowledge is represented as symbolic, structured logical formalisms (ontologies and Description Logics) encoding taxonomic relations and necessary/sufficient conditions; reasoning is explicit rule-based deduction and consistency checking.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Appropriate for formally definable categories and used in the paper for S2 consistency checks (OpenCyc used as the ontology); provides reliable taxonomic and definitional knowledge to correct approximate S1 categorizations.",
            "counter_evidence_or_challenges": "Many common-sense concepts lack strict necessary/sufficient conditions; adding typicality/non-monotonic extensions to DLs is computationally expensive and impractical for large KBs; alignment with similarity-based representations requires nontrivial mapping (partial mapping success reported).",
            "comparison_to_other_theories": "Contrasted with conceptual spaces/prototype/exemplar formats: symbolic ontologies provide precise deductive checks (Type 2), while conceptual spaces provide approximate similarity-based categorization (Type 1); Dual-PECCS uses ontologies to validate or reject S1 candidates.",
            "notable_limitations_or_open_questions": "Mapping coverage between ontological classes (OpenCyc) and conceptual-space representations is incomplete; handling non-monotonic typicality in ontologies remains an open computational problem.",
            "uuid": "e3623.7",
            "source_info": {
                "paper_title": "Dual PECCS: a cognitive system for conceptual representation and categorization",
                "publication_date_yy_mm": "2017-03"
            }
        },
        {
            "name_short": "Dual process theory",
            "name_full": "Dual process theory of reasoning (Type 1 / Type 2)",
            "brief_description": "A functional theory positing two qualitatively different cognitive systems: fast, automatic, associative Type 1 processes and slow, deliberative, rule-based Type 2 processes; applied here to mediate interactions between similarity-based and symbolic categorization.",
            "citation_title": "",
            "mention_or_use": "use",
            "theory_name": "dual process theory",
            "theory_description": "Conceptual processing is functionally governed by two interacting systems: Type 1 processes (fast, automatic, associative) implement prototype/exemplar similarity-based categorization; Type 2 processes (slow, deliberative) implement explicit symbolic/deductive checks using ontologies.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Cited psychological literature (Evans & Frankish; Kahneman) supporting existence of fast/slow processes; implemented in Dual-PECCS where S1 (conceptual spaces) proposes candidates and S2 (ontologies) validates them, reproducing human-like tradeoffs and errors observed in experiments.",
            "counter_evidence_or_challenges": "Architectural incorporation varies (e.g., ACT-R not natively dual-process, requiring explicit engineering); interaction heuristics (e.g., order of S1 then S2, thresholds for rejection) are design choices that may affect behavior and need empirical grounding.",
            "comparison_to_other_theories": "Provides the process-level scaffold for combining prototype/exemplar (Type 1) and classical symbolic (Type 2) representations; paper operationalizes the theory by executing S1 processes first and refining with S2, explicitly comparing outputs and inconsistencies.",
            "notable_limitations_or_open_questions": "Precise mechanisms of S1–S2 negotiation, criteria for when S2 should override S1, and how to implement these in cognitive architectures remain open; observed proxyfication errors indicate more nuanced heuristics are needed.",
            "uuid": "e3623.8",
            "source_info": {
                "paper_title": "Dual PECCS: a cognitive system for conceptual representation and categorization",
                "publication_date_yy_mm": "2017-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Conceptual Spaces: The Geometry of Thought",
            "rating": 2
        },
        {
            "paper_title": "The Psychology of Concepts: A Brief History",
            "rating": 1
        },
        {
            "paper_title": "Where is the concept? Representations, processes and neural substrates",
            "rating": 1
        },
        {
            "paper_title": "The Structure of Autobiographical Memory and Implications for Exemplar Models",
            "rating": 1
        },
        {
            "paper_title": "Cognitive Architecture and Commonsense Reasoning: On the integration of Typicality and Symbolic Representations",
            "rating": 1
        },
        {
            "paper_title": "Proxytypes and Tokenization: Prinz (2002) — The conceptual representation in the brain",
            "rating": 2
        },
        {
            "paper_title": "On the Integration of Prototypes and Exemplars in Categorization (Malt, 1989)",
            "rating": 2
        },
        {
            "paper_title": "Non-monotonic Extensions of Description Logics for Typicality (Giordano et al., 2013)",
            "rating": 2
        }
    ],
    "cost": 0.014512500000000001,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>IHIS AperTO</h1>
<h2>UNIVERSITÀ DEGLI STUDI DI TORINO</h2>
<p>AperTO - Archivio Istituzionale Open Access dell'Università di Torino</p>
<h2>Dual PECCS: a cognitive system for conceptual representation and categorization</h2>
<h2>This is a pre print version of the following article:</h2>
<p>Original Citation:</p>
<h2>Availability:</h2>
<p>This version is available http://hdl.handle.net/2318/1603656 since 2016-10-18T10:12:04Z</p>
<p>Published version:
DOI:10.1080/0952813X.2016.1198934
Terms of use:
Open Access
Anyone can freely access the full text of works made available as "Open Access". Works made available under a Creative Commons license can be used according to the terms and conditions of said license. Use of all other works requires consent of the right holder (author or publisher) if not exempted from copyright protection by the applicable law.</p>
<h1>Dual PECCS: A Cognitive System for Conceptual Representation and Categorization</h1>
<p>Antonio Lieto ${ }^{\mathrm{a}, \mathrm{b} <em>}$ Daniele P. Radicioni ${ }^{\mathrm{a} </em>}$ and Valentina Rho ${ }^{\mathrm{a} *}$<br>${ }^{a}$ University of Turin, Dipartimento di Informatica, 10149 Corso Svizzera 185, Turin, Italy;<br>${ }^{b}$ ICAR-CNR, 90128 Viale delle Scienze 12 Ed.11, Palermo, Italy</p>
<p>(Received 05 July 2015; accepted 02 June 2016)</p>
<h4>Abstract</h4>
<p>In this article we present an advanced version of Dual-PECCS, a cognitively-inspired knowledge representation and reasoning system aimed at extending the capabilities of artificial systems in conceptual categorization tasks. It combines different sorts of common-sense categorization (prototypical and exemplars-based categorization) with standard monotonic categorization procedures. These different types of inferential procedures are reconciled according to the tenets coming from the dual process theory of reasoning. On the other hand, from a representational perspective, the system relies on the hypothesis of conceptual structures represented as heterogeneous proxytypes. Dual-PECCS has been experimentally assessed in a task of conceptual categorization where a target concept illustrated by a simple common-sense linguistic description had to be identified by resorting to a mix of categorization strategies, and its output has been compared to human responses. The obtained results suggest that our approach can be beneficial to improve the representational and reasoning conceptual capabilities of standard cognitive artificial systems, and -in addition- that it may be plausibly applied to different general computational models of cognition. The current version of the system, in fact, extends our previous work, in that Dual-PECCS is now integrated and tested into two cognitive architectures, ACT-R and CLARION, implementing different assumptions on the underlying invariant structures governing human cognition. Such integration allowed us to extend our previous evaluation.</p>
<p>Keywords: Knowledge Representation, Categorization, Conceptual Spaces, Cognitive Architectures, Heterogeneous Proxytypes, ACT-R, Prototypes, Exemplars, Common-sense Reasoning, CLARION.</p>
<h2>1. Introduction</h2>
<p>In this work we present the extended version of an integrated knowledge representation system aimed at performing conceptual categorization tasks. It is named Dual-PECCS (after Prototypes and Exemplars-based Conceptual Categorization System), since it relies on two different sorts of cognitively-inspired common-sense categorization: prototypical and exemplars-based categorization. In addition, it is grounded on the theoretical tenets coming from the dual process theory of mind, and on the hypothesis of "heterogeneous proxytypes" developed in the area of the biologically inspired cognitive architectures (BICA).</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>The system aims at providing a unified framework for the conceptual categorization simulating some of the common-sense heuristic strategies exploited by humans in categorization tasks. More specifically, it integrates strategies based on prototypes and exemplars-based reasoning, as suggested by the psychological results coming form the area of experimental Cognitive Science. The current version of Dual-PECCS has been integrated and tested in the ACT-R and CLARION cognitive architectures to investigate its compatibility with the models of cognition therein implemented (Anderson et al., 2004; Langley et al., 2009; Sun, 2006). ${ }^{1}$</p>
<p>While existing systems and architectures allow to selectively perform either prototype or exemplar-based categorization rather than autonomously adapting their strategy to the input being categorized (Anderson and Betz, 2001), conversely, Dual-PECCS addresses this issue. In addition to the deployment of such common-sense categorization strategies, Dual-PECCS also provides an integration of such types of non-monotonic reasoning with the classical categorization based on standard, deductive, processes. The flow and the interaction of such diverse reasoning mechanisms have been devised based on the tenets coming from the dual process theory of reasoning, and compared to the answers provided by human subjects. In this respect, the main goal of the current system is proposing a cognitively-inspired framework for conceptual representation and categorization. Nonetheless, some preliminary results (see (Lieto et al., 2015a)) show that the resulting system also provides advances in performing common-sense categorization of linguistic descriptions compared with state-of-the-art question-answering systems (including Bing, Google and Wolfram-Alpha). However, a deeper cross-systems comparison is out of the scope of our present contribution, and is ongoing work.</p>
<p>This work is organized as follows: in Section 2 we introduce the theoretical bases inspiring our system, coming from the research in Cognitive Science. In Section 3 we start by outlining the overall architecture and describe the heterogeneous Knowledge Base adopted (Section 3.1), we then illustrate the pipeline going all throughout from the input textual description to the category in output (Section 3.2) and provide the detailed algorithms devised to implement the categorization task (Section 3.3). In Section 4 we show how the hybrid system for the conceptual categorization was integrated into ACTR and CLARION, and in Section 5 we describe the evaluation of the resulting system, by introducing the experimental setting adopted and discussing the obtained results. Finally, we elaborate on future work.</p>
<h1>2. Prototypes, Exemplars and Proxytypes</h1>
<p>In Cognitive Science different theories about the nature of concepts have been proposed. According to the traditional view, known as "classical" or Aristotelian theory, concepts can be simply defined in terms of sets of necessary and sufficient conditions. Such theory was dominant until the mid '70s of the last Century, when Rosch's experimental results demonstrated the inadequacy of such a theory for ordinary -or common-sense- concepts (Rosch, 1975). Rosch's results seemed to suggest, on the other hand, that ordinary concepts are characterized and organized in our mind in terms of prototypes. Since then, different theories of concepts have been proposed to explain different representational and reasoning aspects concerning the problem of typicality: we focus here on the proto-</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>type theory and on the exemplars theory. ${ }^{2}$ According to the prototype view, knowledge about categories is stored in terms of prototypes, i.e., in terms of some representation of the "best" instance of the category. In this view, the concept bird should coincide with a representation of a typical bird (e.g., a robin). In the simpler versions of this approach, prototypes are represented as (possibly weighted) lists of typical features. According to the exemplar view, a given category is mentally represented as set of specific exemplars explicitly stored in memory: the mental representation of the concept bird is a set containing the representation of (some of) the birds we encountered during our past experience.</p>
<p>Although these approaches have been largely considered as competing ones (since they propose different models and predictions about how we organize and reason on conceptual information), they turned out to be not mutually exclusive (Malt, 1989). Rather, they seem to succeed in explaining different classes of cognitive phenomena, such as the fact that human subjects use different representations to categorize concepts: some use exemplars, a few rely on prototypes, and often both exemplars and prototypes are employed (Smith and Minda, 1998). This distinction also has neural plausibility, as witnessed by empirical research (Squire and Knowlton, 1995). Such experimental evidences led to the development of the so called "heterogeneous hypothesis" about the nature of concepts: this approach assumes that concepts do not constitute a unitary phenomenon, and hypothesizes that different types of conceptual representations may co-exist: prototypes, exemplars, classical representations, and so on (Machery, 2009). All such representations, in this view, constitute different bodies of knowledge and contain different types of information associated to the the same conceptual entity. Furthermore, each body of conceptual knowledge is featured by specific processes in which such representations are involved (e.g., in cognitive tasks like recognition, learning, categorization, etc.). In particular prototypes and exemplars-based representations are associated with the possibility of dealing with non-monotonic strategies of reasoning and categorization, while the classical representations (i.e. that ones based on necessary and/or sufficient conditions) are associated with standard deductive mechanism of reasoning. ${ }^{3}$</p>
<p>In recent years an alternative theory of concepts has been proposed: the proxytype theory. It postulates a biological localization and interaction between different brain areas for dealing with conceptual structures, that have a direct counterpart in the distinction between long term and working memory (Prinz, 2002). Such characterization is partic-</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>ularly interesting for the explanation of phenomena such as, for example, the activation (and the retrieval) of conceptual information. In this setting, concepts are seen as proxytypes.</p>
<p>Definition 1 (Proxytypes): A proxytype is any element of a complex representational network stored in long-term memory corresponding to a particular category that can be tokenized in working memory to 'go proxy' for that category (Prinz, 2002).</p>
<p>In other terms, the proxytype theory, inspired by the work of Barsalou (Barsalou, 1999), considers concepts as temporary constructs of a given category, activated (tokenized) in working memory as a result of conceptual processing activities, such as concept identification, recognition and retrieval.</p>
<p>In its original formulation, however, proxytypes are depicted as monolithic conceptual structures, primarily intended as prototypes (Prinz, 2002). A revised view of this approach has been recently proposed in the area of BICA, hypothesizing the availability of a wider range of representation types than just prototypes (Lieto, 2014). They correspond to the kinds of representations hypothesized by the above mentioned heterogeneous approach to concepts. In this sense, proxytypes are assumed to be heterogeneous in nature (i.e., they are composed by heterogeneous networks of conceptual representations and not only by a monolithic one).</p>
<p>Definition 2 (Heterogeneous Proxytypes): Heterogeneous representations (such as prototypes, exemplars, etc.) for each conceptual category are stored in long-term memory. They can be activated and accessed by resorting to different categorization strategies. In this view, each representation has its associated accessing procedures.</p>
<p>In the design of our system we followed the approach based on heterogeneous proxytypes ${ }^{4}$ for both the representational level (that is, we devised a hybrid knowledge base composed of heterogeneous representations, each endowed with specific reasoning mechanisms) and for the 'proxyfication' (that is, the set of procedures implementing the tokenization of the different representations in working memory).</p>
<h1>3. Dual Process Architecture for Conceptual Representation and Processing</h1>
<p>As earlier mentioned, the Dual-PECCS relies -at the representational level- on the heterogeneous proxytypes approach, and it is also inspired by the dual process theory of reasoning and rationality. More in detail, Dual-PECCS is equipped with a hybrid knowledge base composed of heterogeneous representations of the same conceptual entities: that is, the hybrid knowledge base includes prototypes, exemplars and classical representations for the same concept. Such different bodies of knowledge act like semantic pointers towards the same conceptual entity (Blouw et al., 2015; Eliasmith et al., 2012; Thagard, 2012). ${ }^{5}$</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Both prototypes and exemplars are represented by adopting the conceptual spaces framework (see Section 3.1), while classical information is represented through standard symbolic formalisms (i.e., by means of a formal ontology).</p>
<p>From a reasoning perspective, instead, the retrieval of such representations is driven by different process types. In particular, prototype and exemplar-based retrieval is based on a fast and approximate kind of categorization, and benefits from defeasible, commonsense information associated to concepts. On the other hand, the retrieval of classical representation of concepts is featured by explicit rule following, and makes no use of defeasible, common-sense information. These two differing categorization strategies have been widely studied in psychology of reasoning in the frame of the dual process theory, that postulates the co-existence of two different types of cognitive systems (Evans and Frankish, 2009; Kahneman, 2011). The systems of the first type (type 1) are phylogenetically older, unconscious, automatic, associative, parallel and fast. The systems of the second type (type 2) are more recent, conscious, sequential and slow, and featured by explicit rule following. We assume that both systems can be composed in their turn by many sub-systems and processes. According to the hypotheses in (Frixione and Lieto, 2012, 2014), the conceptual representation of our system includes two main sorts of components, based on these two sorts of processes. Type 1 processes have been designed to deal with prototypes- and exemplar-based retrieval, while Type 2 processes have been designed to deal with deductive inference.</p>
<p>The two sorts of system processes interact (Algorithm 1), since Type 1 processes are executed first and their results are then refined by Type 2 processes. In the implemented system the typical representational and reasoning functions are assigned to the System 1 (hereafter $\mathcal{S} 1$ ), which executes processes of Type 1, and is associated to the conceptual spaces framework (Gärdenfors, 2000, 2014). On the other hand, the classical representational and reasoning functions are assigned to the System 2 (hereafter $\mathcal{S} 2$ ) to execute processes of Type 2, and are associated to a standard Description Logics based ontological representation.</p>
<p>Figure 1 shows the heterogeneous representation for the concept tiger, with prototypical and exemplar-based representations semantically pointing to the same conceptual entity. In this example, the exemplar and prototype-based representations make use of non classical (or typical) information. Namely, the prototypical representation grasps information such as that tigers are wild animals, their fur has yellow and black stripes, etc.; the exemplar-based representations grasp information on individuals. For example, in Fig. 1 is represented an individual of white-tiger, which is a particular type of tiger with white fur. ${ }^{6}$ Both sorts of representations activate Type 1 processes. On the other hand, the classical body of knowledge is filled with necessary and sufficient information to characterize the concept (representing, for example, the taxonomic information that a tiger is a mammal and a carnivore), and activates Type 2 processes. For the sake of readability the information in Figure 1 is visualized with a uniform format, even though the different representations are actually encoded in different formalisms.</p>
<p>In the following we introduce the two representational and reasoning frameworks adopted in our system, by focusing $i$ ) on how typicality information (including both prototypes and exemplars) and their corresponding non-monotonic reasoning procedures</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1.: Heterogeneous representation of the tiger concept in the hybrid knowledge base.
can be encoded through conceptual spaces; and $i i$ ) on how classical information can be naturally encoded in terms of formal ontologies.</p>
<h1>3.1. $\mathcal{S} 1-\mathcal{S} 2$ : Conceptual Spaces and Ontologies</h1>
<p>Conceptual spaces (CS) are a representational framework where knowledge is represented as a set of quality dimensions, and where a geometrical structure is associated to each quality dimension. ${ }^{7}$ In this setting, concepts correspond to convex regions, and regions with different geometrical properties correspond to different sorts of concepts (Gärdenfors, 2000). In addition, concepts are characterized in terms of domains; a domain is "a set of integral dimensions that are separable from all other dimensions" (Gärdenfors, 2014). Typical domain examples are color, size, shape, texture. In turn, domain information can be specified along some dimensions: e.g., in the case of the color domain, relevant dimensions are hue, chromaticity, and brightness.</p>
<p>Prototypes are geometrically interpreted in conceptual spaces, in that they correspond to the geometrical centre of a convex region. This can be thought of as a centroid, that is the mean position of all the points in all dimensions. This representation also allows</p>
<p><sup id="fnref6:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>us, given a convex region, to associate each point to a certain centrality degree, that can be interpreted as a measure of its typicality. Instances can be represented as points in a multidimensional space, and their similarity can be computed as the intervening distance between each two points, based on some suitable metrics. ${ }^{8}$ This framework has been employed also to represent exemplars, that are modelled as points in the multidimensional space. In general, conceptual spaces can be used to compute the proximity between any two entities, and between entities and prototypes. In order to compute the distance between two points $p_{1}, p_{2}$ we use Euclidean metrics to calculate within-domain distance, while for dimensions from different domains we use the Manhattan distance metrics, as suggested in (Adams and Raubal, 2009; Gärdenfors, 2000). The weighted Euclidean distance $\operatorname{dist}_{E}$ is computed as follows</p>
<p>$$
\operatorname{dist}<em 1="1">{E}\left(p</em>
$$}, p_{2}\right)=\sqrt{\sum_{i=1}^{n} w_{i}\left(p_{1, i}-p_{2, i}\right)^{2}</p>
<p>where $i$ varies over the $n$ domain dimensions and $w_{i}$ are dimension weights.
In our implementation of conceptual spaces we represent points as vectors (with as many dimensions as required by the considered domain), whose components correspond to the point coordinates, so that a natural metrics to compute the similarity between them is cosine similarity. In this perspective two vectors with same orientation have a cosine similarity 1 , while two orthogonal vectors have cosine similarity 0 . The normalized version of cosine similarity ( $\hat{cs}$ ), also accounting for the above weights $w_{i}$ is computed as</p>
<p>$$
\hat{c s}\left(p_{1}, p_{2}\right)=\frac{\sum_{i=1}^{n} w_{i}\left(p_{1, i} \times p_{2, i}\right)}{\sqrt{\sum_{i=1}^{n} w_{i}\left(p_{1, i}\right)^{2}} \times \sqrt{\sum_{i=1}^{n} w_{i}\left(p_{2, i}\right)^{2}}}
$$</p>
<p>In the metric space we have defined, the distance between an individual and prototypes is computed with the Manhattan distance metrics. The distance between two concepts can be computed as the distance between two regions: namely, we can compute the distance between their prototypes, or the minimal distance between their individuals ${ }^{9}$, or we can apply more sophisticated algorithms. Further details about technical issues can be found in (Ghignone et al., 2013).</p>
<p>Optionally, a context $k$ can be defined as a set of weights, to grade the relative relevance of the considered dimensions -thus resulting in the following formulas: $\operatorname{dist}<em 1="1">{E}\left(p</em>, k\right)$ from Eq. 1 and 2, respectively-, and to adapt the computation to a variety of settings, such as, e.g., default values vs. known values, explicitly asserted values $v s$. computed values and/or inherited, etc.. Although it is widely accepted that context plays a major role in considering similarity issues (both in human judgements and in computational models), presently our similarity metrics does not involve contextually}, p_{2}, k\right)$ and $\hat{c s}\left(p_{1}, p_{2</p>
<p><sup id="fnref7:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>weighted dimensions, nor tunable metrics, such as those devised in (Aisbett and Gibbon, 1994). These aspects represent an interesting enhancement that we defer to future work. However, it is worth noting that linguistic context, also known as discourse context which is the focus of the present work- is implicitly accounted for by Dual-PECCS categorization strategy: in our setting we consider as contextually relevant elements only those explicitly expressed in the input description. The explicit elements of the discourse structure are therefore at the base of our notion of context: this implies that we compute similarity (between the stimulus and the representations in the hybrid knowledge base, see Figure 1) by considering only dimensions whose values are explicitly expressed in the linguistic descriptions.</p>
<p>The internal representation format for handling conceptual spaces has been introduced in (Lieto et al., 2014); we briefly recall it for the sake of self-containedness. Although the format has been developed by attempting to keep it as general as possible (so to extend its usage to further domains), the current implementation has been devised based on specific representational needs described in Section 5. The basic representational structure processed by the system is named genericDescription; it is actually a super-domain that hosts information about both physical and non physical features, arranged into nine further domains, such as size, shape, color, location, feeding, locomotion, hasPart, partOf, manRelationship.</p>
<p>To give an example of the conceptual spaces representation, let us consider the size domain: the size of entities is expressed through the three Euclidean dimensions; the shape allows expressing that an object has circular, square, spherical, cubic, etc., shape. The color space maps object's features onto the three dimensional $\mathrm{L}^{<em>} \mathrm{a}^{</em>} \mathrm{~b}^{<em>}$ color space, in the same spirit as drawn by Gärdenfors in (Gärdenfors, 2000): in particular, in $\mathrm{L}^{</em>} \mathrm{a}^{<em>} \mathrm{~b}^{</em>}$ terms $\mathrm{L}^{<em>}(0 \leq \mathrm{L} \leq 100)$ is the correlate of lightness, $\mathrm{a}^{</em>}(-128 \leq \mathrm{a} \leq 127)$ is the chromaticity axis ranging from green to red, and $\mathrm{b}^{*}(-128 \leq \mathrm{b} \leq 127)$ is the chromaticity axis ranging from blue to yellow. The location domain indicates the place or the environment where the object being modeled can be typically found. It actually results from the combination of five dimensions, and namely: humidity, indicated as a percentage; temperature, ranging in $\left[-40^{\circ}, 50^{\circ}\right]$; altitude, ranging in $[-11000,8848]$; vegetation, ranging in $[0,100]$; time. In turn, time contains a partitioning of the hours of the day into sunrise (4-6 AM), morning (6-12 AM), afternoon (12-5 PM), evening (5-10 PM) and night (10 PM-4 AM). The locomotion domain combines two dimensions: the former dimension is used to account for the type of movement (1: swim, 2: dig, 3: crawl, 4: walk, 5: run, 6: roll, 7: jump, 8: fly), and the latter one is used to account for the speed, expressed in km/h (Bejan and Marden, 2006). The hasPart and partOf domains are used to complement the analogous ontological properties: in particular, we collected information about the following dimensions: name, number, and partSize, partColor that are intended to specialize the above illustrated spaces.</p>
<p>A simplified example of the lion prototype information is reported below.</p>
<div class="codehilite"><pre><span></span><code><span class="nt">&lt;object</span><span class="w"> </span><span class="na">name=</span><span class="s">&quot;lion&quot;</span><span class="nt">&gt;</span>
<span class="w">    </span><span class="nt">&lt;genericPhysicalDescription&gt;</span>
<span class="w">    </span><span class="nt">&lt;size</span><span class="w"> </span><span class="na">name=</span><span class="s">&quot;lion_size&quot;</span><span class="nt">&gt;</span>
<span class="w">        </span><span class="nt">&lt;x&gt;</span>70<span class="nt">&lt;/x&gt;</span>
<span class="w">        </span><span class="nt">&lt;y&gt;</span>120<span class="nt">&lt;/y&gt;</span>
<span class="w">        </span><span class="nt">&lt;z&gt;</span>200<span class="nt">&lt;/z&gt;</span>
<span class="w">    </span><span class="nt">&lt;/size&gt;</span>
<span class="w">    </span><span class="nt">&lt;color</span><span class="w"> </span><span class="na">name=</span><span class="s">&quot;beige&quot;</span><span class="nt">&gt;</span>
<span class="w">        </span><span class="nt">&lt;l&gt;</span>63<span class="nt">&lt;/l&gt;</span>
<span class="w">        </span><span class="nt">&lt;a&gt;</span>13<span class="nt">&lt;/a&gt;</span>
<span class="w">        </span><span class="nt">&lt;b&gt;</span>32<span class="nt">&lt;/b&gt;</span>
<span class="w">    </span><span class="nt">&lt;/color&gt;</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="nt">&lt;location</span><span class="w"> </span><span class="na">name=</span><span class="s">&quot;savanna&quot;</span><span class="nt">&gt;</span>
<span class="w">    </span><span class="nt">&lt;humidity&gt;</span>50<span class="nt">&lt;/humidity&gt;</span>
<span class="w">    </span><span class="nt">&lt;temperature&gt;</span>40<span class="nt">&lt;/temperature&gt;</span>
<span class="w">    </span><span class="nt">&lt;altitude&gt;</span>100<span class="nt">&lt;/altitude&gt;</span>
<span class="w">    </span><span class="nt">&lt;vegetation&gt;</span>50<span class="nt">&lt;/vegetation&gt;</span>
<span class="nt">&lt;/location&gt;</span>
<span class="nt">&lt;locomotion</span><span class="w"> </span><span class="na">name=</span><span class="s">&quot;walk&quot;</span><span class="nt">&gt;</span>
<span class="w">    </span><span class="nt">&lt;movement&gt;</span>4<span class="nt">&lt;/movement&gt;</span>
<span class="w">    </span><span class="nt">&lt;speed&gt;</span>10<span class="nt">&lt;/speed&gt;</span>
<span class="nt">&lt;/locomotion&gt;</span>
<span class="nt">&lt;locomotion</span><span class="w"> </span><span class="na">name=</span><span class="s">&quot;run&quot;</span><span class="nt">&gt;</span>
<span class="w">    </span><span class="nt">&lt;movement&gt;</span>5<span class="nt">&lt;/movement&gt;</span>
<span class="w">    </span><span class="nt">&lt;speed&gt;</span>40<span class="nt">&lt;/speed&gt;</span>
<span class="nt">&lt;/locomotion&gt;</span>
<span class="nt">&lt;/genericPhysicalDescription&gt;</span>
<span class="nt">&lt;/object&gt;</span>
</code></pre></div>

<p>On the other hand, the representation of the classical information regarding a given concept is demanded to classical ontological formalizations. Although relevant efforts have been made in the Description Logics community to enhance the ontological representation and reasoning capacities with the design of formalisms endowing types of typical representation and non-monotonic inference (Giordano et al., 2013), nonetheless the problem of representing and reasoning on typicality remains computationally expensive and practically intractable, and therefore of limited interest for concrete applications (Frixione and Lieto, 2012). ${ }^{10}$ Formal ontologies, then, provide the characterization of concepts in terms of necessary and sufficient conditions (if these conditions exists: as mentioned, most common-sense concepts cannot be characterized in these terms). In our implementation, the ontological representation adopted by the $\mathcal{S} 2$ component is grounded on the OpenCyc ontology, one of the widest ontological resources currently available containing more than 230,000 concepts.</p>
<h1>3.1.1. On the Entity Mapping in Heterogeneous Resources</h1>
<p>A relevant issue we face is aligning knowledge resources based on different sorts of representational formalisms. Although many efforts have been recently invested in the ontology mapping task (Euzenat et al., 2007; Shvaiko and Euzenat, 2013), in the present setting a different effort is required by knowledge bases that are as diverse as conceptual spaces and ontologies.</p>
<p>Under an architectural perspective, $\mathcal{S} 1$ and $\mathcal{S} 2$ rely on knowledge bases encoded in different ways, which need to be connected and mapped onto a shared and uniform representation of meaning in order to allow the ACT-R and CLARION layers to operate them. A rather common approach is to provide entities with sense identifiers, such as WordNet or BabelNet identifiers. WordNet (WN) is a lexical database for the English language (Miller, 1995). Different from common dictionaries -organizing terms alphabetically, but possibly scattering senses- it relies on the idea of grouping terms into synonyms sets (called synsets), that are equipped with short definitions and usage examples. Such sets are represented as nodes of a large semantic network, where the intervening edges represent a number of semantic relations among synset elements (such as hyponymy, hypernymy, antonymy, meronymy, holonymy). BabelNet is a widecoverage multilingual semantic network resulting from the integration of lexicographic</p>
<p><sup id="fnref8:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">TOTAL</th>
<th style="text-align: center;">MAPPED</th>
<th style="text-align: center;">$\%$ SUCCESS</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Wikipedia links</td>
<td style="text-align: center;">19,876</td>
<td style="text-align: center;">7,698</td>
<td style="text-align: center;">38.7</td>
</tr>
<tr>
<td style="text-align: left;">WordNet 2.1 links</td>
<td style="text-align: center;">8,779</td>
<td style="text-align: center;">5,197</td>
<td style="text-align: center;">59.2</td>
</tr>
<tr>
<td style="text-align: left;">total num of classes</td>
<td style="text-align: center;">27,823</td>
<td style="text-align: center;">12,723</td>
<td style="text-align: center;">45.7</td>
</tr>
</tbody>
</table>
<p>Table 1.: Summary of the automatic mapping of OpenCyc classes onto WordNet 3.0 synset IDs.
and encyclopedic knowledge from WordNet and Wikipedia (Navigli and Ponzetto, 2010); it extends the constructive rationale of WN -based on sets of synonyms- through the structure of Wikipedia composed of redirect pages, disambiguation pages, internal links, inter-language links, and categorical information. More on the algorithm used to build BabelNet can be found in (Navigli and Ponzetto, 2012).</p>
<p>Entities represented in the conceptual spaces domains, processed by $\mathcal{S} 1$, are provided with WordNet synset IDs; on the other side, classes in $\mathcal{S} 2$ are featured by Cyc IDs. The linking between such identifiers is presently managed through a mapping table. It turns out, then, that the mapping process is a crucial one in order to practically handle the considered resources; a more detailed account on such anchoring aspects is provided in Section 3.1.2. Our mapping proceeded by considering that about $20 \%$ classes in OpenCyc contain references to external knowledge bases (KBs) such as WordNet 2.1 and Wikipedia. The automatically extracted mappings have been computed by following the references in OpenCyc towards BabelNet and WordNet, which produced as output about 13, 000 new associations. Namely, linking information in OpenCyc can be arranged in two classes:</p>
<ul>
<li>Wikipedia Links. A subset of classes in OpenCyc are provided with references to Wikipedia pages. Such references can be directly mapped onto a BabelSynset (in turn providing a pointer to the WordNet synset ID); each link from a BabelNet ID to a WordNet ID has been added to our mapping table. The steps to perform this kind of mapping were: [OpenCyc Class] $\rightarrow$ [BabelSynset ID] $\rightarrow$ [WordNet 3.0 ID].</li>
<li>WordNet 2.1 Links. A subset of classes in OpenCyc contain a link to the online WordNet 2.1 APIs, whose IDs can be directly converted into WN 3.0 IDs through the SenseMap library. ${ }^{11}$ The synset name has then been converted into a numeric ID through the online WordNet 3.0 APIs, and added to the mapping table. The steps to perform this kind of mapping were: [OpenCyc Class] $\rightarrow$ [WordNet 2.1 SynsetName] $\rightarrow$ [WordNet 3.0 SynsetName] $\rightarrow$ [WordNet 3.0 ID].</li>
</ul>
<p>Table 1 illustrates some figures about the mapping of Wikipedia links and WordNet links, by showing how many links were found in OpenCyc, and how many of them could be mapped onto WN synset IDs. We observed that $i$ ) sometimes Cyc classes are linked to several WN synsets; and $i i$ ) in some cases such links are not precise, mostly due to the differing granularity of the information contained in the KB involved in the mapping process.</p>
<p>At the current stage of development, although the entities described through the conceptual spaces used by $\mathcal{S} 1$ module require being substantially enriched, the mapping procedure allows handling some $13 K$ descriptions.</p>
<p><sup id="fnref9:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h4>3.1.2. On Mapping Conceptual Spaces and Ontological Representations</h4>
<p>As above mentioned, an important aspect related to the proposed artificial architecture for conceptual systems regards the way in which the different kinds of representations (i.e., the symbolic structures of the ontological representation and the corresponding underlying conceptual space representations) are mapped one to another. We dealt with this problem by anchoring both the representations at the level of the general concept enveloping them. The heterogeneous proxytypes approach, in fact, requires the existence of co-referring representational structures where the different bodies of knowledge are assumed to semantically point to the main reference conceptual container (see Figure 1). In our approach such a container has been automatically provided with a WordNet synset identifier. In addition, also the corresponding pointing representations (conveying the different types of conceptual knowledge) have been equipped with the same WordNet synset ID.</p>
<p>The anchoring mechanism between the representations follows two different ways. The first one corresponds to the mapping between the general concept and its related ontological component (S2 mapping). This mapping is already provided in the OpenCyc ontology, which is sometimes equipped with the information regarding the corresponding WordNet synset ID. On the other hand, the anchoring between the conceptual space representations and the corresponding general concept (S1 mapping) is obtained as follows: the linguistic elements extracted through an Information Extraction step (please refer to Section 3.2) are automatically equipped with the corresponding WordNet synset ID, if any. After this process, DUAL-PECCS inspects the Conceptual Spaces Knowledge Base searching for the elements corresponding to the extracted linguistic entities. This process is presently based on a simple string-matching between the names of the extracted linguistic entities and the names of the concepts available in the Conceptual Spaces. Once this mapping is provided, the WordNet synset ID assigned to the extracted linguistic entities is transferred to the corresponding representation in the Conceptual Spaces. Finally, the ID obtained in Conceptual Spaces is linked to the WN synset ID already associated to the general concept.</p>
<p>Interestingly, this approach could be easily extended to visual categorization systems by adding, to the whole networks of heterogeneous representations, the ImageNet identifiers (Deng et al., 2009). In the context of artificial vision and robotic applications there are proposals similar to our approach. In particular, the works in (Chella et al., 1997, 2003) also provides a mapping between different levels of representations, including conceptual spaces and symbolic representations. In this case, anchoring is performed for static and dynamic visual scenes. In particular, in the case of dynamic scenes it is based on an anchoring function defined from time t to couple assertions (formulas for the Situation Calculus) and Conceptual Space structures by using look-up tables. The main similarity with their approach by (Chella et al., 1997) is that also our model is primarily focused on the representational issue of the anchoring problem, and does not consider the procedural one (on these aspects, please refer to (Coradeschi and Saffiotti, 2000)). Conversely, the main difference w.r.t. their approach is that we adopt externally developed and well known resources for providing the linguistic anchoring (such as WordNet). This allows our system a good level of compatibility and interoperability with other language technologies adopting the same resources. In the next sections we present the details regarding the categorization strategies adopted in the DUAL-PECCS.</p>
<p>Data: Linguistic description $d$
Result: A class assignment, as computed by $\mathcal{S} 1$ and $\mathcal{S} 2$
trialCounter $\leftarrow 0$;
closed ${ }^{\mathcal{S} 1}={\emptyset}$
while trialCounter $&lt;$ maxTrials do
// conceptual spaces output
$\mathrm{c} \leftarrow \mathcal{S} 1\left(d\right.$, closed $\left.{ }^{\mathcal{S} 1}\right)$
if trialCounter $==0$ then $\mathrm{c}^{<em>} \leftarrow \mathrm{c}$;
// ontology based consistency check
$\mathrm{cc} \leftarrow \mathcal{S} 2(d$, conceptPointedBy(c));
if cc equals(conceptPointedBy(c)) then
return $\left\langle\mathrm{c}^{</em>}, \mathrm{cc}\right\rangle$
else
closed ${ }^{\mathcal{S} 1}$ add(conceptPointedBy(c))
end
++ trialCounter ;
end
$\mathrm{cc} \leftarrow \mathcal{S} 2(\langle d$, Thing $\rangle)$;
return $\left\langle\mathrm{c}^{*}, \mathrm{cc}\right\rangle$
Algorithm 1: The $\mathcal{S} 1-\mathcal{S} 2$ categorization process.</p>
<h1>3.2. Categorization Pipeline of the Dual-PECCS</h1>
<p>The whole categorization pipeline implemented by Dual-PECCS works as follows. The input to the system is a simple linguistic description, like 'The animal that eats bananas', and the expected output is a given category evoked by the description (e.g., the category monkey in this case). After an Information Extraction (IE) step, the input information is encoded into an internal format devised to store conceptual spaces information, which is then used as input in the categorization task by adopting the strategies that will be described below.</p>
<p>A shallow IE approach has been devised, where the morphological information computed from input sentences has been used to devise a simple finite-state automaton describing the input sentences' structure (more on the input descriptions in Section 5). This approach would not scale to handle more complex sentences; its limitations are due to using morphological information, and in general are inherent in finite-state machines (which prevents us from dealing with parenthetical clauses, like relative clauses). We defer to future work the adoption of richer language models. Despite these limitations, however, it allowed us to complete the automatization of the software pipeline going all throughout from the simple linguistic input description used for the evaluation (that will be described later) to its final conceptual categorization.</p>
<h3>3.3. Dual Process Categorization</h3>
<p>The overall control strategy implemented by Dual-PECCS governs the flow of interaction between the $\mathcal{S} 1$ and $\mathcal{S} 2$ systems (it is thus referred to as $\mathcal{S} 1-\mathcal{S} 2$ categorization). Its underlying rationale is to assess the approximate categorization results obtained by Type 1 processes in $\mathcal{S} 1$ with the ontological information and the deliberative processes of reasoning implemented by $\mathcal{S} 2$. The $\mathcal{S} 1-\mathcal{S} 2$ categorization process can be summarized as follows (Algorithm 1). The system takes in input a textual description $d$ and produces in</p>
<p>Data: Linguistic description: $d$; list of inconsistent concepts: closed ${ }^{\mathcal{S} 1}$.
Result: A typicality based representation of a category.
$1 \mathcal{S} 1_{\mathrm{EX}} \leftarrow$ categorizeExemplars $(d)$;
2 if firstOf $\left(\mathcal{S} 1_{\mathrm{EX}}\right.$, closed $\left.{ }^{\mathcal{S} 1}\right)$.distance $(d)&lt;$ similarityThreshold then
3 return firstOf $\left(\mathcal{S} 1_{\mathrm{EX}}\right.$, closed $\left.{ }^{\mathcal{S} 1}\right)$;
4 else
$5 \mathcal{S} 1_{\mathrm{PR}} \leftarrow$ categorizePrototypes $(d)$;
// in case of equal distance prefer exemplars
6 typicalityCategorization $\leftarrow$ sortResults $\left(\mathcal{S} 1_{\mathrm{EX}}, \mathcal{S} 1_{\mathrm{PR}}\right)$;
7 return firstOf (typicalityCategorization, closed ${ }^{\mathcal{S} 1}$ );
8 end
Algorithm 2: $\mathcal{S} 1$ categorization with prototypes and exemplars implementing the instruction in Algorithm 1: line 4.
output a pair $\left\langle\mathrm{c}^{<em>}, \mathrm{cc}\right\rangle$, the output of $\mathcal{S} 1$ and $\mathcal{S} 2$, respectively. If the categorization result provided by $\mathcal{S} 1$ (based on the similarity calculation between the input and $\mathcal{S} 1$ representations) is consistent with the ontology, then the categorization succeeded and the category provided by $\mathcal{S} 2$ (cc) is returned along with $\mathrm{c}^{</em>}$, the top scoring class returned by $\mathcal{S} 1$. Otherwise the system evaluates a fixed amount (maxTrials) of $\mathcal{S} 1$ candidates, meantime keeping track of the inconsistent elements that are added to the closed ${ }^{\mathcal{S} 1}$ list. In case all the $\mathcal{S} 1$ candidates are inconsistent w.r.t. the ontology in $\mathcal{S} 2$, the output of $\mathcal{S} 2$, computed independently of $\mathcal{S} 1$, is provided along with $\mathrm{c}^{*}$. The control strategy implements a tradeoff between ontological inference and the output of $\mathcal{S} 1$, which is more informative but also formally less reliable. ${ }^{12}$</p>
<p>The $\mathcal{S} 1$ categorization algorithm implements the instruction in Algorithm 1, line 4 by determining which kind of $\mathcal{S} 1$ output must be selected and then checked against the deliberative $\mathcal{S} 2$ module (Algorithm 2). In particular, the algorithm is designed to activate either the prototypical-based or the exemplar-based representation, according to the actual input description. The implemented procedure works as follows: when the input stimulus -in our case a simple linguistic description- is similar enough to an exemplar representation (a threshold has been fixed to these ends), the corresponding exemplar of a given category is retrieved. Otherwise, the prototypical representations are also scanned and the representation (prototype or exemplar) that is closest to the input is returned. By following a preference that has been experimentally observed in human cognition (Medin and Schaffer, 1978), this algorithm favors the results of the exemplars-based categorization if the knowledge-base stores any exemplars similar to the input being categorized.</p>
<h1>4. Integrating Dual-PECCS into ACT-R and CLARION</h1>
<p>The proposed system has been integrated into two of the most widely known cognitive architectures: ACT-R (Anderson et al., 2004) and CLARION (Sun, 2006). The underlying rationale behind such integration efforts is to investigate whether our approach is</p>
<p><sup id="fnref10:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>compatible with architectures implementing different cognitive theories of mind; in this case, it can be considered a candidate general framework for representing and reasoning on conceptual information, and eventually tested with even further architectures.</p>
<p>One main difference between the two architectures is that CLARION natively assumes the perspective of the dual process theory; ACT-R, on the other hand, is not natively dual process based. Therefore, in the latter architecture, the dual mechanisms of reasoning need to be explicitly designed and implemented instantiated within an already existing general framework. In particular, in ACT-R cognitive mechanisms emerge from the interaction of two types of knowledge: the declarative knowledge, that encodes explicit facts that the system knows, and the procedural knowledge, that encodes rules for processing declarative knowledge. The declarative module is used to store and retrieve pieces of information called chunks, that are featured by a type and a set of attributevalue pairs, similar to frame slots. Finally, the central production system connects these modules by using a set of IF-THEN production rules.</p>
<p>Differently, in CLARION, cognitive processes are mainly subject to the activity of two sub-systems, called Action Centered Sub-system (ACS) and the Non-Action Centered Sub-system (NACS). Both sub-systems store information using a two-layered architecture, i.e., they both include an explicit and an implicit level of representation. The working memory, acting as temporary storage for decision making, is a part of the ACS, which also maintains the active behavior strategies. To hold general knowledge, the NACS provides a semantic memory consisting of both a rule-based layer that encodes explicit, symbolic knowledge, and of an underlying distributed layer with implicit, subsymbolic representations. A rule in CLARION connects a condition, encoded as a chunk, with an action, encoded as another chunk. For both architectures we mainly focused on the Declarative Memory and Working Memory, and on the corresponding retrieval mechanisms (Figure 2).</p>
<p>Besides, the dual process strategies of concept categorization have been integrated into the ACT-R and CLARION processes and connected to the retrieval request executed in the Working Memory. More in detail: in the Extended Declarative Memory (equivalent to its counterpart, NACS, in CLARION) every concept is represented as an empty chunk (that is, a chunk having no associated information, except for its WordNet synset ID and a human readable name), referred to by the external bodies of knowledge (prototypes and exemplars) acting like semantic pointers. The novel dual process-based categorization mechanism triggers both the $\mathcal{S} 1$ categorization and the $\mathcal{S} 1-\mathcal{S} 2$ categorization procedures. In this setting, when the categorization result of $\mathcal{S} 1$ is returned, the representation activated in the Extended Declarative Long-Term Memory is proxyfied (i.e., recalled to the working memory, see Algorithm 1, line 4) in order to perform the $\mathcal{S} 2$ consistency check (Algorithm 1, line 6), in the dual process perspective.</p>
<p>As regards as the ACT-R implementation, we have integrated our hybrid knowledge base directly into the declarative memory, differently from other approaches that have extended the knowledge capabilities of ACT-R based on the introduction of a new, $a d$-hoc, external module of declarative memory (Oltramari and Lebiere, 2012; Salvucci, 2014). We designed a novel retrieval request implementing the $\mathcal{S} 1-\mathcal{S} 2$ categorization mechanism by extending the repertoire of the retrieval buffer through a new action (symbolized by the operator $\$$ ). Such action allows a direct access to the heterogeneous information represented by the $\mathcal{S} 1-\mathcal{S} 2$ external bodies of knowledge. ${ }^{13}$ We designed two types of $\$$</p>
<p><sup id="fnref11:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2.: ACT-R Architecture with the used memory slots in dotted frames (top), adapted from (Anderson et al., 2004); CLARION cognitive architecture with the working memory and the declarative memory emphasized through shaded frames (bottom), adapted from (Sun, 2007).</p>
<p>Requests that are executed according to the specific type of request received from the exception of some slots—that need to be explicitly indicated by the programmer—for which it is possible to exploit values similarly); conversely, our approach implements a similarity-based retrieval over all the considered dimensions, which is aimed at providing as result the element minimizing the distance from the input query.</p>
<p>retrieval buffer: the approximate categorization request and the consistency request. The approximate categorization request is activated when the retrieval request is generic: i.e., the request chunk lacks of the concept type (the concept_id slot set to nil), that in this kind of request needs to be retrieved. This task is similar to the open request that is possible to execute in ACT-R (Thomson et al., 2014), like in the following example.</p>
<div class="codehilite"><pre><span></span><code>$retrieval&gt;
    concept_id nil
    family_1_name felin
    haspart_1_name fur
    haspart_1_color_1_name yellow
    haspart_1_color_1_1 80.0
    haspart_1_color_1_a -20.0
    haspart_1_color_1_b 94.0
    haspart_2_name stripe
    haspart_2_color_1_name black
    haspart_2_color_1_1 0.0
    haspart_2_color_1_a 0.0
    haspart_2_color_1_b 0.0
    [...]
</code></pre></div>

<p>This kind of request triggers the $\mathcal{S} 1$ retrieval system, and its output is a chunk-like translation of the exemplar or the prototype resulting from the execution of the $\mathcal{S} 1$ retrieval on the typicality-based knowledge. We used the conceptual finsts, by building on the notion of declarative finsts (Pylyshyn, 1989) delivered in ACT-R, to keep track of the representations that have been recently retrieved by the system $\mathcal{S} 1$. In our implementation, conceptual finsts allow $\mathcal{S} 1$ to exclude the elements already inspected and found inconsistent, by adding them to the closed ${ }^{\mathcal{S} 1}$ list. On the other hand, if the $\$$ request specifies the concept to which it refers (i.e., the $\$$ request chunk contains a filler for the concept_id slot), then we are dealing with a consistency check request, to be sent to the $\mathcal{S} 2$ system: in this case, we convert the request and redirect it to the $\mathcal{S} 2$ system that checks whether the features of the chunk are compatible with the proposed classification. The output of this request is a chunk where the slot concept_id is filled with the conceptual representation resulting from $\mathcal{S} 2$.</p>
<p>The integration at the representational and reasoning level in CLARION followed the same rationale indicated in ACT-R, but has been adapted to the specific requirements of the architecture. In particular, we adopted both implicit and explicit representational layers provided by the NACS in order to create a direct mapping with our hybrid architecture: $\mathcal{S} 1$ (and its typicality-based information represented with conceptual spaces) has been mapped onto the implicit layer, while $\mathcal{S} 2$ (the classical, ontology-based representation), has been mapped onto the explicit one. The mapping between the sub-symbolic module of CLARION and the dimension-based representations of the conceptual spaces has been favored since such architecture also synthesizes the implicit information in terms of dimensions-values slots. The dual process based categorization mechanisms have been implemented based on the following procedure: every request is encoded in working memory as a particular type of instance (instance chunk). The dimensions and values of every instance chunk are filled through an update of the implicit module with the information extracted from the external stimulus (in the present case a linguistic description). After building the chunk request, a retrieval request is executed on the $\mathcal{S} 1$ knowledge base with the aim at retrieving an exemplar or a prototype-based representation. Such result is stored in working memory, and checked, as previously illustrated, with the knowledge of the external $\mathcal{S} 2$ knowledge base (the Cyc ontology in our case). More specifically, the</p>
<p>categorization process starts in CLARION when an instance chunk is built and added to the working memory; such process is executed in the ACS module, and it is arranged as a series of rounds, each producing a query to the implicit $\mathcal{S} 1$ component and to the explicit $\mathcal{S} 2$ module. The ACS module initializes the input layer of the $\mathcal{S} 1$ module, based on the instance chunk being considered. This initialization requires to handle external stimuli (the world) along with internal information, at disposal of CLARION agents. Let us start from the sensory input space: this space represents the agent's percepts, and is encoded as a set of pairs $\langle$ dimension,value $\rangle$. Populating the sensory input space (and therefore building the instance chunk for the request to be sent to the NACS declarative memory) involves adding the appropriate set of $\langle$ dimension,value $\rangle$ pairs (when such information, extracted from the input stimuli, is available). Filling a value of a dimension in CLARION is based on the sub-symbolic activation of that dimension when the external input is processed.</p>
<p>In our implementation the available dimensions that a chunk can assume is based on the set of dimensions defined in (Lieto et al., 2015b) for the encoding of conceptual spaces (therefore the internal information that CLARION can process is fixed). It is worth nothing that the activated chunk can lack of some information (i.e., a dimension not filled with its corresponding value), since by definition percepts include noisy or partially missing information.</p>
<p>When the instance chunk is formed a request to the implicit $\mathcal{S} 1$ component is called. The output will be either a chunk representing a prototype or an exemplar representation, corresponding to the prototype/exemplar returned by $\mathcal{S} 1$. Such intermediate result is then added to the working memory for the consistency check, which is performed by the explicit module. In turn, the explicit module tests the consistency of the instance chunk recently added to the Working Memory: if the instance chunk is consistent with the ontological knowledge base, then the explicit module returns the concept chunk corresponding to the output of $\mathcal{S} 1$, thus implementing the notion of proxyfication; otherwise, a special chunk is returned to indicate that an inconsistency was detected. In this case the explicit module evaluates the next result returned by the implicit module, and the whole $\mathcal{S} 1-\mathcal{S} 2$ process is iterated until a representation consistent with the KB is found (as illustrated in Algorithm 1: line 3), or by exiting with a failure in case the maximal number of rounds is reached (Algorithm 1: line 14).</p>
<p>In the next sections we present and discuss some results obtained by the system.</p>
<h1>5. Evaluation</h1>
<p>A dataset composed of 112 descriptions (corresponding to very simple riddles), was collected and given in input to the implemented system: namely, we selected 56 descriptions for which an exemplar-based representation was expected to be retrieved, and 56 descriptions for which a prototype-based representation was expected to be retrieved. This experimentation extends a previous one, presented in (Lieto et al., 2015c). These stimuli have been built by a multidisciplinary team composed of neuropsychologists, linguists and philosophers in the frame of a project aimed at investigating the brain activation of visual areas in tasks of lexical processing even for very abstract concepts. An example of such descriptions is "The big carnivore with yellow fur and black stripes", where the expected category to be retrieved was tiger, and in particular its representation corresponding to the "prototype of tiger"; conversely, a description such as "The big carnivore with white</p>
<p>fur and black stripes" was expected to lead as answer to "exemplar of white_tiger". ${ }^{14}$
The expected categorical targets represent a gold standard, since they correspond to the results provided by human subjects in a twofold psychological experimentation. In the first experiment, 30 healthy volunteers ( 16 females and 14 males) were recruited for the experiment from the Computer Science and Psychology Departments of the University of Turin. Participants were all naïve to the experimental procedure and to the aims of the study. Participants were asked to perform an inferential task "Naming from definition": the subjects were presented the stimuli and asked to overtly name, as accurately and as fast as possible, the target concept corresponding to the definition, using a microphone connected to a response box. The stimuli were presented through the E-Prime software, which was also used to record data on accuracy and reaction times; a richer account of this experimentation is provided in (Radicioni et al., 2015). An additional experimentation has been run on a dataset also including exemplar-based representations along with prototype-based representations. In this case, 10 subjects ( 4 females and 6 males) were recruited among PhD students and Postdoc fellows from the Computer Science Department of the University of Turin. As for the previous experiment, participants were all naïve to the experimental procedure and to the aims of the study. The experimental design was borrowed from the third experiment described in (Malt, 1989): subjects underwent a training phase where exemplar information was also explicitly taught. For example, for the concept tiger they were presented an exemplar of siberian_tiger, an exemplar of malaysian_tiger and a prototypical tiger. After the training phase they were asked to perform the same inferential task "Naming from definition", by naming not only the target concept corresponding to the definition, but also the specific representation (either exemplar or prototype) activated by the linguistic definition.</p>
<p>In both experimentations the recorded answers were consistent with our assumptions and more in general with the literature concerning prototypes and exemplar-based retrieval, which allows us to consider the target concepts like the expected categories, and the target representations as expected proxyfied representations.</p>
<p>To assess the DuAL-PECCS system we have considered a twofold experimental setting. In the first case we tested the whole pipeline, where the salient information is extracted by starting from the linguistic description, the corresponding representation is retrieved, proxyfied and loaded in working memory according to the dual process approach. The information extraction of the linguistic input is not implemented in ACT-R, but it relies on the CoreNLP Stanford Parser (Manning et al., 2014), which is used to convert the textual description into a chunk request. This measure is intended to assess the robustness of the overall approach, from the input parsing to the final categorization. In the second case we tested the heterogeneous proxytypes approach by directly starting with a manual encoding of the linguistic stimulus in terms of chunk request: this measure is intended to assess the accuracy in the categorization task of the hybrid system, featured by dual process approach, heterogeneous representation and reasoning, proxyfication, integration in the ACT-R architecture, but no information extraction.</p>
<p>In both cases (all linguistic pipeline vs. 'clean' input) we recorded two distinct metrics: i) Concept-categorization accuracy (CC-ACC metrics) This metrics was designed to evaluate the final categorization, that is the accuracy in retrieving the expected concept (in this case, the wrong proxyfication did not count as error).
ii) Proxyfication accuracy (P-ACC metrics) This metrics was designed to evaluate whether</p>
<p><sup id="fnref12:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Table 2.: The accuracy results (Table 2-a) and the analysis of the proxyfication errors (Table 2-b).
a. Accuracy rates obtained for the conceptual categorization accuracy (CC-ACC) and proxyfication accuracy (P-ACC) metrics.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">test</th>
<th style="text-align: center;">CC-ACC</th>
<th style="text-align: center;">P-ACC</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">with no IE</td>
<td style="text-align: center;">$89.3 \%(100 / 112)$</td>
<td style="text-align: center;">$79.0 \%(79 / 100)$</td>
</tr>
<tr>
<td style="text-align: center;">with IE</td>
<td style="text-align: center;">$77.7 \%(87 / 112)$</td>
<td style="text-align: center;">$71.3 \%(62 / 87)$</td>
</tr>
</tbody>
</table>
<p>b. Analysis of the errors in the proxyfication (P-ACC metrics).</p>
<table>
<thead>
<tr>
<th style="text-align: center;">test</th>
<th style="text-align: right;">Proxyfication error</th>
<th style="text-align: right;"></th>
<th style="text-align: right;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: right;">Ex-Proto</td>
<td style="text-align: right;">Proto-Ex</td>
<td style="text-align: right;">Ex-Ex</td>
</tr>
<tr>
<td style="text-align: center;">with no IE</td>
<td style="text-align: right;">$21.0 \%(21 / 100)$</td>
<td style="text-align: right;">$0.0 \%(0 / 100)$</td>
<td style="text-align: right;">$0.0 \%(0 / 100)$</td>
</tr>
<tr>
<td style="text-align: center;">with IE</td>
<td style="text-align: right;">$28.8 \%(26 / 87)$</td>
<td style="text-align: right;">$0.0 \%(0 / 87)$</td>
<td style="text-align: right;">$5.8 \%(5 / 87)$</td>
</tr>
</tbody>
</table>
<p>given in input a description evoking a given concept, the expected proxyfied representation was retrieved. In this case the confusion between prototype and exemplar (or between exemplars) is scored as error even if the expected category is returned.</p>
<h1>5.1. Results and Discussion</h1>
<p>The system obtained an accuracy of $89.3 \%$ in conceptual retrieval (that reduces to $77.7 \%$ when performing the IE step), and $79 \%$ in the proxyfication task ( $71.3 \%$ in the setting with the IE). These figures are reported in Table 2.</p>
<p>The results in the conceptual categorization are in line with those previously reported in (Lieto et al., 2015a), although the dataset was presently more diverse by including exemplars, as well. The results of the whole pipeline (Table 2-a, second row) provide a baseline for future implementations of the IE step; we observe that, although producing $11.6 \%$ error either in the POS tagging or in the IE step proper, this result is also in line with those reported in (Lieto et al., 2015b). This fact shows that the approach -devised to match the simple linguistic structures in the considered stimuli, and which was expected not to generalize to handle further linguistic descriptions- maintains its performance when dealing with a broader dataset. The IE step significantly affects also the P-ACC metrics: that is, if we restrict to considering cases where the concept was categorized as expected, the proxyfication step is performed correctly in $79.0 \%$ of descriptions with 'clean' input, and only in $71.3 \%$ of cases with the Information Extraction step.</p>
<p>Table 2-b reports the detailed errors committed in the proxyfication phase; here we distinguish three cases. Provided that proxyfication errors occur only when the concept has been correctly categorized, three kinds of proxyfication errors were recorded: an exemplar returned in place of an expected prototype (column Ex-Proto); a prototype returned in place of an expected exemplar (column Proto-Ex), or by retrieving a wrong exemplar (e.g., an individual of siberian_tiger in place of an individual of malaysian_tiger, column Ex-Ex). Notably, the vast majority of errors are due to confusion between exemplars and prototypes: in particular, in the $21 \%$ of the considered stimuli an exemplar-proxyfied representation has been returned by the system in spite of the expected prototype. This sort of error raises to $28.8 \%$ in the implementation including the IE task. This error was caused</p>
<p>by the fact that in case exemplar based representations in the KB are equipped with the typical information matching the linguistic description being categorized, then such representations are always favored w.r.t. their prototypical counterpart (see Section 3.1, Algorithm 2). However this fact, although in line with psychological experimental evidence where exemplars -if available- are mostly returned as first choice, is counterintuitive for very general descriptions situated at a high level of abstraction. For example, given the input description "The animal that eats bananas", the Dual-PECCS retrieves the representation of the exemplar associated to roloway_monkey, while the expected output, based on the answers provided by human subjects, is a generic prototype of monkey since the provided description is quite general. This particular class of errors deserves additional clarification in future works: albeit emerged experimenting the computational model, it also suggests that additional analysis is needed in the theoretical debate about exemplars and prototypes. Our results seem to demand deepening the heuristics that steer our categorical choices when the stimulus at hand spans different levels of abstraction. Therefore also from an epistemological perspective this result is interesting, since it shows how cognitively-inspired computational models of cognition taking into account a structuralist perspective, can fruitfully provide insights to the theoretical counterparts that they implement, in a continuous cycle of interaction between theoretical and experimental settings (see e.g. (Lieto and Radicioni, 2016) for the distinction between structuralist and functionalist artificial models of cognition).</p>
<p>The rest of errors are less relevant, except for the type Ex-Ex, where we observe a $5.8 \%$ error rate, which is mostly due to the noisy features extracted from the linguistic descriptions.</p>
<h1>6. Conclusions</h1>
<p>This article has illustrated two main advancements, in that Dual-PECCS provides the heterogeneous proxyfication approach-governed by the dual process theory-with a working implementation; the resulting system is able to autonomously perform prototypical and exemplar-based categorization. Additionally, it has been integrated into ACT-R and CLARION, thus showing a good level of compatibility with two general cognitive systems making different theoretical assumptions about the architecture of human cognition. Although there is room for both refining the theory and tuning the implemented system, the obtained experimental results are encouraging. Our proposal, in addition, seems to suggest, in perspective, a suitable way to deal with both the size and the heterogeneity problems affecting the knowledge level in cognitive architectures (Lieto, 2015).</p>
<p>As mentioned, an aspect that emerged from the experimentation deserves further investigation: namely, it regards the phenomenon of the proxyfication errors ${ }^{15}$ of exemplarbased representations, even for stimuli representing quite general typical descriptions. Such descriptions, in fact, determine in humans the activation of prototypes.</p>
<p>As a future work, we plan to extend the current integrated $\mathcal{S} 1-\mathcal{S} 2$ knowledge base (in particular the $\mathcal{S} 1$ component) by recurring to both semi-automatic enrichment of conceptual spaces through the use of existing resources such as ConceptNet (Liu and Singh, 2004), as well as to manual annotation by exploiting also crowdsourcing and gamification systems.</p>
<p><sup id="fnref13:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{15}$ We remark that we considered as errors results differing from the answers provided by the human subjects interviewed.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref6:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref7:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref8:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref9:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref10:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref11:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref12:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref13:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>