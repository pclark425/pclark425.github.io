<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2455 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2455</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2455</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-65.html">extraction-schema-65</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <p><strong>Paper ID:</strong> paper-263310605</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2309.17288v3.pdf" target="_blank">AutoAgents: A Framework for Automatic Agent Generation</a></p>
                <p><strong>Paper Abstract:</strong> Large language models (LLMs) have enabled remarkable advances in automated task-solving with multi-agent systems. However, most existing LLM-based multi-agent approaches rely on predefined agents to handle simple tasks, limiting the adaptability of multi-agent collaboration to different scenarios. Therefore, we introduce AutoAgents, an innovative framework that adaptively generates and coordinates multiple specialized agents to build an AI team according to different tasks. Specifically, AutoAgents couples the relationship between tasks and roles by dynamically generating multiple required agents based on task content and planning solutions for the current task based on the generated expert agents. Multiple specialized agents collaborate with each other to efficiently accomplish tasks. Concurrently, an observer role is incorporated into the framework to reflect on the designated plans and agents' responses and improve upon them. Our experiments on various benchmarks demonstrate that AutoAgents generates more coherent and accurate solutions than the existing multi-agent methods. This underscores the significance of assigning different roles to different tasks and of team cooperation, offering new perspectives for tackling complex tasks. The repository of this project is available at https://github.com/Link-AGI/AutoAgents.</p>
                <p><strong>Cost:</strong> 0.02</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2455.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2455.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AutoAgents</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AutoAgents: A Framework for Automatic Agent Generation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>AutoAgents is a framework that dynamically generates specialized LLM-based agents for a given task, drafts an execution plan via a Planner+Observers loop, and executes the plan with self-refinement and collaborative refinement coordinated by an Action Observer and memory modules.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AutoAgents</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>AutoAgents dynamically synthesizes a team of specialized LLM agents tailored to the input task. The pipeline has two main stages: (1) Drafting Stage — a Planner generates candidate agents and an execution plan and iteratively refines them through bidirectional dialogue with two Observers (Agent Observer and Plan Observer); (2) Execution Stage — generated agents carry out the plan under the coordination of an Action Observer, using two action types: self-refinement (iterative single-agent think/plan/execute/feedback loops) and collaborative refinement (sequential multi-agent turn-taking discussion). Knowledge sharing uses short-term, long-term and dynamic memory; agent definitions use a structured JSON format (prompt, description, toolset, suggestions).</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable (dynamically generated per task; framework includes 3 drafting-role agents predefined: Planner, Agent Observer, Plan Observer; plus Action Observer during execution and at least one Language Expert agent)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Two kinds: (A) Predefined management roles: Planner (generates agents & plans), Agent Observer (evaluates agent list), Plan Observer (evaluates execution plan), Action Observer (coordinates execution); (B) Dynamically generated expert agents specific to task (examples from case studies: Story Planner, Researcher, Character Developer, Writer, Game Design Expert, UI/UX Design Expert, Programming Expert, Debugging/Test Expert, Language Expert). Each generated agent includes: Prompt (profile/goal/constraints), Description, Toolset (restricted selection), and Suggestions (execution hints/output format).</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Drafting/idea decomposition (task understanding, agent-role synthesis, plan generation), execution/implementation (self-refinement and collaborative execution), monitoring and evaluation (Observers and Action Observer, memory records), and summarization (Language Expert produces final response). Applicable to planning, generation, implementation and evaluation phases of research workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Hierarchical/vertical coordination: drafting uses Planner in iterative dialogue with Agent Observer and Plan Observer to produce agent list and plan; execution uses Action Observer as team leader to assign steps and monitor progress; collaborative refinement uses a fixed-order sequential turn-taking among agents until consensus or iteration limit.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Natural-language prompt-based messages via LLM API calls; structured artifacts for agent definitions (JSON blobs containing 'prompt', 'description', 'tools', 'suggestions'); agents exchange chat-history concatenated utterances (textual messages); memory objects (short-term, long-term, dynamic) are used to pass summarized content between steps/agents.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Multi-level iterative feedback: (1) Drafting feedback: Agent Observer and Plan Observer critique and request revisions from Planner (bidirectional dialogue) until no more feedback or max rounds; (2) Execution feedback: self-refinement loops where an agent performs thought (language-space reasoning), plans, executes and re-evaluates outputs; collaborative refinement where peer agents incorporate others' outputs as 'completed steps' and respond; Action Observer monitors and requests rework until unanimous agreement or max iterations. Memory archives provide historical feedback to future steps.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Bounded iterative loops: Drafting-phase maximum discussion rounds = 3 (paper setting); Execution-phase maximum self-refinement and collaborative-refinement iterations = 5 per agent/step (paper setting). Agents communicate at each turn/step (after each step or iteration), and the collaboration recurs until consensus or iteration limit.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General-purpose tasks demonstrated on open-ended question answering and trivia creative writing; case studies in software engineering (Tetris game development). Designed for tasks requiring multi-domain knowledge fusion, planning, and long-horizon coordination.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported metrics: Trivia Creative Writing metric = fraction of trivia questions correctly mentioned in generated story. Results (Table 3): N=5: AutoAgents 82.0% (Δ +9.9% vs Standard prompting baseline 74.6%); N=10: AutoAgents 85.3% (Δ +10.8% vs Standard 77.0%). Open-ended QA: AutoAgents outperforms ChatGPT, Vicuna-13B and GPT-4 on FairEval and HumanEval (paper reports improved rates; exact table entries indicate strong improvement but only Trivia task gives clear numeric scores). Implementation details: GPT-4 API (temperature=0), drafting max rounds=3, execution max self/collab iterations=5.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared against single-agent baselines and other generated-agent frameworks: Standard prompting (single-agent), CoT, SPP/SPP-Profile, SSP, AgentVerse, AutoGen. Quantitatively: on Trivia Creative Writing AutoAgents > Standard (+9.9% and +10.8%) and slightly > SPP/SPP-Profile and SSP (paper reports AutoAgents 82.0% vs SPP 79.9% for N=5; 85.3% vs SPP 84.7% for N=10). Open-ended QA: AutoAgents reported to outperform ChatGPT, Vicuna-13B, and GPT-4 per FairEval/HumanEval.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Improved knowledge acquisition and reasoning (quantified: ~+10% on Trivia Creative Writing vs Standard). Drafting-stage collaborative discussion (Planner + Observers) yields more comprehensive, realistic agent teams (example: game dev task) and improves final performance (ablation shows observers contribute ~+3%). Self-refinement improves single-agent quality (~+3% contribution). Collaborative refinement improves multi-agent fusion (~+2%). Dynamic memory provides modest gains (~+1%). Overall coordination provides more coherent and accurate multi-step solutions vs single LLM runs.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Limitations noted: reliance on GPT-4 (adaptability to smaller/older LLMs poor); token limits constrain memory (short/long/dynamic memory mitigations but not solved); role rationality and plan generation still imperfect (may produce erroneous outputs); distinctions between roles are primarily prompt/tool differences, not deeply specialized model variants; communication overhead and complexity of recruiting optimal teams remain open problems.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>Reported ablations on 20 Trivia Creative Writing instances (Table 4): removing Observers => performance drops ≈ 3%; removing self-refinement => ≈ 3% drop; removing collaborative refinement => ≈ 2% drop; removing dynamic memory => ≈ 1% drop. These quantify contributions of the coordination/feedback components.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Paper recommends: use draft-stage collaborative discussion (Planner with Agent Observer and Plan Observer) to generate agent list and plan; use Action Observer for vertical coordination during execution; use vertical (hierarchical) sequential communication for tasks requiring iterative decision-making (e.g., software development); limit drafting rounds to ≈3 and per-step self/collab refinements to ≈5 as practical defaults; include self-refinement for specialized agents and dynamic memory for actions requiring domain-specific history.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AutoAgents: A Framework for Automatic Agent Generation', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2455.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2455.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BabyAGI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BabyAGI</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A task-management multi-agent system where one agent generates new tasks from objectives/results, another prioritizes tasks, and another executes tasks; described in this paper as having a fixed-order communication pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>BabyAGI</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A multi-agent task management architecture with specialized components: task-creator, task-prioritizer, and task-executor, arranged in a fixed pipeline where outputs of one stage feed the next.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>3 (task-creator, prioritizer, executor) as described in the paper</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Task Creator (generates new tasks from objectives/results), Task Prioritizer (orders tasks), Task Executor (completes tasks).</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Task generation and execution/automation (management pipeline); not designed for multi-agent debate or complex interdisciplinary scientific research in the description here.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Fixed-order sequential pipeline (each agent acts in order and hands off to the next).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Textual handoff of task descriptions/results between agents (prompt-based LLM messages implied by context).</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Implicit sequential handoff; no observer/iterative critique loop described in this paper's summary (no explicit peer review loop).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Sequential per-task step (producer-to-consumer handoffs); frequency determined by task generation/execution cycles.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General task automation / task management (not specialized to scientific research in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Enables automated task decomposition and pipeline execution across small set of specialized roles (paper mentions as example of multi-agent usage).</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Fixed-order communication restricts flexibility; described as limited compared to frameworks that support richer multi-agent discussion.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>N/A in this paper; described as having a fixed communication order which is a design choice.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AutoAgents: A Framework for Automatic Agent Generation', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2455.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2455.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Auto-GPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Auto-GPT</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An early autonomous agent using an LLM as a controller with tool access to autonomously pursue goals, but operates primarily as a single-agent system (no multi-agent collaboration) according to the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Auto-gpt: An autonomous gpt-4 experiment</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Auto-GPT</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An autonomous agent framework that leverages an LLM (GPT-style) as a controller to plan and execute actions using external tools; designed for single-agent autonomous goal pursuit rather than coordinated multi-agent collaboration.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>1 (single autonomous agent)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Single generalist LLM agent that plans, uses tools and executes steps to accomplish a user-specified goal.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Planning and execution/automation for single-agent goals; not explicitly for collaborative research pipelines in the text.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Not multi-agent — operates in isolation without inter-agent coordination.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Single-agent internal reasoning and tool invocations via prompts and API/tool calls.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Self-iteration and tool-observation loops internal to the agent; no peer feedback from other agents.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>N/A (single agent internal loop).</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General autonomous task execution / automation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Allows autonomous tool-augmented goal pursuit without multi-agent overhead.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Lacks multi-agent collaboration benefits (no multi-role specialization or peer critique), per the paper's discussion.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AutoAgents: A Framework for Automatic Agent Generation', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2455.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2455.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MetaGPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MetaGPT (meta programming for multi-agent collaborative framework)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A specialized LLM multi-agent framework that assigns different GPT-based roles to collaborate on software development tasks (role-assignment and pipeline for complex software development).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>MetaGPT</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A role-based multi-agent system designed for collaborative software development: multiple GPT-based agents are assigned specific software-engineering roles (e.g., PM, designer, programmer) and coordinate to produce development artifacts.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable (multiple role-based agents tailored to software dev)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Software-oriented roles such as project manager, developer/programmer, tester, UI/UX designer, documentation writer (paper notes MetaGPT is specialized for software dev).</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Planning/requirements, implementation (coding), testing, and documentation—applied to software engineering tasks rather than general scientific research.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Role assignment with multi-agent coordination tailored to software development workflows (pipeline/hierarchical coordination implied).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Prompt-based natural language exchanges among role agents; uses workspace/environment structures (paper references MetaGPT environment).</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Agents exchange artifacts and reviews; role-based handoffs and checks as part of the software dev process (exact mechanism not deeply specified in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Sequential and iterative during development cycles (per software dev workflow).</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Collaborative software development (case studies and prior work).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Demonstrated ability to decompose software tasks into role-specific subtasks and coordinate generation of code and artifacts.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Specialized to software development; not necessarily generalizable to arbitrary scientific research without prompt redesign.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AutoAgents: A Framework for Automatic Agent Generation', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2455.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2455.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Camel</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Camel (communicative agents)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A communicative multi-agent role-playing framework where multiple chat agents interact to complete tasks; noted in the paper as demonstrating role-based communication but lacking tool usage support.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Camel</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An LLM multi-agent conversational/role-playing framework where agents adopt personas/roles and communicate to solve tasks; emphasizes inter-agent dialogue and role-play.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable (multiple chat agents in role-play scenarios)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Persona/role-based chat agents (domain experts simulated via prompts), focused on conversational exchange rather than tool-augmented execution.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Idea generation, discussion, and synthesis via multi-agent dialogue (not focused on execution with external tools).</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Turn-taking conversational interaction among role agents (dialogue-driven coordination).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Natural-language conversational messages (role-play prompts and chat history).</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Peer-to-peer dialogic critique and consensus through conversation (no explicit observer/controller or tool-based feedback described here).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Per-turn conversational exchanges until task completion or stopping criterion.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General conversational problem-solving and multi-perspective synthesis (paper notes no tool usage).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Illustrates how role-play and conversational exchange can enable collaborative problem solving; useful for multi-perspective synthesis.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Lacks tool integration, which limits practical execution of some tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AutoAgents: A Framework for Automatic Agent Generation', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2455.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2455.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SSP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SSP</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Mentioned as a prior framework for automatically generating agents from problem input by providing agent samples and having agents solve the problem; AutoAgents is compared to SSP and claimed to emphasize agent reliability and strategic plans more heavily.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>SSP</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A generated-agent framework that creates agents for a problem (given some agent samples) and uses them to solve tasks; emphasizes agent generation but uses a different approach from AutoAgents.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable (generated per-problem)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Diverse generated agents derived from samples; details not elaborated in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Agent generation and execution (per referenced description); specifics not detailed here.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Generated-agent discussion and execution (details not specified in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>LLM-based dialog between generated agents (implied natural-language messages).</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>SSP uses agent generation and discussion; AutoAgents claims to extend with self-refinement and collaborative refinement for reliability.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General tasks requiring agent generation; used as a comparative method in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared in experiments (AutoAgents reported to outperform SSP on Trivia Creative Writing).</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AutoAgents: A Framework for Automatic Agent Generation', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2455.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2455.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AgentVerse</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AgentVerse</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework that can automatically generate unlimited agents; described in the paper as generating execution plans through agents' discussions and adding evaluation strategies for cyclic execution.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AgentVerse</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An agent-generation framework that synthesizes many agents and derives execution plans via inter-agent discussions; incorporates evaluation strategies and cyclic execution management.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable (automatically generated, potentially many)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Generated agents with various roles depending on task input; specifics not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Agent generation, planning and execution with evaluation cycles (per description).</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Inter-agent discussions produce execution plan; includes evaluation strategies and cyclic execution to iterate on plan/results.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>LLM-mediated dialogues among generated agents (natural language), with additional evaluation steps.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Agent discussions plus evaluation strategies for cyclic re-execution (paper reports AgentVerse uses such strategies).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General autonomous agent tasks; used for comparison in experiments and discussion.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared qualitatively/experimentally in the paper; AutoAgents claimed to outperform AgentVerse in some experiments due to emphasis on reliability and refinement actions.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AutoAgents: A Framework for Automatic Agent Generation', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2455.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2455.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AutoGen</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AutoGen</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework that enables development of LLM applications using multiple agents that converse with each other to solve tasks; mentioned as related prior work.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Autogen: Enabling next-gen llm applications via multi-agent conversation framework</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AutoGen</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A general-purpose multi-agent conversation framework where agents (LLMs) exchange messages to collaboratively solve tasks and build applications.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable (multi-agent conversation setup)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Agents can be assigned roles/personas as needed for an application; specifics depend on application design.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Idea generation, multi-agent conversation, and application orchestration; not focused on specific scientific research phases in the paper's discussion.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Multi-agent conversation (decentralized dialogue among agents).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Textual conversational messages between agents mediated by LLM prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Peer conversation and iterative exchanges; no fixed observer-controller design described in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Per-turn conversational exchange until task termination.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General LLM application development via agent conversations.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Facilitates building multi-agent applications through structured agent conversations.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Many prior multi-agent systems (including AutoGen) rely on handcrafted or user-specified agents; AutoAgents claims to improve on adaptability by dynamically generating agents.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'AutoAgents: A Framework for Automatic Agent Generation', 'publication_date_yy_mm': '2023-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Auto-gpt: An autonomous gpt-4 experiment <em>(Rating: 2)</em></li>
                <li>Autogen: Enabling next-gen llm applications via multi-agent conversation framework <em>(Rating: 2)</em></li>
                <li>Meta programming for multi-agent collaborative framework <em>(Rating: 2)</em></li>
                <li>AgentVerse <em>(Rating: 1)</em></li>
                <li>SSP <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2455",
    "paper_id": "paper-263310605",
    "extraction_schema_id": "extraction-schema-65",
    "extracted_data": [
        {
            "name_short": "AutoAgents",
            "name_full": "AutoAgents: A Framework for Automatic Agent Generation",
            "brief_description": "AutoAgents is a framework that dynamically generates specialized LLM-based agents for a given task, drafts an execution plan via a Planner+Observers loop, and executes the plan with self-refinement and collaborative refinement coordinated by an Action Observer and memory modules.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "AutoAgents",
            "system_description": "AutoAgents dynamically synthesizes a team of specialized LLM agents tailored to the input task. The pipeline has two main stages: (1) Drafting Stage — a Planner generates candidate agents and an execution plan and iteratively refines them through bidirectional dialogue with two Observers (Agent Observer and Plan Observer); (2) Execution Stage — generated agents carry out the plan under the coordination of an Action Observer, using two action types: self-refinement (iterative single-agent think/plan/execute/feedback loops) and collaborative refinement (sequential multi-agent turn-taking discussion). Knowledge sharing uses short-term, long-term and dynamic memory; agent definitions use a structured JSON format (prompt, description, toolset, suggestions).",
            "number_of_agents": "variable (dynamically generated per task; framework includes 3 drafting-role agents predefined: Planner, Agent Observer, Plan Observer; plus Action Observer during execution and at least one Language Expert agent)",
            "agent_specializations": "Two kinds: (A) Predefined management roles: Planner (generates agents & plans), Agent Observer (evaluates agent list), Plan Observer (evaluates execution plan), Action Observer (coordinates execution); (B) Dynamically generated expert agents specific to task (examples from case studies: Story Planner, Researcher, Character Developer, Writer, Game Design Expert, UI/UX Design Expert, Programming Expert, Debugging/Test Expert, Language Expert). Each generated agent includes: Prompt (profile/goal/constraints), Description, Toolset (restricted selection), and Suggestions (execution hints/output format).",
            "research_phases_covered": "Drafting/idea decomposition (task understanding, agent-role synthesis, plan generation), execution/implementation (self-refinement and collaborative execution), monitoring and evaluation (Observers and Action Observer, memory records), and summarization (Language Expert produces final response). Applicable to planning, generation, implementation and evaluation phases of research workflows.",
            "coordination_mechanism": "Hierarchical/vertical coordination: drafting uses Planner in iterative dialogue with Agent Observer and Plan Observer to produce agent list and plan; execution uses Action Observer as team leader to assign steps and monitor progress; collaborative refinement uses a fixed-order sequential turn-taking among agents until consensus or iteration limit.",
            "communication_protocol": "Natural-language prompt-based messages via LLM API calls; structured artifacts for agent definitions (JSON blobs containing 'prompt', 'description', 'tools', 'suggestions'); agents exchange chat-history concatenated utterances (textual messages); memory objects (short-term, long-term, dynamic) are used to pass summarized content between steps/agents.",
            "feedback_mechanism": "Multi-level iterative feedback: (1) Drafting feedback: Agent Observer and Plan Observer critique and request revisions from Planner (bidirectional dialogue) until no more feedback or max rounds; (2) Execution feedback: self-refinement loops where an agent performs thought (language-space reasoning), plans, executes and re-evaluates outputs; collaborative refinement where peer agents incorporate others' outputs as 'completed steps' and respond; Action Observer monitors and requests rework until unanimous agreement or max iterations. Memory archives provide historical feedback to future steps.",
            "communication_frequency": "Bounded iterative loops: Drafting-phase maximum discussion rounds = 3 (paper setting); Execution-phase maximum self-refinement and collaborative-refinement iterations = 5 per agent/step (paper setting). Agents communicate at each turn/step (after each step or iteration), and the collaboration recurs until consensus or iteration limit.",
            "task_domain": "General-purpose tasks demonstrated on open-ended question answering and trivia creative writing; case studies in software engineering (Tetris game development). Designed for tasks requiring multi-domain knowledge fusion, planning, and long-horizon coordination.",
            "performance_metrics": "Reported metrics: Trivia Creative Writing metric = fraction of trivia questions correctly mentioned in generated story. Results (Table 3): N=5: AutoAgents 82.0% (Δ +9.9% vs Standard prompting baseline 74.6%); N=10: AutoAgents 85.3% (Δ +10.8% vs Standard 77.0%). Open-ended QA: AutoAgents outperforms ChatGPT, Vicuna-13B and GPT-4 on FairEval and HumanEval (paper reports improved rates; exact table entries indicate strong improvement but only Trivia task gives clear numeric scores). Implementation details: GPT-4 API (temperature=0), drafting max rounds=3, execution max self/collab iterations=5.",
            "baseline_comparison": "Compared against single-agent baselines and other generated-agent frameworks: Standard prompting (single-agent), CoT, SPP/SPP-Profile, SSP, AgentVerse, AutoGen. Quantitatively: on Trivia Creative Writing AutoAgents &gt; Standard (+9.9% and +10.8%) and slightly &gt; SPP/SPP-Profile and SSP (paper reports AutoAgents 82.0% vs SPP 79.9% for N=5; 85.3% vs SPP 84.7% for N=10). Open-ended QA: AutoAgents reported to outperform ChatGPT, Vicuna-13B, and GPT-4 per FairEval/HumanEval.",
            "coordination_benefits": "Improved knowledge acquisition and reasoning (quantified: ~+10% on Trivia Creative Writing vs Standard). Drafting-stage collaborative discussion (Planner + Observers) yields more comprehensive, realistic agent teams (example: game dev task) and improves final performance (ablation shows observers contribute ~+3%). Self-refinement improves single-agent quality (~+3% contribution). Collaborative refinement improves multi-agent fusion (~+2%). Dynamic memory provides modest gains (~+1%). Overall coordination provides more coherent and accurate multi-step solutions vs single LLM runs.",
            "coordination_challenges": "Limitations noted: reliance on GPT-4 (adaptability to smaller/older LLMs poor); token limits constrain memory (short/long/dynamic memory mitigations but not solved); role rationality and plan generation still imperfect (may produce erroneous outputs); distinctions between roles are primarily prompt/tool differences, not deeply specialized model variants; communication overhead and complexity of recruiting optimal teams remain open problems.",
            "ablation_studies": "Reported ablations on 20 Trivia Creative Writing instances (Table 4): removing Observers =&gt; performance drops ≈ 3%; removing self-refinement =&gt; ≈ 3% drop; removing collaborative refinement =&gt; ≈ 2% drop; removing dynamic memory =&gt; ≈ 1% drop. These quantify contributions of the coordination/feedback components.",
            "optimal_configurations": "Paper recommends: use draft-stage collaborative discussion (Planner with Agent Observer and Plan Observer) to generate agent list and plan; use Action Observer for vertical coordination during execution; use vertical (hierarchical) sequential communication for tasks requiring iterative decision-making (e.g., software development); limit drafting rounds to ≈3 and per-step self/collab refinements to ≈5 as practical defaults; include self-refinement for specialized agents and dynamic memory for actions requiring domain-specific history.",
            "uuid": "e2455.0",
            "source_info": {
                "paper_title": "AutoAgents: A Framework for Automatic Agent Generation",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "BabyAGI",
            "name_full": "BabyAGI",
            "brief_description": "A task-management multi-agent system where one agent generates new tasks from objectives/results, another prioritizes tasks, and another executes tasks; described in this paper as having a fixed-order communication pipeline.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "BabyAGI",
            "system_description": "A multi-agent task management architecture with specialized components: task-creator, task-prioritizer, and task-executor, arranged in a fixed pipeline where outputs of one stage feed the next.",
            "number_of_agents": "3 (task-creator, prioritizer, executor) as described in the paper",
            "agent_specializations": "Task Creator (generates new tasks from objectives/results), Task Prioritizer (orders tasks), Task Executor (completes tasks).",
            "research_phases_covered": "Task generation and execution/automation (management pipeline); not designed for multi-agent debate or complex interdisciplinary scientific research in the description here.",
            "coordination_mechanism": "Fixed-order sequential pipeline (each agent acts in order and hands off to the next).",
            "communication_protocol": "Textual handoff of task descriptions/results between agents (prompt-based LLM messages implied by context).",
            "feedback_mechanism": "Implicit sequential handoff; no observer/iterative critique loop described in this paper's summary (no explicit peer review loop).",
            "communication_frequency": "Sequential per-task step (producer-to-consumer handoffs); frequency determined by task generation/execution cycles.",
            "task_domain": "General task automation / task management (not specialized to scientific research in this paper).",
            "performance_metrics": "",
            "baseline_comparison": "",
            "coordination_benefits": "Enables automated task decomposition and pipeline execution across small set of specialized roles (paper mentions as example of multi-agent usage).",
            "coordination_challenges": "Fixed-order communication restricts flexibility; described as limited compared to frameworks that support richer multi-agent discussion.",
            "ablation_studies": "",
            "optimal_configurations": "N/A in this paper; described as having a fixed communication order which is a design choice.",
            "uuid": "e2455.1",
            "source_info": {
                "paper_title": "AutoAgents: A Framework for Automatic Agent Generation",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "Auto-GPT",
            "name_full": "Auto-GPT",
            "brief_description": "An early autonomous agent using an LLM as a controller with tool access to autonomously pursue goals, but operates primarily as a single-agent system (no multi-agent collaboration) according to the paper.",
            "citation_title": "Auto-gpt: An autonomous gpt-4 experiment",
            "mention_or_use": "mention",
            "system_name": "Auto-GPT",
            "system_description": "An autonomous agent framework that leverages an LLM (GPT-style) as a controller to plan and execute actions using external tools; designed for single-agent autonomous goal pursuit rather than coordinated multi-agent collaboration.",
            "number_of_agents": "1 (single autonomous agent)",
            "agent_specializations": "Single generalist LLM agent that plans, uses tools and executes steps to accomplish a user-specified goal.",
            "research_phases_covered": "Planning and execution/automation for single-agent goals; not explicitly for collaborative research pipelines in the text.",
            "coordination_mechanism": "Not multi-agent — operates in isolation without inter-agent coordination.",
            "communication_protocol": "Single-agent internal reasoning and tool invocations via prompts and API/tool calls.",
            "feedback_mechanism": "Self-iteration and tool-observation loops internal to the agent; no peer feedback from other agents.",
            "communication_frequency": "N/A (single agent internal loop).",
            "task_domain": "General autonomous task execution / automation.",
            "performance_metrics": "",
            "baseline_comparison": "",
            "coordination_benefits": "Allows autonomous tool-augmented goal pursuit without multi-agent overhead.",
            "coordination_challenges": "Lacks multi-agent collaboration benefits (no multi-role specialization or peer critique), per the paper's discussion.",
            "ablation_studies": "",
            "optimal_configurations": "",
            "uuid": "e2455.2",
            "source_info": {
                "paper_title": "AutoAgents: A Framework for Automatic Agent Generation",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "MetaGPT",
            "name_full": "MetaGPT (meta programming for multi-agent collaborative framework)",
            "brief_description": "A specialized LLM multi-agent framework that assigns different GPT-based roles to collaborate on software development tasks (role-assignment and pipeline for complex software development).",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "MetaGPT",
            "system_description": "A role-based multi-agent system designed for collaborative software development: multiple GPT-based agents are assigned specific software-engineering roles (e.g., PM, designer, programmer) and coordinate to produce development artifacts.",
            "number_of_agents": "variable (multiple role-based agents tailored to software dev)",
            "agent_specializations": "Software-oriented roles such as project manager, developer/programmer, tester, UI/UX designer, documentation writer (paper notes MetaGPT is specialized for software dev).",
            "research_phases_covered": "Planning/requirements, implementation (coding), testing, and documentation—applied to software engineering tasks rather than general scientific research.",
            "coordination_mechanism": "Role assignment with multi-agent coordination tailored to software development workflows (pipeline/hierarchical coordination implied).",
            "communication_protocol": "Prompt-based natural language exchanges among role agents; uses workspace/environment structures (paper references MetaGPT environment).",
            "feedback_mechanism": "Agents exchange artifacts and reviews; role-based handoffs and checks as part of the software dev process (exact mechanism not deeply specified in this paper).",
            "communication_frequency": "Sequential and iterative during development cycles (per software dev workflow).",
            "task_domain": "Collaborative software development (case studies and prior work).",
            "performance_metrics": "",
            "baseline_comparison": "",
            "coordination_benefits": "Demonstrated ability to decompose software tasks into role-specific subtasks and coordinate generation of code and artifacts.",
            "coordination_challenges": "Specialized to software development; not necessarily generalizable to arbitrary scientific research without prompt redesign.",
            "ablation_studies": "",
            "optimal_configurations": "",
            "uuid": "e2455.3",
            "source_info": {
                "paper_title": "AutoAgents: A Framework for Automatic Agent Generation",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "Camel",
            "name_full": "Camel (communicative agents)",
            "brief_description": "A communicative multi-agent role-playing framework where multiple chat agents interact to complete tasks; noted in the paper as demonstrating role-based communication but lacking tool usage support.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Camel",
            "system_description": "An LLM multi-agent conversational/role-playing framework where agents adopt personas/roles and communicate to solve tasks; emphasizes inter-agent dialogue and role-play.",
            "number_of_agents": "variable (multiple chat agents in role-play scenarios)",
            "agent_specializations": "Persona/role-based chat agents (domain experts simulated via prompts), focused on conversational exchange rather than tool-augmented execution.",
            "research_phases_covered": "Idea generation, discussion, and synthesis via multi-agent dialogue (not focused on execution with external tools).",
            "coordination_mechanism": "Turn-taking conversational interaction among role agents (dialogue-driven coordination).",
            "communication_protocol": "Natural-language conversational messages (role-play prompts and chat history).",
            "feedback_mechanism": "Peer-to-peer dialogic critique and consensus through conversation (no explicit observer/controller or tool-based feedback described here).",
            "communication_frequency": "Per-turn conversational exchanges until task completion or stopping criterion.",
            "task_domain": "General conversational problem-solving and multi-perspective synthesis (paper notes no tool usage).",
            "performance_metrics": "",
            "baseline_comparison": "",
            "coordination_benefits": "Illustrates how role-play and conversational exchange can enable collaborative problem solving; useful for multi-perspective synthesis.",
            "coordination_challenges": "Lacks tool integration, which limits practical execution of some tasks.",
            "ablation_studies": "",
            "optimal_configurations": "",
            "uuid": "e2455.4",
            "source_info": {
                "paper_title": "AutoAgents: A Framework for Automatic Agent Generation",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "SSP",
            "name_full": "SSP",
            "brief_description": "Mentioned as a prior framework for automatically generating agents from problem input by providing agent samples and having agents solve the problem; AutoAgents is compared to SSP and claimed to emphasize agent reliability and strategic plans more heavily.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "SSP",
            "system_description": "A generated-agent framework that creates agents for a problem (given some agent samples) and uses them to solve tasks; emphasizes agent generation but uses a different approach from AutoAgents.",
            "number_of_agents": "variable (generated per-problem)",
            "agent_specializations": "Diverse generated agents derived from samples; details not elaborated in this paper.",
            "research_phases_covered": "Agent generation and execution (per referenced description); specifics not detailed here.",
            "coordination_mechanism": "Generated-agent discussion and execution (details not specified in this paper).",
            "communication_protocol": "LLM-based dialog between generated agents (implied natural-language messages).",
            "feedback_mechanism": "SSP uses agent generation and discussion; AutoAgents claims to extend with self-refinement and collaborative refinement for reliability.",
            "communication_frequency": "",
            "task_domain": "General tasks requiring agent generation; used as a comparative method in experiments.",
            "performance_metrics": "",
            "baseline_comparison": "Compared in experiments (AutoAgents reported to outperform SSP on Trivia Creative Writing).",
            "coordination_benefits": "",
            "coordination_challenges": "",
            "ablation_studies": "",
            "optimal_configurations": "",
            "uuid": "e2455.5",
            "source_info": {
                "paper_title": "AutoAgents: A Framework for Automatic Agent Generation",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "AgentVerse",
            "name_full": "AgentVerse",
            "brief_description": "A framework that can automatically generate unlimited agents; described in the paper as generating execution plans through agents' discussions and adding evaluation strategies for cyclic execution.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "AgentVerse",
            "system_description": "An agent-generation framework that synthesizes many agents and derives execution plans via inter-agent discussions; incorporates evaluation strategies and cyclic execution management.",
            "number_of_agents": "variable (automatically generated, potentially many)",
            "agent_specializations": "Generated agents with various roles depending on task input; specifics not detailed in this paper.",
            "research_phases_covered": "Agent generation, planning and execution with evaluation cycles (per description).",
            "coordination_mechanism": "Inter-agent discussions produce execution plan; includes evaluation strategies and cyclic execution to iterate on plan/results.",
            "communication_protocol": "LLM-mediated dialogues among generated agents (natural language), with additional evaluation steps.",
            "feedback_mechanism": "Agent discussions plus evaluation strategies for cyclic re-execution (paper reports AgentVerse uses such strategies).",
            "communication_frequency": "",
            "task_domain": "General autonomous agent tasks; used for comparison in experiments and discussion.",
            "performance_metrics": "",
            "baseline_comparison": "Compared qualitatively/experimentally in the paper; AutoAgents claimed to outperform AgentVerse in some experiments due to emphasis on reliability and refinement actions.",
            "coordination_benefits": "",
            "coordination_challenges": "",
            "ablation_studies": "",
            "optimal_configurations": "",
            "uuid": "e2455.6",
            "source_info": {
                "paper_title": "AutoAgents: A Framework for Automatic Agent Generation",
                "publication_date_yy_mm": "2023-09"
            }
        },
        {
            "name_short": "AutoGen",
            "name_full": "AutoGen",
            "brief_description": "A framework that enables development of LLM applications using multiple agents that converse with each other to solve tasks; mentioned as related prior work.",
            "citation_title": "Autogen: Enabling next-gen llm applications via multi-agent conversation framework",
            "mention_or_use": "mention",
            "system_name": "AutoGen",
            "system_description": "A general-purpose multi-agent conversation framework where agents (LLMs) exchange messages to collaboratively solve tasks and build applications.",
            "number_of_agents": "variable (multi-agent conversation setup)",
            "agent_specializations": "Agents can be assigned roles/personas as needed for an application; specifics depend on application design.",
            "research_phases_covered": "Idea generation, multi-agent conversation, and application orchestration; not focused on specific scientific research phases in the paper's discussion.",
            "coordination_mechanism": "Multi-agent conversation (decentralized dialogue among agents).",
            "communication_protocol": "Textual conversational messages between agents mediated by LLM prompts.",
            "feedback_mechanism": "Peer conversation and iterative exchanges; no fixed observer-controller design described in this paper.",
            "communication_frequency": "Per-turn conversational exchange until task termination.",
            "task_domain": "General LLM application development via agent conversations.",
            "performance_metrics": "",
            "baseline_comparison": "",
            "coordination_benefits": "Facilitates building multi-agent applications through structured agent conversations.",
            "coordination_challenges": "Many prior multi-agent systems (including AutoGen) rely on handcrafted or user-specified agents; AutoAgents claims to improve on adaptability by dynamically generating agents.",
            "ablation_studies": "",
            "optimal_configurations": "",
            "uuid": "e2455.7",
            "source_info": {
                "paper_title": "AutoAgents: A Framework for Automatic Agent Generation",
                "publication_date_yy_mm": "2023-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Auto-gpt: An autonomous gpt-4 experiment",
            "rating": 2,
            "sanitized_title": "autogpt_an_autonomous_gpt4_experiment"
        },
        {
            "paper_title": "Autogen: Enabling next-gen llm applications via multi-agent conversation framework",
            "rating": 2,
            "sanitized_title": "autogen_enabling_nextgen_llm_applications_via_multiagent_conversation_framework"
        },
        {
            "paper_title": "Meta programming for multi-agent collaborative framework",
            "rating": 2,
            "sanitized_title": "meta_programming_for_multiagent_collaborative_framework"
        },
        {
            "paper_title": "AgentVerse",
            "rating": 1,
            "sanitized_title": "agentverse"
        },
        {
            "paper_title": "SSP",
            "rating": 1
        }
    ],
    "cost": 0.01993375,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>AutoAgents: A Framework for Automatic Agent Generation
29 Apr 2024</p>
<p>Guangyao Chen gy.chen@pku.edu.cn 
Peking University</p>
<p>Siwei Dong 
Peking University</p>
<p>Yu Shu 
Peking University</p>
<p>Ge Zhang 
University of Waterloo</p>
<p>Jaward Sesay 
Beijing Academy of Artificial Intelligence</p>
<p>Börje Karlsson 
Beijing Academy of Artificial Intelligence</p>
<p>Jie Fu jiefu@ust.hk 
Hong Kong University of Science and Technology</p>
<p>Yemin Shi ymshi@pku.edu.cn 
Peking University</p>
<p>AutoAgents: A Framework for Automatic Agent Generation
29 Apr 2024AA1CD1F1EE0248E5642C47692256D79CarXiv:2309.17288v3[cs.AI]
Large language models (LLMs) have enabled remarkable advances in automated task-solving with multi-agent systems.However, most existing LLM-based multiagent approaches rely on predefined agents to handle simple tasks, limiting the adaptability of multi-agent collaboration to different scenarios.Therefore, we introduce AutoAgents, an innovative framework that adaptively generates and coordinates multiple specialized agents to build an AI team according to different tasks.Specifically, AutoAgents couples the relationship between tasks and roles by dynamically generating multiple required agents based on task content and planning solutions for the current task based on the generated expert agents.Multiple specialized agents collaborate with each other to efficiently accomplish tasks.Concurrently, an observer role is incorporated into the framework to reflect on the designated plans and agents' responses and improve upon them.Our experiments on various benchmarks demonstrate that AutoAgents generates more coherent and accurate solutions than the existing multi-agent methods.This underscores the significance of assigning different roles to different tasks and of team cooperation, offering new perspectives for tackling complex tasks.The repository of this project is available at https://github.com/Link-AGI/AutoAgents.</p>
<p>Introduction</p>
<p>Large language models (LLMs) have exhibited astounding capabilities [26,22,29] as versatile task-solving agents, endowed with a rich blend of knowledge and skills.Nevertheless, they still face difficulties [26,22,2] in tackling various tasks that require intensive knowledge and reasoning, such as avoiding hallucination [19], employing slow-thinking strategies [30], ensuring trustworthiness [32], and in combining diverse domain knowledge and long-horizon planning.In contrast, humans often exploit the benefits of collaborative problem solving, which enables them to work together effectively to solve non-routine problems in diverse domains and enhance the quality and reliability of the solutions by distributing the workload among specialties and applying a diversity of perspectives and expertise [21,27,1].</p>
<p>Inspired by collaborative problem solving, several recent works [34,7,17,11] have improved the task-solving capabilities of LLMs by integrating multi-agent discussion.However, most of these multiagent systems depend on handcrafted or user-specified agents, with specific roles and necessitating human supervision, which often restricts the scope of collaborative applications.Moreover, manually Table 1: Comparison of existing and proposed frameworks for LLM-based Agent framework.</p>
<p>To synthesize heterogeneous information from diverse domains is often a crucial requirement in creative industries and other real-world scenarios.We illustrate a concrete example of how AutoAgents tackles the challenging task of writing a novel about the awakening of artificial intelligence in Figure 1.The Story Planner and Researcher collaborate to devise the plot of the story with their respective expertise, while the Character Developer and Writer enrich the novel content through imagination based on the story.Moreover, we conduct quantitative experiments and case studies in complex tasks to demonstrate the effectiveness of AutoAgents.We also conduct a comprehensive analysis and demonstrate the importance of dynamic agents for handling complex tasks, the indispensability of self-refinement for proficient agents, and the effectiveness of collaborative conversation.</p>
<p>To summarize, this paper makes the following novel contributions: First, we propose AutoAgents, a novel framework that dynamically synthesizes and coordinates multiple expert agents to form customized AI teams for diverse tasks.Second, we conduct rigorous quantitative experiments on two challenging tasks and demonstrate that AutoAgents significantly improves both knowledge acquisition and reasoning ability in LLMs and outperforms other generated-agent frameworks.Third, we showcase AutoAgents' ability to adapt to complex tasks by applying it in various scenarios such as software development.Finally, we conduct a thorough investigation and reveal the importance of dynamic agents for accommodating complex tasks and the necessity of self-refinement for proficient agents, and the efficacy of collaborative conversation.</p>
<p>Related Work</p>
<p>LLM-based Autonomous Agents.LLMs have been widely used as core controllers for autonomous agents that can accomplish specific objectives.Auto-GPT [10] is an early work that leverages an Figure 1: A schematic diagram of AutoAgents.The system takes the user input as a starting point and generates a set of specialized agents for novel writing, along with a corresponding execution plan.The agents collaboratively carry out the tasks according to the plan and produce the final novel.Meanwhile, an observer monitors the generation and execution of the Agents and the plan, ensuring the quality and coherence of the process.</p>
<p>LLM as an AI agent that can autonomously achieve a given goal with the help of several tools.However, Auto-GPT does not support multi-agent collaboration and can only work in isolation.One way to enhance the task-solving capabilities of LLMs is to assign different roles and responsibilities to multiple LLMs and let them coordinate their actions to achieve a common goal.For example, BabyAGI [20] is an AI-powered task management system with multiple LLM-based agents.One agent creates new tasks based on the previous task's objective and result, another agent prioritizes the task list, and another agent completes tasks.BabyAGI is a multi-agent system with a fixed order of agent communication.MetaGPT [12] is a multi-agent framework for assigning different roles to GPTs to form a collaborative software entity for complex tasks.It is a specialized LLMbased multi-agent framework for collaborative software development.Camel [16] is an LLM-based communicative agent framework that demonstrates how role-playing can be used to enable chat agents to communicate with each other for task completion.However, Camel does not support tool-using.Several recent works [34,7,17,11,31,15] have enhanced the task-solving capabilities of LLMs by integrating multi-agent discussion.For instance, [34] proposes a multi-agent debate system that allows LLMs to argue for or against a given claim and generate a debate summary.[7] introduce a multi-agent dialogue system that enables LLMs to exchange information and opinions on a given topic and generate a dialogue report.AutoGen [37] is a framework that enables the development of LLM applications using multiple agents that can converse with each other to solve tasks.However, most of these multi-agent systems rely on handcrafted or user-specified agents with specific roles Agent Generalization.Several studies [24,35] employ LLMs to generate agents for social simulacra and epidemic modeling, demonstrating how this technique can facilitate designers in assessing and improving their modeling designs prior to deploying them to real users.Likewise, ExpertPrompting [38] devised a method to generate diverse profiles of agents that can cooperate with human users to accomplish tasks with minimal supervision.However, this method still depends on a restricted set of predefined agents, and the generated agents vary only in their profiles.Recently, SSP [34] and AgentVerse [5] have proposed frameworks for automatically generating unlimited agents.SSP enables LLMs to generate agents for problem input by providing some agent samples, and has these agents solve the problem.AgentVerse generates the execution plan through the generated agents' discussions and adds evaluation strategies for cyclic execution.Unlike the previous two methods, AutoAgents places a heightened emphasis on the reliability of its generated agents and strategic plans, thereby enhancing task execution effect through the utilization of collaborative refinement actions and the integration of self-refinement actions , as illustrated in Table 1.</p>
<p>The Framework for Automatic Agent Generation</p>
<p>To enhance the effectiveness of autonomous multi-agent groups in accomplishing their goals, the process of AutoAgents consists of two critical stages: Drafting Stage and Execution Stage, as illustrated in Figure 2. The drafting stage synthesizes an agent team and an execution plan that are customized to the task by analyzing the input problem or task.The execution stage refines the plan by enabling inter-agent collaboration and feedback, and delivers the final result.The interagent collaboration is based on some principles of multi-agent cooperation, such as communication, coordination, and consensus.These principles help the agents to share information, align their actions, reach agreements, and adapt to the environment.</p>
<p>Drafting Stage</p>
<p>Empirical evidence [36] suggests that diversity within human groups fosters diverse perspectives, which enhances the group's performance across various tasks.The drafting stage, which determines the composition of a multi-agent group, plays a crucial role in setting the upper limits of the group's capabilities.Therefore, it is imperative to generate the optimal agent team and execution plan that can maximize the group's potential.</p>
<p>Predominant methodologies [10,12,37] for assigning role descriptions to autonomous agents rely heavily on human intuition and prior knowledge, requiring manual assignment based on task understanding.Consistent with several parallel findings [38,34,5], dynamically designing agents with different roles can significantly enhance their efficacy.However, the scalability and rationality of agent and plan generation are still unclear, especially in the face of various complex problem environments.</p>
<p>On the one hand, the generated agents should exhibit diversity to accommodate various tasks.On the other hand, the agent and the plan generation should adhere to certain principles, rendering their role allocation more rational.Therefore, we devise three artificially predefined agents to produce agent teams and execution plans, integrating artificial prior knowledge and the dynamic adaptation capability of LLMs to generate more sensible agent teams and execution plans.The three artificially predefined agents comprise Planner, Agent Observer, and Plan Observer:</p>
<p>• Planner P generates and refines an agent team and an execution plan based on the content of the task.• Agent Observer O agent provides suggestions on the rationality of the agent team members and their matching degree with the task.• Plan Observer O plan provides suggestions on the rationality of the execution plan and its matching degree with the task and the agent team.</p>
<p>The Planner generates initial agent team members and a specific plan, and improves the agent team and execution plan based on continuous communication with the Agent Observer and Plan Observer.</p>
<p>Agent Generation.The Planner generates the agent team and facilitates its continuous improvement through reciprocal communication with the Agent Observer.To enable Planner to produce rational agents, we have devised a standard format for the essential elements of a single agent.For each agent A = {P, D, T, S}, the Planner needs to specify its prompt P, description D, toolset T, and suggestions S.</p>
<p>• Prompt P provides a detailed and customized depiction of the expert identity for each specific agent, which comprises profile, goal, and constraints.Profile reflects the domain expertise of the role or job title.Goal indicates the primary responsibility or objective that the role aims to achieve.Constraints specify limitations or principles the role must adhere to when performing actions.• Description D gives additional concrete identity to help establish a more comprehensive role, develop an execution plan, and inspect problems.• Toolset T equips the Agent with tools that it can use, selected from a predefined set of tools.</p>
<p>The rationale for not using all the tools for each agent here is to prevent decision-making confusion caused by excessive tools.• Suggestions S supplies some suggestions for each agent to execute the current task, including but not limited to a clear output, extraction of historical information, and suggestions for execution steps.</p>
<p>Based on the agent list {A 1 , A 2 , • • • , A n } generated by Planner, the Agent Observer evaluates the quality and suitability of each agent.The Agent Observer first verifies whether every agent conforms to the aforementioned specifications and identifies any missing elements {P, description D, toolset T}.Secondly, the Agent Observer assesses the compatibility of each agent with the task, according to their description information and task content.Finally, the Agent Observer examines the agent list for any redundant or missing roles and eliminates or adds them accordingly.</p>
<p>After n rounds of bidirectional communication between the Planner and the Agent Observer, the optimal agent list for accomplishing the task is established.Given the vital role of the agent list in the  task execution, this framework employs a predefined agent and multiple rounds of iterative dialogue among multiple agents to finalize the agent list, thereby enhancing the stability and reliability of the execution phase.</p>
<p>Plan Generation.In parallel to agent generation, the Planner formulates the execution plan and promotes its progressive improvement through reciprocal communication with the Plan Observer.For a given task, the Planner delineates the specific steps {S 1 , S 2 , • • • S n } to accomplish it in the execution plan P .Each step S i entails a clear identification of the agent A j responsible for it, as well as the input information and expected output required for it.</p>
<p>The Plan Observer subsequently validates the execution plan
P = {S 1 , S 2 , • • • S n } according to the agent list {A 1 , A 2 , • • • , A n }
and the task content.It firstly ensures that each step has a corresponding agent and that the step content is coherent and concise.It secondly assesses whether all the steps are sufficient, whether the task can be accomplished, and whether there are any gaps that need to be filled.It finally provides feedback to the Planner, who further refines the execution plan accordingly.After n rounds of dialogue between the Planner and the Plan Observer, the ultimate execution plan for achieving the task is established.</p>
<p>Task Execution Actions.The Planner devises an execution plan that automatically assigns the requisite agents for diverse tasks.The execution plan comprises two actions of task execution: selfrefinement by a single agent and collaborative refinement by multiple agents, as shown in Figure 3. Self-refinement empowers an individual agent to augment its proficiency in accomplishing some specialized tasks.Collaborative refinement fosters knowledge sharing among multiple agents and achieves tasks requiring interdisciplinary expertise.</p>
<p>Execution Stage</p>
<p>In the drafting phase, the framework generates an agent list and an execution plan based on the task requirements.Then, the framework creates corresponding roles and executes the plans in the execution environment 3 .The communication and cooperation among multi-agent systems are essential for accomplishing the tasks effectively.This section elaborates on the communication among multiple agents, the task execution strategies, and the knowledge-sharing mechanisms.</p>
<p>Communication of Multiple Agent.The communication structures among agents have been investigated by many studies [5,34,25,3] to examine their impact on task performance.In this framework, we adopt the vertical communication paradigm, which assigns different tasks to agents according to their roles.To facilitate the specific division of labor among the agents in the generated team, we introduce a predefined Action Observer as the team leader to coordinate the execution plan.Specifically, This mechanism of refinement and communication recurs until the Action Observer attains a unanimous agreement on the execution responses, or the process reaches its maximum iteration limit.For scenarios that demand iterative decision-making towards specific objectives, such as software development, vertical communication would be a preferable option.</p>
<p>Self-refinement Agent.Besides the inter-agent communication, the performance of a single agent also exerts a significant impact on the overall quality of feedback results.Hence, drawing on mechanisms such as AutoGPT [10] and ReAct [40], we have devised a self-refinement mechanism for an individual agent.</p>
<p>For a single agent A, the action at step t is at a t = l t ∪ p t ∪ o t , where l t denotes the thought or the reasoning trace in the language space, which does not alter the external environment, and thus yields no observational feedback, p t represents the execution plan for task completion, o t comprises the completion steps and execution output for this time.</p>
<p>As illustrated in Figure 2, various types of useful thoughts can assist in devising a refinement plan.The execution plan enables the agent to anticipate the steps they need to undertake in the future, and the observational content of the execution result construction allows the agent to reevaluate and enhance the plan arrangement, thereby constructing more refined and complete actions.Through a cycle of self-continuous thinking, planning, execution, and feedback, a single agent can effectively execute and accomplish task content.</p>
<p>Collaborative Refinement Action.In the collaborative refinement action, the agents collaboratively refine and execute the tasks in a sequential manner.Each round of the collaboration involves a fixed order of turn-taking among the agents, who generate their responses based on the current observation.The chat history slot of each agent is updated by concatenating the previous utterances of the other agents.The collaboration terminates automatically when the agents reach a consensus or the maximum number of discussions is reached.</p>
<p>Knowledge Sharing Mechanism.AutoAgents also facilitates the sharing of execution results among various agents for improved communication and feedback.However, when the number of agents is large and a single agent has more self-iterations, it will generate more historical information.Due to the token limitation of LLM models, they often cannot encompass all information.Hence, this framework provides short-term memory, long-term memory, and dynamic memory.</p>
<p>Short-term memory is chiefly concentrated on a singular action, encompassing the gamut of intermediary notions, strategies, and outcomes that emerge during the self-refinement or collaborative refinement phases of an individual action.It is salient to note that these actions frequently culminate in a distilled summary of critical information, epitomizing the final phase of the refinement trajectory.</p>
<p>Long-term memory principally focuses on chronicling the historical trajectory of multifarious actions, predominantly documenting the executed results of each task along with the synthesis of vital feedback information.This aspect is imperative for evaluating the comprehensive extent of task completion.</p>
<p>Dynamic memory predominantly serves actions necessitating specialized attention.The Action Observer, having access to long-term memory archives, adeptly extracts ancillary information, dynamically tailoring it to the specific requirements of the action for task execution.This process significantly augments the efficiency of a single action in task fulfillment.O agent provides feedback on agent team.</p>
<p>6:</p>
<p>P refines agent team based on feedback.</p>
<p>7:</p>
<p>O plan provides feedback on execution plan.</p>
<p>8:</p>
<p>P refines execution plan based on feedback.9: until No feedback or reached the maximum iteration limit.
for {A i , • • • , A j } do 18:
Agent A m analyzes S k , M S and M D .</p>
<p>19:</p>
<p>Agent A m plans the current step and executes this step.</p>
<p>20:</p>
<p>The execution result is stored in M S .</p>
<p>21:</p>
<p>end for</p>
<p>22:</p>
<p>until No step or reached the maximum iteration limit.</p>
<p>23:</p>
<p>The execution results of task S k are stored in M L .</p>
<p>24:</p>
<p>O action coordinates {S 1 , S 2 , • • • S n } and monitors execution.25: end for 26: return Execution results of final step.</p>
<p>Experiments</p>
<p>In order to demonstrate the capabilities and performance of AutoAgents in orchestrating autonomous agent groups to collaboratively accomplish tasks, we have performed extensive quantitative experiments on benchmark tasks and thorough case studies on more complex and realistic applications.In the quantitative analysis, we mainly present results for the Open-ended Question Answer task (detailed in Section 4.1) and the Trivia Creative Writing task (detailed in Section 4.2) to evaluate the framework effectiveness under distinct settings.The Case Studies, discussed in Section 4.4, illustrate the potential of a multi-agent group tackling intricate practical scenarios cooperatively.</p>
<p>Implementation Details:</p>
<p>We conduct all experiments using the GPT-4 API 4 and set the temperature to 0 to ensure reproducibility.The rationale behind this selection is the exceptional performance these models offer, providing more accurate and standardized output.Additionally, their accessibility and ease of use through APIs enable us to directly call and interact with the models during our research, significantly simplifying the process.The maximum number of discussions during the drafting phase is 3, and the maximum number of self-refinement by a single agent and collaborative refinement by multiple agents during the execution phase is 5.</p>
<p>Open-ended Question Answer</p>
<p>Task Description.Open-ended Question Answering is a crucial and challenging task in the domain of NLP and generative AI.It requires an AI system to produce coherent, elaborate, and human-like responses to questions that have no predetermined or fixed set of possible answers.[41] proposed MT-bench, a benchmark consisting of 80 high-quality collected open-ended questions from various categories such as common sense, counterfactual, coding, etc.We then utilize AutoAgents to produce collaborative answers based on multiple generated agents and compare them with the responses given by Vicuna-13B, ChatGPT, and GPT-4.Evaluation Metrics.To measure the quality of open-ended responses with minimal evaluation bias, we adopt FairEval [33] and HumanEval as the evaluation metrics for both the single agent and AutoAgents.FairEval incorporates several methods to mitigate the impact of various sources of bias, resulting in a better alignment with human judgment.For HumanEval, we enlist several volunteers to rate the responses from different models based on their helpfulness, reliability, accuracy, and level of detail.</p>
<p>Results.</p>
<p>Trivia Creative Writing</p>
<p>Task Description.The Trivia Creative Writing task [34] challenges the capabilities of large language models to retrieve and integrate diverse information from their internal self-compressed knowledge.This task requires a model to craft a coherent story around a given topic while incorporating the answers to N trivia questions.We evaluate the models under two settings, N = 5 and N = 10, where a higher N entails more trivia questions and thus demands the model to exhibit more extensive domain knowledge.We constructed a benchmark consisting of 100 instances for each N , encompassing a total of 1000 trivia questions.Evaluation Metrics.Drawing on the approach of [34], we adopt an automatic metric to identify factual errors and measure a model's capacity to integrate diverse domain knowledge.We conduct string matching with the veridical target answers for each question on the generated output.The target answers are supplied from the TriviaQA dataset [14], and each question can have a list of answer variants.A match to any of the answer variants of a question is regarded as a correct mention.The metric score is calculated as Trivia Creative Writing Metric Score = # correct answer mentions/# trivia questions.</p>
<p>Results.Table 3 demonstrates the superior performance of AutoAgents in knowledge acquisition over the existing methods.Compared to the Standard method, which does not employ Agent Generation, AutoAgents achieves a remarkable 10% improvement across all experiments.Moreover, AutoAgents also surpasses SSP [34], which utilizes agent generation but with a different approach.The enhanced performance of AutoAgents can be attributed to its elaborate methods of agent generation discussions and task execution including collaborative refinement and self-refinement.More examples are given in the Appendix A.</p>
<p>Further Analysis</p>
<p>This section delves into the significance of key components within AutoAgents by separately analyzing the self-refinement action, collaborative refinement action, dynamic memory, and observers in the draft stage across 20 instances5 of the Trivia Creative Writing task and additional case studies.[39] 66.0 -11.5% SPP-Profile [34] 74.0 -0.01%SPP [34] 84.4 +13.1% Collaborative discussion is crucial for rational agent generation and plan allocation.During the Drafting Stage, the Planner in AutoAgents engages in collaborative discussions with two Observers to determine the optimal list of agents and the execution plan.Figure 5 illustrates the contrast between agent generation with and without collaborative discussion.In the absence of Observer feedback, the Planner tends to generate programmers exclusively to accomplish game development, neglecting the holistic process of game creation.With the input and coordination of the Observers, the Planner incorporates game design experts, UI design experts, and testing experts into the agent list.It is evident that the agent generation under collaborative discussions is more comprehensive and more aligned with the realistic scenarios of game development.This also corroborates the significance of collaborative discussions for agent generation and plan allocation, which will subsequently influence the execution outcomes.Concurrently, Table 4 elucidates that in the absence of observers, there is a marked 3% reduction in the overall performance of AutoAgents.This substantiates the imperative role of collaborative discussions in agent generation.AutoAgent markedly enhances the caliber of agent generation via collaborative discussions, a facet notably overlooked by other generative frameworks in their consideration of agent generation quality.The empirical data presented in Table 2 and 3 further accentuate the superiority of AutoAgents when juxtaposed against counterparts like AgentVerse and SPP.</p>
<p>Enhancing single-agent through self-refinement.Self-Refinement [18,28,9,6,13,40] is a technique that enables LLMs to "converse" with themselves, evaluate their own generation, and iteratively improve their answers.Self-refinement has been shown to enhance the accuracy of LLMs' outputs in various domains [18,28,9,6,13,40].Although AutoAgents is a framework for multi-agent  collaboration, it also requires self-refinement agents to perform specialized roles for individual tasks.</p>
<p>As shown in the results in Table 4, the performance of AutoAgents decreases by 3% in the absence of the self-refinement action.This observation corroborates the assertion that self-refinement is instrumental in augmenting proficiency in trivia creative writing tasks.Furthermore, the enhancement of single agents via self-refinement plays a pivotal role in fortifying the integrity of the overarching multi-agent framework.</p>
<p>Enhancing multi-agent collaboration through collaborative refinement action.For collaborative refinement, the process resembles the collaborative dialogue mentioned above, which involves integrating knowledge from different domains to accomplish tasks that demand cross-domain knowledge fusion.The results in Table 4 demonstrate the performance when collaborative refinement is absent.It's observable that compared to the scenario with AutoAgents, there is a decline of 2%.Since the necessity for multiple agents to collaborate on a single task is entirely dependent on the decision made by the agent in the drafting phase, not all problems necessarily involve tasks that require collaborative refinement.However, it's evident that when this principle is omitted from the prompt's design, there's a noticeable performance decrease.</p>
<p>Improve the effectiveness of actions by dynamic memory.Dynamic memory predominantly addresses the requisites of specialized agents.As shown in Figure 4, the Action Observer amalgamates pivotal data for forthcoming tasks, utilizing the historical action records archived in long-term memory.Table 4 elucidates a 1% diminution in the efficacy of AutoAgents bereft of dynamic memory.Quintessential insights derived from dynamic memory are assimilated into the prompt, thereby augmenting the comprehension of critical information and bolstering the operational proficiency of actions.</p>
<p>Case Study</p>
<p>To demonstrate the applicability of AutoAgents to more sophisticated and realistic scenarios, we conduct a case study in the software engineering domain.Software engineering is a complex collaborative endeavor that involves diverse roles and responsibilities.From developers who create the underlying code, to UI designers who prioritize user experience, and software testers who ensure the software's quality, experts collaboratively work to enhance and refine the application, ensuring that it meets both functional and user-centric criteria.</p>
<p>As an illustration in Figure 6, a Tetris game has been developed by employing AutoAgents, which has generated various expert roles, such as game design expert, UI design expert, programmer, and debugging expert, to accomplish the game development task.The game design experts provide the game logic documents that specify the rules and mechanics of the game.The UI design experts design the UI components that create the visual interface of the game.The programmers implement the game design based on the aforementioned documents and use appropriate programming languages and tools.Finally, the debugging expert tests the game and debuges the program to ensure its functionality and quality.The game development process is based on the collaboration of multiple expert roles, with more elaborate documentation and programs, making it easier for users to comprehend.</p>
<p>Conclusion</p>
<p>This paper introduces AutoAgents, an innovative framework for automatically synthesizing collaborative specialized agents.AutoAgents mimics the collaborative process of human teams by decomposing tasks into drafting and execution phases and delegating different subtasks to different agents.Our experimental and empirical evaluation validates the advantages of AutoAgents, as it surpasses single agents and other groupings in various tasks that demand diverse skills.Furthermore, our case study in software development illustrates the versatility and potential benefits of our proposed framework.AutoAgents opens up new possibilities for enhancing the interaction and cooperation among agents and transforms the landscape of complex problem-solving.We envisage that its principles can be further generalized and refined to deal with a broader range of tasks, paving the way towards more useful assistive AI. Figure 7: An example of the self-refinement process of programmers' coding make sure the story they produce makes sense and is consistently improved upon.This also supports the idea that working together in this way is helpful when dealing with complicated tasks.</p>
<p>Dynamic agents enhance the adaptability of complex tasks.The ability to generate dynamic agents for various tasks is crucial for enhancing their adaptability to diverse scenarios.Figure 9 illustrates the contrast between GPT4 and AutoAgents' responses to open-ended questions.Unlike GPT-4, AutoAgents can produce agents from three distinct domains, which can provide more elaborate answers.For the trivia creative writing task in Figure 10 and 11, AutoAgents employs a four-step approach for task decomposition.Initially, it sources the answer to the given question using a domainspecific agent, followed by the construction of a narrative.Concurrently, the Language Expert Agent plays a pivotal role, conducting multiple checks to verify the coherence between the narrative and the question, thus guaranteeing the narrative's accuracy.</p>
<p>Furthermore, as illustrated in Figure 12, the Action Observer orchestrates the interaction among multiple generative agents.It provides a concise summary of essential information, proving instrumental in fostering collaboration between various intelligent agents.This coordination is key to ensuring the seamless flow of the task execution process.Collectively, these instances vividly showcase the adaptability and efficiency of our dynamic agent generation framework in handling complex tasks.</p>
<p>Conversely, the prompt employed by AutoAgents exhibits a more universal nature, signifying its capacity to acclimate to diverse tasks without necessitating bespoke customization.As Table 5</p>
<p>Framework Application Agent Generalization by Multi-Agent Discussion</p>
<p>Prompt Generalization</p>
<p>Social Simulacra [24] Social Simulation Epidemic Modeling [35] Social Simulation SSP [34] General Autonomous Agents AgentVerse [5] General Autonomous Agents AutoAgents General Autonomous Agents delineates, both AgentVerse6 and SSP 7 have implemented task-specific enhancements for varied task evaluations.In contrast, our methodology leverages a singular, unified prompt format to accommodate an array of tasks.The commendable efficacy in open-ended question-answer and trivia creative writing tasks further corroborates the wide-ranging applicability and versatility of prompt design within the AutoAgents framework.</p>
<p>B Human Evaluation</p>
<p>In this section, we present the criteria for human evaluation.We instructed the volunteers, who are responsible for assessing the quality of different feedback, to adhere to these standards.</p>
<p>[ Text]Human Evaluation</p>
<p>We would like to request your feedback on the response to the user question displayed above.Please rate the helpfulness, relevance, accuracy, level of details of their responses.</p>
<p>Each response receives an overall score on a scale of 1 to 10, where a higher score indicates better overall performance.Please first provide a comprehensive explanation of your evaluation, avoiding any potential bias and ensuring that the order in which the responses were presented does not affect your judgment.</p>
<p>Output with the following format: Evaluation evidence: <your evluation explanation here> Score: <score></p>
<p>C Discussion</p>
<p>Limitations.AutoAgents exhibit remarkable knowledge acquisition and adaptability in tackling complex tasks, but they are not flawless.One of the limitations is that they may still produce erroneous outcomes even with dynamic role generation.This could be ascribed to the rationality of role generation and planning arrangements.Although this framework employs collaborative discussions to enhance the quality of role generation and planning arrangements, it still necessitates a  more effective method for recruiting teams and devising plans, and further ameliorates the quality of role generation and planning arrangements.</p>
<p>Furthermore, the differences between different roles in this framework mainly hinge on variations in prompt and tool usage, but this does not accentuate the distinctions between different expert roles.</p>
<p>In the future, it is imperative to explore how to incorporate more expert knowledge and create more professional role agents, in order to improve the adaptability of professional agents to professional problems.</p>
<p>Currently, AutoAgents rely heavily on the powerful logical and textual capabilities of GPT-4, and their adaptability to some earlier LLMs is poor.In the future, it is essential to explore more reasonable prompts to improve the adaptability of AutoAgents to different LLMs.</p>
<p>Future Work.Cooperation among multiple agents requires dynamic adaptation and communication.</p>
<p>The initial plan generated by LLMs may not suffice to achieve the desired outcomes [4], resulting in erroneous final output results.Hence, future multi-agent systems need to swiftly detect and rectify errors and adjust their plans dynamically to align with the desired outcomes.</p>
<p>The memory capacity of existing agents is limited by the number of tokens in LLMs.How to devise a high-quality memory mechanism that enables efficient retrieval and storage of memory by agents remains an open question.</p>
<p>The professional skills of the generated agents are effective, but they can be improved by retraining or other mechanisms.Alternatively, an Agent Bank can be established to enable the invocation of professional agents on demand.More professional agent construction is still worthy of exploration.</p>
<p>D Prompts</p>
<p>In this section, we present the prompts of five components in our framework: Planner, Plan Observer, Role Observer, Action Observer, and Custom Agent.These prompts are designed to elicit the desired behaviors and responses from the agents in different scenarios and tasks.</p>
<p>D.1 Planner</p>
<p>The prompt design principles outlined in the template focus on creating and utilizing specialized LLM-based agent roles to solve complex tasks and problems.Here's a summary of these principles:</p>
<ol>
<li>Understanding and Breaking Down Tasks: The first step involves comprehensively understanding, analyzing, and deconstructing the given task or problem.</li>
</ol>
<p>Utilization of Existing Expert Roles:</p>
<p>• Fully leverage existing expert roles suited to the problem.</p>
<p>• Ensure that these roles have cooperative or dependent relationships.</p>
<p>• Output the details of selected roles in JSON format, including their original information.</p>
<p>Creation of New Expert Roles:</p>
<p>• Avoid duplication of functions in new roles.</p>
<p>• New roles should have clear names, detailed descriptions, domain expertise, available tools, execution suggestions, and prompt templates.• Ensure each new expert role has a distinct responsibility and domain of expertise.</p>
<p>• Specify the goals, constraints, and toolset for each new role.</p>
<p>• Provide execution suggestions and develop prompt templates for each new role.</p>
<p>• Output details of new roles in JSON format, following a specific structure.</p>
<p>Creation of Detailed Execution Plan:</p>
<p>• Develop a comprehensive plan with multiple steps addressing the problem.</p>
<p>• Assign at least one expert role to each step, detailing their contributions and collaborations.</p>
<p>• Provide detailed descriptions for each step, including expected outputs and inputs for subsequent steps.</p>
<p>• Include a final independent step for a language expert to provide a detailed response to the user's question.</p>
<p>• Present the execution plan as a numbered list, indicating the expert roles involved in each step.</p>
<p>This structured approach ensures a systematic and detailed resolution of tasks, leveraging the specialized expertise of various LLM agents.</p>
<p>[ Prompt]Planner Here is an example of a valid JSON blob: {{{{ "name": "ROLE NAME", "description": "ROLE DESCRIPTONS", "tools": ["ROLE TOOL"], "suggestions": "EXECUTION SUGGESTIONS", "prompt": "ROLE PROMPT", }}}} 4. Finally, based on the content of the problem/task and the expert roles, provide a detailed execution plan with the required steps to solve the problem.4.1.The execution plan should consist of multiple steps that solve the problem progressively.Make the plan as detailed as possible to ensure the accuracy and completeness of the task.You need to make sure that the summary of all the steps can answer the question or complete the task.4.2.Each step should assign at least one expert role to carry it out.If a step involves multiple expert roles, you need to specify the contributions of each expert role and how they collaborate to produce integrated results.4.3.The description of each step should provide sufficient details and explain how the steps are connected to each other.4.4.The description of each step must also include the expected output of that step and indicate what inputs are needed for the next step.The expected output of the current step and the required input for the next step must be consistent with each other.Sometimes, you may need to extract information or values before using them.Otherwise, the next step will lack the necessary input.4.5.The final step should always be an independent step that says 'Language Expert: Based on the previous steps, please provide a helpful, relevant, accurate, and detailed response to the user's original question: XXX'.4.6.Output the execution plan as a numbered list of steps.For each step, please begin with a list of the expert roles that are involved in performing it.the primary responsibility or objective that the expert role aims to achieve.3.6.You should specify any limitations or principles that each new expert role must adhere to when performing actions.These are called constraints and they must be consistent with the problem requirements and the domain of expertise.3.7.You should select the appropriate tools that each new expert role needs to use from the existing tool set.Each new expert role can have multiple tools or no tool at all, depending on their functions and needs.You should never create any new tool and only use the existing ones.3.8.You should provide some helpful suggestions for each new expert role to execute the task effectively and efficiently.The suggestions should include but not limited to a clear output format, extraction of relevant information from previous steps, and guidance for execution steps.3.9.You should create a prompt template for calling each new expert role according to its name, description, goal, constraints, tools and suggestions.A good prompt template should first explain the role it needs to play (name), its area of expertise (description), the primary responsibility or objective that it aims to achieve (goal), any limitations or principles that it must adhere to when performing actions (constraints), and some helpful suggestions for executing the task (suggestions).The prompt must follow this format: "You are [description], named [name].Your goal is [goal], and your constraints are [constraints].You could follow these execution suggestions: [suggestions].".3.10.You should always have a language expert role who does not require any tools and is responsible for summarizing the results of all steps in natural language.3.11.You should follow the JSON blob format for creating new expert roles.Specifically, The JSON of new expert roles should have a 'name' key (the expert role name), a 'description' key (the description of the expert role's expertise domain), a 'tools' key (with the name of the tools used by the expert role), a 'suggestions' key (some suggestions for each agent to execute the task), and a 'prompt' key (the prompt template required to call the expert role).Each JSON blob should only contain one expert role, and do NOT return a list of multiple expert roles.Here is an example of a valid JSON blob: {{{{ "name": "ROLE NAME", "description": "ROLE DESCRIPTONS", "tools": ["ROLE TOOL"], "suggestions": "EXECUTION SUGGESTIONS",</p>
<h1>Format example</h1>
<p>D.4 Action Observer</p>
<p>The design principles for the Action Observer in this prompt focus on coordinating the efforts of various expert roles to address human questions or tasks effectively.Key aspects include:</p>
<ol>
<li>Understanding the Goal or Problem: Start with a clear understanding of the ultimate goal or the problem posed in the question or task.</li>
</ol>
<p>Determining and Executing Next Steps:</p>
<p>• Review the history of completed steps to understand the progress made so far.</p>
<p>• Assess the unfinished steps and decide on the necessary actions to achieve the goal or solve the problem.• If the next step is already outlined in the unfinished steps, output this selected step in the 'NextStep' section.• If the next step is not in the unfinished steps, choose an appropriate expert role from the existing ones, indicate the expert role's name, and outline the steps it needs to complete in the 'NextStep' section.</p>
<p>Extracting and Utilizing Historical Information:</p>
<p>• Extract relevant information from the history to assist in completing the next step.</p>
<p>• Ensure not to alter the historical information and maintain its original form for the next step.</p>
<p>The final output must adhere to a specific format, maintaining clarity and consistency in the process.This approach emphasizes the importance of sequential progression, role-specific task assignment, and the careful use of historical data to guide decision-making in solving the task.</p>
<p>[ Prompt]Action Observer PROMPT_TEMPLATE = """ You are an expert role manager who is in charge of collecting the results of expert</p>
<p>Figure 2 :
2
Figure 2: The execution process of AutoAgents.During the Drafting Stage, three predefined agents collaboratively determine the list of agents and the execution plan.During the Execution Stage, a predefined agent facilitates coordination and communication among the generated agent teams, and the individual generated agents enhance their execution efficiency through self-refinement.</p>
<p>Write engaging and coherent chapters based on the outline and character profiles.This will form the main body of the novel.Task: The Story Planner collaborates with the Researcher to understand AI concepts and create a detailed outline for the novel.This includes a high-level overview of the story, a breakdown of the story into chapters, and a breakdown of each chapter into scenes.(b) Collaborative refinement by multiple agents (a) Self-refinement by a single agent</p>
<p>Figure 3 :
3
Figure 3: Two types of actions for executing tasks: Self-refinement enables an individual agent to enhance its competence in performing some specialized tasks.Collaborative refinement facilitates knowledge exchange among multiple agents and accomplishes tasks that demand interdisciplinary expertise.</p>
<p>Figure 4 :
4
Figure 4: Legend of Three Knowledge Sharing Mechanisms.(a) Long-term memory focuses on chronicling the historical trajectory of multiple actions.(b) Short-term memory records the history of the self-refinement or collaborative refinement phases of an individual action.(c) Dynamic memory serves actions necessitating specialized attention extracted from the long-term memory.</p>
<p>Figure 5 :
5
Figure 5: Comparison of whether there is a collaborative discussion in the Drafting Stage in the task that developing Python-based software for the Tetris game.</p>
<p>Figure 6 :
6
Figure 6: The illustration of an example process of software development.The task is to develop Python-based software for the Tetris game.</p>
<p>Figure 8 :
8
Figure 8: An example of the collaborative refinement process of trivia creative writing.</p>
<p>Figure 9 :
9
Figure 9: An example of the Open-ended Question Answer.</p>
<p>Figure 10 :
10
Figure 10: (Page 1) An example of the Trivia Creative Writing task.</p>
<p>Figure 11 :
11
Figure 11: (Page 2) An example of the Trivia Creative Writing task.</p>
<p>Figure 12 :
12
Figure 12: An example of the coordination process for the Acton Observer agent.</p>
<p>10 :
10
Execution Stage: 11: Initialize Action Observer O action and long-term memory M L .12: for {S 1 , S 2 , • • • S n } do O action assign task S k and M D to corresponding agents {A i , • • • , A j }.
13:O action generate dynamic memory M D .15:Initialize short-term memory M S .16:repeat17:
14:</p>
<p>Table 2 :
2
[33]Rate of AutoAgents over other models on Open-ended Question Answer, with FairEval[33]and HumanEval serving as evaluators.
FairEval [33]96.3%96.3%76.3%HumanEval75%75%62.5%
Evaluator v.s.ChatGPT v.s.Vicuna-13B v.s.GPT-4</p>
<p>Table 2 demonstrates that AutoAgents outperforms individual LLM models in both FairEval based on LLM and Human evaluations.AutoAgent can produce more comprehensive and nuanced answers to open questions by synthesizing multiple expert models.It can also provide more elaborate explanations and justifications for its answers.More examples are given in the Appendix A.</p>
<p>Table 3 :
3
The results of Trivia Creative Writing task.∆ indicates the differences compared with Standard Prompting (first row).
MethodsN (# trivia questions) = 5N (# trivia questions ) = 10Score (%) ∆ (v.s Standard %)Score (%) ∆ (v.s Standard %)Standard74.60.0%77.00.0%CoT [39]67.1-10.0%68.5-11.1%SPP-Profile [34]79.1+5.9%83.0+7.8%SPP [34]79.9+7.1%84.7+10.0%AutoAgents82.0+9.9%85.3+10.8%</p>
<p>Table 4 :
4
The ablation studies of AutoAgents on 20 instances of Trivia Creative Writing task.∆ indicates the differences compared with Standard Prompting (first row).
MethodsN (# trivia questions) = 5Score (%) ∆ (v.s Standard %)Standard74.60.0%CoT</p>
<p>We need to create a Programming Expert to write the game (a) w/o Collaborative Discussion Agent Observer Planner Planner We also need game experts to design games and UI experts to design game interfaces, ….. We need to create Game Design Expert, UI/UX Design Expert Programming Expert, Debugging Expert …… (b) w/ Collaborative Discussion</p>
<p>Table 5 :
5
Comparison of existing and proposed frameworks for multi-agent generation methods.</p>
<p>You are a manager and an expert-level ChatGPT prompt engineer with expertise in multiple fields.Your goal is to break down tasks by creating multiple LLM agents, assign them roles, analyze their dependencies, and provide a detailed execution plan.You should continuously improve the role list and plan based on the suggestions in the History section.Make full use of the existing expert roles to solve the problem.2.2.Follow the requirements of the existing expert roles.Make sure to select the existing expert roles that have cooperative or dependent relationships.2.3.You MUST output the details of the selected existing expert roles in JSON blob format.Specifically, the JSON of each selected existing expert role should include its original information.3.According to the problem, existing expert roles and the toolset ({tools}), you will create additional expert roles that are needed to solve the problem.You should act as an expert-level ChatGPT prompt engineer and planner with expertise in multiple fields, so that you can better develop a problem-solving plan and provide the best answer.You should follow these principles when creating additional expert roles: 3.1.The newly created expert role should not have duplicate functions with any existing expert role.If there are duplicates, you do not need to create this role.3.2.Each new expert role should include a name, a detailed description of their area of expertise, available tools, execution suggestions, and prompt templates.3.3.Determine the number and domains of expertise of each new expert role based on the content of the problem.Please make sure each expert has a clear responsibility and do not let one expert do too many tasks.The description of their area of expertise should be detailed so that the role understands what they are capable of doing.3.4.Determine the names of each new expert role based on their domains of expertise.The name should express the characteristics of expert roles.3.5.Determine the goals of each new expert role based on their domains of expertise.The goal MUST indicate the primary responsibility or objective that the role aims to achieve.3.6.Determine the constraints of each new expert role based on their domains of expertise.The constraints MUST specify limitations or principles that the role must adhere to when performing actions.3.7.Determine the list of tools that each new expert needs to use based on the existing tool set.Each new expert role can have multiple tools or no tool at all.You should NEVER create any new tool and only use existing tools.3.8.Provide some suggestions for each agent to execute the task, including but not limited to a clear output, extraction of historical information, and suggestions for execution steps.3.9.Generate the prompt template required for calling each new expert role according to its name, description, goal, constraints, tools and suggestions.A good prompt template should first explain the role it needs to play (name), its area of expertise (description), the primary responsibility or objective that the role aims to achieve (goal), limitations or principles that the role must adhere to when performing actions (constraints), and suggestions for agent to execute the task (suggestions).The prompt MUST follow the following format "You are [description], named[name].Your goal is [goal], and your constraints are[constraints].You could follow these execution suggestions:[suggestions].".3.10.You must add a language expert role who does not require any tools and is responsible for summarizing the results of all steps.3.11.You MUST output the details of created new expert roles in JSON blob format.Specifically, The JSON of new expert roles should have a 'name' key (the expert role name), a 'description' key (the description of the expert role's expertise domain), a 'tools' key (with the name of the tools used by the expert role), a 'suggestions' key (some suggestions for each agent to execute the task), and a 'prompt' key (the prompt template required to call the expert role).Each JSON blob should only contain one expert role, and do NOT return a list of multiple expert roles.
PROMPT_TEMPLATE = '''-----# Question or Task{context}# Existing Expert Roles{existing_roles}# History{history}# StepsYou will come up with solutions for any task or problem by following these steps:1. You should first understand, analyze, and break down the human's problem/task.2. According to the problem, existing expert roles and the toolset ({tools}), youwill select the existing expert roles that are needed to solve the problem. Youshould act as an expert-level ChatGPT prompt engineer and planner with expertisein multiple fields, so that you can better develop a problem-solving plan andprovidethe best answer. You should follow these principles when selecting existing expertroles:2.1.</p>
<p>You should first understand, analyze, and break down the human's problem/task.2. According to the problem, existing expert roles and the toolset ({tools}), you should check the selected expert roles.2.1.You should make sure that the selected expert roles can help you solve the problem effectively and efficiently.2.2.You should make sure that the selected expert roles meet the requirements of the problem and have cooperative or dependent relationships with each other.2.3.You should make sure that the JSON blob of each selected expert role contains its original information, such as name, description, and requirements.3.According to the problem, existing expert roles and the toolset ({tools}), you should check the new expert roles that you have created.3.1.You should avoid creating any new expert role that has duplicate functions with any existing expert role.If there are duplicates, you should use the existing expert role instead.3.2.You should include the following information for each new expert role: a name, a detailed description of their area of expertise, a list of tools that they need to use, some suggestions for executing the task, and a prompt template for calling them.3.3.You should assign a clear and specific domain of expertise to each new expert role based on the content of the problem.You should not let one expert role do too many tasks or have vague responsibilities.The description of their area of expertise should be detailed enough to let them know what they are capable of doing.3.4.You should give a meaningful and expressive name to each new expert role based on their domain of expertise.The name should reflect the characteristics and functions of the expert role.3.5.You should state a clear and concise goal for each new expert role based on their domain of expertise.The goal must indicate
steps:1.Your final output should ALWAYS in the following format:{format_example}# Suggestions{suggestions}</p>
<p>You will check the Execution Plan by following these steps: 1.You should first understand, analyze, and disassemble the human's problem.2.You should check if the execution plan meets the following requirements: 2.1.The execution plan should consist of multiple steps that solve the problem progressively.Make the plan as detailed as possible to ensure the accuracy and completeness of the task.You need to make sure that the summary of all the steps can answer the question or complete the task.2.2.Each step should assign at least one expert role to carry it out.If a step involves multiple expert roles, you need to specify the contributions of each expert role and how they collaborate to produce integrated results.2.3.The description of each step should provide sufficient details and explain how the steps are connected to each other.2.4.The description of each step must also include the expected output of that step and indicate what inputs are needed for the next step.The expected output of the current step and the required input for the next step must be consistent with each other.Sometimes, you may need to extract information or values before using them.Otherwise, the next step will lack the necessary input.2.5.The final step should ALWAYS be an independent step that says 'Language Expert: Based on the previous steps, please respond to the user's original question: XXX'.3. Output a summary of the inspection results above.If you find any errors or have any suggestions, please state them clearly in the Suggestions section.If there are no errors or suggestions, you MUST write 'No Suggestions' in the Suggestions section.</p>
<h1>Format exampleYour final output should ALWAYS in the following format:{format_example}-----'''</h1>
<p>Execution environment of AutoAgents is built based on MetaGPT's environment and workspace[12].
The specific model version employed is "GPT-4-0613".
The last 20 samples from a dataset of 100 samples are used as test instances.
https://github.com/OpenBMB/AgentVerse/tree/minecraft/agentverse/tasks
https://github.com/MikeWangWZHL/Solo-Performance-Prompting/tree/main/prompts
AcknowledgementsThis work was partially supported by the National Key R&amp;D Program of China (2022YFC2009600 and 2022YFC2009606) and the Postdoctoral Fellowship Program of CPSF under Grant Number GZB20230024.A More ExamplesEnhancing single-agent through self-refinement.Figure7depicts the self-refinement process of programmers' coding.They first write a pseudo code file and then generate the corresponding program files based on it.This refinement process significantly ensures the validity of the output file.Although AutoAgents is a framework for multi-agent collaboration, it also requires self-refinement agents to perform specialized roles for individual tasks.Improving Teamwork in Multi-Agent Systems with Collaborative Refinement.In collaborative refinement, the method is similar to the team discussions we talked about earlier.This involves bringing together information from various fields to complete tasks that require blending knowledge from different areas.As illustrated in Figure8, during this process, the two agents work together toD.2 Agent ObserverThe prompt's design principles for the Agent Observer are centered on evaluating and refining expert roles for problem-solving.Key aspects include:1. Understanding and Analyzing the Task: Comprehensive analysis of the problem or task.2. Evaluation of Selected Expert Roles: Ensuring selected roles are effective, meet the problem's requirements, and their information (name, description, requirements) is accurately represented in a JSON format.Review of Created Expert Roles:• Avoid creating roles with overlapping functions with existing ones.# StepsYou will check the selected roles list and created roles list by following these "prompt": "ROLE PROMPT", }}}} 3.12.You need to check if the tool contains other tools that are not in the tool ({tools}), and if they do, they should be removed.4. Output a summary of the inspection results above.If you find any errors or have any suggestions, please state them clearly in the Suggestions section.If there are no errors or suggestions, you MUST write 'No Suggestions' in the Suggestions section.# Format exampleYour final output should ALWAYS in the following format: {format_example} -----'''D.3 Plan ObserverThe design principles for the Plan Observer in this prompt focus on evaluating and improving an Execution Plan.The key elements include:1. Understanding the Problem: Begin with a thorough understanding and analysis of the human's problem.Reviewing the Execution Plan:• Ensure the plan contains multiple detailed steps that progressively solve the problem, with a summary that addresses the task or question.• Verify that each step assigns at least one expert role, detailing their contributions and collaboration for integrated results.• Provide sufficient details in each step, explaining how the steps interconnect.• Include in each step's description its expected output and the inputs needed for the next step, ensuring consistency and completeness.• Confirm that the final step involves a language expert responding to the original question.D.5 Custom AgentThe design principles of this prompt are centered around guiding a role, presumably an AI agent, in efficiently completing tasks based on the results and responses of previous agents.The key aspects include:1. Understanding Previous Results: Begin by analyzing the results of previous agents to grasp the context and progress of the task.Task Analysis and Breakdown:Understand, analyze, and deconstruct the given task.Use available tools to assist in task completion.Current Step Identification and Execution:• Examine completed steps and their outcomes to identify the current step that needs to be completed.• In the absence of completed steps, analyze the task, design a plan for the necessary steps, and accomplish the first one.• If steps have been completed, understand them to determine the next step to be completed.Tool Selection and Action Execution:• Choose the appropriate tool from the given list (tool) to complete the current step.• Follow specific format guidelines when using tools like 'Write File'.• Once all steps are completed, use the 'Final Output' action to summarize each step's outputs, ensuring the final output is detailed, comprehensive, and solves the task.Maintaining Format Consistency:Ensure that the final output adheres to the given format example, prioritizing helpfulness, relevance, accuracy, and detail.This approach emphasizes systematic progression through tasks, leveraging tools and prior work, and producing comprehensive and detailed final outputs.[ Prompt]Custom Agent PROMPT_TEMPLATE = ''' -----{role} Base on the following execution result of the previous agents and completed steps and their responses, complete the following tasks as best you can.Building upon the custom agent's framework, a critical aspect of the refinement process is the configuration of 'completed steps' in step 3.1.The specific procedural steps for self-refinement and collaborative refinement are outlined as follows:Self-refinement Action: During its first execution, each custom agent omits the outlined step 3.1 and proceeds to complete the remaining steps.If the task's criteria are not met or the step limit has not been reached, the outcomes from this execution are incorporated as 'completed steps' in the prompt for the next iteration of the task.In subsequent executions, the custom agent will execute all steps, continuing this process until the task is deemed successfully completed.Collaborative Refinement Action: This mirrors the self-refinement action, yet involves active collaboration between multiple agents.For instance, when agents A and B collaborate on a task, A initially bypasses step 3.1 in its first execution.Upon completion, B incorporates A's results as 'completed steps' and then executes all steps.In later cycles, A and B alternate their roles in the task, perpetuating this collaborative cycle until a joint conclusion is reached.
Achieving coordination in collaborative problem-solving groups. Brigid Barron, The journal of the learning sciences. 942000</p>
<p>Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, arXiv:2303.12712Sparks of artificial general intelligence: Early experiments with gpt-4. 2023arXiv preprint</p>
<p>Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang Zhang, Jie Fu, Zhiyuan Liu, arXiv:2308.07201Chateval: Towards better llm-based evaluators through multi-agent debate. 2023arXiv preprint</p>
<p>Adaptive discovering and merging for incremental novel class discovery. Guangyao Chen, Peixi Peng, Yangru Huang, Mengyue Geng, Yonghong Tian, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202438</p>
<p>Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan, Yujia Qin, Yaxi Lu, Ruobing Xie, arXiv:2308.10848Facilitating multi-agent collaboration and exploring emergent behaviors in agents. 2023. 2, 4, 5, 6, 17arXiv preprint</p>
<p>Teaching large language models to self-debug. Xinyun Chen, Maxwell Lin, Nathanael Schärli, Denny Zhou, arXiv:2304.051282023arXiv preprint</p>
<p>Improving factuality and reasoning in language models through multiagent debate. Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, Igor Mordatch, arXiv:2305.14325202313arXiv preprint</p>
<p>Improving language model negotiation with self-play and in-context learning from ai feedback. Yao Fu, Hao Peng, Tushar Khot, Mirella Lapata, arXiv:2305.101422023arXiv preprint</p>
<p>Critic: Large language models can self-correct with tool-interactive critiquing. Zhibin Gou, Zhihong Shao, Yeyun Gong, Yelong Shen, Yujiu Yang, Nan Duan, Weizhu Chen, 2023</p>
<p>Auto-gpt: An autonomous gpt-4 experiment. Significant Gravitas, 2023. 202357</p>
<p>Rui Hao, Linmei Hu, Weijian Qi, Qingliu Wu, Yirui Zhang, Liqiang Nie, arXiv:2304.12998Chatllm network: More brains, more intelligence. 202313arXiv preprint</p>
<p>Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Ceyao Zhang, Zili Wang, Steven Ka, Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, arXiv:2308.00352Meta programming for multi-agent collaborative framework. 2023. 2, 3, 5, 6arXiv preprint</p>
<p>Inner monologue: Embodied reasoning through planning with language models. Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence, Andy Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar, arXiv:2207.056082022arXiv preprint</p>
<p>TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension. Mandar Joshi, Eunsol Choi, Daniel Weld, Luke Zettlemoyer, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. the 55th Annual Meeting of the Association for Computational LinguisticsAssociation for Computational LinguisticsJuly 2017</p>
<p>Martin Josifoski, Lars Klein, Maxime Peyrard, Yifei Li, Saibo Geng, Julian Paul Schnitzler, Yuxing Yao, Jiheng Wei, Debjit Paul, Robert West, arXiv:2308.01285Flows: Building blocks of reasoning and collaborating ai. 2023arXiv preprint</p>
<p>Guohao Li, Hasan Abed, Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, Bernard Ghanem, Camel, arXiv:2303.17760Communicative agents for" mind" exploration of large scale language model society. 202323arXiv preprint</p>
<p>Encouraging divergent thinking in large language models through multi-agent debate. Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Zhaopeng Tu, Shuming Shi, arXiv:2305.19118202313arXiv preprint</p>
<p>Self-refine: Iterative refinement with self-feedback. Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, arXiv:2303.176512023arXiv preprint</p>
<p>On faithfulness and factuality in abstractive summarization. Joshua Maynez, Shashi Narayan, Bernd Bohnet, Ryan Mcdonald, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsAssociation for Computational LinguisticsJuly 2020</p>
<p>Task-driven autonomous agent utilizing gpt-4, pinecone, and langchain for diverse applications. Nakajima, April 2023. 2023183task-driven-autonomous-agent-utilizing-gpt-4-pinecone-and-langchain-for-diverse-applications</p>
<p>Collaborative problem solving. Laurie Miller, Nelson , Instructional-design theories and models. Routledge2013</p>
<p>. OpenAI. Gpt-4 technical report. 12023</p>
<p>Sung Joon, Park, C Joseph, Carrie J O'brien, Meredith Ringel Cai, Percy Morris, Michael S Liang, Bernstein, arXiv:2304.03442Generative agents: Interactive simulacra of human behavior. 2023arXiv preprint</p>
<p>Social simulacra: Creating populated prototypes for social computing systems. Sung Joon, Lindsay Park, Carrie Popowski, Meredith Ringel Cai, Percy Morris, Michael S Liang, Bernstein, Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology. the 35th Annual ACM Symposium on User Interface Software and Technology2022417</p>
<p>Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan Liu, Maosong Sun, arXiv:2307.07924Communicative agents for software development. 2023arXiv preprint</p>
<p>Is chatgpt a general-purpose natural language processing task solver?. Chengwei Qin, Aston Zhang, Zhuosheng Zhang, Jiaao Chen, Michihiro Yasunaga, Diyi Yang, arXiv:2302.064762023arXiv preprint</p>
<p>The construction of shared knowledge in collaborative problem solving. Jeremy Roschelle, Stephanie D Teasley, Computer supported collaborative learning. Springer1995</p>
<p>Reflexion: an autonomous agent with dynamic memory and self-reflection. Noah Shinn, Beck Labash, Ashwin Gopinath, arXiv:2303.113662023arXiv preprint</p>
<p>Yu Shu, Siwei Dong, Guangyao Chen, Wenhao Huang, Ruihua Zhang, Daochen Shi, Qiqi Xiang, Yemin Shi, arXiv:2308.15930Llasm: Large language and speech model. 2023arXiv preprint</p>
<p>The empirical case for two systems of reasoning. Steven A Sloman, Psychological bulletin. 1191</p>
<p>Multi-agent collaboration: Harnessing the power of intelligent llm agents. Yashar Talebirad, Amirhossein Nadiri, arXiv:2306.033142023arXiv preprint</p>
<p>Boxin Wang, Weixin Chen, Hengzhi Pei, Chulin Xie, Mintong Kang, Chenhui Zhang, Chejian Xu, Zidi Xiong, Ritik Dutta, Rylan Schaeffer, arXiv:2306.11698A comprehensive assessment of trustworthiness in gpt models. 2023arXiv preprint</p>
<p>Large language models are not fair evaluators. Peiyi Wang, Lei Li, Liang Chen, Dawei Zhu, Binghuai Lin, Yunbo Cao, Qi Liu, Tianyu Liu, Zhifang Sui, arXiv:2305.179262023arXiv preprint</p>
<p>Unleashing cognitive synergy in large language models: A task-solving agent through multi-persona selfcollaboration. Zhenhailong Wang, Shaoguang Mao, Wenshan Wu, Tao Ge, Furu Wei, Heng Ji, arXiv:2307.053002023. 1, 2, 3, 4, 5, 6, 91017arXiv preprint</p>
<p>Epidemic modeling with generative agents. Ross Williams, Niyousha Hosseinichimeh, Aritra Majumdar, Navid Ghaffarzadegan, arXiv:2307.049862023. 2, 4, 17arXiv preprint</p>
<p>Collective intelligence and group performance. Anita Williams Woolley, Ishani Aggarwal, Thomas W Malone, Current Directions in Psychological Science. 2462015</p>
<p>Autogen: Enabling next-gen llm applications via multi-agent conversation framework. Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, Chi Wang, arXiv:2308.08155202335arXiv preprint</p>
<p>Benfeng Xu, An Yang, Junyang Lin, Quan Wang, Chang Zhou, Yongdong Zhang, Zhendong Mao, arXiv:2305.14688Expertprompting: Instructing large language models to be distinguished experts. 2023. 2, 4, 5arXiv preprint</p>
<p>Tree of thoughts: Deliberate problem solving with large language models. Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, Karthik Narasimhan, arXiv:2305.106012023910arXiv preprint</p>
<p>Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, Yuan Cao, arXiv:2210.03629React: Synergizing reasoning and acting in language models. 2022710arXiv preprint</p>
<p>Judging llm-as-a-judge with mt-bench and chatbot arena. Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, arXiv:2306.056852023arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>