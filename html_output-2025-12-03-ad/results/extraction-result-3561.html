<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3561 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3561</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3561</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-79.html">extraction-schema-79</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to generate or design novel chemicals for specific applications, including details of the model, the application, the generation method, evaluation metrics, results, and any reported limitations or challenges.</div>
                <p><strong>Paper ID:</strong> paper-ae6a4cd221684be6ca3082b6f526a7901281490b</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/ae6a4cd221684be6ca3082b6f526a7901281490b" target="_blank">Emergent autonomous scientific research capabilities of large language models</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> This paper presents an Intelligent Agent system that combines multiple large language models for autonomous design, planning, and execution of scientific experiments and showcases the Agent's scientific research capabilities with three distinct examples.</p>
                <p><strong>Paper Abstract:</strong> Transformer-based large language models are rapidly advancing in the field of machine learning research, with applications spanning natural language, biology, chemistry, and computer programming. Extreme scaling and reinforcement learning from human feedback have significantly improved the quality of generated text, enabling these models to perform various tasks and reason about their choices. In this paper, we present an Intelligent Agent system that combines multiple large language models for autonomous design, planning, and execution of scientific experiments. We showcase the Agent's scientific research capabilities with three distinct examples, with the most complex being the successful performance of catalyzed cross-coupling reactions. Finally, we discuss the safety implications of such systems and propose measures to prevent their misuse.</p>
                <p><strong>Cost:</strong> 0.009</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3561.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3561.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to generate or design novel chemicals for specific applications, including details of the model, the application, the generation method, evaluation metrics, results, and any reported limitations or challenges.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Multi-LLM Agent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Intelligent Agent (multi-large-language-model system)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-module Intelligent Agent that orchestrates multiple LLMs (GPT-4, GPT-3.5) plus tooling (web search, vectorized docs, Python execution, automation APIs) to autonomously design, plan, and execute chemical experiments including reaction selection, stoichiometry calculations, protocol generation, and hardware control.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Emergent autonomous scientific research capabilities of large language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Multi-LLM Agent (GPT-4 as Planner + GPT-3.5 for faster browsing/summarization)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>System-level agent composed of LLM modules (Planner primarily using GPT-4; auxiliary use of GPT-3.5 for faster web/document summarization), connected to external tools: Google Search API, ada embeddings + vector search over documentation, Python code execution in isolated Docker containers, and automation/hardware APIs (Opentrons, Emerald Cloud Lab SLL). The paper notes GPT-4 training-data cutoff (Sep 2021) and limited public details on model internals.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Prompt-driven experimental design and molecule/reaction ideation: the Planner issues web searches, ingests literature and hardware docs (via DOCUMENTATION and BROWSE actions), uses embeddings to retrieve API docs, formulates reaction plans, computes stoichiometry in Python, and generates executable protocols for liquid handlers/heater-shakers; for novel-chemistry ideation the Agent solicits trends, selects biological targets, requests scaffolds and proposes synthetic routes (interactive prompt engineering + retrieval-augmented generation).</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Chemical synthesis planning and autonomous execution (organic synthesis workflows, cross-coupling reactions), plus exploratory drug discovery ideation (anticancer scaffold selection).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Practical experimental validation where performed: GC-MS analysis to detect desired products (used to assess success of planned reactions); code execution success (ability to generate runnable protocols and correct errors based on tracebacks); qualitative correctness of synthetic planning (matching known literature procedures). For novel-drug ideation no experimental metrics reported (ideation only). No formal computational metrics (validity, novelty, synthesizability scores) were reported for generated molecules.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Agent autonomously planned and executed catalyzed cross-coupling reactions (Suzuki and Sonogashira) by selecting substrates, catalysts (Pd/NHC), and base (triethylamine), calculating volumes, generating protocols, correcting a hardware-name mistake via documentation lookup, and running the protocol; subsequent GC-MS confirmed formation of target products. In an exploratory, non-executed task the Agent was prompted to 'develop a novel anticancer drug' — it surveyed trends, selected a biological target, proposed a scaffold and attempted to propose a synthetic route (synthesis was not performed experimentally). Other synthesis examples (ibuprofen, aspirin, aspartame) show planning and stoichiometric calculations; aspartame initial product missed a methyl group but was corrected after providing an example.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baselines</strong></td>
                            <td>No quantitative comparisons to prior computational chemistry generative models or traditional cheminformatics pipelines are reported in the paper; the work is presented as a systems demonstration rather than a benchmarked comparison. The paper cites related works (e.g., ChemCrow) but does not perform head-to-head evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Reported limitations include: reliance on web/documentation quality and LLM pretraining knowledge (GPT-4 cutoff Sept 2021) causing errors on post-cutoff hardware (initial wrong heater-shaker name); occasional incorrect chemical suggestions (e.g., missing methyl group in aspartame), volatility/unstable suggestions when using high-temperature sampling for catalysts/bases; lack of explicit molecule-level validity/synthesizability scoring; novel-compound risk-detection is weak (agent better at refusing known harmful compounds than novel toxins); potential for prompt-based circumvention of safety checks (renaming compounds), and general security/dual-use concerns. For novel anticancer-drug ideation, no experimental validation was performed so efficacy and synthesizability remain untested.</td>
                        </tr>
                        <tr>
                            <td><strong>extra_notes</strong></td>
                            <td>Agent integrates retrieval augmentation (web + vectorized docs) and executes iterative code -> run -> fix loop; safety/human-in-the-loop recommendation emphasized by authors.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Emergent autonomous scientific research capabilities of large language models', 'publication_date_yy_mm': '2023-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3561.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3561.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to generate or design novel chemicals for specific applications, including details of the model, the application, the generation method, evaluation metrics, results, and any reported limitations or challenges.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4 (chemical design use)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative Pre-trained Transformer 4 (as used in chemical research Agent)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>OpenAI's GPT-4 LLM used as the primary Planner for reasoning, literature retrieval interpretation, experimental planning, scaffold selection, and protocol/code generation in the Agent system.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Emergent autonomous scientific research capabilities of large language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Transformer-based large language model from OpenAI; exact model size and training data are not disclosed in the paper, authors note GPT-4's training-data cutoff and reference its technical report. GPT-4 was used for high-quality planning and reasoning; GPT-3.5 used in auxiliary roles for faster web/document summarization.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Prompt engineering with retrieval-augmentation (internet search and documentation ingestion) to: (a) identify synthesis routes and reaction conditions from literature, (b) select molecular scaffolds and biological targets (in the anticancer ideation task), (c) propose synthetic procedures and compute stoichiometry via generated Python code, and (d) generate automation code for liquid handlers / cloud lab SLL. No explicit SMILES- or graph-based de novo molecule sampling method is described for novel-molecule generation; molecule/scaffold proposals are produced via natural-language scaffolding and literature-derived examples.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Autonomous experimental design for organic synthesis (Suzuki, Sonogashira, Friedel–Crafts, aspirin synthesis examples) and ideation-stage drug discovery (anticancer scaffold selection).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Empirical chemical analytics (GC-MS) used to evaluate success of planned reactions; code execution tracebacks and successful hardware runs used to evaluate protocol validity; qualitative inspection for correctness of planning (e.g., correct substrate selection). For ideation-only tasks no quantitative drug-discovery metrics (potency, ADMET, novelty scores) were reported.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>GPT-4 successfully drove planning and execution of catalytic cross-coupling experiments (selected reagents and catalyst, computed reagent volumes, wrote runnable protocols, corrected code/hardware mistakes, and yielded target products confirmed by GC-MS). In the anticancer-drug prompt GPT-4 identified trends and a target, recommended a scaffold and proposed synthetic steps but did not perform experimental validation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baselines</strong></td>
                            <td>No direct baseline comparisons (e.g., to graph generative models, reinforcement-learning molecule generators, or expert chemists) are provided in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>GPT-4 limitations observed in the work include: knowledge cutoff leading to missing newer hardware APIs or modules (necessitating documentation ingestion), occasional missing functional groups or chemical details (as in aspartame example), sensitivity to prompt-temperature settings leading to variable catalyst/base suggestions, and limited capability to reliably identify or refuse novel dual-use molecules. The paper emphasizes the need for human oversight, curated data sources, and guardrails to mitigate misuse.</td>
                        </tr>
                        <tr>
                            <td><strong>extra_notes</strong></td>
                            <td>The authors explicitly state that some tasks (e.g., anticancer-drug ideation) were not experimentally executed; they also report that GPT-4 was used alongside other tools (search APIs, embeddings, code execution) rather than as a standalone molecule generator.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Emergent autonomous scientific research capabilities of large language models', 'publication_date_yy_mm': '2023-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Chemformer: a pre-trained transformer for computational chemistry <em>(Rating: 2)</em></li>
                <li>Generative Chemical Transformer: Neural Machine Learning of Molecular Geometric Structures from Chemical Language via Attention <em>(Rating: 2)</em></li>
                <li>ChemCrow: Augmenting large language models with chemistry tools <em>(Rating: 2)</em></li>
                <li>GPT-4 Technical Report <em>(Rating: 1)</em></li>
                <li>Dual use of artificial-intelligence-powered drug discovery <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3561",
    "paper_id": "paper-ae6a4cd221684be6ca3082b6f526a7901281490b",
    "extraction_schema_id": "extraction-schema-79",
    "extracted_data": [
        {
            "name_short": "Multi-LLM Agent",
            "name_full": "Intelligent Agent (multi-large-language-model system)",
            "brief_description": "A multi-module Intelligent Agent that orchestrates multiple LLMs (GPT-4, GPT-3.5) plus tooling (web search, vectorized docs, Python execution, automation APIs) to autonomously design, plan, and execute chemical experiments including reaction selection, stoichiometry calculations, protocol generation, and hardware control.",
            "citation_title": "Emergent autonomous scientific research capabilities of large language models",
            "mention_or_use": "use",
            "model_name": "Multi-LLM Agent (GPT-4 as Planner + GPT-3.5 for faster browsing/summarization)",
            "model_description": "System-level agent composed of LLM modules (Planner primarily using GPT-4; auxiliary use of GPT-3.5 for faster web/document summarization), connected to external tools: Google Search API, ada embeddings + vector search over documentation, Python code execution in isolated Docker containers, and automation/hardware APIs (Opentrons, Emerald Cloud Lab SLL). The paper notes GPT-4 training-data cutoff (Sep 2021) and limited public details on model internals.",
            "generation_method": "Prompt-driven experimental design and molecule/reaction ideation: the Planner issues web searches, ingests literature and hardware docs (via DOCUMENTATION and BROWSE actions), uses embeddings to retrieve API docs, formulates reaction plans, computes stoichiometry in Python, and generates executable protocols for liquid handlers/heater-shakers; for novel-chemistry ideation the Agent solicits trends, selects biological targets, requests scaffolds and proposes synthetic routes (interactive prompt engineering + retrieval-augmented generation).",
            "application_domain": "Chemical synthesis planning and autonomous execution (organic synthesis workflows, cross-coupling reactions), plus exploratory drug discovery ideation (anticancer scaffold selection).",
            "evaluation_metrics": "Practical experimental validation where performed: GC-MS analysis to detect desired products (used to assess success of planned reactions); code execution success (ability to generate runnable protocols and correct errors based on tracebacks); qualitative correctness of synthetic planning (matching known literature procedures). For novel-drug ideation no experimental metrics reported (ideation only). No formal computational metrics (validity, novelty, synthesizability scores) were reported for generated molecules.",
            "results_summary": "Agent autonomously planned and executed catalyzed cross-coupling reactions (Suzuki and Sonogashira) by selecting substrates, catalysts (Pd/NHC), and base (triethylamine), calculating volumes, generating protocols, correcting a hardware-name mistake via documentation lookup, and running the protocol; subsequent GC-MS confirmed formation of target products. In an exploratory, non-executed task the Agent was prompted to 'develop a novel anticancer drug' — it surveyed trends, selected a biological target, proposed a scaffold and attempted to propose a synthetic route (synthesis was not performed experimentally). Other synthesis examples (ibuprofen, aspirin, aspartame) show planning and stoichiometric calculations; aspartame initial product missed a methyl group but was corrected after providing an example.",
            "comparison_to_baselines": "No quantitative comparisons to prior computational chemistry generative models or traditional cheminformatics pipelines are reported in the paper; the work is presented as a systems demonstration rather than a benchmarked comparison. The paper cites related works (e.g., ChemCrow) but does not perform head-to-head evaluations.",
            "limitations_challenges": "Reported limitations include: reliance on web/documentation quality and LLM pretraining knowledge (GPT-4 cutoff Sept 2021) causing errors on post-cutoff hardware (initial wrong heater-shaker name); occasional incorrect chemical suggestions (e.g., missing methyl group in aspartame), volatility/unstable suggestions when using high-temperature sampling for catalysts/bases; lack of explicit molecule-level validity/synthesizability scoring; novel-compound risk-detection is weak (agent better at refusing known harmful compounds than novel toxins); potential for prompt-based circumvention of safety checks (renaming compounds), and general security/dual-use concerns. For novel anticancer-drug ideation, no experimental validation was performed so efficacy and synthesizability remain untested.",
            "extra_notes": "Agent integrates retrieval augmentation (web + vectorized docs) and executes iterative code -&gt; run -&gt; fix loop; safety/human-in-the-loop recommendation emphasized by authors.",
            "uuid": "e3561.0",
            "source_info": {
                "paper_title": "Emergent autonomous scientific research capabilities of large language models",
                "publication_date_yy_mm": "2023-04"
            }
        },
        {
            "name_short": "GPT-4 (chemical design use)",
            "name_full": "Generative Pre-trained Transformer 4 (as used in chemical research Agent)",
            "brief_description": "OpenAI's GPT-4 LLM used as the primary Planner for reasoning, literature retrieval interpretation, experimental planning, scaffold selection, and protocol/code generation in the Agent system.",
            "citation_title": "Emergent autonomous scientific research capabilities of large language models",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_description": "Transformer-based large language model from OpenAI; exact model size and training data are not disclosed in the paper, authors note GPT-4's training-data cutoff and reference its technical report. GPT-4 was used for high-quality planning and reasoning; GPT-3.5 used in auxiliary roles for faster web/document summarization.",
            "generation_method": "Prompt engineering with retrieval-augmentation (internet search and documentation ingestion) to: (a) identify synthesis routes and reaction conditions from literature, (b) select molecular scaffolds and biological targets (in the anticancer ideation task), (c) propose synthetic procedures and compute stoichiometry via generated Python code, and (d) generate automation code for liquid handlers / cloud lab SLL. No explicit SMILES- or graph-based de novo molecule sampling method is described for novel-molecule generation; molecule/scaffold proposals are produced via natural-language scaffolding and literature-derived examples.",
            "application_domain": "Autonomous experimental design for organic synthesis (Suzuki, Sonogashira, Friedel–Crafts, aspirin synthesis examples) and ideation-stage drug discovery (anticancer scaffold selection).",
            "evaluation_metrics": "Empirical chemical analytics (GC-MS) used to evaluate success of planned reactions; code execution tracebacks and successful hardware runs used to evaluate protocol validity; qualitative inspection for correctness of planning (e.g., correct substrate selection). For ideation-only tasks no quantitative drug-discovery metrics (potency, ADMET, novelty scores) were reported.",
            "results_summary": "GPT-4 successfully drove planning and execution of catalytic cross-coupling experiments (selected reagents and catalyst, computed reagent volumes, wrote runnable protocols, corrected code/hardware mistakes, and yielded target products confirmed by GC-MS). In the anticancer-drug prompt GPT-4 identified trends and a target, recommended a scaffold and proposed synthetic steps but did not perform experimental validation.",
            "comparison_to_baselines": "No direct baseline comparisons (e.g., to graph generative models, reinforcement-learning molecule generators, or expert chemists) are provided in the paper.",
            "limitations_challenges": "GPT-4 limitations observed in the work include: knowledge cutoff leading to missing newer hardware APIs or modules (necessitating documentation ingestion), occasional missing functional groups or chemical details (as in aspartame example), sensitivity to prompt-temperature settings leading to variable catalyst/base suggestions, and limited capability to reliably identify or refuse novel dual-use molecules. The paper emphasizes the need for human oversight, curated data sources, and guardrails to mitigate misuse.",
            "extra_notes": "The authors explicitly state that some tasks (e.g., anticancer-drug ideation) were not experimentally executed; they also report that GPT-4 was used alongside other tools (search APIs, embeddings, code execution) rather than as a standalone molecule generator.",
            "uuid": "e3561.1",
            "source_info": {
                "paper_title": "Emergent autonomous scientific research capabilities of large language models",
                "publication_date_yy_mm": "2023-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Chemformer: a pre-trained transformer for computational chemistry",
            "rating": 2
        },
        {
            "paper_title": "Generative Chemical Transformer: Neural Machine Learning of Molecular Geometric Structures from Chemical Language via Attention",
            "rating": 2
        },
        {
            "paper_title": "ChemCrow: Augmenting large language models with chemistry tools",
            "rating": 2
        },
        {
            "paper_title": "GPT-4 Technical Report",
            "rating": 1
        },
        {
            "paper_title": "Dual use of artificial-intelligence-powered drug discovery",
            "rating": 1
        }
    ],
    "cost": 0.0089995,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Emergent autonomous scientific research capabilities of large language models</h1>
<p>Daniil A. Boiko, ${ }^{1}$ Robert MacKnight, ${ }^{1}$ and Gabe Gomes ${ }^{* 1,2,3}$</p>
<ol>
<li>Department of Chemical Engineering, Carnegie Mellon University, Pittsburgh, PA 15213, USA</li>
<li>Department of Chemistry, Carnegie Mellon University, Pittsburgh, PA 15213, USA</li>
<li>Wilton E. Scott Institute for Energy Innovation, Carnegie Mellon University, Pittsburgh, PA 15213, USA
*corresponding author, gabegomes@cmu.edu</li>
</ol>
<h4>Abstract</h4>
<p>Transformer-based large language models are rapidly advancing in the field of machine learning research, with applications spanning natural language, biology, chemistry, and computer programming. Extreme scaling and reinforcement learning from human feedback have significantly improved the quality of generated text, enabling these models to perform various tasks and reason about their choices. In this paper, we present an Intelligent Agent system that combines multiple large language models for autonomous design, planning, and execution of scientific experiments. We showcase the Agent's scientific research capabilities with three distinct examples, with the most complex being the successful performance of catalyzed cross-coupling reactions. Finally, we discuss the safety implications of such systems and propose measures to prevent their misuse.</p>
<h2>Keywords</h2>
<p>Large Language Models; Intelligent Agents; Generative AI; Autonomous Experimentation; Automation; Physical Sciences; Catalysis.</p>
<h2>Glossary</h2>
<ul>
<li>LLMs: Large Language Models. In this paper, we use OpenAI's GPT-3.5 and GPT-4.</li>
<li>Agent: LLM-based Intelligent Agent (IA) system.</li>
<li>Prompt-provider: A scientist - in this work, one of the human authors - that provides the initial prompt to the Agent.</li>
</ul>
<h1>Main</h1>
<p>Large language models (LLMs), particularly transformer-based models, are experiencing rapid advancements in recent years. These models have been successfully applied to various domains, including natural language, ${ }^{1-5}$ biological ${ }^{6,7}$ and chemical research, ${ }^{8,9}$ as well as code generation. Extreme scaling of models, as demonstrated by OpenAI, has led to significant breakthroughs in the field. ${ }^{1,10}$ Moreover, techniques such as reinforcement learning from human feedback (RLHF) ${ }^{11}$ can considerably enhance the quality of generated text and the models' capability to perform diverse tasks while reasoning about their decisions. ${ }^{12}$</p>
<p>On March 14, 2023, OpenAI released their most capable LLM to date, GPT-4. ${ }^{10}$ Although specific details about the model training, sizes, and data used are limited in the technical report, researchers have provided substantial evidence of the model's exceptional problem-solving abilities. Those include - but are not limited to - high percentiles on the SAT and BAR exams, LeetCode challenges, and contextual explanations from images, including niche jokes. ${ }^{10}$ Moreover, the technical report provides an example of how the model can be employed to address chemistry-related problems.</p>
<p>Inspired by these results, we aimed to develop a multi-LLMs-based Intelligent Agent (hereafter simply called Agent) capable of autonomous design, planning, and performance of complex scientific experiments. The Agent can use tools ${ }^{13}$ to browse the internet and relevant documentation, use robotic experimentation APIs, and leverage other LLMs for various tasks. In this paper, we demonstrate the versatility and efficacy of our Agent by evaluating its performance in three tasks: 1. Efficiently searching and navigating through extensive hardware documentation; 2. Precisely controlling liquid handling instruments at a low level; 3. Tackling complex problems that necessitate simultaneous utilization of multiple hardware modules or integration of diverse data sources.</p>
<h2>The Agent's architecture: action space defined by its multiple modules.</h2>
<p>The Agent's system consists of four components (Figure 1), driven by the "Planner." The Planner takes a prompt as input (e.g., "Perform multiple Suzuki reactions") and carries out actions according to this request. The action space includes accessing the internet ("GOOGLE <query>" request), performing calculations in Python ("PYTHON <code>"), accessing documentation ("DOCUMENTATION <query>"), and running the final experiment ("EXPERIMENT <code>"). Experiments can be performed in various environments - a cloud lab, using a liquid handler, or by providing instructions for performing experiments manually. The model is instructed to reason about its actions, search the internet, calculate all quantities in the reaction, and then perform the corresponding reaction. The Agent is aware that, on average, at least ten steps are needed to fully understand the requested task. No further clarifying questions to the prompt-provider are necessary if the provided description is detailed enough.</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1. Overview of the system architecture. The Agent is composed of multiple modules that exchange messages. Some of them have access to APIs, the Internet, and Python interpreter.</p>
<p>The "Web searcher" component receives queries from the Planner, transforms them into appropriate web search queries, and executes them using the Google Search API. The first ten documents returned are filtered, excluding PDFs, and the resulting list of web pages is passed back to the Web searcher component. The component can then use the "BROWSE" action to extract text from the web pages and compile an answer for the Planner. For this task we can employ GPT-3.5, as it performs significantly faster than GPT-4 with no appreciable loss of quality. The "Docs searcher" component combs through the hardware documentation (e.g., robotic liquid handler, GC-MS, a cloud lab) by utilizing a query and documentation index to find the most relevant pages/sections. Then the best matching results are aggregated to provide a comprehensive and accurate final answer. This module places an emphasize on providing specific function parameter and syntactic information for the hardware API.</p>
<p>The "Code execution" component does not utilize any language models and simply executes the code in an isolated Docker container, protecting the end host machine from any unexpected actions by the Planner. All code outputs are passed back to the Planner, enabling it to fix its predictions in case of software errors. The same applies to the "Automation" component, which then executes the generated code on corresponding hardware or just provides the synthetic procedure for manual experimentation.</p>
<h1>Web search enables Agent's synthesis planning capabilities.</h1>
<p>To demonstrate the system's functionality, we use the synthesis of ibuprofen as an example (Figure 2A). The input prompt is straightforward: "Synthesize ibuprofen." The model then searches the internet for information on ibuprofen synthesis, locating the necessary details on a particular website. The model correctly identifies the first step of the synthesis, which is the Friedel-Crafts reaction between isobutylbenzene and acetic anhydride catalyzed by aluminum chloride (see Appendix A). The planning phase for the first step concludes once the model requests documentation for the Friedel-Crafts synthesis procedure.</p>
<p>Two other examples of the system's capabilities include the synthesis of common aspirin (Figure 2B and Appendix B), which the model searches and designs effectively, and aspartame synthesis (Figure 2D and Appendix C), which, although missing the methyl group in the product, can be corrected once the model receives a suitable synthetic example for execution in the cloud lab. Furthermore, when asked to study a Suzuki reaction, the model accurately identifies the substrates and the product (Figure 2C and Appendix D). The high-temperature parameter for text generation results in volatility when suggesting specific catalysts or bases.</p>
<p>Connecting the model to a chemical reaction database such as Reaxys ${ }^{14}$ or SciFinder ${ }^{15}$ via API could significantly enhance the system's performance. Alternatively, analyzing the system's previous statements is another approach to improving its accuracy.
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2. Agent's capabilities in the synthesis planning task. A. Ibuprofen synthesis. B. Aspirin synthesis. C. Suzuki reaction mechanism study, where the Agent had to choose how to study the mechanism. D. Aspartame synthesis.</p>
<h1>Vector search can be employed for retrieval of dense hardware API documentation.</h1>
<p>To integrate an intelligent Agent capable of sophisticated reasoning with contemporary software, it is crucial to provide a clear and concise presentation of relevant technical documentation. Modern software is characterized by its complexity and the intricate interplay between various components. Consequently, comprehensive software documentation is indispensable for programmers to comprehend these interactions and utilize them effectively to accomplish their goals. Nonetheless, traditional software documentation frequently employs highly technical language, which can be challenging for non-experts to grasp. This creates a barrier to entry for many potential users of the software, limiting its reach and effectiveness.</p>
<p>Large language models have the potential to overcome this barrier by generating natural language descriptions of software documentation that are more accessible to nonexperts. These models are trained on a vast corpus of text from a variety of sources, which includes extensive information related to Application Programming Interfaces (APIs). One such API is the Opentrons Python API. ${ }^{16}$ However, the GPT-4's training data contains information up until September 2021. Thus, there is potential for enhancing the Agent's accuracy in using the API. To this end, we devised an approach to provide the Agent with requisite documentation for a given task, summarized in Figure 3A.
<img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3. Overview of documentation search. A. Prompt-to-(improved OT-2 Python API)-code via ada embedding and distance-based vector search. B. Prompt-to-function recommendation in Emerald Cloud Lab symbolic lab language via supplementation of documentation guide.</p>
<p>For all 14 sections of the OT-2 API documentation we have generated OpenAI's ada embeddings to cross reference and compute similarity with respect to a query. The agent is instructed to inquire about proper use of the API when needed via the Documentation action. An ada embedding for the subsequent query is generated and documentation sections are selected via a distance-based vector search. The number of sections provided is dictated by the number of GPT-4 tokens present in the raw text for a given section. The maximum number of tokens is set to 7800 , such that the relevant documents can be provided in one step. This approach proved critical for providing the agent with information about the heater-shaker hardware module necessary for performing chemical reactions (see "The Agent is capable of designing and performing chemical experiments." section).</p>
<p>A greater challenge emerges when applying this approach to a more diverse robotic platform, such as the Emerald Cloud Lab (ECL). Nonetheless, we can explore the effectiveness of providing information about the Cloud Lab's Symbolic Lab Language (SLL), which is currently unknown to the GPT-4 model. For this we provide the Agent with a documentation guide from ECL pertaining to all available functions for running experiments. ${ }^{17}$ Figure 3B summarizes three examples of the User providing a simple query and the Agent directing the User to relevant ECL functions. More examples are shared in the Appendix G. In all cases, the Agent correctly identifies functions for accomplishing the given task. After selection of appropriate functions, the raw plain text documentation is passed through a separate GPT-4 model to perform code syntax retention and summarization. Specifically, this model efficiently retains information regarding the various options, instruments, and parameters for a given function. Once the entire documentation has been ingested, the model is prompted to produce a code block utilizing the given function to be passed back to the Planner. This serves as a basis for the model to utilize this function with specific options, instruments, and parameters as they are gathered by the Web searcher.</p>
<h1>Mastering automation: multi-instrument systems controlled by natural language.</h1>
<p>Access to documentation enables us to provide sufficient information for the Agent to conduct experiments in the physical world. To initiate the investigation, we chose an open-source liquid handler with a well-documented Python API. The "Getting Started" page from its documentation was supplied to the Planner in the system prompt. Other pages were vectorized using the approach described in the "Providing hardware API Documentation" section. In this section, we did not grant access to the internet (Figure 4A).</p>
<p>A.
<img alt="img-3.jpeg" src="img-3.jpeg" />
<img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>UV-Vis data from plate 1 is ready. You can access it using PYTHON, it will be in the file named
'plate1.npy'. You will have NumPy installed. The file contains NumPy array of shape $(9,12,41)$. There are 41 wavelengths from 350 to 750 with 10 nm step. Think about how would different colors absorb first.</p>
<p>Automated answer</p>
<ul>
<li>guiding prompt
[530, 430, 630]
Automated answer
<img alt="img-5.jpeg" src="img-5.jpeg" /></li>
</ul>
<p>Figure 4. Robotic liquid handler control capabilities and integration with analytical tools. A. Overview of the Agent's configuration. B-E. Drawing geometrical figures. F. The Agent solves a color identification problem using UV-Vis data.</p>
<p>We began with simple experiments on operating the robot, which simultaneously required the ability to consider a set of samples as a whole (in our case, an entire microplate). Straightforward prompts in natural language, such as "Color every other line with one color of your choice," resulted in mostly accurate protocols. When executed by the robot, these protocols closely resembled the requested prompt (Figure 4B-E).</p>
<p>The Agent's first action was to prepare small samples of the original solutions (Figure 4F). It then requested UV-Vis measurements to be performed (Appendix H). Once completed, the Agent was provided with a file name containing a NumPy array with spectra for each well of the microplate. The Agent subsequently wrote Python code to identify the wavelengths with maximum absorbance, using this data to correctly solve the problem.</p>
<h1>Bringing it all together: the Agent's integrated chemical experiment design and execution capabilities.</h1>
<p>Previous experiments could be affected by the knowledge of the Agent's modules from the pretraining step. We wanted to evaluate the Agent's ability to plan an experiment by combining data from the internet, performing the necessary calculations, and ultimately writing the code for the liquid handler. To increase complexity, we asked the Agent to use the heater-shaker module released after the GPT-4 training data collection cutoff. These requirements were incorporated into the Agent's configuration (Figure 5A).</p>
<p>The problem was designed as follows: the Agent is provided with a liquid handler equipped with two microplates. One (Source Plate) contains stock solutions of multiple reagents, including phenyl acetylene and phenylboronic acid, multiple aryl halide coupling partners, two catalysts, two bases, and the solvent to dissolve the sample (Figure 5B). The target plate is installed on the heater-shaker module (Figure 5C). The Agent's goal is to design a protocol to perform Suzuki and Sonogashira reactions.</p>
<p>The Agent begins by searching the internet for information on the requested reactions, their stoichiometry, and conditions (Figure 5D). It selects the correct coupling partners for the corresponding reactions. Among all aryl halides, it selected bromobenzene for Suzuki reaction and iodobenzene for Sonogashira reaction. This behavior changes from each run, as it also selects p-nitroiodobenzene due to its high reactivity in oxidative addition reactions, or bromobenzene because it is reactive but less toxic than aryl iodides. This highlights a potential future use case for the model - performing experiments multiple times to analyze the model's reasoning and construct a bigger picture. The model selected a $\mathrm{Pd} / \mathrm{NHC}$ catalyst as a more efficient, modern approach for cross-coupling reactions, and triethylamine was chosen as the base.</p>
<p>The Agent then calculates the required volumes of all reactants and writes the protocol. However, it used an incorrect heater-shaker module name. Upon noticing the mistake, the model consulted the documentation. This information was then used to modify the protocol, which successfully ran (Figure 5E). Subsequent GC-MS analysis of the reaction mixtures revealed the formation of the target products for both reactions (Appendix I).</p>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 5. Cross-coupling Suzuki and Sonogashira reaction experiments designed and performed by the Agent. A. Overview of the Agent's configuration. B. Available compounds. C. Liquid handler setup. D. Solving the synthesis problem. E. Generated protocol.</p>
<h1>The Agent has high reasoning capabilities.</h1>
<p>The system demonstrates remarkably high reasoning capabilities, enabling it to request necessary information, solve complex problems, and generate high-quality code for experimental design. OpenAI has shown that GPT-4 could rely on some of those capabilities to take actions in the physical world during their initial testing performed by the Alignment Research Center. ${ }^{10}$</p>
<p>The most remarkable reasoning capability exhibited by the Agent was its ability to correct its own code based on the automatically generated outputs. Besides already mentioned examples, during calculations for a mechanistic study of the Suzuki reaction, the model requested the system to execute code that imported the SymPy package (refer to Appendix D), which was not installed. After receiving the corresponding traceback, the Agent revised the code using basic Python. However, this modified code still proved unhelpful, as it did not return any output (the model had assumed that the interpreter was being used in interactive mode). Acknowledging this, the Agent made a final adjustment by incorporating a print() statement.</p>
<h2>The Agent shows interesting approach to key scientific problems.</h2>
<p>Furthermore, we aimed to assess the system's performance when presented with an exceptionally challenging problem. We began by asking the model to develop a novel anticancer drug (refer to Appendix E). The model approached the analysis in a logical and methodical manner: it first inquired about current trends in anticancer drug discovery, subsequently selected a target, and requested a scaffold targeting these compounds. Once the compound was identified, the model attempted its synthesis (this step was not performed experimentally). Another example involved studying the mechanism of a Suzuki reaction (see Appendix D). In this case, the model sought information on the reaction's mechanism and, upon obtaining the individual steps, searched for an example of such a reaction. To execute the reaction, the model calculated the required amounts of reagents and requested the documentation page related to the corresponding synthesis.</p>
<h2>Safety implications of the developed approach.</h2>
<p>There is growing concern regarding the potential misuse of molecular machine learning models for harmful purposes. Specifically, the dual-use application of models for predicting cytotoxicity ${ }^{18}$ to create new poisons or employing AlphaFold2 to develop novel bioweapons has raised alarm. Central to these concerns are the possible misuse of large language models and automated experimentation for dual-use purposes or otherwise. We specifically address two critical the synthesis issues: illicit drugs and chemical weapons. To evaluate these risks, we designed a test set comprising compounds from the DEA's Schedule I and II substances and a list of known chemical weapon agents. We submitted these compounds to the Agent using their common names, IUPAC names, CAS numbers, and SMILES strings to determine if the Agent would carry out extensive analysis and planning (Figure 6).</p>
<p>Note: None of these examples were performed experimentally. Under no circumstances should any individual or organization attempt to recreate, synthesize, or otherwise produce the substances or compounds discussed in this section.
<img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 6. Results of the preliminary dual-use safety study. A. Controlled substances that the Agent agreed to synthesize. B. Controlled substances that Agent refused to synthesize these examples after a web search. C. Controlled substances that Agent refused to synthesize from the initial prompt.</p>
<p>The run logs can be found in Appendix F. Out of 11 different prompts (Figure 6), four (36\%) provided a synthesis solution and attempted to consult documentation to execute the procedure. This figure is alarming on its own, but an even greater concern is the way in which the Agent declines to synthesize certain threats. Out of the seven refused chemicals, five were rejected after the Agent utilized search functions to gather more information about the substance. For instance, when asked about synthesizing codeine, the Agent becomes alarmed upon learning the connection between codeine and morphine, only then concluding that the synthesis cannot be conducted due to the requirement of a controlled substance. However, this search function can be easily manipulated by altering the terminology, such as replacing all mentions of morphine with "Compound A" and codeine with "Compound B". Alternatively, when requesting a synthesis procedure that must be performed in a DEA-licensed facility, bad actors can mislead the Agent by falsely claiming their facility is licensed, prompting the Agent to devise a synthesis solution.</p>
<p>In the remaining two instances, the Agent recognized the common names "heroin" and "mustard gas" as threats and prevented further information gathering. While these results are promising, it is crucial to recognize that the system's capacity to detect misuse primarily applies to known compounds. For unknown compounds, the model is less likely to identify potential misuse, particularly for complex protein toxins where minor sequence changes might allow them to maintain the same properties but become unrecognizable to the model.</p>
<p>It is important to note that while the potential for dual use of Intelligent Agent capable of running scientific experiments is real, fully monitored cloud labs remain a safer choice than simply remote-connected machines. Screening, monitoring, and control safety systems such as the ones implemented by major cloud lab companies offer an additional layer of protection from potential misuses or bad actors.</p>
<h1>Conclusions</h1>
<p>In this paper, we presented an Intelligent Agent system capable of autonomously designing, planning, and executing complex scientific experiments. Our system demonstrates exceptional reasoning and experimental design capabilities, effectively addressing complex problems and generating high-quality code.</p>
<p>However, the development of new machine learning systems and automated methods for conducting scientific experiments raises substantial concerns about the safety and potential dual use consequences, particularly in relation to the proliferation of illicit activities and security threats. By ensuring the ethical and responsible use of these powerful tools, we can continue to explore the vast potential of large language models in advancing scientific research while mitigating the risks associated with their misuse.</p>
<h1>Limitations, Safety Recommendations, and a Call to Action</h1>
<p>We strongly believe that guardrails must be put in place to prevent this type of potential dual-use of large language models. We call for the AI community to engage in prioritizing safety of these powerful models. We call upon OpenAI, Microsoft, Google, Meta, Deepmind, Anthropic, and all the other major players to push the strongest possible efforts on safety of their LLMs. We call upon the physical sciences community to be engaged with the players involved in developing LLMs to assist them in developing those guardrails.</p>
<p>There are several limitations and safety concerns associated with the proposed machine learning system. These concerns warrant the implementation of safety guardrails to ensure responsible and secure usage of the system. At the very least, we argue that the community (both Al and physical sciences) should engage in the following recommendations:</p>
<ol>
<li>Human intervention: While the system demonstrates high reasoning capabilities, there might be instances where human intervention is necessary to ensure the safety and reliability of the generated experiments. We recommend incorporating a human-in-the-loop component for the review and approval of potentially sensitive experiments, especially those involving potentially harmful substances or methodologies. We believe that specialists should oversee and deliberate about the Agent's actions in the physical world.</li>
<li>Novel compound recognition: The current system can detect and prevent the synthesis of known harmful compounds. However, it is less efficient at identifying novel compounds with potentially harmful properties. This could be circumvented by implementing machine learning model to identify potentially harmful structures before passing them into the model.</li>
<li>Data quality and reliability: The system relies on the quality of the data it gathers from the internet and operational documentation. To maintain the reliability of the system, we recommend the continuous curation and update of the data sources, ensuring that the most up-to-date and accurate information is being used to inform the system's decision-making process.</li>
<li>System security: The integration of multiple components, including large language models and automated experimentation, poses security risks. We recommend implementing robust security measures, such as encryption and access control, to protect the system from unauthorized access, tampering, or misuse.</li>
</ol>
<h2>Broader Impacts</h2>
<p>The proposed machine learning system has numerous potential broader impacts on science, technology, and society:</p>
<ol>
<li>Acceleration of scientific research: By automating the design, planning, and execution of experiments, the system can significantly accelerate scientific research</li>
</ol>
<p>across various fields. Researchers can focus on interpreting results, refining hypotheses, and making discoveries, while the system handles the experimental process.
2. Democratization of scientific resources: The system can potentially make scientific experimentation more accessible to researchers with limited resources or expertise. It may enable smaller research groups or individuals to conduct complex experiments with the support of large language models and cloud labs, promoting a more inclusive scientific community.
3. Interdisciplinary collaboration: The system's versatility across domains, including natural language, biology, chemistry, and computer programming, can foster interdisciplinary collaboration. Researchers from different fields can leverage the system's capabilities to address complex problems that require a diverse set of skills and knowledge.
4. Education and training: The system can serve as a valuable educational tool for students and researchers to learn about experimental design, methodology, and analysis. It can help develop critical thinking and problem-solving skills, as well as encourage a deeper understanding of scientific principles.
5. Economic impact: By automating and streamlining the experimental process, the system can potentially reduce the costs associated with research and development. This can lead to increased investment in research and innovation, ultimately driving economic growth and competitiveness.</p>
<p>However, the potential broader impacts also include challenges and risks that must be addressed. Ensuring responsible and ethical use of the system, implementing robust security measures, and continuously updating data sources are essential steps to mitigate potential negative consequences, such as the proliferation of harmful substances or the misuse of powerful machine learning tools for nefarious purposes. By addressing these concerns, we can unlock the full potential of the proposed system and drive positive change across scientific research and society at large.</p>
<h1>Acknowledgments</h1>
<p>We are thankful to all Gomes group members for their support, in particular to Letícia Madureira for assistance with the Figures in this manuscript. We would like to thank the following CMU Chemistry groups for their assistance with providing some of chemicals needed for the Agent's experiments: Sydlik, Garcia Borsch, Matyjaszewski, and Ly. We have special thanks for the Noonan group (Prof. Kevin Noonan and Dhruv Sharma) for providing access to chemicals and GC-MS analytics. We would like to thank the team at Emerald Cloud Labs (with special attention to Ben Kline, Ben Smith, and Brian Frezza) for assisting us with parsing their documentation.
G.G. is grateful to the CMU Cloud Lab Initiative led by the Mellon College of Science for its vision of the future of sciences.</p>
<h1>Funding</h1>
<p>G.G. thanks Carnegie Mellon University, the Mellon College of Sciences and its department of chemistry, the College of Engineering and its department of chemical engineering for the startup support.</p>
<h2>Data availability</h2>
<p>Examples of the experiments discussed in the text are provided in the Appendices. Data (including documentation search and cloud lab execution), code, and prompts will be released in the later versions of this work due to safety concerns.</p>
<h2>Competing interests</h2>
<p>The authors have no competing interests to disclose at this moment.</p>
<h2>Author contributions</h2>
<p>D.A.B. designed the computational pipeline and developed "Planner", "Web searcher", and "Code execution" module. R.M. assisted in designing the computational pipeline and developed the "Docs searcher" module. D.A.B. assisted and oversaw the Agent's scientific experiments. D.A.B. and R.M. designed and performed the initial computational safety studies. G.G. designed the concept, performed preliminary studies, and supervised the project. D.A.B, R.M. and G.G. wrote this manuscript.</p>
<h2>Technology use disclosure</h2>
<p>The writing of this manuscript was assisted by ChatGPT (specifically, GPT-4). The authors have read, corrected, and verified all information presented in this work.</p>
<h1>References and Notes</h1>
<ol>
<li>Brown, T. et al. Language Models are Few-Shot Learners. in Advances in Neural Information Processing Systems (eds. Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M. F. \&amp; Lin, H.) vol. 33 1877-1901 (Curran Associates, Inc., 2020).</li>
<li>Thoppilan, R. et al. LaMDA: Language Models for Dialog Applications. (2022).</li>
<li>Touvron, H. et al. LLaMA: Open and Efficient Foundation Language Models. (2023).</li>
<li>Hoffmann, J. et al. Training Compute-Optimal Large Language Models. (2022).</li>
<li>Chowdhery, A. et al. PaLM: Scaling Language Modeling with Pathways. (2022).</li>
<li>Lin, Z. et al. Evolutionary-scale prediction of atomic-level protein structure with a language model. Science (1979) 379, 1123-1130 (2023).</li>
<li>Luo, R. et al. BioGPT: generative pre-trained transformer for biomedical text generation and mining. Brief Bioinform 23, (2022).</li>
<li>Irwin, R., Dimitriadis, S., He, J. \&amp; Bjerrum, E. J. Chemformer: a pre-trained transformer for computational chemistry. Mach Learn Sci Technol 3, 015022 (2022).</li>
<li>Kim, H., Na, J. \&amp; Lee, W. B. Generative Chemical Transformer: Neural Machine Learning of Molecular Geometric Structures from Chemical Language via Attention. J Chem Inf Model 61, 5804-5814 (2021).</li>
<li>OpenAI. GPT-4 Technical Report. (2023).</li>
<li>Ziegler, D. M. et al. Fine-Tuning Language Models from Human Preferences. (2019).</li>
<li>Ouyang, L. et al. Training language models to follow instructions with human feedback. (2022).</li>
<li>Bran, A. M., Cox, S., White, A. D. \&amp; Schwaller, P. ChemCrow: Augmenting largelanguage models with chemistry tools. (2023).</li>
<li>Reaxys. https://www.reaxys.com.</li>
<li>SciFinder. https://scifinder.cas.org.</li>
<li>Opentrons. Opentrons Python Protocol API. https://docs.opentrons.com/v2/.</li>
<li>
<p>Emerald Cloud Lab. Running Experiments. https://www.emeraldcloudlab.com/guides/runningexperiments.</p>
</li>
<li>
<p>Urbina, F., Lentzos, F., Invernizzi, C. \&amp; Ekins, S. Dual use of artificial-intelligencepowered drug discovery. Nat Mach Intell 4, 189-191 (2022).</p>
</li>
</ol>
<h1>Appendices</h1>
<h2>Glossary for Appendices</h2>
<h2>This box demarks notes from the authors.</h2>
<p>The following description follows OpenAI's notation for chat completion mode:</p>
<ul>
<li>Assistant: Output of the model (in most cases it is the "Planner" module).</li>
<li>User: Outputs of other modules provided to the main module (for example, search results or Python code output). Real user (in these experiments, a human scientist) inputs are marked as "Prompt:".</li>
</ul>
<h2>Appendix A: Synthesis of ibuprofen</h2>
<table>
<thead>
<tr>
<th style="text-align: center;">Assistant</th>
<th style="text-align: center;">First, let's look for a synthesis route for ibuprofen. <br> GOOGLE ibuprofen synthesis route</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">User</td>
<td style="text-align: center;">Ibuprofen is synthesized through a process called Friedel-Crafts acylation. The starting materials for the synthesis are isobutylbenzene and acetic anhydride. This process was discovered by Stewart Adams and John Nicholson in 1961 while they were working at Boots UK Limited. The original ibuprofen synthesis by the Boots Group serves as a basis for the manufacturing process today.</td>
</tr>
<tr>
<td style="text-align: center;">Assistant</td>
<td style="text-align: center;">Great, now that we have the synthesis route through Friedel-Crafts acylation using isobutylbenzene and acetic anhydride, let's find the stoichiometry and the experimental conditions for this reaction. <br> GOOGLE Friedel-Crafts acylation isobutylbenzene and acetic anhydride conditions and stoichiometry</td>
</tr>
<tr>
<td style="text-align: center;">User</td>
<td style="text-align: center;">In the Friedel-Crafts acylation of isobutylbenzene and acetic anhydride, the reaction conditions involve reacting isobutylbenzene (1) with acetic anhydride under the influence of a Lewis acid, such as aluminum chloride (AlCl3) as a catalyst. This reaction forms p-isobutylacetophenone (2) through electrophilic aromatic substitution. <br> The stoichiometry of the reaction would involve one equivalent of isobutylbenzene reacting with one equivalent of acetic anhydride in the presence of the AlCl3 catalyst. However, the actual yield and purity may be influenced by factors such as the concentration of unreacted starting materials or reaction time. Consider extending the reaction time or adding more catalyst to enhance the conversion and yield of the desired product.</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align: center;">Assistant</th>
<th style="text-align: center;">Now that we have information about the reactants and stoichiometry, let's calculate how much of each reactant we need to synthesize around 100 mg of ibuprofen. First, we need the molecular weights of isobutylbenzene, acetic anhydride, and ibuprofen. Then, we'll calculate the amount of isobutylbenzene and acetic anhydride needed based on the reaction stoichiometry. <br> PYTHON <br> isobutylbenzene_mw $=134.22 # \mathrm{~g} / \mathrm{mol}$ <br> acetic_anhydride_mw $=102.09 # \mathrm{~g} / \mathrm{mol}$ <br> ibuprofen_mw $=206.28 # \mathrm{~g} / \mathrm{mol}$ <br> desired_mass $=0.1 #$ in $\mathrm{g}(100 \mathrm{mg})$ <br> isobutylbenzene_moles = desired_mass / ibuprofen_mw <br> acetic_anhydride_moles = isobutylbenzene_moles <br> mass_isobutylbenzene = isobutylbenzene_moles * <br> isobutylbenzene_mw <br> mass_acetic_anhydride = acetic_anhydride_moles * <br> acetic_anhydride_mw <br> print(mass_isobutylbenzene, mass_acetic_anhydride)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">User</td>
<td style="text-align: center;">0.06506689936009308 0.049490983129726586</td>
</tr>
<tr>
<td style="text-align: center;">Assistant</td>
<td style="text-align: center;">Based on our calculations, we need 0.0651 g of isobutylbenzene and 0.0495 g of acetic anhydride to synthesize about 100 mg of ibuprofen. <br> Lastly, let's check the cloud lab documentation for the experimental procedure that involves the Friedel-Crafts acylation reaction with isobutylbenzene and acetic anhydride, and the use of aluminum chloride as a catalyst. <br> DOCUMENTATION Friedel-Crafts acylation experimental procedure with aluminum chloride catalyst</td>
</tr>
</tbody>
</table>
<h1>Second Google search expanded</h1>
<table>
<thead>
<tr>
<th style="text-align: left;">User</th>
<th style="text-align: left;">Friedel-Crafts acylation isobutylbenzene and acetic anhydride conditions <br> and stoichiometry</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Assistant</td>
<td style="text-align: left;">GOOGLE Friedel-Crafts acylation isobutylbenzene and acetic anhydride <br> conditions and stoichiometry</td>
</tr>
<tr>
<td style="text-align: left;">User</td>
<td style="text-align: left;">Google search results: <br> Ibuprofen Synthesis - Writing Anthology <br> https://central.edu/writing-anthology/2019/04/11/ibuprofen-synthesis/ <br> Apr 11, 2019 ... Initially, isobutylbenzene (1) and acetic anhydride, were reacted under Friedel- <br> Crafts acylation conditions to create p-isobutylacetophenone ...</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Synthesis of ibuprofen from benzene - The Science Snail <br> https://www.sciencesnail.com/science/synthesis-of-ibuprofen-from-benzene</td>
</tr>
</tbody>
</table>
<p>Oct 11, 2018 ... Friedel-Crafts acylation mechanism isobutylbenzene ... an aldoxime (7) which is then dehydrated to the nitrile (8) using acetic anhydride.
(PDF) Ibuprofen Continuous Manufacturing - Process Modeling and ...
https://www.researchgate.net/publication/359864378_Ibuprofen_Continuous_Manufacturing_ Process_Modeling_and_Techno-Economic_Assessment_TEA_using_SuperPro_Designer Apr 11, 2022 ... The synthesis process involves Friedel-Crafts acylation, ... The raw materials acetic anhydride and isobutyl benzene (IBB) and the recycled ...</p>
<p>Regioselective Friedel-Crafts Acylation Reaction Using Single ...
https://pubs.acs.org/doi/10.1021/acsomega.2c03555
Aug 31, 2022 ... Again, the Friedel-Crafts (FC) acylation of aromatic substrates with ... (50) and substituted anhydrides (51) in stoichiometric amounts and ...</p>
<p>Flow Chemistry: Recent Developments in the Synthesis of ...
https://pubs.acs.org/doi/10.1021/acs.oprd.5b00325
Nov 26, 2015 ... The continuous flow Friedel-Crafts acylation of isobutylbenzene 68 with propionyl chloride 69 was performed with AlCl3 as a Lewis acid using ...</p>
<p>Strongly Lewis Acidic Metal-Organic Frameworks for Continuous ...
https://pubs.acs.org/doi/10.1021/jacs.9b07891
Sep 4, 2019 ... (58) Conventional Lewis acids for Friedel-Crafts acylation include ... Reaction conditions: arene ( 1 equiv, 1.0 mmol ), acetic anhydride ( 1.0 ...</p>
<p>A comprehensive review of flow chemistry techniques tailored to the ...
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8182698/
Optimisation of the reaction conditions in flow were carried out on ... is the acetylation of geraniol (343) through acetic anhydride developed by Adarme ...</p>
<p>Continuous Flow Organic Chemistry: Successes and Pitfalls at the ...
https://chemistry-europe.onlinelibrary.wiley.com/doi/10.1002/ejoc. 201800149
Mar 13, 2018 ... The reactor effluent was next mixed with acetic anhydride an N ... The first step included a Friedel-Crafts acylation of isobutyl benzene ...</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Assistant</th>
<th style="text-align: center;">BROWSE https://central.edu/writing-anthology/2019/04/11/ibuprofensynthesis/</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">User</td>
<td style="text-align: center;">We removed the text from this website from the paper. You can access it by using URL above.</td>
</tr>
<tr>
<td style="text-align: center;">Assistant</td>
<td style="text-align: center;">OUTPUT In the Friedel-Crafts acylation of isobutylbenzene and acetic anhydride, the reaction conditions involve reacting isobutylbenzene (1) with acetic anhydride under the influence of a Lewis acid, such as aluminum chloride (AlCl3) as a catalyst. This reaction forms pisobutylacetophenone (2) through electrophilic aromatic substitution. <br> The stoichiometry of the reaction would involve one equivalent of isobutylbenzene reacting with one equivalent of acetic anhydride in the presence of the AlCl3 catalyst. However, the actual yield and purity may be influenced by factors such as the concentration of unreacted starting materials or reaction time. Consider extending the reaction time or adding more catalyst to enhance the conversion and yield of the desired product.</td>
</tr>
</tbody>
</table>
<h1>Appendix B: Synthesis of aspirin</h1>
<table>
<thead>
<tr>
<th style="text-align: center;">Assistant</th>
<th style="text-align: center;">I will first look up the synthesis reaction for aspirin to understand the reagents and procedure involved. <br> GOOGLE aspirin synthesis reaction</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">User</td>
<td style="text-align: center;">Aspirin, also known as acetylsalicylic acid, is synthesized through a chemical reaction between salicylic acid and acetic anhydride. Sulfuric acid is used as a catalyst to speed up the reaction. The overall reaction can be described as an esterification reaction, in which a carboxylic acid reacts with an acid anhydride to form an ester. The balanced chemical equation for the reaction is: <br> C7H6O3 (salicylic acid) + C4H6O3 (acetic anhydride) -&gt; C9H8O4 (aspirin) + C2H4O2 (acetic acid) <br> During this reaction, the aspirin product will precipitate when water is added as it has low solubility in water, while acetic anhydride and acetic acid will dissolve in water. Vacuum filtration can then be used to separate the crystalline aspirin from the reaction mixture, excluding any unreacted salicylic acid.</td>
</tr>
<tr>
<td style="text-align: center;">Assistant</td>
<td style="text-align: center;">Since we want to synthesize around 100 mg of aspirin, I will calculate the required quantities of salicylic acid and acetic anhydride using the balanced chemical equation and their molar masses. I will assume a $100 \%$ yield for simplicity. <br> PYTHON <br> aspirin_molar_mass $=180.16 # \mathrm{~g} / \mathrm{mol}$ <br> salicylic_acid_molar_mass $=138.12 # \mathrm{~g} / \mathrm{mol}$ <br> acetic_anhydride_molar_mass $=102.09 # \mathrm{~g} / \mathrm{mol}$ <br> target_aspirin_mass $=100 # \mathrm{mg}$ <br> target_aspirin_mol = target_aspirin_mass / <br> (aspirin_molar_mass * 1e3) <br> required_salicylic_acid_mol = target_aspirin_mol <br> required_acetic_anhydride_mol = target_aspirin_mol <br> required_salicylic_acid_mass = required_salicylic_acid_mol <br> * salicylic_acid_molar_mass * 1e3 <br> required_acetic_anhydride_mass = <br> required_acetic_anhydride_mol * acetic_anhydride_molar_mass <br> * 1e3 <br> print(required_salicylic_acid_mass, <br> required_acetic_anhydride_mass)</td>
</tr>
</tbody>
</table>            </div>
        </div>

    </div>
</body>
</html>