<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6745 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6745</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6745</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-129.html">extraction-schema-129</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <p><strong>Paper ID:</strong> paper-f54aa5a594d054e9564413ed4c30d18f2e747bc7</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/f54aa5a594d054e9564413ed4c30d18f2e747bc7" target="_blank">Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> This work proposes Diffusion-of-Thought (DoT), a novel approach that integrates diffusion models with Chain-of-Thought, a well-established technique for improving the reasoning ability of autoregressive language models.</p>
                <p><strong>Paper Abstract:</strong> Recently, diffusion models have garnered significant interest in the field of text processing due to their many potential advantages compared to conventional autoregressive models. In this work, we propose Diffusion-of-Thought (DoT), a novel approach that integrates diffusion models with Chain-of-Thought, a well-established technique for improving the reasoning ability of autoregressive language models. In contrast to autoregressive language models that make decisions in a left-to-right, token-by-token manner, DoT allows reasoning steps to diffuse over time through a diffusion language model and offers greater flexibility in trading-off computation for reasoning performance. Our experimental results demonstrate the effectiveness of DoT in multi-digit multiplication, boolean logic, and grade school math problems, with a small diffusion model outperforming a much larger autoregressive model in both efficiency and accuracy. In addition to that, DoT showcases promising self-correction abilities and benefits from existing reasoning-enhancing techniques like self-consistency decoding. Our findings contribute to the understanding and development of reasoning with diffusion language models.</p>
                <p><strong>Cost:</strong> 0.021</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6745.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6745.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DoT (from-scratch) - 4x4 Mult.</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Diffusion-of-Thought (DoT) trained from scratch</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A diffusion-language-model chain-of-thought method that diffuses latent 'thought' representations across timesteps to produce intermediate reasoning steps in parallel; here trained from scratch on multiplication tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Transformer (DoT, from-scratch)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>≈124M</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Diffusion-of-Thought (DoT)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>diffusion / parallel (non-autoregressive)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>BIG-bench 4x4 multiplication</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>four-digit × four-digit multi-digit multiplication (arithmetic)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Accuracy (exact match %)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>100.0</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>GPT2-small (Chain-of-Thought)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>0.0</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>DoT from-scratch attains 100% accuracy on 4x4 multiplication while achieving much higher throughput (large speed-up reported vs. autoregressive CoT). Authors note DoT's ability to model exact math computation, and that diffusion sampling at very few timesteps (T=1) suffices for simple tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6745.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6745.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DoT (from-scratch) - 5x5 Mult.</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Diffusion-of-Thought (DoT) trained from scratch</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Same DoT setup trained from scratch evaluated on five-digit multiplication.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Transformer (DoT, from-scratch)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>≈124M</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Diffusion-of-Thought (DoT)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>diffusion / parallel (non-autoregressive)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>BIG-bench 5x5 multiplication</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>five-digit × five-digit multi-digit multiplication (arithmetic)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Accuracy (exact match %)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>100.0</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>GPT2-small (Chain-of-Thought)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>0.0</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>DoT achieves 100% accuracy with very high throughput (T=1) on this arithmetic task; authors emphasize DoT's computational efficiency (up to 27× speed-up vs. GPT-2 CoT in throughput).</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6745.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6745.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DoT (from-scratch) - Boolean</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Diffusion-of-Thought (DoT) trained from scratch</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>DoT trained from scratch evaluated on a boolean logic reasoning task.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Transformer (DoT, from-scratch)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>≈124M</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Diffusion-of-Thought (DoT)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>diffusion / parallel (non-autoregressive)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>Boolean logic task (DyVal style)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>symbolic boolean logical reasoning (logical formulas)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Accuracy (exact match %)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>100.0</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>GPT2-small (Chain-of-Thought)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>0.0</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>DoT reaches perfect accuracy on the boolean logic dataset with very few diffusion steps (T=2); authors attribute success to DoT's ability to denoise and recover exact tokens and to efficient parallel denoising.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6745.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6745.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DoT (from-scratch) - GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Diffusion-of-Thought (DoT) trained from scratch</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>DoT trained from scratch evaluated on GSM8K grade-school math problems (complex reasoning), showing limited performance without pretraining.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Transformer (DoT, from-scratch)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>≈124M</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Diffusion-of-Thought (DoT)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>diffusion / parallel (non-autoregressive)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K-Aug (grade-school math)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>grade-school math word problems requiring language understanding and multi-step arithmetic reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Accuracy (exact match %)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>4.6</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>GPT2-small (Chain-of-Thought)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>-34.4</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Training DoT from scratch on GSM8K yields poor performance, highlighting the importance of pre-trained language understanding for complex tasks; authors therefore fine-tune pre-trained diffusion LMs (Plaid, SEDD) for better results.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6745.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e6745.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DoT - Plaid (fine-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Diffusion-of-Thought (DoT) fine-tuned from Plaid (Likelihood-based diffusion LM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>DoT implemented by fine-tuning the pre-trained continuous diffusion LM Plaid (1.3B) using classifier-free conditioning and diffusion-specific training/sampling techniques.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Likelihood-based diffusion language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Plaid (DoT fine-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>1.3B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Diffusion-of-Thought (DoT)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>diffusion / parallel (non-autoregressive)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K-Aug (grade-school math)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>grade-school math word problems</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Accuracy (exact match %)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>32.6</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>GPT2-medium (Chain-of-Thought)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>-11.3</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Plaid-DoT improves over training-from-scratch DoT, but underperforms GPT2-medium CoT on GSM8K; authors show self-consistency and multi-pass variants can improve Plaid-DoT (e.g., self-consistency to 36.3). Pretraining objective differences (Plaid vs SEDD) affect downstream reasoning performance.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6745.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e6745.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DoT - SEDD-small (fine-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Diffusion-of-Thought (DoT) fine-tuned from SEDD-small (discrete diffusion LM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>DoT applied to a discrete diffusion language model SEDD-small, evaluated on GSM8K and arithmetic tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Discrete diffusion language modeling by estimating the ratios of the data distribution</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>SEDD-small (DoT fine-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>170M</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Diffusion-of-Thought (DoT)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>diffusion / parallel (non-autoregressive)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K-Aug (grade-school math)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>grade-school math word problems</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Accuracy (exact match %)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>45.3</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>GPT2-small (Chain-of-Thought)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>6.3</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>SEDD-small DoT outperforms similarly-sized GPT2-small with CoT on GSM8K; self-consistency further raises performance (to 51.8). Authors attribute improvements to pretraining objective and DoT's diverse path generation enabling majority-vote aggregation.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6745.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e6745.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DoT - SEDD-medium (fine-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Diffusion-of-Thought (DoT) fine-tuned from SEDD-medium (discrete diffusion LM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>DoT fine-tuned from the SEDD-medium pre-trained discrete diffusion LM achieves strong GSM8K performance, exceeding same-scale autoregressive CoT baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Discrete diffusion language modeling by estimating the ratios of the data distribution</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>SEDD-medium (DoT fine-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>424M</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Diffusion-of-Thought (DoT)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>diffusion / parallel (non-autoregressive)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K-Aug (grade-school math)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>grade-school math word problems</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Accuracy (exact match %)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>53.5</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>GPT2-medium (Chain-of-Thought)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>9.6</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>SEDD-medium DoT outperforms a similarly sized GPT2-medium with CoT by ~10 percentage points on GSM8K; authors highlight that diffusion pretraining and DoT's distributed-thought generation plus self-consistency (boost to 59.4) contribute to this advantage.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6745.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e6745.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DoT^MP (multi-pass) - Plaid</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DoT multi-pass (DoT^MP) fine-tuned from Plaid</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-pass variant of DoT that generates rationales one thought at a time to introduce causal inductive bias; used to compensate for causal bias absent in fully parallel DoT.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Plaid (DoT^MP fine-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>1.3B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>DoT^MP (multi-pass Diffusion-of-Thought)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>sequential / multi-pass diffusion (introduces causal bias)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>mixed</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K-Aug (grade-school math)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>grade-school math word problems</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Accuracy (exact match %)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>37.7</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>Plaid (single-pass DoT)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>5.1</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>DoT^MP (multi-pass) shows modest gains over single-pass DoT for Plaid on GSM8K, indicating that adding causal/left-to-right bias can help in some pretraining setups; but it is less efficient (lower throughput).</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6745.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e6745.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Implicit CoT - GPT2-medium</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Implicit Chain-of-Thought (knowledge distillation into hidden states) applied to GPT2-medium</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Implicit CoT distills chain-of-thought reasoning into model hidden states to accelerate CoT-style computation without explicit textual rationales.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Implicit chain of thought reasoning via knowledge distillation</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT2-medium (Implicit CoT)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>355M</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Implicit Chain-of-Thought</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>hidden-state distillation / sequential (accelerated CoT)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>homogeneous</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>BIG-bench multiplication / GSM8K (reported across tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>multi-digit multiplication and grade-school math</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Accuracy (exact match %)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>96.4</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>GPT2-medium (Chain-of-Thought)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>-3.6</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Implicit CoT achieves competitive accuracy on some arithmetic tasks while reporting much higher throughput than autoregressive CoT; however, on harder tasks (e.g., GSM8K) it underperforms DoT and standard CoT in this paper's reported settings. The paper positions Implicit CoT as similar-in-style (homogeneous) but more time-efficient than standard CoT.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6745.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e6745.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Chain-of-Thought (CoT) - GPT2-medium</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chain-of-Thought prompting with autoregressive GPT2-medium</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Standard left-to-right textual chain-of-thought prompting that elicits intermediate rationales token-by-token in autoregressive LMs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Chain of thought prompting elicits reasoning in large language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT2-medium (CoT fine-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>355M</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Chain-of-Thought (CoT)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>sequential / autoregressive</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>single style / homogeneous</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K-Aug (grade-school math)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>grade-school math word problems</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Accuracy (exact match %)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>43.9</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>SEDD-medium (DoT)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>-9.6</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Autoregressive CoT with GPT2-medium achieves solid GSM8K performance but is outperformed by SEDD-medium DoT when DoT is allowed many diffusion steps; CoT is described as less efficient per-token and less naturally diverse than diffusion-based DoT.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6745.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e6745.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Self-Consistency (applied to DoT)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Self-Consistency decoding (majority-vote aggregation) applied to diffusion-of-thought</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An ensemble decoding technique that samples multiple reasoning paths and picks the most frequent final answer; applied here to DoT to exploit diffusion diversity.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Self-consistency improves chain of thought reasoning in language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>SEDD-medium (DoT) with self-consistency</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>424M</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Self-Consistency (aggregation of multiple samples)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>ensemble / majority-vote</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse (leverages diversity)</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K-Aug (grade-school math)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>grade-school math word problems</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Accuracy (exact match %)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>59.4</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>SEDD-medium (DoT) without self-consistency</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>5.9</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Self-consistency consistently improves DoT models (authors report gains across Plaid, SEDD-small, SEDD-medium), attributed to DoT's natural ability to generate diverse reasoning paths via different random noises. Paper shows absolute improvement curves vs. number of samples.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6745.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e6745.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Ablation: Plaid DoT sampling strategies</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Ablation study of scheduled sampling and coupled sampling for Plaid DoT</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Ablation experiments showing the effects of scheduled sampling and coupled sampling (training-time sampling algorithms) on Plaid DoT performance on GSM8K.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Plaid (DoT fine-tuned) - ablation</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>1.3B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Diffusion-of-Thought (DoT) with/without scheduled & coupled sampling</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>diffusion / training-time sampling variants</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>mixed</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K-Aug (grade-school math)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>grade-school math word problems</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Accuracy (exact match %)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>32.6</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>Plaid DoT without scheduled sampling; DoT^MP without coupled sampling</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Ablations: continuing pre-training then gradient-guided decoding gave 0.5% only; Plaid DoT fine-tune 32.6%; removing scheduled sampling reduces to 31.2% (-1.4); DoT^MP-finetune 37.7%; removing coupled sampling yields 35.5% (-2.2). Authors conclude scheduled/coupled sampling improve self-correction and align training to inference.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Implicit chain of thought reasoning via knowledge distillation <em>(Rating: 2)</em></li>
                <li>Self-consistency improves chain of thought reasoning in language models <em>(Rating: 2)</em></li>
                <li>Likelihood-based diffusion language models <em>(Rating: 2)</em></li>
                <li>Discrete diffusion language modeling by estimating the ratios of the data distribution <em>(Rating: 2)</em></li>
                <li>DiffuSeq: Sequence to sequence text generation with diffusion models <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6745",
    "paper_id": "paper-f54aa5a594d054e9564413ed4c30d18f2e747bc7",
    "extraction_schema_id": "extraction-schema-129",
    "extracted_data": [
        {
            "name_short": "DoT (from-scratch) - 4x4 Mult.",
            "name_full": "Diffusion-of-Thought (DoT) trained from scratch",
            "brief_description": "A diffusion-language-model chain-of-thought method that diffuses latent 'thought' representations across timesteps to produce intermediate reasoning steps in parallel; here trained from scratch on multiplication tasks.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Transformer (DoT, from-scratch)",
            "model_size": "≈124M",
            "reasoning_method_name": "Diffusion-of-Thought (DoT)",
            "reasoning_method_type": "diffusion / parallel (non-autoregressive)",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "BIG-bench 4x4 multiplication",
            "task_description": "four-digit × four-digit multi-digit multiplication (arithmetic)",
            "performance_metric": "Accuracy (exact match %)",
            "performance_value": 100.0,
            "comparison_target_method": "GPT2-small (Chain-of-Thought)",
            "performance_difference": 0.0,
            "statistical_significance": null,
            "analysis_notes": "DoT from-scratch attains 100% accuracy on 4x4 multiplication while achieving much higher throughput (large speed-up reported vs. autoregressive CoT). Authors note DoT's ability to model exact math computation, and that diffusion sampling at very few timesteps (T=1) suffices for simple tasks.",
            "ablation_study_present": false,
            "uuid": "e6745.0",
            "source_info": {
                "paper_title": "Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "DoT (from-scratch) - 5x5 Mult.",
            "name_full": "Diffusion-of-Thought (DoT) trained from scratch",
            "brief_description": "Same DoT setup trained from scratch evaluated on five-digit multiplication.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Transformer (DoT, from-scratch)",
            "model_size": "≈124M",
            "reasoning_method_name": "Diffusion-of-Thought (DoT)",
            "reasoning_method_type": "diffusion / parallel (non-autoregressive)",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "BIG-bench 5x5 multiplication",
            "task_description": "five-digit × five-digit multi-digit multiplication (arithmetic)",
            "performance_metric": "Accuracy (exact match %)",
            "performance_value": 100.0,
            "comparison_target_method": "GPT2-small (Chain-of-Thought)",
            "performance_difference": 0.0,
            "statistical_significance": null,
            "analysis_notes": "DoT achieves 100% accuracy with very high throughput (T=1) on this arithmetic task; authors emphasize DoT's computational efficiency (up to 27× speed-up vs. GPT-2 CoT in throughput).",
            "ablation_study_present": false,
            "uuid": "e6745.1",
            "source_info": {
                "paper_title": "Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "DoT (from-scratch) - Boolean",
            "name_full": "Diffusion-of-Thought (DoT) trained from scratch",
            "brief_description": "DoT trained from scratch evaluated on a boolean logic reasoning task.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Transformer (DoT, from-scratch)",
            "model_size": "≈124M",
            "reasoning_method_name": "Diffusion-of-Thought (DoT)",
            "reasoning_method_type": "diffusion / parallel (non-autoregressive)",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "Boolean logic task (DyVal style)",
            "task_description": "symbolic boolean logical reasoning (logical formulas)",
            "performance_metric": "Accuracy (exact match %)",
            "performance_value": 100.0,
            "comparison_target_method": "GPT2-small (Chain-of-Thought)",
            "performance_difference": 0.0,
            "statistical_significance": null,
            "analysis_notes": "DoT reaches perfect accuracy on the boolean logic dataset with very few diffusion steps (T=2); authors attribute success to DoT's ability to denoise and recover exact tokens and to efficient parallel denoising.",
            "ablation_study_present": false,
            "uuid": "e6745.2",
            "source_info": {
                "paper_title": "Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "DoT (from-scratch) - GSM8K",
            "name_full": "Diffusion-of-Thought (DoT) trained from scratch",
            "brief_description": "DoT trained from scratch evaluated on GSM8K grade-school math problems (complex reasoning), showing limited performance without pretraining.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Transformer (DoT, from-scratch)",
            "model_size": "≈124M",
            "reasoning_method_name": "Diffusion-of-Thought (DoT)",
            "reasoning_method_type": "diffusion / parallel (non-autoregressive)",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "GSM8K-Aug (grade-school math)",
            "task_description": "grade-school math word problems requiring language understanding and multi-step arithmetic reasoning",
            "performance_metric": "Accuracy (exact match %)",
            "performance_value": 4.6,
            "comparison_target_method": "GPT2-small (Chain-of-Thought)",
            "performance_difference": -34.4,
            "statistical_significance": null,
            "analysis_notes": "Training DoT from scratch on GSM8K yields poor performance, highlighting the importance of pre-trained language understanding for complex tasks; authors therefore fine-tune pre-trained diffusion LMs (Plaid, SEDD) for better results.",
            "ablation_study_present": false,
            "uuid": "e6745.3",
            "source_info": {
                "paper_title": "Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "DoT - Plaid (fine-tuned)",
            "name_full": "Diffusion-of-Thought (DoT) fine-tuned from Plaid (Likelihood-based diffusion LM)",
            "brief_description": "DoT implemented by fine-tuning the pre-trained continuous diffusion LM Plaid (1.3B) using classifier-free conditioning and diffusion-specific training/sampling techniques.",
            "citation_title": "Likelihood-based diffusion language models",
            "mention_or_use": "use",
            "model_name": "Plaid (DoT fine-tuned)",
            "model_size": "1.3B",
            "reasoning_method_name": "Diffusion-of-Thought (DoT)",
            "reasoning_method_type": "diffusion / parallel (non-autoregressive)",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "GSM8K-Aug (grade-school math)",
            "task_description": "grade-school math word problems",
            "performance_metric": "Accuracy (exact match %)",
            "performance_value": 32.6,
            "comparison_target_method": "GPT2-medium (Chain-of-Thought)",
            "performance_difference": -11.3,
            "statistical_significance": false,
            "analysis_notes": "Plaid-DoT improves over training-from-scratch DoT, but underperforms GPT2-medium CoT on GSM8K; authors show self-consistency and multi-pass variants can improve Plaid-DoT (e.g., self-consistency to 36.3). Pretraining objective differences (Plaid vs SEDD) affect downstream reasoning performance.",
            "ablation_study_present": true,
            "uuid": "e6745.4",
            "source_info": {
                "paper_title": "Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "DoT - SEDD-small (fine-tuned)",
            "name_full": "Diffusion-of-Thought (DoT) fine-tuned from SEDD-small (discrete diffusion LM)",
            "brief_description": "DoT applied to a discrete diffusion language model SEDD-small, evaluated on GSM8K and arithmetic tasks.",
            "citation_title": "Discrete diffusion language modeling by estimating the ratios of the data distribution",
            "mention_or_use": "use",
            "model_name": "SEDD-small (DoT fine-tuned)",
            "model_size": "170M",
            "reasoning_method_name": "Diffusion-of-Thought (DoT)",
            "reasoning_method_type": "diffusion / parallel (non-autoregressive)",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "GSM8K-Aug (grade-school math)",
            "task_description": "grade-school math word problems",
            "performance_metric": "Accuracy (exact match %)",
            "performance_value": 45.3,
            "comparison_target_method": "GPT2-small (Chain-of-Thought)",
            "performance_difference": 6.3,
            "statistical_significance": false,
            "analysis_notes": "SEDD-small DoT outperforms similarly-sized GPT2-small with CoT on GSM8K; self-consistency further raises performance (to 51.8). Authors attribute improvements to pretraining objective and DoT's diverse path generation enabling majority-vote aggregation.",
            "ablation_study_present": false,
            "uuid": "e6745.5",
            "source_info": {
                "paper_title": "Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "DoT - SEDD-medium (fine-tuned)",
            "name_full": "Diffusion-of-Thought (DoT) fine-tuned from SEDD-medium (discrete diffusion LM)",
            "brief_description": "DoT fine-tuned from the SEDD-medium pre-trained discrete diffusion LM achieves strong GSM8K performance, exceeding same-scale autoregressive CoT baselines.",
            "citation_title": "Discrete diffusion language modeling by estimating the ratios of the data distribution",
            "mention_or_use": "use",
            "model_name": "SEDD-medium (DoT fine-tuned)",
            "model_size": "424M",
            "reasoning_method_name": "Diffusion-of-Thought (DoT)",
            "reasoning_method_type": "diffusion / parallel (non-autoregressive)",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "GSM8K-Aug (grade-school math)",
            "task_description": "grade-school math word problems",
            "performance_metric": "Accuracy (exact match %)",
            "performance_value": 53.5,
            "comparison_target_method": "GPT2-medium (Chain-of-Thought)",
            "performance_difference": 9.6,
            "statistical_significance": false,
            "analysis_notes": "SEDD-medium DoT outperforms a similarly sized GPT2-medium with CoT by ~10 percentage points on GSM8K; authors highlight that diffusion pretraining and DoT's distributed-thought generation plus self-consistency (boost to 59.4) contribute to this advantage.",
            "ablation_study_present": false,
            "uuid": "e6745.6",
            "source_info": {
                "paper_title": "Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "DoT^MP (multi-pass) - Plaid",
            "name_full": "DoT multi-pass (DoT^MP) fine-tuned from Plaid",
            "brief_description": "A multi-pass variant of DoT that generates rationales one thought at a time to introduce causal inductive bias; used to compensate for causal bias absent in fully parallel DoT.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Plaid (DoT^MP fine-tuned)",
            "model_size": "1.3B",
            "reasoning_method_name": "DoT^MP (multi-pass Diffusion-of-Thought)",
            "reasoning_method_type": "sequential / multi-pass diffusion (introduces causal bias)",
            "reasoning_style_diversity": "mixed",
            "benchmark_name": "GSM8K-Aug (grade-school math)",
            "task_description": "grade-school math word problems",
            "performance_metric": "Accuracy (exact match %)",
            "performance_value": 37.7,
            "comparison_target_method": "Plaid (single-pass DoT)",
            "performance_difference": 5.1,
            "statistical_significance": false,
            "analysis_notes": "DoT^MP (multi-pass) shows modest gains over single-pass DoT for Plaid on GSM8K, indicating that adding causal/left-to-right bias can help in some pretraining setups; but it is less efficient (lower throughput).",
            "ablation_study_present": true,
            "uuid": "e6745.7",
            "source_info": {
                "paper_title": "Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "Implicit CoT - GPT2-medium",
            "name_full": "Implicit Chain-of-Thought (knowledge distillation into hidden states) applied to GPT2-medium",
            "brief_description": "Implicit CoT distills chain-of-thought reasoning into model hidden states to accelerate CoT-style computation without explicit textual rationales.",
            "citation_title": "Implicit chain of thought reasoning via knowledge distillation",
            "mention_or_use": "mention",
            "model_name": "GPT2-medium (Implicit CoT)",
            "model_size": "355M",
            "reasoning_method_name": "Implicit Chain-of-Thought",
            "reasoning_method_type": "hidden-state distillation / sequential (accelerated CoT)",
            "reasoning_style_diversity": "homogeneous",
            "benchmark_name": "BIG-bench multiplication / GSM8K (reported across tasks)",
            "task_description": "multi-digit multiplication and grade-school math",
            "performance_metric": "Accuracy (exact match %)",
            "performance_value": 96.4,
            "comparison_target_method": "GPT2-medium (Chain-of-Thought)",
            "performance_difference": -3.6,
            "statistical_significance": null,
            "analysis_notes": "Implicit CoT achieves competitive accuracy on some arithmetic tasks while reporting much higher throughput than autoregressive CoT; however, on harder tasks (e.g., GSM8K) it underperforms DoT and standard CoT in this paper's reported settings. The paper positions Implicit CoT as similar-in-style (homogeneous) but more time-efficient than standard CoT.",
            "ablation_study_present": false,
            "uuid": "e6745.8",
            "source_info": {
                "paper_title": "Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "Chain-of-Thought (CoT) - GPT2-medium",
            "name_full": "Chain-of-Thought prompting with autoregressive GPT2-medium",
            "brief_description": "Standard left-to-right textual chain-of-thought prompting that elicits intermediate rationales token-by-token in autoregressive LMs.",
            "citation_title": "Chain of thought prompting elicits reasoning in large language models",
            "mention_or_use": "use",
            "model_name": "GPT2-medium (CoT fine-tuned)",
            "model_size": "355M",
            "reasoning_method_name": "Chain-of-Thought (CoT)",
            "reasoning_method_type": "sequential / autoregressive",
            "reasoning_style_diversity": "single style / homogeneous",
            "benchmark_name": "GSM8K-Aug (grade-school math)",
            "task_description": "grade-school math word problems",
            "performance_metric": "Accuracy (exact match %)",
            "performance_value": 43.9,
            "comparison_target_method": "SEDD-medium (DoT)",
            "performance_difference": -9.6,
            "statistical_significance": false,
            "analysis_notes": "Autoregressive CoT with GPT2-medium achieves solid GSM8K performance but is outperformed by SEDD-medium DoT when DoT is allowed many diffusion steps; CoT is described as less efficient per-token and less naturally diverse than diffusion-based DoT.",
            "ablation_study_present": false,
            "uuid": "e6745.9",
            "source_info": {
                "paper_title": "Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "Self-Consistency (applied to DoT)",
            "name_full": "Self-Consistency decoding (majority-vote aggregation) applied to diffusion-of-thought",
            "brief_description": "An ensemble decoding technique that samples multiple reasoning paths and picks the most frequent final answer; applied here to DoT to exploit diffusion diversity.",
            "citation_title": "Self-consistency improves chain of thought reasoning in language models",
            "mention_or_use": "use",
            "model_name": "SEDD-medium (DoT) with self-consistency",
            "model_size": "424M",
            "reasoning_method_name": "Self-Consistency (aggregation of multiple samples)",
            "reasoning_method_type": "ensemble / majority-vote",
            "reasoning_style_diversity": "diverse (leverages diversity)",
            "benchmark_name": "GSM8K-Aug (grade-school math)",
            "task_description": "grade-school math word problems",
            "performance_metric": "Accuracy (exact match %)",
            "performance_value": 59.4,
            "comparison_target_method": "SEDD-medium (DoT) without self-consistency",
            "performance_difference": 5.9,
            "statistical_significance": false,
            "analysis_notes": "Self-consistency consistently improves DoT models (authors report gains across Plaid, SEDD-small, SEDD-medium), attributed to DoT's natural ability to generate diverse reasoning paths via different random noises. Paper shows absolute improvement curves vs. number of samples.",
            "ablation_study_present": true,
            "uuid": "e6745.10",
            "source_info": {
                "paper_title": "Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "Ablation: Plaid DoT sampling strategies",
            "name_full": "Ablation study of scheduled sampling and coupled sampling for Plaid DoT",
            "brief_description": "Ablation experiments showing the effects of scheduled sampling and coupled sampling (training-time sampling algorithms) on Plaid DoT performance on GSM8K.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Plaid (DoT fine-tuned) - ablation",
            "model_size": "1.3B",
            "reasoning_method_name": "Diffusion-of-Thought (DoT) with/without scheduled & coupled sampling",
            "reasoning_method_type": "diffusion / training-time sampling variants",
            "reasoning_style_diversity": "mixed",
            "benchmark_name": "GSM8K-Aug (grade-school math)",
            "task_description": "grade-school math word problems",
            "performance_metric": "Accuracy (exact match %)",
            "performance_value": 32.6,
            "comparison_target_method": "Plaid DoT without scheduled sampling; DoT^MP without coupled sampling",
            "performance_difference": null,
            "statistical_significance": false,
            "analysis_notes": "Ablations: continuing pre-training then gradient-guided decoding gave 0.5% only; Plaid DoT fine-tune 32.6%; removing scheduled sampling reduces to 31.2% (-1.4); DoT^MP-finetune 37.7%; removing coupled sampling yields 35.5% (-2.2). Authors conclude scheduled/coupled sampling improve self-correction and align training to inference.",
            "ablation_study_present": true,
            "uuid": "e6745.11",
            "source_info": {
                "paper_title": "Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Implicit chain of thought reasoning via knowledge distillation",
            "rating": 2
        },
        {
            "paper_title": "Self-consistency improves chain of thought reasoning in language models",
            "rating": 2
        },
        {
            "paper_title": "Likelihood-based diffusion language models",
            "rating": 2
        },
        {
            "paper_title": "Discrete diffusion language modeling by estimating the ratios of the data distribution",
            "rating": 2
        },
        {
            "paper_title": "DiffuSeq: Sequence to sequence text generation with diffusion models",
            "rating": 2
        }
    ],
    "cost": 0.0212095,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Diffusion of Thought: Chain-of-Thought Reasoning in Diffusion Language Models</h1>
<p>Jiacheng $\mathrm{Ye}^{1}$, Shansan Gong ${ }^{1}$, Liheng Chen ${ }^{1}$, Lin Zheng ${ }^{1}$, Jiahui Gao ${ }^{2}$,Han Shi ${ }^{2}$, Chuan $\mathrm{Wu}^{1}$, Xin Jiang ${ }^{2}$, Zhenguo $\mathrm{Li}^{2}$, Wei $\mathrm{Bi}^{3}$,Lingpeng Kong ${ }^{1}$<br>${ }^{1}$ The University of Hong Kong ${ }^{2}$ Huawei Noah's Ark Lab ${ }^{3}$ Tencent AI Lab<br>{carsonye, sansa933}@connect.hku.hk</p>
<h4>Abstract</h4>
<p>Recently, diffusion models have garnered significant interest in the field of text processing due to their many potential advantages compared to conventional autoregressive models. In this work, we propose Diffusion-of-Thought (DoT), a novel approach that integrates diffusion models with Chain-of-Thought, a well-established technique for improving the reasoning ability of autoregressive language models. In contrast to autoregressive language models that make decisions in a left-to-right, token-by-token manner, DoT allows reasoning steps to diffuse over time through a diffusion language model and offers greater flexibility in trading-off computation for reasoning performance. Our experimental results demonstrate the effectiveness of DoT in multi-digit multiplication, boolean logic, and grade school math problems, with a small diffusion model outperforming a much larger autoregressive model in both efficiency and accuracy. In addition to that, DoT showcases promising self-correction abilities and benefits from existing reasoningenhancing techniques like self-consistency decoding. Our findings contribute to the understanding and development of reasoning with diffusion language models.</p>
<h2>1 Introduction</h2>
<p>Large language models (LLMs) have had a profound impact on the entire field of artificial intelligence [42, 50], transforming our approach to addressing classical problems in natural language processing and machine learning. Among the most notable aspects of LLMs is their remarkable reasoning ability, which many researchers consider to be a representative emergent capability brought about by LLMs [53]. Chain-of-thought prompting (CoT) [54]), which generates a series of intermediate reasoning steps in autoregressive (AR) way, has emerged as a central technique to support complex reasoning processes in LLMs. Despite advancements, errors in intermediate CoT steps can lead to inaccurate answers [32], posing self-correction difficulties [25], and concerns about CoT's inefficiency have been highlighted in recent studies [7].
Recently, diffusion models have attracted interest in text processing [33, 65, 69] as a result of success in the vision domain and distinctive modeling strengths over autoregressive models [34], offering potential benefits including global planning ability [59, 63], self correction [23] and efficiency [37]. As part of the research community effort, pre-trained diffusion language models such as Plaid [18] and SEDD [37] have shown significant progress in text generation capabilities. Although they have not yet attained the scale and capabilities of existing proprietary autoregressive LLMs like GPT-4 [42], these models have demonstrated performance on par with GPT2 [4] and the scaling law [27] in diffusion language models have been highlighted in Plaid. As a result, it becomes pertinent to explore the following question: can diffusion language models also leverage the CoT-style technique to gain enhanced complex reasoning abilities?</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>This work presents a preliminary study on this question. We propose Diffusion of Thought (DoT), an inherent chain-of-thought method tailored for diffusion models. In essence, DoT progressively updates a sequence of latent variables representing thoughts in the hidden space, allowing reasoning steps to diffuse over time in parallel. We also introduce a multi-pass variant of DoT which focuses on generating one thought at a time to compensate for causal bias. To condition on complex queries, instead of using gradient-based classifier guidance [18, 33], DoT trains and samples from the denoising model using the classifier-free guidance as in Gong et al. [15], to provide more reliable controlling signals on exact tokens.</p>
<p>Furthermore, to improve the self-correcting capability of the diffusion model, DoT integrates training-time sampling algorithms to learn to recover from errors originating from prior or current reasoning steps. This feature offers a fresh angle on the issue of error accumulation [25, 32] inherent in autoregressive models. Finally, we adapt a conditional ODE Solver [39] for DoT during inference time to accelerate the inference of continuous diffusion models. We show DoT enjoys flexibility in trading off computation (reasoning time) and performance as more complex problems may necessitate increased computation in reasoning [2, 54].</p>
<p>From a methodological standpoint, DoT shares similarities with the recently proposed Implicit CoT approach [7], where the latter learns thoughts in hidden states across transformer layers to improve the time efficiency of autoregressive CoT generation. A schematic illustration of CoT, Implicit CoT, and DoT can be found in Figure 1.</p>
<p>The main contributions of our paper are threefold:</p>
<ol>
<li>We first introduce the reasoning technique for diffusion models (DoT), and showcase its advantages in simple reasoning tasks (digit multiplication and boolean logic) when compared to autoregressive CoT and Implicit CoT. DoT achieves up to $27 \times$ speed-up without performance drop (§4.2).</li>
<li>We further adapt DoT to continuous and discrete diffusion base models, and introduce two training-time sampling algorithms to improve its self-correction ability. DoT exhibits superior performance compared to GPT2 with CoT on grade school math problems, enabling a small diffusion model to outperform a 4.6x larger autoregressive model, showing the potential of text diffusion models for complex reasoning (§4.3).</li>
<li>Our analysis demonstrates the flexibility of DoT in the trade-off between reasoning time and performance (§4.4), and showcases DoT's self-correction capability (§4.6). We also find that self-consistency decoding can further improve DoT and its multi-pass variant (§4.5).</li>
</ol>
<p>Although it is challenging for current pre-trained diffusion language models to directly compete with LLMs that are hundreds of times larger in parameter size, our study emphasizes the possibility of their complex reasoning abilities and highlights the substantial potential in developing LLMs that go beyond the autoregressive paradigm. We release all the codes at https://github.com/HKUNLP/diffusion-of-thoughts.</p>
<h1>2 Preliminaries</h1>
<p>This section introduces key concepts and notations in diffusion models for text generation. Detailed formulations and derivations are provided in Appendix A.</p>
<p>A typical diffusion model contains the forward and reverse process. For each forward step $q\left(\mathbf{z}<em t-1="t-1">{t} \mid \mathbf{z}</em>}\right)$, we gradually inject noise into the data representation $\mathbf{z<em t="t">{t-1}$ from the last timestep to obtain $\mathbf{z}</em>}$. Here $t=1,2, \ldots, T$ and the larger $t$ corresponds to noisier data. For reverse process, the ultimate goal is to recover the original $\mathbf{z<em t="t">{0}$ by denoising $\mathbf{z}</em>}: p_{\theta}\left(\mathbf{z<em T="T">{0: T}\right):=p\left(\mathbf{z}</em>}\right) \prod_{t=1}^{T} p_{\theta}\left(\mathbf{z<em t="t">{t-1} \mid \mathbf{z}</em>}\right)$. We model the learning process $p_{\theta}\left(\mathbf{z<em t="t">{t-1} \mid \mathbf{z}</em>}\right)$ using the proposed diffusion model $\mathbf{z<em t="t">{\theta}\left(\mathbf{z}</em>, t\right)$.
Previous text generation using diffusion models almost contains two categories: (1) Continuous diffusion models such as Diffusion-LM [33], which relies on a mapping function between the real values and feasible integral point; (2) Discrete diffusion models like D3PM [1], which directly formulate the problem as the integer program. Continuous diffusion models map the discrete text $\mathbf{w}$ into a continuous space through an embedding function $\operatorname{EmB}(\mathbf{w})$, and its inverse operation is called rounding. The forward perturbations are applied according to $q\left(\mathbf{z}<em t-1="t-1">{t} \mid \mathbf{z}</em>}\right)=$ $\mathcal{N}\left(\mathbf{z<em t="t">{t} ; \sqrt{1-\beta</em>}} \mathbf{z<em t="t">{t-1}, \beta</em>} \mathbf{I}\right)$, where $\beta_{t} \in(0,1)$ represents different scales of the Gaussian noise. Plaid [18] is a continuous diffusion language model trained from scratch on 314B tokens with 1024 context size. It is currently the largest scale diffusion language model with 1.3B parameters. In the case of discrete diffusion models, each $\mathbf{z<em t="t">{t}$ is represented as a discrete random variable using one-hot vectors in ${0,1}^{K}$, where $K$ denotes the vocabulary size. They define $q\left(\mathbf{z}</em>} \mid \mathbf{z<em t="t">{t-1}\right)$ through a transition matrix, making it a point mass with probability on an absorbing state [MASK] or a uniform distribution over the vocabulary size. SEDD [37] is a recently trained-from-scratch discrete diffusion language model with small and medium size similar to GPT2.
For sequence-to-sequence (seq2seq) generation, which involves a pair of sequences $\mathbf{w}^{x}$ and $\mathbf{w}^{y}$, DiffuSeq [15] treats these two sequences as a single one $\mathbf{w}^{z}=\mathbf{w}^{[x ; y]}$ and uses a left-aligned mask $[\mathbf{0} ; \mathbf{1}]$ during the forward and reverse diffusion process to distinguish them. Unlike traditional diffusion models that corrupt the entire $\mathbf{z}</em>$ ). This modification, termed partial noising, tailors diffusion models for conditional language generation, and set a difference between the gradient-based token guidance in [33] and [18].}$, DiffuSeq only adds noise to those entries with the mask value of 1 (e.g., $\mathbf{y}_{t</p>
<h1>3 Diffusion-of-Thoughts</h1>
<p>In this section, we begin with an overview of our method and its relationship with other reasoning paradigms (§3.1). We then introduce Diffusion-of-Thoughts (DoT) as well as its multi-pass variant (DoT ${ }^{\mathrm{MP}}$; §3.2), as illustrated in Figure 2. Following this, we outline the implementation of our training (§3.3) and inference (§3.4) protocols.</p>
<h3>3.1 Overview</h3>
<p>Without loss of generality, we use the mathematical problem-solving task as our running example. A problem statement and its correct answer are denoted as $\mathbf{s}$ and $\mathbf{a}$, respectively. We employ a language model with parameters $\theta$, represented as $p_{\theta}^{L M}$, to find the solution for each problem. For regular usage of language models without Chain-of-Thoughts (CoT), the final answer a is generated directly as $\mathbf{a} \sim p_{\theta}^{L M}(\mathbf{a} \mid \mathbf{s})$. The CoT approach introduces meaningful intermediate steps or rationales $\mathbf{r}<em n="n">{1}, \ldots, \mathbf{r}</em>}$ for language models to bridge $\mathbf{s}$ and $\mathbf{a}$, resulting in the output $\mathbf{a} \sim p_{\theta}^{L M}\left(\mathbf{a} \mid \mathbf{s}, \mathbf{r<em 1="1">{1 \ldots n}\right)$. For implicit CoT [7], the hidden representations of rationales $\mathbf{z}</em>}, \ldots, \mathbf{z<em _theta="\theta">{n}$ are distilled into transformer layers, leading to $\mathbf{a} \sim p</em>}^{d o T}\left(\mathbf{a} \mid \mathbf{s}, \mathbf{z<em _theta="\theta">{1 \ldots n}\right)$. Similarly but differently, for DoT, these representations are distributed over diffusion timestep $t$ as $\mathbf{a} \sim p</em>}^{D o T}\left(\mathbf{a} \mid \mathbf{s}, \mathbf{z<em t="t">{t}\right)$, where $\mathbf{z}</em>$ corresponds exactly to the noised data in diffusion models.</p>
<h3>3.2 Modeling</h3>
<p>We begin by observing the gradient-based token guidance fails to do accurate conditioning as the model cannot exactly recover each conditioning token (see Table 2). This is vital, especially in mathematical reasoning, as it is expected to perform reasoning based on exact tokens (e.g., numbers) in the problem statement, rather than more compact gradient signals. For this, we adopt DiffuSeqstyle [15] classifier-free conditioning during the fine-tuning of Plaid, where all rationales are generated by the backward diffusion process in parallel, with all the conditional tokens fixed as still. Specifically, the problem context $s$ is concatenated with the rationales $\mathbf{r}<em 1="1" _ldots="\ldots" n="n">{1 \ldots n}$ during training and sampling, while the noise is only partially imposed to the rationale part in $\mathbf{r}</em>$ anchored as the condition.}$, keeping $\mathbf{s</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 2: Demonstration of DoT pipeline. DoT diffuses all possible thoughts across diffusion timestep t. Multi-pass DoT disentangles each rationale and introduces causal bias. The stacked circles stand for the marginalization over other potential reasoning paths, which is implicitly carried out during the training of diffusion models.</p>
<p>We further propose a multi-pass (MP) variant of DoT, denoted as DoTMP, which generates rationales in a thought-by-thought paradigm. This method disentangles the generation of multiple rationales and introduces casual inductive bias such that later rationale can be guided by stronger condition signals of prior rationales during the generation. Specifically, in the first pass, we generate the first rationale by $\mathbf{r}<em _theta="\theta">{1} \sim p</em>}^{D o T}\left(\mathbf{r<em t="t">{1} \mid \mathbf{s}, \mathbf{z}</em>}^{\tau_{1}}\right)$, where $\mathbf{z<em 1="1">{t}^{\tau</em>}}$ is the noised vector representation of $\mathbf{r<em 1="1">{1}$ in diffusion model. Then $\mathbf{r}</em>}$ is connected to $\mathbf{s}$ as the condition $\left[\mathbf{s} ; \mathbf{r<em 2="2">{1}\right]$ to get $\mathbf{r}</em>} \sim p_{\theta}^{D o T}\left(\mathbf{r<em 1="1">{2} \mid\left[\mathbf{s} ; \mathbf{r}</em>}\right], \mathbf{z<em 2="2">{t}^{\tau</em>}}\right)$, and then we have $\left[\mathbf{s} ; \mathbf{r<em 2="2">{1} ; \mathbf{r}</em>}\right]$. Through multiple iterations, we can get the final answer: $\mathbf{a} \sim p_{\theta}^{D o T}\left(\mathbf{a} \mid\left[\mathbf{s} ; \mathbf{r<em n="n">{1} ; \ldots ; \mathbf{r}</em>}\right], \mathbf{z<em n="n">{t}^{\tau</em>\right)$.}</p>
<h1>3.3 Training</h1>
<p>Scheduled sampling Diffusion models have intrinsic self-correcting capability through the multistep denoising process. To further improve their self-correcting ability, we design a scheduled sampling [3] mechanism tailored for diffusion models such that self-generated error thoughts in previous timesteps are exposed and corrected during the training stage. Formally, for any timesteps $s, t, u$ that satisfy $1&lt;s&lt;t&lt;u&lt;T, \mathbf{z}<em t="t">{t}$ is sampled from the forward distribution $q\left(\mathbf{z}</em>} \mid \mathbf{z<em t="t">{0}\right)$ in the training stage while during inference it is sampled from $q\left(\mathbf{z}</em>} \mid \mathbf{z<em u="u">{\theta}\left(\mathbf{z}</em>} ; u\right)\right)$ instead, where $\mathbf{z<em q="q">{\theta}$ is a denoiser neural network that reparameterizes $\mathbb{E}</em>}\left[\mathbf{z<em t="t">{0} \mid \mathbf{z}</em>}\right]$. The presence of such exposure bias may impede the model's ability to recover from erroneous thoughts during the generation process as the model $\mathbf{z<em t="t">{\theta}$ has only been trained on corruptions $\mathbf{z}</em>}$ diffused from oracle data. To mitigate this problem, we mimic the inference stage with probability $\epsilon_{i}$ during training depending on the current training step $i$, and $\epsilon_{i}$ linearly decays from 1 to $\epsilon_{\text {min }}$. Specifically, for time-step $t$, we randomly sample a former time-step $u \in{t+1, \ldots, T}$, obtain $\mathbf{z<em 0="0">{u}$ by forward noising and perform a model forward pass to get a predicted $\hat{\mathbf{z}}</em>}=\mathbf{z<em u="u">{\theta}\left(\mathbf{z}</em>} ; u\right)$ ). $\mathbf{z<em t="t">{t}$ is then sampled from $q\left(\mathbf{z}</em>\right)$ to replace the regular one in loss calculation. Compared with scheduled sampling for autoregressive models, such a mechanism in DoT helps the model to recover from errors by considering global information instead of relying on the left-side tokens.} \mid \hat{\mathbf{z}}_{0</p>
<p>Coupled sampling In DoT ${ }^{\mathrm{MP}}$, correct previous thoughts are given in the training stage, which is not given during inference. Similar to auto-regressive decoding, $\mathrm{DoT}^{\mathrm{MP}}$ may suffer from error accumulation during the thought-by-thought generation process. To enhance the self-correction ability of $\mathrm{DoT}^{\mathrm{MP}}$, we propose a coupled sampling mechanism by adding noise not only to the current thought but also to previous thoughts during training with some probability. For instance, the previous sequence $\mathbf{z}<em 1="1">{0}=\operatorname{EMB}\left(\left[\mathbf{s} ; \mathbf{r}</em>}\right]\right)$ will be modified to $\mathbf{z<em 1="1">{0}=\operatorname{EMB}\left(\left[\mathbf{s} ; \mathbf{r}</em>} ; \mathbf{r<em 1="1">{2}\right]\right)$, with the partial noise being applied to $\left[\mathbf{r}</em>} ; \mathbf{r<em 2="2">{2}\right]$ rather than just the last rationale $\mathbf{r}</em>}$. Therefore, the model learns to be robust to errors in $\mathbf{r<em 2="2">{1}$ when predicting $\mathbf{r}</em>}$, which better aligns with the inference stage. The new $\mathbf{z<em t="t">{0}$ will be reparameterized into $\mathbf{z}</em>$ as before and other procedures keep the same.</p>
<p>Training objective Given a set of training data for problem-solving tasks of size $D$ : $\left{\mathbf{s}^{j}, \mathbf{r}<em D="D" _in="\in" j="j">{1 \ldots n}^{j}, \mathbf{a}^{j}\right}</em>$, we have two training settings for DoT models: one is training from scratch, while the other is fine-tuning from the pre-trained diffusion model. In both training settings, we share the same training objective. For example, the objective is to minimize the negative</p>
<p>variational lower bound $\mathcal{L}_{\text {VLB }}\left(\mathbf{w}^{z}\right)$ in continuous diffusion models:</p>
<p>$$
\mathcal{L}<em q_left_mathbf_z="q\left(\mathbf{z">{\mathrm{VLB}}\left(\mathbf{w}^{z}\right)=\mathbb{E}</em><em T="T">{0} \mid \mathbf{w}^{z}\right)}\left[\underbrace{\log \frac{q\left(\mathbf{z}</em>} \mid \mathbf{w}^{z}\right)}{p_{\theta}\left(\mathbf{z<em _Prior="{Prior" _text="\text" loss="loss">{T}\right)}}</em>}}+\underbrace{\mathcal{L<em 0="0">{\mathrm{VLB}}\left(\mathbf{z}</em>}\right)<em _theta="\theta">{\text {Diffusion loss }} \underbrace{-\log p</em>}\left(\mathbf{w}^{z} \mid \mathbf{z<em _Rounding="{Rounding" _text="\text" loss="loss">{0}\right)}</em>\right]
$$}</p>
<p>where the rounding loss regularizes the embedding learning and the diffusion loss sums up the KL divergence of each time step $t$ with different weighting terms. Please refer to Appendix A for a detailed training objective formulation of continuous and discrete diffusion models.</p>
<h1>3.4 Inference</h1>
<p>One of the significant advantages of diffusion models is their inference flexibility. Naturally, more complex problems may necessitate increased computation in reasoning time [2, 54], which can be controlled by setting a larger backward timestep $T$ in DoT. However, continuous diffusion such as Plaid usually requires more timesteps, e.g., 4096 [18], to converge. To accelerate the sampling process of the continuous diffusion, we adapt the ODE Solver [38, 39] into a conditional form to fit the conditional training process (detailed in Appendix A.4). Moreover, sharing a similar idea of MBR [30], self-consistency [52] boosts the performance of CoT significantly by generating and aggregating multiple samples. In the context of diffusion models, we can also expect its potential improvement using self-consistency, thanks to their ability to naturally produce diverse responses [15]. After sampling $m$ times to obtain multiple reasoning pathways $\left(\mathbf{r}<em i="i">{i ; 1 \ldots n}, \mathbf{a}</em>}\right)$ from DoT, self-consistency involves marginalizing over $\mathbf{r<em i="i">{i ; 1 \ldots n}$ by taking a majority vote over $\mathbf{a}</em>$, i.e., $\arg \max <em i="1">{\mathbf{a}} \sum</em>=a\right)$. We consider this as the most "consistent" answer among the candidate set of $m$ answers.}^{m} \mathbb{1}\left(\mathbf{a}_{i</p>
<h2>4 Experiments</h2>
<p>We conduct experiments on both simple multi-digit multiplication and boolean logic reasoning as well as complex grade school math problems, to explore the reasoning paradigm in diffusion models.</p>
<h3>4.1 Experimental Setup</h3>
<p>Datasets and Metrics. Following Deng et al. [7], we employ the four-digit $(4 \times 4)$ and five-digit $(5 \times 5)$ multiplication problems from the BIG-bench benchmark [49], known to be challenging for LLMs to solve without CoT. Given that arithmetic reasoning is just one type of the reasoning ability, we also incorporate a boolean logical reasoning task [68]. For more complex tasks, grade school math problems require both language understanding and mathematical reasoning, so we adopt the widely-used GSM8K dataset [6]. We use the augmented training data from Deng et al. [7] and keep all original test sets unchanged. The statistics are listed in Appendix B.1. For both datasets, we use accuracy to measure the exact match accuracy of predicting the final answer, and throughput to measure the number of samples processed per second (it/sec) during inference with a batch size of 1.</p>
<p>Base Models. When training from scratch, we follow DiffuSeq ${ }^{2}$ to use a 12-layer Transformer [51] encoder with similar size as GPT2-small (124M). We also use Plaid ${ }^{3}$ (1.3B) [18], SEDD-small ${ }^{4}$ (170M) and SEED-medium (424M) [37] as pre-trained diffusion language models for further finetuning. Both Plaid and SEDD are pre-trained on OpenWebText [10, 13], which is similar to that in GPT2, and the pre-training perplexity of Plaid and SEDD-small is on par with GPT2-small.</p>
<p>Baselines. We consider Answer-only and CoT as reasoning paradigms for comparison. Another important baseline is Implicit CoT [7], which distills thoughts into transformer layers to accelerate CoT reasoning. We use GPT-2 [4] at various scales (i.e., small 124M, medium 355M, and large 774 M ) as model baselines, known as conventional autoregressive language models. We mainly consider fine-tuning the model due to the relatively small model size, but we also consider prompting the strong commercial LLM ChatGPT gpt-3.5-turbo-1106 using CoT few-shot demonstrations for completeness. We use 5 -shot in the few-shot setting.</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Table 1: The main results on different problem-solving reasoning tasks. Acc ( $\uparrow$ ) is to measure the exact match accuracy of the predicted final answer. Throughput ( $\uparrow$ ) measures the number of samples processed per second during test with batch size equals to 1 . The baseline results for Mult. and GSM8K datasets are taken from the implicit CoT paper [7] and have been validated for reproducibility by us. Bracketed numbers indicate the self-consistency results.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Models</th>
<th style="text-align: center;">$4 \times 4$ Mult.</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">$5 \times 5$ Mult.</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Boolean logic</th>
<th style="text-align: center;"></th>
<th style="text-align: center;">GSM8K-Aug</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Acc</td>
<td style="text-align: center;">Throughput</td>
<td style="text-align: center;">Acc</td>
<td style="text-align: center;">Throughput</td>
<td style="text-align: center;">Acc</td>
<td style="text-align: center;">Throughput</td>
<td style="text-align: center;">Acc</td>
<td style="text-align: center;">Throughput</td>
</tr>
<tr>
<td style="text-align: center;">Answer-only</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">GPT2-small</td>
<td style="text-align: center;">28.7</td>
<td style="text-align: center;">13.2</td>
<td style="text-align: center;">1.2</td>
<td style="text-align: center;">11.1</td>
<td style="text-align: center;">98.8</td>
<td style="text-align: center;">16.2</td>
<td style="text-align: center;">13.3</td>
<td style="text-align: center;">24.7</td>
</tr>
<tr>
<td style="text-align: center;">GPT2-medium</td>
<td style="text-align: center;">76.2</td>
<td style="text-align: center;">7.0</td>
<td style="text-align: center;">1.9</td>
<td style="text-align: center;">5.9</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">9.6</td>
<td style="text-align: center;">17.0</td>
<td style="text-align: center;">9.1</td>
</tr>
<tr>
<td style="text-align: center;">GPT2-large</td>
<td style="text-align: center;">33.6</td>
<td style="text-align: center;">4.8</td>
<td style="text-align: center;">0.9</td>
<td style="text-align: center;">4.0</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">7.4</td>
<td style="text-align: center;">12.7</td>
<td style="text-align: center;">9.1</td>
</tr>
<tr>
<td style="text-align: center;">ChatGPT (few-shot)</td>
<td style="text-align: center;">2.2</td>
<td style="text-align: center;">1.0</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">1.4</td>
<td style="text-align: center;">67.6</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">28.1</td>
<td style="text-align: center;">1.8</td>
</tr>
<tr>
<td style="text-align: center;">Chain-of-Thoughts (CoT)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">GPT2-small</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">2.3</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">1.5</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">0.8</td>
<td style="text-align: center;">39.0 (41.6)</td>
<td style="text-align: center;">2.0</td>
</tr>
<tr>
<td style="text-align: center;">GPT2-medium</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">1.2</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">0.8</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">43.9</td>
<td style="text-align: center;">1.1</td>
</tr>
<tr>
<td style="text-align: center;">GPT2-large</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">0.8</td>
<td style="text-align: center;">99.3</td>
<td style="text-align: center;">0.6</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">0.3</td>
<td style="text-align: center;">44.8</td>
<td style="text-align: center;">0.7</td>
</tr>
<tr>
<td style="text-align: center;">ChatGPT (few-shot)</td>
<td style="text-align: center;">42.8</td>
<td style="text-align: center;">0.1</td>
<td style="text-align: center;">4.5</td>
<td style="text-align: center;">0.1</td>
<td style="text-align: center;">75.8</td>
<td style="text-align: center;">0.2</td>
<td style="text-align: center;">61.5</td>
<td style="text-align: center;">0.2</td>
</tr>
<tr>
<td style="text-align: center;">Implicit CoT</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">GPT2-small</td>
<td style="text-align: center;">96.6</td>
<td style="text-align: center;">8.9</td>
<td style="text-align: center;">9.5</td>
<td style="text-align: center;">7.9</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">20.0</td>
<td style="text-align: center;">16.4</td>
</tr>
<tr>
<td style="text-align: center;">GPT2-medium</td>
<td style="text-align: center;">96.1</td>
<td style="text-align: center;">4.8</td>
<td style="text-align: center;">96.4</td>
<td style="text-align: center;">4.3</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">21.9</td>
<td style="text-align: center;">8.7</td>
</tr>
<tr>
<td style="text-align: center;">Diffusion-of-Thoughts (DoT)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">From-scratch</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">62.5</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">61.8</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">55.2</td>
<td style="text-align: center;">4.6</td>
<td style="text-align: center;">22.7</td>
</tr>
<tr>
<td style="text-align: center;">Plaid</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">24.3</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">21.3</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">10.2</td>
<td style="text-align: center;">32.6 (36.3)</td>
<td style="text-align: center;">0.3</td>
</tr>
<tr>
<td style="text-align: center;">SEDD-small</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">59.2</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">55.5</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">33.3</td>
<td style="text-align: center;">45.3 (51.8)</td>
<td style="text-align: center;">1.0</td>
</tr>
<tr>
<td style="text-align: center;">SEDD-medium</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">31.8</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">28.5</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">17.2</td>
<td style="text-align: center;">53.5 (59.4)</td>
<td style="text-align: center;">0.5</td>
</tr>
<tr>
<td style="text-align: center;">Diffusion-of-Thoughts (DoT ${ }^{\text {MP }}$ )</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">From-scratch</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">11.8</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">9.5</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">3.7</td>
<td style="text-align: center;">5.5</td>
<td style="text-align: center;">8.6</td>
</tr>
<tr>
<td style="text-align: center;">Plaid</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">4.3</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">3.9</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">1.0</td>
<td style="text-align: center;">37.7</td>
<td style="text-align: center;">0.1</td>
</tr>
<tr>
<td style="text-align: center;">SEDD-small</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">9.9</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">9.2</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">3.3</td>
<td style="text-align: center;">43.2</td>
<td style="text-align: center;">0.2</td>
</tr>
<tr>
<td style="text-align: center;">SEDD-medium</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">4.5</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">4.0</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">1.7</td>
<td style="text-align: center;">53.3</td>
<td style="text-align: center;">0.1</td>
</tr>
</tbody>
</table>
<p>Implementation Details. During tokenization, we treat all the digits as individual tokens. For DoT ${ }^{\text {MP }}$, we append a special token <EOS> to the last thought, so when the model generates a thought followed by <EOS>, it stops generating further, which enables the model to decide the number of rationales dynamically. We conduct all the experiments on 8 NVIDIA V100-32G GPUs. During training, we set $\epsilon_{\text {train }}$ to be 0.95 as we find decreasing the probability of oracle demonstration hinders model training. We choose coupled sampling $\gamma=0.01, k=1$ and self-consistency $m=20$. Following Plaid, we also adopt self-conditioning [5] during training. During inference, we set both the temperature of the score and output logit to 0.5 to sharpen the predicted output distribution while maintaining the ability to generate diverse samples. The sampling timesteps $T$ is dynamic. By default, we set it to be 64 . Considering that simple tasks do not necessitate an excessively large number of steps, we opt to reduce $T$ while ensuring there is no notable performance drop. Other details are in Appendix B.3.</p>
<h1>4.2 Results on Digit Multiplication and Boolean Logic</h1>
<p>We first train DoT for digit multiplication tasks and a boolean logical reasoning task as the preliminary investigation, as shown in the left part of Table 1. We observe that neither ChatGPT nor the distilled Implicit CoT model can reach $100 \%$ accuracy. GPT-2 can be fine-tuned to achieve high accuracy but sacrifices throughput during CoT. Interestingly, DoT can attain $100 \%$ accuracy for these tasks while maintaining significant throughput with diffusion sampling steps set at 1 for multiplication datasets and 2 for the boolean logical dataset, achieving maximum $27 \times$ speed-up compared to GPT-2. This preliminary finding indicates that DoT performs well in modeling exact math computation or boolean logic reasoning and benefits from its computational efficiency.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Models</th>
<th style="text-align: right;">Acc. (\%) $\uparrow$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Continue pre-training</td>
<td style="text-align: right;">0.5</td>
</tr>
<tr>
<td style="text-align: left;">DoT-finetune</td>
<td style="text-align: right;">32.6</td>
</tr>
<tr>
<td style="text-align: left;">$(-)$ scheduled sampling</td>
<td style="text-align: right;">31.2</td>
</tr>
<tr>
<td style="text-align: left;">$\mathrm{DoT}^{\mathrm{MP}}$-finetune</td>
<td style="text-align: right;">37.7</td>
</tr>
<tr>
<td style="text-align: left;">$(-)$ coupled sampling</td>
<td style="text-align: right;">35.5</td>
</tr>
</tbody>
</table>
<p>Table 2: Ablation of Plaid DoT on GSM8K.
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 3: The effectiveness of ODE solver in speedup inference of Plaid DoT.</p>
<h1>4.3 Results on Grade School Math</h1>
<p>We now move on to a much more complex grade school math task GSM8K as shown in the right part of Table 1. We first consider training DoT from scratch as in the previous tasks, but we are only able to achieve an accuracy of around $5 \%$, which is much lower than the fine-tuned version of GPT-2. This indicates the pre-trained natural language understanding capability is vital for grade school math. Once DoT is extended based on the pre-trained diffusion language models Plaid and SEDD, the performance is significantly improved after fine-tuning, where the DoT based on SEDD-medium outperforms similar-sized GPT2-medium with CoT by around 10\%. Additionally, multi-pass DoT, with casual bias, performs slightly better than single-pass one on Plaid, while the latter is more efficient. The performance gap between SEDD and Plaid also highlights the importance of the training objective in pretraining diffusion LMs. Finally, we find that self-consistency further yields substantial improvements in DoT models owing to the diverse generations of diffusion model (§4.5).
We further explore several alternatives and conduct an ablation study as in Table 2 when fine-tuning Plaid. As discussed above, continuing pre-training Plaid using the GSM8K-augmented dataset and performing reasoning with gradient-based conditioning is not a good choice for fine-tuning diffusion LMs on downstream tasks, because reasoning tasks require more specific guidance. An example of groundtruth and recovered text is shown below, where bold words in the query part are incorrectly recovered:</p>
<p>Groundtruth: Two trains leave San Rafael at the same time. They begin traveling westward, both traveling for 80 miles. The next day, they travel northwards, covering 150 miles. What's the distance covered by each train in the two days? «2 $280=160 »$ «150»2=300» «300+160=460» «460/2=230» #### 230</p>
<p>Recovered Text: Three trains leave San Juan at the same time. They start traveling westward, both traveling for 80 miles. The next day, they travel southward, covering 150 miles. What's the distance covered by each train in the two days? «3»80=180» «180+80+150=340» «340/30=12.5» #### 12.5</p>
<p>We can see there are three recovered query tokens that exhibit minor differences due to soft gradient guidance, causing interference with the model's comprehension of the problem. The ablation of two sampling strategies proposed in $\S 3.3$ showcases their effectiveness. This provides evidence that better denoising models are trained using our training-time sampling strategies, allowing DoT models to self-correct more effectively during inference. Further analysis about self-correction is listed in $\S 4.6$. In Figure 3, we further show the conditional ODE solver substantially speeds up the inference of continuous diffusion model Plaid, ensuring a decent performance with only 8 generation timesteps.</p>
<h3>4.4 Reasonability-efficiency Trade-off</h3>
<p>The community has devoted substantial efforts to improve the reasoning capabilities of left-to-right language models, such as refining instructions [31, 67], finding better demonstrations [9, 55, 58], and designing elaborate decoding algorithm [43, 56, 57]. Non-autoregressive diffusion models naturally provide another simple way to enhance reasoning by allocating more timesteps during inference, albeit at the expense of efficiency. We show such efficiency trade-off in Figure 4(a), where we</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 4: (a) Accuracy over reasoning steps using various methods. We measure the reasoning steps as the average number of calling the model forward function for instances from the test set. DoT provides a flexible way to balance accuracy and efficiency through the reasoning steps. (b) Absolute accuracy improvement versus samples in self-consistency per instance on the GSM8K dataset with Plaid DoT.
measure the reasoning steps as the average number of calling the model forward function for all the instances from the test set. For CoT and Implicit CoT baselines, we treat reasoning steps as the average number of output tokens for all the test instances ${ }^{5}$.
Given a small budget of reasoning steps (e.g., 1 or 2 ) on simpler tasks such as $5 \times 5$, both DoT-Plaid and DoT-SEDD already have an accuracy of $100 \%$, and no more reasoning steps are needed. For such cases of simple tasks, only a little computation cost is required for our method. For complex tasks such as GSM8K, we find DoT performance can continuously improve by allowing more reasoning steps, which indicates DoT can be efficient if we can sacrifice performance in certain scenarios. Specifically, DoT-SEDD-medium outperforms autoregressive CoT-GPT2-medium when we allocate 32 generation timesteps, and the performance continues improving when we increase the timesteps. In comparison, CoT and Implicit CoT with the autoregressive model are hard to be more efficient given their nature of token-by-token prediction. Overall, with DoT, we can flexibly control the trade-off between efficiency and performance for tasks with different difficulty levels.</p>
<h1>4.5 Self-consistency in DoT</h1>
<p>Figure 4(b) shows the effectiveness of the self-consistency mechanism for Plaid DoT and its variant. We can see self-consistency improves both DoT and $\mathrm{DoT}^{\mathrm{MP}}$, which is in line with the effectiveness of self-consistency for auto-regressive models [52]. From Table 1, SEDD DoT is also significantly improved by self-consistency. This benefits from the diversity generation in DoT. We observe that DoT can generate diverse reasoning paths, such as $&lt;3 * 3=9&gt;&lt;9 * 60=540&gt;$ and $&lt;3 * 60=180&gt;&lt;180 * 3=540&gt;$ for the same question, providing cross-validation when selecting the most "consistent" answer. Note that different from autoregressive models, where diversity usually relies on decoding algorithms [8, 22], the natural advantage of the diffusion models is to generate different sentences with different random noises at each timestep.</p>
<h3>4.6 Self-correction in DoT</h3>
<p>In this section, we provide several cases in Table 3 to show the self-correction ability of Plaid DoT, which acts as a distinct difference between diffusion models and autoregressive models. In the first case, we can see the model figures out all the correct thoughts together with only a single reasoning step (i.e., a single calling of the model forward function), and obtains the correct final answer in the second step. This mirrors how humans think in both fast and slow modes [26]. In the second case where the problem is slightly harder, the model cannot give concrete thoughts in the first step but can still produce the correct answer through the later "slow" thinking process. We can see the solution framework, roughly outlining how the task will be carried out, is established at the very</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Table 3: Cases that show the predictions of Plaid DoT at each time-step $t$ with $T=8$ on the GSM8K test set. The incorrect thoughts are marked in bold red and we omit some correct predictions when $t&lt;4$. The difficulty level of the questions increases from left to right.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Q.</th>
<th style="text-align: left;">A robe takes 2 bolts of blue <br> apper and half that much white <br> fertil. How many bolts in total <br> does it take?</th>
<th style="text-align: left;">Tommy is fundraising for his charity by selling brownies for <br> $\$ 3$ a slice and cheesecakes for $\$ 4$ a slice. If Tommy sells 43 <br> brownies and 23 slices of cheesecake, how much money <br> does Tommy raise?</th>
<th style="text-align: left;">When Freda cooks canned tomatoes into sauce, they <br> lose half their volume. Each 16 ounce can of <br> tomatoes that she uses contains three tomatoes. <br> Freda's last batch of tomato sauce made 32 ounces of <br> sauce. How many tomatoes did Freda use?</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>beginning, and then the subsequent work is for refining and improving, which is also similar to how human performs a complex task. Interestingly, in DoT, the correct thoughts may not appear in a left-to-right paradigm as in the traditional chain-of-thought process. The third case serves as compelling evidence to illustrate this distinctive nature of diffusion-of-thought and how it diverges from the chain-of-thought approach. In step 4 the model has a wrong intermediate thought $&lt;2 * 3=4&gt;$ with the latter thoughts and final answer computed correctly first. In the next step, the error in the wrong intermediate thought is fixed, which suggests both prior and latter thoughts can help in the prediction of the current thought. Furthermore, from these three cases, we observed that the model tends to maintain its prediction after it considers the answer to be complete. This suggests we can further enhance the inference efficiency by incorporating mechanisms such as early exit [16], and easier tasks can get earlier exits as observed in Table 3.</p>
<h1>5 Related Work</h1>
<h3>5.1 Diffusion Models for Text</h3>
<p>Building upon advancements in diffusion models for image generation [21, 45], text continuous diffusion [15, 33] employs an embedding function to transform discrete text into the continuous space. Besides, discrete diffusion models [1, 23] directly introduce discrete noise to accommodate the discrete nature of texts, demonstrating significant potential [37, 65]. Numerous studies have shown that diffusion models can efficiently generate diverse texts [11, 14], and achieve competitive performance in various sequence-to-sequence NLP tasks, including machine translation [60, 61], summarization [62], code generation [44], and style transfer [24]. In this work, we explore diffusion model for mathematical reasoning tasks.</p>
<h3>5.2 Pre-train and fine-tune Diffusion LMs</h3>
<p>The pre-training and fine-tuning paradigm, while a familiar concept in NLP before the era of prompting methods [36], remains relatively under-explored for diffusion language models. Prior efforts include initializing diffusion models with pre-trained masked language models such as BERT [20] and RoBERTa [66] and XLM-RoBERTa [59]. GENIE [35] adopts paragraph denoising to train encoder-decoder models, proving beneficial for summarization tasks. Plaid [18] and SEDD [37] are pioneers in pre-train diffusion language models from scratch, attaining comparative or better perplexity scores over GPT-2 [4]. To the best of our knowledge, we are the first to explore the fine-tuning of a pre-trained diffusion language model for reasoning tasks.</p>
<h3>5.3 Reasoning Paradigms</h3>
<p>Large language models usually excel in performing system-1 [47] tasks that are processed quickly and intuitively by humans but struggle in system-2 tasks, which require deliberate thinking [4, 48, 54]. The chain-of-thought reasoning paradigm $[31,41,54]$ has been widely employed to elicit reasoning</p>
<p>abilities and can be further improved with various techniques. For instance, self-consistency [52] samples a diverse set of reasoning paths and selects the most consistent answer, while tree-ofthought [57] achieves different reasoning paths by tree search. Despite these advancements, errors introduced in intermediate CoT steps can lead to inaccurate answers [32], posing difficulties in self-correction [25]. Moreover, there are concerns about the inefficiency of CoT [7]. From the architecture perspective, we explore diffusion model as an alternative paradigm for reasoning.</p>
<h1>6 Conclusion and Limitation</h1>
<p>In this work, we propose diffusion-of-thought (DoT), integrating CoT reasoning with continuous diffusion models. We thoroughly evaluate DoT on representative mathematical reasoning tasks in various aspects, including their flexible control of reasoning efficiency, self-correction capability, and the ability to generate diverse reasoning paths. Considering pre-trained diffusion models are still in their early stages, particularly in terms of model scales compared to the more extensively studied autoregressive language models, our study presents an initial exploration into the reasoning ability of current diffusion language models. A notable limitation of DoT is its requirement for additional training to achieve accurate reasoning. With more powerful pre-trained diffusion models, we anticipate DoT can attain comparative or better generalization capabilities of auto-regressive language models while removing the need for specialized training. Moreover, extending the standard Transformer to other variants [17] is also a viable direction to further improve inference efficiency. Besides, the diffusion training techniques employed in this work are general and applicable to other tasks beyond mathematical reasoning. Extending our training recipes of diffusion language models to further scaled setups such as multi-task instruction tuning and other modalities [19, 64], is an interesting avenue for future research.</p>
<h2>References</h2>
<p>[1] Jacob Austin, Daniel D. Johnson, Jonathan Ho, Daniel Tarlow, and Rianne van den Berg. Structured denoising diffusion models in discrete state-spaces. In Marc'Aurelio Ranzato, Alina Beygelzimer, Yann N. Dauphin, Percy Liang, and Jennifer Wortman Vaughan, editors, Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December $6-14,2021$, virtual, pages 17981-17993, 2021.
[2] Andrea Banino, Jan Balaguer, and Charles Blundell. Pondernet: Learning to ponder. In 8th ICML Workshop on Automated Machine Learning (AutoML), 2021.
[3] Samy Bengio, Oriol Vinyals, Navdeep Jaitly, and Noam Shazeer. Scheduled sampling for sequence prediction with recurrent neural networks. In Corinna Cortes, Neil D. Lawrence, Daniel D. Lee, Masashi Sugiyama, and Roman Garnett, editors, Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems 2015, December 7-12, 2015, Montreal, Quebec, Canada, pages 1171-1179, 2015.
[4] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners. In Hugo Larochelle, Marc'Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin, editors, Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, 2020 .
[5] Ting Chen, Ruixiang Zhang, and Geoffrey Hinton. Analog bits: Generating discrete data using diffusion models with self-conditioning. ArXiv preprint, abs/2208.04202, 2022.
[6] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. Training verifiers to solve math word problems. ArXiv preprint, abs/2110.14168, 2021.
[7] Yuntian Deng, Kiran Prasad, Roland Fernandez, Paul Smolensky, Vishrav Chaudhary, and Stuart Shieber. Implicit chain of thought reasoning via knowledge distillation. ArXiv preprint, abs/2311.01460, 2023.</p>
<p>[8] Angela Fan, Mike Lewis, and Yann Dauphin. Hierarchical neural story generation. In Proc. of ACL, pages 889-898. Association for Computational Linguistics, 2018.
[9] Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and Tushar Khot. Complexity-based prompting for multi-step reasoning. In The Eleventh International Conference on Learning Representations, 2022.
[10] Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn Presser, and Connor Leahy. The Pile: An 800gb dataset of diverse text for language modeling. arXiv preprint arXiv:2101.00027, 2020.
[11] Zhujin Gao, Junliang Guo, Xu Tan, Yongxin Zhu, Fang Zhang, Jiang Bian, and Linli Xu. Difformer: Empowering diffusion model on embedding space for text generation. ArXiv preprint, abs/2212.09412, 2022.
[12] Daniel T. Gillespie. Approximate accelerated stochastic simulation of chemically reacting systems. Journal of Chemical Physics, 115:1716-1733, 2001. URL https://api.semanticscholar.org/CorpusID: 5109777 .
[13] Aaron Gokaslan and Vanya Cohen. Openwebtext corpus. http://Skylion007.github.io/ OpenWebTextCorpus, 2019.
[14] Shansan Gong, Mukai Li, Jiangtao Feng, Zhiyong Wu, and Lingpeng Kong. DiffuSeq-v2: Bridging discrete and continuous text spaces for accelerated Seq2Seq diffusion models. In Houda Bouamor, Juan Pino, and Kalika Bali, editors, Findings of the Association for Computational Linguistics: EMNLP 2023, pages 9868-9875. Association for Computational Linguistics, 2023.
[15] Shansan Gong, Mukai Li, Jiangtao Feng, Zhiyong Wu, and Lingpeng Kong. DiffuSeq: Sequence to sequence text generation with diffusion models. In International Conference on Learning Representations, $I C L R, 2023$.
[16] Alex Graves. Adaptive computation time for recurrent neural networks. ArXiv preprint, abs/1603.08983, 2016.
[17] Albert Gu and Tri Dao. Mamba: Linear-time sequence modeling with selective state spaces. arXiv preprint arXiv:2312.00752, 2023.
[18] Ishaan Gulrajani and Tatsunori B Hashimoto. Likelihood-based diffusion language models. ArXiv preprint, abs/2305.18619, 2023.
[19] William Harvey and Frank Wood. Visual chain-of-thought diffusion models. arXiv preprint arXiv:2303.16187, 2023.
[20] Zhengfu He, Tianxiang Sun, Kuanning Wang, Xuanjing Huang, and Xipeng Qiu. Diffusionbert: Improving generative masked language models with diffusion models. ArXiv preprint, abs/2211.15029, 2022.
[21] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. In Hugo Larochelle, Marc'Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin, editors, Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, 2020.
[22] Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. The curious case of neural text degeneration. In Proc. of ICLR. OpenReview.net, 2020.
[23] Emiel Hoogeboom, Didrik Nielsen, Priyank Jaini, Patrick Forré, and Max Welling. Argmax flows and multinomial diffusion: Learning categorical distributions. In Marc'Aurelio Ranzato, Alina Beygelzimer, Yann N. Dauphin, Percy Liang, and Jennifer Wortman Vaughan, editors, Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual, pages 12454-12465, 2021.
[24] Zachary Horvitz, Ajay Patel, Chris Callison-Burch, Zhou Yu, and Kathleen McKeown. Paraguide: Guided diffusion paraphrasers for plug-and-play textual style transfer. ArXiv preprint, abs/2308.15459, 2023.
[25] Jie Huang, Xinyun Chen, Swaroop Mishra, Huaixiu Steven Zheng, Adams Wei Yu, Xinying Song, and Denny Zhou. Large language models cannot self-correct reasoning yet. ArXiv preprint, abs/2310.01798, 2023.
[26] Daniel Kahneman. Thinking, fast and slow. 2011.</p>
<p>[27] Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. Scaling laws for neural language models. ArXiv preprint, abs/2001.08361, 2020.
[28] Diederik Kingma, Tim Salimans, Ben Poole, and Jonathan Ho. Variational diffusion models. Advances in neural information processing systems, 34:21696-21707, 2021.
[29] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In Yoshua Bengio and Yann LeCun, editors, Proc. of ICLR, 2015.
[30] Philipp Koehn. Statistical significance tests for machine translation evaluation. In Proc. of EMNLP, pages 388-395. Association for Computational Linguistics, 2004.
[31] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large language models are zero-shot reasoners. ArXiv preprint, abs/2205.11916, 2022.
[32] Tamera Lanham, Anna Chen, Ansh Radhakrishnan, Benoit Steiner, Carson Denison, Danny Hernandez, Dustin Li, Esin Durmus, Evan Hubinger, Jackson Kernion, et al. Measuring faithfulness in chain-of-thought reasoning. ArXiv preprint, abs/2307.13702, 2023.
[33] Xiang Lisa Li, John Thickstun, Ishaan Gulrajani, Percy Liang, and Tatsunori B Hashimoto. Diffusion-lm improves controllable text generation. In Conference on Neural Information Processing Systems, NeurIPS, 2022.
[34] Chu-Cheng Lin, Aaron Jaech, Xin Li, Matthew R. Gormley, and Jason Eisner. Limitations of autoregressive models and their alternatives. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 5147-5173. Association for Computational Linguistics, 2021.
[35] Zhenghao Lin, Yeyun Gong, Yelong Shen, Tong Wu, Zhihao Fan, Chen Lin, Nan Duan, and Weizhu Chen. Text generation with diffusion language models: A pre-training approach with continuous paragraph denoise. In International Conference on Machine Learning, pages 21051-21064. PMLR, 2023.
[36] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing. ACM Computing Surveys, 55(9):1-35, 2023.
[37] Aaron Lou, Chenlin Meng, and Stefano Ermon. Discrete diffusion language modeling by estimating the ratios of the data distribution. ArXiv preprint, abs/2310.16834, 2023.
[38] Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu. Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps. In Conference on Neural Information Processing Systems, NeurIPS, 2022.
[39] Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu. Dpm-solver++: Fast solver for guided sampling of diffusion probabilistic models. ArXiv preprint, abs/2211.01095, 2022.
[40] Chenlin Meng, Kristy Choi, Jiaming Song, and Stefano Ermon. Concrete score matching: Generalized score matching for discrete data. Advances in Neural Information Processing Systems, 35:34532-34545, 2022.
[41] Maxwell Nye, Anders Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, Charles Sutton, and Augustus Odena. Show your work: Scratchpads for intermediate computation with language models. ArXiv preprint, abs/2112.00114, 2021.
[42] OpenAI. Gpt-4 technical report. ArXiv preprint, abs/2303.08774, 2023.
[43] Noah Shinn, Beck Labash, and Ashwin Gopinath. Reflexion: an autonomous agent with dynamic memory and self-reflection. ArXiv preprint, abs/2303.11366, 2023.
[44] Mukul Singh, José Cambronero, Sumit Gulwani, Vu Le, Carina Negreanu, and Gust Verbruggen. CodeFusion: A pre-trained diffusion model for code generation. In Houda Bouamor, Juan Pino, and Kalika Bali, editors, Proc. of EMNLP, pages 11697-11708. Association for Computational Linguistics, 2023.
[45] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. In Proc. of ICLR. OpenReview.net, 2021.</p>
<p>[46] Yang Song, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. In International Conference on Learning Representations, 2021.
[47] Keith E. Stanovich and Richard F. West. Individual differences in reasoning: Implications for the rationality debate? Behavioral and Brain Sciences, 23:645 - 665, 2000.
[48] Mirac Suzgun, Nathan Scales, Nathanael Scharli, Sebastian Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha Chowdhery, Quoc V. Le, Ed Huai hsin Chi, Denny Zhou, and Jason Wei. Challenging bigbench tasks and whether chain-of-thought can solve them. In Annual Meeting of the Association for Computational Linguistics, 2022.
[49] Mirac Suzgun, Nathan Scales, Nathanael Schärli, Sebastian Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha Chowdhery, Quoc Le, Ed Chi, Denny Zhou, and Jason Wei. Challenging BIG-bench tasks and whether chain-of-thought can solve them. In Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki, editors, Findings of the Association for Computational Linguistics: ACL 2023, pages 13003-13051. Association for Computational Linguistics, 2023.
[50] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation language models. ArXiv preprint, abs/2302.13971, 2023.
[51] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan, and Roman Garnett, editors, Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA, pages 5998-6008, 2017.
[52] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models. In The Eleventh International Conference on Learning Representations, 2022.
[53] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. Emergent abilities of large language models. Transactions on Machine Learning Research, 2022.
[54] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Huai hsin Chi, F. Xia, Quoc Le, and Denny Zhou. Chain of thought prompting elicits reasoning in large language models. ArXiv preprint, abs/2201.11903, 2022.
[55] Zhiyong Wu, Yaoxiang Wang, Jiacheng Ye, and Lingpeng Kong. Self-adaptive in-context learning: An information compression perspective for in-context example selection and ordering. In Annual Meeting of the Association for Computational Linguistics, 2022.
[56] Yuxi Xie, Kenji Kawaguchi, Yiran Zhao, Xu Zhao, Min-Yen Kan, Junxian He, and Qizhe Xie. Decomposition enhances reasoning via self-evaluation guided decoding. ArXiv preprint, abs/2305.00633, 2023.
[57] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, and Karthik Narasimhan. Tree of thoughts: Deliberate problem solving with large language models. ArXiv preprint, abs/2305.10601, 2023.
[58] Jiacheng Ye, Zhiyong Wu, Jiangtao Feng, Tao Yu, and Lingpeng Kong. Compositional exemplars for in-context learning. In International Conference on Machine Learning, 2023.
[59] Jiasheng Ye, Zaixiang Zheng, Yu Bao, Lihua Qian, and Quanquan Gu. Diffusion language models can perform many tasks with scaling and instruction-finetuning. ArXiv preprint, abs/2308.12219, 2023.
[60] Jiasheng Ye, Zaixiang Zheng, Yu Bao, Lihua Qian, and Mingxuan Wang. Dinoiser: Diffused conditional sequence learning by manipulating noises. ArXiv preprint, abs/2302.10025, 2023.
[61] Hongyi Yuan, Zheng Yuan, Chuanqi Tan, Fei Huang, and Songfang Huang. Seqdiffuseq: Text diffusion with encoder-decoder transformers. ArXiv preprint, abs/2212.10325, 2022.
[62] Haopeng Zhang, Xiao Liu, and Jiawei Zhang. Diffusum: Generation enhanced extractive summarization with diffusion. ArXiv preprint, abs/2305.01735, 2023.</p>
<p>[63] Yizhe Zhang, Jiatao Gu, Zhuofeng Wu, Shuangfei Zhai, Joshua M. Susskind, and Navdeep Jaitly. PLANNER: Generating diversified paragraph via latent language diffusion model. In Thirty-seventh Conference on Neural Information Processing Systems, 2023.
[64] Zhuosheng Zhang, Aston Zhang, Mu Li, George Karypis, Alex Smola, et al. Multimodal chain-of-thought reasoning in language models. Transactions on Machine Learning Research, 2023.
[65] Lin Zheng, Jianbo Yuan, Lei Yu, and Lingpeng Kong. A reparameterized discrete diffusion model for text generation. ArXiv preprint, abs/2302.05737, 2023.
[66] Kun Zhou, Yifan Li, Wayne Xin Zhao, and Ji rong Wen. Diffusion-nat: Self-prompting discrete diffusion for non-autoregressive text generation. ArXiv preprint, abs/2305.04044, 2023.
[67] Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. ArXiv preprint, abs/2211.01910, 2022.
[68] Kaijie Zhu, Jindong Wang, Jiaheng Zhou, Zichen Wang, Hao Chen, Yidong Wang, Linyi Yang, Wei Ye, Neil Zhenqiang Gong, Yue Zhang, et al. Promptbench: Towards evaluating the robustness of large language models on adversarial prompts. In International Conference on Learning Representations, ICLR, 2024.
[69] Hao Zou, Zae Myung Kim, and Dongyeop Kang. A survey of diffusion models in natural language processing. ArXiv preprint, abs/2305.14671, 2023.</p>
<h1>A Derivations</h1>
<h2>A. 1 Seq2Seq Modeling in DiffuSeq</h2>
<p>To implement the diffusion model in seq2seq generation, we inherit the design from DiffuSeq [14], which systematically defines the forward noising process and reverse denoising process on latent continuous space $\mathbf{z}$ as two major components of the model.</p>
<p>Latent space configuration z. Following Li et al. [33], z is constructed from an embedding function $\operatorname{EMB}\left(\mathbf{w}^{\mathbf{z}}\right)$, which takes the discrete text $\mathbf{w}^{z}$ as input. Particulatly, in Diffuseq [14], $\mathbf{w}^{z}$ contains $\mathbf{w}^{x}$ and $\mathbf{w}^{y}$ where $\mathbf{w}^{x}$ is the source sequence and $\mathbf{w}^{y}$ is the target sequence. The relationship is defined as $\mathbf{w}^{z}=\mathbf{w}^{[x ; y]}$. They denote $\mathbf{z}<em t="t">{t}=\mathbf{x}</em>} \oplus \mathbf{y<em t="t">{t}$ to simplify the wordings, where $\mathbf{x}</em>}$ and $\mathbf{y<em t="t">{t}$ represent parts of $\mathbf{z}</em>$, respectively.}$ that belong to $\mathbf{w}^{x}$ and $\mathbf{w}^{y</p>
<p>Forward diffusion process $q\left(\mathbf{z}<em t-1="t-1">{t} \mid \mathbf{z}</em>}\right)$ and $q\left(\mathbf{z<em 0="0">{t} \mid \mathbf{z}</em>}\right)$. The process of forward noising is to fractionally disrupt the content of input data $\mathbf{z<em t="t">{0}$, introduced as partial noising by Gong et al. [15]. It is achieved by only applying Gaussian noise to $\mathbf{y}</em>}$ and preserving $\mathbf{x<em t="t">{t}$ with a masking scheme, denoted as $\mathbf{z}</em>}=\left[\mathbf{x<em t="t">{t} ; \mathbf{y}</em>]$.
After the process of forward noising where $T$-step forward random disturbance is applied, the $\mathbf{z}}\right]$ with mask $[\mathbf{0} ; \mathbf{1<em T="T">{0}$ is finally transformed into the partial Gaussian noise with $\mathbf{y}</em>)$.} \sim \mathcal{N}(0, \mathbf{I</p>
<p>$$
\begin{gathered}
q\left(\mathbf{z}<em t-1="t-1">{t} \mid \mathbf{z}</em>}\right)=\mathcal{N}\left(\mathbf{z<em t="t">{t} ; \sqrt{1-\beta</em>}} \mathbf{z<em t="t">{t-1}, \beta</em>\right) \
q\left(\mathbf{z}} \mathbf{I<em 0="0">{1: T} \mid \mathbf{z}</em>}\right)=\prod_{t=1}^{T} q\left(\mathbf{z<em t-1="t-1">{t} \mid \mathbf{z}</em>\right)
\end{gathered}
$$</p>
<p>where $t=1,2, \ldots, T$ and $\left{\beta_{t} \in(0,1)\right}<em t="t">{t=1}^{T}$ are the variance schedule. A reparameterization trick could be applied to the above process to attain a closed-form representation of sampling $\mathbf{z}</em>}$ at any arbitrary time step $t$. Let $\alpha_{t}=1-\beta_{t}$ and $\bar{\alpha<em i="1">{t}=\prod</em>$, the equation is reduced to:}^{t} \alpha_{i</p>
<p>$$
\begin{aligned}
\mathbf{z}<em t="t">{t} &amp; =\sqrt{\alpha</em>}} \mathbf{z<em t="t">{t-1}+\sqrt{1-\alpha</em>}} \epsilon_{t-1}=\sqrt{\alpha_{t} \alpha_{t-1}} \mathbf{z<em t="t">{t-2}+\sqrt{1-\alpha</em>} \alpha_{t-1}} \bar{\epsilon<em t="t">{t-2} \
&amp; =\ldots=\sqrt{\bar{\alpha}</em>}} \mathbf{z<em t="t">{0}+\sqrt{1-\bar{\alpha}</em> \epsilon
\end{aligned}
$$}</p>
<p>where $\boldsymbol{\epsilon}<em t-2="t-2">{t-1}, \boldsymbol{\epsilon}</em>$ merges all the Gaussians. In the end:}, \cdots \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$ and $\boldsymbol{\epsilon</p>
<p>$$
q\left(\mathbf{z}<em 0="0">{t} \mid \mathbf{z}</em>}\right)=\mathcal{N}\left(\mathbf{z<em t="t">{t} ; \sqrt{\bar{\alpha}</em>}} \mathbf{z<em t="t">{0},\left(1-\bar{\alpha}</em>\right)
$$}\right) \mathbf{I</p>
<p>A sqrt noise schedule is applied according to the Diffusion-LM [33], that is, $\bar{\alpha}_{t}=1-\sqrt{t / T+s}$ with $s$ as a small constant at the start of the noise level.</p>
<p>Posterior $q\left(\mathbf{z}<em t="t">{t-1} \mid \mathbf{z}</em>\right)$. Derived by Bayes' rule, the posterior is given by:}, \mathbf{z}_{0</p>
<p>$$
q\left(\mathbf{z}<em t="t">{t-1} \mid \mathbf{z}</em>}, \mathbf{z<em t="t">{0}\right)=q\left(\mathbf{z}</em>} \mid \mathbf{z<em 0="0">{t-1}, \mathbf{z}</em>}\right) \frac{q\left(\mathbf{z<em 0="0">{t-1} \mid \mathbf{z}</em>}\right)}{q\left(\mathbf{z<em 0="0">{t} \mid \mathbf{z}</em>
$$}\right)</p>
<p>Given the above relationship, the posterior is still in Gaussian form. After applying the Eq. (4) to it, the mean of $q\left(\mathbf{z}<em t="t">{t-1} \mid \mathbf{z}</em>\right)$ could be derived:}, \mathbf{z}_{0</p>
<p>$$
\mu_{t}\left(\mathbf{z}<em 0="0">{t}, \mathbf{z}</em>}\right)=\frac{\sqrt{\alpha_{t}}\left(1-\bar{\alpha<em t="t">{t-1}\right)}{1-\bar{\alpha}</em>}} \mathbf{z<em t-1="t-1">{t}+\frac{\sqrt{\bar{\alpha}</em>}}\left(1-\alpha_{t}\right)}{1-\bar{\alpha<em 0="0">{t}} \mathbf{z}</em>
$$</p>
<p>Backward generative process $p_{\theta}\left(\mathbf{z}<em T="T">{0: T} \mid \mathbf{z}</em>}\right)$. After the forward noising process is defined and the training is completed, the reverse denoising process then denoises $\mathbf{z<em 0="0">{t}$, aiming to recover original $\mathbf{z}</em>}$ with the trained Diffuseq model $\mathbf{z<em t="t">{\theta}\left(\mathbf{z}</em>, t\right)$. This process is defined as:</p>
<p>$$
\begin{gathered}
p_{\theta}\left(\mathbf{z}<em _theta="\theta">{0: T}\right)=p</em>}\left(\mathbf{z<em t="1">{T}\right) \prod</em>}^{T} p_{\theta}\left(\mathbf{z<em t="t">{t-1} \mid \mathbf{z}</em>\right) \
p_{\theta}\left(\mathbf{z}<em t="t">{t-1} \mid \mathbf{z}</em>}\right)=\mathcal{N}\left(\mathbf{z<em _theta="\theta">{t-1} ; \mu</em>}\left(\mathbf{z<em _theta="\theta">{t}, t\right), \sigma</em>, t\right)\right)
\end{gathered}
$$}\left(\mathbf{z}_{t</p>
<p>and the initial state $p_{\theta}\left(\mathbf{z}_{T}\right)$ is defined as $\mathcal{N}(0, \mathbf{I})$.</p>
<p>Training objective $\mathcal{L}<em 0="0">{\text {VLB. }}$. Inherited from Diffuseq [14], the training objective is to recover the original $\mathbf{z}</em>}$ by denoising $\mathbf{z<em _theta="\theta">{t}$ as in Eq. (8). The learning process as Eq. (9) is modeled by Diffuseq: $\mathbf{z}</em>}\left(\mathbf{z<em _theta="\theta">{t}, t\right)$, where the $\mu</em>}(\cdot)$ and $\sigma_{\theta}(\cdot)$ serve as the parameterization of the predicted mean and standard deviation of $q\left(\mathbf{z<em t="t">{t-1} \mid \mathbf{z}</em>}\right)$ in the forward noising process respectively. The input $\mathbf{x<em _theta="\theta">{t}$ serves as the condition during the reverse denoising process as the partial noising is adopted in the forward noising.
Typically, a transformer architecture is adopted to model $\mathbf{z}</em>}$, which is capable of modeling the semantic relation between $\mathbf{x<em t="t">{t}$ and $\mathbf{y}</em>\right)$ is computed as follows:}$ instinctively. The variational lower bound $\left(\mathcal{L}_{\text {VLB }</p>
<p>$$
\mathcal{L}<em q_left_mathbf_z="q\left(\mathbf{z">{\mathrm{VLB}}\left(\mathbf{w}^{z}\right)=\mathbb{E}</em><em T="T">{0} \mid \mathbf{w}^{z}\right)}[\underbrace{\log \frac{q\left(\mathbf{z}</em>} \mid \mathbf{w}^{z}\right)}{p_{\theta}\left(\mathbf{z<em _Prior="{Prior" _text="\text" loss="loss">{T}\right)}}</em>}}+\underbrace{\mathcal{L<em 0="0">{\mathrm{VLB}}\left(\mathbf{z}</em>}\right)<em _theta="\theta">{\text {Diffusion loss }} \underbrace{-\log p</em>}\left(\mathbf{w}^{z} \mid \mathbf{z<em _Rounding="{Rounding" _text="\text" loss="loss">{0}\right)}</em>
$$}}],</p>
<p>where the diffusion loss is the same as the continuous diffusion loss in DDPM [21], which is given by:</p>
<p>$$
\mathcal{L}<em 0="0">{\mathrm{VLB}}\left(\mathbf{z}</em>}\right)=\mathbb{E<em 1:="1:" T="T">{q\left(\mathbf{z}</em>} \mid \mathbf{z<em T="T">{0}\right)}[\underbrace{\log \frac{q\left(\mathbf{z}</em>} \mid \mathbf{z<em _theta="\theta">{0}\right)}{p</em>}\left(\mathbf{z<em _mathcal_L="\mathcal{L">{T}\right)}}</em><em t="2">{T}}+\underbrace{\sum</em>}^{T} \log \frac{q\left(\mathbf{z<em 0="0">{t-1} \mid \mathbf{z}</em>}, \mathbf{z<em _theta="\theta">{t}\right)}{p</em>}\left(\mathbf{z<em t="t">{t-1} \mid \mathbf{z}</em>}\right)}<em T-1="T-1">{\mathcal{L}</em>}+\cdots+\mathcal{L<em _theta="\theta">{1}}-\underbrace{\log p</em>}\left(\mathbf{z<em 1="1">{0} \mid \mathbf{z}</em>}\right)<em 0="0">{\mathcal{L}</em>]
$$}</p>
<p>Here the prior loss and $\mathcal{L}<em _theta="\theta">{T}$ is considered as a constant when the noising schedule $q$ is fixed and $p</em>)$.
After reweighting each term (i.e., treating all the loss terms across time-steps equally) as in Ho et al. [21] and using the Monte Carlo optimizer, the training objective can be further simplified as:}\left(\mathbf{z}_{T}\right)=\mathcal{N}(0, \mathbf{I</p>
<p>$$
\begin{aligned}
\min <em _mathrm_VLB="\mathrm{VLB">{\theta} \mathcal{L}</em>\right) &amp; \rightarrow \min }}\left(\mathbf{w}^{z<em q_left_mathbf_z="q\left(\mathbf{z">{\theta} \mathbb{E}</em><em t="2">{0: T} \mid \mathbf{w}^{z}\right)}\left[\sum</em>}^{T}\left|\mathbf{z<em _theta="\theta">{0}-\mathbf{z}</em>}\left(\mathbf{z<em _theta="\theta">{t}, t\right)\right|^{2}+\left|\operatorname{EMB}\left(\mathbf{w}^{z}\right)-\mathbf{z}</em>}\left(\mathbf{z<em _theta="\theta">{1}, 1\right)\right|^{2}-\log p</em>}\left(\mathbf{w}^{z} \mid \mathbf{z<em _theta="\theta">{0}\right)\right] \
&amp; \rightarrow \min </em>}\left[\sum_{t=2}^{T}\left|\mathbf{y<em _theta="\theta">{0}-\tilde{\mathbf{z}}</em>}\left(\mathbf{z<em _theta="\theta">{t}, t\right)\right|^{2}+\left|\operatorname{EMB}\left(\mathbf{w}^{y}\right)-\tilde{\mathbf{z}}</em>}\left(\mathbf{z<em 0="0">{1}, 1\right)\right|^{2}+\mathcal{R}\left(\left|\mathbf{y}</em>\right)\right] \
&amp; \rightarrow \min }\right|^{2<em t="1">{\theta}\left[\sum</em>}^{T}\left|\mathbf{y<em _theta="\theta">{0}-\tilde{\mathbf{z}}</em>}\left(\mathbf{z<em 0="0">{t}, t\right)\right|^{2}+\mathcal{R}\left(\left|\mathbf{y}</em>\right)\right]
\end{aligned}
$$}\right|^{2</p>
<p>where $\tilde{\mathbf{z}}<em t="t">{\theta}\left(\mathbf{z}</em>}, t\right)$ is used to denote the fractions of recovered $\mathbf{z<em 0="0">{0}$ corresponding to $\mathbf{y}</em>\right)$ ) is the regularization term which regularizes the embedding learning. The embedding function is shared between source and target sequences, contributing to the joint training process of two different feature spaces.} . \mathcal{R}\left(\left|\mathbf{y}_{0}\right|^{2</p>
<h1>A. 2 Pre-trained Plaid</h1>
<p>The Plaid model [18] mostly adopts the variational diffusion model (VDM) framework [28] and we illustrate its forward, reverse, and loss calculations in this section. When fine-tuning Plaid 1B, we use the VDM formulation and apply the same sequence-to-sequence modification as in DiffuSeq. This involves imposing partial noise on $\mathbf{z}_{t}$ and keeping the source condition sentence anchored as un-noised.</p>
<p>Forward diffusion process $q\left(\mathbf{z}<em 0="0">{t} \mid \mathbf{z}</em>}\right)$ and $q\left(\mathbf{z<em s="s">{t} \mid \mathbf{z}</em>}\right)$. The distribution of latent $\mathbf{z<em 0="0">{t}$ conditioned on $\mathbf{z}</em>$ is given by:</p>
<p>$$
q\left(\mathbf{z}<em 0="0">{t} \mid \mathbf{z}</em>}\right)=\mathcal{N}\left(\alpha_{t} \mathbf{z<em t="t">{0}, \sigma</em>\right)
$$}^{2} \mathbf{I</p>
<p>After reparameterization, we have $\mathbf{z}<em s="s">{0}=\left(\mathbf{z}</em>}-\epsilon_{1} \sigma_{s}\right) / \alpha_{s}$ and $\mathbf{z<em t="t">{t}=\left(\alpha</em>} / \alpha_{s}\right) \mathbf{z<em t="t">{s}-\left(\alpha</em>} \sigma_{s} / \alpha_{s}\right) \epsilon_{1}+\sigma_{t} \epsilon_{2}$, where $\epsilon_{1} \sim \mathcal{N}(0, \mathbf{I})$ and $\epsilon_{2} \sim \mathcal{N}(0, \mathbf{I})$. Then after merging two uniform Gaussians, the distribution of $\mathbf{z<em s="s">{t}$ given $\mathbf{z}</em>$, for any $0 \leq s&lt;t \leq 1$, is given by:</p>
<p>$$
q\left(\mathbf{z}<em s="s">{t} \mid \mathbf{z}</em>}\right)=\mathcal{N}\left(\alpha_{t \mid s} \mathbf{z<em _mid="\mid" s="s" t="t">{s}, \sigma</em>\right)
$$}^{2} \mathbf{I</p>
<p>where $\alpha_{t \mid s}=\alpha_{t} / \alpha_{s}$ and $\sigma_{t \mid s}^{2}=\sigma_{t}^{2}-\alpha_{t \mid s}^{2} \sigma_{s}^{2}$. The variance-preserving special case gives $\alpha_{t}=$ $\sqrt{1-\sigma_{t}^{2}}$. In VDM, the noise schedule $\alpha_{t}$ and $\sigma_{t}^{2}$, which specify how much noise to add at each time in the diffusion process, are parameterized as a scalar-to-scalar neural network $\boldsymbol{\eta}$ that satisfies $\sigma_{t}^{2}=\operatorname{sigmoid}\left(\gamma_{\boldsymbol{\eta}}(t)\right)$ and $\alpha_{t}^{2}=\operatorname{sigmoid}\left(-\gamma_{\boldsymbol{\eta}}(t)\right)$. This is different from previous practices that use a predefined function, e.g., DDPM [21] set the forward process variances to constants increasing linearly from $\beta_{1}=10^{-4}$ to $\beta_{T}=0.02$.</p>
<p>Posterior $q\left(\mathbf{z}<em t="t">{s} \mid \mathbf{z}</em>}, \mathbf{z<em s="s">{0}\right)$. The joint distribution of latent variables $\left(\mathbf{z}</em>}, \mathbf{z<em u="u">{t}, \mathbf{z}</em>}\right)$ at any subsequent timesteps $0 \leq s&lt;t&lt;u \leq 1$ is Markov: $q\left(\mathbf{z<em t="t">{u} \mid \mathbf{z}</em>}, \mathbf{z<em u="u">{s}\right)=q\left(\mathbf{z}</em>} \mid \mathbf{z<em s="s">{t}\right)$. Given the distributions above, we can verify through the Bayes rule that $q\left(\mathbf{z}</em>} \mid \mathbf{z<em 0="0">{t}, \mathbf{z}</em>\right)$, for any $0 \leq s&lt;t \leq 1$, is also Gaussian given by:</p>
<p>$$
\begin{aligned}
q\left(\mathbf{z}<em t="t">{s} \mid \mathbf{z}</em>}, \mathbf{z<em Q="Q">{0}\right) &amp; =\mathcal{N}\left(\mu</em>}\left(\mathbf{z<em 0="0">{t}, \mathbf{z}</em>\right) \
\text { where } \sigma_{Q}^{2}(s, t) &amp; =\sigma_{t \mid s}^{2} \sigma_{s}^{2} / \sigma_{t}^{2} \
\text { and } \mu_{Q}\left(\mathbf{z}} ; s, t\right), \sigma_{Q}^{2}(s, t) \mathbf{I<em 0="0">{t}, \mathbf{z}</em>} ; s, t\right) &amp; =\frac{\alpha_{t \mid s} \sigma_{s}^{2}}{\sigma_{t}^{2}} \mathbf{z<em s="s">{t}+\frac{\alpha</em>
\end{aligned}
$$} \sigma_{t \mid s}^{2}}{\sigma_{t}^{2}} \mathbf{z}_{0</p>
<p>Backward generative process $p_{\theta}\left(\mathbf{z}<em t="t">{s} \mid \mathbf{z}</em>}\right)$. In VDM, the reverse process or the generative process is also defined as a Gaussian that satisfies $p_{\theta}\left(\mathbf{z<em t="t">{s} \mid \mathbf{z}</em>}\right)=q\left(\mathbf{z<em t="t">{s} \mid \mathbf{z}</em>}, \mathbf{z<em _theta="\theta">{0}=\mathbf{z}</em>}\left(\mathbf{z<em s="s">{t} ; t\right)\right)$, i.e. the same as $q\left(\mathbf{z}</em>} \mid \mathbf{z<em 0="0">{t}, \mathbf{z}</em>}\right)$, but with the original data $\mathbf{z<em _theta="\theta">{0}$ replaced by the output of the denoising model $\mathbf{z}</em>}\left(\mathbf{z<em _theta="\theta">{t} ; t\right)$. Therefore, based on Eq. (17), the mean of $p</em>}\left(\mathbf{z<em t="t">{s} \mid \mathbf{z}</em>\right)$ is given by:</p>
<p>$$
\mu_{\theta}\left(\mathbf{z}<em _mid="\mid" s="s" t="t">{t} ; s, t\right)=\frac{\alpha</em>} \sigma_{s}^{2}}{\sigma_{t}^{2}} \mathbf{z<em s="s">{t}+\frac{\alpha</em>} \sigma_{t \mid s}^{2}}{\sigma_{t}^{2}} \mathbf{z<em t="t">{\theta}\left(\mathbf{z}</em> ; t\right)
$$</p>
<p>and the variance is the same as Eq. (16).
Continuous diffusion loss term $\mathcal{L}<em 0="0">{\text {VLB }}\left(\mathbf{z}</em>\right)$. The prior loss and rounding loss in Eq. (10) can be (stochastically and differentiably) estimated using standard techniques. We now derive an estimator for the diffusion loss in VDM. Different from Eq.(12) which simplifies the loss term by reweighting, VDM adopts the standard loss formulation. We begin with the derivations of diffusion loss for discrete-time diffusion with $t \in{1, \ldots, T}$, which is given by:</p>
<p>$$
\mathcal{L}<em 0="0">{\mathrm{VLB}}\left(\mathbf{z}</em>}\right)=\sum_{t=1}^{T} \mathbb{E<em t="t">{q\left(\mathbf{z}</em>} \mid \mathbf{z<em K="K" L="L">{0}\right)} D</em>}\left[q\left(\mathbf{z<em t="t">{s} \mid \mathbf{z}</em>}, \mathbf{z<em s="s">{0}\right) | p\left(\mathbf{z}</em>\right)\right]
$$} \mid \mathbf{z}_{t</p>
<p>and we derive the expression of $D_{K L}\left(q\left(\mathbf{z}<em t="t">{s} \mid \mathbf{z}</em>}, \mathbf{z<em _theta="\theta">{0}\right) | p</em>}\left(\mathbf{z<em t="t">{s} \mid \mathbf{z}</em>\right)\right)$ as follows:</p>
<p>$$
\begin{aligned}
D_{K L}\left(q\left(\mathbf{z}<em t="t">{s} \mid \mathbf{z}</em>}, \mathbf{z<em _theta="\theta">{0}\right) | p</em>}\left(\mathbf{z<em t="t">{s} \mid \mathbf{z}</em>\right|}\right)\right) &amp; =\frac{1}{2 \sigma_{Q}^{2}(s, t)}\left|\mu_{Q}-\mu_{\theta<em t="t">{2}^{2} \
&amp; =\frac{\sigma</em>}^{2}}{2 \sigma_{t \mid s}^{2} \sigma_{s}^{2}} \frac{\alpha_{s}^{2} \sigma_{t \mid s}^{4}}{\sigma_{t}^{4}}\left|\mathbf{z<em _theta="\theta">{0}-\mathbf{z}</em>}\left(\mathbf{z<em 2="2">{t} ; t\right)\right|</em> \
&amp; =\frac{1}{2 \sigma_{s}^{2}} \frac{\alpha_{s}^{2} \sigma_{t \mid s}^{2}}{\sigma_{t}^{2}}\left|\mathbf{z}}^{2<em _theta="\theta">{0}-\mathbf{z}</em>}\left(\mathbf{z<em 2="2">{t} ; t\right)\right|</em> \
&amp; =\frac{1}{2 \sigma_{s}^{2}} \frac{\alpha_{s}^{2}\left(\sigma_{t}^{2}-\alpha_{t \mid s}^{2} \sigma_{s}^{2}\right)}{\sigma_{t}^{2}}\left|\mathbf{z}}^{2<em _theta="\theta">{0}-\mathbf{z}</em>}\left(\mathbf{z<em 2="2">{t} ; t\right)\right|</em> \
&amp; =\frac{1}{2} \frac{\alpha_{s}^{2} \sigma_{t}^{2} / \sigma_{s}^{2}-\alpha_{t}^{2}}{\sigma_{t}^{2}}\left|\mathbf{z}}^{2<em _theta="\theta">{0}-\mathbf{z}</em>}\left(\mathbf{z<em 2="2">{t} ; t\right)\right|</em> \
&amp; =\frac{1}{2}\left(\frac{\alpha_{s}^{2}}{\sigma_{s}^{2}}-\frac{\alpha_{t}^{2}}{\sigma_{t}^{2}}\right)\left|\mathbf{z}}^{2<em _theta="\theta">{0}-\mathbf{z}</em>}\left(\mathbf{z<em 2="2">{t} ; t\right)\right|</em> \
&amp; =\frac{1}{2}(\operatorname{SNR}(s)-\operatorname{SNR}(t))\left|\mathbf{z}}^{2<em _theta="\theta">{0}-\mathbf{z}</em>}\left(\mathbf{z<em 2="2">{t} ; t\right)\right|</em>
\end{aligned}
$$}^{2</p>
<p>where $\operatorname{SNR}(t)=\alpha_{t}^{2} / \sigma_{t}^{2}$ and its physical meaning is signal-to-noise ratio.</p>
<p>After reparameterization of $\mathbf{z}_{t}$, the diffusion loss function becomes:</p>
<p>$$
\begin{aligned}
\mathcal{L}<em 0="0">{\mathrm{VLB}}\left(\mathbf{z}</em>}\right) &amp; =\sum_{t=1}^{T} \mathbb{E<em t="t">{q\left(\mathbf{z}</em>} \mid \mathbf{z<em K="K" L="L">{0}\right)}\left[D</em>}\left(q\left(\mathbf{z<em t="t">{s} \mid \mathbf{z}</em>}, \mathbf{z<em _theta="\theta">{0}\right) | p</em>}\left(\mathbf{z<em t="t">{s} \mid \mathbf{z}</em>\right)\right)\right] \
&amp; =\frac{1}{2} \mathbb{E}<em t="1">{\epsilon \sim \mathcal{N}(0, \mathbf{I})}\left[\sum</em>}^{T}(\operatorname{SNR}(s)-\operatorname{SNR}(t)) | \mathbf{z<em _theta="\theta">{0}-\mathbf{z}</em>}\left(\mathbf{z<em 2="2">{t} ; t\right) |</em>\right]
\end{aligned}
$$}^{2</p>
<p>In practice, we follow Plaid to use the continuous-time diffusion formulation, where $t \in[0,1]$, and we can express $\mathcal{L}$ as a function of $\tau$ with $\tau \rightarrow 0$ :</p>
<p>$$
\mathcal{L}<em 0="0">{\mathrm{VLB}}\left(\mathbf{z}</em>}\right)=\frac{1}{2} \mathbb{E<em 0="0">{\epsilon \sim \mathcal{N}(0, \mathbf{I})} \int</em>}^{1}\left[\frac{\operatorname{SNR}(t-\tau)-\operatorname{SNR}(t)}{\tau}\left|\mathbf{z<em _theta="\theta">{0}-\mathbf{z}</em>}\left(\mathbf{z<em 2="2">{t} ; t\right)\right|</em>\right] d t
$$}^{2</p>
<p>and let $\operatorname{SNR}^{\prime}(t)$ denote the derivative of the SNR function, this then gives:</p>
<p>$$
\mathcal{L}<em 0="0">{\mathrm{VLB}}\left(\mathbf{z}</em>}\right)=-\frac{1}{2} \mathbb{E<em 0="0">{\epsilon \sim \mathcal{N}(0, \mathbf{I})} \int</em>}^{1} \operatorname{SNR}^{\prime}(t)\left|\mathbf{z<em _theta="\theta">{0}-\mathbf{z}</em>}\left(\mathbf{z<em 2="2">{t} ; t\right)\right|</em> d t
$$}^{2</p>
<h1>A. 3 Pre-trained SEDD</h1>
<p>SEDD [37] is a discrete diffusion language model built based on discrete score matching [40], which generalizes score matching [45, 46] to the discrete data. We now denote $x$ as a categorical random variable and the following derivation can be extended to a sequence of variable $\mathbf{x}$ as well.</p>
<p>Concrete score. Instead of directly modeling $p_{\theta}(x)$ to approximate original data distribution $q(x)$, the core idea of discrete score matching is to learn a quantity known as the concrete score [40] through a neural network:</p>
<p>$$
s_{\theta}(x)<em _theta="\theta">{y}=\frac{p</em>
$$}(y)}{p_{\theta}(x)}=\frac{e^{f_{\theta}(y)} / Z}{e^{f_{\theta}(x)} / Z}=\frac{e^{f_{\theta}(y)}}{e^{f_{\theta}(x)}</p>
<p>which eliminates normalizing constant $Z$ as in the energy-based model. In particular, this quantity is the categorical equivalent of the famous score function $\nabla_{x} \log p$ in continuous space. Regarding the choice of $y$, if we model the ratio for every possible $y$, we would have $V$ items given $V$ as the dimension of $x$, and $N^{V}$ items for $\mathbf{x}$ given $N$ as the sequence length of $\mathbf{x}$, which is computationally intractable. So we sparsify and only model "relevant" ratios based on whether $y$ is "close" to $x$. These relevant positions will be denoted as $y \sim x$, e.g., all sentences $y$ that differ from $x$ with Hamming distance 1 .</p>
<p>Training objective. Lou et al. [37] define a learning objective named score entropy to learn the neural network, which is given by:</p>
<p>$$
\mathbb{E}<em _sim="\sim" x="x" y="y">{x \sim q}\left[\sum</em>(x)} s_{\theta<em _theta="\theta">{y}-\frac{q(y)}{q(x)} \log s</em>\right]
$$}(x)_{y</p>
<p>Taking a derivative w.r.t. $s$ and setting it to 0 , we see that this occurs when $s_{\theta}(x)<em t="t">{y}=\frac{q(y)}{q(x)}$, which can be easily checked to be globally optimal as the function is convex as a function of $s$. To handle the unknown term $\frac{q(y)}{q(x)}$, they further propose denoising score entropy motivated by denoising score matching [45] based on $q\left(x</em>\right)$ :}\right)=\sum_{x_{0}} q_{t \mid 0}\left(x_{t} \mid x_{0}\right) q_{0}\left(x_{0</p>
<p>$$
\mathbb{E}<em 0="0">{x</em>, t\right)} \sim q_{0}, t \sim U[0, T], x_{t} \sim q_{t \mid 0}\left(x_{t} \mid x_{0}\right)}\left[\sum_{y \sim x_{t}} s_{\theta}\left(x_{t<em 0="0" _mid="\mid" t="t">{y}-\frac{q</em>\right]
$$}\left(y \mid x_{0}\right)}{q_{t \mid 0}\left(x_{t} \mid x_{0}\right)} \log s_{\theta}\left(x_{t}, t\right)_{y</p>
<p>where $q_{t \mid 0}\left(\cdot \mid x_{0}\right)$ is a perturbation of a base density $q(\cdot)$ by a transition kernel, and the transition ratio $\frac{q_{t \mid 0}\left(y \mid x_{0}\right)}{q_{t \mid 0}\left(x_{t} \mid x_{0}\right)}$ is known by design.</p>
<p>Forward diffusion process. The transition $q_{t \mid 0}\left(x_{t} \mid x_{0}\right)$ is a vector that represents a categorical distribution, and can be defined by a forward diffusion process $q_{t \mid 0}\left(x_{t} \mid x_{0}\right)=\exp \left(\bar{\sigma}(t) Q\right)<em 0="0">{x</em>}}$, where $\bar{\sigma}(t) \in \mathbb{R<em 0="0">{\geq 0}$ is the cumulative noise $\int</em> \sigma(s) d s$ at timestep $t$ with a value close to 0 when $t$ is small and increasing when $t$ growing. Lou et al. [37] use two standard transition matrices with special structures to implement matrix $Q$ following prior work [1]:}^{t</p>
<p>$$
\begin{gathered}
Q^{\text {uniform }}=\left[\begin{array}{rrrrr}
1-V &amp; 1 &amp; \cdots &amp; 1 \
1 &amp; 1-V &amp; \cdots &amp; 1 \
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \
1 &amp; 1 &amp; \cdots &amp; 1-V
\end{array}\right] \
Q^{\text {absorb }}=\left[\begin{array}{ccccc}
-1 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 \
0 &amp; -1 &amp; \cdots &amp; 0 &amp; 0 \
\vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \
0 &amp; 0 &amp; \cdots &amp; -1 &amp; 0 \
1 &amp; 1 &amp; \cdots &amp; 1 &amp; 0
\end{array}\right]
\end{gathered}
$$</p>
<p>One can view the above diffusion process by taking small $\Delta t$ Euler steps and randomly sampling the resulting transitions:</p>
<p>$$
q_{t+\Delta t \mid t}\left(x_{t+\Delta t}=y \mid x_{t}=x\right) \propto \delta_{x y}+Q_{t}(y, x) \Delta t+O(\Delta t)
$$</p>
<p>where $Q_{t}=\sigma(t) Q$, and $O(\Delta t)$ represents terms that tend to zero at a faster rate than $\Delta t$.
Backward generative process. To simulate the diffusion defined above, one can use the Euler strategy to derive the time reversal of the forward process:</p>
<p>$$
q_{t-\Delta t \mid t}\left(x_{t-\Delta t}=y \mid x_{t}=x\right) \propto \delta_{x y}+R_{t}(y, x) \Delta t+O(\Delta t)
$$</p>
<p>where $R_{t}$ is the reverse transition rate matrix that can be derived using Bayes rule: $R_{t}(y, x)=$ $\frac{q_{t}(y)}{q_{t}(x)} Q_{t}(x, y)$. Each column of $R_{t}$ represents the transition probability from a token at timestep $t$ to other tokens at timestep $t-\Delta t$. Let $p_{\theta}\left(x_{t-\Delta t}=y \mid x_{t}=x\right)=q_{t-\Delta t \mid t}\left(x_{t-\Delta t}=y \mid x_{t}=x\right)$, we have:</p>
<p>$$
p_{\theta}\left(x_{t-\Delta t}=y \mid x_{t}=x\right) \propto \delta_{x y}+R_{t}^{\theta}(y, x) \Delta t+O(\Delta t)
$$</p>
<p>where $R_{t}^{\theta}(y, x)=\sum_{x_{0}} q_{0 \mid t}\left(x_{0} \mid x\right) \frac{q_{t \mid 0}\left(y \mid x_{0}\right)}{q_{t \mid 0}\left(x \mid x_{0}\right)} Q_{t}(x, y)=s_{\theta}(x, t)<em t="t">{y} Q</em>$, this is inefficient because only one position is modified per step. A natural alternative has been to use $\tau$-leaping [12], which performs an Euler step at each position simultaneously.}(x, y)$. For a sequence of random variables $\mathbf{x</p>
<h1>A. 4 Conditional ODE solver</h1>
<p>The sampling of continuous diffusion models can be implemented by solving the diffusion ODEs [45, 46]. Specifically, sampling by diffusion ODEs needs to discretize the following ODE [46] with $t$ changing from $T$ to 0 :</p>
<p>$$
\frac{\mathrm{d} \mathbf{z}<em t="t">{t}}{\mathrm{~d} t}=f(t) \mathbf{z}</em>}+\frac{g^{2}(t)}{2 \sigma_{t}} \boldsymbol{\epsilon<em t="t">{\theta}\left(\mathbf{z}</em>\right)
$$}, t\right), \quad \mathbf{z}_{T} \sim \mathcal{N}\left(\mathbf{0}, \tilde{\sigma}^{2} \mathbf{I</p>
<p>The data prediction model $\mathbf{z}<em t="t">{\theta}\left(\mathbf{z}</em>}, t\right)$ predicts the original data $\mathbf{z<em t="t">{0}$ based on the noisy $\mathbf{z}</em>}$, and its relationship with $\boldsymbol{\epsilon<em t="t">{\theta}\left(\mathbf{z}</em>}, t\right)$ is given by $\mathbf{z<em t="t">{\theta}\left(\mathbf{z}</em>} ; t\right):=\left(\mathbf{z<em t="t">{t}-\sigma</em>} \boldsymbol{\epsilon<em t="t">{\theta}\left(\mathbf{z}</em>$ is:}, t\right)\right) / \alpha_{t}$ [28]. Therefore, the equivalent diffusion ODE w.r.t. the data prediction model $\mathbf{z}_{\theta</p>
<p>$$
\frac{\mathrm{d} \mathbf{z}<em t="t">{t}}{\mathrm{~d} t}=\left(f(t)+\frac{g^{2}(t)}{2 \sigma</em>}^{2}}\right) \mathbf{z<em t="t">{t}-\frac{\alpha</em>} g^{2}(t)}{2 \sigma_{t}^{2}} \mathbf{z<em t="t">{\theta}\left(\mathbf{z}</em>\right)
$$}, t\right), \quad \mathbf{z}_{T} \sim \mathcal{N}\left(\mathbf{0}, \tilde{\sigma}^{2} \mathbf{I</p>
<p>where the coefficients $f(t)=\frac{\mathrm{d} \log \alpha_{t}}{\mathrm{~d} t}, g^{2}(t)=\frac{\mathrm{d} \sigma_{t}^{2}}{\mathrm{~d} t}-2 \frac{\mathrm{~d} \log \alpha_{t}}{\mathrm{~d} t} \sigma_{t}^{2}$ [28].
Given an initial value $\mathbf{z}<em _theta="\theta">{s}$ at time $s&gt;0$ and denote $\hat{\mathbf{z}}</em>}\left(\hat{\mathbf{z}<em _theta="\theta">{\lambda}, \lambda\right):=\mathbf{z}</em>}\left(\mathbf{z<em _lambda="\lambda">{t</em>}(\lambda)}, t_{\lambda}(\lambda)\right)$ as the change-ofvariable form of $\mathbf{z<em t="t">{\theta}$ for $\lambda$, the solution $\mathbf{z}</em>$ at time $t \in[0, s]$ of diffusion ODEs in Eq. (40) is:</p>
<p>$$
\mathbf{z}<em t="t">{t}=\frac{\sigma</em>}}{\sigma_{s}} \mathbf{z<em t="t">{s}+\sigma</em>} \int_{\lambda_{s}}^{\lambda_{t}} e^{\lambda} \hat{\mathbf{z}<em _lambda="\lambda">{\theta}\left(\hat{\mathbf{z}}</em> \lambda
$$}, \lambda\right) \mathrm{d</p>
<p>which can be proved by taking derivative w.r.t. $t$ in Eq. (41):</p>
<p>$$
\begin{aligned}
\frac{\mathrm{d} \mathbf{z}<em t="t">{t}}{\mathrm{~d} t} &amp; =\frac{\mathrm{d} \sigma</em>}}{\mathrm{~d} t} \frac{\mathbf{z<em s="s">{s}}{\sigma</em>}}+\frac{\mathrm{d} \sigma_{t}}{\mathrm{~d} t} \int_{\lambda_{s}}^{\lambda_{t}} e^{\lambda} \hat{\mathbf{z}<em _lambda="\lambda">{\theta}\left(\hat{\mathbf{z}}</em>}, \lambda\right) \mathrm{d} \lambda+\frac{\mathrm{d} \lambda_{t}}{\mathrm{~d} t} \sigma_{t} e^{\lambda_{t}} \hat{\mathbf{z}<em _lambda__t="\lambda_{t">{\theta}\left(\hat{\mathbf{z}}</em>\right) \
&amp; =\frac{\mathrm{d} \sigma_{t}}{\mathrm{~d} t} \frac{\mathbf{z}}}, \lambda_{t<em t="t">{t}}{\sigma</em>}}+\frac{\mathrm{d} \lambda_{t}}{\mathrm{~d} t} \sigma_{t} e^{\lambda_{t}} \hat{\mathbf{z}<em _lambda__t="\lambda_{t">{\theta}\left(\hat{\mathbf{z}}</em>\right) \
&amp; =\left(f(t)+\frac{g^{2}(t)}{2 \sigma_{t}^{2}}\right) \frac{\mathbf{z}}}, \lambda_{t<em t="t">{t}}{\sigma</em>}}-\frac{\alpha_{t} g^{2}(t)}{2 \sigma_{t}^{2}} \mathbf{z<em t="t">{\theta}\left(\mathbf{z}</em>, t\right)
\end{aligned}
$$</p>
<p>and this gives us the exact formulation as in Eq. (41).
Based on Eq. (41), the aim of an ODE solver is to approximate the exact solution at time $t_{i}$ given the previous value $\mathbf{z}<em i-1="i-1">{t</em>}}$ at time $t_{i-1}$. Denote $\mathbf{z<em _theta="\theta">{\theta}^{(n)}(\lambda):=\frac{\mathrm{d}^{n} \hat{\mathbf{z}}</em>}\left(\mathbf{z<em _theta="\theta">{\lambda}, \lambda\right)}{\mathrm{d} \lambda^{n}}$ as the $n$-th order total derivatives of $\mathbf{z}</em>}$ w.r.t. $\operatorname{logSNR} \lambda$. Lu et al. [38, 39] show that by taking the $(k-1)$-th Taylor expansion $(k \geq 1)$ at $\lambda_{t_{i-1}}$ for $\mathbf{z<em t__i-1="t_{i-1">{\theta}$ w.r.t. $\lambda \in\left[\lambda</em>$, we have}}, \lambda_{t_{i}}\right]$ and substitute it into Eq. (41) with $s=t_{i-1}$ and $t=t_{i</p>
<p>$$
\mathbf{z}<em i="i">{t</em>}}=\frac{\sigma_{t_{i}}}{\sigma_{t_{i-1}}} \mathbf{z<em i-1="i-1">{t</em>}}+\sigma_{t_{i}} \sum_{n=0}^{k-1} \underbrace{\mathbf{z<em _lambda__t__i-1="\lambda_{t_{i-1">{\theta}^{(n)}\left(\hat{\mathbf{z}}</em>}}}, \lambda_{t_{i-1}}\right)<em _lambda__t__i-1="\lambda_{t_{i-1">{\text {estimated }} \underbrace{\int</em>}}}^{\lambda_{t_{i}}} e^{\lambda} \frac{\left(\lambda-\lambda_{t_{i-1}}\right)^{n}}{n!}<em _omitted="{omitted" _text="\text">{\text {analytically computed }} \mathrm{d} \lambda}</em>
$$}}+\underbrace{\mathcal{O}\left(h_{i}^{k+1}\right)}_{\text {omitted }</p>
<p>where the integral $\int e^{\lambda} \frac{\left(\lambda-\lambda_{t_{i-1}}\right)^{n}}{n!} \mathrm{d} \lambda$ can be analytically computed by integral-by-parts. Therefore, to design a $k$-th order ODE solver, we only need to estimate the $n$-th order derivatives $\mathbf{z}<em t__i-1="t_{i-1">{\theta}^{(n)}\left(\lambda</em>\right)$ terms)}}\right)$ for $n \leq k-1$ after omitting the $\mathcal{O}\left(h_{i}^{k+1}\right)$ high-order error terms. For $k=1$, Eq. (42) becomes (after omitting the $\mathcal{O}\left(h_{i}^{k+1</p>
<p>$$
\mathbf{z}<em i="i">{t</em>}}=\frac{\sigma_{t_{i}}}{\sigma_{t_{i-1}}} \mathbf{z<em i-1="i-1">{t</em>}}+\sigma_{t_{i}} \mathbf{z<em t__i-1="t_{i-1">{\theta}\left(\mathbf{z}</em>}}, t_{i-1}\right) \int_{\lambda_{t_{i-1}}}^{\lambda_{t_{i}}} e^{\lambda} \mathrm{d} \lambda=\frac{\sigma_{t_{i}}}{\sigma_{t_{i-1}}} \mathbf{z<em i-1="i-1">{t</em>}}-\alpha_{t_{i}}\left(e^{-h_{i}}-1\right) \mathbf{z<em t__i-1="t_{i-1">{\theta}\left(\mathbf{z}</em>\right)
$$}}, t_{i-1</p>
<p>where $h_{i}:=\lambda_{t_{i}}-\lambda_{t_{i-1}}$ for $i=1, \ldots, T$.
Since DoT is conditionally trained with partial nosing, we introduce a conditional form of Eq. (43) when adapting the above ODE solver into the inference stage. For $k=1$, this is given by:</p>
<p>$$
\mathbf{y}<em i="i">{t</em>}}=\frac{\sigma_{t_{i}}}{\sigma_{t_{i-1}}} \mathbf{y<em i-1="i-1">{t</em>}}-\alpha_{t_{i}}\left(e^{-h_{i}}-1\right) \hat{\mathbf{z}<em t__i-1="t_{i-1">{\theta}\left(\mathbf{z}</em>\right)
$$}}, t_{i-1</p>
<p>where $\mathbf{z}<em i-1="i-1">{t</em>}}=\left[\mathbf{x}: \mathbf{y<em i-1="i-1">{t</em>}}\right]$ and $\hat{\mathbf{z}<em t="t">{\theta}\left(\mathbf{z}</em>}, t\right)$ is used to denote the fractions of recovered $\mathbf{z<em 0="0">{0}$ corresponding to $\mathbf{y}</em>$.</p>
<h1>B Experiment Details</h1>
<h2>B. 1 Dataset Statistics</h2>
<p>We list the statistics of our used datasets in Table 4. For the digit multiplication datasets and GSM8K dataset, we use processed datasets from Implict $\mathrm{CoT}^{6}$ [7]. For boolean logic task, we construct the training and test dataset using the method from DyVal [68]. All datasets contain 1000 test examples except GSM8K, which contains 1319 examples.</p>
<h2>B. 2 Details of Baselines</h2>
<p>When fine-tuning GPT2, we train 40 epochs using the learning rate of $1 \mathrm{e}-4$ for boolean logic and $5 \mathrm{e}-4$ for others. During inference, we use greedy decoding for single decoding. For self-consistency, following the original paper [52], we apply temperature sampling with $T=0.5$ and truncated at the top- $k(k=40)$ tokens with the highest probability for diverse generation. All GPT2-based models</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Table 4: Training set size, average number of tokens in the input, intermediate, and output texts respectively when using Plaid tokenizer on the validation set and average number of rationales.</p>
<table>
<thead>
<tr>
<th>Dataset</th>
<th>Size</th>
<th>#Input token</th>
<th>#Intermediate token</th>
<th>#Output token</th>
<th>#Rationales</th>
</tr>
</thead>
<tbody>
<tr>
<td>4x4</td>
<td>808k</td>
<td>16</td>
<td>84</td>
<td>15</td>
<td>4</td>
</tr>
<tr>
<td>5x5</td>
<td>808k</td>
<td>20</td>
<td>137</td>
<td>19</td>
<td>5</td>
</tr>
<tr>
<td>Boolean logic</td>
<td>99k</td>
<td>112</td>
<td>134</td>
<td>3</td>
<td>10</td>
</tr>
<tr>
<td>GSM8K-Aug</td>
<td>378k</td>
<td>61</td>
<td>34</td>
<td>2</td>
<td>2.7</td>
</tr>
</tbody>
</table>
<p>use GPT2Tokenizer with vocabulary size of 50257. All datasets are trained using sequence length of 256 except boolean logic, which uses 384 length.</p>
<p>Note in Table 1, we compare Plaid DoT with the fine-tuned GPT2 small, given that the Plaid 1B [18] model exhibits similar perplexity to GPT2 small. This might put our Plaid DoT model at a disadvantage in terms of inference speed, as the parameters of Plaid 1B are nearly $10 \times$ greater than those of GPT2 small.</p>
<p>For Transformer-scratch baseline [51], we use 6 transformer encoder layers and 6 transformer decoder layers. We employ the tokenizer from bert-base-uncased with a vocabulary size of 30522. The learning rate is set to $1 \mathrm{e}-5$, and we train for 60 k steps with a batch size of 128 .
For ChatGPT, we use OpenAI api ${ }^{8}$ with the following prompt in 5 -shot.</p>
<p>Answer the final question following the format of the given examples.</p>
<p>Example problems:
Q: {query}
A: {answer}
...
Question to answer:
Q:
Table 5: Prompt for ChatGPT.</p>
<p>Please note that the throughput of ChatGPT in Table 1 only measures the response speed of ChatGPT and does not represent the actual generation speed of the model. As a blackbox commercial product, ChatGPT may employ various optimization techniques to speedup generating responses to enhance user experiences.</p>
<h1>B. 3 DoT Implementation Details</h1>
<p>We conduct all the experiments on NVIDIA V100-32G GPUs, and we use 8 GPUs for training and sampling. We resort to half precision (fp16) instead of bfloat16 (bf16) as V100 GPU doesn't support bf16, and we don't observe any number explosion. By default, we train DoT from scratch on three datasets respectively, including the four-digit $(4 \times 4)$, five-digit $(5 \times 5)$ multiplication datasets, and the GSM8k dataset. Additionally, we fine-tune the pre-trained model Plaid-1B on the GSM8K dataset with DoT to explore its effectiveness further.
For DoT trained from scratch. We use 12 layers of transformer and bert-base-uncased vocabulary. We preprocess the four-digit $(4 \times 4)$ and five-digit $(5 \times 5)$ multiplication datasets to prepare for the training process of the DoT multi-path variant, and sampling from it. The learning rate is $1 \mathrm{e}-4$ and we train for 60 k steps with the batch size of 128 and max sequence length of 128 . For digit</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{8}$ https://platform.openai.com/docs/api-reference&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>