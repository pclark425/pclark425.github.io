<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8911 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8911</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8911</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-155.html">extraction-schema-155</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models (LLMs) are used to generate or design novel chemicals for specific applications, including details of the models, methods, applications, results, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-958bb3831589246fe5b6b58cf99e3b65c58d027f</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/958bb3831589246fe5b6b58cf99e3b65c58d027f" target="_blank">Multi-modal molecule structure–text model for text-based retrieval and editing</a></p>
                <p><strong>Paper Venue:</strong> Nature Machine Intelligence</p>
                <p><strong>Paper TL;DR:</strong> MoleculeSTM is trained, a foundation model that aligns the structure and text modalities through contrastive learning, and its utility on the downstream tasks of structure–text retrieval, text-guided editing and molecular property prediction is shown.</p>
                <p><strong>Paper Abstract:</strong> There is increasing adoption of artificial intelligence in drug discovery. However, existing studies use machine learning to mainly utilize the chemical structures of molecules but ignore the vast textual knowledge available in chemistry. Incorporating textual knowledge enables us to realize new drug design objectives, adapt to text-based instructions and predict complex biological activities. Here we present a multi-modal molecule structure–text model, MoleculeSTM, by jointly learning molecules’ chemical structures and textual descriptions via a contrastive learning strategy. To train MoleculeSTM, we construct a large multi-modal dataset, namely, PubChemSTM, with over 280,000 chemical structure–text pairs. To demonstrate the effectiveness and utility of MoleculeSTM, we design two challenging zero-shot tasks based on text instructions, including structure–text retrieval and molecule editing. MoleculeSTM has two main properties: open vocabulary and compositionality via natural language. In experiments, MoleculeSTM obtains the state-of-the-art generalization ability to novel biochemical concepts across various benchmarks. Machine learning methods in cheminformatics have made great progress in using chemical structures of molecules, but a large portion of textual information remains scarcely explored. Liu and colleagues trained MoleculeSTM, a foundation model that aligns the structure and text modalities through contrastive learning, and show its utility on the downstream tasks of structure–text retrieval, text-guided editing and molecular property prediction.</p>
                <p><strong>Cost:</strong> 0.02</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8911.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8911.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models (LLMs) are used to generate or design novel chemicals for specific applications, including details of the models, methods, applications, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MoleculeSTM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Multi-modal Molecule Structure-Text Model (MoleculeSTM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A contrastively pretrained multi-modal foundation model that aligns molecular structural encoders (SMILES transformer or GNN) with a scientific language encoder (SciBERT) in a joint embedding space to enable zero-shot text-based retrieval and text-driven molecule editing.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>MoleculeSTM</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Multi-modal contrastive model (text encoder + chemical structure encoder); uses BERT for text and Transformer/GNN for molecules</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Component sizes reported: SciBERT ~109,918,464 params; MegaMolBART (SMILES encoder) ~10,010,635 params; GIN (graph encoder) ~1,885,206 params</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>PubChemSTM: ~281K structure-text pairs constructed from PubChem 'string' field (250K unique molecules, 281K pairs); encoders initialized from pretrained single-modality checkpoints (MegaMolBART pretrained on ~500M ZINC molecules; GIN from GraphMVP pretraining on GEOM conformations; SciBERT pretrained on Semantic Scholar corpus).</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Drug discovery tasks including text-based lead optimization (single- and multi-objective), drug repurposing (structure-text retrieval), binding-affinity guided editing, and molecular property prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Zero-shot text-based molecule editing via: (1) space alignment — learn adaptor m_g2f to map a pretrained generative model's latent space to MoleculeSTM joint space; (2) latent optimization — optimize a latent code w to maximize cosine similarity to the text embedding and stay close (L2) to the input molecule latent; (3) decode optimized latent with the frozen pretrained molecule generative decoder to produce candidate molecules.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_of_chemicals</strong></td>
                            <td>No explicit measurement reported of fraction novel vs training set; qualitative examples show functional-group changes and scaffold modifications (e.g., edits that transform patented analogs toward approved drugs like Celecoxib, Donepezil). Novelty was not quantified as % not in training data or via similarity thresholds beyond task-specific Tanimoto comparisons for drug-relevance editing.</td>
                        </tr>
                        <tr>
                            <td><strong>application_specificity</strong></td>
                            <td>Text prompts specify desired properties (open-vocabulary, compositional prompts e.g., 'high solubility and high permeability'); optimization objective directly ties generated latent to the text embedding (cosine similarity) and constrains proximity to input molecule (L2), enabling edits tailored to textual descriptions; evaluation uses property-specific proxies or classifiers to verify application-specific improvements.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Satisfactory hit ratio (task-specific threshold Δ) for editing; property proxies: LogP (solubility proxy), QED (drug-likeness), tPSA (permeability proxy), HBA/HBD counts; binding-affinity editing evaluated by a ChEMBL-trained classifier (confidence increase); drug-relevance editing evaluated by Tanimoto similarity; retrieval evaluated by T-choose-one accuracy; molecular property prediction evaluated by ROC-AUC on MoleculeNet tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>MoleculeSTM achieved state-of-the-art zero-shot performance on both tasks reported: up to ~50% absolute higher retrieval accuracy vs baselines on DrugBank retrieval tasks and up to ~40% higher satisfactory hit ratio on 20 text-based editing tasks versus baselines; qualitative edits match chemical intuition (functional-group additions/removals, scaffold replacements); fine-tuning on MoleculeNet yields best-average ROC-AUC among baselines (SMILES encoder avg ROC-AUC ~73.33, graph encoder avg ~74.57 in table).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Directly compared to baselines: Frozen/random encoders, Similarity (single-modality proxy), KV-PLM (SMILES-text pretrained PLM), PCA/High-Variance latent perturbations, and Genetic Search; MoleculeSTM outperforms these across retrieval and editing benchmarks (examples: retrieval accuracy improvements ~50%, 40%, 15% for different datasets and T settings; editing hit ratios higher across 20 tasks).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_and_challenges</strong></td>
                            <td>Authors report data insufficiency (PubChemSTM still small relative to other domains), expressiveness limits of chemical structure models and SMILES-based generative decoders, dependence on quality of pretrained generative model (unnamed) and adaptor alignment, vocabulary/tokenization mismatch (SciBERT vocabulary vs PubChem text) and textual-data licensing issues, lack of explicit wet-lab synthesis validation or explicit novelty quantification of generated molecules; 3D geometry not directly incorporated (potentially important for binding-specific design).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Multi-modal molecule structure–text model for text-based retrieval and editing', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8911.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8911.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models (LLMs) are used to generate or design novel chemicals for specific applications, including details of the models, methods, applications, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>KV-PLM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Knowledgeable and Versatile Pretrained Language Model (KV-PLM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prior SMILES-text pretrained language model that jointly models molecular strings and textual annotations to bridge molecular structure and biomedical text; used here as a baseline for cross-modal retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A deep-learning system bridging molecule structure and biomedical text with comprehension comparable to human professionals</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>KV-PLM</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Pretrained language model (unified language modeling over SMILES and text)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Not specified in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Prior work used aligned SMILES-text pairs constructed by matching synonyms to literature (dataset size reported in prior work ~10K structure-text pairs as noted by this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Molecular-text comprehension and retrieval; bridging molecule structure and biomedical text for tasks such as indication/drug relation extraction and retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Unified language modeling on SMILES and paired text (not described as a generative-design model here); used for zero-shot retrieval/search rather than explicit molecule generation in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_of_chemicals</strong></td>
                            <td>Not applicable/ not reported in this work; KV-PLM used as representation baseline rather than a generator.</td>
                        </tr>
                        <tr>
                            <td><strong>application_specificity</strong></td>
                            <td>Learns joint SMILES-text semantics from aligned pairs; limited to concepts present in its aligned training set and constrained by closed vocabulary of the training corpus.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Used here as a baseline for T-choose-one retrieval accuracy; achieved substantially better retrieval than naive baselines but worse than MoleculeSTM (e.g., KV-PLM retrieval accuracies reported in Tables: ~68-74% on some DrugBank retrieval splits, while MoleculeSTM reached ~88-99% on those tasks depending on encoder).</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>KV-PLM achieves meaningful retrieval performance (much above chance and similarity baselines) but is outperformed by MoleculeSTM on cross-modal retrieval and editing tasks in zero-shot settings.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Compared against MoleculeSTM and simpler baselines (Similarity, Frozen, Random). KV-PLM's limitations relative to MoleculeSTM stem from small aligned training data and a unified-language modeling approach preventing easy reuse of large single-modality pretrained checkpoints.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_and_challenges</strong></td>
                            <td>Prior work used small-scale aligned SMILES-text data (~10K pairs), required aligned data for training, modeled only SMILES (1D) representations, and could not readily leverage larger pretrained single-modal checkpoints; therefore limited in generalization and open-vocabulary compositionality.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Multi-modal molecule structure–text model for text-based retrieval and editing', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8911.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8911.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models (LLMs) are used to generate or design novel chemicals for specific applications, including details of the models, methods, applications, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MegaMolBART</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MegaMolBART (SMILES Transformer encoder used in this work)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A pretrained Transformer-based SMILES encoder (cited as MegaMolBART in the paper) used to provide sequence-based molecular representations for MoleculeSTM; pretrained on a very large SMILES corpus.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>MegaMolBART</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer-based SMILES encoder (pretrained sequence model)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Reported in paper: ~10,010,635 parameters (as encoder component)</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Pretrained on ~500M molecules from the ZINC database (as reported in this paper for the checkpoint used).</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Molecular representation learning for downstream tasks (retrieval, editing, property prediction); used as the chemical-structure encoder branch in MoleculeSTM.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Used as an encoder only in this study; not directly used as a generative decoder here.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_of_chemicals</strong></td>
                            <td>Not applicable in this role (encoder only); novelty of generated molecules depends on downstream generative model.</td>
                        </tr>
                        <tr>
                            <td><strong>application_specificity</strong></td>
                            <td>Provides SMILES-based embeddings that, when aligned with text embeddings via contrastive pretraining, enable text-conditioned retrieval and editing through the MoleculeSTM pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Encoder performance is assessed indirectly via downstream retrieval/editing/property prediction improvements when integrated into MoleculeSTM; MoleculeSTM with SMILES encoder shows improved ROC-AUC on MoleculeNet and strong retrieval/editing performance compared to baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>When initialized from the MegaMolBART checkpoint and further contrastively pretrained in MoleculeSTM, the SMILES-branch yields strong zero-shot retrieval and editing performance and improves fine-tuned property prediction relative to other SMILES baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Compared implicitly to GNN (graph) encoder variants in MoleculeSTM; graph encoder sometimes outperforms SMILES on some retrieval datasets, but both variants beat baseline methods.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_and_challenges</strong></td>
                            <td>As a SMILES-based encoder it may not capture full 3D geometric information; quality of downstream editing depends also on the expressiveness of the paired generative decoder which is external to this encoder.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Multi-modal molecule structure–text model for text-based retrieval and editing', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8911.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8911.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models (LLMs) are used to generate or design novel chemicals for specific applications, including details of the models, methods, applications, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SciBERT (text encoder)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SciBERT: Pretrained Language Model for Scientific Text</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A BERT-family language model pretrained on a large scientific corpus (Semantic Scholar) and adapted here as the textual description encoder to provide open-vocabulary, domain-aware embeddings for molecule descriptions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>SciBERT: Pretrained Language Model for Scientific Text</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>SciBERT</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>BERT-based pretrained language model</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Vocabulary size ~31k (SciBERT's original); parameter count ~109,918,464 reported for the SciBERT component used in this study</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Pretrained on 1.14M papers from Semantic Scholar (broad biomedical and computer science domains) and further adapted on PubChemSTM during MoleculeSTM pretraining.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Provides domain-specific text embeddings to represent biochemical properties, assays, ATC labels, and other textual annotations; used to enable open-vocabulary and compositional text prompts for molecule retrieval and editing.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Used to encode text prompts into embeddings that guide latent optimization for molecule editing (via cosine similarity between text embedding and generated latent-adapted representation); not used as a generative language model to output SMILES directly in this work.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_of_chemicals</strong></td>
                            <td>Not directly applicable — SciBERT supplies semantic guidance; novelty depends on downstream latent optimization and decoder.</td>
                        </tr>
                        <tr>
                            <td><strong>application_specificity</strong></td>
                            <td>Enables specification of arbitrary textual objectives (open vocabulary) and compositional prompts (combine multiple property descriptions) that are converted to embeddings and used to guide molecule editing and retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Indirectly evaluated via downstream retrieval accuracy and editing hit ratios when integrated into MoleculeSTM; tokenization/vocabulary overlap analysis performed (SciBERT tokenizer showed good overlap with PubChemSTM text).</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Using SciBERT as text encoder enables open-vocabulary prompts and compositional text descriptions that materially improve zero-shot retrieval and editing performance when contrastively aligned with molecule encoders.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Offers better domain tokenization and scientific vocabulary coverage than naive tokenizers (whitespace, spaCy) and enabled improved alignment compared to prior small-scale SMILES-text models which used unified language modeling.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_and_challenges</strong></td>
                            <td>Vocabulary shift between SciBERT's semantic scholar training corpus and PubChem text exists (mitigated but not eliminated); tokenization and domain terminology remain a challenge for some specialized fields (e.g., ATC codes); SciBERT is an encoder and does not itself generate SMILES or chemical structures.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Multi-modal molecule structure–text model for text-based retrieval and editing', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8911.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e8911.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models (LLMs) are used to generate or design novel chemicals for specific applications, including details of the models, methods, applications, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Pretrained molecule generative model (unnamed)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Pretrained molecule generative model (encoder f_g and decoder h_g) used for decoding optimized latent codes</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An external pretrained generative model (SMILES-based or other) whose latent space is aligned to MoleculeSTM's joint space; used to decode optimized latent codes back to molecular structures during text-driven editing.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Pretrained molecule generative model (unnamed in paper)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Latent-space molecule generative model (SMILES-based decoder implied); specifics not named in paper</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Not specified</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Not specified in this paper (pretrained generative model assumed available externally); the paper notes SMILES-based generative models are commonly used and are a bottleneck.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Generative decoding for molecule editing tasks (producing chemically valid SMILES/structures from optimized latent codes)</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Decoding from latent space: after latent optimization to satisfy text embedding and proximity constraints, decoder h_g maps latent w to output molecule x_c_out = h_g(w).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_of_chemicals</strong></td>
                            <td>Not quantified in paper; novelty and chemical validity depend on the pretrained generative model's coverage and decoder expressiveness.</td>
                        </tr>
                        <tr>
                            <td><strong>application_specificity</strong></td>
                            <td>Specificity to textual objectives is enforced via alignment (adaptor) and latent optimization; final chemical realizations depend on decoder expressiveness and validity constraints inherent to the pretrained generative model.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Same editing evaluation (satisfactory hit ratio, property proxies, binding classifier, Tanimoto) applied to decoded molecules; chemical validity and synthesizability not reported explicitly.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>The editing pipeline that uses an external pretrained generative decoder produced molecules that satisfy textual property prompts at higher rates than baseline latent-direction and genetic-search baselines; qualitative examples match medicinal chemistry expectations. Paper notes overall performance is influenced by the expressiveness of this generative model.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Authors compare MoleculeSTM editing (which relies on this generative model plus alignment/optimization) to baselines that directly perturb latent codes (Random, PCA, High Variance) or operate on molecule graphs (Genetic Search); MoleculeSTM editing outperformed these baselines on reported tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_and_challenges</strong></td>
                            <td>Generative model is unspecified and identified as a bottleneck: limited expressiveness, SMILES-based decoders may miss 3D or synthetic feasibility aspects; authors note need for more expressive decoders and integration of 3D geometry and synthesizability assessments.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Multi-modal molecule structure–text model for text-based retrieval and editing', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8911.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e8911.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models (LLMs) are used to generate or design novel chemicals for specific applications, including details of the models, methods, applications, results, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GraphMVP (pretraining)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GraphMVP: Multi-view pretraining between 2D topologies and 3D geometries</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A graph pretraining method that aligns 2D molecular graphs with 3D geometry-derived views (used here to initialize a GIN molecular graph encoder that is then incorporated into MoleculeSTM).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Pre-training Molecular Graph Representation with 3D Geometry</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GraphMVP (pretrained GIN checkpoint used)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Graph neural network pretraining (multi-view contrastive between 2D and 3D)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>GIN encoder reported ~1,885,206 parameters in this paper when initialized from GraphMVP-pretrained checkpoint</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>GraphMVP pretraining used ~250K conformations from the GEOM dataset (3D conformations)</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Provides enriched graph-based molecular embeddings that capture implicit 3D geometry for downstream tasks (retrieval, editing, property prediction) when aligned with text embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Used as encoder; not a generative model. Its representations are contrastively aligned with SciBERT embeddings in MoleculeSTM to enable text-guided downstream tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_of_chemicals</strong></td>
                            <td>Not applicable (encoder only).</td>
                        </tr>
                        <tr>
                            <td><strong>application_specificity</strong></td>
                            <td>Graph-derived representations bring implicit 3D-aware information which can help downstream property-sensitive editing and prediction when aligned with textual instructions.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Graph-branch MoleculeSTM variants evaluated on same retrieval/editing/property tasks; graph-branch often yields higher retrieval accuracy on certain datasets (reported in tables).</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Graph-branch MoleculeSTM (GIN initialized from GraphMVP) generally outperformed SMILES-branch on several retrieval tasks and achieved the best average ROC-AUC across MoleculeNet property prediction baselines when combined with contrastive text alignment.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_methods</strong></td>
                            <td>Compared to SMILES-based encoders and other graph pretraining methods (MolCLR, InfoGraph, AttrMasking, ContextPred), GraphMVP-initialized MoleculeSTM performed competitively or better on multiple tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_and_challenges</strong></td>
                            <td>Although GraphMVP brings implicit 3D knowledge, the MoleculeSTM framework still does not explicitly use 3D coordinates in the contrastive pretraining (authors note future work to merge explicit 3D geometry).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Multi-modal molecule structure–text model for text-based retrieval and editing', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Retrieval-based Controllable Molecule Generation <em>(Rating: 2)</em></li>
                <li>A deep-learning system bridging molecule structure and biomedical text with comprehension comparable to human professionals <em>(Rating: 2)</em></li>
                <li>Chemformer: a pre-trained transformer for computational chemistry <em>(Rating: 2)</em></li>
                <li>Hierarchical generation of molecular graphs using structural motifs <em>(Rating: 1)</em></li>
                <li>A graph-based genetic algorithm and generative model/Monte Carlo tree search for the exploration of chemical space <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8911",
    "paper_id": "paper-958bb3831589246fe5b6b58cf99e3b65c58d027f",
    "extraction_schema_id": "extraction-schema-155",
    "extracted_data": [
        {
            "name_short": "MoleculeSTM",
            "name_full": "Multi-modal Molecule Structure-Text Model (MoleculeSTM)",
            "brief_description": "A contrastively pretrained multi-modal foundation model that aligns molecular structural encoders (SMILES transformer or GNN) with a scientific language encoder (SciBERT) in a joint embedding space to enable zero-shot text-based retrieval and text-driven molecule editing.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "MoleculeSTM",
            "model_type": "Multi-modal contrastive model (text encoder + chemical structure encoder); uses BERT for text and Transformer/GNN for molecules",
            "model_size": "Component sizes reported: SciBERT ~109,918,464 params; MegaMolBART (SMILES encoder) ~10,010,635 params; GIN (graph encoder) ~1,885,206 params",
            "training_data": "PubChemSTM: ~281K structure-text pairs constructed from PubChem 'string' field (250K unique molecules, 281K pairs); encoders initialized from pretrained single-modality checkpoints (MegaMolBART pretrained on ~500M ZINC molecules; GIN from GraphMVP pretraining on GEOM conformations; SciBERT pretrained on Semantic Scholar corpus).",
            "application_domain": "Drug discovery tasks including text-based lead optimization (single- and multi-objective), drug repurposing (structure-text retrieval), binding-affinity guided editing, and molecular property prediction.",
            "generation_method": "Zero-shot text-based molecule editing via: (1) space alignment — learn adaptor m_g2f to map a pretrained generative model's latent space to MoleculeSTM joint space; (2) latent optimization — optimize a latent code w to maximize cosine similarity to the text embedding and stay close (L2) to the input molecule latent; (3) decode optimized latent with the frozen pretrained molecule generative decoder to produce candidate molecules.",
            "novelty_of_chemicals": "No explicit measurement reported of fraction novel vs training set; qualitative examples show functional-group changes and scaffold modifications (e.g., edits that transform patented analogs toward approved drugs like Celecoxib, Donepezil). Novelty was not quantified as % not in training data or via similarity thresholds beyond task-specific Tanimoto comparisons for drug-relevance editing.",
            "application_specificity": "Text prompts specify desired properties (open-vocabulary, compositional prompts e.g., 'high solubility and high permeability'); optimization objective directly ties generated latent to the text embedding (cosine similarity) and constrains proximity to input molecule (L2), enabling edits tailored to textual descriptions; evaluation uses property-specific proxies or classifiers to verify application-specific improvements.",
            "evaluation_metrics": "Satisfactory hit ratio (task-specific threshold Δ) for editing; property proxies: LogP (solubility proxy), QED (drug-likeness), tPSA (permeability proxy), HBA/HBD counts; binding-affinity editing evaluated by a ChEMBL-trained classifier (confidence increase); drug-relevance editing evaluated by Tanimoto similarity; retrieval evaluated by T-choose-one accuracy; molecular property prediction evaluated by ROC-AUC on MoleculeNet tasks.",
            "results_summary": "MoleculeSTM achieved state-of-the-art zero-shot performance on both tasks reported: up to ~50% absolute higher retrieval accuracy vs baselines on DrugBank retrieval tasks and up to ~40% higher satisfactory hit ratio on 20 text-based editing tasks versus baselines; qualitative edits match chemical intuition (functional-group additions/removals, scaffold replacements); fine-tuning on MoleculeNet yields best-average ROC-AUC among baselines (SMILES encoder avg ROC-AUC ~73.33, graph encoder avg ~74.57 in table).",
            "comparison_to_other_methods": "Directly compared to baselines: Frozen/random encoders, Similarity (single-modality proxy), KV-PLM (SMILES-text pretrained PLM), PCA/High-Variance latent perturbations, and Genetic Search; MoleculeSTM outperforms these across retrieval and editing benchmarks (examples: retrieval accuracy improvements ~50%, 40%, 15% for different datasets and T settings; editing hit ratios higher across 20 tasks).",
            "limitations_and_challenges": "Authors report data insufficiency (PubChemSTM still small relative to other domains), expressiveness limits of chemical structure models and SMILES-based generative decoders, dependence on quality of pretrained generative model (unnamed) and adaptor alignment, vocabulary/tokenization mismatch (SciBERT vocabulary vs PubChem text) and textual-data licensing issues, lack of explicit wet-lab synthesis validation or explicit novelty quantification of generated molecules; 3D geometry not directly incorporated (potentially important for binding-specific design).",
            "uuid": "e8911.0",
            "source_info": {
                "paper_title": "Multi-modal molecule structure–text model for text-based retrieval and editing",
                "publication_date_yy_mm": "2022-12"
            }
        },
        {
            "name_short": "KV-PLM",
            "name_full": "Knowledgeable and Versatile Pretrained Language Model (KV-PLM)",
            "brief_description": "A prior SMILES-text pretrained language model that jointly models molecular strings and textual annotations to bridge molecular structure and biomedical text; used here as a baseline for cross-modal retrieval.",
            "citation_title": "A deep-learning system bridging molecule structure and biomedical text with comprehension comparable to human professionals",
            "mention_or_use": "use",
            "model_name": "KV-PLM",
            "model_type": "Pretrained language model (unified language modeling over SMILES and text)",
            "model_size": "Not specified in this paper",
            "training_data": "Prior work used aligned SMILES-text pairs constructed by matching synonyms to literature (dataset size reported in prior work ~10K structure-text pairs as noted by this paper).",
            "application_domain": "Molecular-text comprehension and retrieval; bridging molecule structure and biomedical text for tasks such as indication/drug relation extraction and retrieval.",
            "generation_method": "Unified language modeling on SMILES and paired text (not described as a generative-design model here); used for zero-shot retrieval/search rather than explicit molecule generation in this paper.",
            "novelty_of_chemicals": "Not applicable/ not reported in this work; KV-PLM used as representation baseline rather than a generator.",
            "application_specificity": "Learns joint SMILES-text semantics from aligned pairs; limited to concepts present in its aligned training set and constrained by closed vocabulary of the training corpus.",
            "evaluation_metrics": "Used here as a baseline for T-choose-one retrieval accuracy; achieved substantially better retrieval than naive baselines but worse than MoleculeSTM (e.g., KV-PLM retrieval accuracies reported in Tables: ~68-74% on some DrugBank retrieval splits, while MoleculeSTM reached ~88-99% on those tasks depending on encoder).",
            "results_summary": "KV-PLM achieves meaningful retrieval performance (much above chance and similarity baselines) but is outperformed by MoleculeSTM on cross-modal retrieval and editing tasks in zero-shot settings.",
            "comparison_to_other_methods": "Compared against MoleculeSTM and simpler baselines (Similarity, Frozen, Random). KV-PLM's limitations relative to MoleculeSTM stem from small aligned training data and a unified-language modeling approach preventing easy reuse of large single-modality pretrained checkpoints.",
            "limitations_and_challenges": "Prior work used small-scale aligned SMILES-text data (~10K pairs), required aligned data for training, modeled only SMILES (1D) representations, and could not readily leverage larger pretrained single-modal checkpoints; therefore limited in generalization and open-vocabulary compositionality.",
            "uuid": "e8911.1",
            "source_info": {
                "paper_title": "Multi-modal molecule structure–text model for text-based retrieval and editing",
                "publication_date_yy_mm": "2022-12"
            }
        },
        {
            "name_short": "MegaMolBART",
            "name_full": "MegaMolBART (SMILES Transformer encoder used in this work)",
            "brief_description": "A pretrained Transformer-based SMILES encoder (cited as MegaMolBART in the paper) used to provide sequence-based molecular representations for MoleculeSTM; pretrained on a very large SMILES corpus.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "MegaMolBART",
            "model_type": "Transformer-based SMILES encoder (pretrained sequence model)",
            "model_size": "Reported in paper: ~10,010,635 parameters (as encoder component)",
            "training_data": "Pretrained on ~500M molecules from the ZINC database (as reported in this paper for the checkpoint used).",
            "application_domain": "Molecular representation learning for downstream tasks (retrieval, editing, property prediction); used as the chemical-structure encoder branch in MoleculeSTM.",
            "generation_method": "Used as an encoder only in this study; not directly used as a generative decoder here.",
            "novelty_of_chemicals": "Not applicable in this role (encoder only); novelty of generated molecules depends on downstream generative model.",
            "application_specificity": "Provides SMILES-based embeddings that, when aligned with text embeddings via contrastive pretraining, enable text-conditioned retrieval and editing through the MoleculeSTM pipeline.",
            "evaluation_metrics": "Encoder performance is assessed indirectly via downstream retrieval/editing/property prediction improvements when integrated into MoleculeSTM; MoleculeSTM with SMILES encoder shows improved ROC-AUC on MoleculeNet and strong retrieval/editing performance compared to baselines.",
            "results_summary": "When initialized from the MegaMolBART checkpoint and further contrastively pretrained in MoleculeSTM, the SMILES-branch yields strong zero-shot retrieval and editing performance and improves fine-tuned property prediction relative to other SMILES baselines.",
            "comparison_to_other_methods": "Compared implicitly to GNN (graph) encoder variants in MoleculeSTM; graph encoder sometimes outperforms SMILES on some retrieval datasets, but both variants beat baseline methods.",
            "limitations_and_challenges": "As a SMILES-based encoder it may not capture full 3D geometric information; quality of downstream editing depends also on the expressiveness of the paired generative decoder which is external to this encoder.",
            "uuid": "e8911.2",
            "source_info": {
                "paper_title": "Multi-modal molecule structure–text model for text-based retrieval and editing",
                "publication_date_yy_mm": "2022-12"
            }
        },
        {
            "name_short": "SciBERT (text encoder)",
            "name_full": "SciBERT: Pretrained Language Model for Scientific Text",
            "brief_description": "A BERT-family language model pretrained on a large scientific corpus (Semantic Scholar) and adapted here as the textual description encoder to provide open-vocabulary, domain-aware embeddings for molecule descriptions.",
            "citation_title": "SciBERT: Pretrained Language Model for Scientific Text",
            "mention_or_use": "use",
            "model_name": "SciBERT",
            "model_type": "BERT-based pretrained language model",
            "model_size": "Vocabulary size ~31k (SciBERT's original); parameter count ~109,918,464 reported for the SciBERT component used in this study",
            "training_data": "Pretrained on 1.14M papers from Semantic Scholar (broad biomedical and computer science domains) and further adapted on PubChemSTM during MoleculeSTM pretraining.",
            "application_domain": "Provides domain-specific text embeddings to represent biochemical properties, assays, ATC labels, and other textual annotations; used to enable open-vocabulary and compositional text prompts for molecule retrieval and editing.",
            "generation_method": "Used to encode text prompts into embeddings that guide latent optimization for molecule editing (via cosine similarity between text embedding and generated latent-adapted representation); not used as a generative language model to output SMILES directly in this work.",
            "novelty_of_chemicals": "Not directly applicable — SciBERT supplies semantic guidance; novelty depends on downstream latent optimization and decoder.",
            "application_specificity": "Enables specification of arbitrary textual objectives (open vocabulary) and compositional prompts (combine multiple property descriptions) that are converted to embeddings and used to guide molecule editing and retrieval.",
            "evaluation_metrics": "Indirectly evaluated via downstream retrieval accuracy and editing hit ratios when integrated into MoleculeSTM; tokenization/vocabulary overlap analysis performed (SciBERT tokenizer showed good overlap with PubChemSTM text).",
            "results_summary": "Using SciBERT as text encoder enables open-vocabulary prompts and compositional text descriptions that materially improve zero-shot retrieval and editing performance when contrastively aligned with molecule encoders.",
            "comparison_to_other_methods": "Offers better domain tokenization and scientific vocabulary coverage than naive tokenizers (whitespace, spaCy) and enabled improved alignment compared to prior small-scale SMILES-text models which used unified language modeling.",
            "limitations_and_challenges": "Vocabulary shift between SciBERT's semantic scholar training corpus and PubChem text exists (mitigated but not eliminated); tokenization and domain terminology remain a challenge for some specialized fields (e.g., ATC codes); SciBERT is an encoder and does not itself generate SMILES or chemical structures.",
            "uuid": "e8911.3",
            "source_info": {
                "paper_title": "Multi-modal molecule structure–text model for text-based retrieval and editing",
                "publication_date_yy_mm": "2022-12"
            }
        },
        {
            "name_short": "Pretrained molecule generative model (unnamed)",
            "name_full": "Pretrained molecule generative model (encoder f_g and decoder h_g) used for decoding optimized latent codes",
            "brief_description": "An external pretrained generative model (SMILES-based or other) whose latent space is aligned to MoleculeSTM's joint space; used to decode optimized latent codes back to molecular structures during text-driven editing.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Pretrained molecule generative model (unnamed in paper)",
            "model_type": "Latent-space molecule generative model (SMILES-based decoder implied); specifics not named in paper",
            "model_size": "Not specified",
            "training_data": "Not specified in this paper (pretrained generative model assumed available externally); the paper notes SMILES-based generative models are commonly used and are a bottleneck.",
            "application_domain": "Generative decoding for molecule editing tasks (producing chemically valid SMILES/structures from optimized latent codes)",
            "generation_method": "Decoding from latent space: after latent optimization to satisfy text embedding and proximity constraints, decoder h_g maps latent w to output molecule x_c_out = h_g(w).",
            "novelty_of_chemicals": "Not quantified in paper; novelty and chemical validity depend on the pretrained generative model's coverage and decoder expressiveness.",
            "application_specificity": "Specificity to textual objectives is enforced via alignment (adaptor) and latent optimization; final chemical realizations depend on decoder expressiveness and validity constraints inherent to the pretrained generative model.",
            "evaluation_metrics": "Same editing evaluation (satisfactory hit ratio, property proxies, binding classifier, Tanimoto) applied to decoded molecules; chemical validity and synthesizability not reported explicitly.",
            "results_summary": "The editing pipeline that uses an external pretrained generative decoder produced molecules that satisfy textual property prompts at higher rates than baseline latent-direction and genetic-search baselines; qualitative examples match medicinal chemistry expectations. Paper notes overall performance is influenced by the expressiveness of this generative model.",
            "comparison_to_other_methods": "Authors compare MoleculeSTM editing (which relies on this generative model plus alignment/optimization) to baselines that directly perturb latent codes (Random, PCA, High Variance) or operate on molecule graphs (Genetic Search); MoleculeSTM editing outperformed these baselines on reported tasks.",
            "limitations_and_challenges": "Generative model is unspecified and identified as a bottleneck: limited expressiveness, SMILES-based decoders may miss 3D or synthetic feasibility aspects; authors note need for more expressive decoders and integration of 3D geometry and synthesizability assessments.",
            "uuid": "e8911.4",
            "source_info": {
                "paper_title": "Multi-modal molecule structure–text model for text-based retrieval and editing",
                "publication_date_yy_mm": "2022-12"
            }
        },
        {
            "name_short": "GraphMVP (pretraining)",
            "name_full": "GraphMVP: Multi-view pretraining between 2D topologies and 3D geometries",
            "brief_description": "A graph pretraining method that aligns 2D molecular graphs with 3D geometry-derived views (used here to initialize a GIN molecular graph encoder that is then incorporated into MoleculeSTM).",
            "citation_title": "Pre-training Molecular Graph Representation with 3D Geometry",
            "mention_or_use": "use",
            "model_name": "GraphMVP (pretrained GIN checkpoint used)",
            "model_type": "Graph neural network pretraining (multi-view contrastive between 2D and 3D)",
            "model_size": "GIN encoder reported ~1,885,206 parameters in this paper when initialized from GraphMVP-pretrained checkpoint",
            "training_data": "GraphMVP pretraining used ~250K conformations from the GEOM dataset (3D conformations)",
            "application_domain": "Provides enriched graph-based molecular embeddings that capture implicit 3D geometry for downstream tasks (retrieval, editing, property prediction) when aligned with text embeddings.",
            "generation_method": "Used as encoder; not a generative model. Its representations are contrastively aligned with SciBERT embeddings in MoleculeSTM to enable text-guided downstream tasks.",
            "novelty_of_chemicals": "Not applicable (encoder only).",
            "application_specificity": "Graph-derived representations bring implicit 3D-aware information which can help downstream property-sensitive editing and prediction when aligned with textual instructions.",
            "evaluation_metrics": "Graph-branch MoleculeSTM variants evaluated on same retrieval/editing/property tasks; graph-branch often yields higher retrieval accuracy on certain datasets (reported in tables).",
            "results_summary": "Graph-branch MoleculeSTM (GIN initialized from GraphMVP) generally outperformed SMILES-branch on several retrieval tasks and achieved the best average ROC-AUC across MoleculeNet property prediction baselines when combined with contrastive text alignment.",
            "comparison_to_other_methods": "Compared to SMILES-based encoders and other graph pretraining methods (MolCLR, InfoGraph, AttrMasking, ContextPred), GraphMVP-initialized MoleculeSTM performed competitively or better on multiple tasks.",
            "limitations_and_challenges": "Although GraphMVP brings implicit 3D knowledge, the MoleculeSTM framework still does not explicitly use 3D coordinates in the contrastive pretraining (authors note future work to merge explicit 3D geometry).",
            "uuid": "e8911.5",
            "source_info": {
                "paper_title": "Multi-modal molecule structure–text model for text-based retrieval and editing",
                "publication_date_yy_mm": "2022-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Retrieval-based Controllable Molecule Generation",
            "rating": 2
        },
        {
            "paper_title": "A deep-learning system bridging molecule structure and biomedical text with comprehension comparable to human professionals",
            "rating": 2
        },
        {
            "paper_title": "Chemformer: a pre-trained transformer for computational chemistry",
            "rating": 2
        },
        {
            "paper_title": "Hierarchical generation of molecular graphs using structural motifs",
            "rating": 1
        },
        {
            "paper_title": "A graph-based genetic algorithm and generative model/Monte Carlo tree search for the exploration of chemical space",
            "rating": 1
        }
    ],
    "cost": 0.019986999999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Multi-modal Molecule Structure-text Model for Text-based Retrieval and Editing</h1>
<p>Shengchao Liu ${ }^{1,2}$, Weili Nie ${ }^{3}$, Chengpeng Wang ${ }^{4}$, Jiarui Lu ${ }^{1,2}$, Zhuoran Qiao ${ }^{5}$, Ling Liu ${ }^{6}$, Jian Tang ${ }^{<em> 1,7}$, Chaowei Xiao ${ }^{</em> 3,8}$, and Animashree Anandkumar ${ }^{* 3,5}$<br>${ }^{1}$ Mila-Québec Artificial Intelligence Institute, Montréal, QC H2S 3H1, Canada<br>${ }^{2}$ Université de Montréal, Montréal, QC H3T 1J4, Canada<br>${ }^{3}$ NVIDIA Research, Santa Clara, CA 95051, United States<br>${ }^{4}$ University of Illinois Urbana-Champaign, Champaign, IL 61801, United States<br>${ }^{5}$ California Institute of Technology, Pasadena, CA 91125, United States<br>${ }^{6}$ Princeton University, Princeton, NJ 08544, United States<br>${ }^{7}$ HEC Montréal, Montréal, QC H3T 2A7, Canada<br>${ }^{8}$ Arizona State University, Tempe, AZ 85281, United States</p>
<h4>Abstract</h4>
<p>There is increasing adoption of artificial intelligence in drug discovery. However, existing studies use machine learning to mainly utilize the chemical structures of molecules but ignore the vast textual knowledge available in chemistry. Incorporating textual knowledge enables us to realize new drug design objectives, adapt to text-based instructions and predict complex biological activities. Here we present a multi-modal molecule structure-text model, MoleculeSTM, by jointly learning molecules' chemical structures and textual descriptions via a contrastive learning strategy. To train MoleculeSTM, we construct a large multi-modal dataset, namely, PubChemSTM, with over 280,000 chemical structure-text pairs. To demonstrate the effectiveness and utility of MoleculeSTM, we design two challenging zero-shot tasks based on text instructions, including structure-text retrieval and molecule editing. MoleculeSTM has two main properties: open vocabulary and compositionality via natural language. In experiments, MoleculeSTM obtains the state-of-the-art generalization ability to novel biochemical concepts across various benchmarks.</p>
<p>Recent progress in artificial intelligence (AI) promises to be transformative for drug discovery [1]. AI methods have been used to augment and accelerate current computational pipelines [2, 3, 4], including but not limited to virtual screening [5, 6], metabolic property prediction $[7,8,9]$, and targeted chemical structure generation and editing [10, 11, 12, 13].</p>
<p>Existing machine learning (ML) methods mainly focus on modeling the chemical structure of molecules through onedimensional descriptions [14], two-dimensional molecular graphs [7, 15, 8], or three-dimensional geometric structures [16, 17, 18]. They also use supervised signals, e.g., toxicity labels, quantum-mechanical properties, and binding affinity measurements. However, such a supervised setting requires expensive annotations on pre-determined label categories, impeding the application to unseen categories and tasks [19]. To overcome this issue, unsupervised pretraining on large-scale databases [20] has been proposed, with the main advantage being the ability to learn chemical structures without supervised annotation by reconstructing the masked topological [21] or geometric [22] substructures. Compared to the supervised setting, although such pretrained models [21, 22] have proven to be more effective in generalizing to various downstream tasks by fine-tuning on a few labeled examples, it is still an open challenge to generalize unseen categories and tasks without such labeled examples or fine-tuning (i.e., the so-called zero-shot setting [23] in ML). Additionally, existing molecule pretraining methods mostly incorporate only chemical structures, leaving the multi-modal representation less explored.</p>
<p>We have a vast amount of textual data that is human-understandable and easily accessible. This is now being harnessed in large-scale multi-modal models for images and videos [24, 25, 26, 27]. A natural language interface is an intuitive way to enable open vocabulary and description of tasks. Pretrained multi-modal models can generalize well to new categories and tasks, even in the zero-shot setting [24, 25, 26, 27]. They also enable agents to interactively learn to solve new tasks and explore new environments [28, 29]. We believe similar capabilities can also be obtained in molecular models by incorporating the vast textual knowledge available in the literature.</p>
<p>Previous work [30] has attempted to leverage the textual knowledge to learn the molecule representation. However, it only supports modeling with the 1D description (the simplified molecular-input line-entry system or SMILES) and learns the chemical structures and textual descriptions on a small-scale dataset ( 10 K structure-text pairs). Furthermore, it unifies two modalities into a single language modeling framework and requires aligned data, i.e., chemical structure and text for each sample, for training.</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1. Pipeline of pretraining and downstream tasks. (a) MoleculeSTM pretraining with two branches, the chemical structure (green) and textual description (pink). (b) Structure-text retrieval downstream task. (c) Text-based molecule editing downstream task. (d) Molecular property prediction downstream task.</p>
<p>As a result, it cannot adopt existing powerful pretrained models, and the availability of aligned data is extremely limited.
Our approach: We design a multi-modal foundation model for molecular understanding that incorporates both molecular structural information and textual knowledge. We demonstrate zero-shot generalization to new drug design objectives using textbased instructions and to the prediction of new complex biological activities without the need for labeled examples or fine-tuning.</p>
<p>We propose MoleculeSTM, consisting of two branches: the chemical structure branch and the textual description branch, to handle the molecules' internal structures and external domain knowledge, respectively. Such a disentangled design enables MoleculeSTM to be integrated with the powerful existing models trained on each modality separately, i.e., molecular structural models [11, 31] and scientific language models [32]. Given these pretrained models, MoleculeSTM bridges the two branches via a contrastive learning paradigm [31, 33].</p>
<p>To align such two branches with MoleculeSTM, we construct a structure-text dataset called PubChemSTM from PubChem [34], which is the largest multi-modal dataset to date in the community ( $28 \times$ larger than the existing dataset [30]). In PubChemSTM, each chemical structure is paired with a textual description, illustrating the chemical and physical properties or high-level bioactivities accordingly. Since MoleculeSTM is trained on a large-scale structure-text pair dataset and such textual data contains open-ended chemical information, it can be generalized to diverse downstream tasks in a zero-shot manner.</p>
<p>To demonstrate the advantages of introducing the language modality, we design two challenging downstream tasks: the structure-text retrieval task and text-based molecule editing task, and we apply the pretrained MoleculeSTM on them in a zero-shot manner. By studying these tasks, we summarize two main attributes of MoleculeSTM: the open vocabulary and compositionality. (1) Open vocabulary means our proposed MoleculeSTM is not limited to a fixed set of pre-defined molecule-related textual descriptions and can support exploring a wide range of biochemical concepts with the unbound vocabulary depicted</p>
<p>by the natural language. In the drug discovery pipeline, such an attribute can be used for the text-based molecule editing in the lead optimization task and the novel disease-drug relation extraction in the drug re-purposing task. (2) Compositionality implies that we can express a complex concept by decomposing it into several simple concepts. This can be applied for the text-based multi-objective lead optimization task [35] where the goal is to generate molecules satisfying multiple properties simultaneously.</p>
<p>Empirically, MoleculeSTM reaches the best performance on six zero-shot retrieval tasks (up to $50 \%$ higher accuracy) and 20 zero-shot text-based editing tasks (up to $40 \%$ higher hit ratio) compared to the state-of-the-art methods. Furthermore, for molecular editing tasks, visual inspections reveal that MoleculeSTM can successfully detect critical structures implied in text descriptions. Additionally, we also explore whether MoleculeSTM can improve the performance on the standard molecular property prediction benchmark [9] via fine-tuning. Our results show that MoleculeSTM can achieve the best overall performance among nine baselines on eight property prediction tasks.</p>
<h1>Results</h1>
<h2>Overview and Preliminaries</h2>
<p>In this section, we first provide an overview of MoleculeSTM. Then, we introduce how to pretrain MoleculeSTM and apply the pretrained MoleculeSTM to three types of downstream tasks (Figure 1).</p>
<p>Overview. MoleculeSTM consists of two branches: the chemical structure branch and the textual description branch ( $\boldsymbol{x}<em t="t">{c}$ and $\boldsymbol{x}</em>$.}$ ). The chemical structure branch illustrates the arrangement of atoms in a molecule. We consider two types of encoders $f_{c}$ : Transformer [36] on the SMILES string and GNNs [7, 8, 15] on the 2D molecular graph. The textual description branch provides a high-level description of the molecule's functionality, and we use the language model from a recent work [37] as the encoder $f_{t</p>
<p>Pretraining. Within this design, MoleculeSTM aims to map the representations extracted from two branches to a joint space using two projectors ( $p_{c}$ and $p_{t}$ ) via contrastive learning [31, 33]. The essential idea of contrastive learning is to reduce the representation distance between the chemical structure and textual description pairs of the same molecule and increase the representation distance between the pairs from different molecules. Specifically, we initialize these two branch encoders with the pretrained single-modal checkpoints [11, 31, 32] and then perform an end-to-end contrastive pretraining on collected dataset PubChemSTM. Specifically for PubChemSTM, it is constructed from PubChem [34]. We extract molecules with the textual description fields, leading to 281 K chemical structure and text pairs. More details can be found in Supplementary A.1.</p>
<h2>Two Principles for Downstream Task Design</h2>
<p>We want to emphasize that for these downstream tasks, the language model in the pretrained MoleculeSTM reveals certain appealing attributes for molecule modeling and drug discovery. We summarize the two key points below.</p>
<p>Open vocabulary. Language is by nature open vocabulary and free form [38]. The large language model has proven its generalization ability in various art-related applications [24, 25, 26], and we find that it can also provide promising and insightful observations for drug discovery tasks. In this vein, our method is not limited to a fixed set of pre-defined molecule-related annotations but can support the exploration of novel biochemical concepts with unbound vocabulary. One example is the drug re-purposing. Suppose we have a textual description for a new disease or protein target functionality. In that case, we can obtain its similarity with all the existing drugs using MoleculeSTM and retrieve the drugs with the highest rankings, which can be adopted for the later stages, such as clinical trials. Another example is text-based lead optimization. We use natural language to depict an entirely new property, which can be reflected in the generated molecules after the optimization.</p>
<p>Compositionality. Another attribute is compositionality. In natural language, a complex concept can be expressed by decomposing it into simple concepts. This is crucial for certain domain-specific tasks, e.g., multi-objective lead optimization [35] where we need to generate molecules with multiple desired properties simultaneously. Existing solutions are either (1) learning one classifier for each desired property and doing filtering on a large candidate pool [10] or (2) optimizing a retrieval database to modify molecules to achieve the multi-objective goal [12]. The main limitation is that the success ratio highly depends on the availability of the labeled data for training the classifier or the retrieval database. While with the language model in MoleculeSTM, we provide an alternative solution. We first craft a natural text, called the text prompt, as the task description. The text prompt can be multi-objective and consists of the description for each property (e.g., "molecule is soluble in water and has high permeability"). With the pretrained joint space between chemical structures and textual descriptions, MoleculeSTM can transform the molecule property compositionality problem into the language compositionality problem, which is more tractable using the language model.</p>
<h2>Downstream: Zero-shot Structure-text Retrieval</h2>
<p>Experiments. For the zero-shot retrieval, we construct three datasets from DrugBank [39]. DrugBank is by far the most comprehensive database for drug-like molecules. Here we extract three fields in DrugBank: the description field, the pharmacodynamics field, and the anatomical therapeutic chemical (ATC) field. These fields illustrate the chemical properties and drug effects on the target organism. Then the retrieval task can be viewed as a $T$-choose-one multiple-choice problem, where</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2. Results for zero-shot structure-text retrieval. (a) Accuracy for zero-shot structure-text retrieval on three DrugBank datasets. (b) Four case studies on DrugBank-ATC retrieval. HMG-CoA is $\beta$-Hydroxy $\beta$-methylglutaryl-CoA.
$T$ is the number of choices. Specifically, we have two settings: (1) given chemical structure to retrieve the textual description and (2) given the textual description to retrieve the chemical structure. The retrieval accuracy is used as the evaluation metric.</p>
<p>Baselines. We first consider two baselines with the pretrained single-modal encoders [11, 31, 32]. (1) Frozen is that we take the pretrained encoders for the two branches and two randomly initialized projectors. (2) Similarity is that we take the similarity from a single branch only. For example, in the first setting, when given chemical structure, we retrieve the most similar chemical structure from PubChemSTM, then we take the corresponding paired text representation in PubChemSTM as the proxy representation. Based on this, we can calculate the similarity score between the proxy representation and $T$ requested text representations. (3) We further consider the third baseline, a pretrained language model for knowledgeable and versatile machine reading (KV-PLM) [30] on SMILES-text pairs.</p>
<p>Results. The zero-shot retrieval results are shown in Figure 2 (a). First, we observe that all the algorithms' accuracies are quite similar between the two settings. Then, as expected, we observe that the baseline Frozen performs no better than the random guess because of the randomly-initialized projectors. The Similarity baseline is better than the chance performance by a modest margin, verifying that the pretrained single-modality does learn semantic information but cannot generalize well between modalities. KV-PLM, on the other hand, learns semantically meaningful information from SMILES-text pairs, and thus, it achieves much higher accuracies on three datasets. For MoleculeSTM, the graph representation from GNNs has higher accuracy on Description and Pharmacodynamics than the SMILES representation from the transformer model; yet, both of them outperform all the other methods on three datasets and two settings by a large margin. For example, the accuracy improvements are around $50 \%, 40 \%$, and $15 \%$ compared to the best baseline with $T=20$. Such large improvement gaps verify</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3. Pipelines for the zero-shot text-based molecule editing. (a) The space alignment step aligns the representation space of a pretrained molecule generation model and the representation space of MoleculeSTM. (b) The latent optimization step learns a latent representation that can be similar to both input molecules and textual descriptions.
that MoleculeSTM can play a better role in understanding and bridging the two modalities of molecules.
Case study on drug re-purposing analysis. In Figure 2 (b), we further show four case studies on the retrieval quality of ATC. Specifically, given the molecule's chemical structure, we take 10 (out of 600) most similar ATC labels. It is observed that MoleculeSTM can retrieve the ground-truth ATC labels with high rankings.</p>
<h1>Downstream: Zero-shot Text-based Molecule Editing</h1>
<p>Experiments. For molecule editing, we randomly sample 200 molecules from ZINC [20] and a text prompt as the inputs. Four categories of text prompts have been covered: (1) Single-objective editing is the text prompt using the single drug-related property for editing, such as "molecule with high solubility" and "molecule more like a drug". (2) Multi-objective (compositionality) editing is the text prompt applying multiple properties simultaneously, such as "molecule with high solubility and high permeability". (3) Binding-affinity-based editing is the text prompt for assay description, where each assay corresponds to one binding affinity task. A concrete example is ChEMBL 1613777 [40] with prompt as "This molecule is tested positive in an assay that are inhibitors and substrates of an enzyme protein. It uses molecular oxygen inserting one oxygen atom into a substrate, and reducing the second into a water molecule.". The output molecules should possess higher binding affinity scores. (4) Drug relevance editing is the text prompt to make molecules structurally similar to certain common drugs, e.g., "this molecule looks like Penicillin". We expect the output molecules to be more similar to the target drug than the input drug. For more detailed descriptions of the text prompts, please check Supplementary D. The evaluation is the satisfactory hit ratio, and it is a hit if the metric difference between output and input is over threshold $\Delta$. The $\Delta$ value is task-specific, and we consider two typical cases: $\Delta=0$ indicates a loose condition, and $\Delta&gt;0$ is a strict condition with a larger positive influence. We provide the algorithm pipeline in Figure 3, and more details can be found in the Methods Section.</p>
<p>Baselines. We consider four baselines. The first three baselines [13] modify the representation of input molecules, followed by the decoding to the molecule space. Random is that we take a random noise as the perturbation to the representation of input molecules. $P C A$ is that we take the eigenvectors as latent directions, where the eigenvectors are obtained after decomposing the latent representation of input molecules using principle component analysis (PCA). High Variance is that we take the latent representation dimension with the highest variance and apply the one-hot encoding on it as a semantic direction for editing. In addition, we also consider a baseline directly modifying the molecule space, the genetic search (GS). It is a variant of graph genetic algorithm [41], while the difference is that GS does a random search instead of a guided search by a reward function since no retrieval database is available in the zero-shot setting.</p>
<p>Results. First, we provide the quantitative results for 20 editing tasks across four editing task types in Figure 4. The empirical results illustrate that the satisfactory hit ratios of MoleculeSTM are the best among all 20 tasks. It verifies that, for both SMILES and molecular graph encoders, MoleculeSTM enables a better semantic understanding of the natural language to explore output molecules with the desired properties. Next, we scrutinize the quality of output molecules in Figure 5 with detailed analysis as follows.</p>
<p>Visual analysis on single-objective molecule editing. We visually analyze the difference between input and output molecules using the single-objective property. Typical modifications are the addition, removal, and replacement of functional groups or cores of the molecules. For example, Figure 5 (a) and (b) show two different edits on the same molecule leading</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4. Visualization results for the zero-shot text-based molecule editing. Satisfactory hit ratios (\%) of four types text-based editing tasks: eight single-objective, four multi-objective, four ChEMBL binding-affinity-based editing tasks (pretrained random forest as an evaluator, and detailed text prompts are in Supplementary D), and four drug relevance editing tasks. The satisfactory threshold $(\Delta)$ is 0 for all visualized results. Each task runs for three random seeds, and the length of each error bar represents the standard deviation.
to opposite directions in solubility change depending on the text prompt. Replacement of pyridine to a pyrazine core improves the solubility, while insertion of a benzene linkage yields an insoluble molecule. In Figure 5 (c) and (d), changing an amide linkage to an alkyl amine and an urea results in higher and lower permeability of the edited molecules, respectively. Finally, Figure 5 (e) and (f) add a butyl ether and a primary amine to the exact position of the molecule, bringing more hydrogen bond acceptors and donors, respectively.</p>
<p>Visual analysis on multi-objective molecule editing. We further analyze the multi-objective (compositional) property editing. Water solubility improvement and permeability reduction are consistent when introducing polar groups to the molecule and removing lipophilic hydrocarbons, such as an amide or primary amine replacing a methyl or phenyl in Figure 5 (g). However, higher solubility and permeability are achievable if polar functionalities are removed or reduced in number together with hydrophobic components. For example, in Figure 5 (h), an amide and a benzene linkage are both removed in the left case, and a [1,2]oxazolo[5,4-b]pyridine substituent is replaced by a water-soluble imidazole with a smaller polar surface in the right case.</p>
<p>Case studies on neighborhood searching for patent drug molecules. In drug discovery, improvement of drug-like properties of lead molecules is crucial for finding drug candidates [35]. Herein we demonstrate two examples of generating approved drugs from their patented analogs by addressing their property deficiencies based on text prompts. Figure 5 (i) generates Celecoxib from its amino-substituted derivative [42], where the removal of the amino group yields a greater intestinal permeability of the molecule leading to higher bioavailability [43]. In Figure 5 (j), the trimethoxy benzene moiety, an electronrich arene known to undergo oxidative phase I metabolisms [44], is replaced by a dimethoxy arene in Donepezil by calling for a metabolically stable molecule.</p>
<p>In summary, we conduct rich experiments on four types and 20 text-based molecule editing tasks, where the satisfactory</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5. Visual analysis on text-based molecule editing. Case studies for solubility editing (a,b), permeability editing (c,d), acceptor and donor editing (e,f), solubility and permeability editing ( $\mathrm{g}, \mathrm{h}$ ), and neighborhood searching for patent data (i,j). The pink and blue regions mark the functional groups before and after the editing, and we list the chemical abstracts service (CAS) registry number. (k) visualizes binding-affinity-based editing, and the dashed red lines mark the potential bindings.
hit ratios of MoleculeSTM are superior to baseline methods. Moreover, our editing results can match the expected outcomes based on chemistry domain knowledge. Both quantitative and qualitative results illustrate that MoleculeSTM can learn semantically meaningful information useful for domain applications, which encourages us to explore more challenging tasks with MoleculeSTM in the future.</p>
<h1>Downstream: Molecular Property Prediction</h1>
<p>Experiments. One advantage for MoleculeSTM is that the pretrained chemical structure representation shares information with the external domain knowledge, and such implicit bias can be beneficial for the property prediction tasks. Similar to previous works on molecule pretraining [21, 31], we adopt the MoleculeNet benchmark [9]. It contains eight single-modal binary classification datasets to evaluate the expressiveness of the pretrained molecule representation methods. The evaluation</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">method</th>
<th style="text-align: center;">BBBP $\uparrow$</th>
<th style="text-align: center;">Tox21 $\uparrow$</th>
<th style="text-align: center;">ToxCast $\uparrow$</th>
<th style="text-align: center;">Sider $\uparrow$</th>
<th style="text-align: center;">ClinTox $\uparrow$</th>
<th style="text-align: center;">MUV $\uparrow$</th>
<th style="text-align: center;">HIV $\uparrow$</th>
<th style="text-align: center;">Bace $\uparrow$</th>
<th style="text-align: center;">Avg $\uparrow$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">SMILES</td>
<td style="text-align: center;">- (random initialized)</td>
<td style="text-align: center;">$66.54 \pm 0.95$</td>
<td style="text-align: center;">$71.18 \pm 0.67$</td>
<td style="text-align: center;">$61.16 \pm 1.15$</td>
<td style="text-align: center;">$58.31 \pm 0.78$</td>
<td style="text-align: center;">$88.11 \pm 0.70$</td>
<td style="text-align: center;">$62.74 \pm 1.57$</td>
<td style="text-align: center;">$70.32 \pm 1.51$</td>
<td style="text-align: center;">$80.02 \pm 1.66$</td>
<td style="text-align: center;">69.80</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">MegaMolBART</td>
<td style="text-align: center;">$68.89 \pm 0.17$</td>
<td style="text-align: center;">$73.89 \pm 0.67$</td>
<td style="text-align: center;">$63.32 \pm 0.79$</td>
<td style="text-align: center;">$59.52 \pm 1.79$</td>
<td style="text-align: center;">$78.12 \pm 4.62$</td>
<td style="text-align: center;">$61.51 \pm 2.75$</td>
<td style="text-align: center;">$71.04 \pm 1.70$</td>
<td style="text-align: center;">$82.46 \pm 0.84$</td>
<td style="text-align: center;">69.84</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">KV-PLM</td>
<td style="text-align: center;">$70.50 \pm 0.54$</td>
<td style="text-align: center;">$72.12 \pm 1.02$</td>
<td style="text-align: center;">$55.03 \pm 1.65$</td>
<td style="text-align: center;">$59.83 \pm 0.56$</td>
<td style="text-align: center;">$89.17 \pm 2.73$</td>
<td style="text-align: center;">$54.63 \pm 4.81$</td>
<td style="text-align: center;">$65.40 \pm 1.69$</td>
<td style="text-align: center;">$78.50 \pm 2.73$</td>
<td style="text-align: center;">68.15</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">MoleculeSTM</td>
<td style="text-align: center;">$70.75 \pm 1.90$</td>
<td style="text-align: center;">$75.71 \pm 0.89$</td>
<td style="text-align: center;">$65.17 \pm 0.37$</td>
<td style="text-align: center;">$63.70 \pm 0.81$</td>
<td style="text-align: center;">$86.60 \pm 2.28$</td>
<td style="text-align: center;">$65.69 \pm 1.46$</td>
<td style="text-align: center;">$77.02 \pm 0.44$</td>
<td style="text-align: center;">$81.99 \pm 0.41$</td>
<td style="text-align: center;">73.33</td>
</tr>
<tr>
<td style="text-align: center;">Graph</td>
<td style="text-align: center;">- (random initialized)</td>
<td style="text-align: center;">$63.90 \pm 2.25$</td>
<td style="text-align: center;">$75.06 \pm 0.24$</td>
<td style="text-align: center;">$64.64 \pm 0.76$</td>
<td style="text-align: center;">$56.63 \pm 2.26$</td>
<td style="text-align: center;">$79.86 \pm 7.23$</td>
<td style="text-align: center;">$70.43 \pm 1.83$</td>
<td style="text-align: center;">$76.23 \pm 0.80$</td>
<td style="text-align: center;">$73.14 \pm 5.28$</td>
<td style="text-align: center;">69.99</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">AttrMask</td>
<td style="text-align: center;">$67.79 \pm 2.60$</td>
<td style="text-align: center;">$75.00 \pm 0.20$</td>
<td style="text-align: center;">$63.57 \pm 0.81$</td>
<td style="text-align: center;">$58.05 \pm 1.17$</td>
<td style="text-align: center;">$75.44 \pm 8.75$</td>
<td style="text-align: center;">$73.76 \pm 1.22$</td>
<td style="text-align: center;">$75.44 \pm 0.45$</td>
<td style="text-align: center;">$80.28 \pm 0.04$</td>
<td style="text-align: center;">71.17</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">ContextPred</td>
<td style="text-align: center;">$63.13 \pm 3.48$</td>
<td style="text-align: center;">$74.29 \pm 0.23$</td>
<td style="text-align: center;">$61.58 \pm 0.50$</td>
<td style="text-align: center;">$60.26 \pm 0.77$</td>
<td style="text-align: center;">$80.34 \pm 3.79$</td>
<td style="text-align: center;">$71.36 \pm 1.44$</td>
<td style="text-align: center;">$70.67 \pm 3.56$</td>
<td style="text-align: center;">$78.75 \pm 0.35$</td>
<td style="text-align: center;">70.05</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">InfoGraph</td>
<td style="text-align: center;">$64.84 \pm 0.55$</td>
<td style="text-align: center;">$76.24 \pm 0.37$</td>
<td style="text-align: center;">$62.68 \pm 0.65$</td>
<td style="text-align: center;">$59.15 \pm 0.63$</td>
<td style="text-align: center;">$76.51 \pm 7.83$</td>
<td style="text-align: center;">$72.97 \pm 3.61$</td>
<td style="text-align: center;">$70.20 \pm 2.41$</td>
<td style="text-align: center;">$77.64 \pm 2.04$</td>
<td style="text-align: center;">70.03</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">MolCLR</td>
<td style="text-align: center;">$67.79 \pm 0.52$</td>
<td style="text-align: center;">$75.55 \pm 0.43$</td>
<td style="text-align: center;">$64.58 \pm 0.07$</td>
<td style="text-align: center;">$58.66 \pm 0.12$</td>
<td style="text-align: center;">$84.22 \pm 1.47$</td>
<td style="text-align: center;">$72.76 \pm 0.73$</td>
<td style="text-align: center;">$75.88 \pm 0.24$</td>
<td style="text-align: center;">$71.14 \pm 1.21$</td>
<td style="text-align: center;">71.32</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">GraphMVP</td>
<td style="text-align: center;">$68.11 \pm 1.36$</td>
<td style="text-align: center;">$77.06 \pm 0.35$</td>
<td style="text-align: center;">$65.11 \pm 0.27$</td>
<td style="text-align: center;">$60.64 \pm 0.13$</td>
<td style="text-align: center;">$84.46 \pm 3.10$</td>
<td style="text-align: center;">$74.38 \pm 2.00$</td>
<td style="text-align: center;">$77.74 \pm 2.51$</td>
<td style="text-align: center;">$80.48 \pm 2.68$</td>
<td style="text-align: center;">73.50</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">MoleculeSTM</td>
<td style="text-align: center;">$69.98 \pm 0.52$</td>
<td style="text-align: center;">$76.91 \pm 0.51$</td>
<td style="text-align: center;">$65.05 \pm 0.39$</td>
<td style="text-align: center;">$60.96 \pm 1.05$</td>
<td style="text-align: center;">$92.53 \pm 1.07$</td>
<td style="text-align: center;">$73.40 \pm 2.90$</td>
<td style="text-align: center;">$76.93 \pm 1.84$</td>
<td style="text-align: center;">$80.77 \pm 1.34$</td>
<td style="text-align: center;">74.57</td>
</tr>
</tbody>
</table>
<p>Table 1. Results on eight MoleculeNet binary classification tasks. Mean and standard deviation of test ROC-AUC on three random seeds are reported.
metric is the area under the receiver operating characteristic curve (ROC-AUC) [45].
Baselines. We consider two types of chemical structures, the SMILES string and the molecular graph. For the SMILES string, we take three baselines: the randomly initialized models and two pretrained language models (MegaMolBART [11] and $K V$-PLM [30]). For the molecular graph, in addition to the random initialization, we consider five pretraining-based methods as baselines: AttrMasking [21], ContextPred [21], InfoGraph [46], MolCLR [47], and GraphMVP [8].</p>
<p>Results. As shown in Table 1, we first observe that pretraining-based methods improve the overall classification accuracy compared to the randomly-initialized ones. MoleculeSTM on the SMILES string has consistent improvements on six out of eight tasks compared to the three baselines. MoleculeSTM on the molecular graph performs the best on four out of eight tasks, while it performs comparably to the best baselines in other four tasks. In both cases, the overall performances (i.e., taking an average across all eight tasks) of MoleculeSTM are the best among all the methods.</p>
<h1>Discussion</h1>
<p>In this work, we have presented a multi-modal model, MoleculeSTM, to illustrate the effectiveness of incorporating textual descriptions for molecule representation learning. On two newly proposed zero-shot tasks and one standard property prediction benchmark, we confirmed consistently improved performance of MoleculeSTM compared to the existing methods. Additionally, we observed that MoleculeSTM can retrieve novel drug-target relations and successfully modify molecule substructures to gain the desired properties. These functionalities may accelerate various downstream drug discovery practices, such as re-purposing and multi-objective lead optimization. Furthermore, the outcomes of such downstream tasks have been found to be consistent with the feedback from chemistry experts, reflecting the domain knowledge exploration ability of MoleculeSTM.</p>
<p>One limitation of this work is data insufficiency. Although PubChemSTM is $28 \times$ larger than the dataset used in existing works, it can be further improved and may require support from the entire community in the future. The second bottleneck of this work is the expressiveness of chemical structure models, including the SMILES encoder, the GNN encoder, and the SMILES-based molecule generative model. The development of more expressive architectures is perpendicular to this work and can be feasibly adapted to our multi-modal pretraining framework.</p>
<p>For future directions, we would like to extend MoleculeSTM from cheminformatics to bioinformatics tasks with richer textual information. This enables us to consider structure-based drug design problems such as protein-ligand binding and fragment design. Besides, the 3D geometric information has become more important for small molecules and polymers and can thus be merged into our foundation model. Last but not least, the tokenization of the textual description may require extra effort. Certain tasks possess rich terminologies (e.g., the ATC codes in DrugBank-ATC), and the overall performance is affected accordingly. Such fundamental problems should be handled carefully.</p>
<h2>Methods</h2>
<p>This section briefly describes certain modules in both pretraining and downstream tasks. Detailed specifications, such as dataset construction, model architectures, and hyperparameters, can be found in Supplementary A.</p>
<h2>MoleculeSTM Pretraining</h2>
<p>Dataset construction. For the structure-text pretraining, we consider the PubChem database [34] as the data source. PubChem includes 112 M molecules, which is one of the largest public databases for molecules. The PubChem database has many fields, and previous work [30] uses the synonym field to match with an academic paper corpus [48], resulting in a dataset with 10 K structure-text pairs. Meanwhile, the PubChem database has another field called "string" with more comprehensive and versatile</p>
<p>molecule annotations. We utilize this field to construct a large-scale dataset called PubChemSTM, consisting of 250 K molecules and 281 K structure-text pairs.</p>
<p>In addition, even though PubChemSTM is the largest dataset with textual descriptions, its dataset size is comparatively small compared to the peers from other domains (e.g., 400 M in the vision-language domain [24]). To mitigate such a data insufficiency issue, we adopt the pretrained models from existing checkpoints and then conduct the end-to-end pretraining, as will be discussed next.</p>
<p>Chemical structure branch $f_{c}$. This work considers two types of chemical structures: the SMILES string views the molecule as a sequence, and the 2D molecular graph takes the atoms and bonds as the nodes and edges, respectively. Then, based on the chemical structures, we apply a deep learning encoder $f_{c}$ to get a latent vector as molecule representation. Specifically, for the SMILES string, we take the encoder from MegaMolBART [11], which is pretrained on 500M molecules from ZINC database [49]. For the molecular graph, we take a pretrained graph isomorphism network (GIN) [15] using GraphMVP pretraining [31]. GraphMVP is doing a multi-view pretraining between the 2D topologies and 3D geometries on 250K conformations from GEOM dataset [50]. Thus, though we are not explicitly utilizing the 3D geometries, the state-of-the-art pretrained GIN models can implicitly encode such information.</p>
<p>Textual description branch $f_{t}$. The textual description branch provides a high-level description of the molecule's functionality. We can view this branch as domain knowledge to strengthen the molecule representation. Such domain knowledge is in the form of natural language, and we use the BERT model [37] as the text encoder $f_{t}$. We further adapt the pretrained SciBERT [32], which was pretrained on the textual data from the chemical and biological domain.</p>
<p>Contrastive pretraining. For the MoleculeSTM pretraining, we adopt the contrastive learning strategy, e.g., EBMNCE [31] and InfoNCE [33]. EBM-NCE and InfoNCE align the structure-text pairs for the same molecule and contrast the pairs for different molecules simultaneously. We consider the selection of contrastive pretraining methods as one important hyperparameter. The objectives for EBM-NCE and InfoNCE are</p>
<p>$$
\begin{aligned}
\mathscr{L}<em _boldsymbol_x="\boldsymbol{x">{\text {EBM-NCE }}= &amp; -\frac{1}{2}\left(\mathbb{E}</em><em t="t">{c}, \boldsymbol{x}</em>}}\left[\log \sigma\left(E\left(\boldsymbol{x<em t="t">{c}, \boldsymbol{x}</em>}\right)\right]+\mathbb{E<em c="c">{\boldsymbol{x}</em>}, \boldsymbol{x<em c="c">{t}^{\prime}}\left[\log \left(1-\sigma\left(E\left(\boldsymbol{x}</em>}, \boldsymbol{x<em _boldsymbol_x="\boldsymbol{x">{t}^{\prime}\right)\right)\right]\right)+\mathbb{E}</em><em t="t">{c}, \boldsymbol{x}</em>}}\left[\log \sigma\left(E\left(\boldsymbol{x<em t="t">{c}, \boldsymbol{x}</em>}\right)\right]+\mathbb{E<em c="c">{\boldsymbol{x}</em>}^{\prime}, \boldsymbol{x<em c="c">{t}}\left[\log \left(1-\sigma\left(E\left(\boldsymbol{x}</em>}^{\prime}, \boldsymbol{x<em _InfoNCE="{InfoNCE" _text="\text">{t}\right)\right)\right]\right)\right. \
\mathscr{L}</em>}}= &amp; -\frac{1}{2} \mathbb{E<em t="t">{\boldsymbol{x}</em>}, \boldsymbol{x<em c="c">{t}}\left[\log \frac{\exp \left(E\left(\boldsymbol{x}</em>}, \boldsymbol{x<em c="c">{t}\right)\right)}{\exp \left(E\left(\boldsymbol{x}</em>}, \boldsymbol{x<em _boldsymbol_x="\boldsymbol{x">{t}\right)\right)+\sum</em><em c="c">{t^{\prime}}} \exp \left(E\left(\boldsymbol{x}</em>}, \boldsymbol{x<em c="c">{t^{\prime}}\right)\right)}+\log \frac{\exp \left(E\left(\boldsymbol{x}</em>}, \boldsymbol{x<em c="c">{t}\right)\right)}{\exp \left(E\left(\boldsymbol{x}</em>}, \boldsymbol{x<em _boldsymbol_x="\boldsymbol{x">{t}\right)\right)+\sum</em><em c_prime="c^{\prime">{t^{\prime}}} \exp \left(E\left(\boldsymbol{x}</em>\right]
\end{aligned}
$$}}, \boldsymbol{x}_{t}\right)\right)</p>
<p>where $\sigma$ is the sigmoid activation function, $\boldsymbol{x}<em t="t">{c}$ and $\boldsymbol{x}</em>}$ form the structure-text pair for each molecule, and $\boldsymbol{x<em t_prime="t^{\prime">{c^{\prime}}$ and $\boldsymbol{x}</em>}}$ are the negative samples randomly sampled from the noise distribution, which we use the empirical data distribution. $E(\cdot)$ is the energy function with a flexible formulation, and we use the dot product on the jointly learned space, i.e., $E\left(\boldsymbol{x<em t="t">{c}, \boldsymbol{x}</em>}\right)=\left\langle p_{c} \circ f_{c}\left(\boldsymbol{x<em t="t">{c}\right), p</em>\right)\right\rangle$, where $\circ$ is the function composition.} \circ f_{t}\left(\boldsymbol{x}_{t</p>
<h1>Downstream: Zero-shot Structure-text Retrieval</h1>
<p>Given a chemical structure and $T$ textual descriptions, the retrieval task is to select the textual description with the highest similarity to the chemical structure (or vice versa) based on a score calculated on the joint representation space. This is appealing for specific drug discovery tasks, such as drug re-purposing or indication expansion [30, 51]. We highlight that pretrained models are used for retrieval in the zero-shot setting, i.e., without model optimization for this retrieval task. Existing works [52] have witnessed the potential issue that utilizing the chemical structure alone is not sufficient, while MoleculeSTM enables a novel perspective by adopting the textual description with the utilization of the high-level functionality of molecules.</p>
<p>In such a zero-shot task setting, all the encoders $\left(f_{c}, f_{t}\right)$ and projectors $\left(p_{c}, p_{t}\right)$ are pretrained from MoleculeSTM, and stay frozen in this downstream task. An example of the retrieval task of setting (1) is</p>
<p>$$
\operatorname{Retrieval}\left(\boldsymbol{x}<em _tilde_boldsymbol_x="\tilde{\boldsymbol{x">{c}\right)=\arg \max </em>}<em c="c">{t}}\left{\left\langle p</em>} \circ f_{c}\left(\boldsymbol{x<em t="t">{c}\right), p</em>} \circ f_{t}\left(\tilde{\boldsymbol{x}<em t="t">{t}\right)\right\rangle \mid \tilde{\boldsymbol{x}}</em>\right}
$$} \in \mathrm{~T} \text { textual descriptions </p>
<h2>Downstream: Zero-shot Text-based Molecule Editing</h2>
<p>The objective of the molecule editing task is to modify the chemical structure of molecules such as functional group change [53] and scaffold hopping [54, 55]. Traditional methods for molecule editing highly rely on domain experts and could be subjective or biased [56, 57]. ML methods have provided an alternative strategy to solve this issue. Given a fixed pretrained molecule generative model (encoder $f_{g}$ and decoder $h_{g}$ ), the ML editing methods learn a semantically meaningful direction on the latent representation (or latent code) space. The decoder $h_{g}$ then generates output molecules with the desired properties by moving along the direction. In MoleculeSTM, with the pretrained joint representation space, we can accomplish this task by injecting the textual description in a zero-shot manner. As shown in Figure 3 (a, b), we need two phases. The first phase is space alignment, where we train an adaptor module to align the representation space of the generative model to the joint representation space of MoleculeSTM. The second phase is latent optimization, where we directly learn the latent code using two similarity</p>
<p>scores as the objective function. Finally, decoding the optimized latent code can lead to the output molecules. Notice that during this editing process, both the MoleculeSTM $\left(f_{c}, p_{c}, f_{t}, p_{t}\right)$ and a pretrained molecule generative model $\left(f_{g}, h_{g}\right)$ are frozen.</p>
<p>Phase 1: space alignment. In this phase, the goal is to learn an adaptor module to align the representation space of the generative model to the joint representation space of MoleculeSTM. Following the Gaussian distribution, the objective function is</p>
<p>$$
\mathscr{L}=\left|m_{g 2 f} \circ f_{g}\left(\boldsymbol{x}<em c="c">{c}\right)-p</em>
$$} \circ f_{c}\left(\boldsymbol{x}_{c}\right)\right|^{2</p>
<p>where $\circ$ is the function composition function, and $m_{g 2 f}$ is the adaptor module optimized to align the two latent spaces.
Phase 2: latent optimization. In this phase, given an input molecule $\boldsymbol{x}<em t="t">{c, \text { in }}$ and a text prompt $\boldsymbol{x}</em>}$, the goal is to optimize a latent code $w$ directly. The optimal $w$ should be close to the representations of $\boldsymbol{x<em t="t">{c, \text { in }}$ and $\boldsymbol{x}</em>$ simultaneously, as:</p>
<p>$$
w=\underset{w \in \mathscr{W}}{\arg \min }\left(-\mathscr{L}<em 2="2" f="f" g="g">{\text {cosine-sim }}\left(m</em>}(w), p_{t} \circ f_{t}\left(\boldsymbol{x<em l__2="l_{2">{t}\right)\right)+\lambda \cdot \mathscr{L}</em>\right)\right)\right)
$$}}\left(w, f_{g}\left(\boldsymbol{x}_{c, \text { in }</p>
<p>where $\mathscr{W}$ is the latent code space, $\mathscr{L}<em l__2="l_{2">{\text {cosine-sim }}$ is the cosine-similarity, and $\mathscr{L}</em>}}$ is the $l_{2}$ distance, and $\lambda$ is a coefficient to balance these two similarity terms. Finally, after we optimize the latent code $w$, we will do decoding using the decoder from the pretrained generative model to obtain the output molecule: $\boldsymbol{x<em g="g">{c, \text { out }}=h</em>(w)$.</p>
<p>Evaluation. The evaluation metric is the satisfactory hit ratio. Suppose we have an input molecule $\boldsymbol{x}<em t="t">{c, \text { in }}$ and a text prompt $\boldsymbol{x}</em>$. Then we use the hit ratio to measure if the output molecule can satisfy the conditions as indicated in the text prompt.}$, the editing algorithm will generate an output molecule $\boldsymbol{x}_{c, \text { out }</p>
<p>$$
\operatorname{hit}\left(\boldsymbol{x}<em t="t">{c, \text { in }}, \boldsymbol{x}</em>}\right)= \begin{cases}1, &amp; \exists \lambda, \text { s.t. } \boldsymbol{x<em g="g">{c, \text { out }}=h</em>}(\mathrm{w} ; \lambda) \wedge \text { satisfy }\left(\boldsymbol{x<em _="{" _text="\text" c_="c," out="out">{c, \text { in }}, \boldsymbol{x}</em>}}, \boldsymbol{x<em i-1="i-1">{t}\right) \ 0, &amp; \text { otherwise }\end{cases}, \quad \operatorname{hit}(t)=\frac{\sum</em>}^{N} \operatorname{hit}\left(\boldsymbol{x<em t="t">{c, \text { in }}^{i}, \boldsymbol{x}</em>
$$}\right)}{N</p>
<p>where $N$ is the total number of editing outputs, and $\operatorname{satisfy}(\cdot)$ is the satisfaction condition. It is task-specific, and we list the five key points below. (1) For single-objective property-based editing, we use the logarithm of partition coefficient (LogP), quantitative estimate of drug-likeness (QED), and topological polar surface area (tPSA) as the proxies to measure the molecule solubility [58], drug likeness [59], and permeability [60], respectively. The count of hydrogen bond acceptors (HBA) and hydrogen bond donors (HBD) are calculated explicitly. It will be a successful hit once the measurement difference between the input molecule and output molecule is above a certain threshold $\Delta$. (2) For multiple-objective property-based editing, we feed in a text prompt describing multiple properties' composition. The $\Delta$ is composed of the threshold on each individual property, and a successful hit needs to satisfy all the properties simultaneously. (3) For binding-affinity-based editing, we take the ground-truth data from ChEMBL to train a binary classifier and test if the output molecules have higher confidence than the input molecules, and $\Delta$ is fixed to 0 . (4) For drug relevance editing, we use Tanimoto similarity to quantify the structural similarity [61]. It will be a hit if the similarity score between the output molecule and target drug is higher than the similarity between the input molecule and target drug by a threshold $\Delta$. (5) Besides, the choice of satisfactory threshold $\Delta$ is also task-specific, and the higher the values are, the stricter the satisfaction condition is. The details of the threshold values can be found in Supplementary D.</p>
<h1>Downstream: Molecular Property Prediction</h1>
<p>For modeling, we take the pretrained encoder $f_{c}$ and add a prediction head $h_{c}$ to predict a categorical-valued or scalar-valued molecular property such as binding affinity or toxicity. Both $f_{c}$ and $h_{c}$ are optimized to fit the target property, i.e., in a fine-tuning manner $[21,31]$.</p>
<h2>Data Availability</h2>
<p>All the datasets are provided at this Hugging Face link. Specifically for the release of PubChemSTM, we encountered a big challenge regarding the textual data license. As confirmed with the PubChem group, performing research on these data does not violate their license; however, PubChem does not possess the license for the textual data, which necessitates an extensive evaluation of the license for each of the 280 structure-text pairs in PubChemSTM. This has hindered the release of PubChemSTM. Nevertheless, we have (1) described the detailed preprocessing steps in Supplementary A.1, (2) provided the molecules with CID file in PubChemSTM and (3) have also provided the detailed preprocessing scripts. By utilizing these scripts, users can easily reconstruct the PubChemSTM dataset.</p>
<h2>Code Availability</h2>
<p>The source code can be found at this GitHub repository and Zenodo [62]. The scripts for pretraining and three downstream tasks are provided here. The checkpoints of the pretrained models are provided at this Hugging Face link. Beyond the methods described so far, to help users try our MoleculeSTM model, this release includes demos in notebooks. Furthermore, users can customize their own datasets by checking the datasets folder.</p>
<h1>Acknowledgements</h1>
<p>This work was done during Shengchao Liu's internship at NVIDIA Research. The authors would like to thank the insightful comments from Michelle Lynn Gill, Abe Stern, and other team members from AIAlgo and Clara team at NVIDIA. The authors would also like to thank the kind help from Teresa Dierks, Evan Bolton, Paul Thiessen, et al from PubChem for confirming the PubChem license.</p>
<h2>Author Contributions Statement</h2>
<p>S.L., W.N., C.W., Z.Q., C.X., and A.A. conceived and designed the experiments. S.L. performed the experiments. S.L. and C.W. analyzed the data. S.L., C.W., and J.L. contributed analysis tools. S.L., W.N., C.W., J.L., Z.Q., L.L., J. T., C.X., and A.A. wrote the paper. J. T., C.X., and A.A. contributed equally to advising this project.</p>
<h2>Competing Interests Statement</h2>
<p>The authors declare no competing interests.</p>
<h2>References</h2>
<p>[1] Thomas Sullivan. "A tough road: cost to develop one new drug is $\$ 2.6$ billion; approval rate for drugs entering clinical development is less than $12 \%$ ". In: Policy \&amp; Medicine (2019).
[2] Atanas Patronov, Kostas Papadopoulos, and Ola Engkvist. "Has artificial intelligence impacted drug discovery?" In: Artificial Intelligence in Drug Design. Springer, 2022, pp. 153-176.
[3] Madura KP Jayatunga, Wen Xie, Ludwig Ruder, Ulrik Schulze, and Christoph Meier. "AI in small-molecule drug discovery: A coming wave". In: Nat. Rev. Drug Discov 21 (2022), pp. 175-176.
[4] John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin Žídek, Anna Potapenko, Alex Bridgland, Clemens Meyer, Simon A. A. Kohl, Andrew J. Ballard, Andrew Cowie, Bernardino Romera-Paredes, Stanislav Nikolov, Rishub Jain, Jonas Adler, Trevor Back, Stig Petersen, David Reiman, Ellen Clancy, Michal Zielinski, Martin Steinegger, Michalina Pacholska, Tamas Berghammer, Sebastian Bodenstein, David Silver, Oriol Vinyals, Andrew W. Senior, Koray Kavukcuoglu, Pushmeet Kohli, and Demis Hassabis. "Highly accurate protein structure prediction with AlphaFold". In: Nature 596.7873 (2021), pp. 583-589.
[5] Sebastian G. Rohrer and Knut Baumann. "Maximum Unbiased Validation (MUV) Data Sets for Virtual Screening Based on PubChem Bioactivity Data". In: Journal of Chemical Information and Modeling 49.2 (2009). PMID: 19161251, pp. 169-184. DOI: 10.1021/ ci8002649. eprint: https://doi.org/10.1021/ci8002649. URL: https://doi.org/10.1021/ci8002649.
[6] Shengchao Liu, Moayad Alnammi, Spencer S Ericksen, Andrew F Voter, Gene E Ananiev, James L Keck, F Michael Hoffmann, Scott A Wildman, and Anthony Gitter. "Practical model selection for prospective virtual screening". In: Journal of chemical information and modeling 59.1 (2018), pp. 282-293.
[7] David K Duvenaud, Dougal Maclaurin, Jorge Iparraguirre, Rafael Bombarell, Timothy Hirzel, Alán Aspuru-Guzik, and Ryan P Adams. "Convolutional networks on graphs for learning molecular fingerprints". In: Advances in neural information processing systems 28 (2015).
[8] Shengchao Liu, Mehmet F Demirel, and Yingyu Liang. "N-Gram Graph: Simple Unsupervised Representation for Graphs, with Applications to Molecules". In: Advances in neural information processing systems 32 (2019).
[9] Zhenqin Wu, Bharath Ramsundar, Evan N Feinberg, Joseph Gomes, Caleb Geniesse, Aneesh S Pappu, Karl Leswing, and Vijay Pande. "MoleculeNet: a benchmark for molecular machine learning". In: Chemical science 9.2 (2018), pp. 513-530.
[10] Wengong Jin, Regina Barzilay, and Tommi Jaakkola. "Hierarchical generation of molecular graphs using structural motifs". In: International conference on machine learning. PMLR. 2020, pp. 4839-4848.
[11] Ross Irwin, Spyridon Dimitriadis, Jiazhen He, and Esben Jannik Bjerrum. "Chemformer: a pre-trained transformer for computational chemistry". In: Machine Learning: Science and Technology 3.1 (2022), p. 015022.
[12] Zichao Wang, Weili Nie, Zhuoran Qiao, Chaowei Xiao, Richard Baraniuk, and Anima Anandkumar. "Retrieval-based Controllable Molecule Generation". In: arXiv preprint arXiv:2208.11126 (2022).
[13] Shengchao Liu, Chengpeng Wang, Weili Nie, Hanchen Wang, Jiarui Lu, Bolei Zhou, and Jian Tang. "GraphCG: Unsupervised Discovery of Steerable Factors in Graphs". In: NeurIPS 2022 Workshop: New Frontiers in Graph Learning. 2022. URL: https: //openreview.net/forum?id=BhR44NzeK_i.
[14] Mario Krenn, Florian Häse, AkshatKumar Nigam, Pascal Friederich, and Alan Aspuru-Guzik. "Self-referencing embedded strings (SELFIES): A 100\% robust molecular string representation". In: Machine Learning: Science and Technology 1.4 (2020), p. 045024.</p>
<p>[15] Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. "How powerful are graph neural networks?" In: arXiv preprint arXiv:1810.00826 (2018).
[16] Kristof T Schütt, Huziel E Sauceda, P-J Kindermans, Alexandre Tkatchenko, and K-R Müller. "Schnet-a deep learning architecture for molecules and materials". In: The Journal of Chemical Physics 148.24 (2018), p. 241722.
[17] Victor Garcia Satorras, Emiel Hoogeboom, and Max Welling. "E (n) equivariant graph neural networks". In: arXiv preprint arXiv:2102.09844 (2021).
[18] Kenneth Atz, Francesca Grisoni, and Gisbert Schneider. "Geometric deep learning on molecular representations". In: Nature Machine Intelligence 3.12 (2021), pp. 1023-1032.
[19] Yuanfeng Ji, Lu Zhang, Jiaxiang Wu, Bingzhe Wu, Long-Kai Huang, Tingyang Xu, Yu Rong, Lanqing Li, Jie Ren, Ding Xue, et al. "DrugOOD: Out-of-Distribution (OOD) Dataset Curator and Benchmark for AI-aided Drug Discovery-A Focus on Affinity Prediction Problems with Noise Annotations". In: arXiv preprint arXiv:2201.09637 (2022).
[20] John J Irwin, Teague Sterling, Michael M Mysinger, Erin S Bolstad, and Ryan G Coleman. "ZINC: a free tool to discover chemistry for biology". In: Journal of chemical information and modeling 52.7 (2012), pp. 1757-1768.
[21] Weihua Hu, Bowen Liu, Joseph Gomes, Marinka Zitnik, Percy Liang, Vijay Pande, and Jure Leskovec. "Strategies for pre-training graph neural networks". In: International Conference on Learning Representations, ICLR. 2020.
[22] Shengchao Liu, Hongyu Guo, and Jian Tang. "Molecular geometry pretraining with se (3)-invariant denoising distance matching". In: arXiv preprint arXiv:2206.13602 (2022).
[23] Hugo Larochelle, Dumitru Erhan, and Yoshua Bengio. "Zero-data learning of new tasks." In: AAAI. Vol. 1. 2. 2008, p. 3.
[24] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. "Learning transferable visual models from natural language supervision". In: International Conference on Machine Learning. PMLR. 2021, pp. 8748-8763.
[25] Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob McGrew, Ilya Sutskever, and Mark Chen. "Glide: Towards photorealistic image generation and editing with text-guided diffusion models". In: arXiv preprint arXiv:2112.10741 (2021).
[26] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. "Hierarchical text-conditional image generation with clip latents". In: arXiv preprint arXiv:2204.06125 (2022).
[27] Or Patashnik, Zongze Wu, Eli Shechtman, Daniel Cohen-Or, and Dani Lischinski. "Styleclip: Text-driven manipulation of stylegan imagery". In: Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021, pp. 2085-2094.
[28] Shuang Li, Xavier Puig, Yilun Du, Clinton Wang, Ekin Akyurek, Antonio Torralba, Jacob Andreas, and Igor Mordatch. "Pre-trained language models for interactive decision-making". In: arXiv preprint arXiv:2202.01771 (2022).
[29] Linxi Fan, Guanzhi Wang, Yunfan Jiang, Ajay Mandlekar, Yuncong Yang, Haoyi Zhu, Andrew Tang, De-An Huang, Yuke Zhu, and Anima Anandkumar. "Minedojo: Building open-ended embodied agents with internet-scale knowledge". In: arXiv preprint arXiv:2206.08853 (2022).
[30] Zheni Zeng, Yuan Yao, Zhiyuan Liu, and Maosong Sun. "A deep-learning system bridging molecule structure and biomedical text with comprehension comparable to human professionals". In: Nature communications 13.1 (2022), pp. 1-11.
[31] Shengchao Liu, Hanchen Wang, Weiyang Liu, Joan Lasenby, Hongyu Guo, and Jian Tang. "Pre-training Molecular Graph Representation with 3D Geometry". In: International Conference on Learning Representations. 2022. URL: https://openreview.net/ forum?id=xQUe1pOKPam.
[32] Iz Beltagy, Kyle Lo, and Arman Cohan. "SciBERT: Pretrained Language Model for Scientific Text". In: EMNLP. 2019. eprint: arXiv:1903.10676.
[33] Aaron van den Oord, Yazhe Li, and Oriol Vinyals. "Representation learning with contrastive predictive coding". In: arXiv preprint arXiv:1807.03748 (2018).
[34] Sunghwan Kim, Jie Chen, Tiejun Cheng, Asta Gindulyte, Jia He, Siqian He, Qingliang Li, Benjamin A Shoemaker, Paul A Thiessen, Bo Yu, et al. "PubChem in 2021: new data content and improved web interfaces". In: Nucleic acids research 49.D1 (2021), pp. D1388D1395.
[35] James P Hughes, Stephen Rees, S Barrett Kalindjian, and Karen L Philpott. "Principles of early drug discovery". In: British journal of pharmacology 162.6 (2011), pp. 1239-1249.
[36] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. "Attention is all you need". In: Advances in neural information processing systems 30 (2017).
[37] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. "Bert: Pre-training of deep bidirectional transformers for language understanding". In: arXiv preprint arXiv:1810.04805 (2018).
[38] Xiuye Gu, Tsung-Yi Lin, Weicheng Kuo, and Yin Cui. "Open-vocabulary object detection via vision and language knowledge distillation". In: arXiv preprint arXiv:2104.13921 (2021).</p>
<p>[39] David S Wishart, Yannick D Feunang, An C Guo, Elvis J Lo, Ana Marcu, Jason R Grant, Tanvir Sajed, Daniel Johnson, Carin Li, Zinat Sayeeda, et al. "DrugBank 5.0: a major update to the DrugBank database for 2018". In: Nucleic acids research 46.D1 (2018), pp. D1074-D1082.
[40] David Mendez, Anna Gaulton, A Patrícia Bento, Jon Chambers, Marleen De Veij, Eloy Félix, María Paula Magariños, Juan F Mosquera, Prudence Mutowo, Michał Nowotka, María Gordillo-Marañón, Fiona Hunter, Laura Junco, Grace Mugumbate, Milagros Rodriguez-Lopez, Francis Atkinson, Nicolas Bosc, Chris J Radoux, Aldo Segura-Cabrera, Anne Hersey, and Andrew R Leach. "ChEMBL: towards direct deposition of bioassay data". In: Nucleic Acids Research 47.D1 (Nov. 2018), pp. D930-D940. ISSN: 0305-1048. DOI: 10.1093/nar/gky1075. eprint: https://academic.oup.com/nar/article-pdf/47/D1/D930/ 27437436/gky1075.pdf. URL: https://doi.org/10.1093/nar/gky1075.
[41] Jan H Jensen. "A graph-based genetic algorithm and generative model/Monte Carlo tree search for the exploration of chemical space". In: Chemical science 10.12 (2019), pp. 3567-3572.
[42] John J Talley, Thomas D Penning, Paul W Collins, Donald J Rogier Jr, James W Malecha, Julie M Miyashiro, Stephen R Bertenshaw, Ish K Khanna, Matthew J Graneto, Roland S Rogers, et al. Substituted pyrazolyl benzenesulfonamides for the treatment of inflammation. US Patent 5,760,068. June 1998.
[43] David Dahlgren and Hans Lennernäs. "Intestinal Permeability and Drug Absorption: Predictive Experimental, Computational and In Vivo Approaches". In: Pharmaceutics 11.8 (2019). ISSN: 1999-4923. DOI: 10.3390 /pharmaceutics11080411. URL: https://www.mdpi.com/1999-4923/11/8/411.
[44] Gordon Guroff, Jean Renson, Sidney Udenfriend, John W Daly, Donald M Jerina, and Bernhard Witkop. "Hydroxylation-Induced Migration: The NIH Shift: Recent experiments reveal an unexpected and general result of enzymatic hydroxylation of aromatic compounds." In: Science 157.3796 (1967), pp. 1524-1530.
[45] Andrew P Bradley. "The use of the area under the ROC curve in the evaluation of machine learning algorithms". In: Pattern recognition 30.7 (1997), pp. 1145-1159.
[46] Fan-Yun Sun, Jordan Hoffmann, Vikas Verma, and Jian Tang. "Infograph: Unsupervised and semi-supervised graph-level representation learning via mutual information maximization". In: International Conference on Learning Representations, ICLR. 2020.
[47] Yuyang Wang, Jianren Wang, Zhonglin Cao, and Amir Barati Farimani. "Molclr: Molecular contrastive learning of representations via graph neural networks". In: arXiv preprint arXiv:2102.10056 (2021).
[48] Kyle Lo, Lucy Lu Wang, Mark Neumann, Rodney Kinney, and Dan S Weld. "S2ORC: The semantic scholar open research corpus". In: arXiv preprint arXiv:1911.02782 (2019).
[49] Teague Sterling and John J Irwin. "ZINC 15-ligand discovery for everyone". In: Journal of chemical information and modeling 55.11 (2015), pp. 2324-2337.
[50] Simon Axelrod and Rafael Gomez-Bombarelli. "GEOM, energy-annotated molecular conformations for property prediction and molecular generation". In: Scientific Data 9.1 (2022), pp. 1-14.
[51] Saurabh Aggarwal. "Targeted cancer therapies". In: Nature reviews. Drug discovery 9.6 (2010), p. 427.
[53] Peter Ertl, Eva Altmann, and Jeffrey M McKenna. "The most common functional groups in bioactive molecules and how their popularity has evolved over time". In: Journal of medicinal chemistry 63.15 (2020), pp. 8408-8418.
[54] Hans-Joachim Böhm, Alexander Flohr, and Martin Stahl. "Scaffold hopping". In: Drug discovery today: Technologies 1.3 (2004), pp. 217-224.
[55] Ye Hu, Dagmar Stumpfe, and Jurgen Bajorath. "Recent advances in scaffold hopping: miniperspective". In: Journal of medicinal chemistry 60.4 (2017), pp. 1238-1246.
[56] Jürgen Drews. "Drug discovery: a historical perspective". In: Science 287.5460 (2000), pp. 1960-1964.
[57] Laurent Gomez. "Decision making in medicinal chemistry: The power of our intuition". In: ACS Medicinal Chemistry Letters 9.10 (2018), pp. 956-958.
[58] Albert Leo, Corwin Hansch, and David Elkins. "Partition coefficients and their uses". In: Chemical Reviews 71.6 (1971), pp. 525-616. DOI: 10.1021/cr60274a001. eprint: https://doi.org/10.1021/cr60274a001. URL: https://doi.org/10. 1021/cr60274a001.
[59] G Richard Bickerton, Gaia V Paolini, Jérémy Besnard, Sorel Muresan, and Andrew L Hopkins. "Quantifying the chemical beauty of drugs". In: Nature chemistry 4.2 (2012), pp. 90-98.
[60] Peter Ertl, Bernhard Rohde, and Paul Selzer. "Fast Calculation of Molecular Polar Surface Area as a Sum of Fragment-Based Contributions and Its Application to the Prediction of Drug Transport Properties". In: Journal of Medicinal Chemistry 43.20 (2000). PMID: 11020286, pp. 3714-3717. DOI: 10.1021/jm000942e. eprint: https://doi.org/10.1021/jm000942e. URL: https://doi.org/10.1021/jm000942e.</p>
<p>[61] Darko Butina. "Unsupervised Data Base Clustering Based on Daylight's Fingerprint and Tanimoto Similarity: A Fast and Automated Way To Cluster Small and Large Data Sets". In: Journal of Chemical Information and Computer Sciences 39.4 (1999), pp. 747-750. DOI: 10.1021/ci9803381. eprint: https://doi.org/10.1021/ci9803381. URL: https://doi.org/10.1021/ ci9803381.
[62] Shengchao Liu, Weili Nie, Chengpeng Wang, Jiarui Lu, Zhuoran Qiao, Ling Liu, Jian Tang, Chaowei Xiao, and Anima Anandkumar. "Multi-modal Molecule Structure-text Model for Text-based Editing and Retrieval". In: (Aug. 2023). DOI: 10.5281 /zenodo . 8303265 .</p>
<h1>Supplementary Information</h1>
<h2>A Pretraining</h2>
<h2>A. 1 PubChemSTM Construction</h2>
<p>We construct a chemical structure-text pair dataset called PubChemSTM, which is extracted from the PubChem database [1]. Below we explain the key steps of the dataset construction.</p>
<ol>
<li>
<p>We use the PUG View (a REST-style web service) to download the textual descriptions of molecules. It has in total of 290 pages, and each page is downloaded in XML format. For reference, an example page (the first page) can be found here. There is a "string" field in the XML data, and we treat it as the textual descriptions for molecules. After construction, we have 250 K molecules (with unique PubChem ID) and 281 K chemical structure-text pairs. Notice that each molecule can have multiple annotations from different resources.</p>
</li>
<li>
<p>Most of the molecule annotations start with the common name or the International Union of Pure and Applied Chemistry (IUPAC) name. We can either use the raw description (with a common name or IUPAC name) or replace it with the text template (e.g., "This molecule is ...").</p>
</li>
<li>
<p>Thus, we construct two versions of PubChemSTM datasets, PubChemSTM-raw and PubChemSTM-extracted, corresponding to using the raw annotation or replacing the molecule name with the text prompt, respectively. These two versions of PubChemSTM share the molecules, except for the molecule names.</p>
</li>
<li>
<p>We download the 326 SDF files from the PubChem FTP service. Each SDF file contains the structural information (e.g., the SMILES string and molecular graph) for a batch of molecules.</p>
</li>
<li>We match the annotation and chemical structure for each molecule from the previous two steps using the PubChem ID, and most of the molecules from the first step contain the corresponding chemical structures from the SDF files. In specific, only 12 molecules failed to find the valid SMILES from SDF files, and we ignore these molecules.</li>
<li>Ultimately, following the above three steps will lead to a structure-text pair dataset with 281 K pairs and 250 K unique molecules. Note that the PubChem database [1] is updated online frequently, and the above numbers are collected in March 2022.</li>
</ol>
<p>Pre-processing Details There is one field in the PubChem database called "name", which includes either the common name or the IUPAC name for each molecule. Notice that the tokenization on IUPAC is nontrivial. Thus we carry out two versions to test its effect, i.e., the PubChemSTM-raw and PubChemSTM-extracted. We find that there exist several patterns of textual descriptions in PubChemSTM-raw, which are further utilized to extract the cleaner version of molecule description as in PubChem-extract. A detailed illustration is given below:</p>
<ul>
<li>The most common pattern is that the molecule annotation starts with "XXX (name) is / are / was / were / appears / occurs / stands for / belongs to / exits ...". We manually extract this to obtain most of the molecule names and replace them with "This molecule ..." or "These molecules ...".</li>
<li>Extra word "Pure". Some molecule annotations start with "Pure xxx ..." and we remove the word "Pure".</li>
<li>Typos. For example, the "Mercurycombines ..." should be "Mercury combines ...".</li>
</ul>
<p>Dataset Examples We provide four examples of the PubChemSTM-raw and PubChemSTM-extracted in Table 2.
Reproducibility Because the PubChem database [1] has been updated online frequently, so we provide all the pre-processed datasets used in this work for reproducibility. In addition, the source codes for the above steps are also provided for future usage.</p>
<p>Comparison As mentioned, we adopt a pretrained SciBERT model [2] and continue training on PubChemSTM. SciBERT is a BERT model specifically trained for scientific discovery. It randomly samples 1.14 M papers from Semantic Scholar [3], where around $18 \%$ papers are from the computer science domain and $82 \%$ papers are from the broad biomedical domain. Its corpus has 3.17B tokens and the vocabulary size is 31 K . Besides, SciBERT was trained on the full paper, not just the abstract. One potential issue is the vocabulary shift from the Semantic Scholar to PubChemSTM. Although we adapt the pretrained checkpoints from SciBERT (together with its vocabulary) in this work, we still want to carefully examine the vocabulary for the textual data.</p>
<p>In Table 3, we list the vocabulary size of PubChemSTM-raw and PubChemSTM-extract with three tokenization methods: using white space, spaCy [4], and the SciBERT tokenizer. We can observe that the difference between PubChemSTM-raw and PubChemSTM-extract using the SciBERT tokenizer is quite small, compared to the ones using white space and spaCy. Thus, we want to claim that vocabulary is also an important factor, and the SciBERT tokenizer has shown quite a stable tokenization effect. In the future, more comprehensive tokenization and vocabulary are required to push forwards this research line, i.e., to enable the large language model for drug discovery. But it is beyond the scope of this paper and requires efforts from the entire community.</p>
<h2>A. 2 Architecture Details</h2>
<p>We have two branches, the chemical structure branch $f_{c}$ and the textual description branch $f_{t}$.</p>
<p>Table 2. Examples on PubChemSTM. Here for the chemical structure, we only list the SMILES string, since the 2D topology graph can be obtained using the RDKit package.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">PubChemSTM-raw</th>
<th style="text-align: left;">PubChemSTM-extracted</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">SMILES: c1ccccc1</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">Benzene is a colorless liquid with a sweet odor. It evaporates</td>
<td style="text-align: left;">This molecule is a colorless liquid with a sweet odor. It evapo-</td>
</tr>
<tr>
<td style="text-align: left;">into the air very quickly and dissolves slightly in water.</td>
<td style="text-align: left;">rates into the air very quickly and dissolves slightly in water.</td>
</tr>
<tr>
<td style="text-align: left;">SMILES: Oc1ccccc1</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">Phenol is both a manufactured chemical and a natural substance.</td>
<td style="text-align: left;">This molecule is both a manufactured chemical and a natural</td>
</tr>
<tr>
<td style="text-align: left;">It is a colorless-to-white solid when pure.</td>
<td style="text-align: left;">substance. It is a colorless-to-white solid when pure.</td>
</tr>
<tr>
<td style="text-align: left;">SMILES: CC(=O)Oc1ccccc1C(=O)O</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">Acetylsalicylic acid appears as odorless white crystals or cryo-</td>
<td style="text-align: left;">This molecule appears as odorless white crystals or crystalline</td>
</tr>
<tr>
<td style="text-align: left;">talline powder with a slightly bitter taste.</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">SMILES: CC1(C)SC2C(NC(=O)Cc3ccccc3)C(=O)N2C1C(=O)O</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">Benzylpenicillin is a penicillin in which the substituent at posi-</td>
<td style="text-align: left;">This molecule is a penicillin in which the substituent at position</td>
</tr>
<tr>
<td style="text-align: left;">tion 6 of the penam ring is a phenylacetamido group. It has a</td>
<td style="text-align: left;">6 of the penam ring is a phenylacetamido group. It has a role as</td>
</tr>
<tr>
<td style="text-align: left;">role as an antibacterial drug, an epitope and a drug allergen.</td>
<td style="text-align: left;">an antibacterial drug, an epitope, and a drug allergen.</td>
</tr>
</tbody>
</table>
<p>Table 3. The vocabulary comparison.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Data Source</th>
<th style="text-align: left;">Tokenization Method</th>
<th style="text-align: right;">size of vocabulary</th>
<th style="text-align: right;">overlap with SciBERT</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Semantic Scholar (used in SciBERT)</td>
<td style="text-align: left;">SciBERT tokenizer</td>
<td style="text-align: right;">31,090</td>
<td style="text-align: right;">-</td>
</tr>
<tr>
<td style="text-align: left;">PubChemSTM-raw</td>
<td style="text-align: left;">white space</td>
<td style="text-align: right;">315,704</td>
<td style="text-align: right;">7,635</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">spaCy</td>
<td style="text-align: right;">114,976</td>
<td style="text-align: right;">719</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">SciBERT tokenizer</td>
<td style="text-align: right;">18,320</td>
<td style="text-align: right;">18,320</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">white space</td>
<td style="text-align: right;">100,877</td>
<td style="text-align: right;">7,562</td>
</tr>
<tr>
<td style="text-align: left;">PubChemSTM-extract</td>
<td style="text-align: left;">spaCy</td>
<td style="text-align: right;">27,519</td>
<td style="text-align: right;">691</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">SciBERT tokenizer</td>
<td style="text-align: right;">17,442</td>
<td style="text-align: right;">17,442</td>
</tr>
</tbody>
</table>
<p>Chemical structure branch $f_{c}$ This work considers two types of chemical structures: the SMILES string views the molecule as a sequence and the 2D molecular graph takes the atoms and bonds as the nodes and edges, respectively. Then based on the chemical structures, we apply a deep learning encoder $f_{c}$ to get a latent vector as molecule representation. Specifically, for the SMILES string, we take the encoder from MegaMolBART [5], which is pretrained on 500M molecules from ZINC database [6]. For the molecular graph, we take a pretrained graph isomorphism network (GIN) [7] using GraphMVP pretraining [8]. GraphMVP is doing a multi-view pretraining between the 2D topologies and 3D geometries on 250K conformations from GEOM dataset [9]. Thus, though we are not explicitly utilizing the 3D geometries, the state-of-the-art pretrained GIN models can implicitly encode such information.</p>
<p>Textual description branch $f_{t}$ The textual description branch provides a high-level description of the molecule's functionality. We can view this branch as domain knowledge to strengthen the molecule representation. Such domain knowledge is in the form of natural language, and we use the BERT model [10] as the text encoder $f_{t}$. We further adapt the pretrained SciBERT [2], which was pretrained on the textual data from the chemical and biological domain.</p>
<p>Table 4. Model specifications. # parameters in each model.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Branch</th>
<th style="text-align: left;">Model</th>
<th style="text-align: right;"># parameters</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Chemical structure</td>
<td style="text-align: left;">MegaMolBART</td>
<td style="text-align: right;">$10,010,635$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">GIN</td>
<td style="text-align: right;">$1,885,206$</td>
</tr>
<tr>
<td style="text-align: left;">Textual description</td>
<td style="text-align: left;">SciBERT</td>
<td style="text-align: right;">$109,918,464$</td>
</tr>
</tbody>
</table>
<h1>A. 3 Pretraining Details</h1>
<p>Pretraining Objective For the MoleculeSTM pretraining, we apply contrastive learning. More concretely, we choose one of the EBM-NCE [8] and InfoNCE [11]. Both are essentially doing the same thing, yet EBM-NCE has been found to be more</p>
<p>effective for graph-data [8, 12]. The objective for EBM-NCE is:</p>
<p>$$
\mathscr{L}=-\frac{1}{2}\left(\mathbb{E}<em i="i">{\boldsymbol{x}</em>}, \boldsymbol{x<em c="c">{t}}\left[\log \sigma\left(E\left(\boldsymbol{x}</em>}, \boldsymbol{x<em _boldsymbol_x="\boldsymbol{x">{t}\right)\right]+\mathbb{E}</em><em t="t">{c}, \boldsymbol{x}</em>}^{\prime}}\left[\log \left(1-\sigma\left(E\left(\boldsymbol{x<em t="t">{c}, \boldsymbol{x}</em>}^{\prime}\right)\right)\right]\right)-\frac{1}{2}\left(\mathbb{E<em t="t">{\boldsymbol{x}</em>}, \boldsymbol{x<em c="c">{t}}\left[\log \sigma\left(E\left(\boldsymbol{x}</em>}, \boldsymbol{x<em _boldsymbol_x="\boldsymbol{x">{t}\right)\right]+\mathbb{E}</em><em t="t">{c}^{\prime}, \boldsymbol{x}</em>}}\left[\log \left(1-\sigma\left(E\left(\boldsymbol{x<em t="t">{c}^{\prime}, \boldsymbol{x}</em>\right)\right)\right]\right)\right.
$$</p>
<p>where $\boldsymbol{x}<em t="t">{c}$ and $\boldsymbol{x}</em>}$ form the structure-text pair for each molecule, and $\boldsymbol{x<em t_prime="t^{\prime">{c^{\prime}}$ and $\boldsymbol{x}</em>}}$ are the negative samples randomly sampled from the noise distribution, which we use the empirical data distribution. $E(\cdot)$ is the energy function with a flexible formulation, and we use the dot product on the jointly learned space, i.e., $E\left(\boldsymbol{x<em t="t">{c}, \boldsymbol{x}</em>}\right)=\left\langle p_{c} \circ f_{c}\left(\boldsymbol{x<em t="t">{c}\right), p</em>\right)\right\rangle$. Similarly, we have the objective for InfoNCE as:} \circ f_{t}\left(\boldsymbol{x}_{t</p>
<p>$$
\mathscr{L}=-\frac{1}{2} \mathbb{E}\left[\log \frac{\exp \left(E\left(\boldsymbol{x}<em t="t">{c}, \boldsymbol{x}</em>}\right)\right)}{\exp \left(E\left(\boldsymbol{x<em t="t">{c}, \boldsymbol{x}</em>}\right)\right)+\sum_{\boldsymbol{x<em c="c">{c}} \exp \left(E\left(\boldsymbol{x}</em>}, \boldsymbol{x<em c="c">{t}\right)\right)}+\log \frac{\exp \left(E\left(\boldsymbol{x}</em>}, \boldsymbol{x<em c="c">{t}\right)\right)}{\exp \left(E\left(\boldsymbol{x}</em>}, \boldsymbol{x<em _boldsymbol_x="\boldsymbol{x">{t}\right)\right)+\sum</em><em c_prime="c^{\prime">{t}} \exp \left(E\left(\boldsymbol{x}</em>\right]
$$}}, \boldsymbol{x}_{t}\right)\right)</p>
<p>Hyperparameters We list the key hyperparameters used for MoleculeSTM pretraining with the SMILES string and 2D molecular graph as inputs, respectively.</p>
<p>Table 5. Hyperparameter specifications for MoleculeSTM pretraining.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Input</th>
<th style="text-align: left;">Hyperparameter</th>
<th style="text-align: left;">Value</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">SMILES string</td>
<td style="text-align: left;">epochs</td>
<td style="text-align: left;">${32}$</td>
</tr>
<tr>
<td style="text-align: left;">learning rate for text branch</td>
<td style="text-align: left;">${1 \mathrm{e}-4}$</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">learning rate for chemical structure branch</td>
<td style="text-align: left;">${1 \mathrm{e}-5,3 \mathrm{e}-5}$</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">objective function</td>
<td style="text-align: left;">${$ EBM-NCE, InfoNCE $}$</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">2D molecular graph</td>
<td style="text-align: left;">epochs</td>
<td style="text-align: left;">${32}$</td>
</tr>
<tr>
<td style="text-align: left;">learning rate for text branch</td>
<td style="text-align: left;">${1 \mathrm{e}-4}$</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">learning rate for chemical structure branch</td>
<td style="text-align: left;">${1 \mathrm{e}-5,3 \mathrm{e}-5}$</td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">objective function</td>
<td style="text-align: left;">${$ EBM-NCE, InfoNCE $}$</td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<p>Running time We list the running time of MoleculeSTM with the SMILES string and 2D molecular graph as inputs, respectively.</p>
<p>Table 6. Running time for MoleculeSTM pretraining.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Input</th>
<th style="text-align: left;">Running Time</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">SMILES string</td>
<td style="text-align: left;">$44 \mathrm{~min} /$ epoch</td>
</tr>
<tr>
<td style="text-align: left;">2D molecular graph</td>
<td style="text-align: left;">$42 \mathrm{~min} /$ epoch</td>
</tr>
</tbody>
</table>
<h1>B Design Principles for Downstream Tasks</h1>
<p>In this section, we discuss the key principles when designing downstream tasks.
Applicable Evaluation One of the biggest differences between the foundation model in the vision-language domain and our MoleculeSTM can be reflected in the evaluation. Most of the vision and language tasks can be viewed as art problems, i.e., there does not exist a standard and exact solution that is applicable for evaluation. For instance, we can detect if the image is "a horse riding an astronaut" or "a panda making latte art" [13], but only visually not computationally, which prevents large-scale evaluation. This is not the case for drug discovery, because it is a scientific task, where the results (e.g., properties of the output molecules in the editing task) can be evaluated exactly, either in vitro or in silico. Following this, the physical experiments are usually expensive and long-lasting, so in this work, we want to focus on tasks that are computationally feasible for evaluation.</p>
<p>Fuzzy Matching Specifically for the molecule editing task, the text prompts should follow the "fuzzy matching" criterion because there could exist multiple output molecules. This is in contradiction with "exact matching", where the output molecules are deterministic. For example, for the functional group change, we can feed in the prompts like "change the third nitrogen in the ring to oxygen". This prompt is very explicit with an exact solution, and there exist rule-based chemistry tools in handling this problem perfectly. Thus, text-based editing cannot show its benefits in this track. Instead, text-based editing can provide more benefits in the fuzzy matching setting by wandering around the semantically meaningful directions in the latent space. This also reflects the open vocabulary attribute of the language model that we have been focusing on.</p>
<h1>C Downstream: Zero-shot Structure-text Retrieval</h1>
<h2>C. 1 Dataset Construction</h2>
<p>The DrugBank database [14] has many fields that can be interesting to explore drug discovery tasks. Here we extract three fields of each small molecule drug for the zero-shot retrieval task: the Description field, the Pharmacodynamics field, and the anatomical therapeutic chemical (ATC) field, as detailed below:</p>
<ul>
<li>DrugBank-Description. The Description field gives a high-level review of the drug's chemical properties, history, and regulatory status.</li>
<li>DrugBank-Pharmacodynamics. This illustrates how the drug modifies or affects the organism it is being used in. This field may include effects in the body that are desired and undesired (also known as the side effects).</li>
<li>
<p>DrugBank-ATC. Anatomical therapeutic chemical (ATC) is a classification system that categorizes the molecule into different groups according to the organ or system on which they act and their therapeutic, pharmacological, and chemical properties.
We list the key steps in dataset construction as follows:</p>
</li>
<li>
<p>We download the full DrugBank database (in XML format) and small chemical structure files (in SDF format) from the website.</p>
</li>
<li>We parse the XML file, and extract the data with three fields: Description, Pharmacodynamics, and ATC.</li>
<li>
<p>We do the mapping from the extracted files to chemical structures in SDF files. For DrugBank-Description and DrugBankPharmacodynamics datasets, we exclude the molecules that have shown up in PubChemSTM, filtered with the canonical SMILES. Meanwhile, for DrugBank-ATC, we exclude the molecules satisfying the following two criteria simultaneously:</p>
</li>
<li>
<p>Chemical structure filtering If the molecule with the same canonical SMILES has shown up in the PubChemSTM;</p>
</li>
<li>
<p>Textual data filtering We first need to define a similarity between two textual data as in Equation (8), where text $<em _PubChemSTM="{PubChemSTM" _text="\text">{\text {DrugBank }}$ and text $</em>$ are the textual data for the same molecule from DrugBank and PubChemSTM, respectively, len() is the length of textual data, and Levenshtein() is the Levenshtein distance between two textual data. Thus, the second condition is: if the similarity between the DrugBank text and the PubChemSTM text is above a certain threshold (e.g., 0.6 ).
Another detail is that, for DrugBank-ATC, there exist multiple ATC fields (text ${ }}<em _PubChemSTM="{PubChemSTM" _text="\text">{\text {DrugBank }}$ ) for each small molecule. In PubChemSTM, there also exist multiple textual descriptions (text ${ }</em>$ ) for each molecule. Thus during the textual data filtering step, for each shared molecule between DrugBank and PubChemSTM, we calculate the similarity for all the text $}<em _PubChemSTM="{PubChemSTM" _text="\text">{\text {DrugBank }}$-text $</em>$ pairs, and exclude the molecule if there exists one pair with similarity above the threshold 0.6 .}</p>
</li>
<li>
<p>Some basic dataset statistics can be found in Table 7. Notice that ATC has many levels, and we are using level 5 for retrieval in this work.
$\operatorname{sim}\left(\right.$ text $<em _PubChemSTM="{PubChemSTM" _text="\text">{\text {DrugBank }}, \operatorname{text}</em>}}$ ) $=1-\frac{\text { Levenshtein }\left(\text { text <em _PubChemSTM="{PubChemSTM" _text="\text">{\text {DrugBank }}, \text { text }</em>$.}}\right)}{\operatorname{len}\left(\text { text }_{\text {DrugBank }}\right)</p>
</li>
</ul>
<p>Table 7. Statistics on three fields in DrugBank. The filtering steps have been illustrated above.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Field</th>
<th style="text-align: center;"># structure-text pairs <br> molecule not in PubChemSTM</th>
<th style="text-align: center;"># structure-text pairs <br> molecule shared in PubChemSTM <br> but text similarity below 0.6</th>
<th style="text-align: center;">total</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">DrugBank-Description</td>
<td style="text-align: center;">1,154</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">1,154</td>
</tr>
<tr>
<td style="text-align: left;">DrugBank-Pharmacodynamics</td>
<td style="text-align: center;">1,005</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">1,005</td>
</tr>
<tr>
<td style="text-align: left;">DrugBank-ATC</td>
<td style="text-align: center;">1,507</td>
<td style="text-align: center;">1,500</td>
<td style="text-align: center;">3,007</td>
</tr>
</tbody>
</table>
<h1>C. 2 Experiments</h1>
<p>For experiments, we introduce three baselines in the main body. As a proof-of-concept, we carry out another baseline called Random. For Random, both encoders $\left(f_{c}\right.$ and $\left.f_{t}\right)$ are randomly initialized. The zero-shot retrieval results on three datasets are shown in Tables 8 to 10 .</p>
<p>Table 8. Accuracy (\%) of DrugBank-Description $T$-choose-one retrieval.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Given Chemical Structure</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Given Text</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">T</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">20</td>
</tr>
<tr>
<td style="text-align: center;">SMILES</td>
<td style="text-align: center;">Random</td>
<td style="text-align: center;">$24.59 \pm 1.14$</td>
<td style="text-align: center;">$10.12 \pm 1.38$</td>
<td style="text-align: center;">$4.97 \pm 0.42$</td>
<td style="text-align: center;">$24.54 \pm 0.97$</td>
<td style="text-align: center;">$9.97 \pm 0.81$</td>
<td style="text-align: center;">$5.09 \pm 0.37$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Frozen</td>
<td style="text-align: center;">$25.07 \pm 1.24$</td>
<td style="text-align: center;">$10.22 \pm 1.19$</td>
<td style="text-align: center;">$5.12 \pm 0.65$</td>
<td style="text-align: center;">$24.69 \pm 1.87$</td>
<td style="text-align: center;">$10.20 \pm 1.38$</td>
<td style="text-align: center;">$5.37 \pm 1.15$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Similarity</td>
<td style="text-align: center;">$36.35 \pm 0.59$</td>
<td style="text-align: center;">$23.22 \pm 0.58$</td>
<td style="text-align: center;">$16.40 \pm 0.59$</td>
<td style="text-align: center;">$22.74 \pm 0.24$</td>
<td style="text-align: center;">$10.31 \pm 0.24$</td>
<td style="text-align: center;">$5.34 \pm 0.24$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">KV-PLM</td>
<td style="text-align: center;">$73.80 \pm 0.00$</td>
<td style="text-align: center;">$53.96 \pm 0.29$</td>
<td style="text-align: center;">$40.07 \pm 0.38$</td>
<td style="text-align: center;">$72.86 \pm 0.00$</td>
<td style="text-align: center;">$52.55 \pm 0.29$</td>
<td style="text-align: center;">$40.33 \pm 0.00$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">MoleculeSTM</td>
<td style="text-align: center;">$97.50 \pm 0.46$</td>
<td style="text-align: center;">$94.18 \pm 0.46$</td>
<td style="text-align: center;">$91.12 \pm 0.46$</td>
<td style="text-align: center;">$98.21 \pm 0.00$</td>
<td style="text-align: center;">$94.54 \pm 0.37$</td>
<td style="text-align: center;">$91.97 \pm 0.46$</td>
</tr>
<tr>
<td style="text-align: center;">Graph</td>
<td style="text-align: center;">Random</td>
<td style="text-align: center;">$25.78 \pm 1.43$</td>
<td style="text-align: center;">$10.71 \pm 0.97$</td>
<td style="text-align: center;">$4.83 \pm 1.00$</td>
<td style="text-align: center;">$24.98 \pm 0.32$</td>
<td style="text-align: center;">$10.20 \pm 0.40$</td>
<td style="text-align: center;">$4.80 \pm 0.21$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Frozen</td>
<td style="text-align: center;">$24.01 \pm 1.34$</td>
<td style="text-align: center;">$9.39 \pm 0.92$</td>
<td style="text-align: center;">$4.85 \pm 0.52$</td>
<td style="text-align: center;">$24.00 \pm 1.66$</td>
<td style="text-align: center;">$9.91 \pm 0.71$</td>
<td style="text-align: center;">$5.07 \pm 0.75$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Similarity</td>
<td style="text-align: center;">$30.03 \pm 0.38$</td>
<td style="text-align: center;">$13.63 \pm 0.27$</td>
<td style="text-align: center;">$7.07 \pm 0.10$</td>
<td style="text-align: center;">$24.81 \pm 0.27$</td>
<td style="text-align: center;">$10.22 \pm 0.24$</td>
<td style="text-align: center;">$4.74 \pm 0.24$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">MoleculeSTM</td>
<td style="text-align: center;">$99.15 \pm 0.00$</td>
<td style="text-align: center;">$97.19 \pm 0.00$</td>
<td style="text-align: center;">$95.66 \pm 0.00$</td>
<td style="text-align: center;">$99.05 \pm 0.37$</td>
<td style="text-align: center;">$97.50 \pm 0.46$</td>
<td style="text-align: center;">$95.71 \pm 0.46$</td>
</tr>
</tbody>
</table>
<p>Table 9. Accuracy (\%) of DrugBank-Pharmacodynamics $T$-choose-one retrieval.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Given Chemical Structure</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Given Text</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">T</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">20</td>
</tr>
<tr>
<td style="text-align: center;">SMILES</td>
<td style="text-align: center;">Random</td>
<td style="text-align: center;">$24.49 \pm 0.68$</td>
<td style="text-align: center;">$9.73 \pm 0.34$</td>
<td style="text-align: center;">$5.14 \pm 0.57$</td>
<td style="text-align: center;">$25.61 \pm 0.62$</td>
<td style="text-align: center;">$10.10 \pm 0.91$</td>
<td style="text-align: center;">$5.07 \pm 0.69$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Frozen</td>
<td style="text-align: center;">$25.47 \pm 1.12$</td>
<td style="text-align: center;">$10.55 \pm 0.75$</td>
<td style="text-align: center;">$5.48 \pm 0.70$</td>
<td style="text-align: center;">$25.34 \pm 0.41$</td>
<td style="text-align: center;">$9.86 \pm 0.44$</td>
<td style="text-align: center;">$4.84 \pm 0.26$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Similarity</td>
<td style="text-align: center;">$27.85 \pm 0.03$</td>
<td style="text-align: center;">$10.75 \pm 0.02$</td>
<td style="text-align: center;">$5.67 \pm 0.01$</td>
<td style="text-align: center;">$24.58 \pm 0.03$</td>
<td style="text-align: center;">$11.25 \pm 0.03$</td>
<td style="text-align: center;">$5.29 \pm 0.02$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">KV-PLM</td>
<td style="text-align: center;">$68.38 \pm 0.03$</td>
<td style="text-align: center;">$47.59 \pm 0.03$</td>
<td style="text-align: center;">$36.54 \pm 0.03$</td>
<td style="text-align: center;">$67.68 \pm 0.03$</td>
<td style="text-align: center;">$48.00 \pm 0.02$</td>
<td style="text-align: center;">$34.66 \pm 0.02$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">MoleculeSTM</td>
<td style="text-align: center;">$88.07 \pm 0.01$</td>
<td style="text-align: center;">$81.70 \pm 0.02$</td>
<td style="text-align: center;">$75.94 \pm 0.02$</td>
<td style="text-align: center;">$88.46 \pm 0.01$</td>
<td style="text-align: center;">$81.01 \pm 0.02$</td>
<td style="text-align: center;">$74.64 \pm 0.03$</td>
</tr>
<tr>
<td style="text-align: center;">Graph</td>
<td style="text-align: center;">Random</td>
<td style="text-align: center;">$26.00 \pm 0.37$</td>
<td style="text-align: center;">$9.65 \pm 0.88$</td>
<td style="text-align: center;">$4.95 \pm 0.36$</td>
<td style="text-align: center;">$25.11 \pm 0.63$</td>
<td style="text-align: center;">$9.99 \pm 0.62$</td>
<td style="text-align: center;">$4.82 \pm 0.54$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Frozen</td>
<td style="text-align: center;">$25.49 \pm 1.82$</td>
<td style="text-align: center;">$10.19 \pm 1.47$</td>
<td style="text-align: center;">$4.74 \pm 0.56$</td>
<td style="text-align: center;">$25.55 \pm 0.45$</td>
<td style="text-align: center;">$10.15 \pm 0.77$</td>
<td style="text-align: center;">$4.88 \pm 0.55$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Similarity</td>
<td style="text-align: center;">$25.33 \pm 0.27$</td>
<td style="text-align: center;">$9.89 \pm 0.52$</td>
<td style="text-align: center;">$4.61 \pm 0.08$</td>
<td style="text-align: center;">$25.28 \pm 0.03$</td>
<td style="text-align: center;">$10.64 \pm 0.02$</td>
<td style="text-align: center;">$5.47 \pm 0.02$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">MoleculeSTM</td>
<td style="text-align: center;">$92.14 \pm 0.02$</td>
<td style="text-align: center;">$86.27 \pm 0.02$</td>
<td style="text-align: center;">$81.08 \pm 0.05$</td>
<td style="text-align: center;">$91.44 \pm 0.02$</td>
<td style="text-align: center;">$86.76 \pm 0.03$</td>
<td style="text-align: center;">$81.68 \pm 0.03$</td>
</tr>
</tbody>
</table>
<p>Table 10. Accuracy (\%) of molecule-ATC $T$-choose-one retrieval.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Given Chemical Structure</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Given Text</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">T</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">20</td>
</tr>
<tr>
<td style="text-align: center;">SMILES</td>
<td style="text-align: center;">Random</td>
<td style="text-align: center;">$25.03 \pm 0.33$</td>
<td style="text-align: center;">$9.83 \pm 0.19$</td>
<td style="text-align: center;">$4.80 \pm 0.22$</td>
<td style="text-align: center;">$25.44 \pm 1.21$</td>
<td style="text-align: center;">$10.03 \pm 0.94$</td>
<td style="text-align: center;">$5.11 \pm 0.79$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Frozen</td>
<td style="text-align: center;">$25.05 \pm 0.94$</td>
<td style="text-align: center;">$10.17 \pm 0.63$</td>
<td style="text-align: center;">$4.99 \pm 0.54$</td>
<td style="text-align: center;">$25.35 \pm 0.78$</td>
<td style="text-align: center;">$10.32 \pm 0.44$</td>
<td style="text-align: center;">$5.22 \pm 0.34$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Similarity</td>
<td style="text-align: center;">$30.03 \pm 0.00$</td>
<td style="text-align: center;">$13.35 \pm 0.02$</td>
<td style="text-align: center;">$7.53 \pm 0.02$</td>
<td style="text-align: center;">$26.74 \pm 0.03$</td>
<td style="text-align: center;">$11.01 \pm 0.00$</td>
<td style="text-align: center;">$5.62 \pm 0.00$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">KV-PLM</td>
<td style="text-align: center;">$60.94 \pm 0.00$</td>
<td style="text-align: center;">$42.35 \pm 0.00$</td>
<td style="text-align: center;">$30.32 \pm 0.00$</td>
<td style="text-align: center;">$60.67 \pm 0.00$</td>
<td style="text-align: center;">$40.19 \pm 0.00$</td>
<td style="text-align: center;">$29.02 \pm 0.00$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">MoleculeSTM</td>
<td style="text-align: center;">$70.84 \pm 0.07$</td>
<td style="text-align: center;">$56.75 \pm 0.05$</td>
<td style="text-align: center;">$46.12 \pm 0.07$</td>
<td style="text-align: center;">$73.07 \pm 0.03$</td>
<td style="text-align: center;">$58.19 \pm 0.03$</td>
<td style="text-align: center;">$48.97 \pm 0.06$</td>
</tr>
<tr>
<td style="text-align: center;">Graph</td>
<td style="text-align: center;">Random</td>
<td style="text-align: center;">$24.48 \pm 0.66$</td>
<td style="text-align: center;">$9.97 \pm 0.25$</td>
<td style="text-align: center;">$4.81 \pm 0.34$</td>
<td style="text-align: center;">$25.48 \pm 0.59$</td>
<td style="text-align: center;">$10.40 \pm 0.37$</td>
<td style="text-align: center;">$5.38 \pm 0.30$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Frozen</td>
<td style="text-align: center;">$24.19 \pm 0.77$</td>
<td style="text-align: center;">$10.24 \pm 0.71$</td>
<td style="text-align: center;">$4.87 \pm 0.47$</td>
<td style="text-align: center;">$24.95 \pm 1.52$</td>
<td style="text-align: center;">$10.07 \pm 0.80$</td>
<td style="text-align: center;">$5.06 \pm 0.36$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Similarity</td>
<td style="text-align: center;">$29.46 \pm 0.00$</td>
<td style="text-align: center;">$12.34 \pm 0.00$</td>
<td style="text-align: center;">$6.52 \pm 0.00$</td>
<td style="text-align: center;">$25.78 \pm 1.53$</td>
<td style="text-align: center;">$10.23 \pm 0.70$</td>
<td style="text-align: center;">$5.06 \pm 0.67$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">MoleculeSTM</td>
<td style="text-align: center;">$69.33 \pm 0.03$</td>
<td style="text-align: center;">$54.83 \pm 0.04$</td>
<td style="text-align: center;">$44.13 \pm 0.05$</td>
<td style="text-align: center;">$71.81 \pm 0.05$</td>
<td style="text-align: center;">$58.34 \pm 0.07$</td>
<td style="text-align: center;">$47.58 \pm 0.05$</td>
</tr>
</tbody>
</table>
<h1>C. 3 Ablation Study: Fixed Pretrained Encoders</h1>
<p>In the main body, we conduct pretraining by adopting pretrained single-modality checkpoints, i.e., the GraphMVP and MegaMolBART for $f_{c}$, and SciBERT for $f_{t}$. Then for MoleculeSTM pretraining, we use contrastive learning and update all the model parameters. Here we take an ablation study by only optimizing the projection layers to the joint space of the two branches $\left(p_{c}, p_{t}\right)$ while keeping the two encoders $\left(f_{c}, f_{t}\right)$ fixed. The results on the three datasets are shown in Tables 11 to 13.</p>
<p>Table 11. Accuracy (\%) of DrugBank-Description $T$-choose-one retrieval.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: center;">Given Chemical Structure</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Given Text</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">T</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">20</td>
</tr>
<tr>
<td style="text-align: left;">SMILES</td>
<td style="text-align: left;">Random</td>
<td style="text-align: center;">$24.59 \pm 1.14$</td>
<td style="text-align: center;">$10.12 \pm 1.38$</td>
<td style="text-align: center;">$4.97 \pm 0.42$</td>
<td style="text-align: center;">$24.54 \pm 0.97$</td>
<td style="text-align: center;">$9.97 \pm 0.81$</td>
<td style="text-align: center;">$5.09 \pm 0.37$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Frozen</td>
<td style="text-align: center;">$25.07 \pm 1.24$</td>
<td style="text-align: center;">$10.22 \pm 1.19$</td>
<td style="text-align: center;">$5.12 \pm 0.65$</td>
<td style="text-align: center;">$24.69 \pm 1.87$</td>
<td style="text-align: center;">$10.20 \pm 1.38$</td>
<td style="text-align: center;">$5.37 \pm 1.15$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Similarity</td>
<td style="text-align: center;">$36.35 \pm 0.59$</td>
<td style="text-align: center;">$23.22 \pm 0.58$</td>
<td style="text-align: center;">$16.40 \pm 0.59$</td>
<td style="text-align: center;">$22.74 \pm 0.24$</td>
<td style="text-align: center;">$10.31 \pm 0.24$</td>
<td style="text-align: center;">$5.34 \pm 0.24$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">MoleculeSTM</td>
<td style="text-align: center;">$47.64 \pm 0.40$</td>
<td style="text-align: center;">$29.21 \pm 0.47$</td>
<td style="text-align: center;">$19.69 \pm 0.47$</td>
<td style="text-align: center;">$52.60 \pm 0.46$</td>
<td style="text-align: center;">$32.24 \pm 0.37$</td>
<td style="text-align: center;">$21.45 \pm 0.37$</td>
</tr>
<tr>
<td style="text-align: left;">Graph</td>
<td style="text-align: left;">Random</td>
<td style="text-align: center;">$25.78 \pm 1.43$</td>
<td style="text-align: center;">$10.71 \pm 0.97$</td>
<td style="text-align: center;">$4.83 \pm 1.00$</td>
<td style="text-align: center;">$24.98 \pm 0.32$</td>
<td style="text-align: center;">$10.20 \pm 0.40$</td>
<td style="text-align: center;">$4.80 \pm 0.21$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Frozen</td>
<td style="text-align: center;">$24.01 \pm 1.34$</td>
<td style="text-align: center;">$9.39 \pm 0.92$</td>
<td style="text-align: center;">$4.85 \pm 0.52$</td>
<td style="text-align: center;">$24.00 \pm 1.66$</td>
<td style="text-align: center;">$9.91 \pm 0.71$</td>
<td style="text-align: center;">$5.07 \pm 0.75$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Similarity</td>
<td style="text-align: center;">$30.03 \pm 0.38$</td>
<td style="text-align: center;">$13.63 \pm 0.27$</td>
<td style="text-align: center;">$7.07 \pm 0.10$</td>
<td style="text-align: center;">$24.81 \pm 0.27$</td>
<td style="text-align: center;">$10.22 \pm 0.24$</td>
<td style="text-align: center;">$4.74 \pm 0.24$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">MoleculeSTM</td>
<td style="text-align: center;">$51.28 \pm 0.00$</td>
<td style="text-align: center;">$31.99 \pm 0.41$</td>
<td style="text-align: center;">$20.71 \pm 0.47$</td>
<td style="text-align: center;">$55.27 \pm 0.00$</td>
<td style="text-align: center;">$33.08 \pm 0.00$</td>
<td style="text-align: center;">$21.77 \pm 0.00$</td>
</tr>
</tbody>
</table>
<p>Table 12. Accuracy (\%) of DrugBank-Pharmacodynamics $T$-choose-one retrieval.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: center;">Given Chemical Structure</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Given Text</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">T</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">20</td>
</tr>
<tr>
<td style="text-align: left;">SMILES</td>
<td style="text-align: left;">Random</td>
<td style="text-align: center;">$24.49 \pm 0.68$</td>
<td style="text-align: center;">$9.73 \pm 0.34$</td>
<td style="text-align: center;">$5.14 \pm 0.57$</td>
<td style="text-align: center;">$25.61 \pm 0.62$</td>
<td style="text-align: center;">$10.10 \pm 0.91$</td>
<td style="text-align: center;">$5.07 \pm 0.69$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Frozen</td>
<td style="text-align: center;">$25.47 \pm 1.12$</td>
<td style="text-align: center;">$10.55 \pm 0.75$</td>
<td style="text-align: center;">$5.48 \pm 0.70$</td>
<td style="text-align: center;">$25.34 \pm 0.41$</td>
<td style="text-align: center;">$9.86 \pm 0.44$</td>
<td style="text-align: center;">$4.84 \pm 0.26$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Similarity</td>
<td style="text-align: center;">$27.85 \pm 0.03$</td>
<td style="text-align: center;">$10.75 \pm 0.02$</td>
<td style="text-align: center;">$5.67 \pm 0.01$</td>
<td style="text-align: center;">$24.58 \pm 0.03$</td>
<td style="text-align: center;">$11.25 \pm 0.03$</td>
<td style="text-align: center;">$5.29 \pm 0.02$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">MoleculeSTM</td>
<td style="text-align: center;">$46.43 \pm 0.00$</td>
<td style="text-align: center;">$27.42 \pm 0.47$</td>
<td style="text-align: center;">$18.24 \pm 0.47$</td>
<td style="text-align: center;">$52.53 \pm 0.41$</td>
<td style="text-align: center;">$30.53 \pm 0.00$</td>
<td style="text-align: center;">$19.98 \pm 0.00$</td>
</tr>
<tr>
<td style="text-align: left;">Graph</td>
<td style="text-align: left;">Random</td>
<td style="text-align: center;">$26.00 \pm 0.37$</td>
<td style="text-align: center;">$9.65 \pm 0.88$</td>
<td style="text-align: center;">$4.95 \pm 0.36$</td>
<td style="text-align: center;">$25.11 \pm 0.63$</td>
<td style="text-align: center;">$9.99 \pm 0.62$</td>
<td style="text-align: center;">$4.82 \pm 0.54$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Frozen</td>
<td style="text-align: center;">$25.49 \pm 1.82$</td>
<td style="text-align: center;">$10.19 \pm 1.47$</td>
<td style="text-align: center;">$4.74 \pm 0.56$</td>
<td style="text-align: center;">$25.55 \pm 0.45$</td>
<td style="text-align: center;">$10.15 \pm 0.77$</td>
<td style="text-align: center;">$4.88 \pm 0.55$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Similarity</td>
<td style="text-align: center;">$25.33 \pm 0.27$</td>
<td style="text-align: center;">$9.89 \pm 0.52$</td>
<td style="text-align: center;">$4.61 \pm 0.08$</td>
<td style="text-align: center;">$25.28 \pm 0.03$</td>
<td style="text-align: center;">$10.64 \pm 0.02$</td>
<td style="text-align: center;">$5.47 \pm 0.02$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">MoleculeSTM</td>
<td style="text-align: center;">$46.29 \pm 0.03$</td>
<td style="text-align: center;">$27.18 \pm 0.02$</td>
<td style="text-align: center;">$17.73 \pm 0.02$</td>
<td style="text-align: center;">$50.95 \pm 0.04$</td>
<td style="text-align: center;">$31.65 \pm 0.03$</td>
<td style="text-align: center;">$23.00 \pm 0.03$</td>
</tr>
</tbody>
</table>
<p>Table 13. Accuracy (\%) of DrugBank-ATC $T$-choose-one retrieval.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: center;">Given Chemical Structure</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Given Text</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">T</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">20</td>
</tr>
<tr>
<td style="text-align: left;">SMILES</td>
<td style="text-align: left;">Random</td>
<td style="text-align: center;">$25.03 \pm 0.33$</td>
<td style="text-align: center;">$9.83 \pm 0.19$</td>
<td style="text-align: center;">$4.80 \pm 0.22$</td>
<td style="text-align: center;">$25.44 \pm 1.21$</td>
<td style="text-align: center;">$10.03 \pm 0.94$</td>
<td style="text-align: center;">$5.11 \pm 0.79$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Frozen</td>
<td style="text-align: center;">$25.05 \pm 0.94$</td>
<td style="text-align: center;">$10.17 \pm 0.63$</td>
<td style="text-align: center;">$4.99 \pm 0.54$</td>
<td style="text-align: center;">$25.35 \pm 0.78$</td>
<td style="text-align: center;">$10.32 \pm 0.44$</td>
<td style="text-align: center;">$5.22 \pm 0.34$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Similarity</td>
<td style="text-align: center;">$30.03 \pm 0.00$</td>
<td style="text-align: center;">$13.35 \pm 0.02$</td>
<td style="text-align: center;">$7.53 \pm 0.02$</td>
<td style="text-align: center;">$26.74 \pm 0.03$</td>
<td style="text-align: center;">$11.01 \pm 0.00$</td>
<td style="text-align: center;">$5.62 \pm 0.00$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">MoleculeSTM</td>
<td style="text-align: center;">$43.41 \pm 0.12$</td>
<td style="text-align: center;">$25.66 \pm 0.06$</td>
<td style="text-align: center;">$15.69 \pm 0.06$</td>
<td style="text-align: center;">$48.75 \pm 0.11$</td>
<td style="text-align: center;">$29.44 \pm 0.06$</td>
<td style="text-align: center;">$19.75 \pm 0.03$</td>
</tr>
<tr>
<td style="text-align: left;">Graph</td>
<td style="text-align: left;">Random</td>
<td style="text-align: center;">$24.48 \pm 0.66$</td>
<td style="text-align: center;">$9.97 \pm 0.25$</td>
<td style="text-align: center;">$4.81 \pm 0.34$</td>
<td style="text-align: center;">$25.48 \pm 0.59$</td>
<td style="text-align: center;">$10.40 \pm 0.37$</td>
<td style="text-align: center;">$5.38 \pm 0.30$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Frozen</td>
<td style="text-align: center;">$24.19 \pm 0.77$</td>
<td style="text-align: center;">$10.24 \pm 0.71$</td>
<td style="text-align: center;">$4.87 \pm 0.47$</td>
<td style="text-align: center;">$24.95 \pm 1.52$</td>
<td style="text-align: center;">$10.07 \pm 0.80$</td>
<td style="text-align: center;">$5.06 \pm 0.36$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Similarity</td>
<td style="text-align: center;">$29.46 \pm 0.00$</td>
<td style="text-align: center;">$12.34 \pm 0.00$</td>
<td style="text-align: center;">$6.52 \pm 0.00$</td>
<td style="text-align: center;">$25.78 \pm 1.53$</td>
<td style="text-align: center;">$10.23 \pm 0.70$</td>
<td style="text-align: center;">$5.06 \pm 0.67$</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">MoleculeSTM</td>
<td style="text-align: center;">$42.53 \pm 0.07$</td>
<td style="text-align: center;">$24.34 \pm 0.00$</td>
<td style="text-align: center;">$14.78 \pm 0.03$</td>
<td style="text-align: center;">$48.91 \pm 0.03$</td>
<td style="text-align: center;">$28.77 \pm 0.07$</td>
<td style="text-align: center;">$19.28 \pm 0.07$</td>
</tr>
</tbody>
</table>            </div>
        </div>

    </div>
</body>
</html>