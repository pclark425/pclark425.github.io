<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1861 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1861</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1861</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-35.html">extraction-schema-35</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that use computational predictions, proxy metrics, or surrogate objectives followed by experimental or ground-truth validation, including quantitative measures of agreement, disagreement, false positive rates, and factors affecting prediction accuracy.</div>
                <p><strong>Paper ID:</strong> paper-278429735</p>
                <p><strong>Paper Title:</strong> AF2Rank Revisited: Reproducing AlphaFold-Based Structure Evaluation and a Hypothesis for Context-Aware Refinement (CAR-AF)</p>
                <p><strong>Paper Abstract:</strong> Protein structure prediction has undergone transformative advancements with AlphaFold2 achieving near-experimental accuracy across extensive protein datasets. This study reproduces and validates the AF2Rank pipeline, which utilizes AlphaFold’s intrinsic confidence metrics—predicted Local Distance Difference Test (pLDDT) and predicted Template Modeling score (pTM)—to evaluate and rank decoy protein structures without dependence on multiple sequence alignments (MSAs). The pipeline was implemented locally using the Rosetta decoy dataset, overcoming reproducibility challenges such as software dependency conflicts, residue indexing inconsistencies, and system-level execution issues. This framework successfully enabled high-confidence evaluation of over 1000 decoys for a benchmark target (1a32), with ongoing expansion to 133 protein targets. Notably, we discovered that AlphaFold confidence metrics encode protein-specific “fingerprints,” enabling reverse classification of structures to their source proteins. Our XGBoost-based classifier achieved 61.5% accuracy across 133 distinct protein targets, substantially exceeding random chance (0.75%). Feature importance analysis revealed that traditional energy functions (Rosetta normalized score, 26%) and derived interaction features (pLDDT-pTM ratio, 16%) provide the strongest discriminative power, suggesting AlphaFold metrics capture meaningful biological and structural information beyond generic quality assessment. Building upon this foundation, a novel hypothesis is introduced: Context-Aware Refinement of AlphaFold Predictions (CAR-AF). This approach postulates that AlphaFold-predicted structures may be further improved through refinement in the presence of their native binding partners—such as receptors or ligands—thereby producing conformations that are both structurally and functionally enhanced. The proposed methodology comprises four stages: generation of initial predictions via AlphaFold, structural modeling of relevant binding partners, docking of predicted proteins into these biological contexts, and refinement of the resulting complexes using molecular modeling tools such as Rosetta or HADDOCK. Structural and energetic metrics including TM-score, RMSD, and binding energy will be used to assess potential improvements in predictive quality.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1861.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1861.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that use computational predictions, proxy metrics, or surrogate objectives followed by experimental or ground-truth validation, including quantitative measures of agreement, disagreement, false positive rates, and factors affecting prediction accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AF2Rank / AlphaFold confidence metrics</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AF2Rank pipeline using AlphaFold2 intrinsic confidence metrics (pLDDT, pTM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Implementation of the AF2Rank approach that uses AlphaFold2's intrinsic confidence scores (per-residue pLDDT averaged to a global score, and pTM) as proxy metrics to evaluate and rank Rosetta decoy structures without MSAs, validated by comparison to native-structure alignment metrics (TM-score, RMSD, GDT_TS).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>AF2Rank: An AlphaFold2-based protein model quality assessment approach.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>AlphaFold2 / AF2Rank pipeline (pLDDT, pTM based ranking)</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>protein structure prediction</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_description</strong></td>
                            <td>AlphaFold-generated confidence metrics used as surrogate objectives for structural correctness: pLDDT (predicted Local Distance Difference Test; per-residue, averaged to a global score), pTM (predicted TM-score). These are used to rank decoy models and predict proximity to native structure without computing MSAs for each decoy.</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_type</strong></td>
                            <td>data-driven ML</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_description</strong></td>
                            <td>Structural similarity to experimentally-derived native structures computed via TM-score (structural alignment), RMSD (root-mean-square deviation to native), and GDT_TS; native structures referenced in the Rosetta decoy dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>quantitative_gap_measure</strong></td>
                            <td>Observed Pearson correlation coefficient r = 0.82 between pLDDT and TM-score (paper-reported). tm_diff (ptm - tm_out) distribution peaks near 1.0 indicating close correspondence in many cases; additional correlation heatmap qualitatively shows strong positive correlations between pLDDT/pTM and TM-score/GDT_TS and negative correlation of RMSD with quality metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_performance</strong></td>
                            <td>Strong statistical association with ground-truth metrics within this dataset: pLDDT vs TM-score Pearson r = 0.82; pLDDT and pTM distributions are right-skewed with many high-confidence predictions across decoys.</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_performance</strong></td>
                            <td>TM-score and GDT_TS distributions show multimodal populations with pronounced peaks in high-accuracy region (no single summary numeric performance metric over the entire dataset reported beyond descriptive distributions).</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_extrapolation_distance</strong></td>
                            <td>Dataset includes diverse decoys (Rosetta decoy set) across 133 protein targets and 50–300+ residue sizes; includes designs and decoys that may lack evolutionary signal (MSA-poor cases), but no explicit quantification of in-distribution vs out-of-distribution performance or extrapolation distance is provided.</td>
                        </tr>
                        <tr>
                            <td><strong>gap_varies_with_novelty</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>gap_variation_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>incremental_vs_transformational</strong></td>
                            <td>Paper frames AF2Rank as an incremental practical method to use AlphaFold confidence metrics for high-throughput decoy ranking without MSAs; does not quantify differential performance on known vs novel/breakthrough cases.</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_or_uncertainty</strong></td>
                            <td>AlphaFold provides pLDDT/pTM as internal confidence scores; calibration is discussed qualitatively via correlation with TM-score (r = 0.82) but no formal calibration metrics (e.g., calibration curves, Brier score) are reported.</td>
                        </tr>
                        <tr>
                            <td><strong>bias_correction_methods</strong></td>
                            <td>No explicit bias-correction between the proxies and ground truth is applied; the pipeline normalizes Rosetta energy (rosetta_norm) and engineers ratio/interaction features for downstream analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_or_maturity_effects</strong></td>
                            <td>Paper notes AlphaFold's general maturity and cites CASP14 performance (median GDT 92.4) as background but does not present a temporal comparison of proxy-ground-truth gap over time within the study.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_factors</strong></td>
                            <td>Identified factors affecting proxy-ground-truth gap: multi-chain/quaternary assembly prediction difficulty, flexible/disordered regions (intrinsically disordered regions), paucity of homologs/MSAs for some proteins (~10–15% 'orphans'), and accuracy of binding-partner models for context-aware refinement.</td>
                        </tr>
                        <tr>
                            <td><strong>multiple_proxy_comparison</strong></td>
                            <td>Multiple metrics compared and correlated: pLDDT, pTM, TM-score, GDT_TS, RMSD, and Rosetta energy. Feature-importance analysis in downstream ML shows rosetta_norm (26%) and derived interaction features (plddt_ptm_ratio 16%) as top contributors, and combined AlphaFold-derived metrics contribute substantially to predictive power (combined contribution reported as 74%).</td>
                        </tr>
                        <tr>
                            <td><strong>sample_size</strong></td>
                            <td>Approximately 145,000 decoy structures across 133 protein targets (500–1,500 decoys per target); initial benchmark run on target 1a32 processed >1,000 decoys to validate pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>cost_or_resource_discussion</strong></td>
                            <td>Processing 145k decoys through AlphaFold required significant computational resources; authors describe dependency and resource challenges and that the AF2Rank approach avoids MSA generation and requires less resource than full AlphaFold predictions, enabling higher throughput evaluation (qualitative discussion, no cost figures).</td>
                        </tr>
                        <tr>
                            <td><strong>exceptional_cases</strong></td>
                            <td>pLDDT distribution is described as bimodal for decoys of target 1a32 with higher scores corresponding to structures closer to native; tm_diff has a peak near 1.0 indicating many decoys where predicted TM aligns with actual TM, representing cases of strong agreement.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_discussion</strong></td>
                            <td>Limitations noted include heavy computational cost for large-scale processing, varying decoy counts per target (class imbalance), potential memory limitations requiring chunked processing, and reduced reliability for complexes, flexible/disordered regions, or when binding-partner structures are inaccurate; no per-target FPR/FNR statistics are provided.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1861.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1861.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that use computational predictions, proxy metrics, or surrogate objectives followed by experimental or ground-truth validation, including quantitative measures of agreement, disagreement, false positive rates, and factors affecting prediction accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Reverse classification (XGBoost)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>XGBoost classifier trained on engineered AlphaFold-derived features and Rosetta energy to predict decoy protein target</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A machine-learning reverse-classification system that uses 17 engineered features derived from AlphaFold confidence metrics (pLDDT, pTM, interactions, ratios) and normalized Rosetta energy to predict which of 133 protein targets a decoy originates from, evaluated on held-out data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>XGBoost classifier on AlphaFold-derived and Rosetta features</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>protein structure prediction / model quality assessment</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_description</strong></td>
                            <td>Feature vector composed of AlphaFold confidence metrics (plddt, ptm), derived ratios and interaction terms (plddt_ptm_ratio, plddt_tm, ptm_gdt, squares), TM-score calculations and deviations (tm_out, tm_diff), GDT_TS, RMSD, and normalized Rosetta energy (rosetta_norm). The proxy objective is to map these surrogate signals to the discrete class label (origin protein).</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_type</strong></td>
                            <td>data-driven ML</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_description</strong></td>
                            <td>Ground truth is the true protein target identity for each decoy (labels in the Rosetta decoy dataset), used to compute classification accuracy and confusion matrices on held-out test data.</td>
                        </tr>
                        <tr>
                            <td><strong>quantitative_gap_measure</strong></td>
                            <td>Classifier achieves 61.5% accuracy on the test set (133 classes) versus random-chance baseline of 0.75% (1/133). Confusion analysis shows misclassification patterns correlated with structural topology similarity but no per-class precision/recall or FPR/FNR numbers are reported in the text (confusion matrix figure shown qualitatively). Feature importance: rosetta_norm 26%, plddt_ptm_ratio 16%, tm_out 12%, gdt_ts 12%, ptm 11%, plddt_tm 11%, plddt 10%.</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_performance</strong></td>
                            <td>Optimized XGBoost test accuracy = 61.5% (after Optuna hyperparameter optimization and feature selection to seven top features).</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_performance</strong></td>
                            <td>Same as proxy performance because the classifier predicts true labels: test accuracy 61.5%; no external experimental validation beyond dataset labels.</td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_extrapolation_distance</strong></td>
                            <td>Task is largely within-distribution classification across 133 known targets (dataset split stratified); paper does not report explicit out-of-distribution or novel-target experiments or numeric measures of extrapolation distance.</td>
                        </tr>
                        <tr>
                            <td><strong>gap_varies_with_novelty</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>gap_variation_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>incremental_vs_transformational</strong></td>
                            <td>Authors present this as a novel application (reverse classification) but framed as an incremental demonstration that AlphaFold-derived metrics encode protein-specific fingerprints; no specific discussion of performance on breakthrough vs known cases.</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_or_uncertainty</strong></td>
                            <td>No calibration metrics for classifier probabilities are reported (no Brier score, reliability diagrams). Hyperparameter optimization performed with Optuna; stratified data splits used to mitigate bias.</td>
                        </tr>
                        <tr>
                            <td><strong>bias_correction_methods</strong></td>
                            <td>Data stratification across training/validation/test (80/10/10) to ensure balanced class representation; memory and processing mitigations applied but no explicit statistical bias-correction methods beyond stratification and feature normalization.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_or_maturity_effects</strong></td>
                            <td>Not discussed for the classifier itself.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_factors</strong></td>
                            <td>Misclassification concentrated between proteins with similar structural topologies or functional domains, indicating that structural similarity reduces discriminability between classes. Varying numbers of decoys per target required stratification to avoid bias.</td>
                        </tr>
                        <tr>
                            <td><strong>multiple_proxy_comparison</strong></td>
                            <td>The classifier leverages multiple proxies jointly (AlphaFold metrics + Rosetta energy + structural alignment metrics); feature-importance analysis quantifies their relative contributions and shows that combining traditional energy (rosetta_norm) with AlphaFold-derived interaction features yields the best discriminative performance.</td>
                        </tr>
                        <tr>
                            <td><strong>sample_size</strong></td>
                            <td>Total dataset ≈ 145,000 decoys across 133 targets; dataset split for ML: training 80%, validation 10%, test 10% (stratified). Exact counts per split not enumerated but consistent with these proportions.</td>
                        </tr>
                        <tr>
                            <td><strong>cost_or_resource_discussion</strong></td>
                            <td>Training required large feature matrices and memory optimizations (chunked processing, float32 usage); hyperparameter search (200 Optuna trials for XGBoost) used computational resources but no wall-time or dollar cost provided.</td>
                        </tr>
                        <tr>
                            <td><strong>exceptional_cases</strong></td>
                            <td>Confusion matrix shows diagonal dominance (many correct predictions) but specific classes with near-perfect discrimination or near-total confusion are not numerically listed; misclassification concentrates among structurally similar proteins.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_discussion</strong></td>
                            <td>Limitations include class imbalance (varying decoy counts per target), potential overfitting needing careful hyperparameter tuning and cross-validation, and that the classifier's accuracy is dataset-dependent and not validated on truly novel proteins or external datasets.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1861.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1861.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems that use computational predictions, proxy metrics, or surrogate objectives followed by experimental or ground-truth validation, including quantitative measures of agreement, disagreement, false positive rates, and factors affecting prediction accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CAR-AF (Context-Aware Refinement)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Context-Aware Refinement of AlphaFold Predictions (CAR-AF)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A proposed hypothesis and methodology to refine AlphaFold-predicted protein structures by modeling them in the presence of native binding partners (receptors, ligands, other proteins) via docking and physics-based refinement to produce structures that are both structurally and functionally improved; presented as a proposed pipeline (prediction → context modeling → docking → refinement) with suggested validation metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>Proposed CAR-AF pipeline (AlphaFold prediction + binding-partner modeling + docking + Rosetta/HADDOCK/OpenMM refinement)</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>protein structure prediction / structural refinement / drug discovery</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_metric_description</strong></td>
                            <td>Proposed use of AlphaFold-predicted structures and AlphaFold confidence metrics as starting proxies for native conformation; proposed refinement objectives include docking scores, interface energy, and physics-based energies (Rosetta energy, binding energy ΔG) used as surrogate goals to move structures toward functionally relevant conformations.</td>
                        </tr>
                        <tr>
                            <td><strong>proxy_type</strong></td>
                            <td>hybrid physics-ML</td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_description</strong></td>
                            <td>Planned validation against experimentally determined complex structures (unbound vs complex forms) using structural metrics (TM-score, RMSD, GDT_TS to experimental complex), energetic comparisons (calculated binding energy ΔG vs experimentally measured affinities when available), and functional metrics (correlation to experimental binding affinities or activities).</td>
                        </tr>
                        <tr>
                            <td><strong>quantitative_gap_measure</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>proxy_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ground_truth_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_positive_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>false_negative_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_or_extrapolation_distance</strong></td>
                            <td>Proposed to be applied to systems where AlphaFold predictions might miss context-specific conformations (e.g., induced fit, allostery, receptor-bound states); no quantitative novelty/extrapolation metrics provided because CAR-AF is not yet implemented or validated in this study.</td>
                        </tr>
                        <tr>
                            <td><strong>gap_varies_with_novelty</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>gap_variation_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>incremental_vs_transformational</strong></td>
                            <td>Presented as a potentially transformational extension (incorporating biological context into refinement), but currently speculative; no empirical distinction provided between incremental vs transformational outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>calibration_or_uncertainty</strong></td>
                            <td>Authors recommend using standard structural/energetic metrics for evaluation but provide no uncertainty calibration procedures; caution about overfitting refinements to inaccurate receptor models is noted.</td>
                        </tr>
                        <tr>
                            <td><strong>bias_correction_methods</strong></td>
                            <td>Proposed safeguards include benchmarking on cases with known unbound and complex experimental structures and careful validation to avoid overfitting to inaccurate binding-partner models, but no concrete bias-correction algorithms are provided.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_or_maturity_effects</strong></td>
                            <td>Paper positions CAR-AF as a next-step research direction leveraging mature tools (AlphaFold, Rosetta, HADDOCK) but does not present temporal trend analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_specific_factors</strong></td>
                            <td>Potential limiting factors identified: accuracy of binding-partner models, reliability of docking to find native binding modes, induced-fit and conformational selection phenomena, flexibility/disordered regions, and risk of overfitting to incorrect receptor conformations.</td>
                        </tr>
                        <tr>
                            <td><strong>multiple_proxy_comparison</strong></td>
                            <td>Proposed to combine ML-derived confidence metrics (pLDDT, pTM) with docking scores and physics-based energy metrics (Rosetta, FoldX, calculated ΔG) and to compare improvements across these proxies versus experimental complexes.</td>
                        </tr>
                        <tr>
                            <td><strong>sample_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>cost_or_resource_discussion</strong></td>
                            <td>Authors note additional computational expense for modeling partners, docking and flexible refinement (Rosetta Relax, MD simulation), and the need for benchmarking on experimentally characterized complexes; no quantitative cost estimates provided.</td>
                        </tr>
                        <tr>
                            <td><strong>exceptional_cases</strong></td>
                            <td>No empirical exceptional cases presented; authors hypothesize CAR-AF may be most beneficial for receptor-bound, allosterically regulated, or induced-fit systems where standard context-free predictions miss functionally relevant conformations.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_discussion</strong></td>
                            <td>Primary limitations are speculative: dependency on accurate binding-partner structures and docking, potential to overfit refinements to inaccurate context models, and the need for robust validation against experimental complex structures before asserting benefit.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>AF2Rank: An AlphaFold2-based protein model quality assessment approach. <em>(Rating: 2)</em></li>
                <li>Highly accurate protein structure prediction with AlphaFold. <em>(Rating: 2)</em></li>
                <li>Protein complex prediction with AlphaFold-Multimer. <em>(Rating: 2)</em></li>
                <li>State-of-the-Art Estimation of Protein Model Accuracy Using AlphaFold. <em>(Rating: 2)</em></li>
                <li>Practically useful: what the Rosetta protein modeling suite can do for you. <em>(Rating: 2)</em></li>
                <li>The HADDOCK2.2 Web Server: User-Friendly Integrative Modeling of Biomolecular Complexes. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1861",
    "paper_id": "paper-278429735",
    "extraction_schema_id": "extraction-schema-35",
    "extracted_data": [
        {
            "name_short": "AF2Rank / AlphaFold confidence metrics",
            "name_full": "AF2Rank pipeline using AlphaFold2 intrinsic confidence metrics (pLDDT, pTM)",
            "brief_description": "Implementation of the AF2Rank approach that uses AlphaFold2's intrinsic confidence scores (per-residue pLDDT averaged to a global score, and pTM) as proxy metrics to evaluate and rank Rosetta decoy structures without MSAs, validated by comparison to native-structure alignment metrics (TM-score, RMSD, GDT_TS).",
            "citation_title": "AF2Rank: An AlphaFold2-based protein model quality assessment approach.",
            "mention_or_use": "use",
            "system_or_method_name": "AlphaFold2 / AF2Rank pipeline (pLDDT, pTM based ranking)",
            "domain": "protein structure prediction",
            "proxy_metric_description": "AlphaFold-generated confidence metrics used as surrogate objectives for structural correctness: pLDDT (predicted Local Distance Difference Test; per-residue, averaged to a global score), pTM (predicted TM-score). These are used to rank decoy models and predict proximity to native structure without computing MSAs for each decoy.",
            "proxy_type": "data-driven ML",
            "ground_truth_description": "Structural similarity to experimentally-derived native structures computed via TM-score (structural alignment), RMSD (root-mean-square deviation to native), and GDT_TS; native structures referenced in the Rosetta decoy dataset.",
            "quantitative_gap_measure": "Observed Pearson correlation coefficient r = 0.82 between pLDDT and TM-score (paper-reported). tm_diff (ptm - tm_out) distribution peaks near 1.0 indicating close correspondence in many cases; additional correlation heatmap qualitatively shows strong positive correlations between pLDDT/pTM and TM-score/GDT_TS and negative correlation of RMSD with quality metrics.",
            "proxy_performance": "Strong statistical association with ground-truth metrics within this dataset: pLDDT vs TM-score Pearson r = 0.82; pLDDT and pTM distributions are right-skewed with many high-confidence predictions across decoys.",
            "ground_truth_performance": "TM-score and GDT_TS distributions show multimodal populations with pronounced peaks in high-accuracy region (no single summary numeric performance metric over the entire dataset reported beyond descriptive distributions).",
            "false_positive_rate": null,
            "false_negative_rate": null,
            "novelty_or_extrapolation_distance": "Dataset includes diverse decoys (Rosetta decoy set) across 133 protein targets and 50–300+ residue sizes; includes designs and decoys that may lack evolutionary signal (MSA-poor cases), but no explicit quantification of in-distribution vs out-of-distribution performance or extrapolation distance is provided.",
            "gap_varies_with_novelty": null,
            "gap_variation_details": null,
            "incremental_vs_transformational": "Paper frames AF2Rank as an incremental practical method to use AlphaFold confidence metrics for high-throughput decoy ranking without MSAs; does not quantify differential performance on known vs novel/breakthrough cases.",
            "calibration_or_uncertainty": "AlphaFold provides pLDDT/pTM as internal confidence scores; calibration is discussed qualitatively via correlation with TM-score (r = 0.82) but no formal calibration metrics (e.g., calibration curves, Brier score) are reported.",
            "bias_correction_methods": "No explicit bias-correction between the proxies and ground truth is applied; the pipeline normalizes Rosetta energy (rosetta_norm) and engineers ratio/interaction features for downstream analysis.",
            "temporal_or_maturity_effects": "Paper notes AlphaFold's general maturity and cites CASP14 performance (median GDT 92.4) as background but does not present a temporal comparison of proxy-ground-truth gap over time within the study.",
            "domain_specific_factors": "Identified factors affecting proxy-ground-truth gap: multi-chain/quaternary assembly prediction difficulty, flexible/disordered regions (intrinsically disordered regions), paucity of homologs/MSAs for some proteins (~10–15% 'orphans'), and accuracy of binding-partner models for context-aware refinement.",
            "multiple_proxy_comparison": "Multiple metrics compared and correlated: pLDDT, pTM, TM-score, GDT_TS, RMSD, and Rosetta energy. Feature-importance analysis in downstream ML shows rosetta_norm (26%) and derived interaction features (plddt_ptm_ratio 16%) as top contributors, and combined AlphaFold-derived metrics contribute substantially to predictive power (combined contribution reported as 74%).",
            "sample_size": "Approximately 145,000 decoy structures across 133 protein targets (500–1,500 decoys per target); initial benchmark run on target 1a32 processed &gt;1,000 decoys to validate pipeline.",
            "cost_or_resource_discussion": "Processing 145k decoys through AlphaFold required significant computational resources; authors describe dependency and resource challenges and that the AF2Rank approach avoids MSA generation and requires less resource than full AlphaFold predictions, enabling higher throughput evaluation (qualitative discussion, no cost figures).",
            "exceptional_cases": "pLDDT distribution is described as bimodal for decoys of target 1a32 with higher scores corresponding to structures closer to native; tm_diff has a peak near 1.0 indicating many decoys where predicted TM aligns with actual TM, representing cases of strong agreement.",
            "limitations_discussion": "Limitations noted include heavy computational cost for large-scale processing, varying decoy counts per target (class imbalance), potential memory limitations requiring chunked processing, and reduced reliability for complexes, flexible/disordered regions, or when binding-partner structures are inaccurate; no per-target FPR/FNR statistics are provided.",
            "uuid": "e1861.0"
        },
        {
            "name_short": "Reverse classification (XGBoost)",
            "name_full": "XGBoost classifier trained on engineered AlphaFold-derived features and Rosetta energy to predict decoy protein target",
            "brief_description": "A machine-learning reverse-classification system that uses 17 engineered features derived from AlphaFold confidence metrics (pLDDT, pTM, interactions, ratios) and normalized Rosetta energy to predict which of 133 protein targets a decoy originates from, evaluated on held-out data.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_or_method_name": "XGBoost classifier on AlphaFold-derived and Rosetta features",
            "domain": "protein structure prediction / model quality assessment",
            "proxy_metric_description": "Feature vector composed of AlphaFold confidence metrics (plddt, ptm), derived ratios and interaction terms (plddt_ptm_ratio, plddt_tm, ptm_gdt, squares), TM-score calculations and deviations (tm_out, tm_diff), GDT_TS, RMSD, and normalized Rosetta energy (rosetta_norm). The proxy objective is to map these surrogate signals to the discrete class label (origin protein).",
            "proxy_type": "data-driven ML",
            "ground_truth_description": "Ground truth is the true protein target identity for each decoy (labels in the Rosetta decoy dataset), used to compute classification accuracy and confusion matrices on held-out test data.",
            "quantitative_gap_measure": "Classifier achieves 61.5% accuracy on the test set (133 classes) versus random-chance baseline of 0.75% (1/133). Confusion analysis shows misclassification patterns correlated with structural topology similarity but no per-class precision/recall or FPR/FNR numbers are reported in the text (confusion matrix figure shown qualitatively). Feature importance: rosetta_norm 26%, plddt_ptm_ratio 16%, tm_out 12%, gdt_ts 12%, ptm 11%, plddt_tm 11%, plddt 10%.",
            "proxy_performance": "Optimized XGBoost test accuracy = 61.5% (after Optuna hyperparameter optimization and feature selection to seven top features).",
            "ground_truth_performance": "Same as proxy performance because the classifier predicts true labels: test accuracy 61.5%; no external experimental validation beyond dataset labels.",
            "false_positive_rate": null,
            "false_negative_rate": null,
            "novelty_or_extrapolation_distance": "Task is largely within-distribution classification across 133 known targets (dataset split stratified); paper does not report explicit out-of-distribution or novel-target experiments or numeric measures of extrapolation distance.",
            "gap_varies_with_novelty": null,
            "gap_variation_details": null,
            "incremental_vs_transformational": "Authors present this as a novel application (reverse classification) but framed as an incremental demonstration that AlphaFold-derived metrics encode protein-specific fingerprints; no specific discussion of performance on breakthrough vs known cases.",
            "calibration_or_uncertainty": "No calibration metrics for classifier probabilities are reported (no Brier score, reliability diagrams). Hyperparameter optimization performed with Optuna; stratified data splits used to mitigate bias.",
            "bias_correction_methods": "Data stratification across training/validation/test (80/10/10) to ensure balanced class representation; memory and processing mitigations applied but no explicit statistical bias-correction methods beyond stratification and feature normalization.",
            "temporal_or_maturity_effects": "Not discussed for the classifier itself.",
            "domain_specific_factors": "Misclassification concentrated between proteins with similar structural topologies or functional domains, indicating that structural similarity reduces discriminability between classes. Varying numbers of decoys per target required stratification to avoid bias.",
            "multiple_proxy_comparison": "The classifier leverages multiple proxies jointly (AlphaFold metrics + Rosetta energy + structural alignment metrics); feature-importance analysis quantifies their relative contributions and shows that combining traditional energy (rosetta_norm) with AlphaFold-derived interaction features yields the best discriminative performance.",
            "sample_size": "Total dataset ≈ 145,000 decoys across 133 targets; dataset split for ML: training 80%, validation 10%, test 10% (stratified). Exact counts per split not enumerated but consistent with these proportions.",
            "cost_or_resource_discussion": "Training required large feature matrices and memory optimizations (chunked processing, float32 usage); hyperparameter search (200 Optuna trials for XGBoost) used computational resources but no wall-time or dollar cost provided.",
            "exceptional_cases": "Confusion matrix shows diagonal dominance (many correct predictions) but specific classes with near-perfect discrimination or near-total confusion are not numerically listed; misclassification concentrates among structurally similar proteins.",
            "limitations_discussion": "Limitations include class imbalance (varying decoy counts per target), potential overfitting needing careful hyperparameter tuning and cross-validation, and that the classifier's accuracy is dataset-dependent and not validated on truly novel proteins or external datasets.",
            "uuid": "e1861.1"
        },
        {
            "name_short": "CAR-AF (Context-Aware Refinement)",
            "name_full": "Context-Aware Refinement of AlphaFold Predictions (CAR-AF)",
            "brief_description": "A proposed hypothesis and methodology to refine AlphaFold-predicted protein structures by modeling them in the presence of native binding partners (receptors, ligands, other proteins) via docking and physics-based refinement to produce structures that are both structurally and functionally improved; presented as a proposed pipeline (prediction → context modeling → docking → refinement) with suggested validation metrics.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "system_or_method_name": "Proposed CAR-AF pipeline (AlphaFold prediction + binding-partner modeling + docking + Rosetta/HADDOCK/OpenMM refinement)",
            "domain": "protein structure prediction / structural refinement / drug discovery",
            "proxy_metric_description": "Proposed use of AlphaFold-predicted structures and AlphaFold confidence metrics as starting proxies for native conformation; proposed refinement objectives include docking scores, interface energy, and physics-based energies (Rosetta energy, binding energy ΔG) used as surrogate goals to move structures toward functionally relevant conformations.",
            "proxy_type": "hybrid physics-ML",
            "ground_truth_description": "Planned validation against experimentally determined complex structures (unbound vs complex forms) using structural metrics (TM-score, RMSD, GDT_TS to experimental complex), energetic comparisons (calculated binding energy ΔG vs experimentally measured affinities when available), and functional metrics (correlation to experimental binding affinities or activities).",
            "quantitative_gap_measure": null,
            "proxy_performance": null,
            "ground_truth_performance": null,
            "false_positive_rate": null,
            "false_negative_rate": null,
            "novelty_or_extrapolation_distance": "Proposed to be applied to systems where AlphaFold predictions might miss context-specific conformations (e.g., induced fit, allostery, receptor-bound states); no quantitative novelty/extrapolation metrics provided because CAR-AF is not yet implemented or validated in this study.",
            "gap_varies_with_novelty": null,
            "gap_variation_details": null,
            "incremental_vs_transformational": "Presented as a potentially transformational extension (incorporating biological context into refinement), but currently speculative; no empirical distinction provided between incremental vs transformational outcomes.",
            "calibration_or_uncertainty": "Authors recommend using standard structural/energetic metrics for evaluation but provide no uncertainty calibration procedures; caution about overfitting refinements to inaccurate receptor models is noted.",
            "bias_correction_methods": "Proposed safeguards include benchmarking on cases with known unbound and complex experimental structures and careful validation to avoid overfitting to inaccurate binding-partner models, but no concrete bias-correction algorithms are provided.",
            "temporal_or_maturity_effects": "Paper positions CAR-AF as a next-step research direction leveraging mature tools (AlphaFold, Rosetta, HADDOCK) but does not present temporal trend analysis.",
            "domain_specific_factors": "Potential limiting factors identified: accuracy of binding-partner models, reliability of docking to find native binding modes, induced-fit and conformational selection phenomena, flexibility/disordered regions, and risk of overfitting to incorrect receptor conformations.",
            "multiple_proxy_comparison": "Proposed to combine ML-derived confidence metrics (pLDDT, pTM) with docking scores and physics-based energy metrics (Rosetta, FoldX, calculated ΔG) and to compare improvements across these proxies versus experimental complexes.",
            "sample_size": null,
            "cost_or_resource_discussion": "Authors note additional computational expense for modeling partners, docking and flexible refinement (Rosetta Relax, MD simulation), and the need for benchmarking on experimentally characterized complexes; no quantitative cost estimates provided.",
            "exceptional_cases": "No empirical exceptional cases presented; authors hypothesize CAR-AF may be most beneficial for receptor-bound, allosterically regulated, or induced-fit systems where standard context-free predictions miss functionally relevant conformations.",
            "limitations_discussion": "Primary limitations are speculative: dependency on accurate binding-partner structures and docking, potential to overfit refinements to inaccurate context models, and the need for robust validation against experimental complex structures before asserting benefit.",
            "uuid": "e1861.2"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "AF2Rank: An AlphaFold2-based protein model quality assessment approach.",
            "rating": 2
        },
        {
            "paper_title": "Highly accurate protein structure prediction with AlphaFold.",
            "rating": 2
        },
        {
            "paper_title": "Protein complex prediction with AlphaFold-Multimer.",
            "rating": 2
        },
        {
            "paper_title": "State-of-the-Art Estimation of Protein Model Accuracy Using AlphaFold.",
            "rating": 2
        },
        {
            "paper_title": "Practically useful: what the Rosetta protein modeling suite can do for you.",
            "rating": 2
        },
        {
            "paper_title": "The HADDOCK2.2 Web Server: User-Friendly Integrative Modeling of Biomolecular Complexes.",
            "rating": 1
        }
    ],
    "cost": 0.014458499999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>AF2Rank Revisited: Reproducing AlphaFold-Based Structure Evaluation and a Hypothesis for Context-Aware Refinement (CAR-AF)</p>
<p>Priyanshu Kumar 
Chandigarh University Mohali
India</p>
<p>B E Biotechnology 
Chandigarh University Mohali
India</p>
<p>AF2Rank Revisited: Reproducing AlphaFold-Based Structure Evaluation and a Hypothesis for Context-Aware Refinement (CAR-AF)
797A1EACD27EC99074795C7343FC656EAlphaFoldProtein Model Quality AssessmentAF2RankContext-Aware Refinement (CAR-AF)Structural Bioinformatics
Protein structure prediction has undergone transformative advancements with AlphaFold2 achieving nearexperimental accuracy across extensive protein datasets.This study reproduces and validates the AF2Rank pipeline, which utilizes AlphaFold's intrinsic confidence metrics-predicted Local Distance Difference Test (pLDDT) and predicted Template Modeling score (pTM)-to evaluate and rank decoy protein structures without dependence on multiple sequence alignments (MSAs).The pipeline was implemented locally using the Rosetta decoy dataset, overcoming reproducibility challenges such as software dependency conflicts, residue indexing inconsistencies, and system-level execution issues.This framework successfully enabled high-confidence evaluation of over 1000 decoys for a benchmark target (1a32), with ongoing expansion to 133 protein targets.Notably, we discovered that AlphaFold confidence metrics encode protein-specific "fingerprints," enabling reverse classification of structures to their source proteins.Our XGBoost-based classifier achieved 61.5% accuracy across 133 distinct protein targets, substantially exceeding random chance (0.75%).Feature importance analysis revealed that traditional energy functions (Rosetta normalized score, 26%) and derived interaction features (pLDDT-pTM ratio, 16%) provide the strongest discriminative power, suggesting AlphaFold metrics capture meaningful biological and structural information beyond generic quality assessment.Building upon this foundation, a novel hypothesis is introduced: Context-Aware Refinement of AlphaFold Predictions (CAR-AF).This approach postulates that AlphaFold-predicted structures may be further improved through refinement in the presence of their native binding partners-such as receptors or ligands-thereby producing conformations that are both structurally and functionally enhanced.The proposed methodology comprises four stages: generation of initial predictions via AlphaFold, structural modeling of relevant binding partners, docking of predicted proteins into these biological contexts, and refinement of the resulting complexes using molecular modeling tools such as Rosetta or HADDOCK.Structural and energetic metrics including TM-score, RMSD, and binding energy will be used to assess potential improvements in predictive quality.</p>
<p>I. INTRODUCTION</p>
<p>Proteins serve as the molecular workhorses of life, executing essential functions such as catalysis, transport, and structural support.Accurately determining a protein's threedimensional conformation is crucial for understanding its biological role and guiding rational design in drug discovery, enzyme engineering, and other biotechnological applications.Historically, experimental methods like X-ray crystallography or NMR spectroscopy were the primary means of resolving protein structures, but these approaches can be labor-intensive, expensive, and limited in throughput.</p>
<p>Recent innovations in machine learning, most notably Al-phaFold2 [1], have revolutionized computational protein structure prediction by providing near-experimental accuracy for a wide range of proteins.AlphaFold2 achieved unprecedented performance at CASP14 (Critical Assessment of protein Structure Prediction) [15], with a median GDT (Global Distance Test) score of 92.4 across targets.While AlphaFold offers confidence metrics such as predicted Local Distance Difference Test (pLDDT) and predicted Template Modeling score (pTM) to judge the reliability of its models, the full potential of these scores remains only partially explored.</p>
<p>The AF2Rank pipeline, proposed by Jing et al. [2], demonstrated that AlphaFold's internal scoring mechanisms could be used to compare and rank decoy structures without reliance on multiple sequence alignments (MSAs) or extensive computational resources.This approach offers significant advantages for high-throughput structure evaluation, particularly when dealing with novel protein designs or sequences with limited evolutionary information.</p>
<p>This study addresses two primary objectives: (1) to reproduce and validate the AF2Rank methodology in a local computing environment, and (2) to propose a novel hypothesis for Context-Aware Refinement of AlphaFold Predictions (CAR-AF).The AF2Rank reproduction involved overcoming numerous technical challenges, including dependency conflicts, system compatibility issues, and data formatting constraints.Upon successful implementation, the pipeline was applied to evaluate protein structure decoys from the Rosetta dataset.</p>
<p>The CAR-AF hypothesis represents a conceptual extension beyond isolated structure prediction.It posits that AlphaFold predictions, while highly accurate in isolation, might benefit from refinement within their biological context-such as in the presence of binding partners, ligands, or receptors.This approach acknowledges that proteins in biological systems rarely function in isolation, but rather adapt their conformations in response to molecular interactions [13].By integrating contextual information into the refinement process, the CAR-AF methodology aims to bridge the gap between geometric accuracy and functional relevance in protein structure prediction.</p>
<p>II. BACKGROUND AND MOTIVATION</p>
<p>The number of sequenced proteins is growing at a staggering pace.Public repositories such as UniProt contain roughly 220 million protein entries, yet only about 180,000 of these have experimentally determined structures [3].This immense gap between sequence data and available structural information poses a critical challenge in molecular biology and drug discovery.Although methods like X-ray crystallography, Nuclear Magnetic Resonance (NMR), and cryoelectron microscopy have provided high-resolution insight into many structures, they are notoriously time-consuming, costly, and often fail for large or flexible proteins.A typical crystallography project may require 6-18 months of dedicated effort, with success rates as low as 30% for novel proteins.Similarly, high-resolution cryo-EM studies might cost upwards of $100,000 per structure and require specialized equipment with lengthy wait times for access.Accelerating structure determination is thus a top priority: beyond its scientific value, a fast and reliable pipeline could inspire solutions to widespread problems ranging from rising global temperatures to the urgent need for sustainable waste management.</p>
<p>While single-protein structure prediction has historically received the most attention, many essential biological functions depend on multi-chain protein complexes.Approximately 65% of proteins in eukaryotic cells function as part of complexes rather than as isolated entities.Accurately predicting these quaternary structures remains an active frontier.Traditional template-based and free-docking approaches often struggle when homologous templates are sparse or when the complex contains flexible regions.Success rates for complex prediction using conventional docking methods rarely exceed 40% Much of the recent progress owes its origins to advances in coevolutionary analysis, where correlated mutations within MSAs highlighted physical proximity or inter-residue interactions [10].This approach laid the groundwork for neuralnetwork-based pipelines by identifying which amino acids likely contact one another in 3D space.Direct Coupling Analysis (DCA) methods, which can detect correlated evolutionary patterns across distant sites in sequences, achieved early successes with contact prediction accuracy rates of 70-80% for the top L/5 predicted contacts (where L is the sequence length).From there, models such as RoseTTAFold, OpenFold, and especially AlphaFold2 used deeper architectures (often transformer-based) and more sophisticated geometric constraints to achieve near-experimental accuracy [8].AlphaFold2, in particular, implemented a novel attention mechanism capable of learning complex patterns across both sequence and spatial dimensions simultaneously, allowing it to integrate evolutionary and physical information in ways previous methods could not [1].</p>
<p>The scientific imperative for accelerating structure determination extends beyond academic interest.Viral pandemics like COVID-19 demonstrated the critical importance of rapidly determining pathogen protein structures to develop countermeasures.Climate change mitigation requires innovative enzymes for carbon capture and utilization, while the growing crisis of antibiotic resistance necessitates new approaches to drug design targeting previously unexploited bacterial proteins.In each case, computational prediction offers a pathway to solutions that would be impractical through experimental methods alone due to time and resource constraints.</p>
<p>Despite these achievements, reliance on MSAs can become a bottleneck, especially for proteins with few known homologs or for de novo designs that lack evolutionary history.Approximately 10-15% of human proteins remain "orphans" with insufficient homologous sequences for reliable MSA construction.Moreover, multi-chain assemblies with complex interfaces are less straightforward to resolve, and proteins with flexible or disordered domains may require specialized strategies that go beyond the current scope of single-sequence predictions.Intrinsically disordered regions, which make up an estimated 30% of eukaryotic proteomes, pose particular challenges as they adopt multiple conformations that cannot be captured by a single structural model.</p>
<p>The economic impact of improved protein structure prediction is substantial.The pharmaceutical industry spends approximately 2.6 billion dollars and 10+ years developing each new drug, with a significant portion of that cost attributed to failed candidates due to unforeseen structural interactions.Computational approaches that accurately predict binding sites and off-target effects could dramatically reduce both cost and time-to-market.Similarly, enzyme engineering for industrial applications traditionally requires extensive directed evolution experiments spanning years; accurate structure prediction could potentially reduce this to months of primarily in silico work.</p>
<p>Our work proceeds from the premise that high-accuracy structural predictions can transform not only basic science but also applied sectors such as pharmaceuticals, bioengineering, and environmental management.By refining current AlphaFold-like methods and incorporating emerging techniques-such as multi-inference sampling, advanced quaternary modeling [4], and improvements to MSA-free prediction frameworks-we aim to bridge remaining gaps.</p>
<p>III. METHODOLOGY A. Reproducing AF2Rank Locally</p>
<p>The AF2Rank pipeline reproduction consisted of multiple technical components, from environment setup to data processing and evaluation.The implementation followed the methodology described in the original paper [2] but required several adaptations to ensure compatibility with local computing resources.</p>
<p>1) Computational Environment Setup: AlphaFold2 was configured on a local machine environment (Windows Subsystem for Linux), which necessitated resolving numerous dependency conflicts.Critical challenges included compatibility issues between JAX, TensorFlow, and CUDA versions; Python package version constraints specific to AlphaFold2; and compilation and installation of TM-score for structural comparison.The original AF2Rank script (test_templates.py)was adapted to function within this environment, with modifications to handle file path conventions, memory optimization, and batch processing capabilities.</p>
<p>2) Dataset Preparation: A Rosetta decoy dataset comprising 133 protein targets was utilized.Key characteristics of this dataset include approximately 145,000 total decoy structures, diversity in protein sizes (50-300+ residues), various structural topologies (α-helical, β-sheet, mixed α/β), and between 500-1,500 decoys per target protein.For initial validation, target 1a32 was selected as a benchmark, with over 1,000 decoy structures processed to confirm pipeline functionality before scaling to the complete dataset.</p>
<p>3) Scoring and Evaluation Process: Each decoy structure was processed through the adapted AF2Rank pipeline according to the following workflow: This process generated several key metrics for each decoy: pLDDT (per-residue confidence, averaged for global score), pTM (predicted Template Modeling score), TM-score (calculated against native structure), RMSD (Root Mean Square Deviation from native), GDT_TS (Global Distance Test score), and Rosetta energy (from original decoy data).All scores were consolidated into a comprehensive CSV file (rosetta_targetseq.csv),preserving target identifiers, decoy information, and the complete set of evaluation metrics.This dataset served as the foundation for subsequent analysis and machine learning tasks.
Algorithm 1 AF2Rank</p>
<p>B. Feature Engineering and Machine Learning Classification</p>
<p>Following successful reproduction of the AF2Rank pipeline, the study explored whether AlphaFold's scoring metrics contained sufficient information to uniquely identify each decoy's native protein target through a reverse classification approach.</p>
<p>1) Feature Engineering: From the consolidated dataset, 17 features were extracted and engineered to capture various aspects of the structural evaluation.The base features included direct metrics from the evaluation pipeline such as plddt (average per-residue confidence), ptm (predicted TM-score), tm_out (TM-score calculated against native structure), tm_diff (difference between ptm and tm_out), tmscore (alternative TM-score calculation), rmsd (Root Mean Square Deviation), gdt_ts (Global Distance Test score), and rosettascore (energy score from Rosetta).</p>
<p>Ratio features were developed to capture relationships between metrics, including plddt_ptm_ratio (ratio of plddt to ptm), tm_ratio (ratio between different TM-score calculations), and gdt_rmsd_ratio (relationship between global and local accuracy).Square features were introduced to capture non-linear effects, including plddt_squared (square of plddt), ptm_squared (square of ptm), and tm_out_squared (square of tm_out).</p>
<p>Interaction features represented metric interactions, specifically plddt_tm (product of plddt and tm_out) and ptm_gdt (product of ptm and gdt_ts).Finally, a normalized feature was included: rosetta_norm (normalized Rosetta energy score).The dataset was split into training (80%), validation (10%), and test (10%) sets, with stratification to ensure balanced representation of all 133 protein targets across the splits.</p>
<p>2) Model Development and Evaluation: Multiple machine learning algorithms were systematically evaluated for the classification task: Hyperparameter optimization was performed using Optuna, an automated hyperparameter search framework.For XG-Boost, the best-performing model, a comprehensive search across learning rate, tree depth, regularization parameters, and ensemble size was conducted over 200 trials.</p>
<p>3) Feature Importance Analysis: Analysis of feature importance in the optimized XGBoost model revealed that seven features contributed most significantly to classification performance.These included rosetta_norm (26% importance), plddt_ptm_ratio (16% importance), tm_out (12% importance), gdt_ts (12% importance), ptm (11% importance), plddt_tm (11% importance), and plddt (10% importance).These seven features were selected for the final model, effectively reducing dimensionality while maintaining predictive performance.Notably, the normalized Rosetta energy score (rosetta_norm) emerged as the single most important feature, suggesting that traditional energy functions retain significant discriminative power even in the context of deep learning-based evaluations [12].</p>
<p>4) Classification Workflow: The complete classification pipeline comprised the following steps: Algorithm 2 Reverse Classification Workflow Building upon the successful reproduction of AF2Rank and insights from the reverse classification analysis, this section introduces a novel hypothesis: Context-Aware Refinement of AlphaFold Predictions (CAR-AF).This concept proposes that protein structure predictions may be further improved by incorporating biological context during the refinement process.</p>
<p>A. Theoretical Foundation</p>
<p>While AlphaFold2 achieves remarkable accuracy in predicting isolated protein structures [5], biological proteins rarely function in isolation.Instead, they operate within complex environments where interactions with binding partners-such Fig. 2. Feature importance ranking from the optimized XGBoost classifier using AlphaFold-derived metrics.The normalized Rosetta energy score (rosetta_norm) contributes the most, followed by interaction and structural quality features.</p>
<p>as receptors, ligands, or other proteins-often induce conformational changes that are critical to their function.This phenomenon, known as induced fit or conformational selection, is well-documented in structural biology literature [13].</p>
<p>The CAR-AF hypothesis posits that AlphaFold predictions, while geometrically accurate, may not fully capture the functional conformations that emerge in biological contexts.By incorporating these contexts into the refinement process, predictions could be enhanced not only in terms of structural accuracy but also functional relevance.</p>
<p>This approach is particularly relevant for proteins whose functions depend critically on binding interactions, such as enzymes that undergo conformational changes upon substrate binding, receptor proteins that transmit signals through interface reorganization, allosteric proteins whose distant sites communicate through conformational coupling, and multimeric assemblies where interface stability influences subunit conformations [4].</p>
<p>B. Proposed Methodology</p>
<p>The CAR-AF methodology comprises four sequential stages, each building upon established techniques in computational structural biology:</p>
<p>1) Implementation Tools: The CAR-AF methodology can be implemented using a combination of established computational tools.For initial prediction, AlphaFold2 [1] or AlphaFold-Colab can be used for high-confidence structure generation.Structure preparation can be performed with Py-MOL or ChimeraX for cleaning structures and preparing docking inputs.Molecular docking can be accomplished using protein-protein tools such as ClusPro, HADDOCK [14], or RosettaDock [12], and protein-ligand tools such as AutoDock Vina or DOCK.</p>
<p>For refinement, Rosetta Relax [12] can be employed for flexible backbone refinement, ModRefiner for loop optimization, and OpenMM or GROMACS for molecular dynamics simulation.Evaluation can be conducted using TM-align for structural comparison, PROCHECK for stereochemical validation, and FoldX for stability assessment.</p>
<p>C. Validation Strategy</p>
<p>To assess the effectiveness of the CAR-AF approach, a systematic validation strategy is proposed.This includes benchmark selection by identifying proteins with known experimental structures in both unbound and complex forms.Performance metrics would encompass structural metrics (TMscore, RMSD, and GDT_TS compared to experimental complex), energetic metrics (binding energy calculations (∆G) and interface scores), and functional metrics (correlation with experimental binding affinities or activities where available).</p>
<p>Comparison protocols would include analysis of AlphaFold prediction versus CAR-AF refined structure versus experimental complex, examination of regions with significant conformational adjustments, and interface residue accuracy assessment [11].</p>
<p>D. Potential Applications and Impact</p>
<p>The CAR-AF methodology, if validated, could have significant implications across multiple domains.In drug discovery, more accurate modeling of protein-ligand interactions could improve virtual screening and lead optimization [9].For enzyme engineering, it could provide better prediction of substrate binding effects on enzyme conformation.In antibody design, it could enable enhanced modeling of antibodyantigen complexes.For protein-protein interaction networks, it could deliver more reliable structural models of interaction interfaces.In studying allosteric regulation, it could improve understanding of long-range conformational coupling [13].</p>
<p>The insights gained from this approach could fundamentally enhance our understanding of protein function beyond static structural characterization, bridging the gap between geometric accuracy and functional biology.</p>
<p>V. RESULTS</p>
<p>This section presents the findings from both the AF2Rank reproduction and the reverse classification machine learning approach.While the CAR-AF hypothesis is presented as a proposal for future work, preliminary insights supporting its potential are discussed.</p>
<p>A. AF2Rank Reproduction Outcomes</p>
<p>The reproduction of the AF2Rank pipeline was successfully accomplished, enabling local evaluation of protein structure decoys using AlphaFold's internal confidence metrics [2].Key outcomes include technical reproducibility, benchmark validation, scoring distribution analysis, and correlation with traditional metrics.</p>
<p>The AF2Rank pipeline was successfully implemented in a local computing environment, overcoming multiple technical challenges including dependency conflicts and computational resource limitations.Initial testing on target 1a32 with over 1,000 decoys confirmed the pipeline's functionality, with scoring patterns consistent with those reported in the original AF2Rank study [2].Analysis of the pLDDT scores across decoy structures revealed a bimodal distribution, with higher scores generally corresponding to structures closer to the native conformation.Strong correlation was observed between AlphaFold confidence scores (pLDDT, pTM) and traditional structural similarity metrics (TM-score, GDT_TS) calculated against native structures (Pearson correlation coefficient r = 0.82 for pLDDT vs. TM-score).</p>
<p>B. Classification Performance and Analysis</p>
<p>The machine learning approach to reverse classification-predicting the protein target of a decoy based solely on AlphaFold-derived confidence metrics and derived features-yielded compelling results.The optimized XGBoost  model achieved 61.5% accuracy on the test set across 133 distinct protein targets, substantially exceeding random chance (0.75% for 133 classes).Error analysis showed that misclassifications were not random but displayed clear patterns, with confusion primarily occurring between proteins with similar structural topologies or functional domains.The combined importance of AlphaFold metrics (pLDDT, pTM) and their derived features accounted for 74% of the model's predictive power, confirming that these scores capture protein-specific information [5].</p>
<p>These results confirm that AlphaFold confidence metrics encode protein-specific "fingerprints" that are sufficiently unique to enable discrimination among different protein targets with considerable accuracy.This finding supports the premise that these metrics capture meaningful biological and structural information beyond generic folding quality assessment [5].</p>
<p>C. Challenges and Limitations</p>
<p>Several challenges and limitations were encountered during this study.Processing the complete dataset of approximately 145,000 decoys through the AlphaFold pipeline required significant computational resources, necessitating batch processing and optimization strategies.The Rosetta decoy dataset contained varying numbers of decoys per target, requiring careful stratification during model training to prevent bias.</p>
<p>Working with large feature matrices for machine learning required memory optimization techniques, including implementation of chunked data processing, utilization of efficient data types (float32 instead of float64), and strategic garbage collection.Balancing model complexity with generalization capability required extensive hyperparameter tuning and crossvalidation.These challenges were systematically addressed through technical solutions and methodological adjustments, enabling successful completion of the study objectives.</p>
<p>VI. DISCUSSION</p>
<p>The findings from this study have several important implications for protein structure prediction, evaluation, and refinement.This section discusses the significance of the results and their potential impact on the field.</p>
<p>A. AF2Rank Reproducibility</p>
<p>The successful reproduction of the AF2Rank pipeline demonstrates that AlphaFold's internal scoring metrics can be reliably utilized for structure evaluation without requiring complex MSA construction or intensive computational resources [2].This has significant practical implications.By removing the dependency on MSA generation, protein  structure evaluation becomes more accessible to researchers without specialized evolutionary data analysis expertise.The streamlined pipeline requires significantly less computational resources than full AlphaFold predictions, enabling higher throughput evaluation of multiple decoys or design candidates.Additionally, the approach is particularly valuable for novel designed proteins or those with limited evolutionary information, where traditional MSA-based methods may be less effective.These advantages position AF2Rank as a valuable tool in the protein structure prediction and design workflow, offering a balance between accuracy and computational efficiency.</p>
<p>B. Biological Fingerprints in AlphaFold Metrics</p>
<p>The reverse classification results provide compelling evidence that AlphaFold confidence metrics capture proteinspecific information beyond generic structural quality assessment [5].This finding has several noteworthy implications.The ability to classify decoys to their correct protein targets with 61.5% accuracy across 133 classes demonstrates that scoring patterns contain protein-specific "fingerprints."The importance of derived features that capture interactions between different metrics (e.g., plddt_ptm_ratio, plddt_tm) suggests that relationships between confidence scores may be more informative than individual metrics in isolation.The significant contribution of rosetta_norm (26% importance) highlights the complementary nature of traditional energy functions and deep learning-based confidence metrics [12].These insights suggest that AlphaFold's scoring system implicitly learns structural patterns that are uniquely associated with specific proteins or protein families, which could be leveraged for various applications beyond simple structure ranking.</p>
<p>C. Potential Applications of Classification Approach</p>
<p>The reverse classification methodology demonstrated in this study opens up several potential applications.It could be used for structure quality control, identifying, and flagging decoys that may have been mislabeled or inappropriately grouped within structural databases.It could also enable structural similarity detection, identifying proteins with similar structural characteristics based on their AlphaFold scoring patterns [7].In addition, it could facilitate advanced error detection by developing more sophisticated error detection methods that go beyond simple confidence thresholds by considering the entire score pattern.Finally, it could be extended for protein family classification, classifying proteins into functional or evolutionary families based on structural signatures [9].These applications could contribute to better protein structure databases, more reliable structure prediction pipelines, and better understanding of protein structure-function relationships.</p>
<p>D. Context-Aware Refinement: From Concept to Implementation</p>
<p>The proposed CAR-AF hypothesis represents a logical extension of the insights gained from the AF2Rank reproduction and reverse classification experiments.If AlphaFold metrics can capture protein-specific information with such fidelity, then incorporating biological context into the refinement process could further enhance prediction accuracy and functional relevance [8].</p>
<p>Several considerations support the feasibility of this approach.The induced fit model of protein-ligand interactions is well-established in structural biology [13], suggesting that refinement in the presence of binding partners is biologically justified.The necessary computational tools (docking algorithms, refinement methods) are already available and wellvalidated [14].The approach leverages the complementary strengths of deep learning-based prediction (AlphaFold) and physics-based refinement (molecular mechanics, docking) [7].In addition, there are clear metrics to quantify potential improvements (TM-score, RMSD, binding energy) [11].</p>
<p>However, successful implementation will require addressing several challenges.The accuracy of the binding partner structures is critical and may be a limiting factor.Reliable identification of binding modes is essential for meaningful refinement [14].Care must be taken to ensure that refinements genuinely improve structural quality rather than overfitting to potentially inaccurate receptor models.A robust validation protocol that uses the experimental structures of protein complexes will be essential to evaluate the effectiveness of the method [15].Despite these challenges, the CAR-AF approach represents a promising direction for advancing protein structure prediction beyond isolated models toward functionally relevant conformational ensembles.</p>
<p>VII. CONCLUSION</p>
<p>This study has successfully addressed two complementary objectives: reproducing and validating the AF2Rank pipeline for protein structure evaluation, and proposing a novel hypothesis for Context-Aware Refinement of AlphaFold Predictions (CAR-AF).</p>
<p>The AF2Rank reproduction demonstrates that AlphaFold's internal confidence metrics can be effectively utilized for structure evaluation without requiring multiple sequence alignments [2], offering a computationally efficient alternative to traditional methods.Implementation in a local computing environment overcame several technical challenges, resulting in a robust pipeline capable of processing large-scale decoy datasets.</p>
<p>Analysis of these confidence metrics through machine learning revealed that they contain sufficient protein-specific information for reverse classification, achieving 61.5% precision in 133 protein targets.This finding confirms that AlphaFold scoring patterns represent unique "fingerprints" that distinguish different proteins, going beyond generic structural quality assessment [5].</p>
<p>Building on these insights, the CAR-AF hypothesis proposes that protein structure predictions could be further improved through refinement in the presence of their biological binding partners [4] [13].This approach acknowledges the importance of molecular context in determining functional protein conformations and offers a potential path to bridge the gap between geometric accuracy and functional relevance.</p>
<p>The integration of deep learning-based structure prediction with context-aware refinement represents a promising direction for advancing protein modeling beyond isolated structures toward functionally relevant ensembles [7].Although the CAR-AF approach awaits experimental validation, the theoretical foundation established in this study provides a clear framework for future research and implementation.</p>
<p>In conclusion, this work contributes to the field of protein structure prediction in three significant ways: (1) demonstrating the reproducibility and utility of AF2Rank for efficient structure evaluation [2], (2) revealing the presence of protein-specific signatures in AlphaFold confidence metrics [5], and (3) proposing a novel methodology for context-aware refinement that could enhance both structural accuracy and functional relevance of predicted protein models.</p>
<p>We invite the scientific community to build on these findings, particularly in testing and expanding the CAR-AF hypothesis through experimental validation.The integration of structural prediction with the biological context represents a promising frontier in computational structural biology with potential applications ranging from drug discovery to protein engineering.</p>
<p>VIII. FUTURE WORK</p>
<p>Several directions for future research emerge from this study.We aim to extend the AF2Rank evaluation to the full set of 133 protein targets and approximately 145,000 decoys to fully validate the pipeline.Further development of more sophisticated features that capture additional aspects of structural quality and protein-specific characteristics is planned [7].</p>
<p>Implementation of the proposed CAR-AF methodology on well-characterized protein-partner systems will begin with cases where experimental structures of both the isolated protein and its complexes are available [14].We also intend to establish a standardized benchmark for evaluating contextaware refinement approaches, ensuring fair comparison of different methodologies [15].</p>
<p>Exploring the possibility of integrating context-aware refinement directly into the AlphaFold prediction process could be accomplished through modified recycle steps that incorporate binding partner information [4].Finally, investigating the application of CAR-AF to predict protein conformational changes induced by small-molecule binding could potentially enhance structure-based drug design [13].</p>
<p>These future directions aim to build upon the foundation established in this study, advancing the field toward more accurate and functionally relevant protein structure predictions that account for the critical role of biological context.</p>
<p>It is anticipated that the CAR-AF hypothesis may expose biologically meaningful conformations that are often absent from standard, context-free structure prediction workflows-especially in receptor-bound or allosterically regulated protein states [13].Feedback and critical evaluation from domain experts are welcomed to assess the feasibility and potential of this approach in advancing context-integrated protein modeling.</p>
<p>Fig. 1 .
1
Fig. 1.Graphical Abstract of AF2Rank Reproduction and CAR-AF Hypothesis.This figure illustrates the three key components of our research.Left panel: The AF2Rank pipeline reproduction, which processes protein decoy structures through AlphaFold2 evaluation to generate confident structure quality assessments without multiple sequence alignments.Middle panel: Our novel reverse classification approach, achieving 61.5% accuracy in identifying protein targets across 133 classes based solely on AlphaFold confidence metrics, with rosetta_norm (26%) and plddt_ptm_ratio (16%) as the most discriminative features.Right panel: The proposed Context-Aware Refinement (CAR-AF) methodology, comprising four sequential stages: AlphaFold prediction, biological context modeling, molecular docking, and context-aware refinement.Bottom panel: Conceptual illustration of the CAR-AF process, from isolated structure prediction through complex formation to contextrefined structure, demonstrating how incorporating biological binding partners can enhance both structural accuracy and functional relevance of protein models.</p>
<p>Algorithm 3 1 : 1 :Fig. 3 .
3113
Fig. 3. Protein target clustering visualization using PCA.Each point represents a target colored by its cluster label.Despite dimensionality reduction, several clusters show clear separation, reinforcing the presence of targetspecific latent patterns in AlphaFold-derived features.</p>
<p>Fig. 4 .
4
Fig. 4. Correlation matrix of structural evaluation metrics.The heatmap displays Pearson correlation coefficients between key metrics, showing strong positive correlations between AlphaFold confidence metrics (pLDDT, pTM) and traditional structural similarity metrics (TM-score, GDT_TS).RMSD exhibits expected negative correlations with quality metrics, while Rosetta energy scores show moderate negative correlations with other measures.</p>
<p>Fig. 5 .
5
Fig. 5. Distribution of AlphaFold's intrinsic confidence metrics (pLDDT and pTM) across the decoy dataset, showing the range of structural quality predictions.Both metrics demonstrate a right-skewed distribution with the majority of values in the higher confidence range, indicating the effectiveness of AlphaFold in recognizing high-quality structures without MSA information.</p>
<p>Fig. 6 .
6
Fig. 6.Distribution of various structural alignment metrics comparing decoy structures to their native counterparts.The multimodal distribution of TMscore (tm_out) shows distinct populations of structures with varying degrees of similarity to the native state, while GDT_TS displays similar characteristics with pronounced peaks in the high-accuracy region.</p>
<p>Fig. 7 .
7
Fig. 7. Distribution of deviation metrics and energy scores across the decoy dataset.The tm_diff distribution shows strong correspondence between predicted and actual TM-scores with a peak near 1.0.RMSD values follow an expected pattern with predominantly low-to-moderate deviations.Rosetta energy scores exhibit a tight distribution around optimal values, complementing the AlphaFold metrics.</p>
<p>Fig. 8 .
8
Fig. 8. t-SNE visualization of high-dimensional feature space for 133 protein targets, using AlphaFold-derived scoring metrics.Clusters indicate targetspecific structural signatures, supporting the hypothesis that AlphaFold metrics encode biologically relevant fingerprints.</p>
<p>Fig. 9 .
9
Fig. 9. MDS visualization of AlphaFold-derived feature vectors across 133 protein targets.Compared to t-SNE, MDS shows reduced cluster separation, highlighting the limitations of linear dimensionality reduction in capturing complex structural patterns.</p>
<p>Fig. 10 .
10
Fig. 10.Cumulative explained variance plot from Principal Component Analysis (PCA) on AlphaFold-derived features.The first three components capture over 98% of the variance, supporting effective dimensionality reduction for downstream classification.</p>
<p>Fig. 11 .
11
Fig. 11.Confusion matrix of the reverse classification model highlighting the most confused protein target classes.Diagonal dominance reflects overall accuracy, while off-diagonal cells reveal structural similarities contributing to misclassification.</p>
<p>1 :
1
Input: Consolidated feature set from rosetta_targetseq.csv
2: Perform feature engineering (ratios, squares, interactions)3: Split data into training (80%), validation (10%), test (10%)4: Apply standard scaling to numerical features5: Encode target labels (133 protein classes)6: Train multiple model candidates on training set7: Select best model based on validation performance8: Optimize hyperparameters using Optuna9: Perform feature selection based on importance analysis10: Retrain final model with selected features and optimizedparameters11: Evaluate on held-out test set12: Output: Classification accuracy, confusion matrix, featureimportanceIV. CONTEXT-AWARE REFINEMENT OF ALPHAFOLDPREDICTIONS (CAR-AF)</p>
<p>Highly accurate protein structure prediction with AlphaFold. J Jumper, R Evans, A Pritzel, T Green, M Figurnov, O Ronneberger, K Tunyasuvunakool, R Bates, A Žídek, A Potapenko, A Bridgland, C Meyer, Saa Kohl, A J Ballard, A Cowie, B Romera-Paredes, S Nikolov, R Jain, J Adler, T Back, S Petersen, D Reiman, E Clancy, M Zielinski, M Steinegger, M Pacholska, T Berghammer, S Bodenstein, D Silver, O Vinyals, A W Senior, K Kavukcuoglu, P Kohli, D Hassabis, 10.1038/s41586-021-03819-2Nature. 59678732021 Aug</p>
<p>AF2Rank: An AlphaFold2-based protein model quality assessment approach. H Jing, C Zhang, R Liu, Y Zhang, 10.1016/j.jmb.2021.167425Journal of Molecular Biology. 43451674252022 Apr</p>
<p>AlphaFold Protein Structure Database: massively expanding the structural coverage of protein-sequence space with high-accuracy models. M Varadi, S Anyango, M Deshpande, S Nair, C Natassia, G Yordanova, D Yuan, O Stroe, G Wood, A Laydon, A Žídek, T Green, K Tunyasuvunakool, S Petersen, J Jumper, E Clancy, R Green, A Vora, M Lutfi, M Figurnov, A Cowie, N Hobbs, P Kohli, G Kleywegt, E Birney, D Hassabis, S Velankar, 10.1093/nar/gkab1061Nucleic Acids Research. 50D12022 Jan</p>
<p>Protein complex prediction with AlphaFold-Multimer. R Evans, O' Neill, M Pritzel, A Antropova, N Senior, A Green, T Žídek, A Bates, R Blackwell, S Yim, J Ronneberger, O Bodenstein, S Zielinski, M Bridgland, A Potapenko, A Cowie, A Tunyasuvunakool, K Jain, R Clancy, E Kohli, P Jumper, J Hassabis, D , 10.1101/2021.10.04.463034bioRxiv. 2021</p>
<p>State-of-the-Art Estimation of Protein Model Accuracy Using AlphaFold. J P Roney, 10.1021/acs.jcim.1c01472Journal of Chemical Information and Modeling. 6262022 Mar</p>
<p>Machine learning in protein structure prediction. M Alquraishi, 10.1016/j.cbpa.2021.04.005Current Opinion in Chemical Biology. 652021 Aug</p>
<p>Deep learning for protein structure prediction and design-progress and applications. J Jänes, P Beltrao, 10.1038/s41580-022-00531-5Nature Reviews Molecular Cell Biology. 242023 Jan</p>
<p>Improving deep learning protein monomer and complex structure prediction using DeepMSA2 with huge metagenomics data. W Zheng, L Freddolino, Q Wuyun, Y Li, Y Zhang, C Zhang, 10.1038/s41467-023-44370-0Nature Communications. 151342024 Jan</p>
<p>Enhancing Protein Function Prediction Performance by Utilizing AlphaFold-Predicted Protein Structures. W Ma, S Zhang, Z Li, M Jiang, S Wang, W Lu, X Bi, H Jiang, H Zhang, Z Wei, 10.1021/acs.jcim.2c00971Journal of Chemical Information and Modeling. 62212022 Nov</p>
<p>MMseqs2 enables sensitive protein sequence searching for the analysis of massive data sets. M Steinegger, J Söding, 10.1038/nbt.3988Nature Biotechnology. 35112017 Nov</p>
<p>QUARK-based protein structure modeling and refinement. C Zhang, Y Zhang, 10.1007/978-1-0716-0892-0_13Methods in Molecular Biology. 21992021</p>
<p>Practically useful: what the Rosetta protein modeling suite can do for you. K W Kaufmann, G H Lemmon, S L Deluca, J H Sheehan, J Meiler, 10.1021/bi902153gBiochemistry. 49142010 Apr</p>
<p>The role of dynamic conformational ensembles in biomolecular recognition. D D Boehr, R Nussinov, P E Wright, 10.1038/nchembio.232Nature Chemical Biology. 5112009 Nov</p>
<p>The HADDOCK2.2 Web Server: User-Friendly Integrative Modeling of Biomolecular Complexes. Gcp Van Zundert, Jpglm Rodrigues, M Trellet, C Schmitz, P L Kastritis, E Karaca, Asj Melquiond, M Van Dijk, S J De Vries, Amjj Bonvin, 10.1016/j.jmb.2015.09.014Journal of Molecular Biology. 42842016 Feb</p>
<p>Critical assessment of methods of protein structure prediction (CASP) -Round XIV. A Kryshtafovych, T Schwede, M Topf, K Fidelis, J Moult, 10.1002/prot.26237Proteins: Structure, Function, and Bioinformatics. 89122021 Dec</p>
<p>RNA Secondary Structure Prediction Using Transformer-Based Deep Learning Models. Recent Advances in Computational Biology. Y Zhou, T Zhan, Y Wu, B Song, C Shi, 10.1007/978-3-030-93158-2_3Bioinformatics and Biostatistics. 2022</p>            </div>
        </div>

    </div>
</body>
</html>