<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6900 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6900</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6900</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-133.html">extraction-schema-133</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <p><strong>Paper ID:</strong> paper-53396896</p>
                <p><strong>Paper Title:</strong> <a href="https://periodicos.ufsc.br/index.php/desterro/article/download/2175-8026.2011n60p105/19473" target="_blank">THE INVESTIGATION OF COMMONALITIES IN HUMAN BRAIN SEMANTIC REPRESENTATIONS ACROSS PEOPLE AND ACROSS LANGUAGES</a></p>
                <p><strong>Paper Abstract:</strong> Recent studies on the organization of conceptual knowledge in the human brain have reported the remarkable ability to predict the word a person is thinking about, or the picture a person is seeing, from their brain activity. By using Machine Learning techniques to analyze neuroimaging data, researchers have been able to find stable patterns of brain activity across different people. These patterns allow computer algorithms to identify the brain activity associated with a specific word or picture. The studies have also reported striking commonalities across different people’s neural signature for the conceptual knowledge associated with thinking about words. The communal characteristic of the organization of meaning allows for the prediction of what one person is thinking about based on another person’s brain activity. The results of some of these studies and the implications for research on cognitive processes and second language learning/acquisition are discussed. Preliminary results from a brain imaging study on cross-language thought identification are also presented. These 106 Augusto Buchweitz recent findings in neuroimaging of human semantics suggest the presence of a common semantic neural representation across people and across languages.</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6900.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6900.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Embodied cognition</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Embodied Cognition / Perceptual Symbol Systems (Barsalou, 1999)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Theory that conceptual knowledge is grounded in sensorimotor systems such that meaning representations contain perceptual and motor components (simulations) derived from interactions with the environment.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Perceptual symbol systems</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Embodied Cognition / Perceptual Symbol Systems</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>embodied simulation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual knowledge is functionally represented as modality-specific perceptual and motor simulations (re-activations) distributed across sensory and motor cortical systems rather than as amodal symbols.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Meaning representations include perceptual/motor features and can be re-instantiated as simulations; explains modality-specific activation during semantic tasks and links perception and cognition.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>fMRI studies cited (neuroimaging evidence showing modality-specific activations)</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>neuroimaging semantic tasks (word reading, picture viewing, imagining handling objects); MVPA classification of category-specific activation</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Areas associated with motor/perceptual processing (e.g., motor-related activation for tools) reliably predict semantic category, consistent with perceptual/motor components of meaning.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Buchweitz, 2011 (citing Barsalou, 1999)</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6900.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6900.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Distributed representation (Haxby)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Distributed and overlapping representations of faces and objects in ventral temporal cortex (Haxby et al., 2001)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Proposal and empirical finding that object categories are represented by distributed, overlapping activity patterns across ventral temporal cortex rather than isolated modular 'category areas'.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Distributed and overlapping representations of faces and objects in ventral temporal cortex</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Distributed overlapping representation / combinatorial codes</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>high‑dimensional space / distributed feature‑based</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are represented as high-dimensional patterns across multiple cortical locations where different combinations of voxel activations (a combinatorial code) encode object/category identity.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Category identity emerges from distributed combinatorial codes, enabling fine-grained discrimination without single-category modules; supports cross-item and cross-subject decoding.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>fMRI study with MVPA classification</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>image viewing in fMRI; multivariate pattern analysis (classification of categories from distributed patterns)</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Patterns across ventral temporal cortex reliably discriminate object categories and are overlapping rather than strictly localized.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Buchweitz, 2011 (citing Haxby et al., 2001)</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6900.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6900.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mitchell 2008 model</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Predicting human brain activity associated with the meanings of nouns</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Computational model mapping corpus-derived semantic feature vectors (word co-occurrence statistics) to voxel activation patterns to predict fMRI responses for nouns, including for words not seen during scanning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Predicting human brain activity associated with the meanings of nouns</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Semantic feature-vector mapping model</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>feature‑based vector / high‑dimensional linear mapping</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Words are represented as vectors of semantic features derived from large text corpora; a learned linear mapping from these semantic vectors to voxel activations enables prediction of brain activation patterns for words (including held-out words).</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Semantic content is encoded as weighted combinations of features across voxels; the model can generalize to predict brain activation for unseen words based on their corpus-derived semantic features.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>fMRI study combined with computational modeling (MVPA/regression mapping)</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>word reading in fMRI; train model on subset of words and predict voxel patterns for held-out words</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Model predicted brain activation patterns for nouns not shown in the scanner using corpus-derived semantic features, indicating a feature-vector style representational format.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Buchweitz, 2011 (discussing Mitchell et al., 2008)</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6900.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6900.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Kay 2008 image-reconstruction</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Identifying natural images from human brain activity</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Empirical demonstration that complex visual images can be identified and partially reconstructed from fMRI activation patterns, implying visual information is represented in reconstructible feature maps in visual cortex.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Identifying natural images from human brain activity</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Image-like/topographic representational format in visual cortex</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>topographic / feature map</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Visual percepts are represented in topographic and feature-specific maps (retinotopic and feature channels) in early visual cortex such that stimulus images can be inferred or reconstructed from voxel patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Low- and mid-level visual features are explicitly encoded in cortex in a manner that supports identification and reconstruction of viewed images from activation patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>fMRI image-viewing study with model-based decoding</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>fMRI during viewing of many natural images; model-fitting and decoding to identify/reconstruct images from activation</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Successful identification of which natural image a subject viewed and preliminary image reconstruction from brain activity.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Buchweitz, 2011 (citing Kay et al., 2008)</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6900.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e6900.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Shinkareva 2008 cross-subject</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Using fMRI brain activation to identify cognitive states associated with perception of tools and dwellings</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>fMRI study showing that distributed activation patterns for concrete nouns (tools, dwellings) permit identification of specific exemplars and generalize across participants, indicating communal neural signatures for concrete concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Using fMRI brain activation to identify cognitive states associated with perception of tools and dwellings</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Communal neural signature for concrete nouns</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>distributed feature-based / shared representational patterns</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concrete noun meanings are represented across a network of regions (including modality-specific areas); commonalities across individuals produce shared distributed patterns that can be used for cross-subject decoding.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Shared, distributed semantic signatures exist across people for concrete nouns, reflecting features such as manipulability that recruit modality-specific systems.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>fMRI study with MVPA cross-participant classification</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>presentation of words/pictures for concrete nouns; classifier trained/tested across participants</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Successful identification of 10 object exemplars and cross-participant prediction of semantic category/item.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Buchweitz, 2011 (citing Shinkareva et al., 2008)</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6900.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e6900.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the representational format of conceptual knowledge in the brain at a functional level, including theoretical models, their descriptions, claimed representational formats, supporting or contradictory empirical evidence, experimental paradigms, key findings, and citation information.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Shared semantic neural representation (cross-language)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Commonality of noun neural representations across languages (cross-language semantic representation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Empirical finding reported in this work that proficient bilinguals exhibit shared distributed neural activation patterns for translation-equivalent concrete nouns across two languages, enabling cross-language decoding of semantic content.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>THE INVESTIGATION OF COMMONALITIES IN HUMAN BRAIN SEMANTIC REPRESENTATIONS ACROSS PEOPLE AND ACROSS LANGUAGES</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Shared distributed semantic representation across languages</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>distributed feature-based</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>In proficient bilinguals, translation equivalents elicit convergent distributed activation patterns encoding semantic features (e.g., manipulability), so that classifiers trained on one language can predict activation in the other.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_claims</strong></td>
                            <td>Proficiency leads to merging of conceptual representations across languages; semantic features are encoded similarly across L1 and L2 allowing cross-language identification of words and categories.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_source</strong></td>
                            <td>fMRI study with machine learning classification (reported preliminary results)</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_paradigm</strong></td>
                            <td>word reading in two languages (English and Portuguese) by proficient bilinguals; MVPA cross-language classification (train on L1/test L2 and vice versa)</td>
                        </tr>
                        <tr>
                            <td><strong>key_result</strong></td>
                            <td>Brain activation for properties of words in one language reliably predicted activation for translation equivalents in the other language; successful cross-language identification of categories and several individual words.</td>
                        </tr>
                        <tr>
                            <td><strong>supports_theory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>citation</strong></td>
                            <td>Buchweitz, 2011 (reporting Buchweitz et al., 2009 / Buchweitz, 2011)</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Perceptual symbol systems <em>(Rating: 2)</em></li>
                <li>Predicting human brain activity associated with the meanings of nouns <em>(Rating: 2)</em></li>
                <li>Distributed and overlapping representations of faces and objects in ventral temporal cortex <em>(Rating: 2)</em></li>
                <li>Using fMRI brain activation to identify cognitive states associated with perception of tools and dwellings <em>(Rating: 2)</em></li>
                <li>Identifying natural images from human brain activity <em>(Rating: 2)</em></li>
                <li>Functional magnetic resonance imaging (fMRI) 'brain reading': detecting and classifying distributed patterns of fMRI activity in human visual cortex <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6900",
    "paper_id": "paper-53396896",
    "extraction_schema_id": "extraction-schema-133",
    "extracted_data": [
        {
            "name_short": "Embodied cognition",
            "name_full": "Embodied Cognition / Perceptual Symbol Systems (Barsalou, 1999)",
            "brief_description": "Theory that conceptual knowledge is grounded in sensorimotor systems such that meaning representations contain perceptual and motor components (simulations) derived from interactions with the environment.",
            "citation_title": "Perceptual symbol systems",
            "mention_or_use": "mention",
            "theory_name": "Embodied Cognition / Perceptual Symbol Systems",
            "theory_type": "embodied simulation",
            "theory_description": "Conceptual knowledge is functionally represented as modality-specific perceptual and motor simulations (re-activations) distributed across sensory and motor cortical systems rather than as amodal symbols.",
            "functional_claims": "Meaning representations include perceptual/motor features and can be re-instantiated as simulations; explains modality-specific activation during semantic tasks and links perception and cognition.",
            "evidence_source": "fMRI studies cited (neuroimaging evidence showing modality-specific activations)",
            "experimental_paradigm": "neuroimaging semantic tasks (word reading, picture viewing, imagining handling objects); MVPA classification of category-specific activation",
            "key_result": "Areas associated with motor/perceptual processing (e.g., motor-related activation for tools) reliably predict semantic category, consistent with perceptual/motor components of meaning.",
            "supports_theory": true,
            "counter_evidence": null,
            "citation": "Buchweitz, 2011 (citing Barsalou, 1999)",
            "uuid": "e6900.0"
        },
        {
            "name_short": "Distributed representation (Haxby)",
            "name_full": "Distributed and overlapping representations of faces and objects in ventral temporal cortex (Haxby et al., 2001)",
            "brief_description": "Proposal and empirical finding that object categories are represented by distributed, overlapping activity patterns across ventral temporal cortex rather than isolated modular 'category areas'.",
            "citation_title": "Distributed and overlapping representations of faces and objects in ventral temporal cortex",
            "mention_or_use": "mention",
            "theory_name": "Distributed overlapping representation / combinatorial codes",
            "theory_type": "high‑dimensional space / distributed feature‑based",
            "theory_description": "Concepts are represented as high-dimensional patterns across multiple cortical locations where different combinations of voxel activations (a combinatorial code) encode object/category identity.",
            "functional_claims": "Category identity emerges from distributed combinatorial codes, enabling fine-grained discrimination without single-category modules; supports cross-item and cross-subject decoding.",
            "evidence_source": "fMRI study with MVPA classification",
            "experimental_paradigm": "image viewing in fMRI; multivariate pattern analysis (classification of categories from distributed patterns)",
            "key_result": "Patterns across ventral temporal cortex reliably discriminate object categories and are overlapping rather than strictly localized.",
            "supports_theory": true,
            "counter_evidence": null,
            "citation": "Buchweitz, 2011 (citing Haxby et al., 2001)",
            "uuid": "e6900.1"
        },
        {
            "name_short": "Mitchell 2008 model",
            "name_full": "Predicting human brain activity associated with the meanings of nouns",
            "brief_description": "Computational model mapping corpus-derived semantic feature vectors (word co-occurrence statistics) to voxel activation patterns to predict fMRI responses for nouns, including for words not seen during scanning.",
            "citation_title": "Predicting human brain activity associated with the meanings of nouns",
            "mention_or_use": "mention",
            "theory_name": "Semantic feature-vector mapping model",
            "theory_type": "feature‑based vector / high‑dimensional linear mapping",
            "theory_description": "Words are represented as vectors of semantic features derived from large text corpora; a learned linear mapping from these semantic vectors to voxel activations enables prediction of brain activation patterns for words (including held-out words).",
            "functional_claims": "Semantic content is encoded as weighted combinations of features across voxels; the model can generalize to predict brain activation for unseen words based on their corpus-derived semantic features.",
            "evidence_source": "fMRI study combined with computational modeling (MVPA/regression mapping)",
            "experimental_paradigm": "word reading in fMRI; train model on subset of words and predict voxel patterns for held-out words",
            "key_result": "Model predicted brain activation patterns for nouns not shown in the scanner using corpus-derived semantic features, indicating a feature-vector style representational format.",
            "supports_theory": true,
            "counter_evidence": null,
            "citation": "Buchweitz, 2011 (discussing Mitchell et al., 2008)",
            "uuid": "e6900.2"
        },
        {
            "name_short": "Kay 2008 image-reconstruction",
            "name_full": "Identifying natural images from human brain activity",
            "brief_description": "Empirical demonstration that complex visual images can be identified and partially reconstructed from fMRI activation patterns, implying visual information is represented in reconstructible feature maps in visual cortex.",
            "citation_title": "Identifying natural images from human brain activity",
            "mention_or_use": "mention",
            "theory_name": "Image-like/topographic representational format in visual cortex",
            "theory_type": "topographic / feature map",
            "theory_description": "Visual percepts are represented in topographic and feature-specific maps (retinotopic and feature channels) in early visual cortex such that stimulus images can be inferred or reconstructed from voxel patterns.",
            "functional_claims": "Low- and mid-level visual features are explicitly encoded in cortex in a manner that supports identification and reconstruction of viewed images from activation patterns.",
            "evidence_source": "fMRI image-viewing study with model-based decoding",
            "experimental_paradigm": "fMRI during viewing of many natural images; model-fitting and decoding to identify/reconstruct images from activation",
            "key_result": "Successful identification of which natural image a subject viewed and preliminary image reconstruction from brain activity.",
            "supports_theory": true,
            "counter_evidence": null,
            "citation": "Buchweitz, 2011 (citing Kay et al., 2008)",
            "uuid": "e6900.3"
        },
        {
            "name_short": "Shinkareva 2008 cross-subject",
            "name_full": "Using fMRI brain activation to identify cognitive states associated with perception of tools and dwellings",
            "brief_description": "fMRI study showing that distributed activation patterns for concrete nouns (tools, dwellings) permit identification of specific exemplars and generalize across participants, indicating communal neural signatures for concrete concepts.",
            "citation_title": "Using fMRI brain activation to identify cognitive states associated with perception of tools and dwellings",
            "mention_or_use": "mention",
            "theory_name": "Communal neural signature for concrete nouns",
            "theory_type": "distributed feature-based / shared representational patterns",
            "theory_description": "Concrete noun meanings are represented across a network of regions (including modality-specific areas); commonalities across individuals produce shared distributed patterns that can be used for cross-subject decoding.",
            "functional_claims": "Shared, distributed semantic signatures exist across people for concrete nouns, reflecting features such as manipulability that recruit modality-specific systems.",
            "evidence_source": "fMRI study with MVPA cross-participant classification",
            "experimental_paradigm": "presentation of words/pictures for concrete nouns; classifier trained/tested across participants",
            "key_result": "Successful identification of 10 object exemplars and cross-participant prediction of semantic category/item.",
            "supports_theory": true,
            "counter_evidence": null,
            "citation": "Buchweitz, 2011 (citing Shinkareva et al., 2008)",
            "uuid": "e6900.4"
        },
        {
            "name_short": "Shared semantic neural representation (cross-language)",
            "name_full": "Commonality of noun neural representations across languages (cross-language semantic representation)",
            "brief_description": "Empirical finding reported in this work that proficient bilinguals exhibit shared distributed neural activation patterns for translation-equivalent concrete nouns across two languages, enabling cross-language decoding of semantic content.",
            "citation_title": "THE INVESTIGATION OF COMMONALITIES IN HUMAN BRAIN SEMANTIC REPRESENTATIONS ACROSS PEOPLE AND ACROSS LANGUAGES",
            "mention_or_use": "use",
            "theory_name": "Shared distributed semantic representation across languages",
            "theory_type": "distributed feature-based",
            "theory_description": "In proficient bilinguals, translation equivalents elicit convergent distributed activation patterns encoding semantic features (e.g., manipulability), so that classifiers trained on one language can predict activation in the other.",
            "functional_claims": "Proficiency leads to merging of conceptual representations across languages; semantic features are encoded similarly across L1 and L2 allowing cross-language identification of words and categories.",
            "evidence_source": "fMRI study with machine learning classification (reported preliminary results)",
            "experimental_paradigm": "word reading in two languages (English and Portuguese) by proficient bilinguals; MVPA cross-language classification (train on L1/test L2 and vice versa)",
            "key_result": "Brain activation for properties of words in one language reliably predicted activation for translation equivalents in the other language; successful cross-language identification of categories and several individual words.",
            "supports_theory": true,
            "counter_evidence": null,
            "citation": "Buchweitz, 2011 (reporting Buchweitz et al., 2009 / Buchweitz, 2011)",
            "uuid": "e6900.5"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Perceptual symbol systems",
            "rating": 2,
            "sanitized_title": "perceptual_symbol_systems"
        },
        {
            "paper_title": "Predicting human brain activity associated with the meanings of nouns",
            "rating": 2,
            "sanitized_title": "predicting_human_brain_activity_associated_with_the_meanings_of_nouns"
        },
        {
            "paper_title": "Distributed and overlapping representations of faces and objects in ventral temporal cortex",
            "rating": 2,
            "sanitized_title": "distributed_and_overlapping_representations_of_faces_and_objects_in_ventral_temporal_cortex"
        },
        {
            "paper_title": "Using fMRI brain activation to identify cognitive states associated with perception of tools and dwellings",
            "rating": 2,
            "sanitized_title": "using_fmri_brain_activation_to_identify_cognitive_states_associated_with_perception_of_tools_and_dwellings"
        },
        {
            "paper_title": "Identifying natural images from human brain activity",
            "rating": 2,
            "sanitized_title": "identifying_natural_images_from_human_brain_activity"
        },
        {
            "paper_title": "Functional magnetic resonance imaging (fMRI) 'brain reading': detecting and classifying distributed patterns of fMRI activity in human visual cortex",
            "rating": 1,
            "sanitized_title": "functional_magnetic_resonance_imaging_fmri_brain_reading_detecting_and_classifying_distributed_patterns_of_fmri_activity_in_human_visual_cortex"
        }
    ],
    "cost": 0.0127,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>THE INVESTIGATION OF COMMONALITIES IN HUMAN BRAIN SEMANTIC REPRESENTATIONS ACROSS PEOPLE AND ACROSS LANGUAGES
jan/jun 2011</p>
<p>Augusto Buchweitz 
Universidade Federal do Rio Grande do Sul</p>
<p>THE INVESTIGATION OF COMMONALITIES IN HUMAN BRAIN SEMANTIC REPRESENTATIONS ACROSS PEOPLE AND ACROSS LANGUAGES
jan/jun 2011A5DFCDD68242385AAE48BDE8DCAD92E6fMRIbilingualismmachine-learning ressonância magnética functionalbilinguismoaprendizagem de máquina
Recent studies on the organization of conceptual knowledge in the human brain have reported the remarkable ability to predict the word a person is thinking about, or the picture a person is seeing, from their brain activity.By using Machine Learning techniques to analyze neuroimaging data, researchers have been able to find stable patterns of brain activity across different people.These patterns allow computer algorithms to identify the brain activity associated with a specific word or picture.The studies have also reported striking commonalities across different people's neural signature for the conceptual knowledge associated with thinking about words.The communal characteristic of the organization of meaning allows for the prediction of what one person is thinking about based on another person's brain activity.The results of some of these studies and the implications for research on cognitive processes and second language learning/acquisition are discussed.Preliminary results from a brain imaging study on cross-language thought identification are also presented.These recent findings in neuroimaging of human semantics suggest the presence of a common semantic neural representation across people and across languages.</p>
<p>Introduction</p>
<p>When we read a word, we activate its meaning, thereby bringing various associated concepts into an activated state.With the advent of brain imaging techniques, it has become possible to identify the areas of the brain that are biologically activated when the meaning of a word is (conceptually) activated.One of the issues that studies of brain imaging and word reading try to address is how meaning is organized in the human brain.For second language researchers, it has been a lasting challenge to understand how bilinguals (re) organize conceptual knowledge when a new language is learned.</p>
<p>The process of learning a second language inevitably leads to some level of merging and association of meaning across languages.In the light of some of the most recent cognitive neuroscience studies on bilingualism, the present paper addresses the use of artificial intelligence techniques (Machine Learning) and neuroimaging data as a promising combination for the identification and prediction of the neural underpinnings of the representation of word meaning in the brain.These studies have been construed as the first steps towards "mind reading, " "brain reading" (Cox and Savoy, 2003), or as the Carnegie Mellon researchers like to call them, "thought identification" experiments (see interview with Marcel Just and Tom Mitchell in Frank, 2009).Regardless of the label, the combination of Machine Learning and brain imaging data is beginning to shed light into the black box of human neural representations for the meaning of objects that surround us and how we perceive them, and into whether these representations have commonalities across people.The objective of the present paper is to briefly introduce machine learning and its use in cognitive neuroscience, and to address some of the implications of these new findings for research on cognition and second language learning/acquisition. Partial results from a new study on cross-language thought identification are presented and discussed (Buchweitz et al., 2009).</p>
<p>Brain Imaging and Machine Learning</p>
<p>In the past few years, the field of cognitive neuroscience has seen an increase in the use of Machine Learning methods for the analysis of brain activation data (Pereira, Mitchell, Botvinick, 2009).The use of Machine Learning in cognitive neuroscience involves the application of computer algorithms to decode (or artificially "learn" from) the brain activation patterns found in massive imaging data sets.The computer algorithm then uses patterns found in the data set to generate predictions.These patterns help scientists create directly testable models on different types of data (for more in-depth information on Machine Learning, see Mitchell, 1997).</p>
<p>Through the use of machine learning, brain imaging data can be investigated as a pattern recognition problem.A pattern of brain activity is initially discerned from a set of data (called the training set of data, on which the computer algorithm is literally trained) and then the pattern learned from the data can be used to identify that same cognitive state in a new set of data (called the test set, on which the predictions are tested).Brain activity from reading instantiations of a word can be used to identify brain activity for that same word read at a different time, or by a different person.</p>
<p>The machine learning approach to brain imaging data has allowed for the identification of cognitive states associated with thinking about semantic exemplars from different categories, such as tools and dwellings (Haxby et al., 2001;Carlson, Schrater, &amp; He, 2003;Cox &amp; Savoy, 2003;Hanson, Matsuka, &amp; Haxby, 2004;O'Toole et al., 2005;Shinkareva et al., 2008).Cox and Savoy (2003) successfully identified 10 categories of object exemplars presented as images to the participants.In a recent study, Shinkareva et al. (2008) were able to identify a pattern of brain activation for 10 different tools or dwellings participants were thinking about.The authors were able to test their predictions on the data across different participants, demonstrating a remarkable power of thought identification based on a communal neural signature for concrete nouns.Figure 1 shows a schematic representation of the combination of neuroimaging data and machine learning analysis techniques.Mitchell et al. (2008) made one of the most impressive contributions from the combination of machine learning techniques and neuroimaging.The researchers were able to predict brain activation for words not shown in the scanner based on word cooccurrences.Extrapolating from the brain imaging data collected, the researchers used machine learning to predict the brain activation for words the participants had not seen in the scanner.The predictions were generated based on the semantic features of words as drawn from an online trillion-token text corpus (Google).</p>
<p>In studies of image identification, Kay et al. (2008) were able to identify which complex image a participant was viewing in the scanner by simply using their brain activation.The authors also showed the first steps towards image reconstruction from brain activity; that is, recreating a photograph from one's brain activation associated with it.The authors hypothesized that in the near future it may be possible to reconstruct mental phenomena, such as a picture of a person's visual experience or a dream, from their brain activity alone.The studies that combine brain imaging and machine-learning classification provide new means for the generation of computational models and predictive theories of the organization of conceptual knowledge and psychological phenomena in the human brain.</p>
<p>Distributed organization of brain activation for the meaning of words</p>
<p>Further contribution to the understanding of the organization of conceptual knowledge in the brain comes from the location of the areas that reliably predict the brain activation for words.The locations in the brain that predicted the words that were being viewed suggest that the neural activity common to the participants encodes information about the properties of the word (specific to the categories of the words, that is, tools and dwellings).Shinkareva et al. (2008) generated predictions based on activation associated with motor activity, such as handling a hammer.This indicates that commonalities in brain activation were not simply based on activation associated with the fact that participants were shown the same visual stimulus.The commonality in activation was not due to lower-level cognitive processing of a string of letters, which was the same for all participants (e.g., the word form, or orthographic appearance, for "hammer" or the picture of a hammer).</p>
<p>The areas of activation associated with the classification of brain activation for the various individual words indicate that meaning is represented in several locations in the brain.The diffuse representation suggests that word meanings are represented in terms of a large number of features or properties that encode varied types of information.The brain activation for thinking about a word is not just in one place in the brain, it is in a network of places.</p>
<p>The location of the areas of brain activation that predict the semantic properties people are thinking about provides evidence for a perceptual theory of knowledge called "embodied cognition." Embodied cognition is a theoretical position that holds that meaning representations contain perceptual and motor components corresponding to one's interaction with objects in the physical environment (e.g., Barsalou, 1999).Embodied cognition advocates that human perception and cognition are intrinsically bound.They are not two separate modular systems.Cognition is grounded in simulations that combine physical and introspective events (Barsalou, 1999).Meaning and conceptual knowledge are represented in the interaction between the environment and our bodies.</p>
<p>Machine learning studies of thought identification show that despite idiosyncrasies in individual representations of meaning (idiosyncrasies that may be due to different individual experiences) there is an identifiable communal representation of meaning for concrete words in the brain.This representation is distributed and forms networks of activation that may be encoding representations of what it feels like to interact with an object (to hold it, to smell it, to imagine yourself moving about in a dwelling).The alert researcher of second language acquisition or teacher of a second language at this point may be associating the theory of embodied representation of meaning with the facilitation that interaction with actual objects can provide in second language vocabulary acquisition, for example.</p>
<p>Figure 1.Schematic representation of the combination of neuroimaging data and machine learning analysis techniques.Brain activation data for thinking about the properties of a word for a group of participants is averaged and computed to find, among the brain activation for several words, what is the activation data for that same word in another participant.</p>
<p>The Organization of Meaning in the Bilingual Brain</p>
<p>One of the most investigated issues in the field of second language acquisition is the effect of age of acquisition (AoA) on the ultimate attainment of a second language and on brain activation.The variable Age of Acquisition (AoA) divides speakers of two languages into early and late bilinguals.The early bilingual (EBL) is one who acquires two languages, at the same time, from infancy.The late bilingual (LBL), in turn, is one who acquires or learns a second language after the age of seven years (Paradis, 2003).This dichotomy in the AoA of a second language is warranted by the different cognitive processes (drawing on what is known about procedural and declarative knowledge) that take place during the learning and acquisition processes of LBLs and EBLs.</p>
<p>A question that arises from early or late acquisition of language is whether older age of acquisition hinders the ultimate attainment of second language skill.It is a general consensus in the field of second language acquisition that early (i.e., during childhood), rather than late (i.e., mid teens and older) second language acquisition favors achievement of better L2 proficiency (Hernandez &amp; Li, 2007).In terms of the organization of brain activation for processing a second language, studies have shown that early acquisition of a new language is associated with a striking similarity in the patterns of activation between two languages (Kim et al., 1997) (for more detailed reviews of brain imaging studies of bilingualism, see Abutalebi, Cappa, &amp; Perani, 2001;Buchweitz, 2005;Perani &amp; Abutalebi, 2005;Hernandez &amp; Li, 2007).</p>
<p>The language skills that are more deeply affected by later learning of an L2 are the ability to parse sentences for grammaticality (syntax), and the ability to segment words into its different written parts or sounds (morphology and phonology) (Hernandez &amp; Li, 2007).Roughly speaking, these are skills associated with learning the workings and taxonomy of how to combine man-made, arbitrary symbols for language into writing systems.But not all L2 skills are completely dependent on AoA.Behavioral studies show that proficient bilinguals achieve comparable performance in lexical and semantic processing tasks regardless of their age (Hernandez &amp; Kohnert, 1999;Hernandez &amp; Reyes, 2002;Kohnert, Bates, &amp; Hernandez 1999).Bilinguals seem to be able to become highly skilled in the processing of meaning in a second language early and late in life.Learning a new writing system and orthography, and being able to verbalize and apply their rules is intrinsically less natural than making meaning associations, which is something we as humans naturally do everyday.</p>
<p>The general notion is that as bilinguals become more proficient there is a developmental shift from lexical to conceptual mapping of meaning in the second language (Kroll &amp; de Groot, 1997).As bilinguals become more proficient, they evolve from processing words in the second language (L2) in association with words in first language (L1), to processing words in the L2 independently of the word in L1 (Chen &amp; Ho, 1986;Tzelgov, Henik, &amp; Leiser, 1990).In a study of semantic priming, Perea et al. (2008) found significant between-language semantic priming for proficient bilinguals, regardless of age of acquisition.The authors replicated the results in two language directions.They concluded that semantic overlap between two languages is a process that solidifies with increased proficiency in the second language.</p>
<p>Picture naming studies have shown that bilinguals learn to map individual words to their concepts in the second language independently of a word association with the first language.Participants in these studies were able to name pictures at the same speed in L1 and L2 (Potter &amp; Faulconer, 1975;Kroll &amp; de Groot, 1997).Also, others have shown that proficient bilinguals can categorize words into semantic groups (e.g., a hammer is a tool) with the same speed in different languages (Caramazza &amp; Brones, 1980;Potter et al., 1984;Shanon, 1982).Studies with bilingual Stroop tasks have shown that more proficient bilinguals suffer a Stroop effect from naming an ink color in their native language when the word names a different color in the second language, in language pairs with similar and with dissimilar orthographies (Kroll &amp; de Groot, 1997;Chen &amp; Ho, 1986;Tzelgov et al., 1990).</p>
<p>Brain imaging studies with bilingual participants corroborate the findings of behavioral studies.As bilinguals become proficient (more skilled) in a second language, the cortical organization of first and second language cognitive processes also becomes increasingly similar in lexical, semantic, and sentence processing tasks (Perani et al., 1998;Illes et al., 1999;Wartenburger et al., 2003;Green, Crinion, &amp; Price, 2006;Hernandez &amp; Li, 2007).The areas that process language in L1 tend to continue to do so in L2.In a study of bilingual sentence comprehension, Buchweitz (2006) found considerable similarities in the brain activation for processing sentences in English and Portuguese.The collective findings from brain imaging of bilingualism suggest that the activation of the proficient bilingual brain in word and sentence processing in two languages occurs in similar ways.One question that remains is how similar is the actual organization of meaning in the bilingual brain for a concept elicited by words (translation equivalents) in two languages, and are there enough similarities to allow for cross-language prediction.</p>
<p>Cross-language identification of brain activation Buchweitz et al. (2009) carried out a study with the aim to establish a correspondence between the activation patterns associated with thinking about words in two different languages.The study applied classification of brain activity for reading words in English and Portuguese in bilinguals.The initial hypothesis of the study was that there would be common neural representations across languages (the participants were proficient, but late, bilinguals) that would allow for cross-language classification of brain activity.Some of the 14 words for tools and dwellings (and their translation) presented were: hammer (martelo); saw (serrote); house (casa); and hut (cabana).</p>
<p>The results showed a remarkable ability to predict the brain activity associated with thinking about the properties of tools and dwellings across languages (Figure 2).The brain activation for the properties of words that participants were thinking about in one language reliably predicted the brain activation for words in another language.The ability to identify an individual word and word categories in one language based on data from another language suggests the presence of shared semantic content for concrete nouns across languages in proficient bilinguals.In the highly-proficient bilinguals included in the study, word meaning representations in the second language and in the first language appear to merge significantly to the point that they are identifiable across languages.The merging of concepts did not affect identification of thought in the first language, which was also successful.</p>
<p>Figure 2: The study of shared semantic representation allowed for cross-language prediction of the brain activity associated with words in English and Portuguese based on brain activation for concrete nouns (Buchweitz et al., 2009).</p>
<p>Portuguese English</p>
<p>reliable cross-language prediction casa house martelo hammer drill furadeira</p>
<p>Concluding remarks</p>
<p>The combination of machine learning analysis techniques and brain imaging data provides a glimpse into the future of cognitive neuroscience studies of bilingual brain activation.Recent findings of neuroimaging studies suggest a common semantic neural representation across people and across languages.The organization of the representation of meaning in the brain is not only identifiable, but it has shared characteristics across people and across different languages.The features shared across people for tools and dwellings are associated with their application.Our brains have a similar signature for, for example, the manipulability of objects, and the brain activation for these features remains identifiable in a second language.</p>
<p>Further studies may be carried out to answer whether reliable classification accuracies across languages would be found in less proficient bilinguals, who may have to rely on L2-to-L1 word associations to retrieve the properties of a word.It also remains to be seen whether the classification accuracies for early bilinguals would be different than those obtained for late bilinguals.Optimistically, the use of machine learning techniques in studies of second language acquisition may allow for future development of generative models of the brain representation for different stages of language skill, and for what may be a dynamic overlap of meaning representations.</p>
<p>The bilingual brain as revealed by functional neuroimaging. J Abutalebi, S F Cappa, D Perani, Bilingualism: language and cognition. 422001</p>
<p>Perceptual symbol systems. L W Barsalou, Behavioral and brain sciences. 221999</p>
<p>Brain and Language: an overview of neuroimaging studies of bilingual language processing. A Buchweitz, Revista brasileira de lingüística aplicada. 52005</p>
<p>Two languages, two input modalities, one brain: an fMRI study of Portuguese-English bilinguals and Portuguese listening and reading comprehension effects on brain activation. Unpublished doctoral dissertation. A Buchweitz, 2006Universidade Federal de Santa CatarinaSanta Catarina</p>
<p>A Buchweitz, S Shinkareva, M A Just, Commonality of noun neural representations across languages. 15th Annual Meeting of the Organization for Human Brain Mapping. 2009</p>
<p>Patterns of activity in the categorical representations of objects. T A Carlson, P Schrater, S He, Journal of Cognitive Neuroscience. 152003</p>
<p>Semantic classification by bilinguals. A Caramazza, I Brones, Canadian Journal of Psychology. 3411980</p>
<p>Development of stroop interference in Chinese-English bilinguals. H C Chen, C Ho, Journal of Experimental Psychology: Learning, Memory, and Cognition. 121986</p>
<p>Functional magnetic resonance imaging (fMRI) ''brain reading'': detecting and classifying distributed patterns of fMRI activity in human visual cortex. D D Cox, R L Savoy, NeuroImage. 192003</p>
<p>Reading my mind. 60 minutes. M Frank, 2009. January 30th. 2009</p>
<p>Convergence, degeneracy, and control. D W Green, J Crinion, C J Price, Language learning. 56s12006</p>
<p>Combinatorial codes in ventral temporal lobe for object recognition: Haxby (2001) revisited: is there a ''face''area?. S J Hanson, T Matsuka, J V Haxby, NeuroImage. 232004</p>
<p>Distributed and overlapping representations of faces and objects in ventral temporal cortex. J V Haxby, M I Gobbini, M L Furey, A Ishai, J L Schouten, Science. 2932001</p>
<p>Aging and language switching in bilinguals. A E Hernandez, K Kohnert, Aging Neuropsychology and Cognition. 61999</p>
<p>Age of Acquisition: Its neural and computa-Age of Acquisition: Its neural and computational mechanisms. A E Hernandez, P Li, Psychological bulletin. 13342007</p>
<p>Within-and Between-Language Priming Differ: Evidence from Repetition of Pictures in Spanish-English Bilinguals. A E Hernandez, I Reyes, Journal of Experimental Psychology: Learning, Memory, and Cognition. 282002</p>
<p>Convergent cortical representation of semantic processing in bilinguals. J Illes, W S Francis, J E Desmond, J D E Gabrieli, G H Glover, R Poldrack, C J Lee, A D Wagner, Brain and Language. 701999</p>
<p>Identifying natural images from human brain activity. K N Kay, T Naselaris, R J Prenger, J L Gallant, Nature. 4522008</p>
<p>Distinct cortical areas associated with native and second languages. K H S Kim, N R Relkin, K Lee, J Hirsch, Nature. 3881997</p>
<p>Balancing bilinguals: Lex-Balancing bilinguals: Lexical-semantic production and cognitive processing in children learning Spanish and English. K J Kohnert, E Bates, A E Hernandez, Journal of Speech, Language, and Hearing Research. 421999</p>
<p>Lexical and conceptual memory in the bilingual. J F Kroll, A M B De Groot, Tutorials in bilingualism: Psycholinguistic perspective. A M B De Groot, J F Kroll, Mahwah, NJErlbaum1997. 1997</p>
<p>T M Mitchell, Machine Learning. McGraw Hill1997</p>
<p>Predicting human brain activity associated with the meanings of nouns. T M Mitchell, S V Shinkareva, A Carlson, K M Chang, V L Malave, R A Mason, M A Just, Science. 3202008</p>
<p>Partially distributed representations of objects and faces in ventral temporal cortex. A O'toole, F Jiang, H Abdi, J V Haxby, Journal of Cognitive Neuroscience. 172005</p>
<p>Differential use of cerebral mechanisms in bilinguals. M Paradis, Mind, Brain, and Language: Multidisciplinary perspectives. M T Banich, M Mack, LondonLawrence Erlbaum2003. 2003</p>
<p>The neural basis of first and second language processing. D Perani, J Abutalebi, Current Opinion in Neurobiology. 152005</p>
<p>The bilingual brain: proficiency and age of acquisition of the second language. D Perani, E Paulesu, N S Galles, E Dupoux, S Dehaene, V Bettinardi, S F Cappa, F Fazio, J Mehler, Brain. 1211998</p>
<p>Masked associative/se-Masked associative/semantic priming effects across languages with highly proficient bilinguals. M Perea, J A Duñabeitia, M Carreiras, Journal of Memory and Language. 582008</p>
<p>Machine learning classifiers and fMRI: A tutorial overview. F Pereira, T Mitchell, M Botvinick, Neuroimage. 452009</p>
<p>Time to understand pictures and words. M C Potter, B A Faulconer, Nature. 2531975</p>
<p>Lexical and conceptual representation in beginning and more proficient bilinguals. M C Potter, K-F So, B Von Eckhardt, L B Feldman, Journal of Verbal Learning and Verbal Behavior. 231984</p>
<p>Identification and classification of words and drawings into two languages. The quarterly journal of experimental psychology 34a. B Shanon, 1982</p>
<p>Using fMRI brain activation to identify cognitive states associated with perception of tools and dwellings. S V Shinkareva, R A Mason, V L Malave, W Wang, T M Mitchell, M A Just, PLoS ONE. 31e13942008</p>
<p>Controlling Stroop interference: evidence from a bilingual task. J Tzelgov, A Henik, D Leiser, Journal of Experimental Psychology. 161990</p>
<p>Early setting of grammatical processing in the bilingual brain. I Wartenburger, H R Heekeren, J Abutalebi, S F Cappa, A Villringer, D Perani, Neuron. 372003</p>            </div>
        </div>

    </div>
</body>
</html>