<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7655 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7655</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7655</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-143.html">extraction-schema-143</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to distill quantitative laws, equations, or functional relationships from collections of scholarly papers, including details of the models, prompting or fine‑tuning approaches, input corpora, extraction methods, types of laws, representation formats, evaluation datasets, metrics, baseline comparisons, validation procedures, and reported performance or limitations.</div>
                <p><strong>Paper ID:</strong> paper-272786577</p>
                <p><strong>Paper Title:</strong> Large language models in medical and healthcare fields: applications, advances, and challenges</p>
                <p><strong>Paper Abstract:</strong> Large language models (LLMs) are increasingly recognized for their advanced language capabilities, offering significant assistance in diverse areas like medical communication, patient data optimization, and surgical planning. Our survey meticulously searched for papers with keywords such as “medical,” “clinical,” “healthcare,” and “LLMs” across various databases, including ACM and Google Scholar. It sought to delve into the latest trends and applications of LLMs in healthcare, analyzing 175 relevant publications to support both practitioners and researchers in the field. We have compiled 56 experimental datasets, various evaluation methods and reviewed cutting-edge LLMs across tasks. Our comprehensive analysis of LLMs in healthcare applications, including medical question-answering, dialogue summarization, electronic health record generation, scientific research, medical education, medical product safety monitoring, clinical health reasoning, and clinical decision support. Furthermore, we have identified the challenges, including data security, inaccurate information, fairness and bias, plagiarism, copyrights, and accountability, and the potential solutions, namely de-identification framework, references,counterfactually fair prompting,opening and ending control codes, and establishing normative standards,to address these open issues,respectively. The findings of this survey exert a profound impact on spurring innovation in practical applications and addressing inherent challenges within the academic and medical communities.</p>
                <p><strong>Cost:</strong> 0.006</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7655",
    "paper_id": "paper-272786577",
    "extraction_schema_id": "extraction-schema-143",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.0064095,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Large language models in medical and healthcare fields: applications, advances, and challenges
20 September 2024</p>
<p>Dandan Wang 
Department of Computer Science
Taizhou University
318000Taizhou, ZhejiangChina</p>
<p>Department of Computer Science
Taizhou University
318000Taizhou, ZhejiangChina</p>
<p>Shiqing Zhang 
Department of Computer Science
Taizhou University
318000Taizhou, ZhejiangChina</p>
<p>Large language models in medical and healthcare fields: applications, advances, and challenges
20 September 20240CD7C2F521DD3429C61EE18C64A287D710.1007/s10462-024-10921-0Accepted: 22 August 2024 /
Large language models (LLMs) are increasingly recognized for their advanced language capabilities, offering significant assistance in diverse areas like medical communication, patient data optimization, and surgical planning.Our survey meticulously searched for papers with keywords such as "medical," "clinical," "healthcare," and "LLMs" across various databases, including ACM and Google Scholar.It sought to delve into the latest trends and applications of LLMs in healthcare, analyzing 175 relevant publications to support both practitioners and researchers in the field.We have compiled 56 experimental datasets, various evaluation methods and reviewed cutting-edge LLMs across tasks.Our comprehensive analysis of LLMs in healthcare applications, including medical question-answering, dialogue summarization, electronic health record generation, scientific research, medical education, medical product safety monitoring, clinical health reasoning, and clinical decision support.Furthermore, we have identified the challenges, including data security, inaccurate information, fairness and bias, plagiarism, copyrights, and accountability, and the potential solutions, namely de-identification framework, references,counterfactually fair prompting,opening and ending control codes, and establishing normative standards,to address these open issues,respectively.The findings of this survey exert a profound impact on spurring innovation in practical applications and addressing inherent challenges within the academic and medical communities.KeywordsLarge language models • Healthcare applications • Medical questionanswering • Electronic health record generation • Clinical health reasoning • Fairness and bias * Shiqing Zhang</p>
<p>Introduction</p>
<p>Recent advancements in large language models (LLMs) have garnered significant interest in both academic and industrial domains due to their impressive success in language understanding and text generation (Chang et al. 2023).The extraordinary capabilities of contemporary LLMs hold great promise for applications in the medical and healthcare domain, surpassing the performance of smaller models with limited data (Sallam 2023a).Large language models in the medical and healthcare domain (LLMMs) have the potential to facilitate communication among healthcare professionals, patients, and their families, streamline the collection and analysis of patient health data, and assist in the development of surgical plans (Zhao et al. 2023).Furthermore, LLMMs can acquire real-time surgical navigation information and physiological parameters, offer postoperative rehabilitation guidance to patients, and provide intraoperative support to surgeons.LLMMs can also be trained to recognize and analyze medical images (e.g., X-rays, magnetic resonance imaging, and ultrasound), video, audio and remote photoplethysmograph signals to identify features and structures (Fan et al. 2024), aiding doctors in accurately and rapidly detecting anomalies and diagnosing diseases or injuries, thereby alleviating the workload of radiologists (Waisberg et al. 2023).</p>
<p>The recent swift advancement of LLMMs has opened up a wide range of application prospects across various scientific research fields (Archana and Jeevaraj 2024).These include aiding in the composition of influential articles through literature review synthesis (Chen and Li 2023), facilitating the retrieval and discovery of the latest scientific developments, supporting grammar correction and text translation (Fatani 2023), offering novel perspectives and research directions (Liebrenz et al. 2023), and providing feedback and improvement suggestions for draft or manuscript inputs (Castellanos-Gomez 2023).Additionally, LLMMs are demonstrating their prowess in data analysis and interpretation.In the realm of medical education, LLMMs have exhibited remarkable performance, for instance, in assisting human learners and educators with United States Medical Licensing Examination (USMLE), Japanese Medical Licensing Examination (JMLE), and other medical licensing examinations, as well as in generating and evaluating multiple-choice tests (Sallam 2023b).Although scholars and medical practitioners have increasingly expressed interest in the application of LLMMs, the practical utility of LLMMs in clinical and research settings is fraught with distinct challenges.These challenges include data security, privacy preservation, the risk of inaccurate information, fairness and bias issues, plagiarism concerns, copyright considerations, and accountability.</p>
<p>This paper offers a comprehensive guide for medical researchers and enthusiasts in the LLMM field, providing a swift introduction to the applications of LLMMs in various medical domains, accessible experimental databases, the performance of different models across tasks, current challenges confronting LLMMs, and potential solutions.It holds significant importance in accelerating the enhancement of LLMMs in artificial intelligence technology for healthcare and their capacity to address real-world problems.Furthermore, it plays a crucial role in promoting the swift deployment of LLMs in practical medical settings and in boosting the efficiency and effectiveness of doctors, patients, and other healthcare professionals in clinical, educational, and research activities.To delineate our work more clearly, we juxtapose the existing reviews of the most advanced LLMMs, outline the process of curating relevant publications, and highlight the contributions of this survey.</p>
<p>Distinctions of this survey from prior research</p>
<p>The remarkable performance and widespread adoption of LLMs have spurred an extensive body of research in this field.For instance, (Wang et al. 2023a) examined the clinical language understanding capabilities of LLMs in healthcare, Tian et al. (Tian et al. 2023) explored the potential and challenges of ChatGPT in the biomedical and health sectors, Liu et al. (Liu et al. 2023a) provided an examination of ChatGPT and GPT-4 across diverse domains, and Sallam et al. (Sallam 2023c) assessed the applicability of ChatGPT in healthcare.Nonetheless, these studies often concentrate on a limited number of LLMs or fail to offer a thorough and expansive analysis of LLM applications and the associated potential issues, such as medical dialog summarization, scientific research, medical product safety monitoring, disease diagnosis, clinical decision support, administrative tasks assistance, and ethical concerns regarding data security and privacy preservation.In contrast, our survey delves deeply into LLMs within the medical and healthcare realm, encompassing research scenarios, accessible medical datasets, evaluation methodologies, and the challenges LLMs encounter in the medical field.Table 1 delineates the disparities between our survey and previous studies.</p>
<p>Methodology for collecting relevant publications</p>
<p>This study was conducted by searching for relevant papers on the renowned digital library Google Scholar, which encompasses literature from ACM, Springer, Elsevier, arXiv, medRxiv, and other multi-source databases.The focus of this paper is on research work from January 2022 up until the submission of this paper in January 2024, with a particular emphasis on models introduced after the launch of ChatGPT in November 2022, as well as those with parameters exceeding 10^9.For the search terms used on Google Scholar, we adopted a combination of application domains and large models, such as ("medical" or "clinical" or "healthcare") and ("large language model").The "or" operator allows for the inclusion of papers that meet any of the connected search terms, while the "and" operator requires that all connected terms be satisfied.We found that this approach yielded a significant number of survey and overview articles, with only a few papers containing relevant models.Consequently, we replaced the keyword "large language model" with specific names of large language models (e.g., ChatGPT, LLaMA, PaLM, etc.) and combined them with "medical", "clinical", and "healthcare".The specific names of the large language models were referenced from (Zhao et al. 2023), (Hadi et al. 2023), and others.The rationale for this approach is that, as specialized models in the medical and healthcare fields, they are generally pre-trained from general large models or generated for fine-tuning, making it reasonable and efficient to refer to existing large models.All the papers retrieved from the above searches were included in the candidate corpus.We then reviewed the titles, abstracts, and keywords of the candidate papers; those that did not include specific large models in the medical or healthcare fields were excluded.Additionally, to ensure a more comprehensive coverage of research content, we also included articles discussing LLMs in the healthcare domain from multiple review papers in the candidate set, ultimately arriving at 175 papers closely related to our research.</p>
<p>To our understanding, our survey is the first to focus on LLMMs in relation to realworld application scenarios, available datasets, evaluation methods, and ethical and safety considerations.By delineating the applications of various LLMMs across different fields,</p>
<p>Table 1</p>
<p>The disparities between our survey and previous studies Main concerns (Wang et al. 2023a) (Tian et al. 2023) .(Liu et al. 2023a) (Sallam 2023c)  we illustrate how LLMMs assist medical professionals, patients, and other healthcare stakeholders in decision-making, answering related questions, and generating electronic health records, as well as in medical education and scientific research.We analyze the latest algorithms and the most appropriate model frameworks in each domain and summarize the challenges, along with potential medical and healthcare solutions.</p>
<p>Contributions of this survey</p>
<p>This survey systematically delves into the applications of LLMMs, examining their usage in various scenarios, the availability of medical datasets, evaluation methodologies, performance across various tasks, and the challenges they face in the medical field.Our goal is to provide dynamic and constructive guidelines for scientific researchers, practitioners, and developers interested in LLMMs.The primary contributions of this work are as follows:</p>
<p>(1) We comprehensively summarize and provide an overview of the state-of-the-art LLMs across diverse application scenarios within the medical and healthcare fields.</p>
<p>(2) We categorize and analyze the works of publications, integrating various tasks and evaluation metrics to assess the performance of LLMMs.</p>
<p>(3) We thoroughly summarize and categorize the current challenges in the medical and healthcare domains and envision potential solutions to address these open issues.</p>
<p>In the remainder of this paper, Sect. 2 provides an overview of ten common application scenarios of LLMMs.Section 3 introduces several experimental datasets that are most frequently utilized by researchers in the medical and healthcare domains.Section 4 discusses the commonly employed metrics for assessing the performance of LLMMs.Section 5 analyzes the capabilities of state-of-the-art LLMMs across a range of tasks.Section 6 identifies the challenges encountered by LLMMs and offers potential solutions.Finally, Sect.7 concludes the survey with a summary of the entire work.</p>
<p>Application scenarios of state-of-the-art LLMMs</p>
<p>The advanced language comprehension and text generation capabilities of LLMs have significantly impacted various aspects of medical and healthcare scenarios.These applications include medical question-answering, medical dialog summarization, electronic health record generation, scientific research, clinical decision support, and more (as depicted in Fig. 1).The deployment of LLMs offers valuable insights for various stakeholders in healthcare domains, such as healthcare providers and patients (Jin and Dobry 2023)).This includes enhancing patient education, drafting responses, or querying patient notes with given questions for healthcare providers, reviewing scientific papers for researchers, and explaining clinical research protocols for clinical research coordinators.</p>
<p>Medical question-answering (MQA)</p>
<p>The robust text analysis and comprehension capabilities of LLMs have accelerated their widespread application in answering biomedical and genetic questions, as well as in USMLE, with models like GPT-4 (Wang et al. 2023b), ChatGPT (Javaid et al. 2023) The application of LLMMs is constrained by their limited medical domain knowledge and the complexities of clinical tasks.For example, the performance of ChatGPT with human respondents in answering genetic questions was not significantly different from human respondents (Duong and Solomon 2023).Given ChatGPT's observed limitations in medical knowledge, Li et al. (Yunxiang et al. 2023) introduced ChatDoctor, employing the LLaMA model with an autonomous information retrieval mechanism.This allows real-time access and utilization of Wikipedia online resources, leading to a substantial enhancement in the quality of patient-physician interactive dialogue.The system has demonstrated notable progress in comprehending patient needs and offering precise treatment options.Toma et al. (Toma et al. 2023) developed Clinical Camel, a dialogue-based knowledge encoding model that enhances the model's implicit knowledge base, maintains session recall, and expands the knowledge base data.As a result, Clinical Camel achieved a higher score than GPT-3.5 on the USMLE test.The model is capable of managing multi-stage clinical case issues, offering adaptive patient counseling, and generating clinical records from conversations (Selvaraj and Konam 2020).Chervenak et al. (Chervenak et al. 2023) conducted a survey on 17 common questions and reproductive knowledge related to infertility using GPT-4 based on existing clinical information.Common questions, surveys, and summaries Fig. 1 The current application scenarios of LLMMs were used as prompts to input GPT-4, including sentiment analysis, factual statements, published population data, etc.The common issues of infertility, factual content, emotional polarity, and subjectivity were consistent with the management of disease control centers.The experiment of ChatGPT-4 showed that the output information of LLMs is relevant and meaningful for clinical queries related to fertility.</p>
<p>However, since most LLMs are trained and learned from English corpora, advanced LLMs do not perform well in Chinese medical question-answering systems.To address this, several scholars have made efforts in the development and application of Chinese LLMs and datasets, such as BenTsao (Wang et al. 2023c), Ziya-LLaMA (Zhang et al. 2022), DoctorGLM (Xiong et al. 2023), Zhongjing (Yang et al. 2023a), and Huatuo (Li et al. 2023a), among others.Xiong et al. (Xiong et al. 2023) developed a large-scale language model, DoctorGLM, trained on a Chinese healthcare database.DoctorGLM incorporates a prompt designer module that extracts relevant keywords from user input, utilizes potential disease names as labels, and generates a description based on the disease knowledge library.Consequently, DoctorGLM can provide users with reliable information, including disease symptoms, diagnosis, treatment, and preventive measures.Yang et al. (Yang et al. 2023a) introduced a Chinese medicine LLM model named Zhongjing, which is based on LLaMA.By employing refined annotation rules and evaluation criteria, the model's proficiency in complex dialogue and active querying was substantially enhanced through feedback reinforcement learning.The architecure of Zhongjing is depicted in Fig. 2.</p>
<p>Medical dialog summarization (MDS)</p>
<p>The MDS aids clinicians in identifying potential health risks for patients and supports informed decision-making (Patel and Lam 2023).By analyzing current patient data, MDS reduces errors and enhances diagnostic precision.The field has seen significant advancements due to the recent progress in LLMs, including BERT (Wei et al. 2023), T5, PEGASUS (Balumuri et al. 2021), BioGPT (Alqahtani et al. 2023), GPT-3 (Nath et al. 2022), CLUSTER2SENT (Krishna et al. 2020),.BioBERT (Lee et al. 2020), and XrayGPT (Thawkar et al. 2023).Agrawal et al. (2022) utilized GPT-based models to extract critical variables from diverse clinical notes, demonstrating that GPT-3 outperforms other models in clinical natural language processing tasks.Chintagunta et al.</p>
<p>Fig. 2 The architecture of Zhongjing LLM (Yang et al. 2023a) (Chintagunta et al. 2021) introduced GPT-3-ENS, a medically adapted GPT-3 model, for data annotation.This model produces synthetic training data that emphasizes relevant medical information, increasing human-labeled examples by over 30-fold.Integrating these high-quality synthetic data with human-labeled data enhances the accuracy and consistency of summaries in MDS tasks.Krishna et al. (Krishna et al. 2020) proposed the deep summarization model CLUSTER2SENT, which employs a pre-trained T5 model as an abstractive component to generate clinical summaries from doctor-patient dialogues.To offer users precise and beneficial health information, Yadav et al. (Yadav et al. 2021) developed a relevance-based reranking model based on the T5 framework, leveraging transfer learning to provide more precise and valuable information in multianswer summarization tasks.Additionally, they applied a pre-trained Transformer model, enhanced with transfer learning, to address summarization challenges.</p>
<p>As the healthcare field evolves, the health-related streaming data available online must grapple with the challenges posed by vast volumes, rapid generation, diversity, and variability.Balumuri et al. (Balumuri et al. 2021) introduced a model that leverages transfer learning on pre-trained BERT, T5, and PEGASUS architectures, markedly enhancing the summarization capabilities of health question-answering systems.(Alqahtani et al. 2023) employed fine-tuned T5, BERT, and BioGPT models to summarize medical dialogues between doctors and patients.These models are adept at capturing all medical conditions described within dialogues and accurately identifying affirmations and negations in a medical context.The task of natural language understanding is significantly challenged when individuals seeking health information online verbose descriptions and peripheral details to articulate medical conditions.Clinical notes summarization assists healthcare practitioners in identifying potential health risks within patients' electronic health records (Wornow et al. 2023), thereby reducing errors and facilitating informed decision-making.Chuang et al. (Chuang et al. 2023) proposed the model-agnostic Soft Prompt-Based Calibration method, SPeC, to address the issue of increased output variance resulting from the integration of instruction prompts with large language models.This method ensures heterogeneity and reliability in the generation of medical summary information, as demonstrated in Fig. 3.</p>
<p>Electronic health records (EHRs), clinical letters and medical note generation</p>
<p>The LLMs are capable of generating clinical letters, medical notes, and electronic health records (EHRs) for specific issues through text-based dialogue.This capability is influenced by models such as ChatGPT (Cascella et al. 2023), GatorTron (Yang et al. 2022), ClinicalBERT (Alsentzer et al. 2019), BioMegatron (Shin et al. 2020), and GPT-4 (Abdelhady and Davis 2023), which impact multiple aspects of clinical documentation.Cascella et al. (Cascella et al. 2023) employed ChatGPT to create medical notes for intensive care unit (ICU) patients.After reviewing laboratory samples, blood gas parameters, and respiratory and hemodynamic data, ChatGPT accurately categorized most parameters into the appropriate domains.The model also exhibited a remarkable ability to self-correct by inquiring if its placement was appropriate, without requiring additional hints.Leveraging ChatGPT's robust language comprehension and text generation capabilities, (Ali et al. 2023) produced high-quality clinical letters across various clinical communication scenarios.The efficacy of the LLMs was demonstrated through a series of intricate commands, enhancing the precision and efficiency of intelligent text generation and ultimately providing more satisfactory services to patients.The research indicated that ChatGPT produces surgical records more rapidly than healthcare professionals, and the quality of these records, as well as their adherence to guidelines, is highly regarded by both patients and physicians, showcasing the potential of LLMs in the medical field.</p>
<p>In comparison to ChatGPT, GPT-4 exhibits superior problem-solving capabilities and an expansive knowledge base.Within the medical and healthcare domains, GPT-4 can supply the most current literature in specific fields, draft discharge summaries for patients post-surgery, analyze medical image characteristics, and identify objects in photographs, revealing its significant potential in clinical trials (Waisberg et al. 2023).Athavale et al. (Athavale et al. 2023) conducted two studies on complex medical issues, encompassing administrative management and chronic venous disease.Their evaluation of the assistance provided by EHR record inbox management functions revealed that GPT-4 outperformed ChatGPT3.5 across all problem domains, suggesting that this technology is poised to be utilized for EHR inbox management.Abdelhady and Davis (Abdelhady and Davis 2023) investigated the use of GPT-4 for generating surgical records of plastic surgeries performed by four surgeons, detailing the surgical types, record categories, description generation time, patient satisfaction, and comprehensive information about the surgeons' qualifications.Yang et al. (Yang et al. 2022) introduced GatorTron, an LLM with over 90 billion words, and assessed its performance on five clinical NLP tasks, examining the impact of varying scale parameters and training data (as depicted in Fig. 4).</p>
<p>Scientific research</p>
<p>In scientific research, LLMs can serve as powerful tools for data analysis (Tao et al. 2022), literature review, and hypothesis generation.They can efficiently sift through vast amounts of medical literature, extracting key information and identifying trends that might escape human researchers (Peng et al. 2023):</p>
<p>(1) LLMs present an exciting opportunity for researchers to streamline their research and craft influential articles by facilitating literature reviews (Chen and Li 2023), retrieving and discovering the latest scientific progress, automatically searching for academic papers based on the needs of a given field and retrieving key information tailored to the requirements of different journals.</p>
<p>(2) LLMs have become indispensable tools in scientific writing, draft generation, article summarization, language and grammar checks, and translation of multilingual content (Liebrenz et al. 2023), engaging in discussions as virtual collaborators, and offering new perspectives and research directions, thereby enhancing the efficiency and diversity of scientific and academic output (Fatani 2023).</p>
<p>(3) LLMs with their advanced capabilities in natural language processing and understanding, can be effectively utilized for comprehensive data analysis and interpretation.These models can assist experimental design by providing valuable predictions, suggestions, summaries and interpretations of experimental results, thus enhancing the efficiency of the research process(Huang and Tan 2023).( 4) Researchers are able to gain valuable feedback and suggestions for improvement by submitting drafts or manuscripts, a practice that is especially advantageous for academic researchers who operate independently and do not have regular access to the peer review process.This allows such researchers to benefit from the expertise and insights of others, helping them to refine their work and enhance the quality of their research findings (Castellanos-Gomez 2023).(5) LLMs can be seamlessly integrated with video, audio, and image recognition technologies to forge groundbreaking models, algorithms, and strategies (Zhang et al. 2023a).</p>
<p>The synergy between LLMs and these recognition technologies empowers systems to understand and process multiple forms of data, allowing the development of sophisticated multimodal sentiment analysis techniques (Zhang et al. 2023b).This interdisciplinary approach has the potential to revolutionize various fields, including media analysis, marketing, and human-computer interaction (Zhang et al. 2023c).</p>
<p>Medical education and language translation</p>
<p>The LLMs have been utilized in diverse contexts within medical education and language translation.These include applications in licensing examinations such as the USMLE and the JMLE, the generation of multiple-choice questions, the evaluation of medical tests, educational initiatives in rehabilitation, and pharmacogenomics, as well as the translation of complex medical imaging reports into layman's terms to enhance healthcare education (Omran et al. 2023).</p>
<p>In the realm of medical assessments, the incorporation of multiple-choice questions necessitates substantial input from clinical professionals and educators.Gilson et al. (Gilson et al. 2023) investigated the performance of ChatGPT on multiple-choice questions from AMBOSS and NBME, which are part of USMLE.They analyzed the reasonableness of ChatGPT's answer generation logic and assessed the presence of internal and external information in the questions.The study found that ChatGPT significantly outperformed GPT-3 and InstructGPT on medical question-answering tasks, with its answer level comparable to that of third-year medical students.ChatGPT thus emerges as a potentially effective tool for interactive medical education that facilitates learning.Klang et al. (Klang et al. 2023) leveraged GPT-4 technology to compose 210 multiple-choice questions based on existing examination blueprints, categorizing them by algorithmic error and inaccuracy traits.GPT-4 thus serves as a potent supportive instrument for specialists in the construction of multiple-choice questions for medical assessments.Ueda et al. (Ueda et al. 2023) assessed ChatGPT's capability to analyze clinical scenarios and make decisions using the "Image Challenge" quiz from the New England Journal of Medicine (NEJM).This evaluation measured the accuracy of ChatGPT's responses in two settings: without options and within multiple-choice contexts.Without options, ChatGPT demonstrated an accuracy rate of 87%, while in multiple-choice scenarios, its accuracy reached 97%.This exceptional performance in the diagnostic category suggests that ChatGPT has significant potential for clinical application.Li et al. (Li et al. 2023b) conducted an evaluation of GPT-4's responses to diagnostic and treatment questions related to orthopedic diseases, adhering to the osteoarthritis management guidelines and orthopedic examination case questions.GPT-4 exhibited higher scores in terms of accuracy and completeness.It is poised to serve as an auxiliary tool in orthopedic clinical practice and patient education, offering high accuracy and comprehensive explanations of osteoarthritis treatment guidelines and clinical case analyses.</p>
<p>To test the performance of LLMs in JMLE, Takagi et al. (Takagi et al. 2023) conducted a comparative analysis and assessed the reliability of these LLMs in Japanese-based clinical reasoning and medical knowledge, examining 254 general sentence questions and clinical sentence questions.The results revealed that GPT-4 outperformed ChatGPT in general clinical questions, complex questions, and specific disease-related queries.Furthermore, GPT-4 achieved a score that met the passing standard of the JMLE, demonstrating its robust reliability in clinical reasoning and medical knowledge within the Japanese context.Kaneda et al. (Kaneda et al. 2023) investigated the responses of ChatGPT and GPT-4 in the Japanese National Nursing Examination (JNNE) of 2023.Their analysis included calculating the correct answer rate, score rate, comparing different LLMs, and assessing the accuracy rate of dialogue questions.GPT-4 exhibited sufficient performance to pass the JNNE, surpassing ChatGPT, which suggests that GPT-4 is suitable for specialized medical training in the Japanese clinical setting.</p>
<p>The remarkable performance of ChatGPT on USMLE has been a significant milestone in medical education (Sallam 2023b).LLMs have the potential to assist human learners in the field of medical education.Madrid-García et al. (Madrid-García et al. 2023) evaluated the performance of ChatGPT and GPT-4 in answering rheumatology questions on a specialized medical training access exam in Spain, examining factors such as the exam year, the diseases addressed, and the disease types.Both ChatGPT and GPT-4 demonstrated a high level of accuracy, suggesting that these models could serve as effective tools for rheumatology education, aiding in test preparation and complementing traditional teaching methods.Nori et al. (Nori et al. 2023) conducted a comprehensive evaluation of the GPT-4 model's performance on the USMLE dataset and the MultiMedQA benchmark dataset, assessing its content memory and the impact of images on the model's performance.The results indicated that GPT-4 achieved a score exceeding the passing threshold on the USMLE by more than 20 points without any professional hints, outperforming GPT-3.5 and specialized medical knowledge models such as Med-PaLM and Flan-PaLM.Kung et al. (Kung et al. 2023) evaluated ChatGPT's performance on the USMLE, a standardized medical test in the United States.ChatGPT achieved an accuracy level of approximately 60% without any specialized training.As the first LLM to reach this benchmark, ChatGPT exhibits comprehensible reasoning and practical clinical insight, enhancing trust and explainability in its applications (as illustrated in Fig. 5).</p>
<p>LLMs such as GPT-4 and Med-PaLM have demonstrated the ability to answer questions in the USMLE clinical knowledge test with an accuracy of over 80%.However, it remains unclear whether these LLMs can generate USMLE-like test questions.To address this question, Fleming et al. (Fleming et al. 2023) evaluated GPT-4's capability to produce Fig. 5 The workflow of generating results (Kung et al. 2023) authentic test questions and found that the USMLE test questions and answers generated by GPT-4 were not significantly different from those crafted by human physicians, and the generated questions and answers were deemed highly effective.</p>
<p>Rehabilitation education plays a vital role in the field of Physical Medicine and Rehabilitation (Peng et al. 2023).Models such as ChatGPT and GPT-4 can serve as virtual educational companions in rehabilitation.Engaging with ChatGPT or GPT-4 allows patients and their families to gain a deeper understanding of the essence, goals, and advantages of rehabilitation.This interaction facilitates a clearer comprehension of the challenges and expectations during the rehabilitation process, thereby enhancing the awareness and involvement in rehabilitation activities.Additionally, by acquiring effective self-management strategies from ChatGPT and GPT-4, patients and their families can actively engage in treatment, leading to improved rehabilitation outcomes and a better quality of life.Lyu et al. (Lyu et al. 2023) utilized ChatGPT to translate radiological reports of 76 brain magnetic resonance imaging cases into plain language.This initiative aimed to facilitate healthcare education for both patients and healthcare providers.</p>
<p>Medical imaging recognition and analysis</p>
<p>The LLMs have been trained to recognize and analyze medical images, including x-rays, magnetic resonance imaging (MRI), and ultrasound.These models can interpret features and structures within images, assisting physicians in accurately and rapidly identifying abnormalities, diagnosing diseases, and injuries.This capability significantly reduces the workload for radiologists (Waisberg et al. 2023).Moreover, LLMs can enhance image quality and resolution by reconstructing high-quality images from raw data obtained during medical imaging procedures.This improvement facilitates a deeper understanding of the internal structure and function of various organisms (e.g., (Tao et al. 2020)).</p>
<p>Medical imaging forms a cornerstone of the medical and healthcare field.The integration of LLMs can enhance radiologists' interpretive skills, facilitate communication between physicians and patients, and streamline workflow in clinical settings, particularly in hospitals.Yang et al. (2023b) developed the analytic framework BIGR-H based on Chat-GPT to investigate the influence of LLMs on various stakeholders, including businesses, insurance companies, governments, research institutions, hospitals, and others within the medical imaging realm.For medical device manufacturers, LLMs can serve as a valuable tool for analyzing user feedback and technical documents, providing insights that inform device development.For health insurance companies and providers, LLMs can process and analyze large datasets to identify potential fraud patterns and anomalies, offering tools for insurers to prevent fraud.Additionally, LLMs can address policyholders' queries, provide personalized recommendations to enhance customer experience, and ensure the delivery of accurate and valuable information.For regulatory bodies, LLMs can strengthen the regulatory review process and assist in the detailed scrutiny of medical product submissions.Public health authorities can utilize the analytical capabilities of these models to analyze health data, identify disease trends and patterns, and significantly enhance disease surveillance, informing disease control and prevention strategies.These insights can also inform the development of more effective health policies, optimize resource allocation, and contribute to public health.Scientific research institutions and academic researchers can leverage LLMs to explain and analyze biomedical datasets, promoting more accurate conclusions and discoveries.Radiology and physical examination centers are integral to healthcare services, and LLMs can significantly impact the medical imaging process.Rao et al. (Rao et al. 2023) utilized ChatGPT to evaluate the capability of radiological clinical decision support for critical clinical manifestations, such as breast cancer screening and breast cancer pain.</p>
<p>Clinical health reasoning and diagnostic reasoning</p>
<p>LLMs have shown remarkable proficiency in tasks involving clinical health reasoning, realworld medical question-answering, and diagnostic reasoning.2023b) also examined the performance of GPT-4 on various logical reasoning tasks, including out-of-distribution dataset testing for the robustness of GPT-related models.To improve the medical reasoning and in-depth thinking abilities of LLMs in medical conversational MQA, Weng et al. proposed a holistic thinking method that guides LLMs to perform both decentralized and centralized thinking, resulting in the generation of more professional and accurate answers (Fatani 2023).</p>
<p>Medical product safety monitoring and disease diagnosis</p>
<p>Due to the constrained scope and diversity of clinical trials for novel pharmaceuticals, comprehensive pre-market safety and efficacy assessments are often unattainable.LLMs can be utilized to monitor the safety of medical products by identifying Adverse Events (AEs) on social media platforms.Raval et al. (2021) developed the Adverse Event Detection and Extraction framework (AEDE), which is based on the T5 model.The AEDE leverages the T5 architecture's versatility in processing text from diverse domains and formats, thereby overcoming challenges such as the identification of infrequent signals, the management of imbalanced data in social media posts, substantial variations in text types across different media, the interpretation of misleading expressions and metaphors, and the annotation of data with extensive variability.Levine et al. (2023) assessed the diagnostic and triage capabilities of GPT-3 for common and serious diseases.GPT-3 yielded superior diagnostic outcomes compared to laypersons without domain-specific expertise, although its performance fell short of that of professional physicians.However, GPT-3 did not demonstrate significantly improved triage abilities over non-professional medical staff.Li et al. (2022a) utilized unbiased prompts to investigate the personality traits of GPT-3, InstructGPT, and FLAN-T5 through personality assessments (Short Dark Triad and Big Five Inventory) and well-being scales (Flourishing Scale and Satisfaction With Life Scale), with the intent of addressing sociopsychological safety concerns.The ChatGPT or GPT-4 model can aid intensive care physicians in reviewing potential diagnoses, treatment modalities, and possible complications in patient cases (Lu et al. 2023).By inputting pertinent information, intensive care physicians can render treatment decisions informed by a blend of clinical expertise.Da Mota Santana et al. ( 2023) discussed the potential utility of GPT-4 in digital oral radiology, based on dental radiographs, with the aim of reducing diagnostic error rates among professionals and enhancing clinical decision-making.</p>
<p>In the field of neurosurgery,LLMs have been utilized to forecast patients' hospital lengths of stay.Mantas (2022) conducted a comparative analysis of these predictions using the GPT-3 model and found no significant difference between the model's predictions and those made by physicians and patients.This result indicates the potential of employing LLMs for predicting the duration of hospitalization in neurosurgical cases.Virtual mental health assistants are increasingly common in healthcare settings, providing services such as counseling and supportive care to patients.However, these assistants are not suitable for use as diagnostic tools because they lack the ability to adhere to essential safety constraints and the professional clinical process knowledge required for accurate diagnosis.Roy et al. (2023) developed an algorithm named ProKnow-algo for the generation of natural language questions to collect diagnostic information iteratively through conversation.ProKnow-algo demonstrated a high level of safety and explainability in the context of diagnosing depression and anxiety (as depicted in Fig. 6).</p>
<p>Clinical decision support and administrative tasks assistance</p>
<p>The advanced capabilities of GPT-4 present a transformative opportunity to enhance doctor-patient communication, fostering a better understanding of patients' needs, anxieties, and expectations, thereby improving the overall medical experience (Nashwan et al. 2023).GPT-4 can facilitate the documentation of patients' medical histories by asking relevant questions, interpreting the responses, and presenting the information to physicians in a structured and concise format.This ensures that doctors gain a comprehensive understanding of their patients' conditions.Furthermore, GPT-4 can translate complex medical terminology and diagnostic results into plain language, making them more accessible to patients.It can also provide personalized advice on healthier lifestyles, diets, and medication use.</p>
<p>Fig. 6 The process of natural language question generation by ProKnow-algo (Roy et al. 2023) To facilitate the efficient use of billing coding in healthcare, Soroush et al. (Soroush et al. 2023) assessed the capability of GPT-3.5 and GPT-4 in generating accurate International Classification of Diseases (ICD) billing codes.They randomly selected 100 codes from the billing code set published by the Centers for Medicare and Medicaid Services (CMS) to test the models' ability to derive correct ICD codes from textual descriptions and to analyze any error patterns qualitatively and quantitatively.In the realm of rehabilitation, proper assessment is pivotal to the patient's treatment process (Peng et al. 2023).Without a thorough evaluation of the patient's status, crafting an effective treatment plan is challenging.Given that ChatGPT and GPT-4 can process a wealth of in-depth rehabilitation evaluation data, they hold significant potential for practical application.These models can extract relevant information, generate statistical analysis reports through data analysis and pattern recognition, and integrate various evaluation data to enhance work efficiency and accuracy.</p>
<p>LLMs can facilitate communication among spinal surgeons, patients, and their relatives, streamline the acquisition and analysis of patient health data, and assist in the development of effective surgical plans.Furthermore, LLMs are capable of acquiring real-time surgical navigation information and physiological parameters, offering postoperative rehabilitation guidance to patients, and providing intraoperative support to spinal surgeons.Ilicki et al. (Ilicki 2023) developed a user-friendly LLM tailored for non-technical professionals in healthcare, which aids in identifying the primary source of patient data, determining the intended recipient, categorizing the data, and assessing fundamental limitations, to evaluate its applicability in healthcare settings.He et al. (He et al. 2023) conducted a systematic investigation into the use of GPT-4 in lumbar disc herniation surgery and found that GPT-4 can significantly support spinal surgeons in diagnosing conditions, managing the perioperative period, conducting scientific research, and enhancing communication with patients, as well as in planning and executing surgical procedures.</p>
<p>Despite growing interest among scholars and medical professionals in leveraging LLMs in healthcare, the examination and appraisal of their practical application and safety in clinical contexts remain limited.To assess whether LLMs, including GPT-3.5 and GPT-4, can reliably assist physicians in responding to queries from Information Consulting Services (ICS) in a safe and consistent manner, Dash et al. submitted 66 questions from an ICS to GPT-3.5 and GPT-4 via simple prompts.The responses were evaluated by 12 physicians regarding their alignment with potential patient injury risk, and they were found to be consistent with the ICS's reports.Among the 35 questions, GPT-3.5 and GPT-4 answered 8 and 13 correctly, respectively (Rosol et al. 2023).The findings indicate that LLMs can furnish safe and dependable responses but may not fully address the specific information requirements of a given query.To comprehensively evaluate LLMs' performance in healthcare settings, calibrating and customizing these models might be warranted.</p>
<p>Neurosurgery is a highly specialized and complex medical field that is dedicated to the surgical management of conditions affecting the central and peripheral nervous systems (Li et al. 2023c).The diagnosis and treatment of neurosurgery are intricate and demand high accuracy.Consequently, experts and scholars have sought to apply the latest and most powerful large language models (LLMs) to preoperative evaluation and preparation, customizing surgical plans and postoperative care and rehabilitation strategies, and providing communication and educational support to patients.Despite the exemplary performance of ChatGPT and GPT-4 models in various medical tasks, there is currently a scarcity of data employing large-scale electronic health records (EHR) to assess the performance of LLMs and their utility in providing clinical diagnostic assistance to patients.Consequently, Zhang et al. (Zhang et al. 2023d) utilized two advanced models, ChatGPT and GPT-4, to conduct this research.The findings revealed that GPT-4 achieved an accuracy rate of 96% in disease classification tasks with a thinking chain and few-shot prompts, and it could be corrected three times for four diagnostic tests.</p>
<p>A significant application of LLMs lies in recommender systems (Wang and Chen 2021),, which offer healthcare decision-making support to both patients and professionals.These systems can suggest personalized lifestyle improvements, such as tailored recipes, exercise regimens, drug therapies, and disease diagnostics (Wang and Zhao 2022).LLMs also have the potential to aid physicians in disease prediction and treatment, while online pharmaceutical retailers can integrate decision-making capabilities into social networks to streamline product selection for customers (Tran et al. 2021).</p>
<p>Case studies of LLMMs</p>
<p>LLMs hold immense promise in the application within the healthcare domain.However, their performance in addressing clinical issues and specific tasks during actual implementation is a matter of concern, prompting some medical scholars to conduct comprehensive evaluations and studies on preoperative guidance (Ke et al. 2024), clinical language understanding (Wang et al. 2023d) among other aspects.Ke et al.(2024) conducted a case study on several critical aspects of preoperative guidance within 14 de-identified clinical scenarios, including fasting guidelines, preoperative carbohydrate loading, medication instructions, medical team guidance, necessary preoperative optimization, and delayed surgery.The case study compared the LLM's responses with those of four anesthesiologists with less than five years of medical experience, resulting in a total of 1260 responses generated jointly by physicians, LLMs, and the LLM-augmented RAG (Retrieval-Augmented Generation) technology.The study involved multiple popular LLMs, such as ChatGPT, GPT-4.0,Llama2, and GPT4-RAG.The research found that the model augmented by GPT-4 with RAG technology was the most accurate, with the GPT4-RAG model achieving a performance of 91.4%, which is 5.1% higher than the human-generated answers at 86.3%.The GPT4-RAG model retrieved information in an average of just 1 s and generated results in an average of 15-20 s, while human physicians took an average of 10 min to produce preoperative instructions.This demonstrates the feasibility of the GPT4-RAG model in the specialized field of healthcare.Moreover, Wang et al. (2023d) have investigated the effectiveness of large models such as ChatGPT, GPT-4, and Bard in various clinical language understanding tasks within the realm of clinical language understanding.These tasks encompass named entity recognition, relation extraction, natural language inference, semantic textual similarity, and QA, among others, by employing different learning strategies and prompting techniques.Experiments were conducted on various clinical benchmark datasets, delving into different prompting strategies such as standard prompts, chain-of-thought, self-questioning, zero-shot, and 5-shot.The findings revealed that GPT-4 generally outperforms Bard and ChatGPT in classification tasks like named entity recognition, natural language inference, and semantic textual similarity.Across all settings, the performance of self-questioning prompts consistently surpasses that of standard prompts, suggesting self-asking to be a promising approach.Compared to zero-shot learning, 5-shot learning typically leads to improved performance across all tasks, indicating that even the incorporation of a small amount of task-specific training data can significantly enhance the efficacy of pre-trained LLMs.</p>
<p>Summarization of state-of-the-art LLMMs application scenarios</p>
<p>LLMMs have achieved significant advancements in various application scenarios, the implementation of LLMMs provides critical insights for various parties within healthcare providers and patients.This comprises improved patient education, crafting responses, or extracting information from patient notes in response to specific queries for healthcare providers, reviewing scientific literature for researchers, and elucidating clinical research protocols for clinical research coordinators (Lee et al. 2023).The latest achievements have witnessed a technological leap in Chinese question-answering systems, such as Doctor-GLM (Xiong et al. 2023), Zhongjing (Yang et al. 2023a), and Huatuo (Li et al. 2023a) However, the generation and training of high-quality LLMMs pose significant challenges, necessitating substantial hardware support due to the massive resource consumption and prolonged training times.Moreover, the complexity of large-scale model architectures has heightened the difficulty in understanding and interpreting these models, particularly within the medical domain where incorrect predictions or biased recommendations could result in substantial harm to patients.</p>
<p>Available experimental datasets of LLMMs</p>
<p>This paper presents 56 experimental datasets that are most widely used by researchers in the medical and healthcare domains.These datasets encompass a range of tasks, including medical question-answering, medical knowledge representation, clinical evidence understanding and integration, diagnosis generation and summarization, and others.However, the extensive training of LLMMs is typically based on English-related datasets, resulting in a lack of medical knowledge, which can lead to poor performance in tasks such as disease diagnosis, drug recommendation, and clinical decision support.Existing medical datasets based on English corpora present challenges for conducting accurate experimental analyses of LLMMs on Chinese tasks.To address these issues, several scholars have proposed feasible solutions, such as Zhongjing (Yang et al. 2023a), DoctorGLM (Xiong et al. 2023), Huatuo (Li et al. 2023a), among others.Table 2 illustrates the datasets for LLMM research.</p>
<p>Evaluation metrics</p>
<p>Evaluating the performance of LLMMs is critical.Commonly used metrics include ROUGE, BERTScore, BLEU scores, accuracy, precision, recall, and F1-score for precision evaluation tasks.Some researchers also measure model performance using Medical Concept Coverage (Chintagunta et al. 2021) to test the importance and negations.Given the potential for unfair and unsafe outputs when applying LLMs in these fields, evaluating models and algorithms in this context requires considering their risks and feasibility.The average number of unsafe matches (Roy et al. 2023) offers a way to measure the effectiveness of the harm or severe consequences of the generated questions.Table 3 provides a summary of evaluation metrics used in different LLMM research papers.) is the maximum number of n-grams in a summary that a re concurrently present in the reference summary (Chintagunta et al. 2021), (Krishna et al. 2020), (Yadav et al. 2021), (Balumuri et al. 2021), (Yadav et al. 2022a), (Feng et al. 2022), (Zhou and Zhang 2021), (Alqahtani et al. 2023), (Sharma et al. 2023), (Chuang et al. 2023)
Concept − precision = N ∑ n=1 | Ĉ(n) ∩ C(n)| N ∑ n=1 | Ĉ(n)| Concept − recall = N ∑ n=1 | Ĉ(n) ∩ C(n)| N ∑ n=1 |C(n)|Accuracy Acc = TP+TN TP+TN+FP+FN
Acc is the ratio of the correctly predicted data to the total data.TP and TN are the positive segments selected and the negative segments unelected, respectively.FP and FN are the segments incorrectly selected or unelected (Krishna et al. 2020), (Zhou and Zhang 2021), (Singhal et al. 2023a), (Liévin et al. 2022), (Agrawal et al. 2022), (Yang et al. 2022), (Duong and Solomon 2023), (Levine et al. 2023), (Soroush et al. 2023), (Rosol et al. 2023), (Takagi et al. 2023),(Fleming et al. 2023), (Nori et al. 2023), (Ueda et al. 2023), (Gilson et al. 2023), (Han et al. 2023), (Singhal et al. 2023b), (Miao et al. 2023)  F1-score is a statistical measure that combines precision and recall to evaluate the accuracy of a test (Krishna et al. 2020), (Raval et al. 2021), (Agrawal et al. 2022), (Yang et al. 2022), (Zhang et al. 2023d) BERTScore
R BERT = 1 �x� ∑ x i ∈x xj ∈x max x T i xj P BERT = 1 �x� ∑ xj ∈x x i ∈x max x T i xj F BERT = 2 * P BERT * R BERT P BERT +R</p>
<p>BERT</p>
<p>BERTScore is a method for measuring the similarity between two texts, taking into account contextual and semantic information.The variable x is a reference, and xˆis a candidate (Yadav et al. 2022a), (Yadav et al. 2021), (Balumuri et al. 2021), (Feng et al. 2022), (Alqahtani et al. 2023)   (Soroush et al. 2023), (Rosol et al. 2023),(Takagi et al. 2023), (Gilson et al. 2023),(Singhal et al. 2023b), (Abdelhady and Davis 2023), (Ali et al. 2023) 5 Comparative performance analysis of various advanced models
BLEU scores BLEU = BP * exp( N ∑ n=1 w n log p n ) BP = 1 if c &gt; r e (1 -r/c) if c ≤ r BLEU
The medical and healthcare domains employ a wide array advanced techniques.We have summarized the performance of state-of-the-art LLMMs across various tasks, including clinical dialogue error correction (Nanayakkara et al. 2022), multiple-choice question answering (Singhal et al. 2023b), the MediQA shared task (Alqahtani et al. 2023), natural language inference (Yang et al. 2022), clinical health-aware reasoning (Feng et al. 2022), safety and explainability (Roy et al. 2023), and clinical decision support (Zhang et al. 2023d).These tasks are assessed using diverse metrics such as WER, accuracy, BLEU, BERTScore, ROUGE, AUM, AKCM, and ASRE.Moreover, we have summarized the performance of Chinese medical QA systems, which are evaluated based on professionalism, fluency, and safety, such as BenTsao (Wang et al. 2023c), Ziya-LLaMA (Zhang et al. 2022), DoctorGLM (Xiong et al. 2023), Zhongjing (Yang et al. 2023a), and Huatuo (Li et al. 2023a).</p>
<p>To present a comprehensive array of details regarding LLMMs across various tasks more clearly, we have meticulously described them in Tables 4 through 7, categorizing by task type.In Table 4, we encapsulate the performance metrics for three clinical dialogue transcription tasks utilizing Automatic Speech Recognition (ASR) technology from four prominent commercial ASR platforms: AWS Transcribe (AWS), Microsoft Speech-to-Text (Microsoft), IBM Watson (IBM), and Google Speech-to-Text (Google).A comprehensive breakdown of the Word Error Rate (WER) for the Gastrointestinal Clinical Dialogue dataset is provided within Table 4.</p>
<p>In Table 5, we have summarized the performance of two QA scenarios (namely, Multiple-choice QA and the MediQA shared task), encompassing six metrics across various datasets, including accuracy, BLEU, and F1 score.In the Multiple-choice QA task, Med-PaLM 2 achieved the top performance on the MedQA (USMLE) and PubMedQA datasets, while GPT-4 excelled on MedMCQA, MMLU-Medical Genetics, and MMLU-College Biology.For the MediQA shared task, the BART-Large model yielded the highest BLEU score, and T5 SAMSum achieved the highest F1 Score.Additionally, Li et al. (Li et al. 2023a) released the largest Chinese medical QA dataset, Huatuo-26 M, and Yang et al. (Yang et al. 2023a) pre-trained on this dataset.They conducted comparisons on Medical QA ranking in terms of Safety, Professionalism, and Fluency, as detailed in Table 5.</p>
<p>Table 6 presents an in-depth analysis of the semantic textual similarity, natural language inference, and clinical health-aware reasoning of multiple large models on the CHARDat, Pro-Know-data, MultiNLI, and Stanford NLI datasets, including metrics such as accuracy, Pearson correlation, BERTScore, ROUGE, AUM, AKCM, and ASRE.</p>
<p>Table 7 compares the performance of ChatGPT and GPT-4 with and without a detailed clinical guideline in providing clinical decision support for Obstructive Pulmonary Disease (COPD), Primary Biliary Cirrhosis (PBC), and Chronic Kidney Disease (CKD) on the MIMIC-III dataset.The results reveal that both ChatGPT and GPT-4, when equipped with an elaborate clinical guideline, consistently achieved higher F1 scores across the board, as detailed in Table 7.</p>
<p>Challenges and future directions</p>
<p>Given the critical nature of medical and healthcare activities, which are inherently linked to patient life and health (Singhal et al. 2023a), the deployment of large prediction models for research, medical advice, and decision-support systems necessitates a heightened focus   on safety, reliability, effectiveness, and patient privacy.As LLMs become more advanced, they are increasingly susceptible to generating harmful or inappropriate content, such as hallucinations, spam, sexist, and racist hate speech.These models may also produce responses that sound plausible yet are incorrect or absurd.Consequently, addressing safety concerns becomes paramount in healthcare decision-making involving LLMs.Recognizing this challenge, several researchers have adopted effective training and evaluation methods and have compiled new datasets for LLMs, such as the use of unbiased prompts (Li et al. 2022a) and the CHARDat dataset (Feng et al. 2022) We categorize the ethical and safety issues associated with LLMs into five key areas: data security and privacy-preservation, the risk of incorrect or misleading information, fairness and bias, transparency, explainability, and trustworthiness, and issues related to plagiarism, copyright, and accountability.We propose potential solutions and outline future prospects based on these categories and the challenges they present, as shown in Table 8.</p>
<p>Data security and privacy-preserving</p>
<p>Medical reports may inadvertently reveal private and demographic details of patient records.Ensuring patient privacy and adhering to data security regulations can be more complex and challenging than achieving optimal medical outcomes (Chuang et al. 2023).</p>
<p>The digitization of healthcare facilitates the sharing and repurposing of medical data, yet it also increases the risk of critical patient information being compromised (Liu et al. 2023c).</p>
<p>The Health Insurance Portability and Accountability Act (HIPAA) mandates patient confidentiality and privacy, stipulating that medical records must be sanitized of sensitive information before dissemination.Consequently, there is an imperative for robust solutions to identify and safeguard medical data.While rule-based and machine learning-based deidentification methods have been extensively implemented in practice, they remain limited in their versatility and effectiveness across diverse scenarios.</p>
<p>LLMs like ChatGPT and GPT-4 demonstrate significant potential in addressing the privacy protection challenge for medical text data.For instance, GPT-4 can leverage named entity recognition to construct a de-identification framework that automatically identifies and eliminates patient-specific information.A data management plan (DMP) (Stanciu 2023) provides guidelines for executing data-related activities and methods for safeguarding data security and confidentiality during storage, presentation, sharing, and distribution.Consequently, the DMP may serve as an effective approach to address data security issues.</p>
<p>Incorrectness and risk of inaccurate information</p>
<p>LLMs exhibit considerable potential in executing a diverse range of tasks that typically require human capabilities, having been trained on extensive internet data (Harrer 2023).However, this training may inadvertently integrate misinformation and biased content, potentially leading to significant drawbacks such as the generation of incorrect or fabricated information (Reddy 2023).Given the safety-critical nature of medical and healthcare domains, erroneous advice regarding patients' symptoms and medications can result in serious injury or even death (Munn et al. 2023), as exemplified by GPT-3 incorrectly recommending suicide for a patient (Atallah et al. 2023a).Consequently, it is imperative to implement safeguards around the use of LLMs in healthcare, including their assistance in tasks such as generating discharge summaries, automatically producing explanatory medical records, and providing medical recommendations.Plagiarism, copyrights, accountability By establishing normative standards for the application of LLMs in healthcare by medical, healthcare institutions, and government agencies, and providing guidance for the design and deployment of these models Section 6.5</p>
<p>The authenticity of LLM-generated outputs for various medical tasks can be validated against different references (Xie et al. 2023).Text summarization or simplification systems rely on the original medical documents, such as study protocols or clinical notes, to ensure that the AI-generated content aligns with the source information.Similarly, AI systems that generate radiology reports from Chest X-ray images use radiologists' reports as the reference.Moreover, methods that integrate few-shot In-Context Learning (ICL) with Chainof-Thought (CoT) and reason prompts can automate the detection and correction of medical errors in clinical notes (Wu et al. 2024).One approach involves manually analyzing a subset of the training and validation data to infer CoT prompts based on error types in the clinical notes.Another method prompts the LLM with the training data to deduce reasons for the correctness or incorrectness of the information.Both methods then enhance the CoTs and reasons with ICL examples to tackle tasks such as error detection, span identification, and error correction.</p>
<p>Fairness and bias</p>
<p>Due to their training on a vast array of internet content, LLMs may inadvertently incorporate biases (Arora and Arora 2023) (e.g., gender bias, racial bias, geopolitical biases, religious bias, nationality bias, sexual orientation bias, and age bias, etc.) across the web, posing severe threats in sensitive fields (Korngiebel and Mooney 2021).. Recent research has revealed a strong correlation between job opportunities and male job seekers, a correlation between negative emotions and the black race, and a correlation between positive emotions and the Asian race.For instance, GPT-4 was found not to simulate the demographics of medical conditions in various situations, consistently producing clinical hallucinations, including the differential diagnosis of standardized clinical samples, which are more likely to include stereotypes of specific racial, ethnic, and gender identities.The assessments and medical plans created by GPT-4 demonstrate a significant association between demographic attributes and patient differences in recommendations for expensive procedures (Zack et al. 2023).Medical and healthcare are particularly complex scenarios for applying LLMs (Singhal et al. 2023a).The training data of LLMs typically comes from institutions in high-income, English-speaking countries, which may severely limit the representativeness of viewpoints from other regions of the world.This can lead to biases in the mechanistic models of health and disease towards understanding this process in high-income countries.For example, when clinicians in Africa use LLMs to generate treatment plans for diabetes, they may focus on treatment models that are only applicable to high-income countries, thereby limiting the implementation of different treatment methods more relevant to the patient populations in other regions of the world (Thirunavukarasu et al. 2023).</p>
<p>The discrepancy between the model's output and the diagnoses of seasoned medical professionals can engender structural bias and inequitable treatment.Consequently, it is imperative to identify potential hazards and deviations that may affect doctors, patients, and healthcare professionals when designing models and algorithms.A limitation of large language models (LLMs) is that when biased data is employed for training (Atallah et al. 2023b), discriminatory outcomes can be perpetuated, persisting even after the model is recalibrated.To address this issue, some researchers have conducted exploratory work.For instance, in response to the unfairness exhibited by large language models such as T5 and LLaMA, Hua et al. (Lin et al. 2023) argue that similar individuals or groups should receive similar outputs in the pursuit of fairness.They have therefore proposed a strategy called Counterfactually Fair Prompting (CFP).For encoder-decoder large language models, an encoder prompt is needed to remove sensitive attributes, and a decoder prompt is required to maintain model performance.For models composed solely of a decoder, only a decoder prompt is necessary.By simply concatenating the CFP with the original input prompt, sensitive information in user token embeddings can be eliminated, achieving fairness across a set of sensitive attributes without the need to retrain the entire base model.</p>
<p>Transparency, explainability, and trustworthiness</p>
<p>Despite their impressive potential in performing various simple tasks, LLMs suffer from a lack of transparency, hindering their efficiency in assisting humans with complex tasks.To address this, several strategies have been proposed, such as using Chaining LLM (Wu et al. 2022) techniques or inserting tokens into generation prompts (Kalpakchi and Boye 2023).Specifically, SweCTRL-Mini is a data-transparent LLM designed for controllable text generation in Swedish.The core concept of SweCTRL-Mini is to enable the steering of the genre of the generated text through the use of Opening Control Codes (OCC) as single-token prompts.In addition to employing OCC to represent various stylistic texts, Keskar and colleagues have also incorporated Ending Control Codes (ECC) to signal to the model when to conclude text generation within a given genre.This transparent approach facilitates checking whether the model begins to blend genres.These strategies enhance the transparency and interpretability of both the LLM's training process and the generated text, thereby reducing errors in medical practitioners and bolstering the credibility of the strategy (Reddy 2023).A significant challenge for healthcare practitioners is the absence of guidelines for assessing whether LLM outputs align with social norms and regulations.The application of LLMs is currently grappling with a crisis of trustworthiness (Liu et al. 2023d).A foundational approach to improving safety and trustworthiness is to employ reinforcement learning from human feedback, which can augment strategies based on human guidance and mitigate the production of harmful content (Huang et al. 2023).</p>
<p>Plagiarism, copyrights, and accountability</p>
<p>Given that LLMs retain and train on the information provided, the generated text introduces the potential for plagiarism, which can be illegal and threaten the integrity and copyright of the publication (Nashwan et al. 2023).A New York Times report (Zhang et al. 2023f) indicates that ChatGPT provided conspiracy theories and misleading responses based on researchers' queries.Following adjustments to the output, ChatGPT generated persuasive but unattributed content, complicating the task of identifying plagiarism or original creation.Consequently, the development and application of new tools for detecting AI-generated text are essential.</p>
<p>Accountability is crucial to ensure that LLMs in medical and healthcare settings are used in a normative, responsible, and ethical manner (Reddy 2023).Establishing clear policies, procedures, and regulations can ensure that the use of LLMs aligns with legal and ethical standards.Therefore, it is advisable for medical, healthcare institutions, and government agencies to develop normative standards for the application of LLMs in healthcare and provide guidance for the design and deployment these models.</p>
<p>, LLaMA (Yunxiang et al. 2023), PMC-LLaMA (Wu et al. 2023), MedPaLM (George et al. 2023), MedPaLM2 (George et al. 2023), T5 and BERT (Wei et al. 2023).Nanayakkara et al. (Nanayakkara et al. 2022) introduced a seq2seq learning approach based on T5 and BERT models for automatic speech recognition and transcription error correction in clinical dialogues between practitioners and patients.Wu et al. (Wu et al. 2023) proposed the PMC-LLaMA open-source language model, which was fine-tuned by learning 4.8 million biomedical academic papers to enhance the accuracy of question answers in the biomedical field and to better understand specific concepts.MedPaLM (Singhal et al. 2023a) was the first LLMM model to pass the USMLE exam, and Med-PaLM 2 (Singhal et al. 2023b) based on PaLM 2 fine-tuned with medical domain knowledge, introducing a new integration method to provide a prompt strategy.The accuracy of Med-PaLM 2 on the MedQA dataset was 19% higher than that of Med-PaLM, achieving better performance compared to Med-PaLM in answering medical questions.</p>
<p>Fig. 3
3
Fig.3The pipeline of SPeC(Chuang et al. 2023)</p>
<p>Fig. 4
4
Fig.4The GatorTron model(Yang et al. 2022)</p>
<p>Feng et al. (2022) proposed the CHARD framework, which utilizes BERT and T5 models for clinical health reasoning, treating text generation models as implicit clinical knowledge bases to generate textual explanations of health-related problems across three dimensions.Liévin et al. (2022) evaluated the reasoning abilities of Codex and InstructGPT models using challenging realworld questions from USMLE, MedMCQA, and the PubMedQA medical reading dataset.Their findings suggested that scaling inference-time computing can enhance the reasoning performance of LLMs.Sharma et al. (2023) developed a Diagnostic Reasoning Benchmark for assessing clinical reasoning, using a clinically trained T5 model to analyze single-task and multi-task training on the summarization task.Singhal et al. (2023a) introduced the MultiMedQA benchmark for evaluating the answers generated by PaLM and Flan-PaLM models, which were refined through adjustments in model scale and instruction prompts.Liu et al. (</p>
<p>MCC measures the extent to which medical terms in the model's summary align with the actual content.Where C quality by comparing the target summary to others.Where n represents the length of the n-gram gram n</p>
<p>ratio of the correctly predicted positive samples to the total number of positive samples(Raval et al. 2021),(Agrawal et al. 2022),(Yang et al. 2022),(Zhang et al.   metric  for measuring the relevance of search results.The rank i represents the rank of the first results(Zhou and Zhang 2021),(Li et al. 2023a)</p>
<p>scores are a metric used to evaluate the quality of machine translation or any automatic translation system.The variable c is the total length of the candidate translation corpus, r is the reference length, w n and p n denote positive weights, and the geometric average of n-gram precision (Alqahtani et al. 2023),(Fatani 2023) Word error rate (WER) WER = S+D+I S+D+G WER measures the percentage of words that are incorrectly recognized or translated in a sequence of words..The S, D, and I represent the number of substitution, deletion, and insertion operations required to convert reference text into the language model output, respectively.G denotes the number of words that are identical in boththe reference text and the output text(Nanayakkara et al. 2022),(Leng et al. 2023),(Willett et al. 2023)</p>
<p>(</p>
<p>Table 3 (
3Research papers(Raval et al. 2021),(Li et al. 2023a),(Agrawalet al. 2022),(Yang et al. 2022),(Zhang et al.2023d)DescriptionRecall is the ratio of the total relevant docu-ments that are correctly retrieved to thetotal relevant documentsComputing formulaRecall = TP TP+FNF1 − score = 2 * Pr ecision * Recall Pr ecision+Recallcontinued)MetricsRecallF1-score</p>
<p>Table 3 (
3Research(Roy et al. 2023),(Sheth et al. 2022)(Roy et al. 2023)(Roy et al. 2023)(Lyu et al. 2023)DescriptionAUM is used to measure whether the gener-ated questions are safe. L is a dictionary ofinsecure concepts, and t( x) is the tokensthat generate text xAKCM is used to measure whether the gen-erated questions are interpretable. K is theknowledge base concept set mapped to xASRE measures the model's propensity togenerate questions that adhere to causaltags and rankings. x i denotes one of thequestions in the generated sequence, i isthe position in the sequence, R(x i ) repre-sents the classifier tag of x i"Good" indicates accurate translation,"Missing" refers to lost information,"Inaccurate" implies partially retainedinformation, and "Incorrect" denotesmisinterpretation of the original radiologyreportP-value represents the probability of observ-ing the data or more extreme data inhypothesis testingComputing formulaAUM (x, L) = |L ∪ t(x)| − |L∩t(x)| |L∪t(x)|AKCM(x, K) = |K∩t(x)| |K∪t(x)|ASRE(x i , R(x)) = x i ∈s i )−i) 2 ∑ (R(x �S�continued)MetricsAverage number of unsafe matches (AUM)Average number of knowledge contextmatches (AKCM)Average square rank error (ASRE)Good, missing, incorrect, and inaccurateP-value</p>
<p>Table 4
4
Summary of LLMMs performance in clinical dialogue transcription
PerformanceModelsTasks</p>
<p>Table 5 (
5Publications(Wang et al. 2023c), (Zhang et al.2022), (Xiong et al. 2023),(Yang et al. 2023a), (Li et al.2023a)MetricsProfessionalism and fluencyimprovement (%)Safety improvement (%)Professionalism and fluencyimprovement (%)Safety improvement (%)continued)Tasks Models Performance DatasetCMtMedQA Chinese medical dialogue Zhongjing-BenTsao 95Zhongjing-DoctorGLM 80Zhongjing-Ziya-LLaMA 71Zhongjing-HuatuoGPT 52Zhongjing-ChatGPT 49Zhongjing-BenTsao 99Zhongjing-DoctorGLM 83Zhongjing-Ziya-LLaMA 54Zhongjing-HuatuoGPT 68Zhongjing-ChatGPT 32Huatuo-26 M Zhongjing-BenTsao 94Zhongjing-DoctorGLM 78Zhongjing-Ziya-LLaMA 56Zhongjing-HuatuoGPT 51Zhongjing-ChatGPT 40Zhongjing-BenTsao 97Zhongjing-DoctorGLM 81Zhongjing-Ziya-LLaMA 44Zhongjing-HuatuoGPT 65Zhongjing-ChatGPT</p>
<p>Table 8
8
The challenges and potential solutions in LLMMs Challenges Mini uses Opening Control Codes (OCC) as single-token prompts to steer the genre of generated text, and Ending Control Codes (ECC) to signal when to end text generation within a genre.This transparent design aids in monitoring genre mixing by the model Section 6.4
Potential solutions
Summary &amp;ConclusionsThis survey systematically reviews the recent advancements in state-of-the-art LLMs within the medical and healthcare domain.The focus includes applications in medical question-answering, medical dialog summarization, electronic health records, clinical letters and medical note generation, scientific research, medical education, language translation, medical imaging recognition and analysis, clinical health reasoning, diagnostic reasoning, medical product safety monitoring, disease diagnosis, clinical decision support, and administrative tasks assistance.Additionally, we summarize the available experimental datasets for developing LLMs and provide evaluation methods to ensure that these models are accurate, safe, and effective for problem-solving in medical and healthcare scenarios.We also discuss the significant challenges in data security and privacy preservation, the risk of incorrect information, fairness and bias, transparency, explainability, trustworthiness, plagiarism, copyrights, and accountability.For each aspect, we summarize the causes of the challenges and limitations and offer possible solutions to address the related problems.Data AvailabilityNo datasets were generated or analysed during the current study.DeclarationsCompeting interests The authors have no competing interests as defined by Springer, or other interests that might be perceived to influence the results and/or discussion reported in this paper.Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.
Overview of the MEDIQA 2019 shared task on textual inference, question entailment and question answering. A Abacha, proceedings of the 18th BioNLP Workshop and Shared Task. the 18th BioNLP Workshop and Shared Task2019</p>
<p>Plastic surgery and artificial intelligence: how ChatGPT improved operation note accuracy, time, and education. A M Abdelhady, C R Davis, Mayo Clin Proc Digit Health. 132023</p>
<p>Large language models are few-shot clinical information extractors. M Agrawal, proceedings of the 2022 conference on empirical methods in natural language processing. the 2022 conference on empirical methods in natural language processing2022</p>
<p>Using ChatGPT to write patient clinic letters. S R Ali, Lancet Digit Health. 542023</p>
<p>Care4Lang at MEDIQA-Chat 2023: Fine-tuning language models for classifying and summarizing clinical dialogues. A Alqahtani, proceedings of the 5th clinical natural language processing workshop. the 5th clinical natural language processing workshop2023</p>
<p>Publicly available clinical BERT embeddings. E Alsentzer, 2019Preprint at</p>
<p>Ms marco chameleons: challenging the ms marco leaderboard with extremely obstinate queries. N Arabzadeh, proceedings of the 30th ACM international conference on information &amp; knowledge management. the 30th ACM international conference on information &amp; knowledge management2021</p>
<p>The survey on GPT-3 driven NLP approach for automatic medical documentation. N Arasu, AIP Conf Proc. 101525032023. 1063/5</p>
<p>Deep learning models for digital image processing: a review. R Archana, P E Jeevaraj, Artif Intell Rev. 571112024</p>
<p>The promise of large language models in health care. A Arora, A Arora, The Lancet. 4016412023. 10377</p>
<p>How large language models including generative pre-trained transformer (GPT) 3 and 4 will impact medicine and surgery. S Atallah, Tech Coloproctol. 272023. 2023</p>
<p>How large language models including generative pre-trained transformer (GPT) 3 and 4 will impact medicine and surgery. S Atallah, Tech Coloproctol. 232023</p>
<p>The potential of chatbots in chronic venous disease patient management. A Athavale, JVS Vasc Insights. 20231000192023</p>
<p>Sb_nitk at mediqa 2021: Leveraging transfer learning for question summarization in medical domain. S Balumuri, proceedings of the 20th workshop on biomedical language processing. the 20th workshop on biomedical language processing2021</p>
<p>Dynamic characterization of breast cancer response to neoadjuvant therapy using biophysical metrics of spatial proliferation. H J Bowers, Sci Rep. 121117182022</p>
<p>Benchmarking pysyft federated learning framework on mimic-iii dataset. A Budrionis, IEEE Access. 92021</p>
<p>Evaluating the feasibility of ChatGPT in healthcare: an analysis of multiple clinical and research scenarios. M Cascella, J Med Syst. 471332023</p>
<p>Good practices for scientific article writing with ChatGPT and other artificial intelligence language models. Castellanos-Gomez Ajn, Nanomanufacturing. 322023</p>
<p>A survey on evaluation of large language models. Y Chang, 10.1145/3641289ACM Trans on Intell Syst Technol. 892023</p>
<p>ChatGPT for mechanobiology and medicine: a perspective. M Chen, G Li, Mech Biol Med. 111000052023</p>
<p>Meddialog: a large-scale medical dialogue dataset. S Chen, 202033329Preprint at</p>
<p>The promise and peril of using a large language model to obtain clinical information: ChatGPT performs strongly as a fertility counseling tool with limitations. J Chervenak, 10.1016/j.fertnstert.2023.05.151Fertil Steril. 2023</p>
<p>Medically aware GPT-3 as a data generator for medical dialogue summarization. B Chintagunta, machine learning for healthcare conference. 2021</p>
<p>Evaluation of bert and albert sentence embedding performance on downstream nlp tasks. H Choi, 25th International conference on pattern recognition (ICPR). 2021. 2020</p>
<p>Spec: A soft prompt-based calibration on mitigating performance variability in clinical notes summarization. Y-N Chuang, 2023Preprint at</p>
<p>Ms marco: Benchmarking ranking models in the large-data regime. N Craswell, proceedings of the 44th International ACM SIGIR conference on research and development in information retrieval. the 44th International ACM SIGIR conference on research and development in information retrieval2021</p>
<p>Can GPT-4 be a viable alternative for discussing complex cases in digital oral radiology? a critical analysis. Sla Da Mota, Excli J. 222023</p>
<p>Smm4h 2022 task 2: Dataset for stance and premise detection in tweets about health mandates related to covid-19. V Davydova, E Tutubalina, Proceedings of The seventh workshop on social media mining for health applications, workshop &amp; shared task. The seventh workshop on social media mining for health applications, workshop &amp; shared task2022</p>
<p>Provision and characterization of a corpus for pharmaceutical, biomedical named entity recognition for pharmacovigilance: evaluation of language registers and training data sufficiency. J Dietrich, P Kazzer, Drug Saf. 462023</p>
<p>Adverse events in twitter-development of a benchmark reference dataset: results from IMI WEB-RADR. J Dietrich, Drug Saf. 432020</p>
<p>Analysis of large-language model versus human performance for genetics questions. D Duong, B D Solomon, Eur J Hum Genet. 322023</p>
<p>Transformer-based multimodal feature enhancement networks for multimodal depression detection integrating video, audio and remote photoplethysmograph signals. H Fan, Inform Fusion. 1041021612024</p>
<p>ChatGPT for future medical and dental research. B Fatani, Cureus. 1542023</p>
<p>Rethinking boundaries: End-to-end recognition of discontinuous mentions with pointer networks. H Fei, proceedings of the aaai conference on artificial intelligence. the aaai conference on artificial intelligence2021</p>
<p>Deep learning-based real-time building occupancy detection using AMI data. C Feng, IEEE Trans Smart Grid. 1152020</p>
<p>CHARD: Clinical health-aware reasoning across dimensions for text generation models. S Y Feng, 2022Preprint at</p>
<p>Assessing the Potential of USMLE-Like Exam Questions Generated by GPT-4. S Fleming, 2023</p>
<p>Understanding the impact of label skewness and optimization on federated learning for text classification. S Francis, Companion Proc of the ACM Web Conf. 20232023</p>
<p>DR. Bench: diagnostic reasoning benchmark for clinical natural language processing. Y Gao, J Biomed Inform. 1381042862023</p>
<p>Contextualized graph embeddings for adverse drug event detection. Y Gao, joint European conference on machine learning and knowledge discovery in databases. 2022</p>
<p>Prospective evaluation of adverse event recognition systems in twitter: results from the web-RADR Project. L M Gattepaille, Drug Saf. 432020</p>
<p>Can ChatGPT pass the thoracic surgery exam?. A Gencer, S Aydin, 10.1016/j.amjms.2023.08.001Am J Med Sci. 2023</p>
<p>AI-Driven breakthroughs in healthcare: google health's advances and the future of medical AI. A S George, Partn Univ Int Innov J. 132023</p>
<p>How does ChatGPT perform on the United States medical licensing examination? The implications of large language models for medical education and knowledge assessment. A Gilson, JMIR Med Educ. 912023</p>
<p>How well does ChatGPT do when taking the medical licensing exams? The implications of large language models for medical education and knowledge assessment. A Gilson, 2022. 22283901Preprint at</p>
<p>On survivorship bias in MS MARCO. P Gupta, S Macavaney, proceedings of the 45th International ACM SIGIR conference on research and development in information retrieval. the 45th International ACM SIGIR conference on research and development in information retrieval2022</p>
<p>A survey on large language models: Applications, challenges, limitations, and practical usage. M U Hadi, Authorea Prepr. 20232023</p>
<p>MedAlpaca: an open-source collection of medical conversational AI models and training data. T Han, 2023Preprint at</p>
<p>Mining adverse drug reactions from unstructured mediums at scale. H U Haq, 2022SpringerBerlin</p>
<p>Attention is not all you need: the complicated case of ethically using large language models in healthcare and medicine. S Harrer, EBioMedicine. 902023</p>
<p>Will ChatGPT/GPT-4 be a lighthouse to guide spinal surgeons?. Y He, Ann Biomed Eng. 512023. 2023</p>
<p>Infusing disease knowledge into BERT for health question answering, medical inference and disease name recognition. Y He, 2020Preprint at</p>
<p>MedNLI is not immune: Natural language inference artifacts in the clinical domain. C Herlihy, R Rudinger, 2021Preprint at</p>
<p>The role of ChatGPT in scientific communication: writing better scientific review articles. J Huang, M Tan, AJCR. 13411482023</p>
<p>A survey of safety and trustworthiness of large language models through the lens of verification and validation. X Huang, 2023Preprint at</p>
<p>A framework for critically assessing ChatGPT and other large language artificial intelligence model applications in health care. J Ilicki, Mayo Clin Proc Digital Health. 122023</p>
<p>ChatGPT for healthcare services: an emerging stage for an innovative perspective. M Javaid, BenchCouncil Trans Benchmarks Stand Eval. 311001052023</p>
<p>ChatGPT for healthcare providers and patients: Practical implications within dermatology. J Q Jin, A S Dobry, 10.1016/j.jaad.2023.05.081J Am Acad Dermatol. 2023</p>
<p>Supplementing domain knowledge to BERT with semi-structured information of documents. C Jing, Expert Syst Appl. 20231210542022</p>
<p>MIMIC-CXR, a de-identified publicly available database of chest radiographs with free-text reports. A E Johnson, Sci Data. 613172019</p>
<p>SweCTRL-Mini: a data-transparent Transformer-based large language model for controllable text generation in Swedish. D Kalpakchi, J Boye, 2023Preprint at</p>
<p>MMEAD: MS marco entity annotations and disambiguations. C Kamphuis, proceedings of the 46th International ACM SIGIR conference on research and development in information retrieval. the 46th International ACM SIGIR conference on research and development in information retrieval2023</p>
<p>Assessing the performance of GPT-3.5 and GPT-4 on the Japanese nursing examination. Y Kaneda, Cureus. 1582023</p>
<p>Development and testing of retrieval augmented generation in large language models: a case study report. Y Ke, 2024Preprint at</p>
<p>Utilizing artificial intelligence for crafting medical examinations: a medical education study with GPT-4. E Klang, Researchsquare. 6134232023</p>
<p>Considering the possibilities and pitfalls of generative pre-trained transformer 3 (GPT-3) in healthcare delivery. D M Korngiebel, S D Mooney, Npj Digit Med. 412021</p>
<p>Generating SOAP notes from doctor-patient conversations using modular summarization techniques. K Krishna, 2020Preprint at</p>
<p>Performance of ChatGPT on USMLE: potential for AI-assisted medical education using large language models. T H Kung, PLoS Digit Health. 22e00001982023</p>
<p>BioBERT: a pre-trained biomedical language representation model for biomedical text mining. J Lee, Bioinformatics. 3642020</p>
<p>ChatGPT Answers Common Patient Questions About Colonoscopy. T-C Lee, Gastroenterology. 1652023. 2023</p>
<p>Softcorrect: error correction with soft detection for automatic speech recognition. Y Leng, proceedings of the AAAI conference on artificial intelligence. the AAAI conference on artificial intelligence2023</p>
<p>The diagnostic and triage accuracy of the GPT-3 artificial intelligence model. D Levine, 2023Preprint at</p>
<p>Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. M Lewis, 2019BartPreprint at</p>
<p>Revolutionizing neurosurgery with GPT-4: a leap forward or ethical conundrum?. W Li, Ann Biomed Eng. 512023c</p>
<p>Discriminative neural clustering for speaker diarisation. Q Li, 2021 IEEE spoken language technology workshop (SLT). 2021</p>
<p>Is gpt-3 a psychopath? evaluating large language models from a psychological perspective. X Li, 2022aPreprint at</p>
<p>Unified named entity recognition as word-word relation classification. J Li, proceedings of the AAAI conference on artificial intelligence. the AAAI conference on artificial intelligence2022b</p>
<p>Huatuo-26M, a large-scale Chinese medical QA dataset. J Li, 2023aPreprint at</p>
<p>Assessing the performance of GPT-4 in the filed of osteoarthritis and orthopaedic case consultation. J Li, 2023bPreprint at</p>
<p>Generating scholarly content with ChatGPT: ethical challenges for medical publishing. M Liebrenz, Lancet Digit Health. 532023</p>
<p>Can large language models reason about medical questions?. V Liévin, 2022Preprint at</p>
<p>Graph-evolving meta-learning for low-resource medical dialogue generation. S Lin, proceedings of the AAAI conference on artificial intelligence. the AAAI conference on artificial intelligence2021</p>
<p>How can recommender systems benefit from large language models: a survey. J Lin, 2023</p>
<p>Heterogeneous graph reasoning for knowledge-grounded medical dialogue system. W Liu, Neurocomputing. 4422021</p>
<p>Summary of chatgpt/gpt-4 research and perspective towards the future of large language models. Y Liu, 2023aPreprint at</p>
<p>Evaluating the logical reasoning ability of chatgpt and gpt-4. H Liu, 2023b</p>
<p>Deid-gpt: Zero-shot medical text de-identification by gpt-4. Z Liu, 2023c</p>
<p>Trustworthy LLMs: a survey and guideline for evaluating large language models' alignment. Y Liu, 2023dPreprint at</p>
<p>Artificial intelligence in intensive care medicine: toward a ChatGPT/GPT-4 Way?. Y Lu, Ann Biomed Eng. 512023</p>
<p>Translating radiology reports into plain language using chatgpt and gpt-4 with prompt learning: promising results, limitations, and potential. Q Lyu, Vis Comput Ind Biomed. 62023. 2023</p>
<p>Harnessing ChatGPT and GPT-4 for evaluating the rheumatology questions of the spanish access exam to specialized medical training. A Madrid-García, 2023Preprint at</p>
<p>Length of stay prediction in neurosurgery with Russian GPT-3 language model compared to human expectations. J Mantas, 2022IOS pressAmsterdam</p>
<p>Assessing the accuracy of ChatGPT on core questions in glomerular disease. J Miao, Kidney Int Rep. 82023</p>
<p>Truth machines: synthesizing veracity in AI language models. L Munn, 2023Preprint at</p>
<p>Pre-training with scientific text improves educational question generation (student abstract). H Muse, proceedings of the aaai conference on artificial intelligence. the aaai conference on artificial intelligence2023</p>
<p>Clinical dialogue transcription error correction using Seq2Seq models. G Nanayakkara, 2022SpringerBerlin</p>
<p>Embracing the future of physician-patient communication: GPT-4 in gastroenterology. A J Nashwan, Gastroent Endosc. 12023. 2023</p>
<p>New meaning for NLP: the trials and tribulations of natural language processing with GPT-3 in ophthalmology. S Nath, Br J Ophthalmol. 10672022</p>
<p>Capabilities of gpt-4 on medical challenge problems. H Nori, 2023Preprint at</p>
<p>Effectiveness of pharmacogenomics educational interventions on healthcare professionals and health professions students: a systematic review. S Omran, 10.1016/j.sapharm.2023.07.012Res Soc Adm Pharm. 2023</p>
<p>Decision models on therapies for intensive medicine. M Passos, Procedia Comp Sci. 2102022</p>
<p>ChatGPT: the future of discharge summaries?. S B Patel, K Lam, Lancet Digit Health. 532023</p>
<p>AI-ChatGPT/GPT-4: an booster for the development of physical medicine and rehabilitation in the new era. S Peng, Ann Biomed Eng. 622023</p>
<p>Can we trust deep learning based diagnosis? the impact of domain shift in chest radiograph classification. In: thoracic image analysis: second international workshop, TIA 2020, held in conjunction with MICCAI. E Pooch, 2020. 2020. October 8, 2020Lima, Peru</p>
<p>Improving adverse drug event extraction with SpanBERT on different text typologies. B Portelli, international workshop on health intelligence. 2021</p>
<p>Scientific claim verification with VerT5erini. R Pradeep, 2020Preprint at</p>
<p>Data mining models for automatic problem identification in intensive medicine. I Quesado, Procedia Comp Sci. 2102022</p>
<p>Evaluating ChatGPT as an adjunct for radiologic decision-making. A Rao, 2023399Preprint at</p>
<p>Exploring a unified sequence-to-sequence transformer for medical product safety monitoring in social media. S Raval, 2021Preprint at</p>
<p>Benchmarking, ethical alignment, and evaluation framework for conversational AI: advancing responsible development of ChatGPT. P P Ray, BenchCouncil Trans Benchmarks Stand Eval. 31001362023</p>
<p>Evaluating large language models for use in healthcare: A framework for translational value assessment. S Reddy, Inform Med Unlocked. 411013042023. 2023</p>
<p>Evaluation of the performance of GPT-3.5 and GPT-4 on the Medical Final Examination. M Rosol, 2023Preprint at</p>
<p>Proknow: Process knowledge for safety constrained and explainable question generation for mental health diagnostic assistance. K Roy, Front Big Data. 510567282023</p>
<p>TDLR: top semantic-down syntactic language representation. In: NeurIPS'22 workshop on all things attention: bridging different perspectives on attention. K Roy, V ; Rawte, S Roy, proceedings of the 30th ACM international conference on information &amp; knowledge management. the 30th ACM international conference on information &amp; knowledge management2022. 2021Knowledge-aware neural networks for medical forum question classification</p>
<p>Multimodal model with text and drug embeddings for adverse drug reaction classification. A Sakhovskiy, E Tutubalina, J Biomed Inform. 1351041822022</p>
<p>The utility of ChatGPT as an example of large language models in healthcare education, research and practice: systematic review on the future perspectives and potential limitations. M J Sallam, 10.1101/2023.02.19.232861552023. 23286155</p>
<p>ChatGPT utility in healthcare education, research, and practice: systematic review on the promising perspectives and valid concerns. M Sallam, Healthcare. 1168872023a</p>
<p>The utility of ChatGPT as an example of large language models in healthcare education, research and practice: systematic review on the future perspectives and potential limitations. M Sallam, Healthcare. 118872023b</p>
<p>Extracting medical entities from social media. S Scepanovic, Proceedings of the ACM conference on health. 2020</p>
<p>Towards an automated SOAP note: classifying utterances from medical conversations. B Schloss, S Konam, machine learning for healthcare conference. 2020</p>
<p>Medication regimen extraction from medical conversations. S P Selvaraj, S Konam, Berlin. Springer2020</p>
<p>Multi-task training with in-domain language models for diagnostic reasoning. B Sharma, 2023Preprint at</p>
<p>Process knowledge-infused AI: toward user-level explainability, interpretability, and safety. A Sheth, IEEE Internet Comput. 2652022</p>
<p>BioMegatron: Larger biomedical domain language model. H-C Shin, 2020Preprint at</p>
<p>Large language models encode clinical knowledge. K Singhal, Nature. 6202023a</p>
<p>Towards expert-level medical question answering with large language models. K Singhal, 2023bPreprint at</p>
<p>Assessing GPT-3.5 and GPT-4 in generating international classification of diseases billing codes. A Soroush, 2023Preprint at</p>
<p>Data management plan for healthcare: following FAIR principles and addressing cybersecurity aspects. a systematic review using instructGPT. A Stanciu, 2023Preprint at</p>
<p>Performance of GPT-35 and GPT-4 on the Japanese medical licensing examination: comparison study. S Takagi, JMIR Med Educ. 91e480022023</p>
<p>Predicted rat interactome database and gene set linkage analysis. Y-T Tao, 10.1093/database/baaa0862020</p>
<p>Genome-wide identification and analysis of bZIP gene family reveal their roles during development and drought stress in wheel wingnut (Cyclocarya paliurus). Y-T Tao, BMC Genom. 2317432022</p>
<p>Xraygpt: Chest radiographs summarization using medical vision-language models. O Thawkar, 2023</p>
<p>Large language models in medicine. A J Thirunavukarasu, Nat Med. 82023</p>
<p>Opportunities and challenges for ChatGPT and large language models in biomedicine and health. S Tian, 2023Preprint at</p>
<p>Clinical Camel: An open-source expert-level medical language model with dialogue-based knowledge encoding. A Toma, 2023Preprint at</p>
<p>Recommender systems in the healthcare domain: state-of-the-art and research issues. Tnt Tran, J Intell Inf Syst. 572021</p>
<p>Evaluating GPT-4-based ChatGPT's clinical potential on the NEJM Quiz. D Ueda, 2023Preprint at</p>
<p>GPT-4: a new era of artificial intelligence in medicine. E Waisberg, Ir J Med Sci. 512023. 2023</p>
<p>A novel cascade hybrid many-objective recommendation algorithm incorporating multistakeholder concerns. D Wang, Y Chen, Inform Sci. 5772021</p>
<p>MedSTS: a resource for clinical semantic textual similarity. D Wang, X ; Zhao, Y Wang, Language Resour Eval. 162022. 2020Front Neurosci</p>
<p>Are large language models ready for healthcare? a comparative study on clinical language understanding. Y Wang, Proc Mach Learn Res. 2192023a</p>
<p>Mimic-extract: A data extraction, preprocessing, and representation pipeline for mimic-iii. S Wang, proceedings of the ACM conference on health. 2020b</p>
<p>Can LLMs like GPT-4 outperform traditional AI tools in dementia diagnosis? Maybe, but not today. Z Wang, 2023bPreprint at</p>
<p>Huatuo: Tuning llama model with chinese medical knowledge. H Wang, 2023cPreprint at</p>
<p>Are large language models ready for healthcare? A comparative study on clinical language understanding. Y Wang, 2023dPreprint at</p>
<p>An overview on language models: recent developments and outlook. C Wei, 2023Preprint at</p>
<p>A high-performance speech neuroprosthesis. F R Willett, Nature. 6202023</p>
<p>The shaky foundations of large language models and foundation models for electronic health records. M Wornow, Npj Digit Med. 611352023</p>
<p>AI chains: transparent and controllable human-AI interaction by chaining large language model prompts. T Wu, Proceedings of the 2022 CHI conference on human factors in computing systems. the 2022 CHI conference on human factors in computing systems2022</p>
<p>Pmc-llama: further finetuning llama on medical papers. C Wu, 2023Preprint at</p>
<p>KnowLab_AIMed at MEDIQA-CORR 2024: Chain-of-Though (CoT) prompting strategies for medical error detection and correction. Z Wu, proceedings of the 6th clinical natural language processing workshop. the 6th clinical natural language processing workshop2024</p>
<p>Faithful AI in medicine: a systematic review with large language models and beyond. medRxiv. Q Xie, 2023</p>
<p>Doctorglm: fine-tuning your chinese doctor is not a herculean task. H Xiong, 2023Preprint at</p>
<p>Question-aware transformer models for consumer health question summarization. S Yadav, J Biomed Inform. 1281040402022</p>
<p>Towards understanding consumer healthcare questions on the web with semantically enhanced contrastive learning. S Yadav, Proc of the ACM Web Conf. 20232023</p>
<p>Transfer learning-based approaches for consumer question and multi-answer summarization. S Yadav, proceedings of the 20th workshop on biomedical language processing. the 20th workshop on biomedical language processing2021</p>
<p>Chq-summ: a dataset for consumer healthcare question summarization. S Yadav, 2022aPreprint at</p>
<p>A large language model for electronic health records. X Yang, Npj Digit Med. 52022</p>
<p>The Impact of ChatGPT and LLMs on medical imaging stakeholders: perspectives and use cases. J Yang, MetaRadiology. 11000072023</p>
<p>COVID-CT-dataset: a CT scan dataset about COVID-19. X Yang, 2020</p>
<p>Zhongjing: enhancing the Chinese medical capabilities of large language model through expert feedback and real-world multi-turn dialogue. S Yang, 2023aPreprint at</p>
<p>Chatdoctor: a medical chat model fine-tuned on llama model using medical domain knowledge. H Yuan, 10.7759/cureus.408952022. 2023BioBART: pretraining and evaluation of a biomedical generative language model</p>
<p>Coding inequity: assessing GPT-4's potential for perpetuating racial and gender biases in healthcare. T Zack, 2023Preprint at</p>
<p>Adversarial neural network with sentiment-aware attention for detecting adverse drug reactions. T Zhang, J Biomed Inform. 1231038962021</p>
<p>MTDAN: a lightweight multi-scale temporal difference attention networks for automated video depression Detection. S Zhang, 10.1109/TAFFC.2023.3312263IEEE Trans Affect Comput. 33122632023a</p>
<p>Deep learning-based multimodal emotion recognition from audio, visual, and text modalities: a systematic review of recent advancements and future prospects. S Zhang, Expert Syst Appl. 2371216922023a</p>
<p>Multimodal emotion recognition based on audio and text by using hybrid attention networks. S Zhang, Biomed Signal Proc. 851050522023b</p>
<p>Chat generative pre-trained transformer (ChatGPT) usage in healthcare. Y Zhang, Gastroent Endosc. 132023c</p>
<p>Intent-aware Prompt Learning for medical question summarization. L Zhang, J Liu, 2022 IEEE international conference on bioinformatics and biomedicine (BIBM). 2022</p>
<p>Fengshenbang 1.0: being the foundation of chinese cognitive intelligence. J Zhang, 2022Preprint at</p>
<p>HuatuoGPT, towards Taming Language Model to Be a Doctor. H Zhang, 2023ePreprint at</p>
<p>The potential and pitfalls of using a large language model such as ChatGPT or GPT-4 as a clinical assistant. J Zhang, 10.48550/arXiv.2303.182232023dPreprint at</p>
<p>A survey of large language models. W X Zhao, 10.48550/arXiv.2303.182232023</p>
<p>Lirex: Augmenting language inference with relevant explanations. X Zhao, V Vydiswaran, proceedings of the AAAI conference on artificial intelligence. the AAAI conference on artificial intelligence2021</p>
<p>Datlmedqa: a data augmentation and transfer learning based solution for medical question answering. S Zhou, Y Zhang, Appl Sci. 1123112512021</p>
<p>Panlp at mediqa 2019: Pre-trained language models, transfer learning and knowlsedge distillation. W Zhu, 10.18653/v1/W19-5039ACL Anthology. 2019</p>            </div>
        </div>

    </div>
</body>
</html>