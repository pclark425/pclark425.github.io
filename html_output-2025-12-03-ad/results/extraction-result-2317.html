<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2317 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2317</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2317</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-63.html">extraction-schema-63</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <p><strong>Paper ID:</strong> paper-271522195</p>
                <p><strong>Paper Title:</strong> Artificial Intelligence Must Be Made More Scientific</p>
                <p><strong>Paper Abstract:</strong> The role of AI within science is growing. Here we assess its impact on research and argue that AI often lacks reproducibility, transparency, objectivity, and mechanistic understanding. To ensure AI benefits research, we need to develop forms of AI that are fully compatible with the scientific method.</p>
                <p><strong>Cost:</strong> 0.019</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2317.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2317.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AlphaFold</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AlphaFold (protein structure prediction model)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A deep learning–based model for predicting 3D protein structures from sequence; described as a very fast alternative to experimental structure determination but acting like a large 'look-up table' with limited uncertainty quantification.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Highly Accurate Protein Structure Prediction with AlphaFold</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>protein folding / structural biology</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Predict the three-dimensional structure of proteins from amino-acid sequence to accelerate structural biology and replace or augment experimental methods (e.g., X-ray crystallography).</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Large labeled datasets of known protein sequences and experimentally determined structures exist (implied abundant training data for many proteins), but coverage and representativeness vary and selection biases exist; the paper notes models work best on what they are trained on and that uncertainty quantification is difficult.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured biological data: amino-acid sequences and 3D coordinate/structural data (high-dimensional, spatial), implicitly multimodal (sequence ↔ structure).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High: complex, nonlinear mapping from sequence to 3D conformation; high dimensionality of structural outputs; model uses very large parameter counts, making behavior hard to characterize and extrapolation risky.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Mature experimental domain (structural biology) with established experimental techniques and extensive prior knowledge; AI application (large-scale DL structure prediction) is a newer, high-impact development within a mature domain.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High - scientific use (e.g., biology, therapeutics) requires mechanistic/structural understanding and reliable uncertainty estimates rather than black-box predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>AlphaFold (deep learning-based protein structure prediction)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>A large deep-learning model trained on known protein structures to predict 3D structures from sequence; characterized in the paper as highly parameterized (acts like a 'glorified look‑up table') and successful on data similar to its training set, but difficult to interrogate internally and to assign reliable uncertainties.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>supervised deep learning / predictive neural network</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable and transformative where abundant training examples exist; limitations arise when predictions require extrapolation beyond training distributions and when uncertainty quantification is necessary.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Qualitatively very effective and fast compared to experimental methods for many proteins, but reliability varies by case and uncertainty estimates are hard to obtain; functions best on in-distribution examples.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High — accelerates structural biology workflows and can substitute for some experimental determinations, enabling broad downstream applications in molecular biology and drug discovery, but impact limited when mechanistic interpretability or uncertainty is essential.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared qualitatively to X-ray crystallography: much faster and scalable but lacking mechanistic transparency and rigorous uncertainty quantification compared to experimental methods.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Large, curated training datasets and massive parameterization that capture statistical relationships in the training distribution; success limited by distributional coverage and lack of physico-chemical interpretability.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Deep learning excels at fast, high-coverage prediction when large labeled datasets exist, but its high parameterization produces a black box with limited uncertainty quantification and mechanistic interpretability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Artificial Intelligence Must Be Made More Scientific', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2317.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2317.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MLIPs</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Machine-Learned Interaction Potentials (MLIPs)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Neural-network–based interatomic potentials trained to map atomic configurations to energies/forces for use in molecular dynamics; highly flexible but typically extremely overparameterized and difficult to interpret or to provide reliable uncertainties.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Exploring the frontiers of condensed-phase chemistry with a general reactive machine learning potential</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>molecular dynamics / force field development / condensed-phase chemistry</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Replace or augment hand-crafted physics-based force fields by learning potentials from (usually large) datasets of atomic configurations and corresponding energies/forces to enable classical MD simulations with near ab initio accuracy and high efficiency.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Paper states MLIPs are trained from 'as large a data set as possible' (implying need for abundant, labelled energy/force data); data availability varies by system and generating labelled simulation or quantum data can be expensive.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured numerical data: atomic positions/configurations, associated energies, forces, and possibly chemical descriptors; high-dimensional and structured as graphs or coordinate arrays.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High: large configuration space, nonlinearity in mapping to energy/forces, high dimensionality, and many-body effects; typical MLIPs use neural networks with hundreds of thousands of fitting parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Emerging/active area built on a mature foundation (classical MD and electronic structure); MLIP approaches are relatively recent and rapidly evolving.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High - scientific simulations require physically meaningful potentials and uncertainty quantification to trust predictions and gain mechanistic insight.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Neural-network machine-learned interaction potentials (MLIPs)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Supervised neural-network regression models that learn mappings from atomic descriptors/configurations to potential energies and/or forces; architectures often have very large numbers of fitting parameters (hundreds of thousands), with parameters serving as statistical fit rather than physically interpretable terms; uncertainty quantification is difficult due to parameter count and opacity.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>supervised deep learning / regression (physics-agnostic ML potentials)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable for building high-accuracy potentials when extensive labelled simulation/QM data is available; limitations include difficulty with extrapolation, interpretability, and rigorous uncertainty quantification.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Can flexibly fit complex energy surfaces and thereby enable reactive and condensed-phase simulations, but reliability is limited outside training distributions and models are opaque compared with physics-based force fields.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Significant potential to improve simulation accuracy and enable new simulations if issues of reliability, interpretability, and UQ are addressed; otherwise risk of producing uninterpretable or non-robust potentials.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Contrasted with physics-based interaction potentials: MLIPs have far more parameters and lack physicochemical meaning, while physics-based models are lower-dimensional and more interpretable; Edeling et al. find only ~10–20 physics‑based parameters are typically influential.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Availability and representativeness of large labelled datasets, model capacity to fit complex surfaces, and careful treatment of extrapolation and uncertainty; failures often stem from overparameterization and insufficient UQ.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>MLIPs perform well in data-rich regimes by fitting complex relationships, but their high parameter counts and lack of physical interpretability make uncertainty quantification and mechanistic understanding difficult compared with physics-based alternatives.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Artificial Intelligence Must Be Made More Scientific', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2317.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2317.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Physics-based potentials + UQ</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Physics-based interaction potentials with uncertainty quantification</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Classical force fields constructed from physically meaningful terms combined with scalable uncertainty-quantification methods to identify which parameters materially influence observables, yielding interpretable, lower-dimensional control.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Global ranking of the sensitivity of interaction potential contributions within classical molecular dynamics force fields</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>molecular dynamics / force field parametrization</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Use physics-grounded functional forms for interatomic potentials and apply UQ to determine parameter sensitivities and ensure reproducible, interpretable predictions for molecular simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured numeric model parameters and simulation outputs (force field terms and resulting macroscopic properties); lower effective dimensionality after sensitivity analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Moderate-to-high: physically motivated models can have hundreds to a few thousand parameters nominally, but effective complexity is often low (small set of parameters dominates behavior).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Well-established: classical force-field modeling and associated theory are mature and widely used; UQ applied to force fields is a developing but credible technique.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High - models are designed to be mechanistically interpretable; mechanistic insight is a primary objective.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Physics-based interaction potentials combined with scalable uncertainty quantification</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Define interaction potentials using physically meaningful terms (electrostatics, van der Waals, bonded terms, etc.), then apply scalable UQ and sensitivity analysis to identify which parameters (typically ~10–20) drive properties of interest, enabling interpretability and robust inference.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>physics-based modeling + uncertainty quantification (not an ML black box)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable where mechanistic interpretability and reliable uncertainty estimates are required; appropriate alternative or complement to pure ML approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Authors report that typically only between ten and 20 force-field parameters have a significant influence on properties of interest.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Provides clearer scientific insight into parameter importance and yields models that are more interpretable and amenable to rigorous uncertainty quantification than large neural-network potentials.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High for enabling mechanistic understanding, reproducibility, and targeted model improvement; supports scientific inference more directly than opaque ML models.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Explicitly compared to MLIPs: physics-based models are lower-dimensional in effective parameter influence and allow meaningful uncertainty quantification, whereas MLIPs have many more fitting parameters without intrinsic physicochemical meaning.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Use of physically motivated model forms, scalable UQ techniques, and sensitivity analysis that reveal a low-dimensional influential parameter subspace.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Constraining models with physical structure and applying UQ yields interpretable, low-dimensional control over simulation behavior, unlike high-parameter black-box ML approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Artificial Intelligence Must Be Made More Scientific', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2317.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2317.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Foundation models / AI4Science</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Foundation models for science (e.g., DiG / Digital Graphormer, MatterGen, TamGen)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Large, general-purpose generative AI models and foundation models proposed for scientific tasks (molecular/materials generation, molecular distributions), often delivered via interactive LLM-style interfaces but raising concerns about reproducibility, interpretability, and extrapolation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>materials design, molecular generation, computational chemistry / AI4Science</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Use large foundation/generative models to propose candidate molecules/materials, predict distributions, or interactively assist scientists via LLM-like interfaces across diverse scientific tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Not specified in detail in the paper; implication is that foundation models require very large, diverse training corpora (i.e., abundant data) to perform broadly, but model performance depends heavily on training coverage.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Varied by model: molecular graphs and structural representations (DiG/Digital Graphormer), text/SMILES-like chemical language (TamGen), and other structured representations for materials; generally graph-structured and sequence-structured data, possibly multimodal.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High: generative design in chemical/material space is combinatorially large, highly nonlinear, and demands both novelty and validity of generated candidates; stochastic generative processes add variability.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Emerging application of foundation models to scientific discovery; underlying domains (materials science, chemistry) are mature, but foundation-model application is nascent and rapidly evolving.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High - authors emphasize that scientific applications require mechanistic explanations and that black-box generative models must be constrained or explainable to be scientifically useful.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Foundation models / generative models (DiG / Digital Graphormer, MatterGen, TamGen)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Large-scale generative or foundation models (graph transformers, chemical language models, other deep architectures) trained on large corpora to produce molecular/material candidates or distributions; often exposed via interactive LLM-style interfaces; outputs are stochastic and can vary between runs due to RNG dependence.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>foundation models / generative deep learning</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Potentially applicable across many design and prediction tasks, but practical use is constrained by reproducibility issues, dependence on training distribution, stochastic output variability, and lack of built-in mechanistic constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Seen as promising and fashionable (AI4Science), but criticized for being opaque, dependent on training data, and producing variable outputs; generative models particularly vulnerable to stochastic variability and extrapolation failure.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High if integrated with scientific constraints and explainability — could accelerate design and hypothesis generation — but substantial risk if used without mechanistic constraints or rigorous validation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Not empirically compared in the paper; conceptually contrasted with physics-constrained/hybrid approaches and with the need for explainability and causal inference.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Scale of model and data, representativeness of training corpus, incorporation of physics or causal constraints, and explainability mechanisms to produce scientifically actionable outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Foundation/generative models provide powerful, general-purpose capabilities but risk non-reproducible, non-mechanistic outputs unless constrained by physics, causality, or explainability tailored to scientific needs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Artificial Intelligence Must Be Made More Scientific', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2317.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2317.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>xAI / Causal AI / Big AI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Explainable AI (xAI), Causal AI, and 'Big AI' (hybrid ML + physics)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Suggested directions to make AI conform to the scientific method: xAI to explain inner workings, causal AI to infer causal relations, and 'Big AI' to combine ML with physics-based constraints so models obey laws of nature.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>general scientific methodology / AI for science</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Address shortcomings of black-box ML (lack of reproducibility, interpretability, mechanistic insight) by developing explainable, causal, and physics-constrained hybrid AI approaches that align with scientific standards.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Conceptual and emerging research directions; not a mature, standardized practice in most scientific fields yet.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Very high - these approaches are advocated precisely to provide mechanistic explanations, causal understanding, and adherence to physical laws.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Explainable AI (xAI), Causal AI, Big AI (hybrid physics-informed ML)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>xAI: techniques to make models' internal decisions and predictions interpretable in scientific terms; Causal AI: methods to identify causal relations rather than correlations; Big AI: deliberate hybrids combining ML with physics-based models and constraints so predictions respect known laws of nature.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>explainable/causal AI; hybrid physics-informed ML</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Recommended and appropriate for scientific applications where reproducibility, interpretability, and mechanistic understanding are required; seen as a path forward rather than a tested solution within this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Advocated qualitatively as necessary to restore scientific rigor to AI-assisted science; no empirical effectiveness data provided in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Potentially transformative: could make AI outputs scientifically trustworthy, reproducible, and mechanistically informative, enabling broader scientific adoption.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Stated in contrast to current black-box ML approaches (e.g., large foundation models and MLIPs) which lack interpretability and rigorous UQ.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Integration of theory and data, enforcement of physical constraints, development of causal inference methods, and widespread adoption of reproducibility and transparency standards.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Imposing explainability, causality, and physics constraints on AI aligns it with the scientific method and addresses the principal failings of current black-box approaches in scientific contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Artificial Intelligence Must Be Made More Scientific', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2317.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2317.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hybrid ML + physics (pandemic pipeline)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hybrid machine learning and physics-based simulations for accelerated drug discovery (pandemic drugs pipeline)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An infrastructure example that integrates machine learning with physics-based simulations on high-performance computers to speed COVID-19 drug-discovery efforts, illustrating a hybrid approach that combines data-driven and mechanistic methods.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Pandemic drugs at pandemic speed: infrastructure for accelerating COVID-19 drug discovery with hybrid machine learningand physics-based simulations on high-performance computers</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>drug discovery / computational biomedicine</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Rapid identification and evaluation of therapeutic candidates by combining ML models and physics-based simulations at scale on HPC infrastructure.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Not specified in detail in this paper; implied multimodal (molecular structures, simulation outputs, assay data) and structured numeric/simulation data.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High: large search spaces of candidate molecules, computationally intensive physics simulations, and need for rapid screening under time constraints requiring HPC resources.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Applied and pragmatic: drug discovery is a mature domain, and hybrid ML+physics pipelines have been applied in the pandemic context (2021) to accelerate workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High - understanding how therapies work and ensuring unbiased, validated predictions is essential in healthcare applications.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Hybrid machine learning + physics-based simulation pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Integrates ML models for rapid screening or surrogate modeling with physics-based simulation methods (e.g., molecular dynamics, free-energy calculations) executed on high-performance computing resources to accelerate candidate evaluation; emphasis on infrastructure and workflow integration.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>hybrid physics-informed ML / integrated simulation-ML workflows</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable and practical for large-scale, time-sensitive drug-discovery efforts when HPC and domain expertise are available; appropriate for combining speed and mechanistic fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Presented as an enabling infrastructure that can accelerate drug-discovery timelines; treated as a positive example of combining ML with physics rather than a rigorous evaluation within this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High in urgent discovery contexts (e.g., pandemics) for reducing time-to-candidate and scaling complex simulations; potential to improve throughput while retaining mechanistic checks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Implicitly favored over pure-ML or pure-simulation approaches: hybrid pipelines aim to balance speed and mechanistic grounding.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Access to HPC resources, well-integrated workflows combining ML surrogates and physics simulations, and strong domain expertise to validate predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Hybrid ML + physics pipelines on HPC can accelerate applied discovery tasks by combining ML speed with mechanistic simulation fidelity, provided infrastructure and domain validation are in place.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Artificial Intelligence Must Be Made More Scientific', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2317.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2317.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Generative methods</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative AI methods (stochastic generative models)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Generative machine-learning approaches used to propose models/solutions (e.g., molecules, materials) that are stochastic by nature and sensitive to random number generators, leading to non-deterministic outputs and reproducibility concerns.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>general scientific design and generation tasks (molecules, materials, distributions)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Generate candidate structures, distributions, or solutions via learned generative processes; outputs are inherently stochastic and can vary between runs.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High: generative tasks operate over combinatorial spaces and require both validity and novelty; stochasticity increases variability and complicates reproducibility.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Emerging in scientific contexts; generative models are widely used in ML but adaptation to rigorous scientific workflows is nascent.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium-to-high - scientific applications demand validation and mechanistic rationale for generated candidates, beyond mere novelty.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Stochastic generative models (generative ML)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Models that produce new samples (molecules, materials, distributions) via learned generative processes; outputs depend on random seeds and internal randomness, producing non-deterministic results and reproducibility challenges.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>generative models / unsupervised or conditional generative learning</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable for hypothesis and candidate generation, but reproducibility and validation are significant constraints for scientific adoption.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Useful for exploring design spaces and proposing candidates, but criticized for non-reproducible one-off outputs and dependence on training distribution; reproducibility challenges analogous to single-run MD simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Moderate-to-high for idea generation if coupled with validation and repeatability protocols; otherwise limited by variability and lack of mechanistic grounding.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Contrasted qualitatively with deterministic physics-based simulations and with ML approaches that emphasize UQ and interpretability.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Repeated sampling, robust validation pipelines, seed control, and integration with mechanistic evaluation to filter and validate generated candidates.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Generative ML is powerful for exploring large design spaces but must be paired with reproducible protocols and mechanistic validation to be scientifically useful.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Artificial Intelligence Must Be Made More Scientific', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Highly Accurate Protein Structure Prediction with AlphaFold <em>(Rating: 2)</em></li>
                <li>Exploring the frontiers of condensed-phase chemistry with a general reactive machine learning potential <em>(Rating: 2)</em></li>
                <li>Global ranking of the sensitivity of interaction potential contributions within classical molecular dynamics force fields <em>(Rating: 2)</em></li>
                <li>Pandemic drugs at pandemic speed: infrastructure for accelerating COVID-19 drug discovery with hybrid machine learningand physics-based simulations on high-performance computers <em>(Rating: 2)</em></li>
                <li>Mattergen: a generative model for inorganic materials design <em>(Rating: 1)</em></li>
                <li>Target-aware Molecule Generation for Drug Design Using a Chemical Language Model <em>(Rating: 1)</em></li>
                <li>Predicting equilibrium distributions for molecular systems with deep learning <em>(Rating: 1)</em></li>
                <li>A rigorous uncertainty-aware quantification framework is essential for reproducible and replicable machine learning workflows <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2317",
    "paper_id": "paper-271522195",
    "extraction_schema_id": "extraction-schema-63",
    "extracted_data": [
        {
            "name_short": "AlphaFold",
            "name_full": "AlphaFold (protein structure prediction model)",
            "brief_description": "A deep learning–based model for predicting 3D protein structures from sequence; described as a very fast alternative to experimental structure determination but acting like a large 'look-up table' with limited uncertainty quantification.",
            "citation_title": "Highly Accurate Protein Structure Prediction with AlphaFold",
            "mention_or_use": "mention",
            "scientific_problem_domain": "protein folding / structural biology",
            "problem_description": "Predict the three-dimensional structure of proteins from amino-acid sequence to accelerate structural biology and replace or augment experimental methods (e.g., X-ray crystallography).",
            "data_availability": "Large labeled datasets of known protein sequences and experimentally determined structures exist (implied abundant training data for many proteins), but coverage and representativeness vary and selection biases exist; the paper notes models work best on what they are trained on and that uncertainty quantification is difficult.",
            "data_structure": "Structured biological data: amino-acid sequences and 3D coordinate/structural data (high-dimensional, spatial), implicitly multimodal (sequence ↔ structure).",
            "problem_complexity": "High: complex, nonlinear mapping from sequence to 3D conformation; high dimensionality of structural outputs; model uses very large parameter counts, making behavior hard to characterize and extrapolation risky.",
            "domain_maturity": "Mature experimental domain (structural biology) with established experimental techniques and extensive prior knowledge; AI application (large-scale DL structure prediction) is a newer, high-impact development within a mature domain.",
            "mechanistic_understanding_requirements": "High - scientific use (e.g., biology, therapeutics) requires mechanistic/structural understanding and reliable uncertainty estimates rather than black-box predictions.",
            "ai_methodology_name": "AlphaFold (deep learning-based protein structure prediction)",
            "ai_methodology_description": "A large deep-learning model trained on known protein structures to predict 3D structures from sequence; characterized in the paper as highly parameterized (acts like a 'glorified look‑up table') and successful on data similar to its training set, but difficult to interrogate internally and to assign reliable uncertainties.",
            "ai_methodology_category": "supervised deep learning / predictive neural network",
            "applicability": "Applicable and transformative where abundant training examples exist; limitations arise when predictions require extrapolation beyond training distributions and when uncertainty quantification is necessary.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Qualitatively very effective and fast compared to experimental methods for many proteins, but reliability varies by case and uncertainty estimates are hard to obtain; functions best on in-distribution examples.",
            "impact_potential": "High — accelerates structural biology workflows and can substitute for some experimental determinations, enabling broad downstream applications in molecular biology and drug discovery, but impact limited when mechanistic interpretability or uncertainty is essential.",
            "comparison_to_alternatives": "Compared qualitatively to X-ray crystallography: much faster and scalable but lacking mechanistic transparency and rigorous uncertainty quantification compared to experimental methods.",
            "success_factors": "Large, curated training datasets and massive parameterization that capture statistical relationships in the training distribution; success limited by distributional coverage and lack of physico-chemical interpretability.",
            "key_insight": "Deep learning excels at fast, high-coverage prediction when large labeled datasets exist, but its high parameterization produces a black box with limited uncertainty quantification and mechanistic interpretability.",
            "uuid": "e2317.0",
            "source_info": {
                "paper_title": "Artificial Intelligence Must Be Made More Scientific",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "MLIPs",
            "name_full": "Machine-Learned Interaction Potentials (MLIPs)",
            "brief_description": "Neural-network–based interatomic potentials trained to map atomic configurations to energies/forces for use in molecular dynamics; highly flexible but typically extremely overparameterized and difficult to interpret or to provide reliable uncertainties.",
            "citation_title": "Exploring the frontiers of condensed-phase chemistry with a general reactive machine learning potential",
            "mention_or_use": "mention",
            "scientific_problem_domain": "molecular dynamics / force field development / condensed-phase chemistry",
            "problem_description": "Replace or augment hand-crafted physics-based force fields by learning potentials from (usually large) datasets of atomic configurations and corresponding energies/forces to enable classical MD simulations with near ab initio accuracy and high efficiency.",
            "data_availability": "Paper states MLIPs are trained from 'as large a data set as possible' (implying need for abundant, labelled energy/force data); data availability varies by system and generating labelled simulation or quantum data can be expensive.",
            "data_structure": "Structured numerical data: atomic positions/configurations, associated energies, forces, and possibly chemical descriptors; high-dimensional and structured as graphs or coordinate arrays.",
            "problem_complexity": "High: large configuration space, nonlinearity in mapping to energy/forces, high dimensionality, and many-body effects; typical MLIPs use neural networks with hundreds of thousands of fitting parameters.",
            "domain_maturity": "Emerging/active area built on a mature foundation (classical MD and electronic structure); MLIP approaches are relatively recent and rapidly evolving.",
            "mechanistic_understanding_requirements": "High - scientific simulations require physically meaningful potentials and uncertainty quantification to trust predictions and gain mechanistic insight.",
            "ai_methodology_name": "Neural-network machine-learned interaction potentials (MLIPs)",
            "ai_methodology_description": "Supervised neural-network regression models that learn mappings from atomic descriptors/configurations to potential energies and/or forces; architectures often have very large numbers of fitting parameters (hundreds of thousands), with parameters serving as statistical fit rather than physically interpretable terms; uncertainty quantification is difficult due to parameter count and opacity.",
            "ai_methodology_category": "supervised deep learning / regression (physics-agnostic ML potentials)",
            "applicability": "Applicable for building high-accuracy potentials when extensive labelled simulation/QM data is available; limitations include difficulty with extrapolation, interpretability, and rigorous uncertainty quantification.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Can flexibly fit complex energy surfaces and thereby enable reactive and condensed-phase simulations, but reliability is limited outside training distributions and models are opaque compared with physics-based force fields.",
            "impact_potential": "Significant potential to improve simulation accuracy and enable new simulations if issues of reliability, interpretability, and UQ are addressed; otherwise risk of producing uninterpretable or non-robust potentials.",
            "comparison_to_alternatives": "Contrasted with physics-based interaction potentials: MLIPs have far more parameters and lack physicochemical meaning, while physics-based models are lower-dimensional and more interpretable; Edeling et al. find only ~10–20 physics‑based parameters are typically influential.",
            "success_factors": "Availability and representativeness of large labelled datasets, model capacity to fit complex surfaces, and careful treatment of extrapolation and uncertainty; failures often stem from overparameterization and insufficient UQ.",
            "key_insight": "MLIPs perform well in data-rich regimes by fitting complex relationships, but their high parameter counts and lack of physical interpretability make uncertainty quantification and mechanistic understanding difficult compared with physics-based alternatives.",
            "uuid": "e2317.1",
            "source_info": {
                "paper_title": "Artificial Intelligence Must Be Made More Scientific",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "Physics-based potentials + UQ",
            "name_full": "Physics-based interaction potentials with uncertainty quantification",
            "brief_description": "Classical force fields constructed from physically meaningful terms combined with scalable uncertainty-quantification methods to identify which parameters materially influence observables, yielding interpretable, lower-dimensional control.",
            "citation_title": "Global ranking of the sensitivity of interaction potential contributions within classical molecular dynamics force fields",
            "mention_or_use": "mention",
            "scientific_problem_domain": "molecular dynamics / force field parametrization",
            "problem_description": "Use physics-grounded functional forms for interatomic potentials and apply UQ to determine parameter sensitivities and ensure reproducible, interpretable predictions for molecular simulations.",
            "data_availability": null,
            "data_structure": "Structured numeric model parameters and simulation outputs (force field terms and resulting macroscopic properties); lower effective dimensionality after sensitivity analysis.",
            "problem_complexity": "Moderate-to-high: physically motivated models can have hundreds to a few thousand parameters nominally, but effective complexity is often low (small set of parameters dominates behavior).",
            "domain_maturity": "Well-established: classical force-field modeling and associated theory are mature and widely used; UQ applied to force fields is a developing but credible technique.",
            "mechanistic_understanding_requirements": "High - models are designed to be mechanistically interpretable; mechanistic insight is a primary objective.",
            "ai_methodology_name": "Physics-based interaction potentials combined with scalable uncertainty quantification",
            "ai_methodology_description": "Define interaction potentials using physically meaningful terms (electrostatics, van der Waals, bonded terms, etc.), then apply scalable UQ and sensitivity analysis to identify which parameters (typically ~10–20) drive properties of interest, enabling interpretability and robust inference.",
            "ai_methodology_category": "physics-based modeling + uncertainty quantification (not an ML black box)",
            "applicability": "Highly applicable where mechanistic interpretability and reliable uncertainty estimates are required; appropriate alternative or complement to pure ML approaches.",
            "effectiveness_quantitative": "Authors report that typically only between ten and 20 force-field parameters have a significant influence on properties of interest.",
            "effectiveness_qualitative": "Provides clearer scientific insight into parameter importance and yields models that are more interpretable and amenable to rigorous uncertainty quantification than large neural-network potentials.",
            "impact_potential": "High for enabling mechanistic understanding, reproducibility, and targeted model improvement; supports scientific inference more directly than opaque ML models.",
            "comparison_to_alternatives": "Explicitly compared to MLIPs: physics-based models are lower-dimensional in effective parameter influence and allow meaningful uncertainty quantification, whereas MLIPs have many more fitting parameters without intrinsic physicochemical meaning.",
            "success_factors": "Use of physically motivated model forms, scalable UQ techniques, and sensitivity analysis that reveal a low-dimensional influential parameter subspace.",
            "key_insight": "Constraining models with physical structure and applying UQ yields interpretable, low-dimensional control over simulation behavior, unlike high-parameter black-box ML approaches.",
            "uuid": "e2317.2",
            "source_info": {
                "paper_title": "Artificial Intelligence Must Be Made More Scientific",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "Foundation models / AI4Science",
            "name_full": "Foundation models for science (e.g., DiG / Digital Graphormer, MatterGen, TamGen)",
            "brief_description": "Large, general-purpose generative AI models and foundation models proposed for scientific tasks (molecular/materials generation, molecular distributions), often delivered via interactive LLM-style interfaces but raising concerns about reproducibility, interpretability, and extrapolation.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "materials design, molecular generation, computational chemistry / AI4Science",
            "problem_description": "Use large foundation/generative models to propose candidate molecules/materials, predict distributions, or interactively assist scientists via LLM-like interfaces across diverse scientific tasks.",
            "data_availability": "Not specified in detail in the paper; implication is that foundation models require very large, diverse training corpora (i.e., abundant data) to perform broadly, but model performance depends heavily on training coverage.",
            "data_structure": "Varied by model: molecular graphs and structural representations (DiG/Digital Graphormer), text/SMILES-like chemical language (TamGen), and other structured representations for materials; generally graph-structured and sequence-structured data, possibly multimodal.",
            "problem_complexity": "High: generative design in chemical/material space is combinatorially large, highly nonlinear, and demands both novelty and validity of generated candidates; stochastic generative processes add variability.",
            "domain_maturity": "Emerging application of foundation models to scientific discovery; underlying domains (materials science, chemistry) are mature, but foundation-model application is nascent and rapidly evolving.",
            "mechanistic_understanding_requirements": "High - authors emphasize that scientific applications require mechanistic explanations and that black-box generative models must be constrained or explainable to be scientifically useful.",
            "ai_methodology_name": "Foundation models / generative models (DiG / Digital Graphormer, MatterGen, TamGen)",
            "ai_methodology_description": "Large-scale generative or foundation models (graph transformers, chemical language models, other deep architectures) trained on large corpora to produce molecular/material candidates or distributions; often exposed via interactive LLM-style interfaces; outputs are stochastic and can vary between runs due to RNG dependence.",
            "ai_methodology_category": "foundation models / generative deep learning",
            "applicability": "Potentially applicable across many design and prediction tasks, but practical use is constrained by reproducibility issues, dependence on training distribution, stochastic output variability, and lack of built-in mechanistic constraints.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Seen as promising and fashionable (AI4Science), but criticized for being opaque, dependent on training data, and producing variable outputs; generative models particularly vulnerable to stochastic variability and extrapolation failure.",
            "impact_potential": "High if integrated with scientific constraints and explainability — could accelerate design and hypothesis generation — but substantial risk if used without mechanistic constraints or rigorous validation.",
            "comparison_to_alternatives": "Not empirically compared in the paper; conceptually contrasted with physics-constrained/hybrid approaches and with the need for explainability and causal inference.",
            "success_factors": "Scale of model and data, representativeness of training corpus, incorporation of physics or causal constraints, and explainability mechanisms to produce scientifically actionable outputs.",
            "key_insight": "Foundation/generative models provide powerful, general-purpose capabilities but risk non-reproducible, non-mechanistic outputs unless constrained by physics, causality, or explainability tailored to scientific needs.",
            "uuid": "e2317.3",
            "source_info": {
                "paper_title": "Artificial Intelligence Must Be Made More Scientific",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "xAI / Causal AI / Big AI",
            "name_full": "Explainable AI (xAI), Causal AI, and 'Big AI' (hybrid ML + physics)",
            "brief_description": "Suggested directions to make AI conform to the scientific method: xAI to explain inner workings, causal AI to infer causal relations, and 'Big AI' to combine ML with physics-based constraints so models obey laws of nature.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "general scientific methodology / AI for science",
            "problem_description": "Address shortcomings of black-box ML (lack of reproducibility, interpretability, mechanistic insight) by developing explainable, causal, and physics-constrained hybrid AI approaches that align with scientific standards.",
            "data_availability": null,
            "data_structure": null,
            "problem_complexity": null,
            "domain_maturity": "Conceptual and emerging research directions; not a mature, standardized practice in most scientific fields yet.",
            "mechanistic_understanding_requirements": "Very high - these approaches are advocated precisely to provide mechanistic explanations, causal understanding, and adherence to physical laws.",
            "ai_methodology_name": "Explainable AI (xAI), Causal AI, Big AI (hybrid physics-informed ML)",
            "ai_methodology_description": "xAI: techniques to make models' internal decisions and predictions interpretable in scientific terms; Causal AI: methods to identify causal relations rather than correlations; Big AI: deliberate hybrids combining ML with physics-based models and constraints so predictions respect known laws of nature.",
            "ai_methodology_category": "explainable/causal AI; hybrid physics-informed ML",
            "applicability": "Recommended and appropriate for scientific applications where reproducibility, interpretability, and mechanistic understanding are required; seen as a path forward rather than a tested solution within this paper.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Advocated qualitatively as necessary to restore scientific rigor to AI-assisted science; no empirical effectiveness data provided in the paper.",
            "impact_potential": "Potentially transformative: could make AI outputs scientifically trustworthy, reproducible, and mechanistically informative, enabling broader scientific adoption.",
            "comparison_to_alternatives": "Stated in contrast to current black-box ML approaches (e.g., large foundation models and MLIPs) which lack interpretability and rigorous UQ.",
            "success_factors": "Integration of theory and data, enforcement of physical constraints, development of causal inference methods, and widespread adoption of reproducibility and transparency standards.",
            "key_insight": "Imposing explainability, causality, and physics constraints on AI aligns it with the scientific method and addresses the principal failings of current black-box approaches in scientific contexts.",
            "uuid": "e2317.4",
            "source_info": {
                "paper_title": "Artificial Intelligence Must Be Made More Scientific",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "Hybrid ML + physics (pandemic pipeline)",
            "name_full": "Hybrid machine learning and physics-based simulations for accelerated drug discovery (pandemic drugs pipeline)",
            "brief_description": "An infrastructure example that integrates machine learning with physics-based simulations on high-performance computers to speed COVID-19 drug-discovery efforts, illustrating a hybrid approach that combines data-driven and mechanistic methods.",
            "citation_title": "Pandemic drugs at pandemic speed: infrastructure for accelerating COVID-19 drug discovery with hybrid machine learningand physics-based simulations on high-performance computers",
            "mention_or_use": "mention",
            "scientific_problem_domain": "drug discovery / computational biomedicine",
            "problem_description": "Rapid identification and evaluation of therapeutic candidates by combining ML models and physics-based simulations at scale on HPC infrastructure.",
            "data_availability": null,
            "data_structure": "Not specified in detail in this paper; implied multimodal (molecular structures, simulation outputs, assay data) and structured numeric/simulation data.",
            "problem_complexity": "High: large search spaces of candidate molecules, computationally intensive physics simulations, and need for rapid screening under time constraints requiring HPC resources.",
            "domain_maturity": "Applied and pragmatic: drug discovery is a mature domain, and hybrid ML+physics pipelines have been applied in the pandemic context (2021) to accelerate workflows.",
            "mechanistic_understanding_requirements": "High - understanding how therapies work and ensuring unbiased, validated predictions is essential in healthcare applications.",
            "ai_methodology_name": "Hybrid machine learning + physics-based simulation pipeline",
            "ai_methodology_description": "Integrates ML models for rapid screening or surrogate modeling with physics-based simulation methods (e.g., molecular dynamics, free-energy calculations) executed on high-performance computing resources to accelerate candidate evaluation; emphasis on infrastructure and workflow integration.",
            "ai_methodology_category": "hybrid physics-informed ML / integrated simulation-ML workflows",
            "applicability": "Applicable and practical for large-scale, time-sensitive drug-discovery efforts when HPC and domain expertise are available; appropriate for combining speed and mechanistic fidelity.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Presented as an enabling infrastructure that can accelerate drug-discovery timelines; treated as a positive example of combining ML with physics rather than a rigorous evaluation within this paper.",
            "impact_potential": "High in urgent discovery contexts (e.g., pandemics) for reducing time-to-candidate and scaling complex simulations; potential to improve throughput while retaining mechanistic checks.",
            "comparison_to_alternatives": "Implicitly favored over pure-ML or pure-simulation approaches: hybrid pipelines aim to balance speed and mechanistic grounding.",
            "success_factors": "Access to HPC resources, well-integrated workflows combining ML surrogates and physics simulations, and strong domain expertise to validate predictions.",
            "key_insight": "Hybrid ML + physics pipelines on HPC can accelerate applied discovery tasks by combining ML speed with mechanistic simulation fidelity, provided infrastructure and domain validation are in place.",
            "uuid": "e2317.5",
            "source_info": {
                "paper_title": "Artificial Intelligence Must Be Made More Scientific",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "Generative methods",
            "name_full": "Generative AI methods (stochastic generative models)",
            "brief_description": "Generative machine-learning approaches used to propose models/solutions (e.g., molecules, materials) that are stochastic by nature and sensitive to random number generators, leading to non-deterministic outputs and reproducibility concerns.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "general scientific design and generation tasks (molecules, materials, distributions)",
            "problem_description": "Generate candidate structures, distributions, or solutions via learned generative processes; outputs are inherently stochastic and can vary between runs.",
            "data_availability": null,
            "data_structure": null,
            "problem_complexity": "High: generative tasks operate over combinatorial spaces and require both validity and novelty; stochasticity increases variability and complicates reproducibility.",
            "domain_maturity": "Emerging in scientific contexts; generative models are widely used in ML but adaptation to rigorous scientific workflows is nascent.",
            "mechanistic_understanding_requirements": "Medium-to-high - scientific applications demand validation and mechanistic rationale for generated candidates, beyond mere novelty.",
            "ai_methodology_name": "Stochastic generative models (generative ML)",
            "ai_methodology_description": "Models that produce new samples (molecules, materials, distributions) via learned generative processes; outputs depend on random seeds and internal randomness, producing non-deterministic results and reproducibility challenges.",
            "ai_methodology_category": "generative models / unsupervised or conditional generative learning",
            "applicability": "Applicable for hypothesis and candidate generation, but reproducibility and validation are significant constraints for scientific adoption.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Useful for exploring design spaces and proposing candidates, but criticized for non-reproducible one-off outputs and dependence on training distribution; reproducibility challenges analogous to single-run MD simulations.",
            "impact_potential": "Moderate-to-high for idea generation if coupled with validation and repeatability protocols; otherwise limited by variability and lack of mechanistic grounding.",
            "comparison_to_alternatives": "Contrasted qualitatively with deterministic physics-based simulations and with ML approaches that emphasize UQ and interpretability.",
            "success_factors": "Repeated sampling, robust validation pipelines, seed control, and integration with mechanistic evaluation to filter and validate generated candidates.",
            "key_insight": "Generative ML is powerful for exploring large design spaces but must be paired with reproducible protocols and mechanistic validation to be scientifically useful.",
            "uuid": "e2317.6",
            "source_info": {
                "paper_title": "Artificial Intelligence Must Be Made More Scientific",
                "publication_date_yy_mm": "2024-07"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Highly Accurate Protein Structure Prediction with AlphaFold",
            "rating": 2,
            "sanitized_title": "highly_accurate_protein_structure_prediction_with_alphafold"
        },
        {
            "paper_title": "Exploring the frontiers of condensed-phase chemistry with a general reactive machine learning potential",
            "rating": 2,
            "sanitized_title": "exploring_the_frontiers_of_condensedphase_chemistry_with_a_general_reactive_machine_learning_potential"
        },
        {
            "paper_title": "Global ranking of the sensitivity of interaction potential contributions within classical molecular dynamics force fields",
            "rating": 2,
            "sanitized_title": "global_ranking_of_the_sensitivity_of_interaction_potential_contributions_within_classical_molecular_dynamics_force_fields"
        },
        {
            "paper_title": "Pandemic drugs at pandemic speed: infrastructure for accelerating COVID-19 drug discovery with hybrid machine learningand physics-based simulations on high-performance computers",
            "rating": 2,
            "sanitized_title": "pandemic_drugs_at_pandemic_speed_infrastructure_for_accelerating_covid19_drug_discovery_with_hybrid_machine_learningand_physicsbased_simulations_on_highperformance_computers"
        },
        {
            "paper_title": "Mattergen: a generative model for inorganic materials design",
            "rating": 1,
            "sanitized_title": "mattergen_a_generative_model_for_inorganic_materials_design"
        },
        {
            "paper_title": "Target-aware Molecule Generation for Drug Design Using a Chemical Language Model",
            "rating": 1,
            "sanitized_title": "targetaware_molecule_generation_for_drug_design_using_a_chemical_language_model"
        },
        {
            "paper_title": "Predicting equilibrium distributions for molecular systems with deep learning",
            "rating": 1,
            "sanitized_title": "predicting_equilibrium_distributions_for_molecular_systems_with_deep_learning"
        },
        {
            "paper_title": "A rigorous uncertainty-aware quantification framework is essential for reproducible and replicable machine learning workflows",
            "rating": 1,
            "sanitized_title": "a_rigorous_uncertaintyaware_quantification_framework_is_essential_for_reproducible_and_replicable_machine_learning_workflows"
        }
    ],
    "cost": 0.018815,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Artificial Intelligence Must Be Made More Scientific
July 27, 2024</p>
<p>Peter V Coveney p.v.coveney@ucl.ac.uk 
Roger Highfield </p>
<p>Centre for Computational Science</p>
<p>Department of Chemistry
University College London
WC1H 0AJLondonU.K</p>
<p>Advanced Research Computing Centre
University College London
WC1H 0AJLondonU.K</p>
<p>Institute for Informatics
Faculty of Science
University of Amsterdam
1098XHAmsterdamThe Netherlands</p>
<p>Center for Advanced Studies
Ludwig Maximilian University of Munich
D-80539MunchenGermany</p>
<p>Artificial Intelligence Must Be Made More Scientific
July 27, 202419779FF5549876B2FCA5A4FBA587A4F910.1021/acs.jcim.4c01091Received: June 22, 2024
The role of AI within science is growing.Here we assess its impact on research and argue that AI often lacks reproducibility, transparency, objectivity, and mechanistic understanding.To ensure AI benefits research, we need to develop forms of AI that are fully compatible with the scientific method.A rtificial Intelligence is taking hold in science, even though it remains a long way from living up to the wilder claims of media headlines.But is it changing what we mean by science?The answer is an emphatic "no": the current generation of AI is in many respects not even scientific.The definition of precisely what we mean by science attracts debate among philosophers and historians, but there is general agreement that it is a fusion of observation and reason: radical empiricism (data without reason) and rationalism (reason without data) were rejected centuries ago, and instead scientists place their faith in using theory to make predictions and prompt new experiments, conducting experiments to produce data to shape theory, and so on. 1 A premium is placed on reproducibility, ensuring science is objective, which sets it apart from other human endeavors.Centuries ago, Bacon described how scientists nurture this symbiosis between rationalism and empiricism, likening them to bees. 2 With the rise of the computer, another kind of science has taken hold, where simulations make actionable predictions.Mathematical models that capture our understanding of the atmosphere and oceans, when combined in a computer with data from satellites, weather stations, and so on, enable forecasting to save lives.The most dramatic forward-looking examples are digital twins of the human body.3ow we are entering a new era of computation, with AI growing in importance.Yet few remember earlier hype cycles, where AI bust followed boom.We have also lost sight of how the abilities of our 20-W brains remain spectacular, even compared with exascale computers that draw a million times more power.It is an embarrassing fact that there is no widely accepted definition of natural intelligence, 4 so what exactly do we mean by AI?We have put excessive faith in computers.5</p>
<p>Despite these shortcomings, bold, not to say outlandish, claims about AI are being made by giant US-based tech companies. 6They have one overriding motivation: to make money.Big institutions are scrambling to adopt AI for fear of missing out.Governments are only too happy to jump on the bandwagon, with the promise that AI will make them more persuasive to their electorates, as well as more effective and efficient.</p>
<p>By claiming that computer algorithms can transcend human intelligence, their most feverish acolytes believe that machines can take over many functions of humans.Ironically, some of the wilder claims come from companies that rely on legions of crowd-sourced labor, what Jeff Bezos called 'artificial artificial intelligence', 7 or "pseudo-AI", to help AI do menial but tricky tasks.</p>
<p>There is a lazy assumption that AI can "do science" too, but machine learning methods were and still are pattern spotters designed to solve technological problems.Their origins have far more to do with the intelligence and security communities devising ways to get computers to sift through oceans of digital data than scientists trying to understand nature.</p>
<p>Here AI certainly does have a role.Perhaps the best-known example is the protein structure prediction model AlphaFold, 8 which has mapped the universe of every known protein.For molecular biologists, AlphaFold is a very fast alternative to X-ray crystallography.Like so much machine learning, AlphaFold works best on what it has been trained to see.But, being a glorified look-up table, it remains hard to say when it will work reliably and when it may fail.Put another way, it is very hard to quantify its uncertainties.</p>
<p>Another fashionable topic is the use of AI to generate machine-learned interaction potentials (MLIPs), for example, ones which can be used to perform classical molecular dynamics simulations.Determining the form of these force fields, or potential parametrizations, is tedious, so, when new ones are required, it is proposed that AI learn how to map from atomic properties to molecular potential energies and/or other quantities of interest, from as large a data set as possible. 9This results in a neural network with many hundreds of thousands of fitting parameters, which are the connection weights between pairs of "neurons" in the network.Again, attempting to quantify the uncertainties in such MLIPs is difficult for two reasons: there are far too many parameters, and they are merely fitting parameters with no intrinsic physicochemical meaning.</p>
<p>In fact, we do understand the science of molecular interactions, so one can also use a physics-based interaction potential (with terms which are scientifically meaningful) with perhaps hundreds to a few thousand parameters.We have been able to use new, scalable forms of uncertainty quantification which allow us to show that typically only between ten and 20 of these force field parameters have a significant influence on the properties of interest. 10In other words, we acquire real insights and understanding about what parameters are important.</p>
<p>By comparison, we cannot make sense of what is going on inside an MLIP or AlphaFold, which require hundreds of thousands to hundreds of millions of parameters.They represent at once the strength and weakness of AI.While the astronomical number of parameters explains why ML can successfully fit so many arbitrary relationships, it also accounts for their unreliability and their failure to provide satisfactory scientific explanations.</p>
<p>Moreover, they are typically trained on some selected data set, broken into a larger portion for training and a smaller subset for validation.But would they work on a different data set?Often, they fail because they are then extrapolating rather than interpolating.</p>
<p>Generative methods suffer from similar problems but are more strongly dependent on random number generators, so a fortiori, they produce different answers each time the code is run.This is reminiscent of molecular dynamics where one-off simulations are not reproducible. 11,12There are other challenges to reproducibility, 13 which require access to the underlying data and ML algorithms employed, which may be kept confidential, 14,15 and sometimes access to substantial computational power.</p>
<p>While science seeks understanding, AI rests on statistical inference.This does not make it wrong per se, but recall the old saw that correlation is not causation.Using results from ergodic, Ramsey, and algorithmic information theories, one can show that large databases contain arbitrary numbers of correlations that increase rapidly with the amount, not the nature, of the data.These correlations also arise in large, randomly generated databases, implying that most are spurious. 16Sifting false correlations from the true requires the scientific method.</p>
<p>Although computers create a veneer of objectivity, humans still play a central role in how AIs are set up and used.Most of the time, to train an AI you must define the categories into which the AI will sort its answers.But any such classification is arbitrary and riddled with ambiguities, reflecting the developers' own motivations: human bias is baked into AI, even before training.</p>
<p>AI typically rests on various assumptions that also reflect human choices, rather than are based on science.Essentially all ML algorithms assume smooth (differentiable) relationships between the quantities involved in its internal data analysis.These are made purely for convenience in order to permit the use of linear algebra, standard software libraries, and substantial speed-up by GPU accelerators.Nonetheless, AI and ML most certainly do provide a wide range of nonlinear predictions.They do this because, though linear algebra is to the fore, they include nonlinear activation functions which relate input to output data.</p>
<p>The comforting assumption that we live in a differentiable world might suggest that sacrificing a little accuracy by moving from double to half precision and even quarter precision in the context of floating-point numbers makes little difference, or that the bell curve of Gaussian statistics is omnipotent.In the real world, none of this holds in general.Sharp discontinuities occur, a hallmark of nonlinear behavior. 17ltimately, the world is highly nonlinear, and because nonlinear science is counterintuitive and often nondifferentiable, there is a temptation to ignore it.Perhaps the ultimate manifestation of nonlinearity, which is rarely discussed, is how rounding may generate profound errors in digital computers. 18,19hough misguided, one can understand why some scientists welcome AI as an alternative to Bacon's busy bees: in complex fields such as the biological sciences, AI's focus on answers rather than understanding is seductive.But, when extended to healthcare, for example, it is vital we understand how proposed therapies work and free them of intrinsic biases�not just in terms of the unrepresentative nature of the data they are trained on, but how AIs are built in the first place.</p>
<p>There is growing excitement in some quarters about the new wave of AI "foundation models," based on "general-purpose AI" or "GPAI" systems that can supposedly solve scientist's problems via an interactive LLM interface akin to ChatGPT.Examples of these "AI4Science" models include DiG (Digital Graphormer) 20 for molecular distributions, MatterGen 21 for inorganic materials design, and TamGen (target-aware molecule generation). 22s these models rain down on us, rather than surrendering the very bastion of science, it is time scientists demanded that AI/ML conform with the highest standards of scientific inquiry.We need a focus on reproducibility and, above all else, on theoretical concepts and methods that provide mechanistic insight and understanding.</p>
<p>AI undoubtedly offers considerable benefits to science, but we must never turn our backs on the reproducible blend of rationalism and empiricism that has endured for three centuries.One way forward might be Explainable AI (xAI), and we should embrace "causal AI", as long as AI can explain its inner workings and predictions in scientific terms.Another is "Big AI," a combination of machine learning and physicsbased methods, which constrain AI to obey the laws of nature. 23In such contexts, their strengths and weaknesses are
 J. Chem. Inf. Model. 2024, 64, 5739−5741
■ ACKNOWLEDGMENTSWe thank Dr. Wouter Edeling and Dr. Shunzou Wan for helpful comments.The authors acknowledge funding support from (i) UKRI-EPSRC for the UK High-End Computing Consortium (EP/R029598/1), the Software Environment for Actionable &amp; VVUQ-evaluated Exascale Applications (SEA-VEA) grant (EP/W007762/1), the UK Consortium on Mesoscale Engineering Sciences (UKCOMES grant no.EP/ L00030X/1), and the Computational Biomedicine at the Exascale (CompBioMedX) grant (EP/X019276/1); (ii) the European Commission for EU H2020 CompBioMed2 Center of Excellence (grant no.823712).RH is a member of the UKRI-Medical Research Council.AuthorRoger Highfield − Science Museum, London SW7NotesThe authors declare no competing financial interest.
Big data need big theory too. P V Coveney, E Dougherty, R R Highfield, 10.1098/rsta.2016.0153Philos. Trans. R. Soc. A. 3742016. 20160153</p>
<p>F Bacon, R M Hutchins, M J Adler, Novum Organum, Great Books of the Western World. </p>
<p>. R M Hutchins, M J Adler, Encyclopaedia Britannica. 351952</p>
<p>Virtual You: How Building Your Digital Twin Will Revolutionize Medicine and Change Your Life. P V Coveney, R R Highfield, </p>
<p>Fractionating Human Intelligence. A Hampshire, R R Highfield, B L Parkin, A M Owen, 10.1016/j.neuron.2012.06.022Neuron. 762012. 1225−1237</p>
<p>When we can trust computers (and when we can't). P V Coveney, R R Highfield, 10.1098/rsta.2020.0067Philos. Trans. R. Soc. A. 3792021. 20200067</p>
<p>Atlas of AI. K Crawford, 2021New Haven and London</p>
<p>Artificial Intelligence, With Help From the Humans. J Pontin, New York Times. March 25, 2007</p>
<p>Highly Accurate Protein Structure Prediction with AlphaFold. J Jumper, R Evans, A Pritzel, T Green, M Figurnov, O Ronneberger, K Tunyasuvunakool, R Bates, A ̌ídek, A Potapenko, A Bridgland, C Meyer, S A A Kohl, A J Ballard, A Cowie, B Romera-Paredes, S Nikolov, R Jain, J Adler, T Back, S Petersen, D Reiman, E Clancy, M Zielinski, M Steinegger, M Pacholska, T Berghammer, S Bodenstein, D Silver, O Vinyals, A W Senior, K Kavukcuoglu, P Kohli, D Hassabis, 10.1038/s41586-021-03819-2Nature. 5962021</p>
<p>Exploring the frontiers of condensed-phase chemistry with a general reactive machine learning potential. S Zhang, M Łg Z Makos, R B Jadrich, E Kraka, K Barros, B T Nebgen, S Tretiak, O Isayev, N Lubbers, R A Messerly, J S Smith, 10.1038/s41557-023-01427-3Nat. Chem. 162024</p>
<p>Global ranking of the sensitivity of interaction potential contributions within classical molecular dynamics force fields. W Edeling, M Vassaux, Y Yang, S Wan, S Guillas, P V Coveney, 10.1038/s41524-024-01272-zComput. Mater. 10872024</p>
<p>On the calculation of equilibrium thermodynamic properties from molecular dynamics. P V Coveney, S Wan, 10.1039/C6CP02349EPhys. Chem. Chem. Phys. 182016</p>
<p>. P V Coveney, S Molecular Wan, Dynamics, Probability and Uncertainty</p>
<p>A rigorous uncertainty-aware quantification framework is essential for reproducible and replicable machine learning workflows. L Pouchard, K G Reyes, F J Alexander, B.-J Yoon, 10.1038/d41586-024-01463-0Digital Discovery. 147282023, 2, 1251−1258. 2024Nature</p>
<p>Not all 'open source' AI models are actually open: here's a ranking. E Gibney, 10.1038/d41586-024-02012-5?urlappend=%3Fref%3DPDF&amp;jav=VoR&amp;rel=cite-asNature. 2024</p>
<p>The deluge of spurious correlations in big data. C S Calude, G Longo, 10.1007/s10699-016-9489-4201722</p>
<p>Big Data: the End of the Scientific Method?. S Succi, P V Coveney, 10.1098/rsta.2018.0145Philos. Trans. R. Soc. A. 3772019. 20180145</p>
<p>A New Pathology in the Simulation of Chaotic Dynamical Systems on Digital Computers. B M Boghosian, P V Coveney, H Wang, 10.1002/adts.201900125Adv. Theory Simul. 22019. 1900125</p>
<p>Periodic orbits in chaotic systems simulated at low precision. M Klöwer, P V Coveney, E A Paxton, T N Palmer, 10.1038/s41598-023-37004-4Sci. Rep. 13114102023</p>
<p>Predicting equilibrium distributions for molecular systems with deep learning. S Zheng, J He, C Liu, Y Shi, Z Lu, W Feng, F Ju, J Wang, J Zhu, Y Min, H Zhang, S Tang, H Hao, P Jin, C Chen, F Noé, H Liu, T Liu, 10.1038/s42256-024-00837-3Nat. Mach. Intell. 62024</p>
<p>C Zeni, R Pinsler, D Zugner, A Fowler, M Horton, X Fu, S Shysheya, J Crabbé, L Sun, J Smith, 10.48550/arXiv.2312.03687?urlappend=%3Fref%3DPDF&amp;jav=VoR&amp;rel=cite-asMattergen: a generative model for inorganic materials design. 2023</p>
<p>Target-aware Molecule Generation for Drug Design Using a Chemical Language Model. Y Xia, K Wu, P Deng, R Liu, Y Zhang, H Guo, Y Cui, Q Pei, L Wu, S Xie, 10.1101/2024.01.08.574635?urlappend=%3Fref%3DPDF&amp;jav=VoR&amp;rel=cite-asbioRxiv. 2024</p>
<p>Blending Big Data with Big Theory to Build Virtual Humans. P V Coveney, R Highfield, A I Big, Artificial Intelligence for Science. A Choudhary, G Fox, T Hey, World Scientific2023398</p>
<p>Pandemic drugs at pandemic speed: infrastructure for accelerating COVID-19 drug discovery with hybrid machine learningand physics-based simulations on high-performance computers. A P Bhati, S Wan, D Alfe, A R Clyde, M Bode, L Tan, M Titov, A Merzky, M Turilli, S Jha, R R Highfield, W Rocchia, N Scafuri, S Succi, D Kranzlmuller, G Mathias, D Wifling, Y Donon, A Di Meglio, S Vallecorsa, H Ma, A Trifan, A Ramanathan, T Brettin, A Partin, F Xia, X Duan, R Stevens, P V Coveney, 10.1098/rsfs.2021.0018Interface Focus. 112021. 20210018</p>            </div>
        </div>

    </div>
</body>
</html>