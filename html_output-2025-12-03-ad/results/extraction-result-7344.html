<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7344 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7344</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7344</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-138.html">extraction-schema-138</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <p><strong>Paper ID:</strong> paper-276960954</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2503.09620v2.pdf" target="_blank">Exploiting Edited Large Language Models as General Scientific Optimizers</a></p>
                <p><strong>Paper Abstract:</strong> Large language models (LLMs) have been widely adopted in mathematical optimization in scientific scenarios for their extensive knowledge and advanced reasoning capabilities. Existing methods mainly focus on utilizing LLMs to solve optimization problems in a prompt-based manner, which takes observational feedback as additional textual descriptions. However, due to LLM's \textbf{high sensitivity to the prompts} and \textbf{tendency to get lost in lengthy prompts}, these methods struggle to effectively utilize the {observational} feedback from each optimization step, which severely hinders the applications for real-world scenarios. To address these challenges, we propose a conceptually simple and general {bi-level} optimization method, namely \textbf{G}eneral \textbf{S}cientific \textbf{O}ptimizers (GSO). Specifically, GSO first utilizes inner-level simulators as experimental platforms to evaluate the current solution and provide observational feedback. Then, LLMs serve as knowledgeable and versatile scientists, generating new solutions by refining potential errors from the feedback as the outer-level optimization. Finally, simulations together with the expert knowledge in LLMs are jointly updated with bi-level interactions via model editing. Extensive experiments show that GSO consistently outperforms existing state-of-the-art methods using \textit{six} different LLM backbones on \textit{seven} different tasks, demonstrating the effectiveness and a wide range of applications.</p>
                <p><strong>Cost:</strong> 0.017</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7344.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7344.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GSO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>General Scientific Optimizers</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A bi-level optimization framework that pairs inner-level numerical simulators (experimental platforms) with outer-level large language models (LLMs) as reasoning agents; simulation feedback is injected into the LLM via model-editing so the LLM iteratively proposes improved hypotheses while avoiding ever-growing prompt length.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Mistral 7B, Llama3 8B, GPT-J 6B (also evaluated on Llama2 13B, Yi-9B, Internlm 7B)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Representative backbones: 7B (Mistral, Internlm), 6B (GPT-J), 8B (Llama3), 13B (Llama2), 9B (Yi)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Open-source base/backbone LLMs (some tested instruction-style variants); GSO applies targeted model editing to these pretrained LLMs (not full fine-tuning)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Multiple scientific subdomains: numerical optimization/operations research (TSP), statistical estimation (linear system regression), materials science / constitutive law discovery (physics/continuum mechanics), computational chemistry / quantum properties (molecule HOMO/LUMO/HOMO-LUMO gap)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Text-driven optimization where LLMs propose candidate solutions (e.g., routes for TSP, constitutive law expressions, molecular property predictions, linear model coefficients), inner numerical simulators evaluate them and return quantitative feedback (loss / objective value and auxiliary comparisons), and LLMs refine proposals iteratively.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>GSO: prompt includes task spec + examples (few-shot style 'str(Examples)') but crucially combines iterative model-editing (editing fact triples derived from simulator feedback into model weights) with a dynamic exploit/explore decoding-temperature schedule based on relative loss change ∆L; compared against vanilla prompting and chain-of-thought (CoT) prompting baselines. GSO also uses requestable intermediate simulator outputs as auxiliary textual feedback.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Task-dependent: linear system regression uses '#steps to reach optimal solution'; TSP uses optimality gap (relative distance to Gurobi oracle); constitutive law and molecular property tasks use mean squared error (MSE); reported as mean ± standard error over 5 seeds.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>Representative results for GSO using Mistral 7B (Table 4): Linear system regression steps = 5.6 ± 3.0; TSP optimality gap = 0.1 ± 0.03; constitutive law (task c) = 3.2 ± 1.7 (MSE); constitutive law (task d) = 13.0 ± 2.1 (MSE); molecule HOMO (e) = 23.9 ± 5.1 (MSE); LUMO (f) = 2.8 ± 1.5 (MSE); HOMO-LUMO gap (g) = 1.7 ± 0.4 (MSE). The paper also reports a maximum precision improvement of >32.6× on the HOMO-LUMO gap task when using Mistral 7B vs other methods.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td>Baselines evaluated include: Vanilla LLM, Chain-of-Thought (CoT) prompting, Funsearch, Eureka, OPRO, and SGA. Representative closed-source baselines (Table 4): GPT-4o: steps=6.4 ±1.5, TSP gap=0.2 ±0.05, constitutive c=9.7 ±7.4, d=45.5 ±9.1, e=181.4 ±33.7, f=313.5 ±45.4, g=67.8 ±10.9; Claude-3.5: worse on many tasks. In nearly all reported tasks GSO (with editing) outperforms these baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['Prompt sensitivity / format (semantically similar prompts can yield widely different results for prompt-only baselines)', "Prompt length and 'lost-in-the-middle' degradation (long iterative trajectories degrade LLM performance if feedback only kept in prompts)", 'Presence vs absence of model editing (editing strongly improves performance; ablation GSO w/o edit degrades results substantially)', 'Dynamic exploit/explore decoding temperature schedule based on ∆L (helps escape local optima and maintain steady improvement)', 'Backbone model choice and size (multiple backbones tested; performance varies but GSO improvements are consistent across sizes)', 'Access to model weights (GSO requires weight access for editing; closed-source models cannot be edited)', 'Randomness/inference stochasticity (LLM output randomness affects repeatability)', 'Choice of which layers are edited (causal tracing used to locate layers for edits; e.g., for Llama3 they edit MLP layers 18–22)']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td>Experiments run 5 times with different seeds; max 100 iterations per optimization; 2048 token generation limit per iteration; termination if no improvement for 10 consecutive iterations; hardware: NVIDIA A100 80GB; decoding temperature adjusted dynamically and clipped to [0,1]; model-editing applies batches of (s,r,o) triples as key-value updates to targeted MLP parameters (after causal tracing).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>LLM-generated content is stochastic and may hurt interpretability; computationally expensive inference; requires access to model weights so not applicable to closed-source models (e.g., GPT-4, Claude); editing can potentially harm general model abilities (cited in limitations); GSO may struggle if underlying physics/optimization is extremely complex; some baseline methods briefly improve then plateau due to prompt-length issues.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploiting Edited Large Language Models as General Scientific Optimizers', 'publication_date_yy_mm': '2025-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7344.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7344.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>OPRO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>OPRO (Large language models as black-box optimizers)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A previously published approach that employs LLMs as black-box optimizers for complex reasoning/optimization tasks by prompting them iteratively to propose candidate solutions evaluated externally.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>General reasoning and optimization tasks (method cited as prior art for using LLMs as optimizers)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>LLMs propose candidate solutions from text prompts; proposals are evaluated by external evaluators/simulators; iterative prompting used to refine solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>Prompt-based iterative optimization (black-box LLM acting as optimizer), compared in this paper to GSO.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['Prompt sensitivity and prompt-format dependence (discussed broadly in paper in relation to such methods)', "Degradation with long prompt histories ('lost-in-the-middle')"]</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Limited ability to effectively utilize per-step observational feedback due to prompt-sensitivity and prompt-length issues (as argued by the current paper).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploiting Edited Large Language Models as General Scientific Optimizers', 'publication_date_yy_mm': '2025-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7344.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7344.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Funsearch</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Funsearch (evolutionary strategy + LLM evaluator)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method that combines evolutionary strategies with LLMs and a systematic evaluator to avoid local optima and improve solution generation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>General optimization tasks (used as baseline in experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Uses LLMs to generate candidate variations and an evaluator to rank/guide evolutionary search.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>Evolutionary approach where LLMs generate variants (few-shot/seeded prompts) and an external evaluator scores them.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>["Vulnerability to prompt variation (empirical instability across semantically-similar prompts noted in paper's comparisons)", 'Prone to noisy / high-variance results on complex scientific tasks compared to GSO']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>In experiments reported in this paper Funsearch often underperforms GSO and shows high variance across prompt variants.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploiting Edited Large Language Models as General Scientific Optimizers', 'publication_date_yy_mm': '2025-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7344.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e7344.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Eureka</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Eureka (multiple-solution generation with LLMs)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An approach that generates multiple candidate solutions per step from LLMs to increase success rate (applied to code/reward-design contexts).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Optimization and code-generation contexts (used as a comparative baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Generate multiple candidate solutions using LLM sampling and select/evaluate them externally.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>Sampling-multiple-candidates per step; can be combined with reward/evaluator signals.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['Benefit from multiple-solution generation but still limited by prompt-length feedback incorporation', 'Performance sensitive to sampling and selection heuristics']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Observed to have higher variance and worse final metrics than GSO on the tested scientific tasks in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploiting Edited Large Language Models as General Scientific Optimizers', 'publication_date_yy_mm': '2025-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7344.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e7344.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SGA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SGA (bi-level optimization integrating simulations)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A bilevel optimization framework that integrates domain simulations with knowledge-driven LLM components to drive scientific discovery; cited as a related approach combining simulation and LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Physical scientific discovery / materials / PDE-driven systems (prior work cited and compared)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>Uses simulations as inner loop and LLM components to guide outer loop optimization; similar high-level goal to GSO but different implementation details.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>Bi-level integration of simulations and LLM-driven hypothesis proposals (as referenced).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['Importance of simulation-LLM coordination; prior art influenced GSO design']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Paper positions GSO as improving on SGA by (i) more effective use of per-step observational feedback via model editing and (ii) explicit dynamic exploration/exploitation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploiting Edited Large Language Models as General Scientific Optimizers', 'publication_date_yy_mm': '2025-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7344.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e7344.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AlphaGeometry</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AlphaGeometry (LLM solving geometry problems)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Work demonstrating LLMs solving complex geometry problems without human demonstrations, illustrating LLMs' potential in automated formal problem solving.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Mathematics / geometry problem solving</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>LLM used to produce formal problem-solving steps; evaluated on geometry problem benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td>Prompting-based reasoning (no human demonstrations required in reported success).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['Demonstrates LLM capacity for automated complex reasoning; motivates LLM use in optimization contexts']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Not used directly in this paper's experiments; cited as inspirational prior result.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploiting Edited Large Language Models as General Scientific Optimizers', 'publication_date_yy_mm': '2025-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7344.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e7344.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of the use of large language models as text-based simulators for scientific subdomains, including details about the model, domain, simulation task, prompting strategy, evaluation metrics, reported accuracy, baselines, and any factors identified as influencing accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Autonomous chemical research (Boiko et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Autonomous chemical research with large language models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A high-profile demonstration of LLMs applied to design and run chemical experiments (Nature); cited as example of LLMs in chemical experimental automation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Chemistry / laboratory automation</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task_description</strong></td>
                            <td>LLMs assist in planning and executing chemical experiments and workflows; used as agents interfacing with lab tools/simulators.</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>factors_reported</strong></td>
                            <td>['Effectiveness depends on tool integration and the ability to interpret and act on experimental feedback']</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_conditions</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_modes</strong></td>
                            <td>Cited in related work to motivate the use of LLMs in scientific experimental loops; details belong to the original paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploiting Edited Large Language Models as General Scientific Optimizers', 'publication_date_yy_mm': '2025-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Large language models as optimizers <em>(Rating: 2)</em></li>
                <li>Llm and simulation as bilevel optimizers: A new paradigm to advance physical scientific discovery <em>(Rating: 2)</em></li>
                <li>Autonomous chemical research with large language models <em>(Rating: 2)</em></li>
                <li>Funsearch <em>(Rating: 1)</em></li>
                <li>Eureka: Human-level reward design via coding large language models <em>(Rating: 1)</em></li>
                <li>Locating and editing factual associations in gpt <em>(Rating: 2)</em></li>
                <li>Llm and simulation as bilevel optimizers: A new paradigm to advance physical scientific discovery <em>(Rating: 1)</em></li>
                <li>Solving olympiad geometry without human demonstrations <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7344",
    "paper_id": "paper-276960954",
    "extraction_schema_id": "extraction-schema-138",
    "extracted_data": [
        {
            "name_short": "GSO",
            "name_full": "General Scientific Optimizers",
            "brief_description": "A bi-level optimization framework that pairs inner-level numerical simulators (experimental platforms) with outer-level large language models (LLMs) as reasoning agents; simulation feedback is injected into the LLM via model-editing so the LLM iteratively proposes improved hypotheses while avoiding ever-growing prompt length.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Mistral 7B, Llama3 8B, GPT-J 6B (also evaluated on Llama2 13B, Yi-9B, Internlm 7B)",
            "model_size": "Representative backbones: 7B (Mistral, Internlm), 6B (GPT-J), 8B (Llama3), 13B (Llama2), 9B (Yi)",
            "model_type": "Open-source base/backbone LLMs (some tested instruction-style variants); GSO applies targeted model editing to these pretrained LLMs (not full fine-tuning)",
            "scientific_domain": "Multiple scientific subdomains: numerical optimization/operations research (TSP), statistical estimation (linear system regression), materials science / constitutive law discovery (physics/continuum mechanics), computational chemistry / quantum properties (molecule HOMO/LUMO/HOMO-LUMO gap)",
            "simulation_task_description": "Text-driven optimization where LLMs propose candidate solutions (e.g., routes for TSP, constitutive law expressions, molecular property predictions, linear model coefficients), inner numerical simulators evaluate them and return quantitative feedback (loss / objective value and auxiliary comparisons), and LLMs refine proposals iteratively.",
            "prompting_strategy": "GSO: prompt includes task spec + examples (few-shot style 'str(Examples)') but crucially combines iterative model-editing (editing fact triples derived from simulator feedback into model weights) with a dynamic exploit/explore decoding-temperature schedule based on relative loss change ∆L; compared against vanilla prompting and chain-of-thought (CoT) prompting baselines. GSO also uses requestable intermediate simulator outputs as auxiliary textual feedback.",
            "evaluation_metric": "Task-dependent: linear system regression uses '#steps to reach optimal solution'; TSP uses optimality gap (relative distance to Gurobi oracle); constitutive law and molecular property tasks use mean squared error (MSE); reported as mean ± standard error over 5 seeds.",
            "reported_accuracy": "Representative results for GSO using Mistral 7B (Table 4): Linear system regression steps = 5.6 ± 3.0; TSP optimality gap = 0.1 ± 0.03; constitutive law (task c) = 3.2 ± 1.7 (MSE); constitutive law (task d) = 13.0 ± 2.1 (MSE); molecule HOMO (e) = 23.9 ± 5.1 (MSE); LUMO (f) = 2.8 ± 1.5 (MSE); HOMO-LUMO gap (g) = 1.7 ± 0.4 (MSE). The paper also reports a maximum precision improvement of &gt;32.6× on the HOMO-LUMO gap task when using Mistral 7B vs other methods.",
            "baseline_accuracy": "Baselines evaluated include: Vanilla LLM, Chain-of-Thought (CoT) prompting, Funsearch, Eureka, OPRO, and SGA. Representative closed-source baselines (Table 4): GPT-4o: steps=6.4 ±1.5, TSP gap=0.2 ±0.05, constitutive c=9.7 ±7.4, d=45.5 ±9.1, e=181.4 ±33.7, f=313.5 ±45.4, g=67.8 ±10.9; Claude-3.5: worse on many tasks. In nearly all reported tasks GSO (with editing) outperforms these baselines.",
            "factors_reported": [
                "Prompt sensitivity / format (semantically similar prompts can yield widely different results for prompt-only baselines)",
                "Prompt length and 'lost-in-the-middle' degradation (long iterative trajectories degrade LLM performance if feedback only kept in prompts)",
                "Presence vs absence of model editing (editing strongly improves performance; ablation GSO w/o edit degrades results substantially)",
                "Dynamic exploit/explore decoding temperature schedule based on ∆L (helps escape local optima and maintain steady improvement)",
                "Backbone model choice and size (multiple backbones tested; performance varies but GSO improvements are consistent across sizes)",
                "Access to model weights (GSO requires weight access for editing; closed-source models cannot be edited)",
                "Randomness/inference stochasticity (LLM output randomness affects repeatability)",
                "Choice of which layers are edited (causal tracing used to locate layers for edits; e.g., for Llama3 they edit MLP layers 18–22)"
            ],
            "experimental_conditions": "Experiments run 5 times with different seeds; max 100 iterations per optimization; 2048 token generation limit per iteration; termination if no improvement for 10 consecutive iterations; hardware: NVIDIA A100 80GB; decoding temperature adjusted dynamically and clipped to [0,1]; model-editing applies batches of (s,r,o) triples as key-value updates to targeted MLP parameters (after causal tracing).",
            "limitations_or_failure_modes": "LLM-generated content is stochastic and may hurt interpretability; computationally expensive inference; requires access to model weights so not applicable to closed-source models (e.g., GPT-4, Claude); editing can potentially harm general model abilities (cited in limitations); GSO may struggle if underlying physics/optimization is extremely complex; some baseline methods briefly improve then plateau due to prompt-length issues.",
            "uuid": "e7344.0",
            "source_info": {
                "paper_title": "Exploiting Edited Large Language Models as General Scientific Optimizers",
                "publication_date_yy_mm": "2025-03"
            }
        },
        {
            "name_short": "OPRO",
            "name_full": "OPRO (Large language models as black-box optimizers)",
            "brief_description": "A previously published approach that employs LLMs as black-box optimizers for complex reasoning/optimization tasks by prompting them iteratively to propose candidate solutions evaluated externally.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": null,
            "model_size": null,
            "model_type": null,
            "scientific_domain": "General reasoning and optimization tasks (method cited as prior art for using LLMs as optimizers)",
            "simulation_task_description": "LLMs propose candidate solutions from text prompts; proposals are evaluated by external evaluators/simulators; iterative prompting used to refine solutions.",
            "prompting_strategy": "Prompt-based iterative optimization (black-box LLM acting as optimizer), compared in this paper to GSO.",
            "evaluation_metric": null,
            "reported_accuracy": null,
            "baseline_accuracy": null,
            "factors_reported": [
                "Prompt sensitivity and prompt-format dependence (discussed broadly in paper in relation to such methods)",
                "Degradation with long prompt histories ('lost-in-the-middle')"
            ],
            "experimental_conditions": null,
            "limitations_or_failure_modes": "Limited ability to effectively utilize per-step observational feedback due to prompt-sensitivity and prompt-length issues (as argued by the current paper).",
            "uuid": "e7344.1",
            "source_info": {
                "paper_title": "Exploiting Edited Large Language Models as General Scientific Optimizers",
                "publication_date_yy_mm": "2025-03"
            }
        },
        {
            "name_short": "Funsearch",
            "name_full": "Funsearch (evolutionary strategy + LLM evaluator)",
            "brief_description": "A method that combines evolutionary strategies with LLMs and a systematic evaluator to avoid local optima and improve solution generation.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": null,
            "model_size": null,
            "model_type": null,
            "scientific_domain": "General optimization tasks (used as baseline in experiments)",
            "simulation_task_description": "Uses LLMs to generate candidate variations and an evaluator to rank/guide evolutionary search.",
            "prompting_strategy": "Evolutionary approach where LLMs generate variants (few-shot/seeded prompts) and an external evaluator scores them.",
            "evaluation_metric": null,
            "reported_accuracy": null,
            "baseline_accuracy": null,
            "factors_reported": [
                "Vulnerability to prompt variation (empirical instability across semantically-similar prompts noted in paper's comparisons)",
                "Prone to noisy / high-variance results on complex scientific tasks compared to GSO"
            ],
            "experimental_conditions": null,
            "limitations_or_failure_modes": "In experiments reported in this paper Funsearch often underperforms GSO and shows high variance across prompt variants.",
            "uuid": "e7344.2",
            "source_info": {
                "paper_title": "Exploiting Edited Large Language Models as General Scientific Optimizers",
                "publication_date_yy_mm": "2025-03"
            }
        },
        {
            "name_short": "Eureka",
            "name_full": "Eureka (multiple-solution generation with LLMs)",
            "brief_description": "An approach that generates multiple candidate solutions per step from LLMs to increase success rate (applied to code/reward-design contexts).",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": null,
            "model_size": null,
            "model_type": null,
            "scientific_domain": "Optimization and code-generation contexts (used as a comparative baseline)",
            "simulation_task_description": "Generate multiple candidate solutions using LLM sampling and select/evaluate them externally.",
            "prompting_strategy": "Sampling-multiple-candidates per step; can be combined with reward/evaluator signals.",
            "evaluation_metric": null,
            "reported_accuracy": null,
            "baseline_accuracy": null,
            "factors_reported": [
                "Benefit from multiple-solution generation but still limited by prompt-length feedback incorporation",
                "Performance sensitive to sampling and selection heuristics"
            ],
            "experimental_conditions": null,
            "limitations_or_failure_modes": "Observed to have higher variance and worse final metrics than GSO on the tested scientific tasks in this paper.",
            "uuid": "e7344.3",
            "source_info": {
                "paper_title": "Exploiting Edited Large Language Models as General Scientific Optimizers",
                "publication_date_yy_mm": "2025-03"
            }
        },
        {
            "name_short": "SGA",
            "name_full": "SGA (bi-level optimization integrating simulations)",
            "brief_description": "A bilevel optimization framework that integrates domain simulations with knowledge-driven LLM components to drive scientific discovery; cited as a related approach combining simulation and LLMs.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": null,
            "model_size": null,
            "model_type": null,
            "scientific_domain": "Physical scientific discovery / materials / PDE-driven systems (prior work cited and compared)",
            "simulation_task_description": "Uses simulations as inner loop and LLM components to guide outer loop optimization; similar high-level goal to GSO but different implementation details.",
            "prompting_strategy": "Bi-level integration of simulations and LLM-driven hypothesis proposals (as referenced).",
            "evaluation_metric": null,
            "reported_accuracy": null,
            "baseline_accuracy": null,
            "factors_reported": [
                "Importance of simulation-LLM coordination; prior art influenced GSO design"
            ],
            "experimental_conditions": null,
            "limitations_or_failure_modes": "Paper positions GSO as improving on SGA by (i) more effective use of per-step observational feedback via model editing and (ii) explicit dynamic exploration/exploitation.",
            "uuid": "e7344.4",
            "source_info": {
                "paper_title": "Exploiting Edited Large Language Models as General Scientific Optimizers",
                "publication_date_yy_mm": "2025-03"
            }
        },
        {
            "name_short": "AlphaGeometry",
            "name_full": "AlphaGeometry (LLM solving geometry problems)",
            "brief_description": "Work demonstrating LLMs solving complex geometry problems without human demonstrations, illustrating LLMs' potential in automated formal problem solving.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": null,
            "model_size": null,
            "model_type": null,
            "scientific_domain": "Mathematics / geometry problem solving",
            "simulation_task_description": "LLM used to produce formal problem-solving steps; evaluated on geometry problem benchmarks.",
            "prompting_strategy": "Prompting-based reasoning (no human demonstrations required in reported success).",
            "evaluation_metric": null,
            "reported_accuracy": null,
            "baseline_accuracy": null,
            "factors_reported": [
                "Demonstrates LLM capacity for automated complex reasoning; motivates LLM use in optimization contexts"
            ],
            "experimental_conditions": null,
            "limitations_or_failure_modes": "Not used directly in this paper's experiments; cited as inspirational prior result.",
            "uuid": "e7344.5",
            "source_info": {
                "paper_title": "Exploiting Edited Large Language Models as General Scientific Optimizers",
                "publication_date_yy_mm": "2025-03"
            }
        },
        {
            "name_short": "Autonomous chemical research (Boiko et al.)",
            "name_full": "Autonomous chemical research with large language models",
            "brief_description": "A high-profile demonstration of LLMs applied to design and run chemical experiments (Nature); cited as example of LLMs in chemical experimental automation.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": null,
            "model_size": null,
            "model_type": null,
            "scientific_domain": "Chemistry / laboratory automation",
            "simulation_task_description": "LLMs assist in planning and executing chemical experiments and workflows; used as agents interfacing with lab tools/simulators.",
            "prompting_strategy": null,
            "evaluation_metric": null,
            "reported_accuracy": null,
            "baseline_accuracy": null,
            "factors_reported": [
                "Effectiveness depends on tool integration and the ability to interpret and act on experimental feedback"
            ],
            "experimental_conditions": null,
            "limitations_or_failure_modes": "Cited in related work to motivate the use of LLMs in scientific experimental loops; details belong to the original paper.",
            "uuid": "e7344.6",
            "source_info": {
                "paper_title": "Exploiting Edited Large Language Models as General Scientific Optimizers",
                "publication_date_yy_mm": "2025-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Large language models as optimizers",
            "rating": 2,
            "sanitized_title": "large_language_models_as_optimizers"
        },
        {
            "paper_title": "Llm and simulation as bilevel optimizers: A new paradigm to advance physical scientific discovery",
            "rating": 2,
            "sanitized_title": "llm_and_simulation_as_bilevel_optimizers_a_new_paradigm_to_advance_physical_scientific_discovery"
        },
        {
            "paper_title": "Autonomous chemical research with large language models",
            "rating": 2,
            "sanitized_title": "autonomous_chemical_research_with_large_language_models"
        },
        {
            "paper_title": "Funsearch",
            "rating": 1
        },
        {
            "paper_title": "Eureka: Human-level reward design via coding large language models",
            "rating": 1,
            "sanitized_title": "eureka_humanlevel_reward_design_via_coding_large_language_models"
        },
        {
            "paper_title": "Locating and editing factual associations in gpt",
            "rating": 2,
            "sanitized_title": "locating_and_editing_factual_associations_in_gpt"
        },
        {
            "paper_title": "Llm and simulation as bilevel optimizers: A new paradigm to advance physical scientific discovery",
            "rating": 1,
            "sanitized_title": "llm_and_simulation_as_bilevel_optimizers_a_new_paradigm_to_advance_physical_scientific_discovery"
        },
        {
            "paper_title": "Solving olympiad geometry without human demonstrations",
            "rating": 1,
            "sanitized_title": "solving_olympiad_geometry_without_human_demonstrations"
        }
    ],
    "cost": 0.017099749999999997,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Exploiting Edited Large Language Models as General Scientific Optimizers
17 Mar 2025</p>
<p>Qitan Lv qitanlv@mail.ustc.edu.cn 
University of Science and Technology of China</p>
<p>Tianyu Liu tianyu_liu@mail.ustc.edu.cn 
University of Science and Technology of China</p>
<p>Hong Wang wanghong1700@mail.ustc.edu.cn 
University of Science and Technology of China</p>
<p>Angelica Chen 
University of Science and Technology of China</p>
<p>Jérémy Scheurer 
University of Science and Technology of China</p>
<p>Tomasz Korbak 
University of Science and Technology of China</p>
<p>JunJon Ander Campos 
University of Science and Technology of China</p>
<p>Shern Chan 
University of Science and Technology of China</p>
<p>Canyu Chen 
University of Science and Technology of China</p>
<p>Baixiang Huang 
University of Science and Technology of China</p>
<p>Zekun Li 
University of Science and Technology of China</p>
<p>Zhaorun Chen 
University of Science and Technology of China</p>
<p>Shiyang Lai 
University of Science and Technology of China</p>
<p>Xiongxiao Xu 
University of Science and Technology of China</p>
<p>Jia-Chen Gu 
University of Science and Technology of China</p>
<p>Jin- Dong Gu 
University of Science and Technology of China</p>
<p>Huaxiu Yao 
University of Science and Technology of China</p>
<p>Chaowei Xiao 
University of Science and Technology of China</p>
<p>Xinyun Chen 
University of Science and Technology of China</p>
<p>Maxwell Lin 
University of Science and Technology of China</p>
<p>Nathanael Schärli 
University of Science and Technology of China</p>
<p>Yutian Chen 
University of Science and Technology of China</p>
<p>Xingyou Song 
University of Science and Technology of China</p>
<p>Chansoo Lee 
University of Science and Technology of China</p>
<p>Zi Wang 
University of Science and Technology of China</p>
<p>Richard Zhang 
University of Science and Technology of China</p>
<p>David Dohan 
University of Science and Technology of China</p>
<p>Kazuya Kawakami 
University of Science and Technology of China</p>
<p>Greg Kochanski 
University of Science and Technology of China</p>
<p>Arnaud Doucet 
University of Science and Technology of China</p>
<p>Marc ' Aurelio 
University of Science and Technology of China</p>
<p>Santo Fortunato 
University of Science and Technology of China</p>
<p>Carl T Bergstrom 
University of Science and Technology of China</p>
<p>Katy Börner 
University of Science and Technology of China</p>
<p>James A Evans 
University of Science and Technology of China</p>
<p>Dirk Helbing 
University of Science and Technology of China</p>
<p>Staša Milojević 
University of Science and Technology of China</p>
<p>Alexander M Petersen 
University of Science and Technology of China</p>
<p>Filippo Radicchi 
University of Science and Technology of China</p>
<p>Roberta Sinatra 
University of Science and Technology of China</p>
<p>Mor Geva 
University of Science and Technology of China</p>
<p>Avi Caciularu 
University of Science and Technology of China</p>
<p>Kevin Ro Wang 
University of Science and Technology of China</p>
<p>Yoav 2022 Goldberg 
University of Science and Technology of China</p>
<p>Transformer 
University of Science and Technology of China</p>
<p>Exploiting Edited Large Language Models as General Scientific Optimizers
17 Mar 202548736A7AB86F51EAEE02DC47C10147DCarXiv:2503.09620v2[math.OC]
Large language models (LLMs) have been widely adopted in mathematical optimization in scientific scenarios for their extensive knowledge and advanced reasoning capabilities.Existing methods mainly focus on utilizing LLMs to solve optimization problems in a promptbased manner, which takes observational feedback as additional textual descriptions.However, due to LLM's high sensitivity to the prompts and tendency to get lost in lengthy prompts, these methods struggle to effectively utilize the observational feedback from each optimization step, which severely hinders the applications for real-world scenarios.To address these challenges, we propose a conceptually simple and general bi-level optimization method, namely General Scientific Optimizers (GSO).Specifically, GSO first utilizes innerlevel simulators as experimental platforms to evaluate the current solution and provide observational feedback.Then, LLMs serve as knowledgeable and versatile scientists, generating new solutions by refining potential errors from the feedback as the outer-level optimization.Finally, simulations together with the expert knowledge in LLMs are jointly updated with bi-level interactions via model editing.Extensive experiments show that GSO consistently outperforms existing state-of-the-art methods using six different LLM backbones on seven different tasks, demonstrating the effectiveness and a wide range of applications.</p>
<p>Introduction</p>
<p>Optimization is ubiquitous across a wide range of scientific domains, spanning mathematics, physics, chemistry, pharmacology, etc (Amari, 1993;Intriligator, 2002;Cova and Pais, 2019).Various research endeavors innovate within its field, creating methods tailored to its specific challenges and nuances to automate and accelerate the process * Equal Contributions.† The Corresponding author.   of mathematical optimization in scientific scenarios (Wang et al., 2023b).However, the need for customization of optimization algorithms to address specific challenges highlights the absence of a universally applicable philosophy (Popper, 2005;Fortunato et al., 2018), which is crucial for establishing a standardized optimization framework and enhancing the efficiency of scientific research.We aim to transcend specific domains and provide a generalized approach to boost mathematical optimization in scientific scenarios.</p>
<p>Standing out as versatile tools with vast knowledge repositories, large language models (LLMs) have recently risen to prominence in optimization across scientific domains for their expansive knowledge bases, advanced reasoning capabilities, and human-friendly natural language interface (AI4Science and Quantum, 2023).Extensive research efforts have been devoted to boosting general mathematical optimization in scientific scenarios.Canonical methods mainly focus on fine-tuning LLMs using domain-specific data to align natural language with scientific information, such as chemical structures (Li et al., 2024b;Chithrananda et al., 2020) or drug structures (Liu et al., 2021).</p>
<p>However, these approaches are constrained to specific domains and require substantial amounts of data and extensive computation resources for broader applicability.Recently, prompt-based iterative optimization methods-which enhance the inherent capabilities of pre-trained LLMs by incorporating the optimization feedback to LLMs-have emerged as a promising approach for advancing scientific optimization (Yang et al., 2023).</p>
<p>Extensive researches have explored leveraging LLMs as optimizers or agents (Zhang et al.) for tasks such as mathematical problem-solving (Romera-Paredes et al., 2024a;Yang et al., 2023), conducting chemical experiments (Boiko et al., 2023), advancing physical scientific discovery (Ma et al., 2024c), molecular discovery (Li et al., 2024a), and drug discovery (Sharma and Thakur, 2023).</p>
<p>Albeit with multiple benefits of the promptbased methods, they confront one significant challenge that severely hinders their general applications-struggling to effectively utilize observational feedback.This challenge primarily stems from two limitations inherent in existing prompt-based methods: (i) LLMs are shown to be sensitive to the prompt format (Lu et al., 2022;Wei et al., 2023;Madaan and Yazdanbakhsh, 2022).In particular, semantically similar prompts can yield drastically different performance (Kojima et al., 2022;Zhou et al.;Yang et al., 2023), and the optimal prompt formats may be model-specific and task-specific, which severely limits the generalizability across different scientific tasks.</p>
<p>(ii) LLMs may get lost in lengthy prompt (Lv et al., 2024).In multi-round iterative optimization, the input prompt can become increasingly lengthy to trace the optimization trajectory, which may distract the LLMs' reasoning and result in the lost in the middle issue (Shi et al., 2023).Despite LLMs' ability to process long contexts, performances significantly decrease as the input grows longer, even for models explicitly designed for long contexts (Lv et al., 2024).</p>
<p>To address this challenge, we propose a conceptually simple, flexible, and general method, namely General Scientific Optimizers (GSO).Specifically, GSO is a bi-level optimization method involving inner-level optimization and outer-level optimiza-tion, together with bi-level interaction between them.For a given optimization task, GSO will iteratively conduct the following process: (i) the inner-level optimization first employs simulators serving as an experimental platform to provide observational feedback for reasoning and refining; (ii) the outer-level optimization then utilizes knowledgeable LLMs as reasoning agents to generate hypotheses, reason with observational feedback, and refine the previous hypothetical solutions.It also devises a dynamic exploit-and-explore strategy to adaptively adjust the LLM reasoning trajectory based on observational feedback; (iii) finally, the bi-level optimization jointly updates the simulations together with the knowledge embedded within LLMs via model editing.</p>
<p>GSO is a novel framework to boost general mathematical optimization in scientific scenarios.</p>
<p>As shown in Figure 1, extensive experiments demonstrate the effectiveness and generalization of our GSO, leading significant and consistent superiority using six different LLM backbone on seven different tasks than existing state-of-the-art methods.</p>
<p>Preliminaries</p>
<p>Model Editing Model editing mainly focuses on altering the internal knowledge within LLMs.It aims to update a range of intricate learned concepts, such as logical reasoning, spatial awareness, and numerical understanding, to make tailored adjustments to the model's behavior.In this paper, we follow (Zhong et al., 2023;Zhang et al., 2024c) to update factual knowledge represented as (subject s, relation r, object o).An LLM is expected to retrieve a memory corresponding to o when given a natural language prompt.Editing a fact involves replacing the existing knowledge triple (s, r, o) with a new one (s, r, o * ).For simplicity, an edit is denoted as e = (s, r, o, o * ).Given a set of edits E = {e 1 , e 2 , . ..} and an original model f θ 0 , sequential model editing applies each edit consecutively, i.e., F(f θ n−1 , e n ) = f θn , where f θn refers to the model after n edits.</p>
<p>Simulator</p>
<p>Simulation:</p>
<p>Total distance is feedback:</p>
<p>Figure 2: The overview of GSO.For a given optimization task, GSO iteratively conducts the inner-level optimization, outer-level optimization, and bi-level interaction sequentially.The workflow is as follows: (i) the inner-level simulator Φ conducts numerical simulations based on the current step's hypothetical solution role of MLP layers in Transformers, revealing that these layers store knowledge, which can be localized to specific neurons and edited (Da et al., 2021;Geva et al., 2020Geva et al., , 2022)).KE (De Cao et al., 2021) and MEND (Mitchell et al.) train a hypernetwork to compute gradient adjustments for updating model parameters.ROME (Meng et al., 2022) and MEMIT (Meng et al.) apply the Locate-Then-Edit strategy, which first locates MLP storing factual knowledge, and then edits such knowledge by injecting a new key-value pair in the MLP module.
s k (v 1 → v 2 → v 3 → v 4 → v 1 )
LLMs for Scientific Optimization A recent line of research explores methods to enhance LLM performance by incorporating natural language feedback as prompts to revise model outputs in improving reasoning (Shinn et al., 2023;Madaan et al., 2024), code generation (Chen et al., 2023a;Olausson et al., 2023), dialogue applications (Nair et al., 2023;Yuan et al., 2024;Liu et al., 2024c), and so on (Wang et al., 2023a;Kim et al., 2024).</p>
<p>LLMs have also been demonstrated to optimize complex problems by utilizing tools (Sumers et al.).</p>
<p>AlphaGeometry 's (Trinh et al., 2024) success in solving complex geometry problems without human demonstrations underscores the potential of LLMs in automating complex tasks.OPRO (Yang et al., 2023) employs LLMs as black-box optimizers for complex reasoning tasks.Eureka (Ma et al., 2023c) generates multiple solutions in each step to increase the success rate of produced codes.Funsearch (Romera-Paredes et al., 2024b) utilizes an evolutionary strategy to avoid local optima by using LLMs along with a systematic evaluator.SGA (Ma et al., 2024c) introduces a bilevel optimization framework to enhance the knowledge-driven capabilities of LLMs by integrating simulations.</p>
<p>Method</p>
<p>We first briefly outline the bi-level pipeline of our GSO, describing how the inner-level and the outerlevel optimization are jointly conducted.Specifically, for a scientific optimization task y (e.g., the traveling salesman problem), GSO aims to predict the optimal solution ŝ, by which GSO iteratively optimizes the solution s k from an initial solution s 0 , where k denotes the iteration step.Each iteration consists of three parts: the innerlevel simulation platform, outer-level LLM optimization, and bi-level interactions.An overview of GSO is in Figure 2.</p>
<p>The inner-level simulator first serves as an experimental platform, where a simulator Φ is employed to take a intermediate solution s k and its scientific expression E k (e.g., coordinates of the nodes in the TSP task) as inputs, and outputs the corresponding observational feedback f k and the optimization objective L k (e.g., the total distance of the current route in the TSP task):
(f k , L k ) = Φ (s k ; E k )
The outer-level optimization then utilizes an LLM with its parameter θ k (denote by M θ k ) as a reasoning agent, propose a new hypothesis to optimize the current solution s k :
E k+1 , s k+1 = M θ k {L i , f i , E i , s i } k i=0 ; P .
Here P denotes the input prompt to LLM, and {L i , f i , E i , s i } k i=0 represents the historical optimization trajectory.</p>
<p>The bi-level interaction finally utilizes the feedback f k from inner-level simulation and the solutions s k provided by the outer-level LLM as a new key-value pair to update the LLM parameters θ through model editing:
M θ k+1 = F (M θ k , s k , f k ) ,
where θ k+1 represents the new parameter matrix obtained by applying a model editing step to the previous parameters θ k , M θ k+1 represents the according updated LLM, and F denotes the model editing process.We can then define the overall optimization task:
min s L y(E, s, Φ) (1a) s.t. G(E, s, Φ) ≤ 0 (1b)
where G (•) ≤ 0 indicates that the current solution satisfies the constraints of the given optimization problem (for example, in the TSP task, the solution must visit all points and return to the starting point).</p>
<p>Inner-level Simulation Platforms</p>
<p>The inner-level optimization conducts numerical simulations for a hypothetical solution.</p>
<p>Simulations can provide domain-specific knowledge, transferring information from the simulation to optimization outputs (e.g., feedback in the form of total distance for the TSP task).</p>
<p>These outputs, paired with the predicted solution s, are then fed back into the LLMs to iteratively refine the hypothesis.</p>
<p>The feedback can include the simulation loss relative to the target metric L, as well as auxiliary information during the optimization process, which can provide more insights for improving solutions.</p>
<p>For instance, if L represents the total distance of a solution for a TSP task, the auxiliary information may include the specific distance between two given points or the relative magnitude of distances between pairs of points (e.g.simulator can provide auxiliary information that (v 4 , v 1 ) has a larger distance than (v 2 , v 4 ) in Figure 2).</p>
<p>Outer-level LLM Optimization</p>
<p>Many studies have demonstrated that LLMs are capable of discovering high-quality solutions and can match or even outperform hand-designed heuristic algorithms (Yang et al., 2023;Romera-Paredes et al., 2024c).Therefore, we design outer-level optimization to: (i) analyze the current optimization task and make reasonable hypotheses; (ii) utilize the feedback from the simulations (including experimental phenomena and loss values, etc.), and update the LLM's knowledge through model editing;</p>
<p>(iii) design and propose new potential solutions and input into the simulation platforms.</p>
<p>Inspired by the scientific optimization process by human scientists, we observe that when confronted with a new problem, scientists tend to be daring adventurers, utilizing expert knowledge and problem parameters to thoroughly explore the search space, eliminating improbable parameter regions.This may significantly reduce the subsequent solution space, yielding solutions that satisfy optimization constraints, though they may not be optimal (Wuestman et al., 2020).</p>
<p>Then, after gaining a deeper understanding of the problem through initial attempts, they change to be cautious followers to keep the trajectory and trail previous solutions, adhering more closely to previous optimizations.This allows them to continually improve the metrics while satisfying optimization constraints, ultimately approaching the optimal solution.We thus design a dynamic exploitation and exploration strategy to mimic this process.</p>
<p>Specifically, we calculate the loss change as ∆L = Lprev−Lcur Lprev .If ∆L &gt; 0, this indicates that the current hypothetical solutions are better than the previous ones.We then apply a lower decoding temperature to allow the LLM to follow the trace, i.e., T cur = T pre × 1 1+∆L ; if ∆L &lt; 0, this indicates that current solutions are worse than the previous ones.We thus apply a higher decoding temperature to be more exploratory and adventurous, i.e., T cur = T pre × (1 + |∆L|).We also clip the temperature to [0, 1] in case that T cur &lt; 0 or T cur &gt; 1.</p>
<p>Empirically, we divide solutions into S exploit and S explore .We observe that (i) S exploit often contains repetitive solutions from previous iterations, and (ii) S explore tends to yield solutions to be informative for guiding optimization, or otherwise infeasible.</p>
<p>Bi-level Interactions</p>
<p>The key challenge in integrating the two levels of optimization is developing a protocol that facilitates efficient, structured, and flexible communication between them.</p>
<p>Therefore, we propose an interaction strategy considering the two aspects.On the one hand, from simulation platforms to LLMs, drawing upon (Meng et al., 2022), we incorporate the feedback from simulation platforms as new knowledge edited into the model.We first locate how facts are stored within the parameters of LLMs.We begin by analyzing and identifying which specific layers and their parameters W have the strongest causal effect on predictions of individual facts through causal tracing (Meng et al., 2022) (Detailed steps and results of the causal tracing for different LLMs are in Appendix B).Next, we integrate the experimental results from the simulation platforms as new knowledge, formatted as triples, into the model.For instance, in the context of the TSP problem, suppose the simulation platform's feedback template includes: (i) the path length for the solution v 1 → v 2 → v 3 → v 4 is 108, (ii) the distance between v 1 and v 4 is greater than that between v 2 and v 4 , and etc.These statements are then transformed into triples, such as (v 1 → v 2 → v 3 → v 4 , has distance of, 108) and (v 1 , v 4 ), greater than, (v 2 , v 4 )), which are subse-quently edited into the model.Finally, by collecting such triples (s, r, o), we compile a series of key-value pairs for a set of vector keys S = [s 1 , s 2 , . . ., s n ] and corresponding vector values O = [o 1 , o 2 , . . ., o n ] in each iteration step.Therefore, for the u new (s, r, o) pairs obtained from the next iteration step, the objective of editing can be given by the following formula:
W1 ≜ arg min Ŵ n i=1 Ŵ si − oi 2 + n+u i=n+1 Ŵ si − oi 2
Here, W denotes the original matrix and W 1 denotes the edited weight matrix.</p>
<p>Due to this straightforward algebraic structure, any fact can be inserted directly once (s, o) is determined.We can update the parameters of the LLM by editing the newly obtained u parameterfeedback pairs all at once, which adaptively utilizes the feedback from each simulation platform interaction into the LLM.It directly updates the LLM's weight parameters and prevents the input prompt length from increasing with iterations, alleviating the loss-in-the-middle issue during long-text and multi-round optimization processes.</p>
<p>On the other hand, from LLMs to simulation platforms, we leverage the LLM as a domain expert to guide the setup of each subsequent simulation based on the results of the previous results.This process is akin to an experienced scientist providing tailored guidance for the experimental configuration of the next step simulation based on the current results.The simulation platforms can then continue running experiments based on the guidance of the LLM to provide observational feedback.Specifically, each time the outer-level LLM receives feedback from the previous iteration of simulation platforms, it can simultaneously request intermediate results from the inner-level platforms to aid in its reasoning.Taking the TSP problem as an example, when the LLM provides the solution
v 1 → v 2 → v 3 → v 4 → v 1 ,
it can also request the platforms to provide the specific distance between two points.This additional feedback can then assist in refining the reasoning for the next iteration.</p>
<p>Experiments</p>
<p>Problem Descriptions</p>
<p>We provide a brief definition of each task.More detailed definitions are in Appendix F. For the linear system regression task, the objective is to estimate the linear coefficients to model relationships Table 1: Results of our GSO against 6 baselines using GPT-J 6B, Llama3 8B, and Mistral 7B as three representative backbone models (for more results of different backbone models, please see Appendix E).Our experiments encompass 7 different tasks, which are divided into linear system regression (LSR) (a), travel salesman problem (TSP) (b), constitutive law prediction (c-d), and molecule property prediction (e-g).We report the mean ± standard error of each optimization result.The symbol N/A indicates that the model cannot provide a feasible solution for the current task.A lower value is preferable across all tasks.The best results are highlighted in bold text.</p>
<p>Backbone Method</p>
<p>Linear System Travel Salesman Constitutive Law Molecule Property   5.6 ± 3.0 0.1 ± 0.0 3.2 ± 1.7 13.0 ± 2.1 23.9 ± 5.1 2.8 ± 1.5 1.7 ± 0.4
(a) ↓ (b) ↓ (c) ↓ (d) ↓ (e) ↓ (f) ↓ (g) ↓ GPT-J 6B Vanilla N/A 6.0 ± 2.0 N/A N/A N/A N/A N/A CoT N/A 4.4 ± 1.9 N/A N/A N/A N/A N/(a) ↓ (b) ↓ (c) ↓ (d) ↓ (e) ↓ (f) ↓ (g) ↓ Llama3 8B Vanilla N/A 6.0 ± 2.0 N/A N/A N/A N/A N/A CoT N/A 4.4 ± 1.9 3397.0 ± 298.9 N/A N/A N/A N/(a) ↓ (b) ↓ (c) ↓ (d) ↓ (e) ↓ (f) ↓ (g) ↓ Mistral 7B Vanilla N/A 6.0 ± 2.0 N/A N/A N/A N/A N/A CoT N/A 4.4 ± 1.9 N/A N/A N/A N/A N/
between input and corresponding output (Fisher, 1922).We use "#steps" (optimization steps for successfully finding the optimal solution) as the metric.We follow the same dataset setting as OPRO (Yang et al., 2023).For the TSP task, the objective is that given a set of n nodes with known coordinates, it seeks to find the shortest possible route that visits each node once and returns to the starting point.We follow the same dataset setting as OPRO (Yang et al., 2023) and use the Gurobi solver (Gurobi Optimization, LLC, 2024) to construct the oracle solutions and compute the optimality gap as the metric (the difference between the distance in the solution by the evaluated approach and by the oracle solution, divided by the distance of the oracle solution).For the constitutive law prediction task, we consider both fitting linear and non-linear materials and follow the same dataset setting as SGA (Ma et al., 2024c).We use mean square error (MSE) as the metric.For the molecular property prediction task, we consider three tasks: predict a molecule's highest occupied molecular orbital (HOMO), lowest unoccupied molecular orbital (LUMO), and the HOMO-LUMO gap based on their conformations and quantum mechanical properties.We follow SGA to use the QM9 dataset (Ramakrishnan et al., 2014) for experiments.We also use MSE as the metric.</p>
<p>Experiment Setups</p>
<p>Implementation Details.We apply LLMs including GPT-J 6B (Radford et al., 2019), Llama3 8B (Team, 2024b), Mistral 7B (Jiang et al., 2023), Llama2 13B (Team, 2023c), Yi9b (Young et al., 2024), and Internlm 7B (Team, 2023b).We follow (Ma et al., 2023c) to conduct all experiments five times using different random seeds to guarantee stable and reproducible results.More details of implementation details are in Appendix F. We consider six strong baselines for evaluation: (i) vanilla LLMs without additional modules.Vanilla LLMs represent the original capabilities</p>
<p>Main Results</p>
<p>We conduct our experiments on the 7 designed tasks using GPT-J 6B, Llama3 8B, and Mistral 7B as three representative backbone models in Table 1.We also provide more results for other three different backbone models in Table 5 in Appendix E to demonstrate the versatility of our GSO across different backbones.GSO enables tasks, which are challenging to effectively optimize with traditional Vanilla and CoT methods, to become feasible.We also observe that GSO significantly and consistently outperforms existing methods on the scientific optimization tasks, which demonstrates the effectiveness of our GSO.Notably, for the molecule property prediction task on predicting the HOMO-LUMO gap, GSO achieves a maximum precision improvement of over 32.6× when utilizing Mistral 7B as the backbone model.These results underscore the importance of effectively utilizing the observational feedback to adaptively adjust its optimization directions.The universality of six popular open-source backbone models in Appendix E also suggests the generalizability of our GSO.</p>
<p>Ablation Study</p>
<p>To further investigate the contribution of each component within GSO, we conduct a series of ablation experiments on the entire framework.Specifically, we denote GSO without edit as GSO w/o edit , GSO without the dynamic strategy as GSO w/o dynamic , respectively.We use Llama3 8B as the backbone model, the results of other backbone models are in Appendix G.We present the ablation results of GSO using Llama 3 8B as the backbone model in Table 2.More Results using the other five different backbone models are in Appendix G.As shown in Table 2, the absence of any component within GSO results in a performance degradation of the entire framework.Notably, GSO w/o edit exhibits more significant impacts on the performance of GSO, which demonstrates the importance of effectively utilizing the observational feedback to adaptively adjust the optimization direction.</p>
<p>Case Study</p>
<p>Robustness of the Prompt As mentioned in Section 1, one appealing feature of our GSO compared to other methods is its robustness to prompts.Prompts with similar semantics do not require meticulous crafting to yield consistently promising results.To provide more insights into our GSO, we manually generated two prompts and used Ope-nAI o1 to rewrite an additional three based on the original task prompts for each task (details of the generated prompts are in Appendix D).As shown in Table 3, we observe that prompt-based methods tend to be sensitive to the prompts, with semantically similar prompts often leading to fluctuating results across many tasks.This necessitates signifi- cant effort from users to perform prompt 'tuning' during application.In contrast, our GSO consistently produces robust results across different prompts, with minimal variation between semantically similar prompts.This reduces the need for extensive prompt "tuning," highlighting its potential for broader real-world applications.</p>
<p>Loss Curve and Decoding Temperature We also investigate the impact of the number of lengthy input prompts as optimization iterations increase on each method.We present the feedback loss trend for the non-linear constitutive law task (d) in Figure 3 as an example.We observe that GSO achieves significantly lower loss and exhibits a clear convergence trend compared to existing baselines.This demonstrates that GSO can effectively leverage feedback from each iteration to achieve stable and consistent improvements in scenarios involving lengthy prompts.Notably, some methods show improvement at the beginning (i.e., loss reduction) when the initial prompt is short and the optimization space is large, but as the number of optimization steps increases, the feedback loss fluctuates, making further optimization difficult.In contrast, GSO effectively leverages each step feedback to adaptively adjust its optimization direction, leading to a stable and consistent loss decrease.</p>
<p>These results demonstrate that GSO can effectively observational feedback from lengthy prompts to facilitate further optimization, thereby alleviating the loss in the middle issue.</p>
<p>Comparison with Advanced Closed-source LLMs We also compared our GSO framework on open-source models with the current state-ofthe-art closed-source model, GPT-4o1 and Claude-3-Sonnet2 .As shown in Table 4, our GSO utilizing Mistral 7B can consistently outperform GPT-4o and Claude-3-Sonnet, demonstrating the effectiveness of our approach.Note that our method is orthogonal to the choice of backbone model, making it a versatile plug-and-play module that can be directly applied to more advanced LLMs to further achieve enhanced results.</p>
<p>Conclusion</p>
<p>In</p>
<p>Limitations</p>
<p>We consider a few limitations and future directions.</p>
<p>(i) The content generated by LLMs exhibits a certain degree of randomness, and the optimization process cannot guarantee interpretability or transparency.(ii) LLM inference requires large computational resources and thus increases expense.It paves the way for research on LLM inference acceleration to expedite our GSO (Leviathan et al., 2023;Liu et al., 2024b).(iii) GSO requires access to model weights, which limits its applicability to closed-source models like GPT-4 and Claude 3.5.We believe that as the community progresses and the performance gap between open-source and closed-source models narrows, our GSO will be able to demonstrate its capabilities more effectively.</p>
<p>A More Related Works</p>
<p>A.1 Classical Language Model Methods for Scientific Optimization</p>
<p>Besides the methods using LLMs for scientific optimization in Section 3, these are several classical studies that have fine-tuned language models (LMs) to function as mutation and crossover operators within evolutionary algorithms (Meyerson et al., 2023a;Zhang et al., 2024a;Li et al., 2024c).LMX (Meyerson et al., 2023b) employs language models guided by few-shot exemplars to generate evolutionary crossovers in tasks like image and code generation, enhancing the model's ability to adapt and innovate across diverse domains.ELM (Lehman et al., 2022) trains an LLM to generate code diffs, which serve as the mutation operator, and introduces a fine-tuning method to enhance performance in the Sodarace domain for robotic simulation.Evo-Prompting (Chen et al., 2024a) leverages large language models to evolve neural network architectures by integrating evolutionary search with soft prompt tuning.OptFormer (Chen et al., 2022) incorporates trajectories as input for optimization by training a transformer model on extensive hyperparameter optimization datasets.These methods primarily focus on fine-tuning LLMs with domainspecific data to align natural language with scientific information.However, these approaches are domain-bound and demand substantial data which also limits their broader applicability.</p>
<p>A.2 Large Language Models</p>
<p>Language models such as GPT (Radford et al., 2018), BERT (Kenton and Toutanova, 2019), RoBERTa (Liu et al., 2019), and Megatron-LM (Shoeybi et al., 2019) have led to a learning paradigm shift in natural language processing (NLP).Models are first pre-trained on extensive volumes of unlabeled text corpora with language modeling objectives and then fine-tuned on downstream tasks.Recently, large language models (LLMs) including LLama (Team, 2024b(Team, , 2023c) ) ChatGPT (OpenAI, 2020) GPT4 (OpenAI, 2023), PaLM (Team, 2022), Gemini (Team, 2023a), and Claude3 (Team, 2024a) have shown great performance in both few-shot and even zero-shot scenarios (Brown et al., 2020).To further enhance the interpretability of these LLMs, some research endeavors explain LLMs through attribution analysis (Wang et al.;Hanna et al., 2024;Gurnee et al.;Chen et al., 2024c).Another line of work aims to retrieve the knowledge explicitly from LLMs as the basis for interpreting them, including the reasoning task (Shi et al., 2023) and the QA task (Hao et al., 2023;Dhingra et al.;Guu et al., 2020).</p>
<p>B Results of the Causal Tracing for Different LLMs</p>
<p>Causal tracing has emerged as a pivotal methodology for dissecting and understanding the internal mechanisms of model (Didelez and Pigeot, 2001).This technique facilitates the identification and modification of specific factual associations within a model without necessitating comprehensive retraining (Neuberg, 2003).In the context of model editing, causal tracing enables precise interventions by isolating the neural correlates responsible for particular behaviors or outputs.We follow (Meng et al., 2022) to build a causal graph (Neuberg, 2003) to describe dependencies between the hidden variables.This graph illustrates numerous pathways from the input on the left to the output (next-word prediction) at the lower right.Our aim is to determine whether specific hidden state variables are more important than others in the process of recalling a fact.</p>
<p>To quantify each state's contribution to a correct factual prediction, we analyze all of LLM's internal activations across three runs: a clean run that accurately predicts the fact, a corrupted run where the prediction is impaired, and a corruptedwith-restoration run that evaluates the ability of a single state to restore the correct prediction.</p>
<p>Let P[o], P * [o], and P * , clean h l i [o] denote the probability of emitting the given entity o under the clean, corrupted, and corrupted-with-restoration runs, respectively; dependence on the input x is omitted for notational simplicity.</p>
<p>The total effect (TE) is defined as the difference between two probabilities:
TE = P[o] − P * [o].
The indirect effect (IE) of a specific mediating state ĥi l is defined as the difference between the probability of o under the corrupted condition and the probability of o when that state is restored to its clean version, while the subject remains in a corrupted state:
IE = P * ,clean h i l [o] − P * [o].
By averaging over a sample of statements, we can derive the average indirect effect (AIE) for Table 5: Results of our GSO against 6 baselines using Llama2 13B, Yi 9B, and Internlm 7B as the backbone models.Our experiments encompass 7 different tasks, which are divided into linear system regression (LSR) (a), travel salesman problem (TSP) (b), constitutive law prediction (c-d), and molecule property prediction (e-g).For the LSR task, we use the number of steps of successfully finding the optimal solution as the metric.For the TSP task, we use the optimality gap as the metric.For the rest five tasks, we use MSE loss as the metric.We calculate the mean ± standard error of each optimization result.The symbol N/A indicates that the model is unable to provide a feasible solution for the current task.A lower value is preferable across all tasks.The best results are highlighted in bold text.</p>
<p>Backbone Method</p>
<p>Linear System Travel Salesman Constitutive Law Molecule Property  3.0 ± 0.8 0.0 ± 0.0 5.9 ± 2.1 89.1 ± 33.9 67.9 ± 23.1 172.9 ± 43.1
(a) ↓ (b) ↓ (c) ↓ (d) ↓ (e) ↓ (f) ↓ (g) ↓ Llama2 13B Vanilla N/A 6.0 ± 2.0 N/A N/A N/A N/A N/A CoT N/A 4.4 ± 1.9 N/A N/A N/A N/A N/A Funsearch N/A 2.(a) ↓ (b) ↓ (c) ↓ (d) ↓ (e) ↓ (f) ↓ (g) ↓ Yi 9B Vanilla N/A 6.0 ± 2.0 N/A N/A N/A N/A N/A CoT N/A 4.4 ± 1.9 N/A N/A N/A N/A N/5.5 ± 2.1 Backbone Method Linear System Travel Salesman Constitutive Law Molecule Property (a) ↓ (b) ↓ (c) ↓ (d) ↓ (e) ↓ (f) ↓ (g) ↓ Internlm 7B Vanilla N/A 6.0 ± 2.0 N/A N/A N/A N/A N/A CoT N/A 4.4 ± 1.9 N/A N/A N/A N/A N/</p>
<p>C Prompt Templates for Each Task</p>
<p>We list the prompt templates for different tasks to offer more visually intuitive results for each task in Table 7, respectively.More detailed prompt information for the best performance of each task and dataset can be seen within the code.</p>
<p>D Details of Augmented Prompts</p>
<p>As mentioned in Section 5.5, we discussed the robustness of the GSO method compared to traditional prompt-based approaches when handling semantically similar prompts.Specifically, we manually generated five prompts and used OpenAI o1 to rewrite an additional five prompts based on the original task prompts.We now list these augmented prompts in Tables 8 and 9 to provide more insights  The causal impact on output probability is mapped for (a) the effect of each hidden state on the prediction, (b) the effect of MLP activations alone, and (c) the effect of attention activations alone.We also give according to mean causal traces of over a sample of 1000 factual statements, shown as a line plot with 95% confidence intervals, which is below the first three figures.The confidence intervals confirm that the distinctions between peak and non-peak causal effects at both early and late sites are significant.into our GSO.</p>
<p>E More Results of Different Edited Models</p>
<p>As mentioned in Section 5.3, we select GPT-J 6B, Llama3 8B, and Mistral 7B as representative models in Table 1.In this section, to further demonstrate the generalization and versatility of GSO, we also conducted experiments on several popular open-source LLMs at different scales, including Llama2 13B, Yi-9B, and Internlm 7B.As shown in Table 5, we can still observe that our GSO method significantly outperforms existing baselines.This further demonstrates the effectiveness of our GSO approach.We also present radar charts for each model to provide a more intuitive performance comparison in Figures 10 and 11.We apply a linear mapping to assign a score of 100 to values with a zero loss.Higher loss values correspond to progressively lower scores, with an inability to answer the question resulting in a score of zero.For formatting reasons, we also provide the radar chart of Llama3 8B.The effectiveness of our GSO across various popular open-source models further demonstrates its strong versatility and generalization capabilities.</p>
<p>F More Details of Experiment Setups and Task Definitions</p>
<p>We present more details of experiment setups and task definitions in this section.</p>
<p>Experiment Setups For the experimental setup, we apply several representative open-source LLMs: Llama3 8B 4 , GPT-J-6B 5 , Llama2 13B 6 , Yi 9B 7 , InternLM 7B 8 , and Mistral 7B 9 .Other open-source models can also be replaced based on specific requirements.All experiments were conducted on a single Nvidia A100 GPU (80GB).Our approach is implemented using PyTorch 2.4.1 10 and Huggingface's Transformers 4.44.2 11 .For each task, we set a maximum of 100 iterations, with a limit of 2048 tokens generated per iteration.The optimization process terminates if no performance improvement or accurate result is observed after 10 consecutive iterations, or if an accurate result is reached earlier.</p>
<p>More detailed configurations for the best perfor- Figure 5: Causal tracing visualization results for GPT-J 6B.The causal impact on output probability is mapped for (a) the effect of each hidden state on the prediction, (b) the effect of MLP activations alone, and (c) the effect of attention activations alone.We also give according to mean causal traces of over a sample of 1000 factual statements, shown as a line plot with 95% confidence intervals, which is below the first three figures.The confidence intervals confirm that the distinctions between peak and non-peak causal effects at both early and late sites are significant.mance of each task and dataset can be seen within our code.</p>
<p>For task definitions, we provide a more detailed of each task definition and setting.</p>
<p>Linear System Regression In linear system regression, the objective is to estimate the linear coefficients that most effectively model the relationship between input variables and their corresponding responses, within a probabilistic framework (Fisher, 1922).We follow the dataset setting as OPRO (Yang et al., 2023) which we include 437 samples.Linear system regression is a fundamental technique in statistics and machine learning, widely applied in both theoretical and practical settings (Montgomery et al., 2021;Seber and Lee, 2012).</p>
<p>Traveling Salesman Problem (TSP) The Traveling Salesman Problem (TSP) (Jünger et al., 1995;Gutin and Punnen, 2006) is a classical combinatorial optimization problem that has garnered significant attention in the literature, with numerous algorithms proposed, ranging from heuristic methods to exact solvers (Rosenkrantz et al., 1977;Golden et al., 1980;Gurobi Optimization, LLC, 2024;Helsgaun, 2017).Recently, the problem has also been approached through the use of deep neural networks (Kool et al., 2018;Deudon et al., 2018;Chen and Tian, 2019;Nazari et al., 2018), underscor-ing its adaptability to modern machine learning techniques.Formally, given a set of n nodes with known coordinates, the TSP seeks to determine the shortest possible route that visits each node exactly once and returns to the starting point.We follow the dataset setting as OPRO (Yang et al., 2023), which we include 177 TSP problems.At each optimization step, a maximum of 8 new solutions are generated.To evaluate the performance of various methods, we utilize the Gurobi solver (Gurobi Optimization, LLC, 2024) to generate oracle solutions and compute the optimality gap.The optimality gap is defined as the relative difference between the distance of the solution obtained by the tested approach and that of the oracle solution, normalized by the oracle solution's distance.</p>
<p>Constitutive Law Prediction Identifying constitutive laws from elastic material remains one of the most challenging tasks in fields such as physics, materials science, and mechanical engineering.In this paper, we follow the dataset settings as (Ma et al., 2023a(Ma et al., , 2024c)), including 357 different linear and non-linear materials and utilizing differentiable Material Point Method (MPM) simulators (Sulsky et al., 1995;Jiang et al., 2016).The primary objective of this task is to uncover both the discrete structure and continuous parameters of a constitutive law, specifically identifying the material models φ(•) along with their associated material parame-  The causal impact on output probability is mapped for (a) the effect of each hidden state on the prediction, (b) the effect of MLP activations alone, and (c) the effect of attention activations alone.We also give according to mean causal traces of over a sample of 1000 factual statements, shown as a line plot with 95% confidence intervals, which is below the first three figures.The confidence intervals confirm that the distinctions between peak and non-peak causal effects at both early and late sites are significant.</p>
<p>ters θ, from a ground-truth trajectory of particle positions Xt∈[1,...,T ] , where T represents the number of time steps.In this context, we consider two classes of constitutive laws: φ E (•; θ E ) for modeling elastic materials and φ P (•; θ P ) for modeling plastic materials, both of which contain both linear and non-linear materials and are formally defined as the following:
φ E (F; θ E ) → τ φ P (F; θ P ) → F corrected ,
where F ∈ R 3×3 is the deformation gradient, τ ∈ R 3×3 is the Kirchhoff stress tensor, F corrected ∈ R 3×3 is the deformation gradient after elastic return-mapping correction, and θ E and θ P are the continuous material parameters for elastic and elastic constitutive laws respectively.Given a specific constitutive law, we input it to the differentiable simulation and yields a particle position trajectory:
X t∈[1,...,T ] = sim (φ (•; θ)) ,
and we optimize the constitutive law by fitting the output trajectory to the ground truth Xt∈[1,...,T ] .</p>
<p>Molecule Property Prediction Predicting the Highest Occupied Molecular Orbital (HOMO), Lowest Unoccupied Molecular Orbital (LUMO), and HOMO-LUMO gap value of molecules is a key challenge in computational chemistry, particularly in the fields of quantum chemistry, material science, and drug design.In this task, we aim to predict the HOMO value based on molecular descriptors, such as molecular weight, Topological Polar Surface Area (TPSA), Octanol-water partition coefficient (logP), etc (maximum to 2k different properties).Although traditional quantum mechanical methods such as Density Functional Theory (DFT) are widely used for HOMO calculations, their computational cost can be prohibitive for large datasets.In this work, we adopt a machine learning approach to predict the HOMO value using these physicalchemical properties as input features.We follow the dataset settings as (Ma et al., 2023a(Ma et al., , 2024c)), including 238 different molecules.</p>
<p>The primary goal of this task is to construct a model that accurately predicts the HOMO energy level ϵ HOMO by learning a mapping ψ(•) between the input molecular properties x ∈ R n , such as molecular weight, TPSA, and logP, and the HOMO energy ϵ HOMO ∈ R. The machine learning model is trained on a dataset containing known molecular properties and their corresponding HOMO values, and optimized to minimize the prediction error relative to the true HOMO values εHOMO .</p>
<p>Given a set of molecular descriptors, the model outputs the predicted HOMO value:  of attention activations alone.We also give according to mean causal traces of over a sample of 1000 factual statements, shown as a line plot with 95% confidence intervals, which is below the first three figures.The confidence intervals confirm that the distinctions between peak and non-peak causal effects at both early and late sites are significant.and the objective is to minimize the loss function, defined as the difference between the predicted and true HOMO values:
ϵ HOMO = ψ(x),L = ∥ψ(x) − εHOMO ∥ 2 .
This approach provides a computationally efficient alternative to traditional quantum mechanical methods, offering the potential for high-throughput screening of molecular libraries for their electronic properties, including HOMO values.</p>
<p>G More Results of Ablation Study</p>
<p>In Section 5.4, we report the results of the ablation study using Llama3 8B as the backbone model.In this section, we will further present the results using GPT-J-6B, Llama2 13B, Yi 9B, InternLM 7B, and Mistral 7B as backbone models to obtain more insights into the individual components constituting GSO across various backbone models.As illustrated in Tables 11, 12, 13, 14, and 15, we still observe that the absence of each component within GSO leads to a decline in performance across diverse domains for almost all applied backbone models in the seven tested scientific optimization tasks, which further demonstrates that GSO organically integrates the two-level optimization into a unified framework as well.We also observe that the absence of model editing leads to a more significant decline in accuracy, which further demonstrates the importance of effectively utilizing observational feedback to adaptively adjust the optimization direction.</p>
<p>H More Case Study on Generalization or Memorization</p>
<p>To investigate whether the improvements brought by our method are solely due to the LLM having seen solutions during the training phase, we designed an experiment aimed at eliminating this factor by having the model invent an imaginary constitutive law that does not exist on Earth.We combined the von Mises plasticity constitutive law, granular material, and weakly compressible fluid in proportions of 50%, 30%, and 20%, respectively, creating a new constitutive law that represents an exceedingly complex hypothetical material.As shown in Table 6, our method was still able to discover the constitutive law with minimal quantitative loss compared to other existing baselines.These results also indicate that GSO does not simply rely on memorization to achieve results but instead indeed effectively performs optimization.</p>
<p>I Inference Time Comparisons</p>
<p>We note that GSO requires an additional process to utilize the optimization feedback by applying model editing techniques to update LLM's parameters.Compared to the vanilla model, this process  The causal impact on output probability is mapped for (a) the effect of each hidden state on the prediction, (b) the effect of MLP activations alone, and (c) the effect of attention activations alone.We also give according to mean causal traces of over a sample of 1000 factual statements, shown as a line plot with 95% confidence intervals, which is below the first three figures.The confidence intervals confirm that the distinctions between peak and non-peak causal effects at both early and late sites are significant.could potentially introduce extra inference time.However, we also observe that GSO effectively reduces the input prompt length through this approach, thereby decreasing the LLM's inference time.Hence, to explore the interplay between these two effects, we record and compare the average inference time per sample of different methods using a single Nvidia A100 GPU (80GB), including vanilla, CoT, OPRO, Eureka, Funsearch, SGA, and GSO on each mentioned scientific optimization task to explore the influence of additional inference time and provide more insight of our GSO.We report the average inference time per sample as a metric, as shown in Table 10.We observe from the table that although the incorporation of model editing within the GSO framework introduces just marginal additional inference time costs.On average, the increase in inference time cost per sample due to the introduction of GSO, compared to the vanilla LLM, is 7.75s.Notably, when utilizing Mistral 7B as the backbone model, this additional inference time is only 5.8s, yet it offers a maximum precision improvement of 32.6× in the HOMO-LUMO gap prediction task compared to all other methods.Furthermore, GSO exhibits higher inference efficiency compared to existing methods.We may focus on exploring ways to further reduce the time cost of the GSO, including lightweighting LLMs to get a faster calculation (Zhu et al., 2023;Hsieh et al., 2023) or adopting more efficient (Wang et al., 2023c;Zhao et al., 2024;Frantar and Alistarh, 2023) and rational large model inference strategies such as speculative decoding (Leviathan et al., 2023;Liu et al., 2024b) as for future works.</p>
<p>J Scientific Artifacts</p>
<p>The data we collect in specialized domains is publicly available and viewable online.The data owners have indicated that the data can be used for scientific research or have not indicated that the data cannot be used for scientific research, and our collection process is also in compliance with regulations.Moreover, there is no unique identification of individuals or offensive content in these data.</p>
<p>K More Discussions On GSO K.1 What is the key advantage of using LLMs to optimize over some traditional optimization algorithms, especially on classical optimization problems?</p>
<p>The key advantage is that one can use natural language to describe the optimization problem.Instead of formally defining the optimization problem and deriving the update step with a programmed solver.This makes optimization more accessible to general users who may not have extensive domain knowledge of the specific types of optimization tasks in question, and it may also enhance To investigate how the dynamic exploitation/exploration strategy works, we designed an ablation experiment in Section 5.4 and Appendix G. Statistically, the strategy has a relatively positive effect, especially for tasks like predicting the HOMO-LUMO gap of molecules.We find that: Without exploitation, GSO sometimes finds it difficult to effectively provide consistent high-quality parameter hypotheses.Without exploration, GSO sometimes becomes trapped in local optima, unable to further optimize the task to gain additional insights.Consequently, using a balanced exploitation/explo- The HOMO value for each molecule should be distinct from any previously reported values, and the predictions should ensure an accurate representation of their electronic properties.Each predicted value should be formatted to start with <value> and end with </value> ration strategy enables one to escape local optima and obtain consistent loss decay.As shown in Figure 3, GSO with this strategy is the only one that continues to progress toward better results, whereas others exhibit plateaued stagnation curves.</p>
<p>K.3 Is GSO still effective when dealing with high-dimensional data or extremely intricate optimization tasks?</p>
<p>Our experimental design includes both simple, lowdimensional ideal, and high-dimensional complex scientific optimization problems aimed at minimizing the sim-to-real gap to the greatest extent possible.This ensures that GSO generates meaningful and practical optimizations rather than questionable toys.We believe this is a strength rather than a weakness for GSO.Moreover, the success of GSO stems from the effective utilization of optimization feedback at each step and a dynamic exploration/exploitation strategy, which is domain-agnostic and can be applied to other domains.We also acknowledge that when the underlying physics of the opti-</p>
<p>Figure 1 :
1
Figure 1: GSO achieves state-of-the-art performance on a broad range of scientific optimization tasks compared with existing methods, using LLama 3 8B (Team, 2024b) as the backbone.Results of other five LLMs are in Figures 10 and 11.</p>
<p>Figure 1: GSO achieves state-of-the-art performance on a broad range of scientific optimization tasks compared with existing methods, using LLama 3 8B (Team, 2024b) as the backbone.Results of other five LLMs are in Figures 10 and 11.</p>
<p>Figure2: The overview of GSO.For a given optimization task, GSO iteratively conducts the inner-level optimization, outer-level optimization, and bi-level interaction sequentially.The workflow is as follows: (i) the inner-level simulator Φ conducts numerical simulations based on the current step's hypothetical solutions k (v 1 → v 2 → v 3 → v 4 → v 1) and returns observational feedback f k , L k (the edge (v 4 , v 1 ) has a larger distance than the edge (v 2 , v 4 ), current total distance: 108); (ii) the outer-level LLM M θ k generates new hypothetical solutions s k+1 (v 1 → v 2 → v 4 → v 3 → v 1 ) based on the observational feedback f k , L k ; (iii) the bi-level interaction jointly updates simulations in conjunction with the expert knowledge within the LLMs through model editing.</p>
<p>Figure 3 :
3
Figure 3: We visualize the average MSE loss values of each method for the non-linear Constitutive Law task (d) across five random seeds at the same optimization steps using Mistral 7B as the backbone model, with shading representing the standard deviation.</p>
<p>on p(o) Average indirect effect of a run of 10 Attn modules</p>
<p>Figure 4 :
4
Figure4: Causal tracing visualization results for Llama3 8B.The causal impact on output probability is mapped for (a) the effect of each hidden state on the prediction, (b) the effect of MLP activations alone, and (c) the effect of attention activations alone.We also give according to mean causal traces of over a sample of 1000 factual statements, shown as a line plot with 95% confidence intervals, which is below the first three figures.The confidence intervals confirm that the distinctions between peak and non-peak causal effects at both early and late sites are significant.</p>
<p>on p(o) Average indirect effect of a run of 10 Attn modules</p>
<p>on p(o) Average indirect effect of a run of 10 Attn modules</p>
<p>Figure 6 :
6
Figure6: Causal tracing visualization results for Llama2 13B.The causal impact on output probability is mapped for (a) the effect of each hidden state on the prediction, (b) the effect of MLP activations alone, and (c) the effect of attention activations alone.We also give according to mean causal traces of over a sample of 1000 factual statements, shown as a line plot with 95% confidence intervals, which is below the first three figures.The confidence intervals confirm that the distinctions between peak and non-peak causal effects at both early and late sites are significant.</p>
<p>on p(o) Average indirect effect of a run of 10 Attn modules</p>
<p>Figure 7 :
7
Figure7: Causal tracing visualization results for Yi 9B.The causal impact on output probability is mapped for (a) the effect of each hidden state on the prediction, (b) the effect of MLP activations alone, and (c) the of attention activations alone.We also give according to mean causal traces of over a sample of 1000 factual statements, shown as a line plot with 95% confidence intervals, which is below the first three figures.The confidence intervals confirm that the distinctions between peak and non-peak causal effects at both early and late sites are significant.</p>
<p>on p(o) Average indirect effect of a run of 10 Attn modules</p>
<p>Figure 8 :
8
Figure8: Causal tracing visualization results for Internlm 7B.The causal impact on output probability is mapped for (a) the effect of each hidden state on the prediction, (b) the effect of MLP activations alone, and (c) the effect of attention activations alone.We also give according to mean causal traces of over a sample of 1000 factual statements, shown as a line plot with 95% confidence intervals, which is below the first three figures.The confidence intervals confirm that the distinctions between peak and non-peak causal effects at both early and late sites are significant.</p>
<p>Figure 10 :
10
Figure10: GSO achieves state-of-the-art performance on a broad range of scientific optimization tasks compared with existing methods, using LLama 3 7B, GPT-J 6B, and Llama2 13B as backbone models, respectively.We linearly map the evaluation metrics to [0, 100] for presentation.</p>
<p>level Optimization Outer-level Optimization Bi-level Interaction k-th iter
𝒗 𝟏𝒗 𝟐Current Solution:𝒗 𝟏𝒗 𝟐𝒗 𝟒𝒗 𝟑𝑣 1 → 𝑣 2 → 𝑣 3→ 𝑣 4 → 𝑣 1𝒗 𝟒𝒗 𝟑Inner-𝒗 𝟏 𝒗 𝟐𝒗 𝟒𝒗 𝟑</p>
<p>Table 2 :
2
The results of the ablation study of our GSO on the seven scientific optimization tasks, using Llama3 8B as the backbone model (We provide more results for the other five backbone models, in Appendix G).
MethodLinear System Travel SalesmanConstitutive LawMolecule Property(a) ↓(b) ↓(c) ↓(d) ↓(e) ↓(f) ↓(g) ↓GSO w/o dynamic6.5 ± 3.50.0 ± 0.023.7 ± 9.976.9 ± 11.435.0 ± 17.145.0 ± 19.321.9 ± 7.3GSO5.1 ± 1.00.0 ± 0.08.1 ± 2.120.1 ± 3.930.1 ± 14.920.9 ± 9.39.7 ± 3.6FunsearchEurekaOPROSGAGSO (ours)Zoom In
GSO w/o edit 33.7 ± 10.1 0.7 ± 0.3 116.1 ± 30.1 141.5 ± 36.9 307.7 ± 31.4 331.2 ± 89.2 164.3 ± 38.9</p>
<p>Table 3 :
3
We evaluate our GSO against other baseline methods on five prompts that vary in format but are semantically similar, and report their average results of each method, using Mistral 7B as the representative backbone model.The symbol N/A indicates that the model cannot provide a feasible solution for the current task.
Linear System Travel SalesmanConstitutive LawMolecule PropertyBackbone Method(a) ↓(b) ↓(c) ↓(d) ↓(e) ↓(f) ↓(g) ↓Funsearch52.2 ± 29.42.4 ± 1.5411.0 ± 193.4 254.9 ± 109.3 473.3 ± 130.2 403.1 ± 135.0 173.0 ± 66.3Eureka60.25 ± 29.23.5 ± 2.6303.7 ± 180.3 179.0 ± 65.8219.0 ± 40.6287.9 ± 99.0 148.9 ± 55.0Mistral 7BOPRON/A0.4 ± 0.3107.6 ± 61.4224.8 ± 34.294.3 ± 50.6593.7 ± 266.8 40.5 ± 28.0SGA38.7 ± 20.30.3 ± 0.255.4 ± 43.9203.2 ± 22.3211.7 ± 98.073.0 ± 18.862.9 ± 33.2GSO (ours)8.3 ± 3.30.1 ± 0.05.5 ± 3.120.9 ± 8.318.8 ± 7.03.9 ± 2.12.2 ± 0.4</p>
<p>Table 4 :
4
Results of our GSO against popular closed-source LLMs, including GPT-4o and Claude-3.5.We present the results of our GSO Mistral 7B as the backbone model for comparison.
MethodLinear System Travel SalesmanConstitutive LawMolecule Property(a) ↓(b) ↓(c) ↓(d) ↓(e) ↓(f) ↓(g) ↓GPT-4o6.4 ± 1.50.2 ± 0.059.7 ± 7.445.5 ± 9.1 181.4 ± 33.7 313.5 ± 45.4 67.8 ± 10.9Claude-312.1 ± 2.00.2 ± 0.1128.1 ± 13.5 103.0 ± 5.2 162.3 ± 21.2 519.3 ± 37.4 37.8 ± 8.3GSO5.6 ± 3.00.1 ± 0.03.2 ± 1.713.0 ± 2.123.9 ± 5.12.8 ± 1.51.7 ± 0.4</p>
<p>Extensive experiments on six differ-ent open-source and seven different scientific tasks demonstrate the superiority of our GSO, delivering consistent, robust, generalizable, and nearly monotonic improvement.We view our GSO as a trailblazer, establishing a new paradigm for utilizing LLMs and simulations as bi-level optimization to further advancements in scientific optimizations.3
this paper, we propose a novel General ScientificOptimizers method, effectively enabling LLMs toutilize observational feedback from each optimiza-tion step. Specifically, GSO consists of a bi-leveloptimization framework: outer-level LLMs func-tion as knowledgeable and versatile scientists, gen-erating new hypotheses to optimize experimentalhyperparameters; inner-level simulations functionas experimental platforms to perform numericalsimulations to these hypotheses and provide obser-vational feedback; a bi-level interaction then updatethe simulators together with the expert knowledgewithin LLMs via model editing. GSO effectivelyguides LLMs to derive a more precise and stableoptimization direction, yielding superior optimiza-tion results.</p>
<p>Table 6 :
6
We consider an imaginary constitutive law setting to prevent the LLM from cheating by memorization and report the results using Mistral 7B as the representative backbone model.
mentioned LLMs in Figures 5, 6, 7, 8, and 9 toprovide a more comprehensive results.FunsearchEurekaOPROSGAGSO201.1 ± 39.0 291.0 ± 20.8 190.0 ± 10.3 59.7 ± 5.9 17.1 ± 4.0each hidden state variable. Specifically, whenrestoring hidden states from the original run, wesubstitute the values computed originally for thecorresponding layer and token, allowing subse-quent computations to proceed without furthermodification. Taking Llama3 8B as an example,as shown in Figure 4, we observe that the 18-22thlayers for the last subject token demonstrate themost causality in the AIE metric. Therefore, weuse the 18-22th MLP layers as the layers wheremodel edits are applied to update knowledge bymodifying the parameters. We also visualize other</p>
<p>Table 7 :
7
Prompt templates for each task.In the prompts, "str(Examples)" represents initial solutions for each task."str(Nodes)" and "str(Properties)" represent some basic properties of the materials/molecules.Linear System Regression You will help me minimize a function with two input variables w, b.I have some (w, b) pairs and the function values at those points.The pairs are arranged in descending order based on their function values, where lower values are better.Below are some examples: str(Examples) Give me a new (w, b) pair that is different from all pairs above, and has a function value lower than any of the examples.Travel Salesman Problem You are given a list of points with coordinates below: str(Nodes) Below are some previous traces and their lengths.The traces are arranged in descending order based on their lengths, where lower values are better: str(Traces) Give me a new trace that is different from all traces above, and has a length lower than any of the above.The trace should traverse all points exactly once.The trace should start with <trace> and end with </trace>.You are given a list of materials with corresponding properties below: str(Properties) Below are some previous stress-strain responses for each material, sorted in descending order based on compliance, where lower compliance values indicate better structural integrity: str(Examples) Provide a new constitutive law that differs from all the laws above, ensuring that it produces a compliance value lower than any of the existing responses.The constitutive law should describe the relationship between stress and strain accurately for the material and should start with <law> and end with </law>.You are given a list of molecules with their chemical properties below: str(Properties).Your goal is to predict the HOMO (can be adjusted to LUMO or HOMO-LUMO gap depending on different tasks) values for the listed molecules.Below are some examples: str(Examples)
Optimization TasksPrompt Templates
https://openai.com/o1/
https://www.anthropic.com/news/claude-3-5-sonnet
AcknowledgementsThe authors would like to thank all the anonymous reviewers for their insightful comments.The causal impact on output probability is mapped for (a) the effect of each hidden state on the prediction, (b) the effect of MLP activations alone, and (c) the effect of attention activations alone.We also give according to mean causal traces of over a sample of 1000 factual statements, shown as a line plot with 95% confidence intervals, which is below the first three figures.The confidence intervals confirm that the distinctions between peak and non-peak causal effects at both early and late sites are significant.Figure11: GSO achieves state-of-the-art performance on a broad range of scientific optimization tasks compared with existing methods, using Yi 9B, Internlm 7B, and Mistral 7B as backbone models, respectively.We linearly map the evaluation metrics to [0, 100] for presentation.mization problem is too complex, this represents a limitation of our approach.A potential extension could focus on data compression by pre-training an auto-encoder to project high-dimensional data into a latent space.K.4 What is the difference between updating LLM parameters using model editing and employing methods like fine-tuning?The differences are two-folds:(i) the key difference lies in their scope and flexibility.Fine-tuning typically involves adjusting a large portion of the model's parameters over a dataset, often requiring extensive computational resources and time(Hu et al., 2021;Zhu et al., 2020), and it can result in overfitting or catastrophic forgetting of prior knowledge(Luo et al., 2023).Model editing is a more targeted approach, allowing for precise modifications to specific parts of the model in response to new information or tasks without altering the broader knowledge encoded within the model.(ii) Another difference is its efficiency; it enables rapid updates to the model without the need for extensive retraining.This makes it particularly suitable for dynamic optimization tasks where quick adjustments are necessary.Moreover, model editing preserves the generalization abilities of the LLM while fine-tuning may risk degrading its performance on unrelated tasks.In this sense, model editing offers a more controlled and adaptive method for refining LLM behavior, especially in domain-agnostic and task-agnostic scenarios, making it an ideal tool for iterative optimization processes.Optimization Tasks Augmented PromptsLinear System Regression (i) Travel Salesman Problem (i) Given the coordinates of points: str(Nodes).Here are some previous routes and their lengths, sorted from longest to shortest (shorter is better).Give me a new trace that is different from all traces above, and has a length lower than any of the above.The trace should traverse all points exactly once.The trace should start with <trace> and end with </trace>.(ii) Consider the following points with coordinates: str(Nodes).Generate a new trace that differs from all previous traces and is shorter than any of them.Ensure that this trace covers each point exactly once, begins with <trace>, and ends with </trace>.(iii) You have a set of points at these coordinates below: str(Nodes).Please provide a unique trace that is distinct from all preceding traces and has a length shorter than any of the prior traces.This trace should start with <trace> and conclude with </trace>, while visiting each point one time.(iv) Here are points with their coordinates: str(Nodes).Please craft a new trace that is unique from all previous traces and shorter in length than any listed above.This trace should traverse all points a single time, beginning with <trace> and ending with </trace>.(v) You are provided with points with their coordinates: str(Nodes).Produce a trace that does not resemble any of the existing traces and has a length less than the shortest one listed.It should begin with <trace>, finish with </trace>, and cover each point exactly once.Table13: The results of the ablation study of our GSO on the seven scientific optimization tasks, using Yi 9B as the backbone model.GSO (ours) 3.0 ± 0.8 0.0 ± 0.0 5.9 ± 2.1 89.1 ± 33.9 67.9 ± 23.1 172.9 ± 43.1 5.5 ± 2.1Method Linear System Travel SalesmanTable14: The results of the ablation study of our GSO on the seven scientific optimization tasks, using Internlm 7B as the backbone model.Table15: The results of the ablation study of our GSO on the seven scientific optimization tasks, using mistral 7B as the backbone model.Method
The Theory of Parsing, Translation and Compiling. Alfred V Aho, Jeffrey D Ullman, 1972Prentice-Hall1Englewood Cliffs, NJ</p>
<p>arXiv:2311.07361Microsoft Research AI4Science and Microsoft Azure Quantum. 2023. The impact of large language models on scientific discovery: a preliminary study using gpt-4. arXiv preprint</p>
<p>Backpropagation and stochastic gradient descent method. Shun-Ichi Amari, Neurocomputing. 54-51993</p>
<p>Publications Manual. 1983American Psychological AssociationWashington, DC</p>
<p>A simple neural network generating an interactive memory. Anderson James, Mathematical biosciences. 143-41972</p>
<p>A framework for learning predictive structures from multiple tasks and unlabeled data. Journal of Machine Learning Research. 62005More discussions on GSO are in Appendix K. Rie Kubota Ando and Tong Zhang</p>
<p>Scalable training of L1-regularized log-linear models. Galen Andrew, Jianfeng Gao, Proceedings of the 24th International Conference on Machine Learning. the 24th International Conference on Machine Learning2007</p>
<p>Rewriting a deep generative model. David Bau, Steven Liu, Tongzhou Wang, Jun-Yan Zhu, Antonio Torralba, Computer Vision-ECCV 2020: 16th European Conference. Glasgow, UKSpringer2020. August 23-28, 2020Proceedings, Part I 16</p>
<p>Scaling learning algorithms towards AI. Yoshua Bengio, Yann Lecun, Large Scale Kernel Machines. MIT Press2007</p>
<p>Autonomous chemical research with large language models. Robert Daniil A Boiko, Ben Macknight, Gabe Kline, Gomes, Nature. 62479922023</p>
<p>Language models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Advances in neural information processing systems. 202033</p>
<p>. K Ashok, Dexter C Chandra, Larry J Kozen, Stockmeyer, 10.1145/322234.322243Alternation. Journal of the Association for Computing Machinery. 2811981</p>
<p>Evoprompting: language models for code-level neural architecture search. Angelica Chen, David Dohan, David So, Advances in Neural Information Processing Systems. 2024a36</p>
<p>Jia-Chen Gu, Hao-Xiang Xu, Jun-Yu Ma, Pan Lu, Zhen-Hua Ling, Kai-Wei Chang, Nanyun Peng, arXiv:2401.04700Model editing can hurt general abilities of large language models. 2024arXiv preprint</p>
<p>Finding neurons in a haystack: Case studies with sparse probing. Wes Gurnee, Neel Nanda, Matthew Pauly, Katherine Harvey, Dmitrii Troitskii, Dimitris Bertsimas, Transactions on Machine Learning Research. </p>
<p>Gurobi Optimization, LLC. 2024. Gurobi Optimizer Reference Manual. </p>
<p>The traveling salesman problem and its variations. Dan Gusfield, ; Gregory Gutin, Abraham P Punnen, Algorithms on Strings, Trees and Sequences. Cambridge, UKSpringer Science &amp; Business Media1997. 200612</p>
<p>Retrieval augmented language model pre-training. Kelvin Guu, Kenton Lee, Zora Tung, International conference on machine learning. PMLR2020Panupong Pasupat, and Mingwei Chang</p>
<p>How does gpt-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model. Michael Hanna, Ollie Liu, Alexandre Variengien, Advances in Neural Information Processing Systems. 202436</p>
<p>Bertnet: Harvesting knowledge graphs with arbitrary relations from pretrained language models. Shibo Hao, Bowen Tan, Kaiwen Tang, Bin Ni, Xiyan Shao, Hengzhe Zhang, Eric Xing, Zhiting Hu, Findings of the Association for Computational Linguistics: ACL 2023. 2023</p>
<p>Aging with grace: Lifelong model editing with discrete key-value adaptors. Tom Hartvigsen, Swami Sankaranarayanan, Hamid Palangi, Yoon Kim, Marzyeh Ghassemi, Advances in Neural Information Processing Systems. 202436</p>
<p>An extension of the linkernighan-helsgaun tsp solver for constrained traveling salesman and vehicle routing problems. Keld Helsgaun, 201712RoskildeRoskilde University</p>
<p>A fast learning algorithm for deep belief nets. Geoffrey E Hinton, Simon Osindero, Yee Whye Teh, Neural Computation. 182006</p>
<p>Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes. Cheng-Yu Hsieh, Chun-Liang Li, Chih-Kuan Yeh, Hootan Nakhost, Yasuhisa Fujii, Alexander Ratner, Ranjay Krishna, Chen-Yu Lee, Tomas Pfister, arXiv:2305.023012023arXiv preprint</p>
<p>J Edward, Yelong Hu, Phillip Shen, Zeyuan Wallis, Yuanzhi Allen-Zhu, Shean Li, Lu Wang, Weizhu Wang, Chen, arXiv:2106.09685Lora: Low-rank adaptation of large language models. 2021arXiv preprint</p>
<p>Mathematical optimization and economic theory. Michael D Intriligator, 2002SIAM</p>
<p>Alexandre Albert Q Jiang, Arthur Sablayrolles, Chris Mensch, Devendra Bamford, Diego Singh Chaplot, Florian De Las Casas, Gianna Bressand, Guillaume Lengyel, Lucile Lample, Saulnier, arXiv:2310.06825Mistral 7b. 2023arXiv preprint</p>
<p>The material point method for simulating continuum materials. Chenfanfu Jiang, Craig Schroeder, Joseph Teran, Alexey Stomakhin, Andrew Selle, Acm siggraph 2016 courses. 2016</p>
<p>The traveling salesman problem. Handbooks in operations research and management science. Michael Jünger, Gerhard Reinelt, Giovanni Rinaldi, 19957</p>
<p>Bert: Pre-training of deep bidirectional transformers for language understanding. Proceedings of naacL-HLT. Jacob Devlin, Ming-Wei Chang, Kenton , Lee Kristina, Toutanova , naacL-HLTMinnesota20191Minneapolis</p>
<p>Advances in Neural Information Processing Systems, 36. Teuvo Kohonen. 1972. Correlation matrix memories. Geunwoo Kim, Pierre Baldi, Stephen Mcaleer, IEEE transactions on computers. 10042024Language models can solve computer tasks</p>
<p>Large language models are zero-shot reasoners. Takeshi Kojima, Shane Shixiang, Machel Gu, Yutaka Reid, Yusuke Matsuo, Iwasawa, Advances in neural information processing systems. 202235</p>
<p>Wouter Kool, Herke Van Hoof, Max Welling, arXiv:1803.08475Attention, learn to solve routing problems!. 2018arXiv preprint</p>
<p>Evolution through large models. Joel Lehman, Jonathan Gordon, Shawn Jain, Kamal Ndousse, Cathy Yeh, Kenneth O Stanley, arXiv:2206.088962022Preprint</p>
<p>Fast inference from transformers via speculative decoding. Yaniv Leviathan, Matan Kalman, Yossi Matias, International Conference on Machine Learning. PMLR2023</p>
<p>Empowering molecule discovery for molecule-caption translation with large language models: A chatgpt perspective. Jiatong Li, Yunqing Liu, Wenqi Fan, Xiao-Yong Wei, Hui Liu, Jiliang Tang, Qing Li, IEEE Transactions on Knowledge and Data Engineering. 2024a</p>
<p>Chemvlm: Exploring the power of multimodal large language models in chemistry area. Junxian Li, Di Zhang, Xunzhi Wang, Zeying Hao, Jingdi Lei, Qian Tan, Cai Zhou, Wei Liu, Yaotian Yang, Xinrui Xiong, Weiyun Wang, Zhe Chen, Wenhai Wang, Wei Li, Shufei Zhang, Mao Su, Wanli Ouyang, Yuqiang Li, Dongzhan Zhou, arXiv:2408.072462024bPreprint</p>
<p>Chemvlm: Exploring the power of multimodal large language models in chemistry area. Junxian Li, Di Zhang, Xunzhi Wang, Zeying Hao, Jingdi Lei, Qian Tan, Cai Zhou, Wei Liu, Yaotian Yang, Xinrui Xiong, Weiyun Wang, Zhe Chen, Wenhai Wang, Wei Li, Shufei Zhang, Mao Su, Wanli Ouyang, Yuqiang Li, Dongzhan Zhou, arXiv:2408.072462024cPreprint</p>
<p>Lost in the middle: How language models use long contexts. Kevin Nelson F Liu, John Lin, Ashwin Hewitt, Michele Paranjape, Fabio Bevilacqua, Percy Petroni, Liang, Transactions of the Association for Computational Linguistics. 112024a</p>
<p>Parallel speculative decoding with adaptive draft length. Tianyu Liu, Yun Li, Qitan Lv, Kai Liu, Jianchen Zhu, Winston Hu, arXiv:2408.118502024bPreprint</p>
<p>Learning rule-induced subgraph representations for inductive relation prediction. Tianyu Liu, Qitan Lv, Jie Wang, Shuling Yang, Hanzhu Chen, Advances in Neural Information Processing Systems. 2024c36</p>
<p>Roberta: A robustly optimized bert pretraining approach. Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov, arXiv:1907.116922019Preprint</p>
<p>Ai-based language models powering drug discovery and development. Zhichao Liu, Ruth A Roberts, Madhu Lal-Nag, Xi Chen, Ruili Huang, Weida Tong, Drug Discovery Today. 26112021</p>
<p>Fantastically ordered prompts and where to find them: Overcoming fewshot prompt order sensitivity. Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, Pontus Stenetorp, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 60th Annual Meeting of the Association for Computational Linguistics20221</p>
<p>An empirical study of catastrophic forgetting in large language models during continual fine-tuning. Yun Luo, Zhen Yang, Fandong Meng, Yafu Li, Jie Zhou, Yue Zhang, arXiv:2308.087472023arXiv preprint</p>
<p>Coarse-to-fine highlighting: Reducing knowledge hallucination in large language models. Qitan Lv, Jie Wang, Hanzhu Chen, Bin Li, Yongdong Zhang, Feng Wu, Forty-first International Conference on Machine Learning. 2024</p>
<p>Jun-Yu Ma, Zhen-Hua Ling, Ningyu Zhang, Jia-Chen Gu, arXiv:2401.17623Neighboring perturbations of knowledge editing on large language models. 2024aarXiv preprint</p>
<p>Jun-Yu Ma, Hong Wang, Hao-Xiang Xu, Zhen-Hua Ling, Jia-Chen Gu, arXiv:2405.16821Perturbationrestrained sequential model editing. 2024barXiv preprint</p>
<p>Learning neural constitutive laws from motion observations for generalizable pde dynamics. Pingchuan Ma, Bolei Peter Yichen Chen, Joshua B Deng, Tao Tenenbaum, Chuang Du, Wojciech Gan, Matusik, International Conference on Machine Learning. PMLR2023a</p>
<p>Pingchuan Ma, Tsun-Hsuan Wang, Minghao Guo, Zhiqing Sun, Joshua B Tenenbaum, Daniela Rus, Chuang Gan, Wojciech Matusik, arXiv:2405.09783Llm and simulation as bilevel optimizers: A new paradigm to advance physical scientific discovery. 2024carXiv preprint</p>
<p>Let's do a thought experiment: Using counterfactuals to improve moral reasoning. Xiao Ma, Swaroop Mishra, Ahmad Beirami, Alex Beutel, Jilin Chen, arXiv:2306.143082023barXiv preprint</p>
<p>Eureka: Human-level reward design via coding large language models. Jason Yecheng, William Ma, Guanzhi Liang, De-An Wang, Osbert Huang, Dinesh Bastani, Yuke Jayaraman, Linxi Zhu, Anima Fan, Anandkumar, The Twelfth International Conference on Learning Representations. 2023c</p>
<p>Self-refine: Iterative refinement with self-feedback. Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, arXiv:2209.07686Advances in Neural Information Processing Systems, 36. Aman Madaan and Amir Yazdanbakhsh. 2022. Text and patterns: For effective chain of thought, it takes two to tango. 2024arXiv preprint</p>
<p>Locating and editing factual associations in gpt. Kevin Meng, David Bau, Alex Andonian, Yonatan Belinkov, Advances in Neural Information Processing Systems. 202235</p>
<p>Mass-editing memory in a transformer. Kevin Meng, Sen Arnab, Alex J Sharma, Yonatan Andonian, David Belinkov, Bau, The Eleventh International Conference on Learning Representations. </p>
<p>Language model crossover: Variation through few-shot prompting. Elliot Meyerson, Mark J Nelson, Herbie Bradley, Adam Gaier, Arash Moradi, Amy K Hoover, Joel Lehman, arXiv:2302.121702023aarXiv preprint</p>
<p>Language model crossover: Variation through few-shot prompting. Elliot Meyerson, Mark J Nelson, Herbie Bradley, Adam Gaier, Arash Moradi, Amy K Hoover, Joel Lehman, arXiv:2302.121702023barXiv preprint</p>
<p>Fast model editing at scale. Eric Mitchell, Charles Lin, Antoine Bosselut, Chelsea Finn, Christopher D Manning, International Conference on Learning Representations. </p>
<p>Memorybased model editing at scale. Eric Mitchell, Charles Lin, Antoine Bosselut, Christopher D Manning, Chelsea Finn, International Conference on Machine Learning. PMLR2022</p>
<p>. Douglas C Montgomery, Elizabeth A Peck, Geoffrey G Vining, 2021WileyIntroduction to Linear Regression Analysis. 6th edition edition</p>
<p>Varun Nair, Elliot Schumacher, Geoffrey Tso, Anitha Kannan, arXiv:2303.17071Dera: enhancing large language model completions with dialog-enabled resolving agents. 2023arXiv preprint</p>
<p>Reinforcement learning for solving the vehicle routing problem. Advances in neural information processing systems. Mohammadreza Nazari, Afshin Oroojlooy, Lawrence Snyder, Martin Takác, 201831</p>
<p>Causality: models, reasoning, and inference, by judea pearl, cambridge university press. Leland Gerson, Neuberg , Econometric Theory. 1942003. 2000</p>
<p>Demystifying gpt self-repair for code generation. Jeevana Theo X Olausson, Chenglong Priya Inala, Jianfeng Wang, Armando Gao, Solar-Lezama, arXiv:2306.098962023arXiv preprint</p>
<p>Chatgpt: A large-scale generative model for conversation. 2020OpenAI</p>
<p>arXiv:2303.08774Gpt-4 technical report. 2023OpenAIPreprint</p>
<p>The logic of scientific discovery. Karl Popper, 2005Routledge</p>
<p>Improving language understanding by generative pre-training. Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, 2018</p>
<p>Language models are unsupervised multitask learners. Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, OpenAI blog. 1892019</p>
<p>Quantum chemistry structures and properties of 134 kilo molecules. Raghunathan Ramakrishnan, Matthias Pavlo O Dral, O Rupp, Von Anatole, Lilienfeld, Scientific data. 112014</p>
<p>Mohammad Sadegh Rasooli, Joel R Tetreault, arXiv:1503.06733Yara parser: A fast and accurate dependency parser. Computing Research Repository. 20152</p>
<p>Mathematical discoveries from program search with large language models. Bernardino Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov, Matej Balog, Pawan Kumar, Emilien Dupont, Francisco Jr Ruiz, Jordan S Ellenberg, Pengming Wang, Omar Fawzi, Nature. 62579952024a</p>
<p>Mathematical discoveries from program search with large language models. Bernardino Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov, Matej Balog, Pawan Kumar, Emilien Dupont, Francisco Jr Ruiz, Jordan S Ellenberg, Pengming Wang, Omar Fawzi, Nature. 62579952024b</p>
<p>Mathematical discoveries from program search with large language models. Bernardino Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov, Matej Balog, Pawan Kumar, Emilien Dupont, Francisco Jr Ruiz, Jordan S Ellenberg, Pengming Wang, Omar Fawzi, Nature. 62579952024c</p>
<p>An analysis of several heuristics for the traveling salesman problem. Richard E Daniel J Rosenkrantz, Philip M Stearns, I I Lewis, SIAM journal on computing. 631977</p>
<p>Linear Regression Analysis. A F George, Alan J Seber, Lee, 2012Wiley2nd edition edition</p>
<p>Gaurav Sharma, Abhishek Thakur, Chatgpt in drug discovery. 2023</p>
<p>Large language models can be easily distracted by irrelevant context. Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, Ed H Chi, Nathanael Schärli, Denny Zhou, International Conference on Machine Learning. PMLR2023</p>
<p>Reflexion: an autonomous agent with dynamic memory and self-reflection. Noah Shinn, Beck Labash, Ashwin Gopinath, arXiv:2303.11366202329arXiv preprint</p>
<p>Megatron-lm: Training multibillion parameter language models using model parallelism. Mohammad Shoeybi, Md Mostofaali Patwary, Raul Puri, Patrick Legresley, Jared Casper, Bryan Catanzaro, 2019Cornell University -arXiv,Cornell University -arXiv</p>
<p>Application of a particle-in-cell method to solid mechanics. Deborah Sulsky, Shi-Jian, Howard L Zhou, Schreyer, Computer physics communications. 871-21995</p>
<p>Cognitive architectures for language agents. Theodore Sumers, Shunyu Yao, Karthik Narasimhan, Thomas Griffiths, Transactions on Machine Learning Research. </p>
<p>Anthropic Team. 2024a. The claude 3 model family: Opus, sonnet, haiku. </p>
<p>Gemini: A family of highly capable multimodal models. Gemini Team, arXiv:2312.118052023aPreprint</p>
<p>Internlm: A multilingual language model with progressively enhanced capabilities. Internlm Team, 2023b</p>
<p>Llama 2: Open foundation and fine-tuned chat models. arXiv:2307.09288arXiv:2407.21783Llama3 Team. 2024b. The llama 3 herd of models. 2023carXiv preprint</p>
<p>Palm: Scaling language modeling with pathways. arXiv:2204.02311Preprint</p>
<p>Solving olympiad geometry without human demonstrations. Yuhuai Trieu H Trinh, Wu, He Quoc V Le, Thang He, Luong, Nature. 62579952024</p>
<p>Ai feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity. Silviu-Marian, Andrew Udrescu, Jiahai Tan, Orisvaldo Feng, Tailin Neto, Max Wu, Tegmark, Advances in Neural Information Processing Systems. 202033</p>
<p>Linxi Fan, and Anima Anandkumar. 2023a. Voyager: An open-ended embodied agent with large language models. Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, arXiv:2305.16291arXiv preprint</p>
<p>Scientific discovery in the age of artificial intelligence. Hanchen Wang, Tianfan Fu, Yuanqi Du, Wenhao Gao, Kexin Huang, Ziming Liu, Payal Chandak, Shengchao Liu, Peter Van Katwyk, Andreea Deac, Nature. 62079722023b</p>
<p>Bitnet: Scaling 1-bit transformers for large language models. Hongyu Wang, Shuming Ma, Li Dong, Shaohan Huang, Huaijie Wang, Lingxiao Ma, Fan Yang, Ruiping Wang, Yi Wu, Furu Wei, arXiv:2310.114532023carXiv preprint</p>
<p>Interpretability in the wild: a circuit for indirect object identification in gpt-2 small. Kevin Ro, Wang , Alexandre Variengien, Arthur Conmy, Buck Shlegeris, Jacob Steinhardt, The Eleventh International Conference on Learning Representations. </p>
<p>Chain-of-thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Denny Quoc V Le, Zhou, Advances in neural information processing systems. 202235</p>
<p>Larger language models do in-context learning differently. Jerry Wei, Jason Wei, Yi Tay, Dustin Tran, Albert Webson, Yifeng Lu, Xinyun Chen, Hanxiao Liu, Da Huang, Denny Zhou, arXiv:2303.038462023arXiv preprint</p>
<p>A typology of scientific breakthroughs. Mignon Wuestman, Jarno Hoekman, Koen Frenken, Quantitative Science Studies. 132020</p>
<p>Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V Le, Denny Zhou, Xinyun Chen, Large language models as optimizers. 2023</p>
<p>Yi: Open foundation models by 01. Alex Young, Bei Chen, Chao Li, Chengen Huang, Ge Zhang, Guanwei Zhang, Heng Li, Jiangcheng Zhu, Jianqun Chen, Jing Chang, arXiv:2403.046522024arXiv preprint</p>
<p>Melo: Enhancing model editing with neuron-indexed dynamic lora. Lang Yu, Qin Chen, Jie Zhou, Liang He, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202438</p>
<p>Exploring the residual stream of transformers. Zeping Yu, Kailai Yang, Zhiwei Liu, Sophia Ananiadou, arXiv:2312.121412023arXiv preprint</p>
<p>System-level natural language feedback. Weizhe Yuan, Kyunghyun Cho, Jason Weston, Proceedings of the 18th Conference of the European Chapter. Long Papers. the 18th Conference of the European Chapterthe Association for Computational Linguistics2024</p>
<p>Di Zhang, Wei Liu, Qian Tan, Jingdan Chen, Hang Yan, Yuliang Yan, Jiatong Li, Weiran Huang, Xiangyu Yue, Dongzhan Zhou, arXiv:2402.06852Chemllm: A chemical large language model. 2024aarXiv preprint</p>
<p>Towards building specialized generalist ai with system 1 and system 2 fusion. Kaiyan Zhang, Biqing Qi, Bowen Zhou, arXiv:2407.086422024barXiv preprint</p>
<p>Ningyu Zhang, Yunzhi Yao, Bozhong Tian, Peng Wang, Shumin Deng, Mengru Wang, Zekun Xi, Shengyu Mao, Jintian Zhang, Yuansheng Ni, arXiv:2401.01286A comprehensive study of knowledge editing for large language models. 2024carXiv preprint</p>
<p>Autonomous generalist scientist: Towards and beyond human-level automatic research using foundation model-based ai agents and robots. Starkson Zhang, Alfredo Pearson, Zhenting Wang, a position</p>
<p>Atom: Lowbit quantization for efficient and accurate llm serving. Yilong Zhao, Chien-Yu Lin, Kan Zhu, Zihao Ye, Lequn Chen, Size Zheng, Luis Ceze, Arvind Krishnamurthy, Tianqi Chen, Baris Kasikci, Proceedings of Machine Learning and Systems. Machine Learning and Systems20246</p>
<p>Sglang: Efficient execution of structured language model programs. Lianmin Zheng, Liangsheng Yin, Zhiqiang Xie, Chuyue Sun, Jeff Huang, Cody Hao Yu, Shiyi Cao, Christos Kozyrakis, Ion Stoica, Joseph E Gonzalez, 2023</p>
<p>Zexuan Zhong, Zhengxuan Wu, Christopher D Manning, Christopher Potts, Danqi Chen, arXiv:2305.14795Mquake: Assessing knowledge editing in language models via multi-hop questions. 2023arXiv preprint</p>
<p>Large language models are human-level prompt engineers. Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, Jimmy Ba, The Eleventh International Conference on Learning Representations. </p>
<p>Chen Zhu, Ankit Singh Rawat, Manzil Zaheer, Srinadh Bhojanapalli, Daliang Li, Felix Yu, Sanjiv Kumar, arXiv:2012.00363Modifying memories in transformer models. 2020arXiv preprint</p>
<p>Xunyu Zhu, Jian Li, Yong Liu, Can Ma, Weiping Wang, arXiv:2308.07633A survey on model compression for large language models. 2023arXiv preprint</p>
<p>Meta-Llama-3-8B-Instruct 5. </p>            </div>
        </div>

    </div>
</body>
</html>