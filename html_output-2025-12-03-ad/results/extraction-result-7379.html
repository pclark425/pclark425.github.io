<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7379 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7379</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7379</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-139.html">extraction-schema-139</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <p><strong>Paper ID:</strong> paper-268819532</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2404.01135v1.pdf" target="_blank">Enhancing Reasoning Capacity of SLM Using Cognitive Enhancement</a></p>
                <p><strong>Paper Abstract:</strong> Large Language Models (LLMs) have been applied to automate cyber security activities and processes including cyber investigation and digital forensics. However, the use of such models for cyber investigation and digital forensics should address accountability and security considerations. Accountability ensures models have the means to provide explainable reasonings and outcomes. This information can be extracted through explicit prompt requests. For security considerations, it is crucial to address privacy and confidentiality of the involved data during data processing as well. One approach to deal with this consideration is to have the data processed locally using a local instance of the model. Due to limitations of locally available resources, namely memory and GPU capacities, a Smaller Large Language Model (SLM) will typically be used. These SLMs have significantly fewer parameters compared to the LLMs. However, such size reductions have notable performance reduction, especially when tasked to provide reasoning explanations. In this paper, we aim to mitigate performance reduction through the integration of cognitive strategies that humans use for problem-solving. We term this as cognitive enhancement through prompts. Our experiments showed significant improvement gains of the SLMs' performances when such enhancements were applied. We believe that our exploration study paves the way for further investigation into the use of cognitive enhancement to optimize SLM for cyber security applications.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7379.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7379.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SLM-RAG-TaskDecomp</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Retrieval-Augmented Generation with Smaller Language Models and Prompt-based Task Decomposition (Explain/Decide/Reflect)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>This paper's core experiment: use of quantized smaller LLMs (LLaMA 2 and Vicuna variants) with a Retrieval-Augmented Generation pipeline and prompt-level cognitive enhancements (task decomposition into Explain, Decide, then Self-Reflection sequences) to detect anomalies in log-entry datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMa 2 (LLaMa 2 7B, LLaMa 2 13B), Vicuna (7B, 13B)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Decoder-only transformer language models; LLaMa 2 models are instruction-tuned (SFT + RLHF) and Vicuna models are fine-tuned from LLaMa 2 on conversational data; quantized GGUF Q4_K_M format for local inference using llama.cpp.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B, 13B</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Retrieval-Augmented Generation (RAG): embed incoming log entry, retrieve similar normal log entries from a vector DB populated with clustered normal samples, then run a prompt-based classification/reasoning query on the SLM; apply prompt-level task decomposition (Explain and Decide as combined or as sequential Explain -> Decide) and a Self-Reflection step.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td>Example prompts used (two variants shown): "You are a system admin. Consider this log entry… <query: log entry> Question: Does the log entry indicate normalcy or not ?Explain your analysis and answer True if normal otherwise answer False." (and a similar variant where "Explain" and "Answer" are requested explicitly). Experimental conditions also used decomposed sequences: [{E,D}+R], [{D,E}+R], [E+D+R], [D+E+R] where E=Explain, D=Decide, R=Reflect.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>log entries (textual time-series / event logs)</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>BGL; Thunderbird</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Precision, Recall, F1 (defined in paper as standard binary classification metrics)</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Paper reports significant improvements in F1 when task decomposition (Explain -> Decide -> Reflect) was applied for many model/condition combinations; no numeric scores are provided in the text. It also reports some cases where task decomposition reduced performance (LLaMa 2 7B with [E+D+R] and LLaMa 2 13B with [D+E+R]).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Qualitative comparison to prior RAGLog (GPT-3.5) and other LLM log-analysis approaches discussed in Related Work; no numeric baseline scores reported in this paper for direct comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Zero-shot style classification via RAG (no fine-tuning; retrieval supplies exemplars of normal logs to the prompt rather than few-shot in-prompt examples).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Authors report: imbalanced anomaly labels in datasets; SLMs have weaker multi-step reasoning leading to poorer outcomes unless aided by task decomposition; task decomposition sometimes reduces performance for specific model/sequence combinations; sequence order (Explain vs Decide first) did not show significant effect overall; prompts may need further tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Models were quantized (GGUF Q4_K_M) and run locally due to resource constraints; exact GPU hours, latency, or token-costs not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Enhancing Reasoning Capacity of SLM Using Cognitive Enhancement', 'publication_date_yy_mm': '2025-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7379.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7379.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RAGLog (prior)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RAGLog: Log Anomaly Detection using Retrieval Augmented Generation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Authors' prior work applying Retrieval-Augmented Generation with GPT-3.5 to log anomaly detection using a vector DB of selected normal log entries and zero-shot classification.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>RAGLog: Log Anomaly Detection using Retrieval Augmented Generation.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI chat/completion style large language model (instruction-tuned), used as the generative component in a RAG pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Retrieval-Augmented Generation: embed query log, retrieve closest normal examples, and query the LLM to classify/analyze the entry (zero-shot).</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td>Question-and-Answer template used in a RAG pipeline to ask the model whether a log entry is normal or anomalous, providing retrieved normal log examples as context.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>log entries</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Precision, Recall, F1 implied (paper states it performed relatively well for a zero-shot classifier)</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Described as performing relatively well as a zero-shot classifier in prior work; no numeric values provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Zero-shot (RAG)</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Prior RAGLog used an online LLM (privacy concerns for sensitive data) — motivating local SLM experiments in the present paper.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Enhancing Reasoning Capacity of SLM Using Cognitive Enhancement', 'publication_date_yy_mm': '2025-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7379.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7379.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LogGPT / ChatGPT (Qi et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced study that applied ChatGPT to log-based anomaly detection exploring different prompt constructs, input window sizes and input sequences; highlighted sensitivity to prompt and window-size and reported high false positive rates.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI conversational/instruction-tuned LLM (specific model version not specified in the mention).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Prompting ChatGPT with various prompt templates and windowing of log input sequences to classify anomalies.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>log entries</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Paper mention: observed high false positive rates; specific metrics not quoted in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Reported sensitivity to prompt formulation and window size; high false positive rate noted (no numeric values provided here).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Zero-shot prompting (varied prompts/windows)</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>High false positive rates and non-trivial dependence on prompt and window-size selection.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Enhancing Reasoning Capacity of SLM Using Cognitive Enhancement', 'publication_date_yy_mm': '2025-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7379.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e7379.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mudgal et al. (ChatGPT for log parsing)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>An Assessment of ChatGPT on Log Data</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Referenced work that designed specific prompts with ChatGPT for log parsing and achieved excellent parsing performance but noted limitations of LLMs for other log-analysis tasks (anomaly detection, summarization).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>An Assessment of ChatGPT on Log Data.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI conversational LLM (used for prompt-based log parsing experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Prompt engineering for log parsing (not primarily anomaly classification); evaluated other log tasks where limitations appeared.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>log entries</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Excellent performance on log parsing tasks per the referenced study; limitations when applied to anomaly detection and summarization noted (no numeric values provided here).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Prompt-based (zero-shot/in-context prompting implied)</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Limitations observed in anomaly detection and log summarization despite strong parsing performance.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Enhancing Reasoning Capacity of SLM Using Cognitive Enhancement', 'publication_date_yy_mm': '2025-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7379.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e7379.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LogPrompt (Liu et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LogPrompt: Prompt Engineering Towards Zero-Shot and Interpretable Log Analysis</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Referenced study that tested prompt-engineered methods (self-prompt, Chain-of-Thought, In-context) in zero-shot scenarios for log analysis; reported promise but very low precision for some tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>LogPrompt: Prompt Engineering Towards Zero-Shot and Interpretable Log Analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLMs (unspecified in this paper's mention)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Prompted LLMs evaluated under different prompting formats (self-prompt, CoT, in-context).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Zero-shot prompting with different prompt formats and varying numbers of provided log samples (not fine-tuning).</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td>Variants including self-prompt, Chain-of-Thought prompts, and in-context examples as tested in zero-shot setups.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>log entries</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Precision noted specifically as very low in zero-shot tests per the mention in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Promising overall but very low precision scores for anomaly detection tasks (no numeric values included in this paper's discussion).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Zero-shot (with prompt variations and varying provided samples)</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Very low precision in zero-shot log anomaly detection despite promising overall behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Enhancing Reasoning Capacity of SLM Using Cognitive Enhancement', 'publication_date_yy_mm': '2025-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection <em>(Rating: 2)</em></li>
                <li>LogPrompt: Prompt Engineering Towards Zero-Shot and Interpretable Log Analysis <em>(Rating: 2)</em></li>
                <li>RAGLog: Log Anomaly Detection using Retrieval Augmented Generation. <em>(Rating: 2)</em></li>
                <li>An Assessment of ChatGPT on Log Data. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7379",
    "paper_id": "paper-268819532",
    "extraction_schema_id": "extraction-schema-139",
    "extracted_data": [
        {
            "name_short": "SLM-RAG-TaskDecomp",
            "name_full": "Retrieval-Augmented Generation with Smaller Language Models and Prompt-based Task Decomposition (Explain/Decide/Reflect)",
            "brief_description": "This paper's core experiment: use of quantized smaller LLMs (LLaMA 2 and Vicuna variants) with a Retrieval-Augmented Generation pipeline and prompt-level cognitive enhancements (task decomposition into Explain, Decide, then Self-Reflection sequences) to detect anomalies in log-entry datasets.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "LLaMa 2 (LLaMa 2 7B, LLaMa 2 13B), Vicuna (7B, 13B)",
            "model_description": "Decoder-only transformer language models; LLaMa 2 models are instruction-tuned (SFT + RLHF) and Vicuna models are fine-tuned from LLaMa 2 on conversational data; quantized GGUF Q4_K_M format for local inference using llama.cpp.",
            "model_size": "7B, 13B",
            "anomaly_detection_approach": "Retrieval-Augmented Generation (RAG): embed incoming log entry, retrieve similar normal log entries from a vector DB populated with clustered normal samples, then run a prompt-based classification/reasoning query on the SLM; apply prompt-level task decomposition (Explain and Decide as combined or as sequential Explain -&gt; Decide) and a Self-Reflection step.",
            "prompt_template": "Example prompts used (two variants shown): \"You are a system admin. Consider this log entry… &lt;query: log entry&gt; Question: Does the log entry indicate normalcy or not ?Explain your analysis and answer True if normal otherwise answer False.\" (and a similar variant where \"Explain\" and \"Answer\" are requested explicitly). Experimental conditions also used decomposed sequences: [{E,D}+R], [{D,E}+R], [E+D+R], [D+E+R] where E=Explain, D=Decide, R=Reflect.",
            "training_data": null,
            "data_type": "log entries (textual time-series / event logs)",
            "dataset_name": "BGL; Thunderbird",
            "evaluation_metric": "Precision, Recall, F1 (defined in paper as standard binary classification metrics)",
            "performance": "Paper reports significant improvements in F1 when task decomposition (Explain -&gt; Decide -&gt; Reflect) was applied for many model/condition combinations; no numeric scores are provided in the text. It also reports some cases where task decomposition reduced performance (LLaMa 2 7B with [E+D+R] and LLaMa 2 13B with [D+E+R]).",
            "baseline_comparison": "Qualitative comparison to prior RAGLog (GPT-3.5) and other LLM log-analysis approaches discussed in Related Work; no numeric baseline scores reported in this paper for direct comparison.",
            "zero_shot_or_few_shot": "Zero-shot style classification via RAG (no fine-tuning; retrieval supplies exemplars of normal logs to the prompt rather than few-shot in-prompt examples).",
            "limitations_or_failure_cases": "Authors report: imbalanced anomaly labels in datasets; SLMs have weaker multi-step reasoning leading to poorer outcomes unless aided by task decomposition; task decomposition sometimes reduces performance for specific model/sequence combinations; sequence order (Explain vs Decide first) did not show significant effect overall; prompts may need further tuning.",
            "computational_cost": "Models were quantized (GGUF Q4_K_M) and run locally due to resource constraints; exact GPU hours, latency, or token-costs not reported.",
            "uuid": "e7379.0",
            "source_info": {
                "paper_title": "Enhancing Reasoning Capacity of SLM Using Cognitive Enhancement",
                "publication_date_yy_mm": "2025-02"
            }
        },
        {
            "name_short": "RAGLog (prior)",
            "name_full": "RAGLog: Log Anomaly Detection using Retrieval Augmented Generation",
            "brief_description": "Authors' prior work applying Retrieval-Augmented Generation with GPT-3.5 to log anomaly detection using a vector DB of selected normal log entries and zero-shot classification.",
            "citation_title": "RAGLog: Log Anomaly Detection using Retrieval Augmented Generation.",
            "mention_or_use": "mention",
            "model_name": "GPT-3.5",
            "model_description": "OpenAI chat/completion style large language model (instruction-tuned), used as the generative component in a RAG pipeline.",
            "model_size": null,
            "anomaly_detection_approach": "Retrieval-Augmented Generation: embed query log, retrieve closest normal examples, and query the LLM to classify/analyze the entry (zero-shot).",
            "prompt_template": "Question-and-Answer template used in a RAG pipeline to ask the model whether a log entry is normal or anomalous, providing retrieved normal log examples as context.",
            "training_data": null,
            "data_type": "log entries",
            "dataset_name": null,
            "evaluation_metric": "Precision, Recall, F1 implied (paper states it performed relatively well for a zero-shot classifier)",
            "performance": "Described as performing relatively well as a zero-shot classifier in prior work; no numeric values provided in this paper.",
            "baseline_comparison": null,
            "zero_shot_or_few_shot": "Zero-shot (RAG)",
            "limitations_or_failure_cases": "Prior RAGLog used an online LLM (privacy concerns for sensitive data) — motivating local SLM experiments in the present paper.",
            "computational_cost": null,
            "uuid": "e7379.1",
            "source_info": {
                "paper_title": "Enhancing Reasoning Capacity of SLM Using Cognitive Enhancement",
                "publication_date_yy_mm": "2025-02"
            }
        },
        {
            "name_short": "LogGPT / ChatGPT (Qi et al.)",
            "name_full": "LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection",
            "brief_description": "A referenced study that applied ChatGPT to log-based anomaly detection exploring different prompt constructs, input window sizes and input sequences; highlighted sensitivity to prompt and window-size and reported high false positive rates.",
            "citation_title": "LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection.",
            "mention_or_use": "mention",
            "model_name": "ChatGPT",
            "model_description": "OpenAI conversational/instruction-tuned LLM (specific model version not specified in the mention).",
            "model_size": null,
            "anomaly_detection_approach": "Prompting ChatGPT with various prompt templates and windowing of log input sequences to classify anomalies.",
            "prompt_template": null,
            "training_data": null,
            "data_type": "log entries",
            "dataset_name": null,
            "evaluation_metric": "Paper mention: observed high false positive rates; specific metrics not quoted in this paper.",
            "performance": "Reported sensitivity to prompt formulation and window size; high false positive rate noted (no numeric values provided here).",
            "baseline_comparison": null,
            "zero_shot_or_few_shot": "Zero-shot prompting (varied prompts/windows)",
            "limitations_or_failure_cases": "High false positive rates and non-trivial dependence on prompt and window-size selection.",
            "computational_cost": null,
            "uuid": "e7379.2",
            "source_info": {
                "paper_title": "Enhancing Reasoning Capacity of SLM Using Cognitive Enhancement",
                "publication_date_yy_mm": "2025-02"
            }
        },
        {
            "name_short": "Mudgal et al. (ChatGPT for log parsing)",
            "name_full": "An Assessment of ChatGPT on Log Data",
            "brief_description": "Referenced work that designed specific prompts with ChatGPT for log parsing and achieved excellent parsing performance but noted limitations of LLMs for other log-analysis tasks (anomaly detection, summarization).",
            "citation_title": "An Assessment of ChatGPT on Log Data.",
            "mention_or_use": "mention",
            "model_name": "ChatGPT",
            "model_description": "OpenAI conversational LLM (used for prompt-based log parsing experiments).",
            "model_size": null,
            "anomaly_detection_approach": "Prompt engineering for log parsing (not primarily anomaly classification); evaluated other log tasks where limitations appeared.",
            "prompt_template": null,
            "training_data": null,
            "data_type": "log entries",
            "dataset_name": null,
            "evaluation_metric": null,
            "performance": "Excellent performance on log parsing tasks per the referenced study; limitations when applied to anomaly detection and summarization noted (no numeric values provided here).",
            "baseline_comparison": null,
            "zero_shot_or_few_shot": "Prompt-based (zero-shot/in-context prompting implied)",
            "limitations_or_failure_cases": "Limitations observed in anomaly detection and log summarization despite strong parsing performance.",
            "computational_cost": null,
            "uuid": "e7379.3",
            "source_info": {
                "paper_title": "Enhancing Reasoning Capacity of SLM Using Cognitive Enhancement",
                "publication_date_yy_mm": "2025-02"
            }
        },
        {
            "name_short": "LogPrompt (Liu et al.)",
            "name_full": "LogPrompt: Prompt Engineering Towards Zero-Shot and Interpretable Log Analysis",
            "brief_description": "Referenced study that tested prompt-engineered methods (self-prompt, Chain-of-Thought, In-context) in zero-shot scenarios for log analysis; reported promise but very low precision for some tasks.",
            "citation_title": "LogPrompt: Prompt Engineering Towards Zero-Shot and Interpretable Log Analysis.",
            "mention_or_use": "mention",
            "model_name": "LLMs (unspecified in this paper's mention)",
            "model_description": "Prompted LLMs evaluated under different prompting formats (self-prompt, CoT, in-context).",
            "model_size": null,
            "anomaly_detection_approach": "Zero-shot prompting with different prompt formats and varying numbers of provided log samples (not fine-tuning).",
            "prompt_template": "Variants including self-prompt, Chain-of-Thought prompts, and in-context examples as tested in zero-shot setups.",
            "training_data": null,
            "data_type": "log entries",
            "dataset_name": null,
            "evaluation_metric": "Precision noted specifically as very low in zero-shot tests per the mention in this paper.",
            "performance": "Promising overall but very low precision scores for anomaly detection tasks (no numeric values included in this paper's discussion).",
            "baseline_comparison": null,
            "zero_shot_or_few_shot": "Zero-shot (with prompt variations and varying provided samples)",
            "limitations_or_failure_cases": "Very low precision in zero-shot log anomaly detection despite promising overall behavior.",
            "computational_cost": null,
            "uuid": "e7379.4",
            "source_info": {
                "paper_title": "Enhancing Reasoning Capacity of SLM Using Cognitive Enhancement",
                "publication_date_yy_mm": "2025-02"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection",
            "rating": 2,
            "sanitized_title": "loggpt_exploring_chatgpt_for_logbased_anomaly_detection"
        },
        {
            "paper_title": "LogPrompt: Prompt Engineering Towards Zero-Shot and Interpretable Log Analysis",
            "rating": 2,
            "sanitized_title": "logprompt_prompt_engineering_towards_zeroshot_and_interpretable_log_analysis"
        },
        {
            "paper_title": "RAGLog: Log Anomaly Detection using Retrieval Augmented Generation.",
            "rating": 2,
            "sanitized_title": "raglog_log_anomaly_detection_using_retrieval_augmented_generation"
        },
        {
            "paper_title": "An Assessment of ChatGPT on Log Data.",
            "rating": 1,
            "sanitized_title": "an_assessment_of_chatgpt_on_log_data"
        }
    ],
    "cost": 0.01175425,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Enhancing Reasoning Capacity of SLM using Cognitive Enhancement</p>
<p>Jonathan Pan jonathan_pan@htx.gov.sg 
Home Team Science and Technology Agency
Singapore</p>
<p>XinSwee Liang Wong 
Home Team Science and Technology Agency
Singapore</p>
<p>Wei Chia chia_xin_wei@htx.gov.sg 
Home Team Science and Technology Agency
Singapore</p>
<p>Yidi Yuan yuan_yidi@htx.gov.sg 
Home Team Science and Technology Agency
Singapore</p>
<p>Enhancing Reasoning Capacity of SLM using Cognitive Enhancement
7D4B0E2B365300DE7ACC073FEC7B70B4Smaller Large Language ModelCognitive EnhancementDigital Forensics
Large Language Models (LLMs) have been applied to automate cyber security activities and processes including cyber investigation and digital forensics.However, the use of such models for cyber investigation and digital forensics should address accountability and security considerations.Accountability ensures models have the means to provide explainable reasonings and outcomes.This information can be extracted through explicit prompt requests.For security considerations, it is crucial to address privacy and confidentiality of the involved data during data processing as well.One approach to deal with this consideration is to have the data processed locally using a local instance of the model.Due to limitations of locally available resources, namely memory and GPU capacities, a Smaller Large Language Model (SLM) will typically be used.These SLMs have significantly fewer parameters compared to the LLMs.However, such size reductions have notable performance reduction, especially when tasked to provide reasoning explanations.In this paper, we aim to mitigate performance reduction through the integration of cognitive strategies that humans use for problemsolving.We term this as cognitive enhancement through prompts.Our experiments showed significant improvement gains of the SLMs' performances when such enhancements were applied.We believe that our exploration study paves the way for further investigation into the use of cognitive enhancement to optimize SLM for cyber security applications.</p>
<p>I. INTRODUCTION</p>
<p>In the field of cyber investigation and digital forensics, the analysis of logs is a frequent activity.It is also an important research topic with practical significance in the field of failure identification [1], [2] and security threat detection [3], [4].Such analysis is done to facilitate the detection of anomalous activities so that immediate or corresponding remediation may be done to contain or remediate the issue recorded in the logs.The issue may affect system resiliency against system faults, degradation and intentionally induced cyber physical attacks.However, the analysis of logs has its complexities namely from being voluminous, varied, and contextual.Additionally, logs possess inherent semantic complexity [5].</p>
<p>With the recent advances with Large Language Models (LLMs), they provide the means to automate the analysis of logs [6] [7][8] [9].While automation provides productivity gains, explain-ability of the analysis and conclusions made by such Artificial Intelligence (AI) solutions remains an important attribute for such solutions to be adopted [10].Another issue with LLMs is that not all digital forensics or investigative activities are suitable for services delivered through online channels [11].A locally deployed model would be needed where there are privacy and confidentiality concerns.However, such online LLMs are measurably larger with their resource demands requiring more compute resources in the form of GPUs and memory.An alternative solution is to run smaller versions of their large contemporaries on local compute resources like GPU equipped laptops, work stations or servers.In this research work, we explore the use of cognitive enhancement through prompts to improve the performance of the Smaller Large Language Models (SLMs).</p>
<p>In the next section, we will cover the complexity of performing log analysis and considerations when using language models for such task.This is followed by a review of current research work in the use of language models for log analysis and ways to improve the performances of SLMs.We then described our proposed cognitive enhancement technique used with details of the experimental setup and its evaluation.This paper concludes with a summary of this work and potential future research direction.</p>
<p>II. BACKGROUND INFORMATION</p>
<p>In this section, we articulate the background information related to the complexity in performing log analysis.We also consider what is needed if language models are practically used for such task.</p>
<p>A. Complexity with Log Analysis</p>
<p>The form for logs is typically unique to how the software has been developed or configured to post entries into these textual files.These logs are contextual to the environment which the system resides in [5].Hence, the analysis of such log datasets requires contextual understanding of the system or component that generates such logs especially when attempting to classify or distinguish what is a normal log entry and what is not.Anomaly recordings in logs may not include explicit keywords like 'Error' or 'Failure' to which signature-based rule engine could detect and draw needed attention.The limited sample size of the varied forms of anomalous log entries would create more constraints to enable the development of a robust machine learning model to detect anomalies from logs.Hence log analysis requires semantic comprehension [12][5] and to overcome the constraints of having limitedly available information about the form of anomalies that could occur.</p>
<p>B. Consideration on the Use of Language Models</p>
<p>In our previous research work, we demonstrated that we could use a LLM to perform log anomaly detection with a vector database containing only selected samples of normal log entries based on the log entries clustering distribution.Our model construct, that we called RAGLog [9] used the Retrieval Augmented Generative approach with GPT 3.5 to perform logs analysis that performed relatively well for a zero-shot classifier.</p>
<p>However, for cybersecurity applications, we will require the construct to work on locally deployed LLM instead of using online LLM instances.This is to address concerns with privacy and confidentiality.However, locally deployed LLM have limited resources available in terms of compute and memory resources.Hence, local deployment would be limited to SLMs to operate within such constraints.Given the absence of clear technical definitions of SLMs in the field, in this paper, we describe them as models that can be readily operated on a consumer hardware.This includes models such as LLaMa 2 7b.However, it is known that these smaller models have comparatively limited capabilities as compared to their larger counterparts.In this research context, the smaller models have difficulties solving complex tasks that involves multiple reasoning steps [13].This research work seeks to deal with that.</p>
<p>Another important consideration with the use of LLM for log analysis and for the broader cyber security application is to have the means for humans to evaluate the correctness of the models' assessment.This will help the human log reviewer or investigator to assess whether the anomaly classification is valid and warrants further investigation.In the absence of the means to evaluate the correctness of such models, these cyber security practitioners would be less inclined to accept the decisions made by these models [14].</p>
<p>III. RELATED WORK</p>
<p>In this section, we review the current state of art research work in the use of Language Models to perform log analysis and log anomaly detection.We also review how Small Language Models are being tuned for high performance.</p>
<p>A. Language Models for Log Analysis</p>
<p>There are several research attempts to apply Large Language models to perform log analysis.Qi et al. [6] proposed a framework for log-based anomaly detection using ChatGPT using varied prompt constructs, window sizes and input sequences.Their work showed the non-triviality of an optimal prompt, window size limitations as well as high false positive rates.Mudgal et al. [7] designed specific prompts with ChatGPT for log parsing that had excellent performance.However, with other areas of log analysis like anomaly detection and log summarization, the LLM exhibited limitations that warrant further research.Liu et al. [8] tested their LogPrompt model in zero-shot scenarios with varying number of provided log samples and different prompt formats (self-prompt, CoT prompts and In-context Prompt).The zero-shot test results</p>
<p>showed promise when compared with our log analysis algorithms and other Deep Learning architectures.However, it had very low precision scores which is not optimal if applied to log analysis for operations and maintenance activities to support resiliency.We also applied GPT 3.5 to perform log anomaly detection using Retrieval Augmented Generation approach which we called RAGLog [9].However, all such approaches focused on the use of Large Language Models instead of Small Language Model.This research work seeks to address this gap.</p>
<p>B. Improving Smaller Large Language Models</p>
<p>There are a number of studies in how to teach or improve the capabilities of small language models.Magister et.al [15] argued that one approach, through the use of knowledge distillation, enables the transfer of reasoning capabilities from a large model of over 100 billion parameters to smaller models.Such finetuning approach improves the task accuracy of these smaller models across a range of benchmarking datasets.Xie et.al [29] suggested training several small language models with multiple candidates plan and subsequently select a good one.Another work suggested parameter editing methods and saw performance in small language models [30].Majority of approaches look to improve SLMs through fine tuning [31].However, this approach requires expertise and computational resources, which poses a challenge for local deployment where resources are limited.Therefore, there is a need to explore alternative strategies to improve the performance of SLMs without the need of extensive computational resources.</p>
<p>C. Cognitive Enhancements of Language models</p>
<p>In this paper, we explore the use of cognitive enhancements to improve the outcome of a SLM.While there has been extensive research into the use of prompt engineering to improve performance, such as Chain-of-Thought (CoT) [34] and Self-Consistency [33] these approaches were often performed on larger language models.Importantly, it was found that the use of CoT only yielded performance improvement when used on models with larger than 100B model parameters.Smaller models produced illogical outcomes, leading to poorer outcomes.The same limitations were observed for Self-Consistency where the gain in accuracy was lower for smaller models.Inspired by introspective reasoning in human cognition, Wang and Zhao [35] explored the use of metacognition to improve the outcome of LLMs.Metacognitive prompting led to an improvement of accuracy when compared to standard and CoT prompting.However, like CoT, performance gains were only observed in the larger GPT-4 model.Hence, there is a need to further investigate cognitive enhancement techniques that would significantly improve the performance of SLMs.</p>
<p>IV. COGNITIVE ENHANCEMENT</p>
<p>Our research question attempts to address the question whether smaller language models, with its comparatively weaker cognitive capabilities, could improve its performance through cognitive enhancements.More specifically, we hypothesized that decomposing a task into smaller manageable steps can improve the outcome of SLMs on a combined reasoning and decision-making or classification task.We also applied Self-Reflection to validate the reasoning and decisionmaking cognitive process.</p>
<p>A. Task Decomposition</p>
<p>In the study of psychology and cognitive science, there are studies on the effects of increased levels of cognitive load that could cause people to make poorer decisions [19].One approach proposed to deal with cognitive overload is the use of task decomposition [20].Task decomposition is the process of breaking down complex tasks or problems into smaller manageable tasks or steps.It also involves defining the sequence of subgoals to achieve the main goal or objective [21] [22].We propose that we could apply the same approach to break down the complex task of performing log analysis into smaller sub-tasks that the small language models are better capable of handling and to assess whether our approach leads to better and comparable performances against their much larger counterparts.There exists past work in the use of Task Decomposition [23].However, they are focused on its application in LLMs to enhance their performance instead of SLMs.</p>
<p>We propose the following mathematical formulation for task decomposition in Equation 1, where a complex composite task  is broken into simpler sequentially concatenated tasks  ! .For each decomposed task an input  !formulated in the form of a prompt is given to the language model.The reply from the language model would be the output  to the prompt query and classification conclusion to the query task.When there is a concatenation of two cognitive tasks with the additive operation, the output of the preceding cognitive task would be the input to the proceeding cognitive task (Equation 2).This continues until the entire set of the decomposed tasks is done.In contrast, without task decomposition, a composite task can be given an input in the form of a composite input  (Equation 3).
𝑐 = 𝑐 ! + 𝑐 " (1) 𝑦 = 𝑐 ! (𝑥 ! ) + 𝑐 " (𝑥 " ) (2) 𝑦 = 𝑐(𝑥) (3)
An example of the prompt-based task decomposition is as such.</p>
<p>B. Self-Reflection</p>
<p>As the analysis task was decomposed into smaller tasks namely with the reasoning (Explaining) and classification (Deciding) as two smaller tasks, we included self-reflective task.The self-reflective task acts as a feedback activity for the language model to validate the earlier reasoning and classification conclusion.Shinn et.al [32] argues that using selfreflection improves decision-making performance.</p>
<p>V. METHODOLOGY AND ANALYSIS</p>
<p>In our experiment setup, we designed our experiment to address our research question whether Retrieval Augmented Generation in LLM could perform log anomaly detection.</p>
<p>A. Log Datasets</p>
<p>For our log datasets, we used BGL [25] and Thunderbird [26].These are two popular datasets typically used by researchers to evaluate log analysis models [24].</p>
<p>The BGL are open real-world datasets from HPC from a BlueGene/L supercomputer at Lawrence Livermore National Labs.This dataset has an important characteristic associated with their appearance of many new log messages in the timeline of the data, that is, the systems change over time.The Thunderbird open dataset of logs was collected by Sandia National Lab.It contains alert and non-alert messages.Both datasets are labelled with sizeable imbalance for the anomaly class.</p>
<p>B. Evaluation Metrics</p>
<p>As the dataset used had binary classification labels, we used Precision to measure the accuracy of the model against type I error (true positive) and Recall to measure the accuracy of the models against type II error (true negative).Finally, we used F1 score to measure the harmonic mean of precision and recall.
𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 = 𝑇𝑃 𝑇𝑃 + 𝐹𝑃 (4)+ 𝑅𝑒𝑐𝑎𝑙𝑙 = 𝑇𝑃 𝑇𝑃 + 𝐹𝑁 (5) 𝐹1 𝑠𝑐𝑜𝑟𝑒 = 2 × 𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 × 𝑅𝑒𝑐𝑎𝑙𝑙 𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 + 𝑅𝑒𝑐𝑎𝑙𝑙(6)
TP (True Positive) represents the number of correctly classified anomalies, TN (True Negative) represents normal log entries and FP (False Positive) is the number of incorrect anomaly classification.FN (False Negative) is the number of incorrect classifications of log entries as normal while the label or ground truth states overwise.</p>
<p>C. Experimentation Preparation and Execution</p>
<p>We first populated the vector database with selected samples and limited size of the log database with normal log entries.The selection was done by first applying unsupervised k-means clustering to the dataset and populating the database from random sampling from the cluster classes.This is to ensure that the sample selection had a good distribution of the normal log entries.</p>
<p>For our experiment, we used four variations of pretrained Small Language Models.They are Meta's LLaMa 2 7B, Meta's LLaMa 2 13B, Vicuna 7B and Vicuna 13B.The LLaMa 2 [27] is an auto-regression language model that uses an optimized transformer architecture.The models are tuned using supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) to align to human preferences for helpfulness and safety.The Vicuna models [28] are fine-tuned from LLaMa 2 using high quality conversations using user-shared conversations hosted in ShareGPT.com.Due to resource limitations, we used the quantized versions of the models specifically the GGUF Q4_K_M format by llama.cppteam.</p>
<p>The experiment configuration for this research work used the the same construct as our previous experiment in our work in RAGLog [9].We used vector databases to store the embeddings of limited sized selected log entries.The log entries in the database contain only the normal log entries and number no more than two thousand.The selection of the normal log entries to be populated is done first with the clustering of normal log entries and random selection of cluster classes.Using the Retrieval Augmented Generation approach [17], the Small Language Model would be queried with the log entry under evaluation using the Question and Answer template [18].The orchestrator would then query the vector database through the embedding model to retrieve the best matched normal log entry.The resultant from the vector database would then be given to the SLM with our specially constructed prompts with the final concluding reply provided by the orchestrator where ground truth verification is done against the provided labels for corresponding dataset.The concluding reply to the queried log entry would contain the reasoning explanation to facilitate validation by a human analyst and the inferred classification conclusion that would be used to assess the model's performance.</p>
<p>For this paper, the orchestrator was scripted to enable the incorporation of cognitive enhancement.The main variable to our research construct is the inclusion of Task Decomposition through prompts.For our experiment, we used two such forms namely Explain First and Decide Later or Decide First and Explain Later.The Explain First and Decide Later is an approach proposed by Yao et.al [16] with their ReAct framework for LLMs to generate reasoning traces and taskspecific actions.Results from research work showed that their framework outperform several state-of-the-art baseline tests on decision-making tasks.As part of this experiment, we attempted to explore the alternative, Decide First and Explain Later to investigate if the sequence of task decomposition affects performance.We included Self-Reflection into our cognitive process as the concluding cognitive process task after both reasoning explanation and classification conclusion were generated.</p>
<p>Hence, our experiments conducted were as such with the corresponding prompts.</p>
<p>• [{E,D}+R] Explain and Decide then Reflect; where Explain and Decide are done as one activity without task decomposition followed by self-reflection.</p>
<p>• [{D,E}+R] Decide and Explain then Reflect; where Decide and Explain are done as one activity without task decomposition followed by self-reflection</p>
<p>• [E+D+R] Explain, Decide then Reflect; where each activity is done in the mentioned sequence with task decomposition followed by self-reflection.</p>
<p>• [D+E+R] Decide, Explain then Reflect; where each activity is done in the mentioned sequence with task decomposition followed by self-reflection.</p>
<p>Each activity was executed with its corresponding prompt.One prompt was used for the combined pair of Decide and Explain or Explain and Decide when they were executed as one activity.The reply responses from the models following the query prompts were evaluated against their corresponding labels (normal or anomaly).</p>
<p>Figure 1 .
1
Figure 1.Task Decomposition illustrating the decomposition of a prompt into two sequential Explain and Decide prompts respectively.</p>
<p>Figure 2 .
2
Figure 2. Workflow of log analysis.</p>
<p>You are a system admin.Consider this log entry… <query: log entry> Question: Does the log entry indicate normalcy or not ?Explain your analysis and answer True if normal otherwise answer False.
You are a system admin. Consider this log entry…<query: log entry>Question: Does the log entry indicate normalcy or not ?Explain your analysis.Answer True if normal otherwise answer False.
D. Results and AnalysisThe following are our experiment test results for both datasets (BGL and Thunderbird).Bolded scores indicate the best result for each model.The highlighted F1 scores showed significant improvements especially when Task Decomposition was applied.However, we do notice that for conditions LLaMa 2 7B with [E+D+R] and LLaMA 2 13B with [D+E+R], Task Decomposition led to a reduction in performance when compared to their respective conditions without Task Decomposition.This warrants further experiments especially with the tuning of prompts.In addition, we found that the sequence of Explain and Decide does not play a significant role in the model's performance.VI. CONCLUSION AND FUTURE DIRECTIONS Our research work explored the use of Smaller LargeLanguage Model (SLM) to perform log anomaly detection based on our earlier work that applied the Retrieval Augmented Generation approach with GPT 3.5 (RAGLog).As SLMs lack reasoning capacity in comparison to LLMs, we used Task Decomposition to decompose the prompt into smaller manageable steps and noted significant performance improvements.By applying this to a log analysis cybersecurity application, we improved the performance of SLMs to achieve robust outcomes while simultaneously addressing concerns related to data privacy and confidentiality.Our study demonstrates the plausible use of such cognitive enhancement through Task Decomposition to improve SLMs' capabilities.The next step to this research work is to apply this to realworld log analysis and assess the performance.Also, we will look into how such language models can reduce the time needed for such log analysis as the current approach performs log analysis sequentially.
Improving logbased field failure data analysis of multi-node computing systems. A Pecchia, D Cotroneo, Z Kalbarczyk, R K Iyer, DSN'11: Proc. of the 41st IEEE/IFIP International Conference on Dependable Systems and Networks. IEEE2011</p>
<p>Detecting large-scale system problems by mining console logs. W Xu, L Huang, A Fox, D Patterson, M I Jordon, SOSP'09: Proc. of the ACM Symposium on Operating Systems Principles. 2009</p>
<p>Log Files Analysis For Network Intrusion Detection. A Brandao, P Georgieva, 10.1109/IS48319.2020.91999762020 IEEE 10th International Conference on Intelligent Systems (IS). 2020</p>
<p>Detecting Web Attacks Using Multi-stage Log Analysis. M Moh, S Pininti, S Doddapaneni, T Moh, 10.1109/IACC.2016.1412016 IEEE 6th International Conference on Advanced Computing (IACC). 2016</p>
<p>Taming the logs -Vocabularies for semantic security analysis. A Ekelhart, E Kiesling, K Kurniawan, SEMANTiCS 2028 -14 th International Conference on Semantic Systems, Science Direct, Procedia Comput Science. 2018137</p>
<p>LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection. J Qi, S Huang, Z Luan, C Fung, H Yang, D Qian, arXiv:2309.01189v12023</p>
<p>P Mudgal, R Wouhaybi, arXiv:2309.07938v1An Assessment of ChatGPT on Log Data. 2023</p>
<p>Y Liu, S Tao, W Meng, J Wang, W Ma, Y Zhao, Y Chen, H Yang, Y Jiang, X Chen, arXiv:2308.07610v1LogPrompt: Prompt Engineering Towards Zero-Shot and Interpretable Log Analysis. 2023</p>
<p>RAGLog: Log Anomaly Detection using Retrieval Augmented Generation. J Pan, S L Wong, Y Yuan, 10.48550/arXiv.2311.05261arXiv:2311.05261</p>
<p>Explainable Artificial Intelligence Applications in Cyber Security: Stateof-the-Art in Research. Z Zhang, H A Hamadi, E Damiani, Y Y Chan, F Tahar, 10.1109/ACCESS.2022.3204051IEEE Access. 2022</p>
<p>ChatGPT for digital forensic investigation: The good, the bad and the unknown. M Scanlon, F Breitinger, C Hargreaves, J Hilgert, J Sheppard, Forensic Science International: Digital Investigation. 46</p>
<p>. Supplement, 10.1016/j.fsidi.2023.301609Oct 2023</p>
<p>Log-based Anomaly Detection without Log Parsing. V H Le, H Zhang, 2021 36 th IEEE/ACM International Conference on Automated Software Engineering (ASE). Nov 2021</p>
<p>W X Zhao, K Zhou, J Li, T Tang, X Wang, Y Hou, Y Min, B Zhang, J Zhang, Z Dong, Y Du, C Yang, Y Chen, Z Chen, J Jiang, R Ren, Y Li, X Tang, Z Liu, P Liu, J Y Nie, J R Wen, 10.48550/arXiv.2303.18223arXiv:2303.18223A Survey of Large Language Models. </p>
<p>Explainable Artificial Intelligence in CyberSecurity: A Survey. N Capuano, G Fenza, V Loia, C Stanzione, IEEE Access. 10Sep 2022</p>
<p>Teaching Small Language Models to Reason. L C Magister, J Mallinson, J Adamek, E Malmi, A Severyn, 10.48550/arXiv.2212.08410arXiv:2212.08410</p>
<p>ReAct: Synergizing Reasoning and Acting in Language Models. S Yao, J Zhao, D Yu, N Du, I Shafran, K Narasimhan, Y Cao, 10.48550/arXiv.2210.3629arXiv:2210.03629</p>
<p>Retrieval-augmented generation for knowledge-intensive nlp tasks. P Lewis, E Perez, A Piktus, F Petroni, V Karpukhin, N Goyal, H Küttler, M Lewis, W Yih, T Rocktäschel, Advances in Neural Information Processing Systems. 202033</p>
<p>Latent retrieval for weakly supervised open domain question answering. K Lee, M W Chang, K Toutanov, arXiv:1906.003002019</p>
<p>The effect of cognitive load on economic decision making: A survey and new experiment. C Deck, S Jahedi, 10.1016/j.euroecorev.2015.05.004European Economic Review. 78Aug 2015</p>
<p>A cognitive decomposition to empirically study human performance in control room environments. B M Knisely, J S Joyner, A M Rutkowski, M Wong, S Barksdale, H Hotham, K Kharod, M Vaughn-Cooke, International Journal of Human-Computer Studies. 141Sep 2020</p>
<p>Resourcerational Task Decomposition to Minimize Planning Costs. C G Correa, M K Ho, F Callaway, T L Griffiths, 42 nd Annual Meeting of the Cognitive Science Society: Developing a Mind: Learning in Humans, Animals, and Machines. CogSci2020. 2020</p>
<p>Cognitive Task Analysis. J M Schraagen, S F Chipman, V L Shalin, 2000Psychology Press</p>
<p>Understanding the planning of LLM agents: A survey. X Huang, W Liu, X Chen, X Wang, H Wang, D Lian, Y Wang, R Tang, E Chen, 10.48550/arXiv.2402.02716arXiv:2402.02716</p>
<p>Experience Report: Deep Learning-based System Log Analysis for Anomaly Detection. Z Chen, J Liu, W Gu, Y Su, M R Lyu, 10.48550/arXiv.2107.05908arXiv:2107.05908</p>
<p>What supercomputers say: A study of five system logs. A Oliner, J Stearley, 37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07. IEEE2007</p>
<p>What supercomputers say: A study of five system logs. A Oliner, J Stearley, DSN. 2007</p>
<p>LLAMA 2: Open Foundation and Fine-Tuned Chat Models. H Touvron, 10.48550/arXiv.2307.09288arXiv:2307.09288</p>
<p>L Zheng, W L Chiang, Y Sheng, S Zhuang, Z Wu, Y Zhuang, Z Lin, Z Li, D Li, E P Xing, H Zhang, J E Gonzalez, I Stoica, 10.48550/arXiv.2306.05685arXiv:2306.05685Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena. </p>
<p>S M Xie, H Pham, X Dong, N Du, H Liu, Y Lu, P Liang, Q V Le, T Ma, A W Yu, arXiv:2305.10429Doremi: Optimizing data mixtures speeds up language model pretraining. 2023</p>
<p>Editing large lanague models: Problems, method and opportunities. Y Yao, P Wang, B Tian, S Cheng, Z Li, S Deng, H Chen, N Zhang, abs/2305.13172CoRR. 2023</p>
<p>BERT: pre-training of deep bidirectional transformers for language understanding. J Devlin, M Chang, K Lee, K Toutanova, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019. Long and Short Papers. J Burstein, C Doran, T Solorio, the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019Minneapolis, MN, USAAssociation for Computational LinguisticsJune 2-7, 2019. 20191</p>
<p>Reflexion: an autonomous agent with dynamic memory and self-reflection. N Shinn, B Labash, A Gopinath, arXiv:2303.113662023arXiv preprint</p>
<p>Self-Consistency Improves Chain of Thought Reasoning in Language Models. X Wang, J Wei, D Schuurmans, Q Le, E Chi, S Narang, A Chowdhery, D Zhou, arXiv:2203.111712023arXiv preprint</p>
<p>Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. J Wei, X Wang, D Schuurmans, M Bosma, B Ichter, F Xia, E Chi, Q Le, D Zhou, arXiv:2201.119032023arXiv preprint</p>
<p>Y Wang, Y Zhao, arXiv:2308.05342v4Metacognitive Prompting Improves Understanding in Large Language Models. 2024arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>