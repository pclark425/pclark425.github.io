<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7876 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7876</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7876</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-144.html">extraction-schema-144</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods that use large language models to synthesize, distill, or generate scientific theories, hypotheses, or structured knowledge from collections of scholarly papers.</div>
                <p><strong>Paper ID:</strong> paper-1ee1220d4c408425143142932ca8f9f7f8234adc</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/1ee1220d4c408425143142932ca8f9f7f8234adc" target="_blank">DoubleLingo: Causal Estimation with Large Language Models</a></p>
                <p><strong>Paper Venue:</strong> North American Chapter of the Association for Computational Linguistics</p>
                <p><strong>Paper TL;DR:</strong> This paper enables theoretically consistent estimation of causal effects using LLM-based nuisance models by incorporating them within the framework of Double Machine Learning and obtains a 10.4% reduction in the relative absolute error for the estimated causal effect over existing methods.</p>
                <p><strong>Paper Abstract:</strong> Estimating causal effects from non-randomized data requires assumptions about the underlying data-generating process. To achieve unbiased estimates of the causal effect of a treatment on an outcome, we typically adjust for any confounding variables that influence both treatment and outcome. When such confounders include text data, existing causal inference methods struggle due to the high dimensionality of the text. The simple statistical models which have sufficient convergence criteria for causal estimation are not well-equipped to handle noisy unstructured text, but flexible large language models that excel at predictive tasks with text data do not meet the statistical assumptions necessary for causal estimation. Our method enables theoretically consistent estimation of causal effects using LLM-based nuisance models by incorporating them within the framework of Double Machine Learning. On the best available dataset for evaluating such methods, we obtain a 10.4% reduction in the relative absolute error for the estimated causal effect over existing methods.</p>
                <p><strong>Cost:</strong> 0.005</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7876",
    "paper_id": "paper-1ee1220d4c408425143142932ca8f9f7f8234adc",
    "extraction_schema_id": "extraction-schema-144",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.004581999999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>DoubleLingo: Causal Estimation with Large Language Models</h1>
<p>Marko Veljanovski, Zach Wood-Doughty<br>Northwestern University<br>Department of Computer Science<br>marko@u.northwestern.edu, zach@northwestern.edu</p>
<h4>Abstract</h4>
<p>Estimating causal effects from non-randomized data requires assumptions about the underlying data-generating process. To achieve unbiased estimates of the causal effect of a treatment on an outcome, we typically adjust for any confounding variables that influence both treatment and outcome. When such confounders include text data, existing causal inference methods struggle due to the high dimensionality of the text. The simple statistical models which have sufficient convergence criteria for causal estimation are not well-equipped to handle noisy unstructured text, but flexible large language models that excel at predictive tasks with text data do not meet the statistical assumptions necessary for causal estimation. Our method enables theoretically consistent estimation of causal effects using LLM-based nuisance models by incorporating them within the framework of Double Machine Learning. On the best available dataset for evaluating such methods, we obtain a $10.4 \%$ reduction in the relative absolute error for the estimated causal effect over existing methods.</p>
<h2>1 Introduction</h2>
<p>A common goal of scientific research is the analysis of causal relationships (Triantafillou et al., 2017; Sanna et al., 2019; Chang et al., 2022). Consider the following motivating example, where a pharmaceutical company wants to estimate the causal effect of the prescription of antibiotics (treatment) on the patient's disease progression (outcome). The causal effect is defined as the expected change in disease progression across two counterfactual worlds which only differ in whether the patient is given antibiotics (Hernán, 2004). When randomization is impossible or unethical, we estimate causal effects from observational data using assumptions about the underlying data distribution. Confounders - variables affecting both the treatment and outcome - introduce potential bias that must be addressed.</p>
<p>When data is low-dimensional, confounding can be controlled for using various methods from the literature (Pearl, 2009). However, several challenges arise in the case of high-dimensional confounders. Suppose the pharmaceutical company has free-text clinical notes that may include information about patients' histories, diagnoses, or relationships with their doctors (Rajkomar et al., 2018). If these variables appear nowhere else in the patients' records, then account for potential confounding should use text-based causal methods (Rosenbloom et al., 2011; Wu et al., 2013). Since text is high-dimensional, it requires sophisticated modeling that captures semantic meaning.</p>
<p>Existing models often utilize overly simplified representations of the text (Wood-Doughty et al., 2018; Keith et al., 2020), such as a bag-of-words (BoW) representation. While such representations combined with simple estimation models allow for consistent ${ }^{1}$ estimation, they may fail to capture the true complexity of the text's underlying relationships. The use of large language models (LLMs) in causal estimation has only recently been studied (Veitch et al., 2020), and many researchers suggest the need for more sophisticated natural language processing (NLP) techniques (WoodDoughty et al., 2021; Feder et al., 2022; Keith et al., 2023). However, while LLMs excel at predictive tasks, they do not meet the necessary statistical assumptions for a consistent causal estimation.</p>
<p>We present DoubleLingo, combining Double Machine Learning with LLM-based nuisance models to enable a theoretically consistent estimation of causal effects with text-based confounding. We test our model on a novel dataset (Keith et al., 2023), obtaining the best causal effect estimates reported thus far. In particular, our relative absolute error is over $10 \%$ lower than the best current models.</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h2>2 Causal Inference Background</h2>
<p>While causal inference is a broad and diverse field (Robins et al., 2000; Pearl, 2009), we provide a brief introduction here. For recent surveys of causal inference and natural language processing, see Keith et al. (2020) or Feder et al. (2022).</p>
<h3>2.1 DAGs \&amp; Counterfactuals</h3>
<p>The motivating example described above is illustrated by the directed acyclic graph (DAG) in Figure 1, where we use a binary random variable $A$ to indicate whether the patient receives $(A=1)$ antibiotics or not $(A=0)$. We similarly use a binary $Y$ to denote whether the disease progresses $(Y=1)$ or not $(Y=0)$. An arrow in the DAG such as $A \rightarrow Y$ indicates that $A$ has a potential causal effect on $Y$. Finally, we denote $T$ as the patient medical records, and $C$ as the set of all confounding variables contained in the records. For example, such variables could include income status or family disease history (Acharya et al., 2021). Most importantly, $C$ is unobserved - we don't know the exact confounding variables, but we have access to the text $T$ containing them. In particular, $T$ is related to $A$ and $Y$ through $C$. The counterfactual outcome $Y^{a=1}$ represents the hypothetical disease progression had we intervened to assign $A=1$ (prescribe antibiotics), and $Y^{a=0}$ is defined analogously. In causal inference, the most common estimand is the average treatment effect $(A T E)$ of $A$ on $Y$, computed as:</p>
<p>$$
A T E=\mathbb{E}\left[Y^{a=1}-Y^{a=0}\right]
$$</p>
<p>A fundamental problem is that we can never simultaneously observe both counterfactuals $Y^{a=1}, Y^{a=0}$ (Holland, 1986), thus we need a way to compute the $A T E$ only utilizing observed data.</p>
<h3>2.2 Identification Assumptions</h3>
<p>We proceed by assuming consistency, requiring that the outcome we observe for any possible treatment $a$ is equal to the counterfactual outcome we would have observed had we intervened to assign $A=a$. Formally:</p>
<p>$$
A=a \Rightarrow Y^{a}=Y
$$</p>
<p>We then assume conditional exchangeability, requiring the independence between our counterfactual $Y^{a}$ and the observed treatment $A$ conditioned on all confounders $C$, formalized as:</p>
<p>$$
Y^{a} \perp A \mid C \quad \forall a \in{0,1}
$$</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Textual Confounding DAG with Treatment $A$, Outcome $Y$, Confounders $C$, and Text $T$. We assume the $C \rightarrow T$ edge is such that adjusting for $T$ can control $C$ 's confounding of the $A \rightarrow Y$ relationship.</p>
<p>Using these assumptions, we may compute the counterfactual $\mathbb{E}\left[Y^{a}\right]$ as follows:</p>
<p>$$
\begin{aligned}
\mathbb{E}\left[Y^{a}\right] &amp; =\sum_{C} \mathbb{E}\left[Y^{a} \mid C\right] \mathbb{P}(C) \
&amp; \stackrel{(3)}{=} \sum_{C} \mathbb{E}\left[Y^{a} \mid A=a, C\right] \mathbb{P}(C) \
&amp; \stackrel{(3)}{=} \sum_{C} \mathbb{E}[Y \mid A=a, C] \mathbb{P}(C)
\end{aligned}
$$</p>
<p>Equation (6) expresses our counterfactual as a function of observed data. However, we are interested in the case where the low-dimensional $C$ is unobserved but encoded inside the high-dimensional $T$. Thus, if we could adequately model $T$, we would be able to adjust for $C$ 's confounding effect.</p>
<h3>2.3 Causal Effect Estimation</h3>
<p>To estimate (1) using (6), we thus require (a) a representation of the text and (b) an appropriate causal estimation method. As mentioned in $\S 1$, a BoW text representation is commonly used by existing text-based causal estimators. For (b), there are countless estimation methods, and we refer the reader to a much more exhaustive guide by Peters et al. (2017). One such commonly used method is the Inverse Propensity of Treatment Weighting (IPTW), where $\mathbb{E}\left[Y^{a}\right]$ is calculated as follows for a dataset of size $N$ :</p>
<p>$$
\mathbb{E}\left[Y^{a}\right]=\frac{1}{N} \sum_{i \in[N]} Y_{i} \frac{\mathbb{1}\left(A_{i}=a\right)}{\mathbb{P}\left(A_{i}=a \mid T\right)}
$$</p>
<p>A simple way to combine (a) and (b) is to use IPTW and train a Logistic Regression model $\mathbb{P}(A \mid T)$ for the propensity of the treatment $A$ given a BoW text representation $T$. However, BoW will fail to model the complexities of real-world text, introducing bias into our estimates.</p>
<h2>3 Model</h2>
<p>We now introduce notation to formalize our proposed method to use LLMs to replace a simplistic BoW text representation. Consider this partially linear model corresponding to Figure 1:</p>
<p>$$
\begin{array}{ll}
Y=A \theta_{0}+g_{0}(T)+U, &amp; \mathbb{E}[U \mid T, A]=0 \
A=m_{0}(T)+V, &amp; \mathbb{E}[V \mid T]=0
\end{array}
$$</p>
<p>Here $\theta_{0}$ is the true $A T E$ we hope to estimate, $\eta_{0}=$ $\left(m_{0}, g_{0}\right)$ are nuisance parameters, and $U, V$ are our error terms. Following Keith et al. (2023), ${ }^{2}$ we similarly assume the causal effect $A \rightarrow Y$ is linear. Any estimator $\widehat{\theta}<em 0="0">{0}$ of $\theta</em>$}$ must be both unbiased and consistent such that: ${ }^{3</p>
<p>$$
\mathbb{E}\left[\widehat{\theta}<em 0="0">{0}\right]=\theta</em>} \quad \text { and } \quad \widehat{\theta<em 0="0">{0} \xrightarrow{p} \theta</em>
$$</p>
<p>While LLMs have drastically changed the field of NLP (Vaswani et al., 2017; Min et al., 2023), they are not consistent estimators of causal parameters due to both explicit and implicit regularization (Neyshabur, 2017; Chernozhukov et al., 2018). Thus, a naive approach of using an LLM such as BERT (Devlin et al., 2019) to learn the propensity $\mathbb{P}(A \mid T)$ in Equation (7) would be biased.</p>
<h3>3.1 Double Machine Learning</h3>
<p>To overcome this challenge, we turn to Double Machine Learning (DML), which has never previously been used in the context of LLMs. As introduced by Chernozhukov et al. (2018), DML is an estimation procedure which removes regularization bias and overfitting on estimation by combining (a) Neyman-orthogonal moments with (b) samplesplitting. Let $\widehat{m}<em 0="0">{0}$ and $\widehat{g}</em>}$ be ML estimators of $\eta_{0}$. For (a), we partial out the effect of $T$ from $A$ to obtain the orthogonalized regressor $\widehat{V}=A-\widehat{m<em 0="0">{0}(T)$. For (b), we randomly split our dataset of size $N$ into a main and auxiliary sample with their indices denoted respectively by $I$ and $I^{C}$, both of size $n=N / 2$. We first train $\widehat{m}</em>}$ and $\widehat{g<em 0="0">{0}$ on $I^{C}$, and then subsequently estimate $\theta</em>$ from $I$ as follows:</p>
<p>$$
\widehat{\theta}<em I="I" _in="\in" i="i">{0}=\left(\frac{1}{n} \sum</em>} \widehat{V<em i="i">{i} A</em>}\right)^{-1} \frac{1}{n} \sum_{i \in I} \widehat{V<em i="i">{i}\left(Y</em>}-\widehat{g<em i="i">{0}\left(T</em>\right)\right)
$$</p>
<p>Now, as shown by Chernozhukov et al. (2018), the scaled estimation error can be decomposed as:</p>
<p>$$
\sqrt{n}\left(\widehat{\theta}<em 0="0">{0}-\theta</em>\right)=A+B+C
$$</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup>The $A$ term from (12) converges in distribution to a mean-zero Gaussian with variance $\Sigma$ :</p>
<p>$$
\frac{1}{\mathbb{E}\left[V^{2}\right] \sqrt{n}} \sum_{i \in I} V_{i} U_{i} \xrightarrow{d} \mathcal{N}(0, \Sigma)
$$</p>
<p>Sample-splitting guarantees that the $C$ term is $O_{p}(1)$, as it contains terms of form:</p>
<p>$$
\frac{1}{\sqrt{n}} \sum_{i \in I} V_{i}\left(\widehat{g}<em i="i">{0}\left(T</em>\right)\right)
$$}\right)-g_{0}\left(T_{i</p>
<p>Finally, the regularization bias from training our two ML estimators $\widehat{m}<em 0="0">{0}$ and $\widehat{g}</em>$ is captured by the $B$ term, which equals:</p>
<p>$$
\frac{1}{\mathbb{E}\left[V^{2}\right] \sqrt{n}} \sum_{i \in I}\left(\widehat{m}<em i="i">{0}\left(T</em>}\right)-m_{0}\left(T_{i}\right)\right)\left(\widehat{g<em i="i">{0}\left(T</em>\right)\right)
$$}\right)-g_{0}\left(T_{i</p>
<p>Observe that due to orthogonalization via (a), term $B$ contains the product of the estimation errors, which Chernozhukov et al. (2018) show to be upper-bounded by $\sqrt{n} n^{-\left(\varphi_{m}+\varphi_{g}\right)}$, where $n^{-\varphi_{m}}$ and $n^{-\varphi_{g}}$ denote the respective convergence rates of $\widehat{m}<em 0="0">{0}$ and $\widehat{g}</em>}$. Hence, this term vanishes even in cases where $\widehat{m<em 0="0">{0}$ and $\widehat{g}</em>$-consistent, where:}$ converge at relatively slower rates. In particular, if these two ML estimators converge at $n^{-1 / 4}$, the estimation of the $A T E$ is $\sqrt{n</p>
<p>$$
\widehat{\theta}<em 0="0">{0}-\theta</em>\right)
$$}=O_{p}\left(n^{-1 / 2</p>
<p>For proofs of the above claims, and more general cases covering unequal split-sizes, please see Chernozhukov et al. (2018). Finally, as we train both $\widehat{m}<em 0="0">{0}$ and $\widehat{g}</em>$, the estimation is doubly robust such that only one of the two need to be correctly specified to obtain an unbiased $A T E$ (Funk et al., 2011).</p>
<h3>3.2 Faster Converging Model Variations</h3>
<p>A potential concern is that our two ML estimators must converge at $n^{-1 / 4}$ to obtain the desired $\sqrt{n}$-consistent estimation of $\theta_{0}$. While there is research on the rate of convergence of misclassification probability (Gurevych et al., 2022) for encoderbased transformer classifiers such as BERT, its convergence rate for semiparametric inference is unknown. Since fully fine-tuning BERT classifiers within the DML framework may not be appropriate, we present DoubleLingo, utilizing two faster converging model variations.</p>
<p>BERT+Adapter. Our first configuration utilizes parameter efficient transfer learning in the form of adapters (Houlsby et al., 2019). Thus, instead of fine-tuning all of BERT, we only fine-tune the adapter layers. Here, it's crucial to note that there are no theoretical bounds for the convergence of adapters. While a proof that BERT+Adapter converges at $n^{-1 / 4}$ would be desirable, it is outside the scope of this paper. However, see $\S 5.2$ for an empirical justification.</p>
<p>Embedding+FFN. Fully-connected feedforward neural networks (FFNs) with the ReLU activation function have been proven to converge at $n^{-1 / 4}$ rates for their use in semiparametric inference (Farrell et al., 2021). Thus, instead of fine-tuning BERT at all, a potential approach is to fine-tune a feedforward layer on top of BERT's pre-trained $[C L S]$ encoding. However, this encoding is pre-trained on next sentence prediction which may not necessarily result in a semantically meaningful representation of the sentence. Consequently, we utilize embeddings from pre-trained sentence transformers (Reimers and Gurevych, 2019), which are much more semantically meaningful. While transformer embeddings have been widely influential in many NLP tasks (Ethayarajh, 2019), to our knowledge we are the first to compare their potential for causal estimation against simpler text representations.</p>
<h2>4 Causal Dataset \&amp; Experiment</h2>
<p>Unlike supervised learning models, which can be evaluated on held-out test sets with ground-truth labels, causal estimation methods require evaluations with counterfactual ground-truth, which is impossible to measure from observed data (Holland, 1986). Researchers often turn to (semi-)synthetic data, for which there is a tension between generating realistic text and maintaining full knowledge of the underlying data-generating process (DGP) (WoodDoughty et al., 2021). Most current datasets fail to accomplish both, either fully specifying the DGP but with unrealistic text (Johansson et al., 2016; Yao et al., 2019), or using real-world text inside a semi-synthetic DGP (Veitch et al., 2020).</p>
<h3>4.1 Dataset and Baselines</h3>
<p>A recent novel dataset employs a randomized controlled trial (RCT) rejection sampling algorithm to create datasets with real text that build on a realworld DGP (Keith et al., 2023). In particular, the authors fix $C$ to be a single binary confounding
variable contained in the text and choose RCT's with an existing $C \rightarrow Y$ relationship. They then sample the dataset to artificially create a $C \rightarrow A$ relationship and evaluate 8 different models over 100 sampled dataset subsets. They train Logistic Regression and CatBoost nuisance models based on a BoW representation for the text, combining both with 4 different causal estimation techniques, including IPTW, Augmented-IPTW (AIPTW), Outcome Regression, and DML. They finally evaluate an Oracle with full access to the (otherwise unobserved) $C$ variable. We include their empirical results in our Table 1.</p>
<h3>4.2 DoubleLingo Experiments</h3>
<p>We now describe our methods that use LLMs inside the DML framework. Our BERT+Adapter method fine-tunes adapters within BERT classifiers for both $\widehat{m}<em 0="0">{0}$ and $\widehat{g}</em>$ based on MPNet (Song et al., 2020) and fine-tuned on over 1 billion sentence pairs including paper abstracts from S2ORC (Lo et al., 2020). Second, SPECTER (Cohan et al., 2020), pre-trained on a dataset of scientific paper titles and abstracts which matches the exact format of Keith et al. (2023). For both Embedding+FFN methods, we use a single hidden layer, ReLU activation functions, and the AdamW optimizer (Loshchilov and Hutter, 2018). Finally, we implement a $T F-I D F+F F N$ baseline, following Manzoor et al. (2023), which uses DML with FFNs with batch normalization (Ioffe and Szegedy, 2015) and a TF-IDF text representation. A more detailed implementation, including specific hyper-parameters and RCT parameterization choices are provided in Appendix A.}$ (Houlsby et al., 2019). Our Embedding+FFN configuration uses embeddings from two transformers. First, all-mpnet-base-v2, ${ }^{4</p>
<h2>5 Results and Conclusions</h2>
<h3>5.1 Main Findings</h3>
<p>Table 1 shows that our three DoubleLingo estimators obtain the lowest $A T E$ relative absolute error $(0.103)$, a $10.4 \%$ decrease from the prior best $(0.115)$. These results provide strong empirical evidence that the DML framework successfully enables the use of LLMs in causal estimation. Notably, the prior best was achieved by both a BoW model $\left(\mathrm{CB}_{\text {AIPTW }}\right)$ and the Oracle estimator which calculates the estimates using the unobserved $C$ values. If $C$ contained all causes of $A$ and $Y$, it would</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">LR</th>
<th style="text-align: center;">CB</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Outcome</td>
<td style="text-align: center;">$1.408(1.00)$</td>
<td style="text-align: center;">$0.237(0.10)$</td>
</tr>
<tr>
<td style="text-align: left;">IPTW</td>
<td style="text-align: center;">$0.470(0.16)$</td>
<td style="text-align: center;">$0.141(0.11)$</td>
</tr>
<tr>
<td style="text-align: left;">AIPTW</td>
<td style="text-align: center;">$1.579(0.66)$</td>
<td style="text-align: center;">$0.115(0.10)$</td>
</tr>
<tr>
<td style="text-align: left;">DML</td>
<td style="text-align: center;">$1.899(0.91)$</td>
<td style="text-align: center;">$0.128(0.10)$</td>
</tr>
<tr>
<td style="text-align: left;">BERT+Adapter</td>
<td style="text-align: center;">$0.104(0.08)$</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">MPNetV2+FFN</td>
<td style="text-align: center;">$0.103(0.08)$</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">SPECTER+FFN</td>
<td style="text-align: center;">$0.104(0.08)$</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">TF-IDF+FFN</td>
<td style="text-align: center;">$0.118(0.09)$</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">Unadjusted</td>
<td style="text-align: center;">$0.214(0.08)$</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: left;">Oracle (C)</td>
<td style="text-align: center;">$0.115(0.09)$</td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>Table 1: Relative Absolute Error mean (variance) for all methods over 100 subsets. Oracle, Unadjusted, Logistic Regression (LR), and CatBoost (CB) baselines are from Keith et al. (2023). Oracle and Unadjusted models use Outcome regressions. Our DoubleLingo methods and TF-IDF baseline use DML, as described in $\S 4.2$. Our methods achieve the best (lowest) error and variance.
be the theoretically-optimal efficient adjustment set (Rotnitzky and Smucler, 2020) and the Oracle should - asymptotically - be impossible to outperform. However, while the $C \rightarrow A$ relationship is artificially induced by the sampling procedure of Keith et al. (2023), the authors verified that $C \not Y$ using an odds-ratio test. We hypothesize that the underlying complexity of the $T \rightarrow Y$ relationship is not fully captured by the binary topic $C$, and there exists some $T \rightarrow Y$ relationship. If true, then modeling $T$ allows for more efficient estimation reflected in DoubleLingo's outperformance of the Oracle.</p>
<p>Our results specifically support the hypothesis that the text representation itself matters to causal estimation. Among all DML methods with feedforward classifiers, our Embedding+FFN methods' outperformance of our TF-IDF+FFN baseline shows that better representations can enable lower estimation error. Appendix B also shows our models' slightly better classification accuracy than the $T F-I D F+F F N$ baseline during estimation.</p>
<p>Between our three proposed methods, we see no large differences in performance. This suggests that while the incorporation of LLMs into the estimators is essential, the specific architecture and training setup matters less. However, BERT+Adapter trains two to three times slower than Embedding+FFN. We also see little difference between the two pre-trained embeddings, de-
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Empirical convergence comparison of BERT+Adapter with FFN configurations. We plot the $A T E$ relative absolute error at 4 sample sizes.
spite the similarity of the SPECTER embedding's dataset to that of our evaluation data.</p>
<h3>5.2 Convergence Experiment</h3>
<p>The assumptions of DML require that $\widehat{m}<em 0="0">{0}$ and $\widehat{g}</em>$ rate.}$ must converge at $n^{-1 / 4}$ to enable a $\sqrt{n}$ consistent estimation of $\theta_{0}$. Analysis and proof of BERT+Adapter convergence is left for future work. However, we empirically compare its convergence rate to that of the three FFN configurations which are proven to converge at $n^{-1 / 4}$ (Farrell et al., 2021). Figure 5.2 plots the $A T E$ relative absolute error mean as we increase the available data. Regressing the logarithms of the means against the sample sizes, we obtain rough estimates that BERT+Adapter, MPNetV2+FFN, SPECTER+FFN, and $T F-I D F+F F N$ converge respectively at $\left(n^{-0.57}, n^{-0.64}, n^{-0.67}, n^{-0.56}\right)$, all faster than our desired $n^{-0.25</p>
<h3>5.3 Conclusion</h3>
<p>This work proposes DoubleLingo, a theoretically consistent causal estimator that uses LLM nuisance models inside the DML framework. We show that both adapters and sentence transformers can achieve the lowest estimation error on the best available dataset for evaluating methods that account for text confounding. We release our code which reproduces our results to enable future research. ${ }^{5}$</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h2>Limitations</h2>
<p>The main limitation of our estimation procedure is compute time - training the BERT+Adapter configuration on 100 sampled dataset subsets takes 10 hours parallelized across 2 RTX 8000's, significantly longer than the baseline Linear Regression or CatBoost models. In particular, our model's reliance on sample-splitting and double robustness to obtain a consistent final estimate requires training 4 times as many models per each dataset subset. However, it's important to note that the Embedding+FFN configurations only take a third of the time, yet achieve identical results.</p>
<p>While DML provides solid theoretical grounding for our methods, we have necessarily focused on a specific DAG and dataset. We have assumed that the relationship between $C$ and $T$ is such that DML nuisance models fit to $T$ can control for the confounding effect of $C$. In the dataset released by Keith et al. (2023), this is plausible given the underlying connections between text and topic. In other datasets (e.g., if $T$ were only loosely predictive of $C$ ), additional methods might be necessary to account for measurement error, for example following Kuroki and Pearl (2014).</p>
<p>Additionally, our work only focuses on causal estimation with text-based confounding. Dealing with textual treatments or outcomes is still an open problem in the field (Feder et al., 2022). Finally, we only train on a single English-language dataset; we encourage future work to expand on this by testing other types of text-based RCTs.</p>
<h2>Acknowledgments</h2>
<p>We would like to express our gratitude to the Northwestern WNS Undergraduate Research Fellowship for funding our work through the 2023 McCormick Summer Undergraduate Research Award. We further thank the Northwestern Undergraduate Innovation Fellowship for providing additional financial support. The resources and support from these fellowships have been instrumental in the completion of this research.</p>
<h2>References</h2>
<p>Mahip Acharya, Thomas Kim, and Chenghui Li. 2021. Broad-spectrum antibiotic use and disease progression in early-stage melanoma patients: A retrospective cohort study. Cancers, 13(17).</p>
<p>Chun-Wei Chang, Stephan B Munch, and Chih-hao</p>
<p>Hsieh. 2022. Comments on identifying causal relationships in nonlinear dynamical systems via empirical mode decomposition. Nature communications, 13(1):2860.</p>
<p>Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney Newey, and James Robins. 2018. Double/debiased machine learning for treatment and structural parameters.</p>
<p>Arman Cohan, Sergey Feldman, Iz Beltagy, Doug Downey, and Daniel Weld. 2020. SPECTER: Document-level representation learning using citation-informed transformers. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 2270-2282, Online. Association for Computational Linguistics.</p>
<p>Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171-4186, Minneapolis, Minnesota. Association for Computational Linguistics.</p>
<p>Kawin Ethayarajh. 2019. How contextual are contextualized word representations? comparing the geometry of bert, elmo, and gpt-2 embeddings. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 55-65.</p>
<p>Max H Farrell, Tengyuan Liang, and Sanjog Misra. 2021. Deep neural networks for estimation and inference. Econometrica, 89(1):181-213.</p>
<p>Amir Feder, Katherine A. Keith, Emaad Manzoor, Reid Pryzant, Dhanya Sridhar, Zach Wood-Doughty, Jacob Eisenstein, Justin Grimmer, Roi Reichart, Margaret E. Roberts, Brandon M. Stewart, Victor Veitch, and Diyi Yang. 2022. Causal inference in natural language processing: Estimation, prediction, interpretation and beyond. Transactions of the Association for Computational Linguistics, 10:1138-1158.</p>
<p>Michele Jonsson Funk, Daniel Westreich, Chris Wiesen, Til Stürmer, M. Alan Brookhart, and Marie Davidian. 2011. Doubly Robust Estimation of Causal Effects. American Journal of Epidemiology, 173(7):761-767.</p>
<p>Iryna Gurevych, Michael Kohler, and Gözde Gül Şahin. 2022. On the rate of convergence of a classifier based on a transformer encoder. IEEE Transactions on Information Theory, 68(12):8139-8155.</p>
<p>Miguel Angel Hernán. 2004. A definition of causal effect for epidemiological research. Journal of Epidemiology \&amp; Community Health, 58(4):265-271.</p>
<p>Paul W. Holland. 1986. Statistics and causal inference. Journal of the American Statistical Association, 81(396):945-960.</p>
<p>Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin De Laroussilhe, Andrea Gesmundo, Mona Attariyan, and Sylvain Gelly. 2019. Parameter-efficient transfer learning for nlp. In International Conference on Machine Learning, pages 2790-2799. PMLR.</p>
<p>Sergey Ioffe and Christian Szegedy. 2015. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In Proceedings of the 32nd International Conference on Machine Learning, volume 37 of Proceedings of Machine Learning Research, pages 448-456, Lille, France. PMLR.</p>
<p>Fredrik Johansson, Uri Shalit, and David Sontag. 2016. Learning representations for counterfactual inference. In Proceedings of The 33rd International Conference on Machine Learning, volume 48 of Proceedings of Machine Learning Research, pages 3020-3029, New York, New York, USA. PMLR.</p>
<p>Katherine Keith, David Jensen, and Brendan O'Connor. 2020. Text and causal inference: A review of using text to remove confounding from causal estimates. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 53325344, Online. Association for Computational Linguistics.</p>
<p>Katherine A Keith, Sergey Feldman, David Jurgens, Jonathan Bragg, and Rohit Bhattacharya. 2023. Rct rejection sampling for causal estimation evaluation. Transactions on Machine Learning Research.</p>
<p>Manabu Kuroki and Judea Pearl. 2014. Measurement bias and effect restoration in causal inference. Biometrika, 101(2):423-437.</p>
<p>Kyle Lo, Lucy Lu Wang, Mark Neumann, Rodney Kinney, and Daniel Weld. 2020. S2ORC: The semantic scholar open research corpus. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4969-4983, Online. Association for Computational Linguistics.</p>
<p>Ilya Loshchilov and Frank Hutter. 2018. Decoupled weight decay regularization. In International Conference on Learning Representations.</p>
<p>Emaad Manzoor, George H Chen, Dokyun Lee, and Michael D Smith. 2023. Influence via ethos: On the persuasive power of reputation in deliberation online. Management Science.</p>
<p>Bonan Min, Hayley Ross, Elior Sulem, Amir Pouran Ben Veyseh, Thien Huu Nguyen, Oscar Sainz, Eneko Agirre, Ilana Heintz, and Dan Roth. 2023. Recent advances in natural language processing via large pre-trained language models: A survey. ACM Computing Surveys, 56(2):1-40.</p>
<p>Behnam Neyshabur. 2017. Implicit regularization in deep learning. arXiv preprint arXiv:1709.01953.</p>
<p>Judea Pearl. 2009. Causality. Cambridge university press.</p>
<p>Jonas Peters, Dominik Janzing, and Bernhard Schlkopf. 2017. Elements of Causal Inference: Foundations and Learning Algorithms. The MIT Press.</p>
<p>Alvin Rajkomar, Eyal Oren, Kai Chen, Andrew M Dai, Nissan Hajaj, Michaela Hardt, Peter J Liu, Xiaobing Liu, Jake Marcus, Mimi Sun, et al. 2018. Scalable and accurate deep learning with electronic health records. NPJ digital medicine, 1(1):18.</p>
<p>Nils Reimers and Iryna Gurevych. 2019. SentenceBERT: Sentence embeddings using Siamese BERTnetworks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 3982-3992, Hong Kong, China. Association for Computational Linguistics.</p>
<p>James M Robins, Miguel Angel Hernan, and Babette Brumback. 2000. Marginal structural models and causal inference in epidemiology. Epidemiology, pages 550-560.</p>
<p>S Trent Rosenbloom, Joshua C Denny, Hua Xu, Nancy Lorenzi, William W Stead, and Kevin B Johnson. 2011. Data from clinical notes: a perspective on the tension between structure and flexible documentation. Journal of the American Medical Informatics Association, 18(2):181-186.</p>
<p>Andrea Rotnitzky and Ezequiel Smucler. 2020. Efficient adjustment sets for population average causal treatment effect estimation in graphical models. The Journal of Machine Learning Research, 21(1):76427727 .</p>
<p>Serena Sanna, Natalie R van Zuydam, Anubha Mahajan, Alexander Kurilshikov, Arnau Vich Vila, Urmo Võsa, Zlatan Mujagic, Ad AM Masclee, Daisy MAE Jonkers, Marije Oosting, et al. 2019. Causal relationships among the gut microbiome, short-chain fatty acids and metabolic diseases. Nature genetics, 51(4):600-605.</p>
<p>Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and TieYan Liu. 2020. Mpnet: Masked and permuted pretraining for language understanding. Advances in Neural Information Processing Systems, 33:1685716867 .</p>
<p>Sofia Triantafillou, Vincenzo Lagani, Christina HeinzeDeml, Angelika Schmidt, Jesper Tegner, and Ioannis Tsamardinos. 2017. Predicting causal relationships from biological data: Applying automated causal discovery on mass cytometry data of human immune cells. Scientific reports, 7(1):12724.</p>
<p>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. Advances in neural information processing systems, 30 .</p>
<p>Victor Veitch, Dhanya Sridhar, and David Blei. 2020. Adapting text embeddings for causal inference. In Conference on Uncertainty in Artificial Intelligence, pages 919-928. PMLR.</p>
<p>Zach Wood-Doughty, Ilya Shpitser, and Mark Dredze. 2018. Challenges of using text classifiers for causal inference. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4586-4598, Brussels, Belgium. Association for Computational Linguistics.</p>
<p>Zach Wood-Doughty, Ilya Shpitser, and Mark Dredze. 2021. Generating synthetic text data to evaluate causal inference methods. arXiv preprint arXiv:2102.05638.</p>
<p>Chia-Yi Wu, Chin-Kuo Chang, Debbie Robson, Richard Jackson, Shaw-Ji Chen, Richard D Hayes, and Robert Stewart. 2013. Evaluation of smoking status identification using electronic health records and open-text information in a large mental health case register. PloS one, 8(9):e74262.</p>
<p>Liuyi Yao, Sheng Li, Yaliang Li, Hongfei Xue, Jing Gao, and Aidong Zhang. 2019. On the estimation of treatment effect with text covariates. In Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19, pages 4106-4113. International Joint Conferences on Artificial Intelligence Organization.</p>
<h2>A Implementation</h2>
<p>This section gives a more detailed overview of our implementation, including specific hyperparameter values for both model configurations and parameterization choices of $\mathbb{P}(A \mid C)$ required by the RCT rejection sampling algorithm.</p>
<p>BERT+Adapters. For our BERT adapter configuration, we use a batch size of 128 , the maximum that can fit parallelized across two RTX 8000's. We use default values for beta and weight decay, setting $B_{1}=0.9, B_{2}=0.999, \lambda=0$. We manually optimize for the learning rate and number of epochs based on validation accuracy on a small subset of the 100 datasets, resulting in a learning rate of $3 e-4$ over 5 epochs. Our estimation takes around 10 hours to complete. For the estimation of a single dataset, we suggest practitioners perform a larger search over hyper-parameters, however the use of sample-splitting and doublyrobust estimation requires training 4 times the number of models. Thus, a simple grid-search over just 10 hyper-parameter combinations with 4 -fold cross-validation over 100 dataset seeds would require the training of 16,000 models. Finally, we
use BERT ${ }_{\text {BASE }}$ which has $109,482,240$ parameters, however the use of adapters allows us to only fine-tune 894, 528 parameters.</p>
<p>Embedding+FFN. For all of our FFN configurations, we use the same batch size of 128 and the same default beta and weight decay values. We use a single hidden layer with the same number of nodes as the input layer, equal to 768 for both sentence transformers. Since these FFNs are much quicker to train, we perform a search over the learning rates, ${1 e-5,1 e-4,1 e-3,1 e-2}$, combined with early-stopping for each one of the 100 dataset subsets.</p>
<p>TF-IDF Tokenization For the TF-IDF+FFN baseline, we follow the same tokenization and vocabulary selection procedure as used for BoW by Keith et al. (2023) to allow for a fair comparison. In particular, the text is first preprocessed to remove numbers. We then utilize the following parameters:</p>
<ul>
<li>max_features=2000: The maximum number of features to consider based on term frequency across the corpus.</li>
<li>lowercase=True: Convert all characters to lowercase before tokenizing.</li>
<li>strip_accents="unicode": Remove accents and perform other character normalization during the preprocessing step.</li>
<li>stop_words="english": Exclude common English stop words from the vocabulary.</li>
<li>max_df=0.9: Ignore terms that appear in more than $90 \%$ of the documents.</li>
<li>min_df=5: Ignore terms that appear in fewer than 5 documents.</li>
<li>binary=True: All non-zero term counts are set to 1 .</li>
</ul>
<p>For the remaining parameters unique to TF-IDF (not present for BoW), we use the default sklearn parameters:</p>
<ul>
<li>norm='12': Sum of squares of vector elements is 1 . The cosine similarity between two vectors is their dot product when 12 norm has been applied.</li>
<li>
<p>use_idf=True: Enable inverse-documentfrequency reweighting.</p>
</li>
<li>
<p>smooth_idf=True: Smooth idf weights by adding one to document frequencies, as if an extra document was seen containing every term in the collection exactly once. Prevents zero divisions.</p>
</li>
<li>sublinear_tf=False: Apply sublinear tf scaling, i.e. replace tf with $1+\log (\mathrm{tf})$.</li>
</ul>
<p>RCT parameterization. The RCT rejection sampling algorithm requires practitioners to specify $\mathbb{P}(A \mid C)$. In particular, the authors choose $C$ to be a binary random variable representing the specific text topic. We accordingly utilize the default provided RCT using medicine $(C=0)$ and physics $(C=1)$ articles. Authors then define $\mathbb{P}(A \mid C)$ as follows:</p>
<p>$$
\mathbb{P}(A=1 \mid C)= \begin{cases}\zeta_{0} &amp; \text { if } C=0 \ \zeta_{1} &amp; \text { if } C=1\end{cases}
$$</p>
<p>which is used in sampling the RCT to create an artificial $C \rightarrow A$ effect. We utilize the default choices of $\zeta_{0}=0.85$ and $\zeta_{1}=0.15$ which induce the highest amount of confounding. For a much more thorough explanation, we direct readers to Keith et al. (2023).</p>
<h2>B Nuisance Model Predictive Accuracy</h2>
<table>
<thead>
<tr>
<th style="text-align: left;">Model</th>
<th style="text-align: center;">Accuracy</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">$\widehat{m}_{0}$</td>
<td style="text-align: center;">$\widehat{g}_{0}$</td>
</tr>
<tr>
<td style="text-align: left;">Logistic Regression</td>
<td style="text-align: center;">75.5</td>
<td style="text-align: center;">82.8</td>
</tr>
<tr>
<td style="text-align: left;">CatBoost</td>
<td style="text-align: center;">80.3</td>
<td style="text-align: center;">95.5</td>
</tr>
<tr>
<td style="text-align: left;">TF-IDF+FFN</td>
<td style="text-align: center;">80.6</td>
<td style="text-align: center;">95.3</td>
</tr>
<tr>
<td style="text-align: left;">SPECTER+FFN</td>
<td style="text-align: center;">82.8</td>
<td style="text-align: center;">95.7</td>
</tr>
<tr>
<td style="text-align: left;">MPNetV2+FFN</td>
<td style="text-align: center;">83.2</td>
<td style="text-align: center;">95.7</td>
</tr>
<tr>
<td style="text-align: left;">BERT+Adapter</td>
<td style="text-align: center;">83.2</td>
<td style="text-align: center;">95.7</td>
</tr>
</tbody>
</table>
<p>Table 2: Average Predictive Accuracy over 100 dataset subsets</p>
<p>Specific values for the average predictive accuracy during estimation of all tested nuisance models are provided in Table 2. A similar trend appears compared to causal estimation results in Table 1, where the largest improvement occurs from simply switching to non-linear nuisance models (CatBoost vs. LogisticRegression).</p>
<p>While our three DoubleLingo model configurations achieve the best predictive accuracies $(83.2 \%, 95.7 \%)$, the values are only slightly higher than those for the $T F$-IDF+FFN implementation.</p>
<p>Here, it's important to note that predictive accuracy alone does not directly contribute to a more accurate estimation (Wood-Doughty et al., 2018).</p>
<h2>C Use of Scientific Artifacts \&amp; Licensing</h2>
<p>Our work uses the RCT rejection sampling dataset by Keith et al. (2023). In particular, the dataset is fully in English, containing publicly available paper titles and abstracts. The authors remove any potentially personally identifiable information from the dataset (author names, user ids, user IP addresses, or session ids). The dataset is made publically available for research purposes (apache-2.0).</p>
<p>Finally, DoubleLingo uses the Hugging Face implementations for bert-base-uncased, allenai/specter, and all-mpnet-base-v2, all made publically available for research purposes (apache-2.0).</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{5}$ https://github.com/markov24/DoubleLingo&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>