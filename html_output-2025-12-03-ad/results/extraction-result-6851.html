<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6851 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6851</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6851</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-132.html">extraction-schema-132</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <p><strong>Paper ID:</strong> paper-cefe4223b4e6ebed686fd1dc9a52bcc4cb656cfd</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/cefe4223b4e6ebed686fd1dc9a52bcc4cb656cfd" target="_blank">Large language models, physics-based modeling, experimental measurements: the trinity of data-scarce learning of polymer properties</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> This work empirically demonstrate that supervised pretraining is vital to obtaining accurate finetuned LLMs, via the lens of learning polymer flammability metrics where cone calorimeter data is sparse, and presents a physics-based training pipeline that tackles the pathology of data scarcity.</p>
                <p><strong>Paper Abstract:</strong> Large language models (LLMs) bear promise as a fast and accurate material modeling paradigm for evaluation, analysis, and design. Their vast number of trainable parameters necessitates a wealth of data to achieve accuracy and mitigate overfitting. However, experimental measurements are often limited and costly to obtain in sufficient quantities for finetuning. To this end, we present a physics-based training pipeline that tackles the pathology of data scarcity. The core enabler is a physics-based modeling framework that generates a multitude of synthetic data to align the LLM to a physically consistent initial state before finetuning. Our framework features a two-phase training strategy: (1) utilizing the large-in-amount while less accurate synthetic data for supervised pretraining, and (2) finetuning the phase-1 model with limited experimental data. We empirically demonstrate that supervised pretraining is vital to obtaining accurate finetuned LLMs, via the lens of learning polymer flammability metrics where cone calorimeter data is sparse.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6851.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6851.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MoLFormer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MoLFormer (pretrained molecular transformer)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A pretrained chemical language transformer (linear attention, rotary positional embeddings) used in this work as the LLM backbone to map canonical SMILES polymer representations to thermophysical and flammability targets via supervised pretraining on physics-based synthetic data and finetuning on scarce experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>MoLFormer</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>encoder transformer (pretrained chemical language model); modified decoder for regression/classification</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>not specified in paper</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Pretrained on ~1.1 billion unlabeled SMILES from PubChem and ZINC (from MolFormer pretraining corpus); in this work further supervised-pretrained on physics-based synthetic polymer data (SMILES -> FDS outputs) and finetuned on small experimental sets.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Not used to generate molecules; used for supervised regression/classification (direct fine-tuning / supervised pretraining). Pretraining: supervised on synthetic FDS-labeled polymers; Phase-2: finetuning on limited experimental data.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>Canonical SMILES (polymer notation with '*' for polymerization point; copolymers as monomer SMILES separated by '.')</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Polymer property prediction and polymer flammability assessment (time to ignition t_ig, peak heat release rate pHRR); thermophysical properties: density (ρ), thermal conductivity (κ), specific heat (c_p).</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>Training-stage constraints: pre-classification to exclude 'un-ignitable' polymers (t_ig = 600 s constant and very small pHRR) for supervised pretraining; relative-MSE loss emphasizing low-flammability polymers during finetuning.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Used together with physics-based synthetic-data pipeline: group-contribution (GC) estimates, Random Forest Regressors (to map GC outputs to some pyrolysis parameters), Fire Dynamics Simulator (FDS) high-fidelity and a reduced-order model (ROM) for rapid synthetic label generation, and Probabilistic Collocation Method (PCM) for UQ.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>Pretraining corpus (PubChem and ZINC) from MolFormer original pretraining; in-work datasets: 3237 synthetic cone-cal calorimeter outputs (FDS), PolyInfo datasets for ρ (1032 points), κ (110), c_p (243), literature pyrolysis kinetics (88 points), experimental cone calorimeter: t_ig & pHRR (45 points), SEA (38 points).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Relative mean squared error (relative MSE) for regression; binary cross-entropy for ignitability classifier; R^2 reported for the Random Forest regressors used inside pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Thermophysical MoLFormer test relative MSEs: density 3.27%, thermal conductivity 16.35%, specific heat 5.82%. Phase-1 supervised-pretraining (on synthetic ignitable set, split 1900 train / 469 test): t_ig train/test rel. MSE 4.40% / 9.60%; pHRR train/test rel. MSE 3.58% / 6.68%. Phase-2 (two-phase) final MoLFormers (best models): train rel. MSE 11.92% (t_ig) and 11.72% (pHRR); test rel. MSE 23.71% (t_ig) and 33.86% (pHRR); per-sample errors reported 13.49% (t_ig) and 14.67% (pHRR). Baseline (trained only on small experimental data) per-sample errors: 27.67% (t_ig) and 61.52% (pHRR). The two-phase approach reduced test errors by ~25.6% (t_ig) and ~51.2% (pHRR) relative to the baseline and per-sample errors by ~51.2% and ~76.2%, respectively.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Requires substantial synthetic data to align large model parameters before finetuning; model size unspecified and thus computational/finetuning cost unclear; possible bias from focusing on ignitable subset; relative-MSE loss biases toward low-flammability polymers (larger errors at high pHRR/SEA); synthetic labels are low-fidelity (GC and ROM approximations) requiring correction by scarce experimental data.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large language models, physics-based modeling, experimental measurements: the trinity of data-scarce learning of polymer properties', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6851.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6851.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Group Contribution (GC) polymer generation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Physics-based Group Contribution (GC) hypothetical polymer generation (Lyon et al. GC method)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A physics-grounded combinatorial generation method that assembles molar groups into structurally admissible hypothetical polymers and provides low-fidelity estimates of pyrolysis kinetic parameters (heat release capacity η_c, heat of combustion h_c, char fraction μ) used as inputs to downstream regressors and FDS.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Group Contribution (Lyon GC variant)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>physics-based group-contribution estimator / combinatorial generator (not an LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>not applicable</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>GC contributions obtained from literature (Lyon et al.) based on 38 molar groups; GC itself uses fitted group-contribution coefficients from prior datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Combinatorial sampling of molar groups (sampled groups with two open valences; assembled up to three-group combinations) to produce structurally valid polymer repeating units; each generated polymer labeled by GC-predicted properties.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>Canonical SMILES for the generated repeating unit using polymer SMILES conventions ('*' polymerization point, '.' for copolymers).</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Create a large set of physically meaningful hypothetical polymers for LLM supervised pretraining and downstream polymer flammability prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>Post-generation filtering to remove nonphysical instances: retain only compounds with μ < 1, h_c < 50 (kJ/g), η_c > 0, and 1 < dT < 300 (K). Sampled up to three-group combinations; final synthetic set size 3237.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>GC outputs used as inputs to Random Forest regressors (to obtain dT and T_p) and thermophysical predictors (MoLFormer models) to assemble full FDS input parameter sets; then FDS/ROM used to simulate cone calorimeter outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>GC group definitions and contribution coefficients from Lyon and related literature; no external molecule-generation LLM used here.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Filtering criteria (physical plausibility); uncertainty quantification of propagated errors via PCM; validation against available experimental polymers (PE and POM) by comparing experimental cone calorimeter outputs with synthetic trust regions.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Generated 3237 physically meaningful hypothetical polymers; after filtering 3237 remained; 2369 were classified as ignitable (t_ig ≤ 600 s) and used for supervised pretraining (split 1900 train / 469 test). GC-derived inputs (μ, h_c, η_c) used to produce FDS synthetic outputs t_ig and pHRR covering ranges: t_ig [20.2, 600] s and pHRR [0.117, 1864.828] kW/m^2.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>GC is low-fidelity and introduces systematic errors; requires learned mappings (RFRs) for some parameters (dT, T_p); uncertainties in GC propagate through FDS; GC cannot guarantee chemical synthesizability or real-world physicality beyond group-level approximations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large language models, physics-based modeling, experimental measurements: the trinity of data-scarce learning of polymer properties', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6851.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6851.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Prior fragment-assembly generation (PolyBERT-style mention)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Random fragment-assembly hypothetical polymer generation (prior work referenced: Kuenneth & Ramprasad, 'polybert')</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Prior reported approach that decomposes existing polymers into fragments and randomly reassembles them to create hypothetical polymers for unsupervised pretraining of chemical language models; mentioned as baseline prior art and criticized for not guaranteeing physical meaningfulness or property-label coupling.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>polybert: a chemical language model to enable fully machine-driven ultrafast polymer informatics</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Not detailed in this paper; referenced prior work decomposes polymers into fragments from real datasets and assembles them into hypothetical compounds (unsupervised pretraining corpora).</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Fragment decomposition and random recombination of fragments to create hypothetical polymers (unsupervised synthetic data generation).</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>Likely SMILES/fragments (not specified in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Pretraining chemical language models for polymer property prediction and polymer informatics.</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>Not detailed here; prior approach noted as lacking checks for physical meaningfulness or property label coupling.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Not specified in this paper (mentioned as prior work).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>Not specified in this paper; reference points to polymer datasets used in prior work.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Not specified here (only mentioned qualitatively).</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Paper notes that fragment-random-assembly methods may produce polymers of uncertain physical realism and cannot be directly correlated to fundamental physical properties needed for physics-based simulation labels; thus they may be less suitable for supervised pretraining when physical labels are needed.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large language models, physics-based modeling, experimental measurements: the trinity of data-scarce learning of polymer properties', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6851.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6851.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FDS + ROM (fire simulation pipeline)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Fire Dynamics Simulator (FDS) high-fidelity model and reduced-order model (ROM) used for synthetic label generation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A coupled high-fidelity CFD-based FDS model (solid + gas phases) validated against experimental cone calorimeter data, and a computationally cheap ROM (solid-phase with step heat-flux correction) used to rapidly generate synthetic cone-calorimeter metrics (t_ig, pHRR) for thousands of hypothetical polymers.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Fire Dynamics Simulator (FDS) and a derived reduced-order model (ROM)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>physics-based CFD simulator (FDS) and simplified reduced-order solid-phase simulator (ROM)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>not applicable</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>High-fidelity FDS validated against available polymer cone calorimeter experiments; ROM calibrated to reproduce high-fidelity outputs with large speed-up.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Numerical simulation of cone calorimeter experiments using FDS for selected inputs; ROM (solid-phase + step increase in heat flux post-ignition) used to produce many synthetic runs in seconds each.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>Input parameters to FDS derived from SMILES via GC + RFR + MoLFormer-predicted thermophysical properties; not direct molecule strings inside FDS.</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Generate labeled synthetic dataset of cone calorimeter outputs (time-to-ignition, peak heat release rate) for supervised LLM pretraining.</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>Input parameter distributions modeled as Gaussian (additive i.i.d. noise) except μ (log-normal) for UQ; retained only physically plausible GC outputs per filtering rules described.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>FDS/ROM integrated into pipeline downstream of GC, Random Forest regressors, and MoLFormer thermophysical predictors; PCM used to propagate input uncertainty to outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>Used to generate synthetic cone-cal outputs for 3237 hypothetical polymers (t_ig and pHRR ranges reported); high-fidelity validation against literature experimental cone calorimeter measurements (45 samples).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Comparison to experimental data; uncertainty quantification via Probabilistic Collocation Method (PCM); used synthetic outputs as supervised labels for LLM pretraining and evaluated LLM via relative MSE against experimental labels.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>High-fidelity FDS runtime: ~1–4 hours per simulation; ROM runtime: seconds per run; ROM produces synthetic t_ig range [20.2,600] s and pHRR [0.117,1864.828] kW/m^2 for the synthetic set. PCM used to produce trust regions; examples (PE, POM) experimental values lie within/near computed trust regions.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>High-fidelity FDS is computationally expensive; ROM approximations and GC/RFR input errors lead to label noise that must be corrected via finetuning; FDS could not generate synthetic SEA in this work (smoke metric), noted as a limitation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large language models, physics-based modeling, experimental measurements: the trinity of data-scarce learning of polymer properties', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Large-scale chemical language representations capture molecular structure and properties <em>(Rating: 2)</em></li>
                <li>polybert: a chemical language model to enable fully machine-driven ultrafast polymer informatics <em>(Rating: 2)</em></li>
                <li>Transpolymer: a transformer-based language model for polymer property predictions <em>(Rating: 2)</em></li>
                <li>MolFormer: Motif-based transformer on 3D heterogeneous molecular graphs <em>(Rating: 2)</em></li>
                <li>gp-molformer: A foundation model for molecular generation <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6851",
    "paper_id": "paper-cefe4223b4e6ebed686fd1dc9a52bcc4cb656cfd",
    "extraction_schema_id": "extraction-schema-132",
    "extracted_data": [
        {
            "name_short": "MoLFormer",
            "name_full": "MoLFormer (pretrained molecular transformer)",
            "brief_description": "A pretrained chemical language transformer (linear attention, rotary positional embeddings) used in this work as the LLM backbone to map canonical SMILES polymer representations to thermophysical and flammability targets via supervised pretraining on physics-based synthetic data and finetuning on scarce experiments.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "MoLFormer",
            "model_type": "encoder transformer (pretrained chemical language model); modified decoder for regression/classification",
            "model_size": "not specified in paper",
            "training_data_description": "Pretrained on ~1.1 billion unlabeled SMILES from PubChem and ZINC (from MolFormer pretraining corpus); in this work further supervised-pretrained on physics-based synthetic polymer data (SMILES -&gt; FDS outputs) and finetuned on small experimental sets.",
            "generation_method": "Not used to generate molecules; used for supervised regression/classification (direct fine-tuning / supervised pretraining). Pretraining: supervised on synthetic FDS-labeled polymers; Phase-2: finetuning on limited experimental data.",
            "chemical_representation": "Canonical SMILES (polymer notation with '*' for polymerization point; copolymers as monomer SMILES separated by '.')",
            "target_application": "Polymer property prediction and polymer flammability assessment (time to ignition t_ig, peak heat release rate pHRR); thermophysical properties: density (ρ), thermal conductivity (κ), specific heat (c_p).",
            "constraints_used": "Training-stage constraints: pre-classification to exclude 'un-ignitable' polymers (t_ig = 600 s constant and very small pHRR) for supervised pretraining; relative-MSE loss emphasizing low-flammability polymers during finetuning.",
            "integration_with_external_tools": "Used together with physics-based synthetic-data pipeline: group-contribution (GC) estimates, Random Forest Regressors (to map GC outputs to some pyrolysis parameters), Fire Dynamics Simulator (FDS) high-fidelity and a reduced-order model (ROM) for rapid synthetic label generation, and Probabilistic Collocation Method (PCM) for UQ.",
            "dataset_used": "Pretraining corpus (PubChem and ZINC) from MolFormer original pretraining; in-work datasets: 3237 synthetic cone-cal calorimeter outputs (FDS), PolyInfo datasets for ρ (1032 points), κ (110), c_p (243), literature pyrolysis kinetics (88 points), experimental cone calorimeter: t_ig & pHRR (45 points), SEA (38 points).",
            "evaluation_metrics": "Relative mean squared error (relative MSE) for regression; binary cross-entropy for ignitability classifier; R^2 reported for the Random Forest regressors used inside pipeline.",
            "reported_results": "Thermophysical MoLFormer test relative MSEs: density 3.27%, thermal conductivity 16.35%, specific heat 5.82%. Phase-1 supervised-pretraining (on synthetic ignitable set, split 1900 train / 469 test): t_ig train/test rel. MSE 4.40% / 9.60%; pHRR train/test rel. MSE 3.58% / 6.68%. Phase-2 (two-phase) final MoLFormers (best models): train rel. MSE 11.92% (t_ig) and 11.72% (pHRR); test rel. MSE 23.71% (t_ig) and 33.86% (pHRR); per-sample errors reported 13.49% (t_ig) and 14.67% (pHRR). Baseline (trained only on small experimental data) per-sample errors: 27.67% (t_ig) and 61.52% (pHRR). The two-phase approach reduced test errors by ~25.6% (t_ig) and ~51.2% (pHRR) relative to the baseline and per-sample errors by ~51.2% and ~76.2%, respectively.",
            "experimental_validation": false,
            "challenges_or_limitations": "Requires substantial synthetic data to align large model parameters before finetuning; model size unspecified and thus computational/finetuning cost unclear; possible bias from focusing on ignitable subset; relative-MSE loss biases toward low-flammability polymers (larger errors at high pHRR/SEA); synthetic labels are low-fidelity (GC and ROM approximations) requiring correction by scarce experimental data.",
            "uuid": "e6851.0",
            "source_info": {
                "paper_title": "Large language models, physics-based modeling, experimental measurements: the trinity of data-scarce learning of polymer properties",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "Group Contribution (GC) polymer generation",
            "name_full": "Physics-based Group Contribution (GC) hypothetical polymer generation (Lyon et al. GC method)",
            "brief_description": "A physics-grounded combinatorial generation method that assembles molar groups into structurally admissible hypothetical polymers and provides low-fidelity estimates of pyrolysis kinetic parameters (heat release capacity η_c, heat of combustion h_c, char fraction μ) used as inputs to downstream regressors and FDS.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Group Contribution (Lyon GC variant)",
            "model_type": "physics-based group-contribution estimator / combinatorial generator (not an LLM)",
            "model_size": "not applicable",
            "training_data_description": "GC contributions obtained from literature (Lyon et al.) based on 38 molar groups; GC itself uses fitted group-contribution coefficients from prior datasets.",
            "generation_method": "Combinatorial sampling of molar groups (sampled groups with two open valences; assembled up to three-group combinations) to produce structurally valid polymer repeating units; each generated polymer labeled by GC-predicted properties.",
            "chemical_representation": "Canonical SMILES for the generated repeating unit using polymer SMILES conventions ('*' polymerization point, '.' for copolymers).",
            "target_application": "Create a large set of physically meaningful hypothetical polymers for LLM supervised pretraining and downstream polymer flammability prediction.",
            "constraints_used": "Post-generation filtering to remove nonphysical instances: retain only compounds with μ &lt; 1, h_c &lt; 50 (kJ/g), η_c &gt; 0, and 1 &lt; dT &lt; 300 (K). Sampled up to three-group combinations; final synthetic set size 3237.",
            "integration_with_external_tools": "GC outputs used as inputs to Random Forest regressors (to obtain dT and T_p) and thermophysical predictors (MoLFormer models) to assemble full FDS input parameter sets; then FDS/ROM used to simulate cone calorimeter outputs.",
            "dataset_used": "GC group definitions and contribution coefficients from Lyon and related literature; no external molecule-generation LLM used here.",
            "evaluation_metrics": "Filtering criteria (physical plausibility); uncertainty quantification of propagated errors via PCM; validation against available experimental polymers (PE and POM) by comparing experimental cone calorimeter outputs with synthetic trust regions.",
            "reported_results": "Generated 3237 physically meaningful hypothetical polymers; after filtering 3237 remained; 2369 were classified as ignitable (t_ig ≤ 600 s) and used for supervised pretraining (split 1900 train / 469 test). GC-derived inputs (μ, h_c, η_c) used to produce FDS synthetic outputs t_ig and pHRR covering ranges: t_ig [20.2, 600] s and pHRR [0.117, 1864.828] kW/m^2.",
            "experimental_validation": false,
            "challenges_or_limitations": "GC is low-fidelity and introduces systematic errors; requires learned mappings (RFRs) for some parameters (dT, T_p); uncertainties in GC propagate through FDS; GC cannot guarantee chemical synthesizability or real-world physicality beyond group-level approximations.",
            "uuid": "e6851.1",
            "source_info": {
                "paper_title": "Large language models, physics-based modeling, experimental measurements: the trinity of data-scarce learning of polymer properties",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "Prior fragment-assembly generation (PolyBERT-style mention)",
            "name_full": "Random fragment-assembly hypothetical polymer generation (prior work referenced: Kuenneth & Ramprasad, 'polybert')",
            "brief_description": "Prior reported approach that decomposes existing polymers into fragments and randomly reassembles them to create hypothetical polymers for unsupervised pretraining of chemical language models; mentioned as baseline prior art and criticized for not guaranteeing physical meaningfulness or property-label coupling.",
            "citation_title": "polybert: a chemical language model to enable fully machine-driven ultrafast polymer informatics",
            "mention_or_use": "mention",
            "model_name": "",
            "model_type": "",
            "model_size": "",
            "training_data_description": "Not detailed in this paper; referenced prior work decomposes polymers into fragments from real datasets and assembles them into hypothetical compounds (unsupervised pretraining corpora).",
            "generation_method": "Fragment decomposition and random recombination of fragments to create hypothetical polymers (unsupervised synthetic data generation).",
            "chemical_representation": "Likely SMILES/fragments (not specified in this paper).",
            "target_application": "Pretraining chemical language models for polymer property prediction and polymer informatics.",
            "constraints_used": "Not detailed here; prior approach noted as lacking checks for physical meaningfulness or property label coupling.",
            "integration_with_external_tools": "Not specified in this paper (mentioned as prior work).",
            "dataset_used": "Not specified in this paper; reference points to polymer datasets used in prior work.",
            "evaluation_metrics": "Not specified here (only mentioned qualitatively).",
            "reported_results": "",
            "experimental_validation": null,
            "challenges_or_limitations": "Paper notes that fragment-random-assembly methods may produce polymers of uncertain physical realism and cannot be directly correlated to fundamental physical properties needed for physics-based simulation labels; thus they may be less suitable for supervised pretraining when physical labels are needed.",
            "uuid": "e6851.2",
            "source_info": {
                "paper_title": "Large language models, physics-based modeling, experimental measurements: the trinity of data-scarce learning of polymer properties",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "FDS + ROM (fire simulation pipeline)",
            "name_full": "Fire Dynamics Simulator (FDS) high-fidelity model and reduced-order model (ROM) used for synthetic label generation",
            "brief_description": "A coupled high-fidelity CFD-based FDS model (solid + gas phases) validated against experimental cone calorimeter data, and a computationally cheap ROM (solid-phase with step heat-flux correction) used to rapidly generate synthetic cone-calorimeter metrics (t_ig, pHRR) for thousands of hypothetical polymers.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Fire Dynamics Simulator (FDS) and a derived reduced-order model (ROM)",
            "model_type": "physics-based CFD simulator (FDS) and simplified reduced-order solid-phase simulator (ROM)",
            "model_size": "not applicable",
            "training_data_description": "High-fidelity FDS validated against available polymer cone calorimeter experiments; ROM calibrated to reproduce high-fidelity outputs with large speed-up.",
            "generation_method": "Numerical simulation of cone calorimeter experiments using FDS for selected inputs; ROM (solid-phase + step increase in heat flux post-ignition) used to produce many synthetic runs in seconds each.",
            "chemical_representation": "Input parameters to FDS derived from SMILES via GC + RFR + MoLFormer-predicted thermophysical properties; not direct molecule strings inside FDS.",
            "target_application": "Generate labeled synthetic dataset of cone calorimeter outputs (time-to-ignition, peak heat release rate) for supervised LLM pretraining.",
            "constraints_used": "Input parameter distributions modeled as Gaussian (additive i.i.d. noise) except μ (log-normal) for UQ; retained only physically plausible GC outputs per filtering rules described.",
            "integration_with_external_tools": "FDS/ROM integrated into pipeline downstream of GC, Random Forest regressors, and MoLFormer thermophysical predictors; PCM used to propagate input uncertainty to outputs.",
            "dataset_used": "Used to generate synthetic cone-cal outputs for 3237 hypothetical polymers (t_ig and pHRR ranges reported); high-fidelity validation against literature experimental cone calorimeter measurements (45 samples).",
            "evaluation_metrics": "Comparison to experimental data; uncertainty quantification via Probabilistic Collocation Method (PCM); used synthetic outputs as supervised labels for LLM pretraining and evaluated LLM via relative MSE against experimental labels.",
            "reported_results": "High-fidelity FDS runtime: ~1–4 hours per simulation; ROM runtime: seconds per run; ROM produces synthetic t_ig range [20.2,600] s and pHRR [0.117,1864.828] kW/m^2 for the synthetic set. PCM used to produce trust regions; examples (PE, POM) experimental values lie within/near computed trust regions.",
            "experimental_validation": true,
            "challenges_or_limitations": "High-fidelity FDS is computationally expensive; ROM approximations and GC/RFR input errors lead to label noise that must be corrected via finetuning; FDS could not generate synthetic SEA in this work (smoke metric), noted as a limitation.",
            "uuid": "e6851.3",
            "source_info": {
                "paper_title": "Large language models, physics-based modeling, experimental measurements: the trinity of data-scarce learning of polymer properties",
                "publication_date_yy_mm": "2024-07"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Large-scale chemical language representations capture molecular structure and properties",
            "rating": 2,
            "sanitized_title": "largescale_chemical_language_representations_capture_molecular_structure_and_properties"
        },
        {
            "paper_title": "polybert: a chemical language model to enable fully machine-driven ultrafast polymer informatics",
            "rating": 2,
            "sanitized_title": "polybert_a_chemical_language_model_to_enable_fully_machinedriven_ultrafast_polymer_informatics"
        },
        {
            "paper_title": "Transpolymer: a transformer-based language model for polymer property predictions",
            "rating": 2,
            "sanitized_title": "transpolymer_a_transformerbased_language_model_for_polymer_property_predictions"
        },
        {
            "paper_title": "MolFormer: Motif-based transformer on 3D heterogeneous molecular graphs",
            "rating": 2,
            "sanitized_title": "molformer_motifbased_transformer_on_3d_heterogeneous_molecular_graphs"
        },
        {
            "paper_title": "gp-molformer: A foundation model for molecular generation",
            "rating": 1,
            "sanitized_title": "gpmolformer_a_foundation_model_for_molecular_generation"
        }
    ],
    "cost": 0.014515499999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Large language models, physics-based modeling, experimental measurements: the trinity of data-scarce learning of polymer properties</h1>
<p>Ning Liu ${ }^{\mathrm{a}}$, Siavash Jafarzadeh ${ }^{\mathrm{b}}$, Brian Y. Lattimer ${ }^{\mathrm{c}}$, Shuna $\mathrm{Ni}^{\mathrm{d}}$, Jim Lua ${ }^{\mathrm{a}}$, Yue Yu ${ }^{\mathrm{b}, *}$<br>${ }^{a}$ Global Engineering and Materials, Inc., Princeton, NJ 08540, USA<br>${ }^{b}$ Department of Mathematics, Lehigh University, Bethlehem, PA 18015, USA<br>${ }^{c}$ Department of Mechanical Engineering, Virginia Tech, Blacksburg, VA 24060, USA<br>${ }^{d}$ Department of Fire Protection Engineering, University of Maryland, College Park, MD 20742, USA</p>
<h4>Abstract</h4>
<p>Large language models (LLMs) bear promise as a fast and accurate material modeling paradigm for evaluation, analysis, and design. Their vast number of trainable parameters necessitates a wealth of data to achieve accuracy and mitigate overfitting. However, experimental measurements are often limited and costly to obtain in sufficient quantities for finetuning. To this end, we present a physics-based training pipeline that tackles the pathology of data scarcity. The core enabler is a physics-based modeling framework that generates a multitude of synthetic data to align the LLM to a physically consistent initial state before finetuning. Our framework features a two-phase training strategy: (1) utilizing the large-in-amount while less accurate synthetic data for supervised pretraining, and (2) finetuning the phase-1 model with limited experimental data. We empirically demonstrate that supervised pretraining is vital to obtaining accurate finetuned LLMs, via the lens of learning polymer flammability metrics where cone calorimeter data is sparse.</p>
<h2>1. Introduction</h2>
<p>Hundreds of millions of tons of polymer materials have been crafted for use in a colossal and everexpanding array of applications with unceasing novel material demands, spanning automotive and ship components [1], consumer packaging [2], fabrics [3], solar cells [4], etc. The quest for qualified polymer materials for specific applications hinges on the precise prediction of their properties, driving the need for swift and accurate assessment methods. In this pursuit, machine learning (ML) based models [5-8] have emerged as a promising platform that empowers more rapid and precise polymer property prediction compared to state-of-the-art analytical and numerical methods (e.g., density functional theory [9, 10]). In particular, a variety of supervised learning methods such as graph-based neural models [11-13] have excelled in predicting polymer property tasks, largely attributed to their awareness and explicit encoding of the underlying chemical topology. Nevertheless, the vast chemical space, together with the generally restricted availability of polymer property labels, has made supervised learning cumbersome. This, in turn, has fostered the necessity for generalizable molecular representation learning and further sparked the exploitation in the</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>use of attention-based large language models (LLMs) [14-16] for polymer property prediction, where one can simply convert the intricate chemical structure to a compact string representation termed Simplified Molecular-Input Line Entry System (SMILES) [17-21]. SMILES is essentially equivalent to a flattening of the chemical graph via a depth-first pre-order traversal of the spanning tree structure, and it thereby encodes the molecular graph in an implicit manner. Applying LLMs to polymer property prediction thus amounts to a chemical language learning task where the LLM endeavors to grasp the semantic and syntactic rules of the molecular structure leveraging various unsupervised learning schemes such as masked language modeling. The pretrained LLMs, akin to chemical linguists, can then be applied for downstream tasks via finetuning using labeled data [22-26]. Pioneering work [14-16] has demonstrated the exceptional power of LLMs in predicting polymer properties and the correct geometrical interpretation of the spatial connectivity across substructures in a molecule.</p>
<p>On the other hand, although LLMs are powerful in aiding material assessment and novel design, the current application of LLMs resorts to directly finetuning a previously pretrained LLM with (likely limited) labeled data for downstream applications [15, 16]. This task poses grand challenge, as the vast number of trainable parameters in LLMs (in the order of tens of millions [27]) necessitates a substantial amount of experimental data to finetune the LLM in order to reach a desired level of accuracy. However, this is generally infeasible in many material design and assessment tasks, where conducting a large set of experiments is either prohibitively expensive or simply unfeasible. In this context, it calls for a highly effective training method to finetune LLMs with only a handful of experimental data.</p>
<p>A natural pathway to overcome this dilemma is to generate a large amount of synthetic data to pretrain the LLM, either in a supervised or unsupervised manner. Prior work [15] has explored decomposing existing polymers into chemical fragments [28], followed by randomly assembling these fragments to yield hypothetical polymers. While this method shows promise in pretraining the underlying LLM in an unsupervised manner, it is hard to judge whether the generated hypothetical polymers are physically meaningful, nor can these plausible polymers be correlated with any fundamental properties instrumental in constructing a physicsbased simulation model or finetuning the final LLM decoder. In contrast, we take a different approach and investigate to incorporate physical knowledge into the synthetic polymer generation process. Specifically, we design a hypothetical polymer generation method grounded on physics-based group contribution (GC) [29], based on which a variety of fundamental material properties such as the heat of combustion and heat capacity can be calculated. These computed fundamental properties can further be used to either finetune a decoder for direct downstream applications or serve as inputs to a numerical model of the physical asset to generate a large dataset of quantities of interest. An overview of the proposed trinity framework is illustrated in Figure 1.</p>
<p>Besides the superiority in generating physically meaningful polymers, we show for the first time that, by simultaneously pretraining the encoder and decoder of the pretrained LLMs with physics-based synthetic data, the resulting LLMs inherit a better prior from GC, thereby achieving high predictability even in</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: An overview of the proposed trinity framework for data-scarce learning of LLMs.
cases where experimental data is extremely limited. We then put forward a simple yet effective two-phase prediction-correction training strategy for finetuning pretrained LLMs towards polymer property prediction. In phase 1, we implicitly impose the physical knowledge from GC by training the encoder and decoder of pretrained LLMs using (possibly low-fidelity) physics-based synthetic data. As a result, the encoder and decoder parameters arrive at a physically consistent initial state. We then start from this initial state in phase 2 and further finetune the LLM with limited but most accurate experimental data. Analogous to pretraining the encoder of LLMs where one aims to train the encoder to learn the syntactical and grammatical rules of the underlying language [30], the rationale behind the first phase is to pretrain the encoder and decoder to understand the physical rules governing the underlying chemical formation of polymers, through a data-driven process fused with physics-based synthetic data. To distinguish our phase-1 pretraining from the unsupervised pretraining of LLM encoders, we term it supervised pretraining. In phase 2, the limited experimental data is leveraged to mitigate the effect of numerical errors and simplified assumptions intrinsically inherited from the simulation model and maximize prediction accuracy.</p>
<p>Our main contributions are:</p>
<ul>
<li>We propose a pathway that allows the generation of a large dataset of physically meaningful hypothetical polymers for LLM pretraining, anchored on the foundation of a physics-based GC with which a variety of fundamental properties can be correlated with the generated polymers.</li>
<li>We put forth a physics-based modeling framework, leveraging on the fundamental properties obtained from GC as model input and efficiently producing a large amount of synthetic data.</li>
<li>We design a two-phase prediction-correction training strategy for finetuning LLMs in scientific prob-</li>
</ul>
<p>lems in the absence of sufficient ground truth data, where the first phase applies supervised pretraining to the encoder and decoder using the generated (possibly less accurate) synthetic dataset, and the second phase employs the limited but most accurate experimental measurements for final finetuning/correction.</p>
<ul>
<li>Interlocking the three pillars of LLMs, physics-based modeling and experimental measurements, we demonstrate the proposed trinity framework via the lens of learning polymer flammability metrics [3134], where cone calorimeter data is limited to dozens, and show that, by supervisedly pretraining the LLM with synthetic data, the model's prediction accuracy can be effectively improved by more than $50 \%$.</li>
</ul>
<p>To the authors' best knowledge, the present work represents the first attempt that explores the generation of physically meaningful synthetic polymers for supervised pretraining of LLMs. Together with the two-phase training strategy, we present not only an effective approach that makes the best use of limited labeled data, but also, more importantly, a comprehensive LLM learning framework applicable to a broad range of scientific problems.</p>
<h1>2. Results</h1>
<h2>Physically meaningful hypothetical polymer generation</h2>
<p>We generate a set of structurally valid and physically meaningful hypothetical polymers based on GC $[29,35,36]$ (cf. the "Methods" section). The method provides a list of groups, their contributions to a variety of physical properties, and a relationship that estimates the compound's properties from the contributing groups. To estimate a property for a compound, one typically identifies the constituent sub-molecule groups from the list and uses their contributions and the relationship to obtain an estimation. In this work, we exploit a method to generate labeled hypothetical polymers. The idea is to use various admissible combinations between groups to construct new compounds and use (4.1) to label them with associated pyrolysis kinetic parameters. An admissible combination refers to a selection of groups that can form a structurally valid polymer compound (i.e., without open valences except at polymerization points). In the current study, we sample groups with two open valences and obtain unique combinations for up to three groups, which results in a total of 3237 hypothetical polymers. Figure 2 demonstrates the formation of physically admissible polymers from constituent groups and the process of obtaining estimations for the associated pyrolysis properties.</p>
<h2>Physics-based modeling and synthetic data generation</h2>
<p>To generate adequate synthetic data for supervised pretraining of LLMs, a numerically accurate and computationally efficient model of the physical process needs to be constructed. In the instantiation to assessing the fire performance of polymers, we adopt the state-of-the-art fire simulation toolkit, Fire Dynamics Simulator (FDS) [37], to emulate the cone calorimeter test and predict polymer flammability metrics such as the time to ignition $t_{\text {ig }}$ and the peak heat release rate per unit area pHRR. A brief introduction of the</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Using group contribution to generate structurally admissible hypothetical polymers with physically meaningful material properties.</p>
<p>cone calorimeter test, FDS and our modeling strategy is provided in the "Methods" section. In this context, our goal is to first build a high-fidelity FDS model that correctly simulates the thermal decomposition process of polymers and the accompanied pyrolysis gas generation that further fuels the fire. With the correct physics being captured, we can then build a reduced-order model (ROM) for rapid data generation via either simplifying the high-fidelity model or ML.</p>
<p>A demonstration of the workflow for physically meaningful synthetic data generation can be found in Figure 3. To simulate the cone calorimeter process in FDS, several material properties need to be defined, including thermophysical properties like density <em>ρ</em>, thermal conductivity <em>κ</em> and specific heat <em>c<sub>p</sub></em>, and kinetic pyrolysis parameters like heat release capacity <em>η<sub>c</sub></em>, heat of combustion <em>h<sub>c</sub></em>, char fraction <em>µ</em>, the temperature range of pyrolysis <em>dT</em>, and the temperature at peak mass loss rate <em>T<sub>p</sub></em>. Through GC for physically meaningful hypothetical polymer generation, the kinetic pyrolysis parameters of <em>η<sub>c</sub></em>, <em>h<sub>c</sub></em> and <em>µ</em> are implicitly correlated. By further assuming single reaction, the temperature range of pyrolysis <em>dT</em> is dependent on <em>η<sub>c</sub></em> and <em>h<sub>c</sub></em>, however without an explicit algebraic connection [29]. Additionally, previous work [29] has shown that the temperature at peak mass loss rate <em>T<sub>p</sub></em> is a function of <em>η<sub>c</sub></em>, <em>h<sub>c</sub></em>, and <em>dT</em>. We therefore employ two random forest regressors (RFRs) to learn these relationships, one from (<em>η<sub>c</sub></em>, <em>h<sub>c</sub></em>) to <em>dT</em> and the other from (<em>η<sub>c</sub></em>, <em>h<sub>c</sub></em>, <em>dT</em>) to <em>T<sub>p</sub></em>. The two trained RFRs reach a <em>R<sup>2</sup></em> accuracy of 0.99/0.92 and 0.99/0.88 for training/testing, respectively. Note that GC is a low-fidelity method and can only provide estimates. To improve the quality of the synthetic labeled data, we filter out nonphysical instances. In particular, we only keep the compounds with <em>µ</em> &lt; 1, <em>h<sub>c</sub></em> &lt; 50, <em>η<sub>c</sub></em> &gt; 0, and 1 &lt; <em>dT</em> &lt; 300 and discard otherwise. After filtering, we come in possession of 3237 physically meaningful hypothetical polymers labeled with their kinetic pyrolysis parameters.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Demonstration of the synthetic data generation workflow.</p>
<p>On the other hand, since the thermophysical properties are relatively more available, we resort to the online polymer database, PolyInfo [38], to build three training datasets for density $\rho$, thermal conductivity $\kappa$ and specific heat $c_{p}$, covering various polymer types including homopolymers and copolymers. A summary of the employed datasets is listed in Table 1. With these three datasets, we take the SMILES representations of polymers as input and train three large chemical language models to predict $\rho, \kappa$ and $c_{p}$, respectively. Although the proposed framework is model-agnostic, in this work we employ MoLFormer [14, 22], an opensource pretrained molecular transformer, for demonstration. We report the test errors in terms of the relative mean squared error (MSE), and the best MoLFormers obtain $3.27 \%, 16.35 \%$, and $5.82 \%$ for $\rho, \kappa$ and $c_{p}$, respectively. Note that only the density dataset is randomly split into $932 / 100$ for training and testing, respectively. Due to the relatively small datasets for $\kappa$ and $c_{p}$ and the good coverage of polymer types, we use all the data for training and only use the homopolymer data for testing, so as to get an accurate model for interpolation without considerably compromising generalizability. Leveraging GC, two RFRs and three MoLFormers, all the needed FDS input parameters can be computed.</p>
<p>With the above capability to define the input parameters for FDS, we subsequently build a high-fidelity FDS model to simulate cone calorimeter tests at a constant heat flux exposure of $50 \mathrm{~kW} / \mathrm{m}^{2}$, taking into</p>
<p>account the full solid and gas phases of the process. This model, albeit validated against available polymer cone calorimeter data and showed high accuracy [39], is computationally slow in that it takes 1-4 hours to run one simulation. We then simplify the model by only considering the solid phase of the decomposition process with an additional simulation that includes a step increase in the heat flux of $25 \mathrm{~kW} / \mathrm{m}^{2}$ after ignition to account for the heat flux from the flames back down onto the polymer sample. This ROM produces comparable results to the high-fidelity model and can be completed in approximately a few seconds, thus enabling rapid generation of a large synthetic dataset for supervised pretraining.</p>
<p>Table 1: A summary of the employed datasets.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Property</th>
<th style="text-align: center;">Unit</th>
<th style="text-align: center;">Source</th>
<th style="text-align: center;">Data range</th>
<th style="text-align: center;"># datapoints</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Thermophysical</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Density $\rho$</td>
<td style="text-align: center;">$\mathrm{g} / \mathrm{cm}^{3}$</td>
<td style="text-align: center;">PolyInfo</td>
<td style="text-align: center;">$[0.770,2.868]$</td>
<td style="text-align: center;">1032</td>
</tr>
<tr>
<td style="text-align: center;">Thermal conductivity $\kappa$</td>
<td style="text-align: center;">$W /(m \cdot K)$</td>
<td style="text-align: center;">PolyInfo</td>
<td style="text-align: center;">$[0.013,23]$</td>
<td style="text-align: center;">110</td>
</tr>
<tr>
<td style="text-align: center;">Specific heat $c_{p}$</td>
<td style="text-align: center;">$\mathrm{cal} /(g \cdot C)$</td>
<td style="text-align: center;">PolyInfo</td>
<td style="text-align: center;">$[0.085,2.520]$</td>
<td style="text-align: center;">243</td>
</tr>
<tr>
<td style="text-align: center;">Pyrolysis kinetic</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Heat release capacity $\eta_{c}$</td>
<td style="text-align: center;">$J /(g \cdot K)$</td>
<td style="text-align: center;">Literature</td>
<td style="text-align: center;">$[20.291,1527.251]$</td>
<td style="text-align: center;">88</td>
</tr>
<tr>
<td style="text-align: center;">Heat of combustion $h_{c}$</td>
<td style="text-align: center;">$k J / g$</td>
<td style="text-align: center;">Literature</td>
<td style="text-align: center;">$[3.823,46.528]$</td>
<td style="text-align: center;">88</td>
</tr>
<tr>
<td style="text-align: center;">Temperature range of pyrolysis $d T$</td>
<td style="text-align: center;">K</td>
<td style="text-align: center;">Literature</td>
<td style="text-align: center;">$[46.093,333.964]$</td>
<td style="text-align: center;">88</td>
</tr>
<tr>
<td style="text-align: center;">Temperature at peak mass loss rate $T_{p}$</td>
<td style="text-align: center;">K</td>
<td style="text-align: center;">Literature</td>
<td style="text-align: center;">$[386.285,765.922]$</td>
<td style="text-align: center;">88</td>
</tr>
<tr>
<td style="text-align: center;">Experimental cone calorimeter</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Time to ignition $t_{\text {ig }}$</td>
<td style="text-align: center;">$s$</td>
<td style="text-align: center;">Literature</td>
<td style="text-align: center;">$[1,538]$</td>
<td style="text-align: center;">45</td>
</tr>
<tr>
<td style="text-align: center;">Peak heat release rate pHRR</td>
<td style="text-align: center;">$\mathrm{kW} / \mathrm{m}^{2}$</td>
<td style="text-align: center;">Literature</td>
<td style="text-align: center;">$[19,1761]$</td>
<td style="text-align: center;">45</td>
</tr>
<tr>
<td style="text-align: center;">Smoke extinction area SEA</td>
<td style="text-align: center;">$\mathrm{m}^{2} / \mathrm{kg}$</td>
<td style="text-align: center;">Literature</td>
<td style="text-align: center;">$[33,1300]$</td>
<td style="text-align: center;">38</td>
</tr>
<tr>
<td style="text-align: center;">Synthetic cone calorimeter</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Time to ignition $t_{\text {ig }}$</td>
<td style="text-align: center;">$s$</td>
<td style="text-align: center;">FDS</td>
<td style="text-align: center;">$[20.2,600]$</td>
<td style="text-align: center;">3237</td>
</tr>
<tr>
<td style="text-align: center;">Peak heat release rate pHRR</td>
<td style="text-align: center;">$\mathrm{kW} / \mathrm{m}^{2}$</td>
<td style="text-align: center;">FDS</td>
<td style="text-align: center;">$[0.117,1864.828]$</td>
<td style="text-align: center;">3237</td>
</tr>
</tbody>
</table>
<h1>Quantifying uncertainty of synthetic data</h1>
<p>A key question is how reliable the generated synthetic data is. Both GC and RFR introduce unavoidable errors, which induce uncertainty in the FDS inputs. These uncertainties further propagate through the course of FDS simulation, resulting in posterior uncertainty in cone calorimeter predictions. To determine the trust regions for the synthetic $t_{\mathrm{ig}}$ and pHRR of a particular polymer, we must quantify the uncertainty of FDS simulation from its inputs. In this regard, we use an additive independent and identically distributed (i.i.d.) noise to model the errors of FDS inputs. Specifically, we follow the practice in scientific ML [40-42] and assume that the distributions of all inputs follow Gaussian distributions, $\xi \sim \mathcal{N}\left(E_{\xi}, \sigma_{\xi}^{2}\right)$. The only exception is char fraction $\mu$, where a log-normal distribution is assumed: $\ln (\mu) \sim \mathcal{N}\left(E_{\ln (\mu)}, \sigma_{\ln (\mu)}^{2}\right)$, to guarantee the physical consistency of nonnegativity. For the kinetic parameters $\mu, h_{c}$, and $\eta_{c}$ obtained from GC, we approximate their means and standard deviations as the test results and the averaged test errors of GC. To estimate the distributions of $d T$ and $T_{p}$, we employ the probabilistic collocation method (PCM) [43-47] on RFR models to determine the means and standard deviations. For the thermophysical inputs $\rho, K$, and $C_{p}$ generated via MoLFormers, we use MoLFormer's predictions and their averaged test errors to estimate their</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Quantifying uncertainties on the generated synthetic data: (a) general workflow, (b) the computed probability distributions of physics-based variables, and (c) trust region vs. experimental measurement plots.</p>
<p>Distributions. With the standard deviations for all seven FDS inputs obtained, we again apply PCM to the FDS model and find the distributions for $t_{\text{ig}}$ and pHRR. To verify this process, we consider two polymers from the synthetic dataset that correspond to known polymers with available experimental measurements, namely Polyethylene (PE) and Polyoxymethylene (POM). Figure 4b lists the means and standard deviations for the FDS inputs and outputs. Figure 4c displays the trust regions for $t_{\text{ig}}$ and pHRR predicted by the data generation method versus experimental measurements for PE and POM. The green segments span four standard deviations corresponding to 95% of the possible values. The inclusion of the measured values within or near the trust regions demonstrates the reliability and trust-worthiness of the synthetic data generation approach.</p>
<h3>Phase-1 supervised pretraining</h3>
<p>A significant advantage of the proposed trinity framework is the supervised pretraining of LLMs that aims to align the model to a physically consistent initial state prior to finetuning. In the circumstance of cone calorimeter test, we pretrain the LLM with labeled synthetic data in terms of time to ignition $t_{\text{ig}}$ and peak heat release rate per unit area pHRR. In particular, we first categorize the synthetic data into two classes, one with ignitable polymers (indicated by $t_{\text{ig}} \leq 600s$) and the other with un-ignitable polymers. We slightly modify the MoLFormer architecture by adding a sigmoid function to the decoder output together with the binary cross-entropy loss as the loss function to train a classifier that identifies if a given polymer is</p>
<p>(a). Phase-1 supervised pretraining results</p>
<table>
<thead>
<tr>
<th>$t_{\text {ig }}$ s</th>
<th></th>
<th>pHRR, kW/m²</th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>size</td>
<td>rel. MSE</td>
<td>size</td>
<td>rel. MSE</td>
<td>Size</td>
<td>rel. MSE</td>
<td>size</td>
<td>rel. MSE</td>
</tr>
<tr>
<td>Train</td>
<td>1900</td>
<td>4.40%</td>
<td>1900</td>
<td>3.58%</td>
<td>Train</td>
<td>39</td>
<td>5.41%</td>
<td>39</td>
</tr>
<tr>
<td>Test</td>
<td>469</td>
<td>9.60%</td>
<td>469</td>
<td>6.68%</td>
<td>Test</td>
<td>6</td>
<td>17.86%</td>
<td>6</td>
</tr>
</tbody>
</table>
<p>(c). Phase-2 finetuning results (best errors are highlighted in bold)</p>
<table>
<thead>
<tr>
<th>$t_{\text {ig }}$ s</th>
<th></th>
<th>pHRR, kW/m²</th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td>size</td>
<td>rel. MSE</td>
<td>size</td>
<td>rel. MSE</td>
<td>size</td>
<td>rel. MSE</td>
<td></td>
</tr>
<tr>
<td>Baseline MoLFormers trained with test data only</td>
<td>Train</td>
<td>39</td>
<td>27.02%</td>
<td>39</td>
<td>60.31%</td>
<td>32</td>
<td>30.87%</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Test</td>
<td>6</td>
<td>31.87%</td>
<td>6</td>
<td>69.37%</td>
<td>6</td>
<td>41.11%</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Per-sample error</td>
<td></td>
<td>27.67%</td>
<td></td>
<td>61.52%</td>
<td></td>
<td>32.49%</td>
<td></td>
</tr>
<tr>
<td>Final MoLFormers trained in 2 phases</td>
<td>Train</td>
<td>39</td>
<td>11.92%</td>
<td>39</td>
<td>11.72%</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Test</td>
<td>6</td>
<td>23.71%</td>
<td>6</td>
<td>33.86%</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Per-sample error</td>
<td></td>
<td>13.49%</td>
<td></td>
<td>14.67%</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Figure 5: MoLFormer training results for cone calorimeter metrics prediction. ignitable. We then use the ignitable synthetic polymers for supervised pretraining. This pre-processing step is critical because un-ignitable polymers are characterized by a constant $t_{\text {ig }}$ of 600 s and very small pHRRs, which could otherwise introduce unbalanced outputs and deteriorate prediction accuracy. By implementing a pre-classification step, we address this data distribution challenge by focusing on the ignitable polymers of interest, thereby enhancing the model's predictability. Next, we randomly split the 2369 ignitable polymers into 1900 for training and 469 for testing. The supervised pretraining results can be found in Figure 5a, where the best trained MoLFormers achieve training and test errors of $4.40 \% / 9.60 \%$ and $3.58 \% / 6.68 \%$ for $t_{\text {ig }}$ and pHRR, respectively. With these superb training results, the two MoLFormers are anticipated to inherit good physical priors from the physics-based synthetic data and qualify as initial models for phase-2 finetuning.</p>
<h1>Phase-2 finetuning</h1>
<p>In phase 2, we finetune the obtained phase-1 models with good physics-based priors. Due to the limited size of the experimental cone calorimeter datasets (cf. Table 1), we randomly split each dataset 5 times and train 5 MoLFormers for both $t_{\text {ig }}$ and pHRR to mitigate the effect of bias in splitting data. We then report the averaged relative MSE in Figure 5c, together with the results from the best MoLFormers (out of the 5 trained) in Figure 5b. In general, we observe a good agreement between the ground truth data and the prediction, as indicated by their alignment along the $y=x$ line. We note that during training, the loss function is defined based on relative MSE. As such, the denominator becomes smaller for polymers with smaller pHRR and SEA values, which is equivalent to placing a larger weight on these polymers. Consequently, the model is anticipated to provide better predictions for polymers with lower flammability.</p>
<p>This loss function is chosen because optimal polymer structures with lowest flammability are often more favorable [48]. The effect of the relative MSE loss can also be observed in our results shown in Figure 5, where the model generally presents larger errors in the higher pHRR and SEA regimes, underscoring the importance of an application-oriented loss function. We also point out that with a proper selection of suitable loss functions or simply the augmentation of more data of large pHRRs and SEAs, the trained MoLFormers can be further finetuned to reach higher accuracy. This is, however, out of the scope of the current study.</p>
<h1>Enhanced predictability of the learned models</h1>
<p>To demonstrate the enhanced predictability of the final MoLFormers utilizing the 2-phase training approach, we compare their accuracy with the baseline MoLFormers trained with test data only in Figure 5c. Note that, due to the inability of FDS to generate synthetic SEA data, we do not compare the performance in terms of SEA. However, synthetic SEA data can be generated using other physics-based methods such as the smoke calculation method in [49], which is left as a future research direction. With this caveat in mind, by comparing qualitatively across the prediction plots in Figure 5b, a much wider dispersion from the $y=x$ line together with an early-stage deviation is observed in the SEA plot, emphasizing the indispensable need of the phase-1 supervised pretraining. By comparing the performance between the baseline single-phase MoLFormers (i.e., trained with test data only) and our final physics-guided MoLFormers in Figure 5c, the final MoLFormers manifest significantly higher accuracy in the prediction of both $t_{\mathrm{ig}}$ and pHRR, where the test errors are improved by $25.6 \%$ and $51.2 \%$, respectively. Note that, since the best models are chosen based on the best test errors, the training errors in the best models are also effectively reduced. By comparing the per-sample errors between the baseline and final MoLFormers, a remarkable improvement of $51.2 \%$ and $76.2 \%$ is observed in the prediction of $t_{\mathrm{ig}}$ and pHRR, respectively. These results highlight the effectiveness of the proposed 2-phase training framework in imposing physics-based priors and tackling the pathology of data scarcity.</p>
<h2>3. Discussion</h2>
<p>We present a physics-guided ML pipeline tailored for finetuning LLMs with limited data availability, in which a 2-phase training strategy is designed to blend physics knowledge with pretrained LLMs and finite experimental measurements. Our training strategy begins with a supervised pretraining phase (phase 1), wherein physics-based synthetic data is leveraged to lead the LLM to a physically consistent initial state that establishes the prior physical knowledge for subsequent finetuning. In phase 2, the obtained phase-1 model, having acquired a condensed representation of polymers and a deep physical understanding of the downstream problem, undergoes finetuning that makes the best use of limited experimental data, thereby achieving the final LLM with enhanced precision.</p>
<p>The realization of the proposed 2-phase training framework relies on a suite of physics-based numerical models for efficient synthetic data generation. On one hand, group contribution plays a critical role, not only in generating a vast array of hypothetical polymers for LLM pretraining, but also in correlating each</p>
<p>generated polymer with a diverse range of fundamental physical properties that materialize the hypothetical polymer with actual physical significance. On the other hand, the proposed physics-based modeling framework of the physical process enables the production of a multitude of synthetic data for supervised pretraining. Another outstanding feature of the 2-phase training strategy lies in its relaxation of the stringent accuracy requirement on synthetic data, as the phase-2 finetuning aims to utilize the most accurate experimental data to correct the phase-1 prediction and mitigate the impact of numerical errors and simplified assumptions intrinsically inherited from the numerical simulation model, thus maximizing prediction accuracy.</p>
<p>Interlocking the three pillars of scientific machine learning-LLMs, physics-based modeling and experimental measurements - we demonstrate the proposed trinity framework via the lens of learning polymer flammability metrics, where cone calorimeter data is limited (to only a few dozen measurements). We show that, through supervised pretraining of the LLM with synthetic data, the model's per-sample accuracy can be effectively enhanced by at least $50 \%$. This extraordinary capability in making accurate predictions while relaxing the requirement of an excessive amount of expensive experimental data enables the exploration of the gigantic polymer design universe and the discovery of optimal polymer structures for downstream applications in a precise and efficient manner.</p>
<h1>4. Methods</h1>
<h2>SMILES canonicalization</h2>
<p>SMILES (Simplified Molecular Input Line Entry Systems) is developed in the 1980s [17] and can be viewed as a chemical language for describing molecular structures. While there can be more than one SMILES expressions for a given structure, canonical SMILES are unique. Canonicalization is an algorithm that maps any valid SMILES for a given structure to the unique (canonical) version for that molecule [50].</p>
<p>Since the chemical structures of polymers can be described by their repeating units, researchers have adopted SMILES notations to represent polymers (e.g., [51] and [52]). In this work, we employ a similar notation as in [52], where the polymerization point is denoted by an asterisk (i.e., "*"). For copolymers, the corresponding SMILES consists of SMILES of the constituent monomers, connected by dots (i.e., ".").</p>
<h2>Group contribution</h2>
<p>The group contribution (GC) method is a low-fidelity methodology for estimating various properties of chemical compounds by dividing them into smaller constituents (i.e., sub-molecular structures), sometimes referred to as molar groups. A compound's property is then assumed to be computable according to the contribution of the constituent molar groups [53]. For any particular property, and given a dataset containing this property for a number of compounds, one needs to gather a finite set of molar groups that describe all the given compounds and any other compounds for which one aims to obtain the property. Then, a weighted linear equation is assumed that relates the property to the contribution of molar groups, and a regression</p>
<p>problem is solved to obtain the group contributions. Once the contributions are found, they can be used to estimate the properties for compounds outside of the original dataset.</p>
<p>The selection of molar groups and the equation that relates properties to the group contributions are not unique and vary across applications. In this work, we use the GC method by Lyon [29] that provides estimates for heat release capacity $\eta_{c}$, specific heat of combustion $h_{c}$, and char fraction $\mu$ for polymer compounds based on a set of 38 molar groups, using:</p>
<p>$$
\eta_{c}=\sum_{i=1}^{n_{g}} \frac{N_{i} \Psi_{i}}{N_{i} M_{i}}, \quad h_{c}=\sum_{i=1}^{n_{g}} \frac{N_{i} \Omega_{i}}{N_{i} M_{i}}, \quad \mu=\sum_{i=1}^{n_{g}} \frac{N_{i} X_{i}}{N_{i} M_{i}}
$$</p>
<p>where $n_{g}$ is the number of distinct groups in the compound, $N_{i}$ is the number of occurrence of group $i$ in the compound, $M_{i}$ is the molar mass of the group $i$, and $\Psi, \Omega_{i}, X_{i}$ are contributions of group $i$ to the $\eta_{c}, h_{c}, \mu$ properties, respectively.</p>
<h1>Numerical modeling of the physical process</h1>
<p>Two essential ingredients of a synthetic data generator are the numerical accuracy and computational efficiency of the simulation model. The model needs to be numerically validated against experimental measurements to produce trustworthy data. This is often achieved via constructing a high-fidelity model that simulates the complete process of the physical asset. Concurrently, the model should also be computationally efficient to be able to generate a large amount of data in a relatively short amount of time. This is often accomplished via reduced-order modeling of the high-fidelity process.</p>
<p>We instantiate the modeling framework of the physical process in the form of cone calorimeter experiments [54] that are used to study fire behaviors in small samples of condensed-phase materials. In this case, Fire Dynamics Simulator (FDS) [37] is adopted as the computational framework. FDS is a computational fluid dynamics (CFD) model based on large-eddy simulation developed by the National Institute of Standards and Technology, which predicts the thermo-chemo-physical response of the surrounding solid-phase materials and their potential contribution to the fire through the generation of pyrolysis gases that create fuel for the fire. In this context, we construct a high-fidelity FDS model to predict the fire behavior of polymers exposed to a constant heat flux from the cone heater. A high-fidelity simulation model is constructed that performs a single simulation to predict the temperature rise and the decomposition of polymers over time in the solid phase as well as the combustion of pyrolysis gases in the gas phase. This model, albeit being numerically accurate against experimental data, is computationally slow in that it takes 1-4 hours to run one simulation. To alleviate the computational burden, we proceed to build a reduced-order model (ROM) by only considering the solid-phase mode with an additional simulation that includes a step increase in the heat flux of $25 \mathrm{~kW} / \mathrm{m}^{2}$ after ignition to account for the heat flux from the flames back down onto the polymer sample. This ROM produces comparable results to the high-fidelity model and can be completed in approximately one second, thus enabling rapid generation of a large synthetic dataset for supervised pretraining.</p>
<h2>Probabilistic collocation for uncertainty quantification</h2>
<p>The Probabilistic Collocation Method (PCM) [43-47, 55-57] is a popular numerical method for stochastic models. It retains the ease of implementation found in Monte Carlo methods, as only solutions at the sample points are needed. This makes PCM particularly suitable in cases where the deterministic model operates as a black box or pre-compiled/pre-trained software. Additionally, when combined with sparse grids such as the Smolyak formulation [58], PCM reduces the number of sample points needed to achieve a given numerical accuracy, especially for problems with relatively small $(\leq 50)$ random dimensions [47] and sufficient solution smoothness in the parameter space [56]. These attributes make PCM an ideal candidate for our application.</p>
<p>We elaborate on PCM for a given stochastic model, $f(\boldsymbol{x}, \boldsymbol{\xi})$, where $\boldsymbol{x} \in \mathbb{R}^{d_{x}}$ denotes physical parameters and $\boldsymbol{\xi} \in \Omega_{\xi}$ represents random variables of the random field. Here, $\Omega_{\xi}$ is the random space. It is often assumed that all elements of $\boldsymbol{\xi}$ are i.i.d. random variables with a probability density $\rho: \Omega_{\xi} \rightarrow \mathbb{R}^{+}$. The goal of PCM is to construct an approximate solution manifold of $f(\boldsymbol{x}, \boldsymbol{\xi})$ based on Lagrange interpolation in the random space. Specifically, let $\Theta_{N}=\left{\boldsymbol{\xi}<em k="1">{k}\right}</em>$ can be approximated using the Lagrange interpolation polynomial:}^{K} \subset \Omega_{\xi}$ be a set of prescribed nodes such that the Lagrange interpolation can be performed in the random space $\Omega_{\xi}$, where $N$ is the dimension of the parametric space. Then, the function $f(\boldsymbol{x}, \cdot): \Omega_{\xi} \rightarrow \mathbb{R</p>
<p>$$
\mathcal{J}<a href="\boldsymbol{x}, \boldsymbol{\xi}">f</a>=\sum_{k=1}^{K} f\left(\boldsymbol{x}, \boldsymbol{\xi}<em k="k">{k}\right) J</em>)
$$}(\boldsymbol{\xi</p>
<p>where $J_{k}(\boldsymbol{\xi})$ is the Lagrange polynomial satisfying $J_{k}\left(\boldsymbol{\xi}<em j="j" k="k">{j}\right)=\delta</em>$. Then, the statistical moments of the stochastic model $f$ can be evaluated as follows:</p>
<p>$$
\mathbb{E}<a href="\boldsymbol{x}">f</a> \approx \int_{\Gamma} \sum_{k=1}^{K} f\left(\boldsymbol{x}, \boldsymbol{\xi}<em k="k">{k}\right) J</em>, \sigma}(\boldsymbol{\xi}) \rho(\boldsymbol{\xi}) d \boldsymbol{\xi<a href="\boldsymbol{x}">f</a> \approx \sqrt{\int_{\Gamma}\left[\sum_{k=1}^{K} f\left(\boldsymbol{x}, \boldsymbol{\xi}<em k="k">{k}\right) J</em>}(\boldsymbol{\xi})\right]^{2} \rho(\boldsymbol{\xi}) d \boldsymbol{\xi}-[\mathbb{E<a href="\boldsymbol{x}">f</a>]^{2}}
$$</p>
<p>and so on. In our application, we take $f$ as the RFR model (when estimating the uncertainty of $d T$ and $T_{p}$ ) or the FDS model (when estimating the uncertainty in cone calorimeter tests). We evaluate the RFR and FDS models at each collocation point, $\boldsymbol{\xi}_{k}$, producing a set of system responses corresponding to different input values. Using these responses, we can then estimate the statistical moments of the output distribution, such as the mean, variance, and higher-order moments, following (4.2).</p>
<h1>Large chemical language models for polymer property prediction</h1>
<p>Without loss of generality, we employ the pretrained large chemical language model, MolLFormer [14], as our LLM backbone. MolLFormer is an efficient transformer encoder model with linear attention mechanism and rotary positional embeddings. Although the proposed trinity framework is applicable to any large chemical language model (i.e., it is LLM-agnostic), we choose MoLFormer for demonstration because it is pre-trained on a relatively large database of 1.1 billion unlabeled SMILES representations of compounds from the PubChem and ZINC datasets. This pretraining database covers a diverse range of real-world compounds and positions MoLFormer as an arguably more general-purpose chemical linguist. It has been shown that MolLFormer can capture an adequate amount of structural and chemical information for accurate predictions</p>
<p>of a diverse array of downstream applications [14].</p>
<h1>Two-phase training strategy</h1>
<p>The two-phase prediction-correction training strategy consists of a supervised pretraining phase with a myriad of synthetic data, and a finetuning phase using limited experimental data. In the first phase, we aim to instil in the encoder and decoder the physical knowledge governing the underlying problem, via a data-driven process using a multitude of synthetic data. The rationale behind this phase closely resembles the unsupervised pretraining of transformer encoders in most LLMs that aims to pretrain the encoder to understand the syntactical and grammatical rules of the chemical language. Another significant advantage of the proposed strategy is that it relaxes the stringent requirement on the accuracy of the synthetic dataset. In fact, the phase-2 finetuning leverages the most accurate experimental measurements, treated as ground truth data, to correct the phase-1 predictions and mitigate the effects of numerical errors and simplified assumptions intrinsically inherited from the numerical simulation model. In this way, our two-phase training strategy enhances prediction accuracy by seamlessly blending prior physical knowledge with experimental measurements.</p>
<h2>Acknowledgments</h2>
<p>This work is supported by the Office of Naval Research (ONR) under Grant No. N68335-24-C-0123. This support is gratefully acknowledged.</p>
<h2>References</h2>
<p>[1] P. Tran, Q. T. Nguyen, K. Lau, Fire performance of polymer-based composites for maritime infrastructure, Composites Part B: Engineering 155 (2018) 31-48.
[2] C. Silvestre, D. Duraccio, S. Cimmino, Food packaging based on polymer nanomaterials, Progress in polymer science 36 (12) (2011) 1766-1782.
[3] C. Fu, Z. Wang, Y. Gao, J. Zhao, Y. Liu, X. Zhou, R. Qin, Y. Pang, B. Hu, Y. Zhang, et al., Sustainable polymer coating for stainproof fabrics, Nature Sustainability 6 (8) (2023) 984-994.
[4] G. Li, R. Zhu, Y. Yang, Polymer solar cells, Nature photonics 6 (3) (2012) 153-161.
[5] H. Doan Tran, C. Kim, L. Chen, A. Chandrasekaran, R. Batra, S. Venkatram, D. Kamal, J. P. Lightstone, R. Gurnani, P. Shetty, et al., Machine-learning predictions of polymer properties with polymer genome, Journal of Applied Physics 128 (17) (2020).
[6] E. Kazemi-Khasragh, J. P. F. Blázquez, D. G. Gómez, C. González, M. Haranczyk, Facilitating polymer property prediction with machine learning and group interaction modelling methods, International Journal of Solids and Structures 286 (2024) 112547.</p>
<p>[7] C. Kim, R. Batra, L. Chen, H. Tran, R. Ramprasad, Polymer design using genetic algorithm and machine learning, Computational Materials Science 186 (2021) 110067.
[8] L. Tao, V. Varshney, Y. Li, Benchmarking machine learning models for polymer informatics: an example of glass transition temperature, Journal of Chemical Information and Modeling 61 (11) (2021) 53955413 .
[9] W. E. McMullen, K. F. Freed, A density functional theory of polymer phase transitions and interfaces, The Journal of chemical physics 92 (2) (1990) 1413-1426.
[10] J. Wu, Density functional theory for chemical engineering: From capillarity to soft materials, AIChE journal 52 (3) (2006) 1169-1193.
[11] J. Park, Y. Shim, F. Lee, A. Rammohan, S. Goyal, M. Shim, C. Jeong, D. S. Kim, Prediction and interpretation of polymer properties using the graph convolutional network, ACS Polymers Au 2 (4) (2022) $213-222$.
[12] R. Gurnani, C. Kuenneth, A. Toland, R. Ramprasad, Polymer informatics at scale with multitask graph neural networks, Chemistry of Materials 35 (4) (2023) 1560-1567.
[13] N. Liu, Y. Yu, H. You, N. Tatikola, Ino: Invariant neural operators for learning complex physical systems with momentum conservation, in: International Conference on Artificial Intelligence and Statistics, PMLR, 2023, pp. 6822-6838.
[14] J. Ross, B. Belgodere, V. Chenthamarakshan, I. Padhi, Y. Mroueh, P. Das, Large-scale chemical language representations capture molecular structure and properties, Nature Machine Intelligence 4 (12) (2022) $1256-1264$.
[15] C. Kuenneth, R. Ramprasad, polybert: a chemical language model to enable fully machine-driven ultrafast polymer informatics, Nature Communications 14 (1) (2023) 4099.
[16] C. Xu, Y. Wang, A. Barati Farimani, Transpolymer: a transformer-based language model for polymer property predictions, npj Computational Materials 9 (1) (2023) 64.
[17] D. Weininger, Smiles, a chemical language and information system. 1. introduction to methodology and encoding rules, Journal of chemical information and computer sciences 28 (1) (1988) 31-36.
[18] G. B. Goh, N. O. Hodas, C. Siegel, A. Vishnu, Smiles2vec: An interpretable general-purpose deep neural network for predicting chemical properties, arXiv preprint arXiv:1712.02034 (2017).
[19] H. Öztürk, A. Özgür, E. Ozkirimli, Deepdta: deep drug-target binding affinity prediction, Bioinformatics 34 (17) (2018) i821-i829.</p>
<p>[20] A. Paul, D. Jha, R. Al-Bahrani, W.-k. Liao, A. Choudhary, A. Agrawal, Chemixnet: Mixed dnn architectures for predicting chemical properties using multiple molecular representations, arXiv preprint arXiv:1811.08283 (2018).
[21] B. Shin, S. Park, K. Kang, J. C. Ho, Self-attention based molecule representation for predicting drugtarget interaction, in: Machine learning for healthcare conference, PMLR, 2019, pp. 230-248.
[22] F. Wu, D. Radev, S. Z. Li, Molformer: Motif-based transformer on 3d heterogeneous molecular graphs, in: Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 37, 2023, pp. 5312-5320.
[23] L. Maziarka, D. Majchrowski, T. Danel, P. Gainski, J. Tabor, I. Podolak, P. Morkisz, S. Jastrzebski, Relative molecule self-attention transformer, Journal of Cheminformatics 16 (1) (2024) 3.
[24] Y. Wang, S. Li, T. Wang, B. Shao, N. Zheng, T.-Y. Liu, Geometric transformer with interatomic positional encoding, Advances in Neural Information Processing Systems 36 (2024).
[25] J. Ross, B. Belgodere, S. C. Hoffman, V. Chenthamarakshan, Y. Mroueh, P. Das, Gp-molformer: A foundation model for molecular generation, arXiv preprint arXiv:2405.04912 (2024).
[26] B. Belgodere, V. Chenthamarakshan, P. Das, P. Dognin, T. Kurien, I. Melnyk, Y. Mroueh, I. Padhi, M. Rigotti, J. Ross, et al., Cloud-based real-time molecular screening platform with molformer, in: Joint European Conference on Machine Learning and Knowledge Discovery in Databases, Springer, 2022, pp. $641-644$.
[27] Z. Wu, B. Ramsundar, E. N. Feinberg, J. Gomes, C. Geniesse, A. S. Pappu, K. Leswing, V. Pande, Moleculenet: a benchmark for molecular machine learning, Chemical science 9 (2) (2018) 513-530.
[28] J. Degen, C. Wegscheid-Gerlach, A. Zaliani, M. Rarey, On the art of compiling and using'druglike'chemical fragment spaces, ChemMedChem 3 (10) (2008) 1503.
[29] R. E. Lyon, M. T. Takemori, N. Safronava, S. I. Stoliarov, R. N. Walters, A molecular basis for polymer flammability, Polymer 50 (12) (2009) 2608-2617.
[30] E. Kasneci, K. Seßler, S. Küchemann, M. Bannert, D. Dementieva, F. Fischer, U. Gasser, G. Groh, S. Günnemann, E. Hüllermeier, et al., Chatgpt for good? on opportunities and challenges of large language models for education, Learning and individual differences 103 (2023) 102274.
[31] R. E. Lyon, M. L. Janssens, et al., Polymer flammability, Tech. rep., United States. Federal Aviation Administration. Office of Aviation Research (2005).
[32] S. M. Kraft, B. Y. Lattimer, C. B. Williams, Flammability of 3-d printed polymers-composition and geometry factors (2016).</p>
<p>[33] K. Carpenter, M. Janssens, Using heat release rate to assess combustibility of building products in the cone calorimeter, Fire technology 41 (2005) 79-92.
[34] V. Babrauskas, The development and evolution of the cone calorimeter: a review of 12 years of research and standardization, Fire Standards in the International Marketplace (1995).
[35] R. N. Walters, R. E. Lyon, Molar group contributions to polymer flammability, Journal of Applied Polymer Science 87 (3) (2003) 548-563.
[36] A. S. Hukkerikar, B. Sarup, A. Ten Kate, J. Abildskov, G. Sin, R. Gani, Group-contribution+ (gc+) based estimation of properties of pure components: Improved property estimation and uncertainty analysis, Fluid Phase Equilibria 321 (2012) 25-43.
[37] K. McGrattan, S. Hostikka, R. McDermott, J. Floyd, C. Weinschenk, K. Overholt, Fire dynamics simulator user's guide, NIST special publication 1019 (6) (2013) 1-339.
[38] S. Otsuka, I. Kuwajima, J. Hosoya, Y. Xu, M. Yamazaki, Polyinfo: Polymer database for polymeric materials design, in: 2011 International Conference on Emerging Intelligent Data and Web Technologies, IEEE, 2011, pp. 22-29.
[39] J. L. Hodges, B. Y. Lattimer, A. Kapahi, J. E. Floyd, An engineering model for the pyrolysis of materials, Fire safety journal 141 (2023) 103980.
[40] C. Moya, A. Mollaali, Z. Zhang, L. Lu, G. Lin, Conformalized-deeponet: A distribution-free framework for uncertainty quantification in deep operator networks, arXiv preprint arXiv:2402.15406 (2024).
[41] Z. Zou, X. Meng, G. E. Karniadakis, Uncertainty quantification for noisy inputs-outputs in physicsinformed neural networks and neural operators, arXiv preprint arXiv:2311.11262 (2023).
[42] A. Ghosh, S. V. Kalinin, M. A. Ziatdinov, Discovery of structure-property relations for molecules via hypothesis-driven active learning over the chemical space, APL Machine Learning 1 (4) (2023).
[43] D. Xiu, J. S. Hesthaven, High-order collocation methods for differential equations with random inputs, SIAM Journal on Scientific Computing 27 (3) (2005) 1118-1139.
[44] F. Nobile, R. Tempone, C. G. Webster, An anisotropic sparse grid stochastic collocation method for partial differential equations with random input data, SIAM Journal on Numerical Analysis 46 (5) (2008) $2411-2442$.
[45] X. Ma, N. Zabaras, An adaptive hierarchical sparse grid collocation algorithm for the solution of stochastic differential equations, Journal of Computational Physics 228 (8) (2009) 3084-3113.
[46] G. Zhang, M. Gunzburger, Error analysis of a stochastic collocation method for parabolic partial differential equations with random input data, SIAM Journal on Numerical Analysis 50 (4) (2012) 1922-1940.</p>
<p>[47] G. Lin, A. M. Tartakovsky, An efficient, high-order probabilistic collocation method on sparse grids for three-dimensional flow and solute transport in randomly heterogeneous porous media, Advances in Water Resources 32 (5) (2009) 712-722.
[48] S. Bourbigot, S. Duquesne, C. Jama, Polymer nanocomposites: how to reach low flammability?, in: Macromolecular Symposia, Vol. 233, Wiley Online Library, 2006, pp. 180-190.
[49] A. Tewarson, A. Tewarson, Smoke point height and fire properties of materials, US Department of Commerce, National Institute of Standards and Technology, 1988.
[50] D. Weininger, A. Weininger, J. L. Weininger, Smiles. 2. algorithm for generation of unique smiles notation, Journal of chemical information and computer sciences 29 (2) (1989) 97-101.
[51] Bigsmiles, https://olsenlabmit.github.io/BigSMILES/docs/line_notation.html# the-bigsmiles-line-notation.
[52] Psmiles, https://psmiles.readthedocs.io/en/latest/.
[53] K. G. Joback, R. C. Reid, Estimation of pure-component properties from group-contributions, Chemical Engineering Communications 57 (1-6) (1987) 233-243.
[54] V. Babrauskas, The cone calorimeter, SFPE handbook of fire protection engineering (2016) 952-980.
[55] D. Xiu, G. E. Karniadakis, The wiener-askey polynomial chaos for stochastic differential equations, SIAM journal on scientific computing 24 (2) (2002) 619-644.
[56] Y. Fan, X. Tian, X. Yang, X. Li, C. Webster, Y. Yu, An asymptotically compatible probabilistic collocation method for randomly heterogeneous nonlocal problems, Journal of Computational Physics 465 (2022) 111376.
[57] Y. Fan, H. You, X. Tian, X. Yang, X. Li, N. Prakash, Y. Yu, A meshfree peridynamic model for brittle fracture in randomly heterogeneous materials, Computer Methods in Applied Mechanics and Engineering 399 (2022) 115340. doi:https://doi.org/10.1016/j.cma.2022.115340.
[58] S. A. Smolyak, Quadrature and interpolation formulas for tensor products of certain classes of functions, in: Doklady Akademii Nauk, Vol. 148, Russian Academy of Sciences, 1963, pp. 1042-1045.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>*Corresponding author
Email address: yuy214@lehigh.edu (Yue Yu)&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>