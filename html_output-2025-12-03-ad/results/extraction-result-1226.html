<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1226 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1226</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1226</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-27.html">extraction-schema-27</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <p><strong>Paper ID:</strong> paper-259287283</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2306.16927v3.pdf" target="_blank">End-to-End Autonomous Driving: Challenges and Frontiers</a></p>
                <p><strong>Paper Abstract:</strong> The autonomous driving community has witnessed a rapid growth in approaches that embrace an end-to-end algorithm framework, utilizing raw sensor input to generate vehicle motion plans, instead of concentrating on individual tasks such as detection and motion prediction. End-to-end systems, in comparison to modular pipelines, benefit from joint feature optimization for perception and planning. This field has flourished due to the availability of large-scale datasets, closed-loop evaluation, and the increasing need for autonomous driving algorithms to perform effectively in challenging scenarios. In this survey, we provide a comprehensive analysis of more than 270 papers, covering the motivation, roadmap, methodology, challenges, and future trends in end-to-end autonomous driving. We delve into several critical challenges, including multi-modality, interpretability, causal confusion, robustness, and world models, amongst others. Additionally, we discuss current advancements in foundation models and visual pre-training, as well as how to incorporate these techniques within the end-to-end driving framework.</p>
                <p><strong>Cost:</strong> 0.022</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1226.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1226.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Dreamer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Dream to Control (Dreamer)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A latent-imagination world model that learns compact recurrent latent dynamics (RSSM) and uses imagined rollouts in latent space to train policies and value functions, improving sample efficiency for RL.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Dream to control: Learning behaviors by latent imagination</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Dreamer (latent imagination model)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Recurrent state-space latent model: encoder maps observations to latent states, a recurrent transition model (RSSM) predicts next latent states and rewards, and a decoder reconstructs observations; policies and value heads are trained on imagined trajectories produced by rolling out the latent transition model.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>latent world model</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>reinforcement learning / autonomous driving (discussed as general MBRL component)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>prediction / reconstruction loss in latent and image space; downstream policy return (cumulative reward) when training on imagined rollouts</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>Relatively low-level interpretability (latent space is a learned compressed representation); not inherently human-interpretable though components (reconstructions, imagined trajectories) can be inspected.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>visualization of decoded reconstructions and imagined future trajectories; inspection of latent rollouts</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Adds model-training overhead (learning encoder/transition/decoder) but reduces environment interactions (sample complexity); specific compute/time figures not reported in survey.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>Survey states Dreamer-style models improve sample efficiency over model-free RL by enabling policy training inside the world model and reducing reliance on slow simulators, but no numeric factor provided.</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Survey reports Dreamer-style approaches have been adapted for driving and can enable RL where simulators are slow, but gives no concrete numeric task metrics for driving.</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>High utility for reducing sample complexity and enabling imagined rollouts for policy improvement; however, fidelity of visual/image predictions can limit usefulness for driving because small details (e.g., traffic lights) may be missed in image-space reconstructions.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>Trade-off between modelling fidelity (especially in raw image space) and utility: higher-fidelity image predictors are costly and still may miss small but critical details; learning latent dynamics is more efficient but may omit task-relevant cues.</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>Uses compact latent representations and recurrent transition model to enable imagined rollouts; prioritizes learning dynamics useful for policy (latent reward predictors, transition regularization).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared qualitatively to model-free RL: Dreamer-like latent world models reduce environment sample complexity; compared to raw-image predictive models, latent models are more tractable but potentially less faithful to every pixel.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>Survey suggests Dreamer-style latent models are promising for driving when combined with task-oriented design (e.g., BEV latent spaces or disentangling controllable vs uncontrollable factors); no single optimal configuration is prescribed.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'End-to-End Autonomous Driving: Challenges and Frontiers', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1226.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1226.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ISO-Dream</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ISO-Dream (Isolating and leveraging noncontrollable visual dynamics in world models)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Dreamer-derived method that disentangles visual dynamics into controllable and uncontrollable latent subspaces, training policies on disentangled states to mitigate modeling errors from parts of the scene the agent cannot control.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Iso-dream: Isolating and leveraging noncontrollable visual dynamics in world models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ISO-Dream</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A latent world model that factorizes latent state into controllable and uncontrollable components and learns separate transition/prediction modules, enabling policy learning on the controllable subspace while accounting for uncertainty from uncontrollable dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>latent world model (disentangled)</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>model-based RL / autonomous driving (discussed as method to improve world models for driving)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>latent prediction losses for both subspaces; downstream policy returns when training on disentangled representations; uncertainty estimation on uncontrollable components</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>Improved interpretability relative to monolithic latent models because the factorization highlights which latent factors are controllable vs. not; still fundamentally a learned latent model.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>Explicit disentanglement of latent factors into controllable/uncontrollable; inspection of separate latent dynamics and uncertainty signals.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Some additional modeling overhead to learn and maintain separate latent components and respective predictors; survey does not provide numeric compute costs.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>Survey implies ISO-Dream can improve robustness of imagined rollouts and policy learning relative to undifferentiated latent models, but no quantitative efficiency numbers provided.</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Presented as aiding policy learning by focusing imagination on controllable dynamics and reducing negative effects from unpredictable environment elements; no explicit driving-task metrics given in survey.</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>Useful for autonomous driving where many elements (other agents, weather) are uncontrollable; by isolating uncontrollable dynamics, policies trained on the controllable subspace are expected to be more robust.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>Extra complexity to learn factorization versus benefit in reducing policy degradation due to uncontrollable prediction errors; potential increased training complexity and hyperparameter sensitivity.</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>Discrete design choice to partition latent space and to train separate predictors and uncertainty models for each partition; emphasizes controllable latent learning for policy.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared qualitatively to standard Dreamer: ISO-Dream aims to reduce the negative impact of modelling noisy/uncontrollable dynamicsâ€”improving policy robustness at the cost of increased model complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>Survey recommends decoupling controllable and uncontrollable components for driving but does not specify precise architecture/hyperparameters.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'End-to-End Autonomous Driving: Challenges and Frontiers', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1226.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1226.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Prob-Seq-Latent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Probabilistic Sequential Latent World Model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A probabilistic sequential latent model (e.g., VAE-style or sequential latent-variable model) used as an internal world model to predict future latent states and rewards for imagined rollouts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>probabilistic sequential latent model</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Probabilistic latent-variable model that learns a distribution over latent states and transitions (often via variational objectives), enabling sampling of future latent trajectories with uncertainty quantification.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>latent world model (probabilistic)</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>autonomous driving model-based RL and imagination-based policy training</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>likelihood / ELBO / next-step prediction MSE in latent or observation space; downstream policy return</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>Latent probabilistic models remain largely opaque; uncertainty estimates are explicit but internal latent dimensions are not directly interpretable without additional constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>Uncertainty quantification (e.g., predictive variance) and inspection of sampled rollouts; no specific interpretability mechanisms described in survey.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Training probabilistic sequential latent models requires extra compute for variational inference and sampling; however, imagined rollouts reduce the need for environment interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>Qualitatively more sample efficient than model-free RL by enabling many imagined rollouts; computational training overhead vs environment-step cost trade-off.</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Survey notes these models have been used in driving but emphasizes challenges in capturing fine-grained visual details necessary for driving decisions, limiting raw image-space fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>Useful insofar as the latent predictions capture task-relevant dynamics; full image-space fidelity not necessary if latent encodes task-relevant features (e.g., BEV abstractions).</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>Probabilistic latent models trade off modeling expressiveness vs tractability; richer models capture more detail but are costlier and harder to stabilize.</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>Choosing latent dimension size, probabilistic vs deterministic transitions, and whether to model in image vs BEV/semantic space are key design factors mentioned.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared with deterministic latent or image-space predictors: probabilistic variants provide uncertainty which can be used to truncate imagined rollouts, improving robustness but adding compute.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>Survey suggests modeling in task-aligned spaces (e.g., BEV segmentation) and using probabilistic estimates to manage rollout truncation is a promising balance, but gives no prescriptive configuration.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'End-to-End Autonomous Driving: Challenges and Frontiers', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1226.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1226.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Ensemble World Models</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Ensembles of Learned World Models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Using multiple independently-trained world models in an ensemble to estimate epistemic uncertainty and decide when to truncate or trust imagined rollouts for policy learning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ensemble of world models</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Several world models (e.g., latent dynamics predictors) trained with differing initializations/data partitions; ensemble variance is used as uncertainty estimate for imagined rollouts and planning.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>latent world model ensemble (probabilistic proxy for uncertainty)</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>model-based RL for autonomous driving and imagined-rollout truncation</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>ensemble predictive variance; next-step prediction error across ensemble members</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>Provides a form of uncertainty-based interpretability (where high disagreement indicates unreliable predictions); internal model details remain black-box.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>Uncertainty estimation via ensemble disagreement and truncation heuristics; no direct saliency interpretability.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Multiplicative training/inference cost proportional to ensemble size (multiple models to train and evaluate); survey notes ensembles are used to trade compute for uncertainty robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>Ensembles increase compute but improve safety/robustness of imagination-based methods by enabling rollout truncation when uncertainty is high; no numeric comparisons provided.</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Survey describes ensembles as a method to mitigate inaccurate world model rollouts, improving policy training stability; no numerical task metrics given.</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>High utility for uncertainty-aware MBRL: ensembles allow identifying unreliable imaginations and reducing cascading errors in policy training.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>Increased compute and memory cost vs improved uncertainty estimates and safer imagined rollouts.</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>Number of ensemble members, diversity-inducing training procedures, and the thresholding policy for truncating rollouts are key design points.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared to single-model uncertainty approximations (e.g., dropout), ensembles are often more reliable but more costly.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>Survey suggests ensembles are a pragmatic method to manage model inaccuracies in driving, but does not give a specific ensemble size or training recipe.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'End-to-End Autonomous Driving: Challenges and Frontiers', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1226.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1226.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Diffusion-based Predictors</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Diffusion-based image-space predictive models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use diffusion generative models to forecast future raw-image observations or frames, aiming to capture complex stochasticity of visual dynamics more faithfully than simple deterministic decoders.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>High-resolution image synthesis with latent diffusion models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>diffusion-based predictive model (image-space)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Diffusion generative models (denoising diffusion probabilistic models) used to generate future frames or predictions in pixel space, potentially conditioned on past frames and actions.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>explicit image-space generative world model (neural diffusion)</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>visual prediction for autonomous driving (image-space future forecasting)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>perceptual similarity metrics (e.g., LPIPS), pixel-wise MSE, and qualitative fidelity to small but critical visual details</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>Low interpretability of internal denoising steps; outputs are visually inspectable and can capture realistic samples, but internal states are opaque.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>Visual inspection of generated frames; metrics for perceptual similarity and downstream policy impact assessment.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>High rendering and inference times (survey notes diffusion renders are slow and often require per-scene training), making them computationally expensive for real-time driving use.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>Much more computationally intensive than latent-rollout methods; survey explicitly notes high rendering times and per-scene training requirements for NeRF-like / diffusion approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Better visual realism in generated frames, but survey warns that even high-quality image predictions can miss task-critical small details (e.g., traffic lights) and thus limit utility for driving policies.</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>High perceptual fidelity does not necessarily translate to improved policy performance if critical elements are not consistently captured; computational cost hinders real-time use.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>High-fidelity image predictions vs heavy compute and slower inference; fidelity improvements may not yield proportional policy gains.</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>Choosing image-space vs latent-space diffusion, scene-specific vs generalizable models, and latency-optimized architectures are key tradeoffs.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared to latent-world models (Dreamer), diffusion models give more photorealistic predictions but at much higher compute cost and uncertain policy benefit.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>Survey suggests diffusion techniques help image prediction fidelity but recommends modeling in task-aligned representations (e.g., BEV/semantic) for driving rather than raw image diffusion for better cost/utility balance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'End-to-End Autonomous Driving: Challenges and Frontiers', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1226.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1226.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MILE / BEV-world</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MILE (Dreamer-style world model learning in BEV segmentation space)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An approach that learns world-model style dynamics in a bird's-eye-view (BEV) segmentation/semantic space rather than raw image space, used as an auxiliary task to improve imitation learning and reduce RL sample complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Enhance sample efficiency and robustness of end-to-end urban autonomous driving via semantic masked world model</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BEV-segmentation world model (MILE)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Dreamer-style latent world model trained on BEV semantic segmentation maps (rather than raw images), providing future semantic occupancy forecasts for use as auxiliary supervision or for model-based policy learning.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>latent world model (task-aligned BEV space)</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>autonomous driving (end-to-end policy learning and auxiliary world-model supervision)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>accuracy of BEV segmentation forecasting / semantic occupancy prediction; downstream policy return and sample efficiency</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>Higher interpretability than image-space latent models because BEV semantic maps are human-interpretable and show predicted freespace/occupancy.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>Visualization of predicted BEV semantic maps and occupancy; use of semantic layers that correspond to human concepts (lane, vehicle, pedestrian).</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Lower than image-space generative models due to dense but lower-dimensional BEV semantics; still requires training world-model components (encoder, transition, decoder).</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>Survey suggests BEV-space world models are more computationally efficient and more task-relevant than raw-image world models, enabling better sample efficiency gains for RL.</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Reported as improving sample efficiency and robustness as an auxiliary task combined with IL/RL in driving setups; no numeric metrics provided in survey.</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>Because BEV focuses on task-relevant semantics (occupancy, lanes), high fidelity in BEV predictions more directly benefits planning/policies than pixel-accurate image predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>Using BEV trades off raw visual realism for task-aligned semantics and interpretability, improving usefulness for planning while reducing modeling difficulty.</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>Choice to model in BEV segmentation space (semantic abstraction) rather than pixel space; inclusion as auxiliary loss vs primary training target.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared favorably to image-space world models for driving because BEV models better capture planning-relevant information at lower cost.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>Survey recommends learning world models in BEV/semantic spaces for driving as a pragmatic balance of fidelity, interpretability, efficiency, and task utility.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'End-to-End Autonomous Driving: Challenges and Frontiers', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1226.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e1226.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DeRL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DeRL (Model-Free + Model-Based Fusion)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid approach that fuses a model-free actor-critic agent with a learned world model by combining self-assessments (action or state estimates) from both models to improve policy learning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>DeRL (hybrid model-free/model-based fusion)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Maintains both a model-free actor-critic policy and a learned world model; fuses assessments from both sources (e.g., Q-values, imagined returns) to supervise or refine policy updates.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>hybrid world model (model-free + learned model fusion)</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>autonomous driving RL / imitation learning augmentation</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>agreement/disagreement between model-free and model-based estimates; downstream policy return and stability</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>Provides more interpretability than purely black-box model-free approaches by exposing model-based imagined predictions and their agreement with model-free estimates.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>Comparative analysis of model-free vs model-based self-assessment signals; inspection of when and why they diverge.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Costs of running both model-free training and maintaining a world model; additional fusion overhead but can reduce sample complexity overall.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>Survey suggests this hybrid approach can leverage advantages of each paradigm (robustness of model-free, sample-efficiency of model-based), but exact efficiency gains are not quantified.</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Described as a way to improve training stability and performance by combining complementary signals; no precise task metrics given.</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>Useful in settings where pure model-based rollouts may be unreliable: model-free critic provides a complementary signal that can correct model bias.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>Increased system complexity and compute for potentially improved sample efficiency and robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>Which signals to fuse (action, state, value), how to weight them, and mechanisms to detect model inaccuracy are key design choices.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared to pure model-free RL: aims to reduce sample complexity; compared to pure model-based RL: aims to reduce sensitivity to model inaccuracies.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>Survey notes DeRL-like hybrids are promising but does not prescribe a definitive configuration; tuning fusion mechanisms is important.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'End-to-End Autonomous Driving: Challenges and Frontiers', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1226.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e1226.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TrafficBots</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>TrafficBots (world models for simulation & motion prediction)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A work that formulates world models specifically for driving-related simulation and motion prediction tasks, focusing on generating realistic multi-agent behaviors useful for both simulation and planning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>TrafficBots: Towards world models for autonomous driving simulation and motion prediction</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>TrafficBots world model</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A learned model of multi-agent traffic dynamics that can be used both for simulating realistic traffic in closed-loop evaluation and for motion prediction, likely combining data-driven agent models with learned interaction dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>neural multi-agent world model (simulation & prediction)</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>autonomous driving simulation, motion prediction, and benchmarking</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>realism of generated traffic trajectories (distributional match to real data), motion prediction error metrics, and usefulness for stress-testing driving policies</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>Provides interpretable traffic-level outputs (trajectories, agent intents) though internal interaction modeling remains learned and opaque.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>Visualization of generated multi-agent trajectories and scenario statistics; comparison to real-world distributions.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Not specified in survey; data-driven traffic/world models require training on large multi-agent datasets and have runtime costs for simulating many agents.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>Survey positions such world models as efficient alternatives to hand-crafted or rule-based traffic simulators (IDM) for generating realistic scenarios, but concrete efficiency numbers aren't provided.</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Useful for generating realistic and diverse traffic scenarios for closed-loop evaluation and training; no quantitative metrics reported in survey excerpt.</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>High utility for simulation-based benchmarking and for producing realistic interactive behaviors that improve evaluation fidelity for driving policies.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>Data-driven realism vs generalization to rare or safety-critical cases; learned models may reproduce biases present in data.</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>Modeling agent interactions, conditioning on maps/goals, and balancing stochasticity vs physical plausibility are key choices.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared to rule-based traffic models (e.g., IDM), TrafficBots aims to capture richer, learned interactions at the cost of data/training requirements.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>Survey suggests learned traffic/world models are a promising component of the simulation stack for driving, but stresses need to ensure physical plausibility and coverage of rare events.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'End-to-End Autonomous Driving: Challenges and Frontiers', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1226.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e1226.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Vista</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Vista (A generalizable driving world model with high fidelity and versatile controllability)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A driving-specific world model that emphasizes high-fidelity forecasting and controllability for downstream tasks such as planning and policy learning, introduced as a recent example of a driving world model.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Vista: A generalizable driving world model with high fidelity and versatile controllability</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Vista driving world model</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A driving-focused world model designed for high-fidelity forecasting and controllable generation of future scenes (likely in BEV or multi-view representations) to support planning and policy evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>domain-specific learned world model (driving)</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>autonomous driving simulation, forecasting and planning</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>high-fidelity forecasting metrics (unspecified in survey) and controllability benchmarks for scene generation</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>Survey references Vista as having high fidelity and controllability; likely offers interpretable predicted scene representations (e.g., BEV forecasts), but internal model interpretability unspecified.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>Visualization of predicted controlled futures and BEV/state-space forecasts; not further detailed in survey.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Not specified in the survey; likely non-trivial given 'high fidelity' claims.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>Survey cites Vista as a high-fidelity, generalizable world model for driving; no head-to-head efficiency numbers provided.</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Reported in survey references as a recent advancement that achieves high fidelity and controllability for driving world modeling, but the survey does not include numeric task metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>Designed to directly support planning and forecasting tasks in autonomous driving by providing controllable, high-fidelity future predictions; considered a promising direction in the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>High fidelity and controllability likely come at computational and data cost; survey notes need to balance fidelity vs tractability for downstream planning.</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>Emphasis on BEV or task-aligned representations, controllable conditioning inputs, and generalizability across scenarios.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Posited as an improvement over naive image-space models and generic latent models for driving due to its emphasis on fidelity and controllability; no quantitative comparisons provided in survey.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>Survey suggests that a driving 'foundation' model could be a world model trained to forecast reasonable futures in 2D/3D/latent spaces with task-sophisticated objectives; Vista is given as an example of this direction.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'End-to-End Autonomous Driving: Challenges and Frontiers', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Dream to control: Learning behaviors by latent imagination <em>(Rating: 2)</em></li>
                <li>Iso-dream: Isolating and leveraging noncontrollable visual dynamics in world models <em>(Rating: 2)</em></li>
                <li>TrafficBots: Towards world models for autonomous driving simulation and motion prediction <em>(Rating: 2)</em></li>
                <li>Vista: A generalizable driving world model with high fidelity and versatile controllability <em>(Rating: 2)</em></li>
                <li>Enhance sample efficiency and robustness of end-to-end urban autonomous driving via semantic masked world model <em>(Rating: 2)</em></li>
                <li>Model-predictive policy learning with uncertainty regularization for driving in dense traffic <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1226",
    "paper_id": "paper-259287283",
    "extraction_schema_id": "extraction-schema-27",
    "extracted_data": [
        {
            "name_short": "Dreamer",
            "name_full": "Dream to Control (Dreamer)",
            "brief_description": "A latent-imagination world model that learns compact recurrent latent dynamics (RSSM) and uses imagined rollouts in latent space to train policies and value functions, improving sample efficiency for RL.",
            "citation_title": "Dream to control: Learning behaviors by latent imagination",
            "mention_or_use": "mention",
            "model_name": "Dreamer (latent imagination model)",
            "model_description": "Recurrent state-space latent model: encoder maps observations to latent states, a recurrent transition model (RSSM) predicts next latent states and rewards, and a decoder reconstructs observations; policies and value heads are trained on imagined trajectories produced by rolling out the latent transition model.",
            "model_type": "latent world model",
            "task_domain": "reinforcement learning / autonomous driving (discussed as general MBRL component)",
            "fidelity_metric": "prediction / reconstruction loss in latent and image space; downstream policy return (cumulative reward) when training on imagined rollouts",
            "fidelity_performance": null,
            "interpretability_assessment": "Relatively low-level interpretability (latent space is a learned compressed representation); not inherently human-interpretable though components (reconstructions, imagined trajectories) can be inspected.",
            "interpretability_method": "visualization of decoded reconstructions and imagined future trajectories; inspection of latent rollouts",
            "computational_cost": "Adds model-training overhead (learning encoder/transition/decoder) but reduces environment interactions (sample complexity); specific compute/time figures not reported in survey.",
            "efficiency_comparison": "Survey states Dreamer-style models improve sample efficiency over model-free RL by enabling policy training inside the world model and reducing reliance on slow simulators, but no numeric factor provided.",
            "task_performance": "Survey reports Dreamer-style approaches have been adapted for driving and can enable RL where simulators are slow, but gives no concrete numeric task metrics for driving.",
            "task_utility_analysis": "High utility for reducing sample complexity and enabling imagined rollouts for policy improvement; however, fidelity of visual/image predictions can limit usefulness for driving because small details (e.g., traffic lights) may be missed in image-space reconstructions.",
            "tradeoffs_observed": "Trade-off between modelling fidelity (especially in raw image space) and utility: higher-fidelity image predictors are costly and still may miss small but critical details; learning latent dynamics is more efficient but may omit task-relevant cues.",
            "design_choices": "Uses compact latent representations and recurrent transition model to enable imagined rollouts; prioritizes learning dynamics useful for policy (latent reward predictors, transition regularization).",
            "comparison_to_alternatives": "Compared qualitatively to model-free RL: Dreamer-like latent world models reduce environment sample complexity; compared to raw-image predictive models, latent models are more tractable but potentially less faithful to every pixel.",
            "optimal_configuration": "Survey suggests Dreamer-style latent models are promising for driving when combined with task-oriented design (e.g., BEV latent spaces or disentangling controllable vs uncontrollable factors); no single optimal configuration is prescribed.",
            "uuid": "e1226.0",
            "source_info": {
                "paper_title": "End-to-End Autonomous Driving: Challenges and Frontiers",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "ISO-Dream",
            "name_full": "ISO-Dream (Isolating and leveraging noncontrollable visual dynamics in world models)",
            "brief_description": "A Dreamer-derived method that disentangles visual dynamics into controllable and uncontrollable latent subspaces, training policies on disentangled states to mitigate modeling errors from parts of the scene the agent cannot control.",
            "citation_title": "Iso-dream: Isolating and leveraging noncontrollable visual dynamics in world models",
            "mention_or_use": "mention",
            "model_name": "ISO-Dream",
            "model_description": "A latent world model that factorizes latent state into controllable and uncontrollable components and learns separate transition/prediction modules, enabling policy learning on the controllable subspace while accounting for uncertainty from uncontrollable dynamics.",
            "model_type": "latent world model (disentangled)",
            "task_domain": "model-based RL / autonomous driving (discussed as method to improve world models for driving)",
            "fidelity_metric": "latent prediction losses for both subspaces; downstream policy returns when training on disentangled representations; uncertainty estimation on uncontrollable components",
            "fidelity_performance": null,
            "interpretability_assessment": "Improved interpretability relative to monolithic latent models because the factorization highlights which latent factors are controllable vs. not; still fundamentally a learned latent model.",
            "interpretability_method": "Explicit disentanglement of latent factors into controllable/uncontrollable; inspection of separate latent dynamics and uncertainty signals.",
            "computational_cost": "Some additional modeling overhead to learn and maintain separate latent components and respective predictors; survey does not provide numeric compute costs.",
            "efficiency_comparison": "Survey implies ISO-Dream can improve robustness of imagined rollouts and policy learning relative to undifferentiated latent models, but no quantitative efficiency numbers provided.",
            "task_performance": "Presented as aiding policy learning by focusing imagination on controllable dynamics and reducing negative effects from unpredictable environment elements; no explicit driving-task metrics given in survey.",
            "task_utility_analysis": "Useful for autonomous driving where many elements (other agents, weather) are uncontrollable; by isolating uncontrollable dynamics, policies trained on the controllable subspace are expected to be more robust.",
            "tradeoffs_observed": "Extra complexity to learn factorization versus benefit in reducing policy degradation due to uncontrollable prediction errors; potential increased training complexity and hyperparameter sensitivity.",
            "design_choices": "Discrete design choice to partition latent space and to train separate predictors and uncertainty models for each partition; emphasizes controllable latent learning for policy.",
            "comparison_to_alternatives": "Compared qualitatively to standard Dreamer: ISO-Dream aims to reduce the negative impact of modelling noisy/uncontrollable dynamicsâ€”improving policy robustness at the cost of increased model complexity.",
            "optimal_configuration": "Survey recommends decoupling controllable and uncontrollable components for driving but does not specify precise architecture/hyperparameters.",
            "uuid": "e1226.1",
            "source_info": {
                "paper_title": "End-to-End Autonomous Driving: Challenges and Frontiers",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "Prob-Seq-Latent",
            "name_full": "Probabilistic Sequential Latent World Model",
            "brief_description": "A probabilistic sequential latent model (e.g., VAE-style or sequential latent-variable model) used as an internal world model to predict future latent states and rewards for imagined rollouts.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "probabilistic sequential latent model",
            "model_description": "Probabilistic latent-variable model that learns a distribution over latent states and transitions (often via variational objectives), enabling sampling of future latent trajectories with uncertainty quantification.",
            "model_type": "latent world model (probabilistic)",
            "task_domain": "autonomous driving model-based RL and imagination-based policy training",
            "fidelity_metric": "likelihood / ELBO / next-step prediction MSE in latent or observation space; downstream policy return",
            "fidelity_performance": null,
            "interpretability_assessment": "Latent probabilistic models remain largely opaque; uncertainty estimates are explicit but internal latent dimensions are not directly interpretable without additional constraints.",
            "interpretability_method": "Uncertainty quantification (e.g., predictive variance) and inspection of sampled rollouts; no specific interpretability mechanisms described in survey.",
            "computational_cost": "Training probabilistic sequential latent models requires extra compute for variational inference and sampling; however, imagined rollouts reduce the need for environment interactions.",
            "efficiency_comparison": "Qualitatively more sample efficient than model-free RL by enabling many imagined rollouts; computational training overhead vs environment-step cost trade-off.",
            "task_performance": "Survey notes these models have been used in driving but emphasizes challenges in capturing fine-grained visual details necessary for driving decisions, limiting raw image-space fidelity.",
            "task_utility_analysis": "Useful insofar as the latent predictions capture task-relevant dynamics; full image-space fidelity not necessary if latent encodes task-relevant features (e.g., BEV abstractions).",
            "tradeoffs_observed": "Probabilistic latent models trade off modeling expressiveness vs tractability; richer models capture more detail but are costlier and harder to stabilize.",
            "design_choices": "Choosing latent dimension size, probabilistic vs deterministic transitions, and whether to model in image vs BEV/semantic space are key design factors mentioned.",
            "comparison_to_alternatives": "Compared with deterministic latent or image-space predictors: probabilistic variants provide uncertainty which can be used to truncate imagined rollouts, improving robustness but adding compute.",
            "optimal_configuration": "Survey suggests modeling in task-aligned spaces (e.g., BEV segmentation) and using probabilistic estimates to manage rollout truncation is a promising balance, but gives no prescriptive configuration.",
            "uuid": "e1226.2",
            "source_info": {
                "paper_title": "End-to-End Autonomous Driving: Challenges and Frontiers",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "Ensemble World Models",
            "name_full": "Ensembles of Learned World Models",
            "brief_description": "Using multiple independently-trained world models in an ensemble to estimate epistemic uncertainty and decide when to truncate or trust imagined rollouts for policy learning.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "ensemble of world models",
            "model_description": "Several world models (e.g., latent dynamics predictors) trained with differing initializations/data partitions; ensemble variance is used as uncertainty estimate for imagined rollouts and planning.",
            "model_type": "latent world model ensemble (probabilistic proxy for uncertainty)",
            "task_domain": "model-based RL for autonomous driving and imagined-rollout truncation",
            "fidelity_metric": "ensemble predictive variance; next-step prediction error across ensemble members",
            "fidelity_performance": null,
            "interpretability_assessment": "Provides a form of uncertainty-based interpretability (where high disagreement indicates unreliable predictions); internal model details remain black-box.",
            "interpretability_method": "Uncertainty estimation via ensemble disagreement and truncation heuristics; no direct saliency interpretability.",
            "computational_cost": "Multiplicative training/inference cost proportional to ensemble size (multiple models to train and evaluate); survey notes ensembles are used to trade compute for uncertainty robustness.",
            "efficiency_comparison": "Ensembles increase compute but improve safety/robustness of imagination-based methods by enabling rollout truncation when uncertainty is high; no numeric comparisons provided.",
            "task_performance": "Survey describes ensembles as a method to mitigate inaccurate world model rollouts, improving policy training stability; no numerical task metrics given.",
            "task_utility_analysis": "High utility for uncertainty-aware MBRL: ensembles allow identifying unreliable imaginations and reducing cascading errors in policy training.",
            "tradeoffs_observed": "Increased compute and memory cost vs improved uncertainty estimates and safer imagined rollouts.",
            "design_choices": "Number of ensemble members, diversity-inducing training procedures, and the thresholding policy for truncating rollouts are key design points.",
            "comparison_to_alternatives": "Compared to single-model uncertainty approximations (e.g., dropout), ensembles are often more reliable but more costly.",
            "optimal_configuration": "Survey suggests ensembles are a pragmatic method to manage model inaccuracies in driving, but does not give a specific ensemble size or training recipe.",
            "uuid": "e1226.3",
            "source_info": {
                "paper_title": "End-to-End Autonomous Driving: Challenges and Frontiers",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "Diffusion-based Predictors",
            "name_full": "Diffusion-based image-space predictive models",
            "brief_description": "Use diffusion generative models to forecast future raw-image observations or frames, aiming to capture complex stochasticity of visual dynamics more faithfully than simple deterministic decoders.",
            "citation_title": "High-resolution image synthesis with latent diffusion models",
            "mention_or_use": "mention",
            "model_name": "diffusion-based predictive model (image-space)",
            "model_description": "Diffusion generative models (denoising diffusion probabilistic models) used to generate future frames or predictions in pixel space, potentially conditioned on past frames and actions.",
            "model_type": "explicit image-space generative world model (neural diffusion)",
            "task_domain": "visual prediction for autonomous driving (image-space future forecasting)",
            "fidelity_metric": "perceptual similarity metrics (e.g., LPIPS), pixel-wise MSE, and qualitative fidelity to small but critical visual details",
            "fidelity_performance": null,
            "interpretability_assessment": "Low interpretability of internal denoising steps; outputs are visually inspectable and can capture realistic samples, but internal states are opaque.",
            "interpretability_method": "Visual inspection of generated frames; metrics for perceptual similarity and downstream policy impact assessment.",
            "computational_cost": "High rendering and inference times (survey notes diffusion renders are slow and often require per-scene training), making them computationally expensive for real-time driving use.",
            "efficiency_comparison": "Much more computationally intensive than latent-rollout methods; survey explicitly notes high rendering times and per-scene training requirements for NeRF-like / diffusion approaches.",
            "task_performance": "Better visual realism in generated frames, but survey warns that even high-quality image predictions can miss task-critical small details (e.g., traffic lights) and thus limit utility for driving policies.",
            "task_utility_analysis": "High perceptual fidelity does not necessarily translate to improved policy performance if critical elements are not consistently captured; computational cost hinders real-time use.",
            "tradeoffs_observed": "High-fidelity image predictions vs heavy compute and slower inference; fidelity improvements may not yield proportional policy gains.",
            "design_choices": "Choosing image-space vs latent-space diffusion, scene-specific vs generalizable models, and latency-optimized architectures are key tradeoffs.",
            "comparison_to_alternatives": "Compared to latent-world models (Dreamer), diffusion models give more photorealistic predictions but at much higher compute cost and uncertain policy benefit.",
            "optimal_configuration": "Survey suggests diffusion techniques help image prediction fidelity but recommends modeling in task-aligned representations (e.g., BEV/semantic) for driving rather than raw image diffusion for better cost/utility balance.",
            "uuid": "e1226.4",
            "source_info": {
                "paper_title": "End-to-End Autonomous Driving: Challenges and Frontiers",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "MILE / BEV-world",
            "name_full": "MILE (Dreamer-style world model learning in BEV segmentation space)",
            "brief_description": "An approach that learns world-model style dynamics in a bird's-eye-view (BEV) segmentation/semantic space rather than raw image space, used as an auxiliary task to improve imitation learning and reduce RL sample complexity.",
            "citation_title": "Enhance sample efficiency and robustness of end-to-end urban autonomous driving via semantic masked world model",
            "mention_or_use": "mention",
            "model_name": "BEV-segmentation world model (MILE)",
            "model_description": "Dreamer-style latent world model trained on BEV semantic segmentation maps (rather than raw images), providing future semantic occupancy forecasts for use as auxiliary supervision or for model-based policy learning.",
            "model_type": "latent world model (task-aligned BEV space)",
            "task_domain": "autonomous driving (end-to-end policy learning and auxiliary world-model supervision)",
            "fidelity_metric": "accuracy of BEV segmentation forecasting / semantic occupancy prediction; downstream policy return and sample efficiency",
            "fidelity_performance": null,
            "interpretability_assessment": "Higher interpretability than image-space latent models because BEV semantic maps are human-interpretable and show predicted freespace/occupancy.",
            "interpretability_method": "Visualization of predicted BEV semantic maps and occupancy; use of semantic layers that correspond to human concepts (lane, vehicle, pedestrian).",
            "computational_cost": "Lower than image-space generative models due to dense but lower-dimensional BEV semantics; still requires training world-model components (encoder, transition, decoder).",
            "efficiency_comparison": "Survey suggests BEV-space world models are more computationally efficient and more task-relevant than raw-image world models, enabling better sample efficiency gains for RL.",
            "task_performance": "Reported as improving sample efficiency and robustness as an auxiliary task combined with IL/RL in driving setups; no numeric metrics provided in survey.",
            "task_utility_analysis": "Because BEV focuses on task-relevant semantics (occupancy, lanes), high fidelity in BEV predictions more directly benefits planning/policies than pixel-accurate image predictions.",
            "tradeoffs_observed": "Using BEV trades off raw visual realism for task-aligned semantics and interpretability, improving usefulness for planning while reducing modeling difficulty.",
            "design_choices": "Choice to model in BEV segmentation space (semantic abstraction) rather than pixel space; inclusion as auxiliary loss vs primary training target.",
            "comparison_to_alternatives": "Compared favorably to image-space world models for driving because BEV models better capture planning-relevant information at lower cost.",
            "optimal_configuration": "Survey recommends learning world models in BEV/semantic spaces for driving as a pragmatic balance of fidelity, interpretability, efficiency, and task utility.",
            "uuid": "e1226.5",
            "source_info": {
                "paper_title": "End-to-End Autonomous Driving: Challenges and Frontiers",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "DeRL",
            "name_full": "DeRL (Model-Free + Model-Based Fusion)",
            "brief_description": "A hybrid approach that fuses a model-free actor-critic agent with a learned world model by combining self-assessments (action or state estimates) from both models to improve policy learning.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "DeRL (hybrid model-free/model-based fusion)",
            "model_description": "Maintains both a model-free actor-critic policy and a learned world model; fuses assessments from both sources (e.g., Q-values, imagined returns) to supervise or refine policy updates.",
            "model_type": "hybrid world model (model-free + learned model fusion)",
            "task_domain": "autonomous driving RL / imitation learning augmentation",
            "fidelity_metric": "agreement/disagreement between model-free and model-based estimates; downstream policy return and stability",
            "fidelity_performance": null,
            "interpretability_assessment": "Provides more interpretability than purely black-box model-free approaches by exposing model-based imagined predictions and their agreement with model-free estimates.",
            "interpretability_method": "Comparative analysis of model-free vs model-based self-assessment signals; inspection of when and why they diverge.",
            "computational_cost": "Costs of running both model-free training and maintaining a world model; additional fusion overhead but can reduce sample complexity overall.",
            "efficiency_comparison": "Survey suggests this hybrid approach can leverage advantages of each paradigm (robustness of model-free, sample-efficiency of model-based), but exact efficiency gains are not quantified.",
            "task_performance": "Described as a way to improve training stability and performance by combining complementary signals; no precise task metrics given.",
            "task_utility_analysis": "Useful in settings where pure model-based rollouts may be unreliable: model-free critic provides a complementary signal that can correct model bias.",
            "tradeoffs_observed": "Increased system complexity and compute for potentially improved sample efficiency and robustness.",
            "design_choices": "Which signals to fuse (action, state, value), how to weight them, and mechanisms to detect model inaccuracy are key design choices.",
            "comparison_to_alternatives": "Compared to pure model-free RL: aims to reduce sample complexity; compared to pure model-based RL: aims to reduce sensitivity to model inaccuracies.",
            "optimal_configuration": "Survey notes DeRL-like hybrids are promising but does not prescribe a definitive configuration; tuning fusion mechanisms is important.",
            "uuid": "e1226.6",
            "source_info": {
                "paper_title": "End-to-End Autonomous Driving: Challenges and Frontiers",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "TrafficBots",
            "name_full": "TrafficBots (world models for simulation & motion prediction)",
            "brief_description": "A work that formulates world models specifically for driving-related simulation and motion prediction tasks, focusing on generating realistic multi-agent behaviors useful for both simulation and planning.",
            "citation_title": "TrafficBots: Towards world models for autonomous driving simulation and motion prediction",
            "mention_or_use": "mention",
            "model_name": "TrafficBots world model",
            "model_description": "A learned model of multi-agent traffic dynamics that can be used both for simulating realistic traffic in closed-loop evaluation and for motion prediction, likely combining data-driven agent models with learned interaction dynamics.",
            "model_type": "neural multi-agent world model (simulation & prediction)",
            "task_domain": "autonomous driving simulation, motion prediction, and benchmarking",
            "fidelity_metric": "realism of generated traffic trajectories (distributional match to real data), motion prediction error metrics, and usefulness for stress-testing driving policies",
            "fidelity_performance": null,
            "interpretability_assessment": "Provides interpretable traffic-level outputs (trajectories, agent intents) though internal interaction modeling remains learned and opaque.",
            "interpretability_method": "Visualization of generated multi-agent trajectories and scenario statistics; comparison to real-world distributions.",
            "computational_cost": "Not specified in survey; data-driven traffic/world models require training on large multi-agent datasets and have runtime costs for simulating many agents.",
            "efficiency_comparison": "Survey positions such world models as efficient alternatives to hand-crafted or rule-based traffic simulators (IDM) for generating realistic scenarios, but concrete efficiency numbers aren't provided.",
            "task_performance": "Useful for generating realistic and diverse traffic scenarios for closed-loop evaluation and training; no quantitative metrics reported in survey excerpt.",
            "task_utility_analysis": "High utility for simulation-based benchmarking and for producing realistic interactive behaviors that improve evaluation fidelity for driving policies.",
            "tradeoffs_observed": "Data-driven realism vs generalization to rare or safety-critical cases; learned models may reproduce biases present in data.",
            "design_choices": "Modeling agent interactions, conditioning on maps/goals, and balancing stochasticity vs physical plausibility are key choices.",
            "comparison_to_alternatives": "Compared to rule-based traffic models (e.g., IDM), TrafficBots aims to capture richer, learned interactions at the cost of data/training requirements.",
            "optimal_configuration": "Survey suggests learned traffic/world models are a promising component of the simulation stack for driving, but stresses need to ensure physical plausibility and coverage of rare events.",
            "uuid": "e1226.7",
            "source_info": {
                "paper_title": "End-to-End Autonomous Driving: Challenges and Frontiers",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "Vista",
            "name_full": "Vista (A generalizable driving world model with high fidelity and versatile controllability)",
            "brief_description": "A driving-specific world model that emphasizes high-fidelity forecasting and controllability for downstream tasks such as planning and policy learning, introduced as a recent example of a driving world model.",
            "citation_title": "Vista: A generalizable driving world model with high fidelity and versatile controllability",
            "mention_or_use": "mention",
            "model_name": "Vista driving world model",
            "model_description": "A driving-focused world model designed for high-fidelity forecasting and controllable generation of future scenes (likely in BEV or multi-view representations) to support planning and policy evaluation.",
            "model_type": "domain-specific learned world model (driving)",
            "task_domain": "autonomous driving simulation, forecasting and planning",
            "fidelity_metric": "high-fidelity forecasting metrics (unspecified in survey) and controllability benchmarks for scene generation",
            "fidelity_performance": null,
            "interpretability_assessment": "Survey references Vista as having high fidelity and controllability; likely offers interpretable predicted scene representations (e.g., BEV forecasts), but internal model interpretability unspecified.",
            "interpretability_method": "Visualization of predicted controlled futures and BEV/state-space forecasts; not further detailed in survey.",
            "computational_cost": "Not specified in the survey; likely non-trivial given 'high fidelity' claims.",
            "efficiency_comparison": "Survey cites Vista as a high-fidelity, generalizable world model for driving; no head-to-head efficiency numbers provided.",
            "task_performance": "Reported in survey references as a recent advancement that achieves high fidelity and controllability for driving world modeling, but the survey does not include numeric task metrics.",
            "task_utility_analysis": "Designed to directly support planning and forecasting tasks in autonomous driving by providing controllable, high-fidelity future predictions; considered a promising direction in the survey.",
            "tradeoffs_observed": "High fidelity and controllability likely come at computational and data cost; survey notes need to balance fidelity vs tractability for downstream planning.",
            "design_choices": "Emphasis on BEV or task-aligned representations, controllable conditioning inputs, and generalizability across scenarios.",
            "comparison_to_alternatives": "Posited as an improvement over naive image-space models and generic latent models for driving due to its emphasis on fidelity and controllability; no quantitative comparisons provided in survey.",
            "optimal_configuration": "Survey suggests that a driving 'foundation' model could be a world model trained to forecast reasonable futures in 2D/3D/latent spaces with task-sophisticated objectives; Vista is given as an example of this direction.",
            "uuid": "e1226.8",
            "source_info": {
                "paper_title": "End-to-End Autonomous Driving: Challenges and Frontiers",
                "publication_date_yy_mm": "2024-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Dream to control: Learning behaviors by latent imagination",
            "rating": 2,
            "sanitized_title": "dream_to_control_learning_behaviors_by_latent_imagination"
        },
        {
            "paper_title": "Iso-dream: Isolating and leveraging noncontrollable visual dynamics in world models",
            "rating": 2,
            "sanitized_title": "isodream_isolating_and_leveraging_noncontrollable_visual_dynamics_in_world_models"
        },
        {
            "paper_title": "TrafficBots: Towards world models for autonomous driving simulation and motion prediction",
            "rating": 2,
            "sanitized_title": "trafficbots_towards_world_models_for_autonomous_driving_simulation_and_motion_prediction"
        },
        {
            "paper_title": "Vista: A generalizable driving world model with high fidelity and versatile controllability",
            "rating": 2,
            "sanitized_title": "vista_a_generalizable_driving_world_model_with_high_fidelity_and_versatile_controllability"
        },
        {
            "paper_title": "Enhance sample efficiency and robustness of end-to-end urban autonomous driving via semantic masked world model",
            "rating": 2,
            "sanitized_title": "enhance_sample_efficiency_and_robustness_of_endtoend_urban_autonomous_driving_via_semantic_masked_world_model"
        },
        {
            "paper_title": "Model-predictive policy learning with uncertainty regularization for driving in dense traffic",
            "rating": 1,
            "sanitized_title": "modelpredictive_policy_learning_with_uncertainty_regularization_for_driving_in_dense_traffic"
        }
    ],
    "cost": 0.021874499999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>End-to-end Autonomous Driving: Challenges and Frontiers
2021 2022 2023</p>
<p>Li Chen 
are with OpenDriveLab
Shanghai AI Lab
ShanghaiChina</p>
<p>University of Hong Kong
Hong KongChina. P. Wu</p>
<p>Penghao Wu 
are with OpenDriveLab
Shanghai AI Lab
ShanghaiChina</p>
<p>Kashyap Chitta 
are with OpenDriveLab
Shanghai AI Lab
ShanghaiChina</p>
<p>Bernhard Jaeger 
are with OpenDriveLab
Shanghai AI Lab
ShanghaiChina</p>
<p>Andreas Geiger 
are with OpenDriveLab
Shanghai AI Lab
ShanghaiChina</p>
<p>Shanghai AI Lab
ShanghaiChina. K. Chitta, B</p>
<p>Hongyang Li lihongyang@pjlab.org.cn 
are with OpenDriveLab
Shanghai AI Lab
ShanghaiChina</p>
<p>University of Hong Kong
Hong KongChina. P. Wu</p>
<p>Transfuser King 
Shanghai AI Lab
ShanghaiChina. K. Chitta, B</p>
<p>End-to-end Autonomous Driving: Challenges and Frontiers
2021 2022 2023D8DFA825A4968CFCB5A4927AF4B79942arXiv:2306.16927v3[cs.RO]Autonomous DrivingEnd-to-end System DesignPolicy LearningSimulation Section 1 Benchmarking Section 3 Imitation Learning -Behavior Cloning Reinforcement Learning Imitation Learning -Inverse Optimal Control
The autonomous driving community has witnessed a rapid growth in approaches that embrace an end-to-end algorithm framework, utilizing raw sensor input to generate vehicle motion plans, instead of concentrating on individual tasks such as detection and motion prediction.End-to-end systems, in comparison to modular pipelines, benefit from joint feature optimization for perception and planning.This field has flourished due to the availability of large-scale datasets, closed-loop evaluation, and the increasing need for autonomous driving algorithms to perform effectively in challenging scenarios.In this survey, we provide a comprehensive analysis of more than 270 papers, covering the motivation, roadmap, methodology, challenges, and future trends in end-to-end autonomous driving.We delve into several critical challenges, including multi-modality, interpretability, causal confusion, robustness, and world models, amongst others.Additionally, we discuss current advancements in foundation models and visual pre-training, as well as how to incorporate these techniques within the end-to-end driving framework.We maintain an active repository that contains up-to-date literature and open-source projects at https://github.com/OpenDriveLab/End-to-end-Autonomous-Driving.</p>
<p>INTRODUCTION</p>
<p>C ONVENTIONAL autonomous driving systems adopt a modular design strategy, wherein each functionality, such as perception, prediction, and planning, is individually developed and integrated into onboard vehicles.The planning or control module, responsible for generating steering and acceleration outputs, plays a crucial role in determining the driving experience.The most common approach for planning in modular pipelines involves using sophisticated rule-based designs, which are often ineffective in addressing the vast number of situations that occur on road.Therefore, there is a growing trend to leverage large-scale data and to use learning-based planning as a viable alternative.</p>
<p>We define end-to-end autonomous driving systems as fully differentiable programs that take raw sensor data as input and produce a plan and/or low-level control actions as output.Fig. 1 (a)-(b) illustrates the difference between the classical and end-to-end formulation.The conventional approach feeds the output of each component, such as bounding boxes and vehicle trajectories, directly into subsequent units (dashed arrows).In contrast, the end-to-end paradigm propagates feature representations across components (gray solid arrow).The optimized function is set to be, for example, the planning performance, and the loss is minimized via back-propagation (red arrow).Tasks are jointly and globally optimized in this process.</p>
<p>In this survey, we conduct an extensive review of this emerging topic.Fig. 1 provides an overview of our work.We begin by discussing the motivation and roadmap for end-toend autonomous driving systems.End-to-end approaches can be broadly classified into imitation and reinforcement learning, and we give a brief review of these methodologies.We cover datasets and benchmarks for both closed and open-loop evaluation.We summarize a series of critical challenges, including interpretability, generalization, world models, causal confusion, etc.We conclude by discussing future trends that we think should be embraced by the community to incorporate the latest developments from data engines, and large foundation models, amongst others.Note that this review is mainly orchestrated from a theoretical perspective.Engineering efforts such as version control, unit testing, data servers, data cleaning, software-hardware co-design, etc., play crucial roles in deploying the end-toend technology.Publicly available information regarding the latest practices on these topics is limited.We invite the community towards more openness in future discussions.</p>
<p>Motivation of an End-to-end System</p>
<p>In the classical pipeline, each model serves a standalone component and corresponds to a specific task (e.g., traffic light detection).Such a design is beneficial in terms of interpretability and ease of debugging.However, since the optimization objectives across modules are different, with detection pursuing mean average precision (mAP) while planning aiming for driving safety and comfort, the entire system may not be aligned with a unified target, i.e., the ultimate planning/control task.Errors from each module, as the sequential procedure proceeds, could be compounded and result in an information loss.Moreover, compared to one end-to-end neural network, the multi-task, multi-model deployment which involves multiple encoders and message transmission systems, may increase the computational burden and potentially lead to sub-optimal use of compute.</p>
<p>In contrast to its classical counterpart, an end-to-end autonomous system offers several advantages.(a) The most apparent merit is its simplicity in combining perception, prediction, and planning into a single model that can be jointly trained.(b) The whole system, including its intermediate representations, is optimized towards the ultimate task.(c) Shared backbones increase computational efficiency.(d) Data-driven optimization has the potential to improve the system by simply scaling training resources.</p>
<p>Note that the end-to-end paradigm does not necessarily indicate one black box with only planning/control outputs.It could have intermediate representations and outputs (Fig. 1 (b)) as in classical approaches.In fact, several state-ofthe-art systems [1,2] propose a modular design but optimize all components together to achieve superior performance.</p>
<p>Roadmap</p>
<p>Fig. 2 depicts a chronological roadmap of critical achievements in end-to-end autonomous driving, where each part indicates an essential paradigm shift or performance boost.The history of end-to-end autonomous driving dates back to 1988 with ALVINN [3], where the input was two "retinas" from a camera and a laser range finder, and a simple neural network generated steering output.NVIDIA designed a prototype end-to-end CNN system, which reestablished this idea in the new era of GPU computing [8].Notable progress has been achieved with the development of deep neural networks, both in imitation learning [15,16] and reinforcement learning [4,17,18,19].The policy distillation paradigm proposed in LBC [5] and related approaches [20,21,22,23] has significantly improved closed-loop performance by mimicking a well-behaved expert.To enhance generalization ability due to the discrepancy between the expert and learned policy, several papers [10,24,25] have proposed aggregating on-policy data [26] during training.</p>
<p>A significant turning point occurred around 2021.With diverse sensor configurations available within a reasonable computational budget, attention was focused on incorporating more modalities and advanced architectures (e.g., Transformers [27]) to capture global context and representative features, as in TransFuser [6,28] and many variants [29,30,31].Combined with more insights about the simulation environment, these advanced designs resulted in a substantial performance boost on the CARLA benchmark [13].To improve the interpretability and safety of autonomous systems, approaches [11,32,33] explicitly involve various auxiliary modules to better supervise the learning process or utilize attention visualization.Recent works prioritize generating safety-critical data [7,34,35 Fig. 2: Roadmap of End-to-end Autonomous Driving.We present the key milestones chronologically, grouping similar works under the same theme.The representative or first work is shown in bold with an illustration, while the date of the rest of the literature in the same theme may vary.We also display the score for each year's top entry in the CARLA leaderboard [13] (DS, ranging from 0 to 100) and the recent nuPlan challenge [14] (Score ranging from 0 to 1).</p>
<p>foundation model or backbone curated for policy learning [12,36,37], and advocating a modular end-to-end planning philosophy [1,2,38,39].Meanwhile, the new and challenging CARLA v2 [13] and nuPlan [14] benchmarks have been introduced to facilitate research into this area.</p>
<p>Comparison to Related Surveys</p>
<p>We would like to clarify the difference between our survey and previous related surveys [40,41,42,43,44,45,46,47,48].Some prior surveys [40,41,42,43] cover content similar to ours in the sense of an end-to-end system.However, they do not cover new benchmarks and approaches that arose with the significant recent transition in the field, and place a minor emphasis on frontiers and challenges.The others focus on specific topics in this domain, such as imitation learning [44,45,46] or reinforcement learning [47,48].In contrast, our survey provides up-to-date information on the latest developments in this field, covering a wide span of topics and providing in-depth discussions of critical challenges.</p>
<p>Contributions</p>
<p>To summarize, this survey has three key contributions: (a) We provide a comprehensive analysis of end-to-end autonomous driving for the first time, including high-level motivation, methodologies, benchmarks, and more.Instead of optimizing a single block, we advocate for a philosophy to design the algorithm framework as a whole, with the ultimate target of achieving safe and comfortable driving.</p>
<p>(b)</p>
<p>We extensively investigate the critical challenges that concurrent approaches face.Out of the more than 270 papers surveyed, we summarize major aspects and provide in-depth analysis, including topics on generalizability, language-guided learning, causal confusion, etc. (c) We cover the broader impact of how to embrace large foundation models and data engines.We believe that this line of research and the large scale of high-quality data it provides could significantly advance this field.To facilitate future research, we maintain an active repository updated with new literature and open-source projects.</p>
<p>METHODS</p>
<p>This section reviews fundamental principles behind most existing end-to-end self-driving approaches.Sec.2.1 discusses methods using imitation learning and provides details on the two most popular sub-categories, namely behavior cloning and inverse optimal control.Sec.2.2 summarizes methods that follow the reinforcement learning paradigm.</p>
<p>Imitation Learning</p>
<p>Imitation learning (IL), also referred to as learning from demonstrations, trains an agent to learn the policy by imitating the behavior of an expert.IL requires a dataset D = {Î¾ i } containing trajectories collected under the expert's policy Ï€ Î² , where each trajectory is a sequence of state-action pairs.The goal of IL is to learn an agent policy Ï€ that matches Ï€ Î² .The policy Ï€ can output planned trajectories or control signals.Early works usually adopt control outputs, due to the ease of collection.However, predicting controls at different steps could lead to discontinuous maneuvers and the network inherently specializes to the vehicle dynamics which hinders generalization to other vehicles.Another genre of works predicts waypoints.It considers a relatively longer time horizon.Meanwhile, converting trajectories for vehicles to track into control signals needs additional controllers, which is non-trivial and involves vehicle models and control algorithms.Since no clear performance gap has been observed between these two paradigms, we do not differentiate them explicitly in this survey.An interesting and more in-depth discussion can be found in [22].</p>
<p>One widely used category of IL is behavior cloning (BC) [49], which reduces the problem to supervised learning.Inverse Optimal Control (IOC), also known as Inverse Reinforcement Learning (IRL) [50] is another type of IL method that utilizes expert demonstrations to learn a reward function.We elaborate on these two categories below.</p>
<p>Behavior Cloning</p>
<p>In BC, matching the agent's policy with the expert's is accomplished by minimizing planning loss as supervised Early applications of BC for driving [3,8,51] utilized an end-to-end neural network to generate control signals from camera inputs.Further enhancements, such as multi-sensor inputs [6,52], auxiliary tasks [16,28], and improved expert design [21], have been proposed to enable BC-based end-toend driving models to handle challenging urban scenarios.</p>
<p>BC is advantageous due to its simplicity and efficiency, as it does not require hand-crafted reward design, which is crucial for RL.However, there are some common issues.During training, it treats each state as independently and identically distributed, resulting in an important problem known as covariate shift.For general IL, several onpolicy methods have been proposed to address this issue [26,53,54,55].In the context of end-to-end autonomous driving, DAgger [26] has been adopted in [5,10,25,56].Another common problem with BC is causal confusion, where the imitator exploits and relies on false correlations between certain input components and output signals.This issue has been discussed in the context of end-to-end autonomous driving in [57,58,59,60].These two challenging problems are further discussed in Sec.4.9 and Sec.4.8, respectively.</p>
<p>Inverse Optimal Control</p>
<p>Traditional IOC algorithms learn an unknown reward function R(s, a) from expert demonstrations, where the expert's reward function can be represented as a linear combination of features [50,61,62,63,64].However, in continuous, highdimensional autonomous driving scenarios, the definition of the reward is implicit and difficult to optimize.</p>
<p>Generative adversarial imitation learning [65,66,67] is a specialized approach in IOC that designs the reward function as an adversarial objective to distinguish the expert and learned policies, similar to the concept of generative adversarial networks [68].Recently, several works propose optimizing a cost volume or cost function with auxiliary perceptual tasks.Since a cost is an alternative representation of the reward, we classify these methods as belonging to the IOC domain.We define the cost learning framework as follows: end-to-end approaches learn a reasonable cost c(â€¢) and use algorithmic trajectory samplers to select the trajectory Ï„ * with the minimum cost, as illustrated in Fig. 3.</p>
<p>Regarding cost design, it has representations including a learned cost volume in a bird's-eye-view (BEV) [32], joint energy calculated from other agents' future motion [69], or a set of probabilistic semantic occupancy or freespace layers [39,70,71].On the other hand, trajectories are typically sampled from a fixed expert trajectory set [1,72] or processed by parameter sampling with a kinematic model [32,38,39,70].Then, a max-margin loss is adopted as in classic IOC methods to encourage the expert demonstration to have a minimal cost while others have high costs.</p>
<p>Several challenges exist with cost learning approaches.In particular, in order to generate more realistic costs, HD maps, auxiliary perception tasks, and multiple sensors are typically incorporated, which increases the difficulty of learning and constructing datasets for multi-modal multitask frameworks.Nevertheless, the aforementioned cost learning methods significantly enhance the safety and interpretability of decisions (see Sec. 4.6), and we believe that the industry-inspired end-to-end system design is a viable approach for real-world applications.</p>
<p>Reinforcement Learning</p>
<p>Reinforcement learning (RL) [73,74] is a field of learning by trial and error.The success of deep Q networks (DQN) [75] in achieving human-level control on the Atari benchmark [76] has popularized deep RL.DQN trains a neural network called the critic (or Q network), which takes as input the current state and an action, and predicts the discounted return of that action.The policy is then implicitly defined by selecting the action with the highest predicted return.</p>
<p>RL requires an environment that allows potentially unsafe actions to be executed, to collect novel data (e.g., via random actions).Additionally, RL requires significantly more data to train than IL.For this reason, modern RL methods often parallelize data collection across multiple environments [77].Meeting these requirements in the real world presents great challenges.Therefore, almost all papers that use RL in driving have only investigated the technique in simulation.Most use different extensions of DQN.The community has not yet converged on a specific RL algorithm.</p>
<p>RL has successfully learned lane following on a real car on an empty street [4].Despite this encouraging result, it must be noted that a similar task was already accomplished by IL three decades prior [3].To date, no report has shown results for end-to-end training with RL that are competitive with IL.The reason for this failure likely is that the gradients obtained via RL are insufficient to train deep perception architectures (i.e., ResNet) required for driving.Models used in benchmarks like Atari, where RL succeeds, are relatively shallow, consisting of only a few layers [78].</p>
<p>RL has been successfully applied in end-to-end driving when combined with supervised learning (SL).Implicit affordances [18,19] pre-train the CNN encoder using SL with tasks like semantic segmentation.In the second stage, this encoder is frozen, and a shallow policy head is trained on the features from the frozen encoder with a modern version of Q-learning [79].RL can also be used to finetune full networks that were pre-trained using IL [17,80].</p>
<p>RL can also been effectively applied, if the network has access to privileged simulator information.[48,81,82].Privileged RL agents can be used for dataset curation.Roach [21] trains an RL agent on privileged BEV semantic maps and uses the policy to automatically collect a dataset with which a downstream IL agent is trained.WoR [20] employs a Q-function and tabular dynamic programming to generate additional or improved labels for a static dataset.</p>
<p>A challenge in the field is to transfer the findings from simulation to the real world.In RL, the objective is expressed as reward functions, and many algorithms require them to be dense and provide feedback at each environment step.Current works typically use simple objectives, such as progress and collision avoidance.These simplistic designs potentially encourage risky behaviors [81].Devising or learning better reward functions remains an open problem.Another direction would be to develop RL algorithms that can handle sparse rewards, enabling the optimization of relevant metrics directly.RL can be effectively combined with world models [83,84,85], though this presents specific challenges (See Sec.4.3).Current RL solutions for driving rely heavily on low-dimensional representations of the scene, and this issue is further discussed in Sec.4.2.2.</p>
<p>BENCHMARKING</p>
<p>Autonomous driving systems require a comprehensive evaluation to ensure safety.Researchers must benchmark these systems using appropriate datasets, simulators, metrics, and hardware to accomplish this.This section delineates three approaches for benchmarking end-to-end autonomous driving systems: (1) real-world evaluation, (2) online or closedloop evaluation in simulation, and ( 3) offline or open-loop evaluation on driving datasets.We focus on the scalable and principled online simulation setting and summarize realworld and offline assessments for completeness.</p>
<p>Real-world Evaluation</p>
<p>Early efforts on benchmarking self-driving involved realworld evaluation.Notably, DARPA initiated a series of races.The first event offered $1M in prize money for autonomously navigating a 240km route through the Mojave desert, which no team achieved [86].The final series event, called the DARPA Urban Challenge, required vehicles to navigate a 96km mock-up town course, adhering to traffic laws and avoiding obstacles [87].These races fostered important developments in self-driving, such as LiDAR sensors.Following this spirit, the University of Michigan established MCity [88], a large controlled real-world environment to facilitate testing autonomous vehicles.However, such academic ventures have not been widely employed for end-to-end systems due to a lack of data and vehicles.In contrast, industries with the resources to deploy fleets of driverless vehicles could rely on real-world evaluation to benchmark improvements in their algorithms.</p>
<p>Online/Closed-loop Simulation</p>
<p>Conducting tests of self-driving systems in the real world is costly and risky.To address this challenge, simulation is a viable alternative [14,89,90,91,92,93].Simulators facilitate rapid prototyping and testing, enable the quick iteration of ideas, and provide low-cost access to diverse scenarios for unit testing.In addition, simulators offer tools for measuring performance accurately.However, their primary disadvantage is that the results obtained in a simulated environment do not necessarily generalize to the real world (Sec.4.9.3).</p>
<p>Closed-loop evaluation involves building a simulated environment that closely mimics a real-world driving environment.The evaluation entails deploying the driving system in simulation and measuring its performance.The system has to navigate safely through traffic while progressing toward a designated goal location.There are four main sub-tasks involved in developing such simulators: parameter initialization, traffic simulation, sensor simulation, and vehicle dynamics simulation.We briefly describe these subtasks below, followed by a summary of currently available open-source simulators for closed-loop benchmarks.</p>
<p>Parameter Initialization</p>
<p>Simulation offers the benefit of a high degree of control over the environment, including weather, maps, 3D assets, and low-level attributes such as the arrangement of objects in a traffic scene.While powerful, the number of these parameters is substantial, resulting in a challenging design problem.Current simulators tackle this in two ways:</p>
<p>Procedural Generation: Traditionally, initial parameters are hand-tuned by 3D artists and engineers [89,90,91,92].This limits scalability.Recently, some of the simulation properties can be sampled from a probabilistic distribution with computer algorithms, which we refer to as procedural generation [94].Procedural generation algorithms combine rules, heuristics, and randomization to create diverse road networks, traffic patterns, lighting conditions, and object placements [95,96].Due to its efficiency compared to fully manual design, it has become one of the most commonly used methods of initialization for video games and simulations.Nevertheless, the process still needs pre-defined parameters and algorithms to control generation reliability, which is time-consuming and requires a lot of expertise.</p>
<p>Data-Driven: Data-driven approaches for simulation initialization aim to learn the required parameters.Arguably, the simplest way is to sample from real-world driving logs [14,93], where parameters such as road maps or traffic patterns are directly extracted from pre-recorded datasets.The advantage of log sampling is its ability to capture the natural variability present in real-world data, leading to more realistic simulation scenarios.However, it may not encompass rare situations that are critical for testing the robustness of autonomous driving systems.The initial parameters can be optimized to increase the representation of such scenarios [7,34,35].Another advanced data-driven approach to initialization is generative modeling, where machine learning algorithms are utilized to learn the underlying structure and distributions of real-world data.They can then generate novel scenarios that resemble the real world but were not included in the original data [97,98,99,100].</p>
<p>Traffic Simulation</p>
<p>Traffic simulation involves generating and positioning virtual entities in the environment with realistic motion [98,101].These entities often include vehicles (such as cars, motorcycles, bicycles, etc.) and pedestrians.Traffic simulators must account for the effects of speed, acceleration, braking, obstructions, and the behavior of other entities.Moreover, traffic light states must be periodically updated to simulate realistic city driving.There are two popular approaches for traffic simulation, which we describe below.</p>
<p>Rule-Based: Rule-based traffic simulators use predefined rules to generate the motion of traffic entities.The most prominent implementation of this concept is the Intelligent Driver Model (IDM) [102].IDM is a car-following model that computes acceleration for each vehicle based on its current speed, the speed of the leading vehicle, and a desired safety distance.Although widely used and straightforward, this approach may be inadequate to simulate realistic motion and complex interactions in urban environments.</p>
<p>Data-Driven: Realistic human traffic behavior is highly interactive and complex, including lane changing, merging, sudden stopping, etc.To model such behavior, data-driven traffic simulation utilizes data collected from real-world driving.These models can capture more nuanced, realistic behavior but require significant amounts of labeled data for training.A wide variety of learning-based techniques have been proposed for this task [98,99,101,103,104,105].</p>
<p>Sensor Simulation</p>
<p>Sensor simulation is crucial for evaluating end-to-end selfdriving systems.This involves generating simulated raw sensor data, such as camera images or LiDAR scans that the driving system would receive from different viewpoints in the simulator [106,107,108].This process needs to take into account noise and occlusions to realistically assess the autonomous system.There are two main branches of ideas concerning sensor simulation, as described below.</p>
<p>Graphics-Based: Recent computer graphics simulators use 3D models of the environment, along with traffic entity models, to generate sensor data via approximations of physical rendering processes in the sensors [90,91].For example, this can involve occlusions, shadows, and reflections present in real-world environments while simulating camera images.However, the realism of graphics-based simulation is often subpar or comes at the cost of heavy computation, making parallelization non-trivial [109].It is closely tied to the quality of the 3D models and the approximations used in modeling the sensors.A comprehensive survey of graphicsbased rendering for driving data is provided in [110].</p>
<p>Data-Driven: Data-driven sensor simulation leverages real-world sensor data to create the simulation where both the ego vehicle and background traffic may move differently from the way they did in recordings [111,112,113].Popular methods are Neural Radiance Fields (NeRF) [114] and 3D Gaussian Splatting [115], which can generate novel views of a scene by learning an implicit representation of the scene's geometry and appearance.These methods can produce more realistic sensor data visually than graphics-based approaches, but they have limitations such as high rendering times or requiring independent training for each scene being</p>
<p>Simulator Benchmarks</p>
<p>CARLA</p>
<p>CoRL [91], noCrash [124], Town05 [6], LAV [52], Roach [21], Longest6 [28], Leaderboard v1 and v2 [13] nuPlan NAVSIM [125], Val14 [126], Leaderboard [14] TABLE 1: Open-source Simulators with active benchmarks for closed-loop evaluation of autonomous driving.</p>
<p>reconstructed [108,116,117,118,119].Another approach to data-driven sensor simulation is domain adaptation, which aims to minimize the gap between real and graphics-based simulated sensor data [120].Deep learning techniques such as GANs can be employed to improve realism (Sec.4.9.3).</p>
<p>Vehicle Dynamics Simulation</p>
<p>The final aspect of driving simulation pertains to ensuring that the simulated vehicle adheres to physically plausible motion.Most existing publicly available simulators use highly simplified vehicle models, such as the unicycle model [121] or the bicycle model [122].However, in order to facilitate seamless transfer of algorithms from simulation to the real world, it is essential to incorporate more accurate physical modeling of vehicle dynamics.For instance, CARLA adopts a multi-body system approach, representing a vehicle as a collection of sprung masses on four wheels.For a comprehensive review, please refer to [123].</p>
<p>Benchmarks</p>
<p>We give a succinct overview of end-to-end driving benchmarks available up to date in Table 1.In 2019, the original benchmark released with CARLA [91] was solved with nearperfect scores [5].The subsequent NoCrash benchmark [124] involves training on a single CARLA town under specific weather conditions and testing generalization to another town and set of weathers.Instead of a single town, the Town05 benchmark [6] involves training on all available towns while withholding Town05 for testing.Similarly, the LAV benchmark trains on all towns except Town02 and Town05, which are both reserved for testing.Roach [21] uses a setting with 3 test towns, albeit all seen during training, and without the safety-critical scenarios in Town05 and LAV.Finally, the Longest6 benchmark [28] uses 6 test towns.Two online servers, the leaderboard (v1 and v2) [13], ensure fair comparisons by keeping evaluation routes confidential.Leaderboard v2 is highly challenging due to the long route length (over 8km on average, as opposed to 1-2km on v1) and a wide variety of new traffic scenarios.The nuPlan simulator is currently accessible for evaluating end-to-end systems via the NAVSIM project [125].Further, there are two benchmarks on which agents input maps and object properties via the data-driven parameter initialization for nuPlan (Sec.3.2.1).Val14, proposed in [126], uses a validation split of nuPlan.The leaderboard, a submission server with the private test set, was used in the 2023 nuPlan challenge, but it is no longer public for submissions.</p>
<p>Offline/Open-loop Evaluation</p>
<p>Open-loop evaluation mainly assesses a system's performance against pre-recorded expert driving behavior.This method requires evaluation datasets that include (1) sensor readings, (2) goal locations, and (3) corresponding future driving trajectories, usually obtained from human drivers.Given sensor inputs and goal locations as inputs, performance is measured by comparing the system's predicted future trajectory against the trajectory in the driving log.Systems are evaluated based on how closely their trajectory predictions match the human ground truth, as well as auxiliary metrics such as the collision probability with other agents.The advantage of open-loop evaluation is that it is easy to implement using realistic traffic and sensor data, as it does not require a simulator.However, the key disadvantage is that it does not measure performance in the actual test distribution encountered during deployment.During testing, the driving system may deviate from the expert driving corridor, and it is essential to verify the system's ability to recover from such drift (Sec.4.9.2).Furthermore, the distance between the predicted and the recorded trajectories is not an ideal metric in a multi-modal scenario.For example, in the case of merging into a turning lane, both the options of merging immediately or later could be valid, but open-loop evaluation penalizes the option that was not observed in the data.Therefore, besides measuring collision probability and prediction errors, a few metrics were proposed to cover more comprehensive aspects such as traffic violations, progress, and driving comfort [126].</p>
<p>This approach requires comprehensive datasets of trajectories to draw from.The most popular datasets for this purpose include nuScenes [127], Argoverse [128], Waymo [129], and nuPlan [14].All of these datasets comprise a large number of real-world driving traversals with varying degrees of difficulty.However, open-loop results do not provide conclusive evidence of improved driving behavior in closedloop, due to the aforementioned drawbacks [124,126,130,131].Overall, a realistic closed-loop benchmarking, if available and applicable, is recommended in future research.</p>
<p>CHALLENGES</p>
<p>Following each topic illustrated in Fig. 1, we now walk through current challenges, related works or potential resolutions, risks, and opportunities.We start with challenges in handling different input modalities in Sec.4.1, followed by a discussion on visual abstraction for efficient policy learning in Sec.4.2.Further, we introduce learning paradigms such as world model learning (Sec.4.3), multi-task frameworks (Sec.4.4), and policy distillation (Sec.4.5).Finally, we discuss general issues that impede safe and reliable end-to-end autonomous driving, including interpretability in Sec.4.6, safety guarantees in Sec.4.7, causal confusion in Sec.4.8, and robustness in Sec.4.9.</p>
<p>Dilemma over Sensing and Input Modalities</p>
<p>Sensing and Multi-sensor Fusion</p>
<p>Sensing: Though early work [8] successfully achieved following a lane with a monocular camera, this single input modality cannot handle complex scenarios.Therefore, various sensors in Fig. 4 have been introduced for recent selfdriving vehicles.Particularly, RGB images from cameras replicate how humans perceive the world, with abundant Multi-sensor fusion has predominantly been discussed in perception-related fields, e.g., object detection [132,133] and semantic segmentation [134,135], and is typically categorized into three groups: early, mid, and late fusion.Endto-end autonomous driving algorithms explore similar fusion schemes.Early fusion combines sensory inputs before feeding them into shared feature extractors, where concatenation is a common way for fusion [32,136,137,138,139].To resolve the view discrepancy, some works project point clouds on images [140] or vice versa (predicting semantic labels for LiDAR points [52,141]).On the other hand, late fusion combines multiple results from multi-modalities.It is less discussed due to its inferior performance [6,142].Contrary to these methods, middle fusion achieves multi-sensor fusion within the network by separately encoding inputs and then fusing them at the feature level.Naive concatenation is also frequently adopted [15,22,30,143,144,145,146,147].Recently, works have employed Transformers [27] to model interactions among features [6,28,29,148,149].The attention mechanism in Transformers has demonstrated great effectiveness in aggregating the context of different sensor inputs and achieving safer end-to-end driving.</p>
<p>Inspired by the progress in perception, it is beneficial to model modalities in a unified space such as BEV [132,133].End-to-end driving also requires identifying policyrelated contexts and discarding irrelevant details.We discuss perception-based representations in Sec.4.2.1.Besides, the self-attention layer, interconnecting all tokens freely, in-curs a significant computational cost and cannot guarantee useful information extraction.Advanced Transformer-based fusion mechanisms in the perception field, such as [150,151], hold promise for application to the end-to-end driving task.</p>
<p>Language as Input</p>
<p>Humans drive using both visual perception and intrinsic knowledge which together form causal behaviors.In areas related to autonomous driving such as embodied AI, incorporating natural language as fine-grained knowledge and instructions to control the visuomotor agent has achieved notable progress [152,153,154,155].However, compared to robotic applications, the driving task is more straightforward without the need for task decomposition, and the outdoor environment is much more complex with highly dynamic agents but few distinctive anchors for grounding.</p>
<p>To incorporate linguistic knowledge into driving, a few datasets are proposed to benchmark outdoor grounding and visual language navigation tasks [156,157,158,159].HAD [160] takes human-to-vehicle advice and adds a visual grounding task.Sriram et al. [161] translate natural language instructions into high-level behaviors, while [162,163] directly ground the texts.CLIP-MC [164] and LM-Nav [165] utilize CLIP [166] to extract both linguistic knowledge from instructions and visual features from images.</p>
<p>Recently, observing the rapid development of large language models (LLMs) [167,168], works encode the perceived scene into tokens and prompt them to LLMs for control prediction and text-based explanations [169,170,171].Researchers also formulate the driving task as a questionanswering problem and construct corresponding benchmarks [172,173].They highlight that LLMs offer opportunities to handle sophisticated instructions and generalize to different data domains, which share similar advantages to applications in robotic areas [174].However, LLMs for onroad driving could be challenging at present, considering their long inference time, low quantitative accuracy, and instability of outputs.Potential resolutions could be employing LLMs on the cloud specifically for complex scenarios and using them solely for high-level behavior prediction.</p>
<p>Dependence on Visual Abstraction</p>
<p>End-to-end autonomous driving systems roughly have two stages: encoding the state into a latent feature representation, and then decoding the driving policy with intermediate features.In urban driving, the input state, i.e., the surrounding environment and ego state, is much more diverse and high-dimensional compared to common policy learning benchmarks such as video games [18,175], which might lead to the misalignment between representations and necessary attention areas for policy making.Hence, it is helpful to design "good" intermediate perception representations, or first pre-train visual encoders using proxy tasks.This enables the network to extract useful information for driving effectively, thus facilitating the subsequent policy stage.Furthermore, this can improve the sample efficiency for RL methods.</p>
<p>Representation Design</p>
<p>Naive representations are extracted with various backbones.Classic convolutional neural networks (CNNs) still dominate, with advantages in translation equivariance and high efficiency [176].Depth-pre-trained CNNs [177] significantly boost perception and downstream performance.In contrast, Transformer-based feature extractors [178,179] show great scalability in perception tasks while not being widely adopted for end-to-end driving yet.For driving-specific representations, researchers introduce the concept of bird's-eyeview (BEV), fusing different sensor modalities and temporal information within a unified 3D space [133,180,181].It also facilitates easy adaptions to downstream tasks [2,30,182,183].In addition, grid-based 3D occupancy is developed to capture irregular objects and used for collision avoidance in planning [184].Nevertheless, the dense representation brings huge computation costs compared to BEV methods.</p>
<p>Another unsettled problem is representations of the map.Traditional autonomous driving relies on HD Maps.Due to the high cost of availability of HD Maps, online mapping methods have been devised with different formulations, such as BEV segmentation [185], vectorized lanlines [186], centerlines and their topology [187,188], and lane segments [189].However, the most suitable formulation for end-to-end systems remains unvalidated.</p>
<p>Though various representation designs offer possibilities of how to design the subsequent decision-making process, they also place challenges as co-designing both parts is necessary for a whole framework.Besides, given the trends observed in several simple yet effective approaches with scaling up training resources [22,28], the ultimate necessity of explicit representations such as maps is uncertain.</p>
<p>Representation Learning</p>
<p>Representation learning often incorporates certain inductive biases or prior information.There inevitably exist possible information bottlenecks in the learned representation, and redundant context unrelated to decisions may be removed.Some early methods directly utilize semantic segmentation masks from off-the-shelf networks as the input representation for subsequent policy training [190,191].SESR [192] further encodes segmentation masks into classdisentangled representations through a VAE [193].In [194,195], predicted affordance indicators, such as traffic light states, offset to the lane center, and distance to the leading vehicle, are used as representations for policy learning.</p>
<p>Observing that results like segmentation as representations can create bottlenecks defined by humans and result in loss of useful information, some have chosen intermediate features from pre-training tasks as effective representations for RL training [18,19,196,197].In [198], latent features in VAE are augmented by attention maps obtained from the diffused boundary of segmentation and depth maps to highlight important regions.TARP [199] utilizes data from a series of previous tasks to perform different tasks-related prediction tasks to acquire useful representations.In [200], the latent representation is learned by approximating the Ï€-bisimulation metric, which is comprised of differences of rewards and outputs from the dynamics model.ACO [36] learns discriminative features by adding steering angle categorization into the contrastive learning structure.Recently, PPGeo [12] proposes to learn effective representation through motion prediction together with depth estimation in a self-supervised way on uncalibrated driving videos.ViDAR [201] utilizes the raw image-point cloud pairs and pretrains the visual encoder with a point cloud forecasting pre-task.These works demonstrate that self-supervised representation learning from large-scale unlabeled data for policy learning is promising and worthy of future exploration.</p>
<p>Complexity of World Modeling for Model-based RL</p>
<p>Besides the ability to better abstract perceptual representations, it is essential for end-to-end models to make reasonable predictions about the future to take safe maneuvers.In this section, we mainly discuss the challenges of current model-based policy learning works, where a world model provides explicit future predictions for the policy model.</p>
<p>Deep RL typically suffers from the high sample complexity, which is pronounced in autonomous driving.Modelbased reinforcement learning (MBRL) offers a promising direction to improve sample efficiency by allowing agents to interact with the learned world model instead of the actual environment.MBRL methods employ an explicit world (environment) model, which is composed of transition dynamics and reward functions.This is particularly helpful in driving, as simulators like CARLA are relatively slow.</p>
<p>However, modeling the highly dynamic environment is a challenging task.To simplify the problem, Chen et al. [20] factor the transition dynamics into a non-reactive world model and a simple kinematic bicycle model.In [138], a probabilistic sequential latent model is used as the world model.To address the potential inaccuracy of the learned world model, Henaff et al. [202] train the policy network with dropout regularization to estimate the uncertainty cost.Another approach [203] uses an ensemble of multiple world models to provide uncertainty estimation, based on which imaginary rollouts could be truncated and adjusted accordingly.Motivated by Dreamer [83], ISO-Dream [204] decouples visual dynamics into controllable and uncontrollable states, and trains the policy on the disentangled states.</p>
<p>It is worth noting that learning world models in raw image space is non-trivial for autonomous driving.Important small details, such as traffic lights, would easily be missed in predicted images.To tackle this, a few works [205,206,207] employ the prevailing diffusion technique [208].MILE [209] incorporates the Dreamer-style world model learning in the BEV segmentation space as an auxiliary task besides imitation learning.SEM2 [137] also extends the Dreamer structure but with BEV map inputs, and uses RL for training.Besides directly using the learned world model for MBRL, DeRL [197] combines a model-free actor-critic framework with the world model, by fusing self-assessments of the action or state from both models.</p>
<p>World model learning for end-to-end autonomous driving is an emerging and promising direction as it greatly reduces the sample complexity for RL, and understanding the world is helpful for driving.However, as the driving environment is highly complex and dynamic, further study is still needed to determine what needs to be modeled and how to model the world effectively.</p>
<p>Reliance on Multi-Task Learning</p>
<p>Multi-task learning (MTL) involves jointly performing several related tasks based on a shared representation through separate heads.MTL provides advantages such as computational cost reduction, the sharing of relevant domain knowledge, and the ability to exploit task relationships to improve model's generalization ability [210].Consequently, MTL is well-suited for end-to-end driving, where the ultimate policy prediction requires a comprehensive understanding of the environment.However, the optimal combination of auxiliary tasks and appropriate weighting of losses to achieve the best performance presents a significant challenge.</p>
<p>In contrast to common vision tasks where dense predictions are closely correlated, end-to-end driving predicts a sparse signal.The sparse supervision increases the difficulty of extracting useful information for decision-making in the encoder.For image input, auxiliary tasks such as semantic segmentation [28,31,140,211,212,213] and depth estimation [28,31,211,212,213] are commonly adopted in endto-end autonomous driving models.Semantic segmentation helps the model gain a high-level understanding of the scene; depth estimation enables the model to capture the 3D geometry of the environment and better estimate distances to critical objects.Besides auxiliary tasks on perspective images, 3D object detection [28,31,52] is also useful for LiDAR encoders.As BEV becomes a natural and popular representation for autonomous driving, tasks such as BEV segmentation are included in models [11,23,28,29,30,31,52,149] that aggregate features in BEV space.Moreover, in addition to these vision tasks, [29,211,214] also predict visual affordances including traffic light states, distances to opposite lanes, etc. Nonetheless, constructing large-scale datasets with multiple types of aligned and high-quality annotations is non-trivaial for real-world applications, which remain as a great concern due to current models' reliance on MTL.</p>
<p>Inefficient Experts and Policy Distillation</p>
<p>As imitation learning, or its predominant sub-category, behavior cloning, is simply supervised learning that mimics expert behaviors, corresponding methods usually follow the "Teacher-Student" paradigm.There lie two main challenges:</p>
<p>(1) Teachers, such as the handcrafted expert autopilot provided by CARLA, are not perfect drivers, though having access to ground-truth states of surrounding agents and maps.( 2) Students are supervised by the recorded output with sensor input only, requiring them to extract perceptual features and learn policy from scratch simultaneously.</p>
<p>A few studies propose to divide the learning process into two stages, i.e., training a stronger teacher network and then distilling the policy to the student.In particular, Chen et al. [5,52] first employ a privileged agent to learn how to act with access to the state of the environment, then let the sensorimotor agent (student) closely imitate the privileged agent with distillation at the output stage.More compact BEV representations as input for the privileged agent provide stronger generalization abilities and supervision than the original expert.The process is depicted in Fig. 5.</p>
<p>Apart from solely supervising planning results, several works also distill knowledge at the feature level.For example, FM-Net [215] employs segmentation and optical flow models as auxiliary teachers to guide feature training.SAM [216] adds L2 feature loss between teacher and student networks, while CaT [23] aligns features in BEV.WoR [20] learns a model-based action-value function and then uses it to supervise the visuomotor policy.Roach [21] trains a stronger privileged expert with RL, eliminating the upper bound of BC.It incorporates multiple distillation targets, i.e., action distribution, values/rewards, and latent features.By leveraging the powerful RL expert, TCP [22] achieves a new state-of-the-art on the CARLA leaderboard with a single camera as visual input.DriveAdpater [182] learns a perception-only student and adapters with the feature alignment objective.The decoupled paradigm fully enjoys the teacher's knowledge and student's training efficiency.</p>
<p>Though huge efforts have been devoted to designing a robust expert and transferring knowledge at various levels, the teacher-student paradigm still suffers from inefficient distillation.For instance, the privileged agent has access to ground-truth states of traffic lights, which are small objects in images and thus hard to distill corresponding features.As a result, the visuomotor agents exhibit large performance gaps compared to their privileged agents.It may also lead to causal confusion for students (see Sec. 4.8).It is worth exploring how to draw more inspiration from general distillation methods in machine learning to minimize the gap.</p>
<p>Lack of Interpretability</p>
<p>Interpretability plays a critical role in autonomous driving [217].It enables engineers to better debug the system, provides performance guarantees from a societal perspective, and promotes public acceptance.Achieving interpretability for end-to-end driving models, which are often referred to as "black boxes", is more essential and challenging.</p>
<p>Given trained models, some post-hoc X-AI (explainable AI) techniques could be applied to gain saliency maps [211,218,219,220,221].Saliency maps highlight specific regions in the visual input on which the model primarily relies for planning.However, this approach provides limited information, and its effectiveness and validity are difficult to evaluate.Instead, we focus on end-to-end frameworks that directly enhance interpretability in their model design.We introduce each category of interpretability in Fig. 6 below.The car is driving forward as there is noting to impede it.</p>
<p>Interpretability for E2E AD
Attention Interpretable Tasks Cost Learning Natural Language Uncertainty Modeling Learned Attention Weights Transformer
Fig. 6: Summary of the different forms of interpretability.</p>
<p>They aid in human comprehension of decision-making processes of end-to-end models and the reliability of outputs.</p>
<p>Attention Visualization: The attention mechanism provides a certain degree of interpretability.In [33,211,214,221,222], a learned attention weight is applied to aggregate important features from intermediate feature maps.Attention weights can also adaptively combine ROI pooled features from different object regions [223] or a fixed grid [224].NEAT [11] iteratively aggregates features to predict attention weights and refine the aggregated feature.Recently, Transformer attention blocks are employed to better fuse different sensor inputs, and attention maps display important regions in the input for driving decisions [28,29,31,148,225].In PlanT [226], attention layers process features from different vehicles, providing interpretable insights into the corresponding action.Similar to post-hoc saliency methods, although attention maps offer straightforward clues about models' focus, their faithfulness and utility remain limited.</p>
<p>Interpretable Tasks: Many IL-based works introduce interpretability by decoding the latent feature representations into other meaningful information besides policy prediction, such as semantic segmentation [2,11,15,28,29,31,52,140,164,211,212,213,227], depth estimation [15,28,31,211,212], object detection [2,28,31,52], affordance predictions [29,211,214], motion prediction [2,52], and gaze map estimation [228].Although these methods provide interpretable information, most of them only treat these predictions as auxiliary tasks [11,15,28,31,140,211,212,214], with no explicit impact on final driving decisions.Some [29,52] do use these outputs for final actions, but they are incorporated solely for performing an additional safety check.</p>
<p>Rules Integration and Cost Learning: As discussed in Sec.2.1.2,cost learning-based methods share similarities with traditional modular systems and thus exhibit a certain level of interpretability.NMP [32] and DSDNet [229] construct the cost volume in conjunction with detection and motion prediction results.P3 [39] combines predicted semantic occupancy maps with comfort and traffic rules constraints to construct the cost function.Various representations, such as probabilistic occupancy and temporal motion fields [1], emergent occupancy [71], and freespace [70], are employed to score sampled trajectories.In [38,126,183,230], human expertise and pre-defined rules including safety, comfort, traffic rules, and routes based on perception and prediction outputs are explicitly included to form the cost for trajectory scoring, demonstrating improved robustness and safety.</p>
<p>Linguistic Explainability: As one aspect of interpretability is to help humans understand the system, natural language is a suitable choice for this purpose.Kim et al. [33] and Xu et al. [231] develop datasets pairing driving videos or images with descriptions and explanations, and propose endto-end models with both control and explanation outputs.BEEF [232] fuses the predicted trajectory and the intermediate perception features to predict justifications for the decision.ADAPT [233] proposes a Transformer-based network to jointly estimate action, narration, and reasoning.Recently, [170,172,173] resort to the progress of multi-modality and foundation models, using LLMs/VLMs to provide decisionrelated explanations, as discussed in Sec.4.1.2.</p>
<p>Uncertainty Modeling: Uncertainty is a quantitative approach for interpreting the dependability of deep learning model outputs [234,235], which can be helpful for designers and users to identify uncertain cases for improvement or necessary intervention.For deep learning, there are two types of uncertainty: aleatoric uncertainty and epistemic uncertainty.Aleatoric uncertainty is inherent to the task, while epistemic uncertainty is due to limited data or modeling capacity.In [236], authors leverage certain stochastic regularizations in the model to perform multiple forward passes as samples to measure the uncertainty.However, the requirement of multiple forward passes is not feasible in real-time scenarios.Loquercio et al. [235] and Filos et al. [237] propose capturing epistemic uncertainty with an ensemble of expert likelihood models and aggregating the results to perform safe planning.Regarding methods modeling aleatoric uncertainty, driving actions/planning and uncertainty (usually represented by variance) are explicitly predicted in [147,238,239].Such methods directly model and quantify the uncertainty at the action level as a variable for the network to predict.The planner would generate the final action based on the predicted uncertainty, either choosing the action with the lowest uncertainty from multiple actions [238] or generating a weighted combination of proposed actions based on the uncertainties [147].Currently, predicted uncertainty is mainly utilized in combination with hardcoded rules.Exploring better ways to model and utilize uncertainty for autonomous driving is necessary.</p>
<p>Lack of Safety Guarantees</p>
<p>Ensuring safety is of utmost importance when deploying autonomous driving systems in real-world scenarios.However, the learning-based nature of end-to-end frameworks inherently lacks precise mathematical guarantees regarding safety, unlike traditional rule-based approaches [240].</p>
<p>Nevertheless, it should be noted that modular driving stacks have already incorporated specific safety-related constraints or optimizations within their motion planning or speed prediction modules to enforce safety [241,242,243].These mechanisms can potentially be adapted for integration into end-to-end models as post-process steps or safety checks, thereby providing additional safety guarantees.Furthermore, the intermediate interpretability predictions, as discussed in Sec.4.6, such as detection and motion prediction results, can be utilized in post-processing procedures.</p>
<p>Causal Confusion</p>
<p>Driving is a task that exhibits temporal smoothness, which makes past motion a reliable predictor of the next action.However, methods trained with multiple frames can become overly reliant on this shortcut [244] and suffer from catastrophic failure during deployment.This problem is referred to as the copycat problem [57] in some works and is a manifestation of causal confusion [245], where access to more information leads to worse performance.Causal confusion in imitation learning has been a persistent challenge for nearly two decades.One of the earliest reports of this effect was made by LeCun et al. [246].They used a single input frame for steering prediction to avoid such extrapolation.Though simplistic, this is still a preferred solution in current state-of-the-art IL methods [22,28].Unfortunately, using a single frame makes it hard to extract the motion of surrounding actors.Another source of causal confusion is speed measurement [16].Fig. 7 showcases an example of a car waiting at a red light.The action of the car could highly correlate with its speed because it has waited for many frames where the speed is zero and the action is the brake.Only when the traffic light changes from red to green does this correlation break down.</p>
<p>There are several approaches to combat the causal confusion problem when using multiple frames.In [57], the authors attempt to remove spurious temporal correlations from the bottleneck representation by training an adversarial model that predicts the ego agent's past action.Intuitively, the resulting min-max optimization trains the network to eliminate its past from intermediate layers.It works well in MuJoCo but does not scale to complex visionbased driving.OREO [59] maps images to discrete codes representing semantic objects and applies random dropout masks to units that share the same discrete code, which helps in confounded Atari.In end-to-end driving, Chauf-feurNet [247] addresses the causal confusion issue by using the past ego-motion as intermediate BEV abstractions and dropping out it with a 50% probability during training.Wen et al. [58] propose upweighting keyframes in the training loss, where a decision change occurs (and hence are not predictable by extrapolating the past).PrimeNet [60] improves performance compared to keyframes by using an ensemble, where the prediction of a single-frame model is given as additional input to a multi-frame model.Chuang et al. [248] do the same but supervise the multi-frame network with action residuals instead of actions.In addition, the problem of causal confusion can be circumvented by using only LiDAR histories (with a single frame image) and realigning point clouds into one coordinate system.This removes egomotion while retaining information about other vehicles' past states.This technique has been used in multiple works [1,32,52], though it was not motivated this way.</p>
<p>However, these studies have used environments that are modified to simplify studying the causal confusion problem.Showing performance improvements in state-of-the-art settings as mentioned in Sec.3.2.5 remains an open problem.</p>
<p>Lack of Robustness</p>
<p>Long-tailed Distribution</p>
<p>One important aspect of the long-tailed distribution problem is dataset imbalance, where a few classes make up the majority, as shown in Fig. 8 (a).This poses a big challenge for models to generalize to diverse environments.Various methods mitigate this issue with data processing, including over-sampling [249,250], under-sampling [251,252], and data augmentation [253,254].Besides, weighting-based approaches [255,256] are also commonly used.</p>
<p>In the context of end-to-end autonomous driving, the long-tailed distribution issue is particularly severe.Most drives are repetitive and uninteresting e.g., following a lane for many frames.Conversely, interesting safety-critical scenarios occur rarely but are diverse in nature, and hard to replicate in the real world for safety reasons.To tackle this, some works rely on handcrafted scenarios [13,101,257,258,259] to generate more diverse data in simulation.LBC [5] leverages the privileged agent to create imaginary supervisions conditioned on different navigational commands.LAV [52] includes trajectories of non-ego agents for training to promote data diversity.In [260], a simulation framework is proposed to apply importance-sampling strategies to accelerate the evaluation of rare-event probabilities.</p>
<p>Another line of research [7,34,35,261,262,263] generates safety-critical scenarios in a data-driven manner through adversarial attacks.In [261], Bayesian Optimization is employed to generate adversarial scenarios.Learning to collide [35] represents driving scenarios as the joint distribution over building blocks and applies policy gradient RL methods to generate risky scenarios.AdvSim [34] modifies agents' trajectories to cause failures, while still adhering to physical plausibility.KING [7] proposes an optimization algorithm for safety-critical perturbations using gradients through differentiable kinematics models.</p>
<p>In general, efficiently generating realistic safety-critical scenarios that cover the long-tailed distribution remains a significant challenge.While many works focus on adversarial scenarios in simulators, it is also essential to better utilize real-world data for critical scenario mining and potential adaptation to simulation.Besides, a systematic, rigorous, comprehensive, and realistic testing framework is crucial for evaluating end-to-end autonomous driving methods under these long-tailed distributed safety-critical scenarios.</p>
<p>Covariate Shift</p>
<p>As discussed in Sec.2.1, one important challenge for behavior cloning is covariate shift.The state distributions from the expert's policy and those from the trained agent's policy differ, leading to compounding errors when the trained agent is deployed in unseen testing environments or when the reactions from other agents differ from training time.This could result in the trained agent being in a state that is outside the expert's distribution for training, leading to severe failures.An illustration is presented in Fig. 8 (b).</p>
<p>DAgger (Dataset Aggregation) [26] is a common solution for this issue.DAgger is an iterative training process.The current trained policy is rolled out in each iteration to collect new data, and the expert is used to label the visited states.This enriches the dataset by adding examples of how to recover from suboptimal states that an imperfect policy might visit.The policy is then trained on the augmented dataset, and the process repeats.However, one downside of DAgger is the need for an available expert to query online.</p>
<p>For end-to-end autonomous driving, DAgger is adopted in [24] with an MPC-based expert.To reduce the cost of constantly querying the expert, SafeDAgger [25] extends the original DAgger algorithm by learning a safety policy that estimates the deviation between the current policy and the expert policy.The expert is only queried when the deviation is large.MetaDAgger [56] uses meta-learning with DAgger to aggregate data from multiple environments.LBC [5] adopts DAgger and resamples the data with higher loss more frequently.In DARB [10], to better utilize failure or safety-related samples, it proposes several mechanisms, including task-based, policy-based, and policy &amp; expertbased mechanisms, to sample such critical states.</p>
<p>Domain Adaptation</p>
<p>Domain adaptation (DA) is a type of transfer learning in which the target task is the same as the source task, but the domains differ.Here we discuss scenarios where labels are available for the source domain while there are no labels or a limited amount of labels available for the target domain.</p>
<p>As shown in Fig. 8 (c), domain adaptation for autonomous driving tasks encompasses several cases [264]:</p>
<p>â€¢ Sim-to-real: the large gap between simulators used for training and the real world used for deployment.â€¢ Geography-to-geography: different geographic locations with varying environmental appearances.â€¢ Weather-to-weather: changes in sensor inputs caused by weather conditions such as rain, fog, and snow.â€¢ Day-to-night: illumination variations in visual inputs.</p>
<p>â€¢ Sensor-to-sensor: possible differences in sensor characteristics, e.g., resolution and relative position.Note that the aforementioned cases often overlap.</p>
<p>Typically, domain-invariant feature learning is achieved with image translators and discriminators to map images from two domains into a common latent space or representations like segmentation maps [265,266].LUSR [267] and UAIL [238] adopt a Cycle-Consistent VAE and GAN, respectively, to project images into a latent representation comprised of a domain-specific part and a domain-general part.In SESR [192], class disentangled encodings are extracted from a semantic segmentation mask to reduce the sim-to-real gap.Domain randomization [268,269,270] is also a simple and effective sim-to-real technique for RL policy learning, which is further adapted for end-to-end autonomous driving [190,271].It is realized by randomizing the rendering and physical settings of the simulators to cover the variability of the real world during training.</p>
<p>Currently, sim-to-real adaptation through source target image mapping or domain-invariant feature learning is the focus.Other DA cases are handled by constructing a diverse and large-scale dataset.Given that current methods mainly concentrate on the visual gap in images, and LiDAR has become a popular input modality for driving, specific adaptation techniques tailored for LiDARs must also be designed.Besides, traffic agents' behavior gaps between the simulator and the real world should be noticed as well.Incorporating real-world data into simulation through techniques such as NeRF [114] is another promising direction.</p>
<p>FUTURE TRENDS</p>
<p>Considering the challenges and opportunities discussed, we list some crucial directions for future research that may have a broader impact in this field.</p>
<p>Zero-shot and Few-shot Learning</p>
<p>It is inevitable for autonomous driving models to eventually encounter real-world scenarios that lie beyond the training data distribution.This raises the question of whether we can successfully adapt the model to an unseen target domain where limited or no labeled data is available.Formalizing this task for the end-to-end driving domain and incorporating techniques from the zero-shot/few-shot learning literature are the key steps toward achieving this [272,273].</p>
<p>Modular End-to-end Planning</p>
<p>The modular end-to-end planning framework optimizes multiple modules while prioritizing the ultimate planning task, which enjoys the advantages of interpretability as indicated in Sec.4.6.This is advocated in recent literature [2,274] and certain industry solutions (Tesla, Wayve, etc.) have involved similar ideas.When designing these differentiable perception modules, several questions arise regarding the choice of loss functions, such as the necessity of 3D bounding boxes for object detection, whether opting for BEV segmentation over lane topology for static scene perception, or the training strategies with limited modules' data.</p>
<p>Data Engine</p>
<p>The importance of large-scale and high-quality data for autonomous driving can never be emphasized enough [275].Establishing a data engine with an automatic labeling pipeline [276] could greatly facilitate the iterative development of both data and models.The data engine for autonomous driving, especially modular end-to-end planning systems, needs to streamline the process of annotating highquality perception labels with the aid of large perception models in an automatic way.It should also support mining hard/corner cases, scene generation, and editing to facilitate the data-driven evaluations discussed in Sec.3.2 and promote diversity of data and the generalization ability of models (Sec.4.9).A data engine would enable autonomous driving models to make consistent improvements.</p>
<p>Foundation Model</p>
<p>Recent advancements in foundation models in both language [167,168] and vision [276,277] have proved that large-scale data and model capacity can unleash the immense potential of AI in high-level reasoning tasks.The paradigm of finetuning [278] or prompt learning [279], optimization in the form of self-supervised reconstruction [280] or contrastive pairs [166], etc., are all applicable to the end-to-end driving domain.However, we contend that the direct adoption of LLMs for driving might be tricky.The output of an autonomous agent requires steady and accurate measurements, whereas the generative output in language models aims to behave like humans, irrespective of its accuracy.A feasible solution to develop a "foundation" driving model is to train a world model that can forecast the reasonable future of the environment, either in 2D, 3D, or latent space.To perform well on downstream tasks like planning, the objective to be optimized for the model needs to be sophisticated enough, beyond frame-level perception.</p>
<p>CONCLUSION AND OUTLOOK</p>
<p>In this survey, we provide an overview of fundamental methodologies and summarize various aspects of simulation and benchmarking.We thoroughly analyze the extensive literature to date, and highlight a wide range of critical challenges and promising resolutions.</p>
<p>Outlook: The industry has dedicated considerable effort over the years to develop advanced modular-based systems capable of achieving self-driving on highways.However, these systems face significant challenges when confronted with complex scenarios, e.g., inner-city streets and intersections.Therefore, an increasing number of companies have started exploring end-to-end autonomous driving techniques specifically tailored for these environments.It is envisioned that with extensive high-quality data collection, large-scale model training, and the establishment of reliable benchmarks, the end-to-end approach will have enormous potential over modular stacks in terms of performance and effectiveness.In summary, end-to-end autonomous driving faces great opportunities and challenges simultaneously, with the ultimate goal of building generalist agents.In this era of emerging technologies, we hope this survey could serve as a starting point to shed new light on this domain.</p>
<p>Fig. 1 :
1
Fig. 1: Survey at A Glance.(a) Pipeline and Methods.We define end-to-end autonomous driving as a learning-based algorithm framework with raw sensor input and planning/control output.We deepdive into 270+ papers and categorize into imitation learning (IL) and reinforcement learning (RL).(b) Benchmarking.We group popular benchmarks into closed-loop and open-loop evaluation, respectively.We cover various aspects of closed-loop simulation and the limitations of open-loop evaluation for this problem.(c) Challenges.This is the main section of our work.We list key challenges from a wide range of topics and extensively analyze why these concerns are crucial.Promising resolutions to these challenges are covered as well.(d) Future Trends.We discuss how end-to-end paradigm could benefit by aid of the rapid development of foundation models, visual pre-training, etc. Partial photos by courtesy of online resources.</p>
<p>Fig. 3 :
3
Fig.3: Overview of methods in end-to-end autonomous driving.We illustrate three popular paradigms, including two imitation learning frameworks (behavior cloning and inverse optimal control), as well as online reinforcement learning.</p>
<p>Fig. 4 :
4
Fig. 4: Examples of input modality and fusion strategy.Different modalities have distinct characteristics, leading to the challenge of effective sensor fusion.We take point clouds and images as examples to depict various fusion strategies.</p>
<p>Fig. 5 :
5
Fig. 5: Policy distillation.(a) The privileged agent learns a robust policy with access to privileged ground-truth information.The expert is labeled with dashed lines to indicate that it is not mandatory if the privileged agent is trained via RL.(b) The sensorimotor agent imitates the privileged agent through both feature distillation and output imitation.</p>
<p>braking because I see a red light.-Iam braking because my speed is low.</p>
<p>Fig. 7 :
7
Fig. 7: Causal Confusion.The current action of a car is strongly correlated with low-dimensional spurious features such as the velocity or the car's past trajectory.End-to-End models may latch on to them leading to causal confusion.</p>
<p>Fig. 8 :
8
Fig. 8: Challenges in robustness.Three primary generalization issues arise in relation to dataset distribution discrepancies, namely long-tailed and normal cases, expert demonstration and test scenarios, and domain shift in locations, weather, etc.</p>
<p>ACKNOWLEDGMENTSThis project is partially supported by National Key R&amp;D Program of China (2022ZD0160104), NSFC (62206172), and Shanghai Committee of Science and Technology (23YF1462000).Andreas Geiger and Bernhard Jaeger are supported by the ERC Starting Grant LEGO-3D (850533), the BMWi in the project KI Delta Learning (project number 19A19013O), and the DFG EXC number 2064/1 -project number 390727645.Kashyap Chitta is supported by the German Federal Ministry of Education and Research (BMBF): TÃ¼bingen AI Center, FKZ: 01IS18039A.We thank the International Max Planck Research School for Intelligent Systems for supporting Bernhard Jaeger and Kashyap Chitta.
Mp3: A unified model to map, perceive, predict and plan. S Casas, A Sadat, R Urtasun, 2021</p>
<p>Planning-oriented autonomous driving. Y Hu, J Yang, L Chen, K Li, C Sima, X Zhu, S Chai, S Du, T Lin, W Wang, L Lu, X Jia, Q Liu, J Dai, Y Qiao, H Li, CVPR. 2023</p>
<p>Alvinn: An autonomous land vehicle in a neural network. D A Pomerleau, NeurIPS1988</p>
<p>Learning to drive in a day. A Kendall, J Hawke, D Janz, P Mazur, D Reda, J.-M Allen, V.-D Lam, A Bewley, A Shah, ICRA. 2019</p>
<p>Learning by cheating. D Chen, B Zhou, V Koltun, P KrÃ¤henbÃ¼hl, CoRL2020</p>
<p>Multi-modal fusion transformer for end-to-end autonomous driving. A Prakash, K Chitta, A Geiger, CVPR. 2021</p>
<p>King: Generating safety-critical driving scenarios for robust imitation via kinematics gradients. N Hanselmann, K Renz, K Chitta, A Bhattacharyya, A Geiger, ECCV. 2022</p>
<p>End to end learning for self-driving cars. M Bojarski, D Del, D Testa, B Dworakowski, B Firner, P Flepp, L D Goyal, M Jackel, U Monfort, J Muller, Zhang, arXiv.org201616047316</p>
<p>End-to-end driving via conditional imitation learning. F Codevilla, M MÃ¼ller, A LÃ³pez, V Koltun, A Dosovitskiy, ICRA2018</p>
<p>Exploring data aggregation in policy learning for visionbased urban autonomous driving. A Prakash, A Behl, E Ohn-Bar, K Chitta, A Geiger, CVPR. 2020</p>
<p>Neat: Neural attention fields for end-to-end autonomous driving. K Chitta, A Prakash, A Geiger, ICCV. 2021</p>
<p>Policy pre-training for autonomous driving via self-supervised geometric modeling. P Wu, L Chen, H Li, X Jia, J Yan, Y Qiao, ICLR2023</p>
<p>CARLA autonomous driving leaderboard. 2022CARLA</p>
<p>Nuplan: A closed-loop ml-based planning benchmark for autonomous vehicles. H Caesar, J Kabzan, K S Tan, W K Fong, E Wolff, A Lang, L Fletcher, O Beijbom, S Omari, CVPR Workshops. 2021</p>
<p>Urban driving with conditional imitation learning. J Hawke, R Shen, C Gurau, S Sharma, D Reda, N Nikolov, P Mazur, S Micklethwaite, N Griffiths, A Shah, ICRA. 2020</p>
<p>Exploring the limitations of behavior cloning for autonomous driving. F Codevilla, E Santana, A M LÃ³pez, A Gaidon, ICCV. 2019</p>
<p>Cirl: Controllable imitative reinforcement learning for vision-based self-driving. X Liang, T Wang, L Yang, E Xing, ECCV. 2018</p>
<p>End-toend model-free reinforcement learning for urban driving using implicit affordances. M Toromanoff, E Wirbel, F Moutarde, CVPR. 2020</p>
<p>Gri: General reinforced imitation and its application to vision-based autonomous driving. R Chekroun, M Toromanoff, S Hornauer, F Moutarde, 2023Robotics</p>
<p>Learning to drive from a world on rails. D Chen, V Koltun, P KrÃ¤henbÃ¼hl, ICCV. 2021</p>
<p>End-to-end urban driving by imitating a reinforcement learning coach. Z Zhang, A Liniger, D Dai, F Yu, L Van Gool, ICCV. 2021</p>
<p>Trajectory-guided control prediction for end-to-end autonomous driving: A simple yet strong baseline. P Wu, X Jia, L Chen, J Yan, H Li, Y Qiao, NeurIPS2022</p>
<p>Coaching a teachable student. J Zhang, Z Huang, E Ohn-Bar, CVPR. 2023</p>
<p>Agile autonomous driving using end-to-end deep imitation learning. Y Pan, C.-A Cheng, K Saigol, K Lee, X Yan, E A Theodorou, B Boots, RSS2017</p>
<p>Query-efficient imitation learning for end-to-end simulated driving. J Zhang, K Cho, AAAI. 2017</p>
<p>A reduction of imitation learning and structured prediction to no-regret online learning. S Ross, G Gordon, D Bagnell, AISTATS2011</p>
<p>Attention is all you need. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, Å Kaiser, I Polosukhin, NeurIPS2017</p>
<p>Transfuser: Imitation with transformer-based sensor fusion for autonomous driving. K Chitta, A Prakash, B Jaeger, Z Yu, K Renz, A Geiger, 2022PAMI</p>
<p>Safetyenhanced autonomous driving using interpretable sensor fusion transformer. H Shao, L Wang, R Chen, H Li, Y Liu, CoRL2022</p>
<p>Think twice before driving: Towards scalable decoders for end-to-end autonomous driving. X Jia, P Wu, L Chen, J Xie, C He, J Yan, H Li, CVPR. 2023</p>
<p>Hidden biases of endto-end driving models. B Jaeger, K Chitta, A Geiger, ICCV. 2023</p>
<p>End-to-end interpretable neural motion planner. W Zeng, W Luo, S Suo, A Sadat, B Yang, S Casas, R Urtasun, CVPR. 2019</p>
<p>Textual explanations for self-driving vehicles. J Kim, A Rohrbach, T Darrell, J Canny, Z Akata, ECCV. 2018</p>
<p>Advsim: Generating safety-critical scenarios for self-driving vehicles. J Wang, A Pun, J Tu, S Manivasagam, A Sadat, S Casas, M Ren, R Urtasun, CVPR. 2021</p>
<p>Learning to collide: An adaptive safety-critical scenarios generating method. W Ding, B Chen, M Xu, D Zhao, IROS2020</p>
<p>Learning to drive by watching youtube videos: Action-conditioned contrastive policy pretraining. Q Zhang, Z Peng, B Zhou, ECCV. 2022</p>
<p>Selfd: Self-learning large-scale driving policies from the web. J Zhang, R Zhu, E Ohn-Bar, CVPR. 2022</p>
<p>St-p3: End-to-end vision-based autonomous driving via spatialtemporal feature learning. S Hu, L Chen, P Wu, H Li, J Yan, D Tao, ECCV. 2022</p>
<p>Perceive, predict, and plan: Safe motion planning through interpretable semantic representations. A Sadat, S Casas, M Ren, X Wu, P Dhawan, R Urtasun, ECCV. 2020</p>
<p>Computer vision for autonomous vehicles: Problems, datasets and state-of-the-art. J Janai, F GÃ¼ney, A Behl, A Geiger, arXiv.org. 170455192017</p>
<p>A survey of end-to-end driving: Architectures and training methods. A Tampuu, T Matiisen, M Semikin, D Fishman, N Muhammad, TNNLS. 2020</p>
<p>Motion planning for autonomous driving: The state of the art and future perspectives. S Teng, X Hu, P Deng, B Li, Y Li, D Yang, Y Ai, L Li, L Chen, Z Xuanyuan, 2023TIV</p>
<p>A review of end-to-end autonomous driving in urban environments. D Coelho, M Oliveira, IEEE Access. 2022</p>
<p>Learning to drive by imitation: An overview of deep behavior cloning methods. A O Ly, M Akhloufi, 2020TIV</p>
<p>A survey on imitation learning techniques for end-to-end autonomous vehicles. L Le Mero, D Yi, M Dianati, A Mouzakitis, TITS. 2022</p>
<p>Imitation learning: Progress, taxonomies and challenges. B Zheng, S Verma, J Zhou, I W Tsang, F Chen, TNNLS. 2022</p>
<p>A survey of deep RL and IL for autonomous driving policy learning. Z Zhu, H Zhao, TITS. 2021</p>
<p>Deep reinforcement learning for autonomous driving: A survey. B R Kiran, I Sobh, V Talpaert, P Mannion, A A A Sallab, S K Yogamani, P PÃ©rez, TITS. 2021</p>
<p>A framework for behavioural cloning. M Bain, C Sammut, Machine Intelligence 15. 1995</p>
<p>Maximum entropy inverse reinforcement learning. B D Ziebart, A L Maas, J A Bagnell, A K Dey, AAAI. 2008</p>
<p>Dave: Autonomous off-road vehicle control using endto-end learning. Y Lecun, E Cosatto, J Ben, U Muller, B Flepp, 2004Courant Institute/CBLLTech. Rep. DARPA-IPTO Final Report</p>
<p>Learning from all vehicles. D Chen, P KrÃ¤henbÃ¼hl, CVPR. 2022</p>
<p>Active imitation learning: Formal and practical reductions to iid learning. K Judah, A P Fern, T G Dietterich, P Tadepalli, 2014JMLR</p>
<p>Efficient reductions for imitation learning. S Ross, D Bagnell, AISTATS. 2010</p>
<p>Reinforcement and imitation learning via interactive no-regret learning. S Ross, J A Bagnell, arXiv.org. 14062014</p>
<p>Meta learning framework for automated driving. A E Sallab, M Saeed, O A Tawab, M Abdou, arXiv.org. 170640382017</p>
<p>Fighting copycat agents in behavioral cloning from observation histories. C Wen, J Lin, T Darrell, D Jayaraman, Y Gao, NeurIPS2020</p>
<p>Keyframe-focused visual imitation learning. C Wen, J Lin, J Qian, Y Gao, D Jayaraman, ICML. 2021</p>
<p>Object-aware regularization for addressing causal confusion in imitation learning. J Park, Y Seo, C Liu, L Zhao, T Qin, J Shin, T.-Y Liu, NeurIPS2021</p>
<p>Fighting fire with fire: avoiding dnn shortcuts through priming. C Wen, J Qian, J Lin, J Teng, D Jayaraman, Y Gao, ICML. 2022</p>
<p>Extrapolating beyond suboptimal demonstrations via inverse reinforcement learning from observations. D Brown, W Goo, P Nagarajan, S Niekum, ICML. 2019</p>
<p>Guided cost learning: Deep inverse optimal control via policy optimization. C Finn, S Levine, P Abbeel, ICML. 2016</p>
<p>Sqil: Imitation learning via reinforcement learning with sparse rewards. S Reddy, A D Dragan, S Levine, arXiv.org. 1905.11108, 2019</p>
<p>Self-imitation learning by planning. S Luo, H Kasaei, L Schomaker, ICRA. 2021</p>
<p>Generative adversarial imitation learning. J Ho, S Ermon, NeurIPS2016</p>
<p>Infogail: Interpretable imitation learning from visual demonstrations. Y Li, J Song, S Ermon, NeurIPS2017</p>
<p>Mixgail: Autonomous driving using demonstrations with mixed qualities. G Lee, D Kim, W Oh, K Lee, S Oh, IROS2020</p>
<p>Generative adversarial networks. I Goodfellow, J Pouget-Abadie, M Mirza, B Xu, D Warde-Farley, S Ozair, A Courville, Y Bengio, 2020ACM</p>
<p>End-toend interactive prediction and planning with optical flow distillation for autonomous driving. H Wang, P Cai, R Fan, Y Sun, M Liu, CVPR Workshops. 2021</p>
<p>Safe local motion planning with self-supervised freespace forecasting. P Hu, A Huang, J Dolan, D Held, D Ramanan, CVPR. 2021</p>
<p>Differentiable raycasting for self-supervised occupancy forecasting. T Khurana, P Hu, A Dave, J Ziglar, D Held, D Ramanan, ECCV. 2022</p>
<p>Vadv2: End-to-end vectorized autonomous driving via probabilistic planning. S Chen, B Jiang, H Gao, B Liao, Q Xu, Q Zhang, C Huang, W Liu, X Wang, arXiv.org. 240213243. 2024</p>
<p>Reinforcement learning: An introduction. R S Sutton, A G Barto, TNNLS. 1998</p>
<p>An invitation to deep reinforcement learning. B Jaeger, A Geiger, arXiv.org. 231283652023</p>
<p>Human-level control through deep reinforcement learning. V Mnih, K Kavukcuoglu, D Silver, A A Rusu, J Veness, M G Bellemare, A Graves, M Riedmiller, A K Fidjeland, G Ostrovski, Nature. 2015</p>
<p>The arcade learning environment: An evaluation platform for general agents. M G Bellemare, Y Naddaf, J Veness, M Bowling, 2013JAIR</p>
<p>. D Horgan, J Quan, D Budden, G Barth-Maron, M Hessel, H Van Hasselt, D Silver, 1803.00933arXiv.org. 2018Distributed prioritized experience replay</p>
<p>Towards deeper deep reinforcement learning with spectral normalization. J Bjorck, C P Gomes, K Q Weinberger, NeurIPS2021</p>
<p>Is deep reinforcement learning really superhuman on atari? leveling the playing field. M Toromanoff, E Wirbel, F Moutarde, arXiv.org. 1908.04683, 2019</p>
<p>Learning situational driving. E Ohn-Bar, A Prakash, A Behl, K Chitta, A Geiger, CVPR. 2020</p>
<p>Reward (mis)design for autonomous driving. W B Knox, A Allievi, H Banzhaf, F Schmitt, P Stone, 2023AI</p>
<p>Rethinking closed-loop training for autonomous driving. C Zhang, R Guo, W Zeng, Y Xiong, B Dai, R Hu, M Ren, R Urtasun, ECCV. 2022</p>
<p>Dream to control: Learning behaviors by latent imagination. D Hafner, T Lillicrap, J Ba, M Norouzi, ICLR2020</p>
<p>Mastering atari with discrete world models. D Hafner, T Lillicrap, M Norouzi, J Ba, ICLR2021</p>
<p>Recurrent world models facilitate policy evolution. D Ha, J Schmidhuber, NeurIPS2018</p>
<p>M Buehler, K Iagnemma, S Singh, The 2005 DARPA grand challenge: the great robot race. Springer200736</p>
<p>The DARPA urban challenge: autonomous vehicles in city traffic. M Buehler, K Iagnemma, S Singh, 2009Springer Science &amp; Business Media56</p>
<p>Mcity. U Michigan, 2015</p>
<p>Torcs, the open racing car simulator. T Team, 2000</p>
<p>Beyond grand theft auto v for training, testing and enhancing deep learning in self driving cars. M Martinez, C Sitawarin, K Finch, L Meincke, A Yablonski, A Kornhauser, arXiv.org. 171213972017</p>
<p>CARLA: An open urban driving simulator. A Dosovitskiy, G Ros, F Codevilla, A Lopez, V Koltun, CoRL2017</p>
<p>Deepdrive: a simulator that allows anyone with a pc to push the state-of-the-art in self-driving. D Team, 2020</p>
<p>Metadrive: Composing diverse driving scenarios for generalizable reinforcement learning. Q Li, Z Peng, L Feng, Q Zhang, Z Xue, B Zhou, 2022PAMI</p>
<p>Procedural content generation for games: A survey. M Hendrikx, S Meijer, J Van Der Velden, A Iosup, TOMM. 2013</p>
<p>Scenic: a language for scenario specification and scene generation. D J Fremont, T Dreossi, S Ghosh, X Yue, A L Sangiovanni-Vincentelli, S A Seshia, PLDI. 2019</p>
<p>Did we test all scenarios for automated and autonomous driving systems?. F Hauer, T Schmidt, B HolzmÃ¼ller, A Pretschner, 2019," in ITSC</p>
<p>Scenegen: Learning to generate realistic traffic scenes. S Tan, K Wong, S Wang, S Manivasagam, M Ren, R Urtasun, CVPR. 2021</p>
<p>Simnet: Learning reactive self-driving simulations from realworld observations. L Bergamini, Y Ye, O Scheel, L Chen, C Hu, L D Pero, B Osinski, H Grimmett, P Ondruska, ICRA. 2021</p>
<p>Trafficgen: Learning to generate diverse and realistic traffic scenarios. L Feng, Q Li, Z Peng, S Tan, B Zhou, ICRA2023</p>
<p>Sledge: Synthesizing simulation environments for driving agents with generative models. K Chitta, D Dauner, A Geiger, ECCV. 2024</p>
<p>Trafficsim: Learning to simulate realistic multi-agent behaviors. S Suo, S Regalado, S Casas, R Urtasun, CVPR. 2021</p>
<p>Congested traffic states in empirical observations and microscopic simulations. M Treiber, A Hennecke, D Helbing, Physical review E. 2000</p>
<p>Guided conditional diffusion for controllable traffic simulation. Z Zhong, D Rempe, D Xu, Y Chen, S Veer, T Che, B Ray, M Pavone, ICRA2023</p>
<p>Bits: Bi-level imitation for traffic simulation. D Xu, Y Chen, B Ivanovic, M Pavone, ICRA2023</p>
<p>Traf-ficBots: Towards world models for autonomous driving simulation and motion prediction. Z Zhang, A Liniger, D Dai, F Yu, L Van Gool, ICRA2023</p>
<p>Lidarsim: Realistic lidar simulation by leveraging the real world. S Manivasagam, S Wang, K Wong, W Zeng, M Sazanovich, S Tan, B Yang, W Ma, R Urtasun, CVPR. 2020</p>
<p>Geosim: Realistic video simulation via geometry-aware composition for self-driving. Y Chen, F Rong, S Duggal, S Wang, X Yan, S Manivasagam, S Xue, E Yumer, R Urtasun, CVPR. 2021</p>
<p>Unisim: A neural closedloop sensor simulator. Z Yang, Y Chen, J Wang, S Manivasagam, W.-C Ma, A J Yang, R Urtasun, CVPR. 2023</p>
<p>Megaverse: Simulating embodied agents at one million experiences per second. A Petrenko, E Wijmans, B Shacklett, V Koltun, ICML. 2021</p>
<p>Synthetic datasets for autonomous driving: A survey. Z Song, Z He, X Li, Q Ma, R Ming, Z Mao, H Pei, L Peng, J Hu, D Yao, 2024TIV</p>
<p>Learning robust control policies for end-to-end autonomous driving from data-driven simulation. A Amini, I Gilitschenski, J Phillips, J Moseyko, R Banerjee, S Karaman, D Rus, 2020RA-L</p>
<p>Vista 2.0: An open, data-driven simulator for multimodal sensing and policy learning for autonomous vehicles. A Amini, T.-H Wang, I Gilitschenski, W Schwarting, Z Liu, S Han, S Karaman, D Rus, ICRA. 2022</p>
<p>Learning interactive driving policies via data-driven simulation. T.-H Wang, A Amini, W Schwarting, I Gilitschenski, S Karaman, D Rus, ICRA2022</p>
<p>Nerf: Representing scenes as neural radiance fields for view synthesis. B Mildenhall, P P Srinivasan, M Tancik, J T Barron, R Ramamoorthi, R Ng, ECCV. 2020</p>
<p>3d gaussian splatting for real-time radiance field rendering. B Kerbl, G Kopanas, T LeimkÃ¼hler, G Drettakis, ACM Trans. on Graphics. 2023</p>
<p>Block-nerf: Scalable large scene neural view synthesis. M Tancik, V Casser, X Yan, S Pradhan, B Mildenhall, P P Srinivasan, J T Barron, H Kretzschmar, CVPR. 2022</p>
<p>Meganerf: Scalable construction of large-scale nerfs for virtual fly-throughs. H Turki, D Ramanan, M Satyanarayanan, CVPR. 2022</p>
<p>Panoptic Neural Fields: A Semantic Object-Aware Neural Scene Representation. A Kundu, K Genova, X Yin, A Fathi, C Pantofaru, L Guibas, A Tagliasacchi, F Dellaert, T Funkhouser, CVPR. 2022</p>
<p>Urbangiraffe: Representing urban scenes as compositional generative neural feature fields. Y Yang, Y Yang, H Guo, R Xiong, Y Wang, Y Liao, ICCV. 2023</p>
<p>Enhancing photorealism enhancement. S R Richter, H A Alhaija, V Koltun, 2023PAMI</p>
<p>Design and test of a computer-stabilized unicycle. A Schoonwinkel, 1988Stanford University</p>
<p>The kinematic bicycle model: A consistent model for planning feasible trajectories for autonomous vehicles?. P Polack, F AltchÃ©, B Novel, A De, La Fortelle, IV2017</p>
<p>Vehicle dynamics and control. R Rajamani, 2011Springer Science &amp; Business Media</p>
<p>On offline evaluation of vision-based driving models. F Codevilla, A M Lopez, V Koltun, A Dosovitskiy, ECCV. 2018</p>
<p>Navsim: Data-driven non-reactive autonomous vehicle simulation and benchmarking. D Dauner, M Hallgarten, T Li, X Weng, Z Huang, Z Yang, H Li, I Gilitschenski, B Ivanovic, M Pavone, arXiv.org. 240615349. 2024</p>
<p>Parting with misconceptions about learning-based vehicle motion planning. D Dauner, M Hallgarten, A Geiger, K Chitta, CoRL2023</p>
<p>nuscenes: A multimodal dataset for autonomous driving. H Caesar, V Bankiti, A H Lang, S Vora, V E Liong, Q Xu, A Krishnan, Y Pan, G Baldan, O Beijbom, CVPR. 2020</p>
<p>Argoverse 2: Next generation datasets for self-driving perception and forecasting. B Wilson, W Qi, T Agarwal, J Lambert, J Singh, S Khandelwal, B Pan, R Kumar, A Hartnett, J K Pontes, NeurIPS Datasets and Benchmarks. 2021</p>
<p>Scalability in perception for autonomous driving: Waymo open dataset. P Sun, H Kretzschmar, X Dotiwalla, A Chouard, V Patnaik, P Tsui, J Guo, Y Zhou, Y Chai, B Caine, CVPR. 2020</p>
<p>Rethinking the open-loop evaluation of end-to-end autonomous driving in nuscenes. J.-T Zhai, Z Feng, J Du, Y Mao, J.-J Liu, Z Tan, Y Zhang, X Ye, J Wang, arXiv.org. 230510430. 2023</p>
<p>Is ego status all you need for open-loop endto-end autonomous driving?. Z Li, Z Yu, S Lan, J Li, J Kautz, T Lu, J M Alvarez, CVPR. 2024</p>
<p>BEVFusion: A simple and robust liDAR-camera fusion framework. T Liang, H Xie, K Yu, Z Xia, Z Lin, Y Wang, T Tang, B Wang, Z Tang, NeurIPS2022</p>
<p>Bevfusion: Multi-task multi-sensor fusion with unified bird's-eye view representation. Z Liu, H Tang, A Amini, X Yang, H Mao, D Rus, S Han, ICRA2023</p>
<p>Sensor fusion for semantic segmentation of urban scenes. R Zhang, S A Candra, K Vetter, A Zakhor, ICRA2015</p>
<p>Sensor fusion for joint 3d object detection and semantic segmentation. G P Meyer, J Charland, D Hegde, A Laddha, C Vallespi-Gonzalez, CVPR Workshops. 2019</p>
<p>Does computer vision matter for action?. B Zhou, P KrÃ¤henbÃ¼hl, V Koltun, Science Robotics. 2019</p>
<p>Enhance sample efficiency and robustness of end-to-end urban autonomous driving via semantic masked world model. Z Gao, Y Mu, R Shen, C Chen, Y Ren, J Chen, S E Li, P Luo, Y Lu, TITS. 2024</p>
<p>Interpretable endto-end urban autonomous driving with latent deep reinforcement learning. J Chen, S E Li, M Tomizuka, TITS. 2022</p>
<p>Carl-lead: Lidarbased end-to-end autonomous driving with contrastive deep reinforcement learning. P Cai, S Wang, H Wang, M Liu, arXiv.org. 210984732021</p>
<p>Multi-modal sensor fusion-based deep neural network for end-to-end autonomous driving with scene understanding. Z Huang, C Lv, Y Xing, J Wu, IEEE Sensors Journal. 2020</p>
<p>Fully end-to-end autonomous driving with semantic depth cloud mapping and multiagent. O Natan, J Miura, IV2022</p>
<p>Multimodal end-to-end autonomous driving. Y Xiao, F Codevilla, A Gurram, O Urfalioglu, A M LÃ³pez, TITS. 2020</p>
<p>End-toend multi-modal sensors fusion system for urban automated driving. I Sobh, L Amin, S Abdelkarim, K Elmadawy, M Saeed, O Abdeltawab, M E Gamal, A E Sallab, 2018in NeurIPS Workshops</p>
<p>Lidar-video driving dataset: Learning driving policies effectively. Y Chen, J Wang, J Li, C Lu, Z Luo, H Xue, C Wang, CVPR. 2018</p>
<p>Dynamic conditional imitation learning for autonomous driving. H M Eraqi, M N Moustafa, J Honer, TITS. 2022</p>
<p>Multinet: Multimodal multi-task learning for autonomous driving. S Chowdhuri, T Pankaj, K Zipser, WACV2019</p>
<p>Probabilistic endto-end vehicle navigation in complex dynamic environments with multimodal sensor fusion. P Cai, S Wang, Y Sun, M Liu, 2020RA-L</p>
<p>Mmfn: Multi-modal-fusion-net for end-to-end driving. Q Zhang, M Tang, R Geng, F Chen, R Xin, L Wang, IROS2022</p>
<p>Reasonnet: End-to-end driving with temporal and global reasoning. H Shao, L Wang, R Chen, S L Waslander, H Li, Y Liu, CVPR. 2023</p>
<p>Deepfusion: Lidarcamera deep fusion for multi-modal 3d object detection. Y Li, A W Yu, T Meng, B Caine, J Ngiam, D Peng, J Shen, Y Lu, D Zhou, Q V Le, CVPR. 2022</p>
<p>X-align: Cross-modal crossview alignment for bird's-eye-view segmentation. S Borse, M Klingner, V R Kumar, H Cai, A Almuzairee, S Yogamani, F Porikli, WACV2023</p>
<p>Vision-and-language navigation: Interpreting visuallygrounded navigation instructions in real environments. P Anderson, Q Wu, D Teney, J Bruce, M Johnson, N SÃ¼nderhauf, I Reid, S Gould, A Van Den, Hengel, CVPR. 2018</p>
<p>Cliport: What and where pathways for robotic manipulation. M Shridhar, L Manuelli, D Fox, CoRL2022</p>
<p>A survey of embodied ai: From simulators to research tasks. J Duan, S Yu, H L Tan, H Zhu, C Tan, 2022TETCI</p>
<p>Chatgpt for robotics: Design principles and model abilities. S Vemprala, R Bonatti, A Bucker, A Kapoor, arXiv.org. 230617582. 2023</p>
<p>Talk2car: Taking control of your selfdriving car. T Deruyttere, S Vandenhende, D Grujicic, L Van Gool, M F Moens, EMNLP. 2019</p>
<p>Learning to navigate in cities without a map. P Mirowski, M Grimes, M Malinowski, K M Hermann, K Anderson, D Teplyashin, K Simonyan, A Zisserman, R Hadsell, NeurIPS2018</p>
<p>Touchdown: Natural language navigation and spatial reasoning in visual street environments. H Chen, A Suhr, D Misra, N Snavely, Y Artzi, CVPR. 2019</p>
<p>Generating landmark navigation instructions from maps as a graph-to-text problem. R Schumann, S Riezler, ACL. 2021</p>
<p>Grounding human-to-vehicle advice for self-driving vehicles. J Kim, T Misu, Y.-T Chen, A Tawari, J Canny, CVPR. 2019</p>
<p>Talk to the vehicle: Language conditioned autonomous navigation of self driving cars. S Narayanan, T Maniar, J Kalyanasundaram, V Gandhi, B Bhowmick, K M Krishna, IROS2019</p>
<p>Advisable learning for self-driving vehicles by internalizing observation-to-action rules. J Kim, S Moon, A Rohrbach, T Darrell, J Canny, CVPR. 2020</p>
<p>Conditional driving from natural language instructions. J Roh, C Paxton, A Pronobis, A Farhadi, D Fox, CoRL2019</p>
<p>Ground then navigate: Language-guided navigation in dynamic scenes. K Jain, V Chhangani, A Tiwari, K M Krishna, V Gandhi, ICRA2023</p>
<p>Lm-nav: Robotic navigation with large pre-trained models of language, vision, and action. D Shah, B Osi, S Levine, CoRL2023</p>
<p>Learning transferable visual models from natural language supervision. A Radford, J W Kim, C Hallacy, A Ramesh, G Goh, S Agarwal, G Sastry, A Askell, P Mishkin, J Clark, ICML. 2021</p>
<p>Openai, arXiv.orgGPT-4 Technical Report. 202323038774</p>
<p>Llama: Open and efficient foundation language models. H Touvron, T Lavril, G Izacard, X Martinet, M.-A Lachaux, T Lacroix, B RoziÃ¨re, N Goyal, E Hambro, F Azhar, arXiv.org13971. 20232302</p>
<p>J Mao, Y Qian, H Zhao, Y Wang, Gpt-driver: Learning to drive with gpt. 2310.01415, 2023</p>
<p>Z Xu, Y Zhang, E Xie, Z Zhao, Y Guo, K K Wong, Z Li, H Zhao, Drivegpt4: Interpretable end-to-end autonomous driving via large language model. 202323101412</p>
<p>Lmdrive: Closed-loop end-to-end driving with large language models. H Shao, Y Hu, L Wang, S L Waslander, Y Liu, H Li, CVPR. 2024</p>
<p>Drivelm: Driving with graph visual question answering. C Sima, K Renz, K Chitta, L Chen, H Zhang, C Xie, J BeiÃŸwenger, P Luo, A Geiger, H Li, ECCV. 2024</p>
<p>Nuscenes-qa: A multi-modal visual question answering benchmark for autonomous driving scenario. T Qian, J Chen, L Zhuo, Y Jiao, Y.-G Jiang, AAAI. 2024</p>
<p>A survey of large language models for autonomous driving. Z Yang, X Jia, H Li, J Yan, arXiv.org. 231110432023</p>
<p>Toward deep reinforcement learning without a simulator: An autonomous steering example. B Hilleli, R El-Yaniv, AAAI. 2018</p>
<p>Deep residual learning for image recognition. K He, X Zhang, S Ren, J Sun, CVPR. 2016</p>
<p>An energy and gpu-computation efficient backbone network for real-time object detection. Y Lee, J.-W Hwang, S Lee, Y Bae, J Park, CVPR Workshops. 2019</p>
<p>An image is worth 16x16 words: Transformers for image recognition at scale. A Dosovitskiy, L Beyer, A Kolesnikov, D Weissenborn, X Zhai, T Unterthiner, M Dehghani, M Minderer, G Heigold, S Gelly, ICLR. 2021</p>
<p>Scaling vision transformers to 22 billion parameters. M Dehghani, J Djolonga, B Mustafa, P Padlewski, J Heek, J Gilmer, A P Steiner, M Caron, R Geirhos, I Alabdulmohsin, ICML. 2023</p>
<p>Delving into the devils of bird's-eye-view perception: A review, evaluation and recipe. H Li, C Sima, J Dai, W Wang, L Lu, H Wang, J Zeng, Z Li, J Yang, H Deng, 2023PAMI</p>
<p>Bevformer: Learning bird's-eye-view representation from multi-camera images via spatiotemporal transformers. Z Li, W Wang, H Li, E Xie, C Sima, T Lu, Y Qiao, J Dai, ECCV. 2022</p>
<p>Driveadapter: Breaking the coupling barrier of perception and planning in end-to-end autonomous driving. X Jia, Y Gao, L Chen, J Yan, P L Liu, H Li, ICCV. 2023</p>
<p>Vad: Vectorized scene representation for efficient autonomous driving. B Jiang, S Chen, Q Xu, B Liao, J Chen, H Zhou, Q Zhang, W Liu, C Huang, X Wang, ICCV. 2023</p>
<p>Scene as occupancy. W Tong, C Sima, T Wang, L Chen, S Wu, H Deng, Y Gu, L Lu, P Luo, D Lin, ICCV. 2023</p>
<p>Hdmapnet: An online hd map construction and evaluation framework. Q Li, Y Wang, Y Wang, H Zhao, ICRA2022</p>
<p>MapTR: Structured modeling and learning for online vectorized HD map construction. B Liao, S Chen, X Wang, T Cheng, Q Zhang, W Liu, C Huang, ICLR2023</p>
<p>Openlane-v2: A topology reasoning benchmark for unified 3d hd mapping. H Wang, T Li, Y Li, L Chen, C Sima, Z Liu, B Wang, P Jia, Y Wang, S Jiang, NeurIPS Datasets and Benchmarks. 2023</p>
<p>Graph-based topology reasoning for driving scenes. T Li, L Chen, H Wang, Y Li, J Yang, X Geng, S Jiang, Y Wang, H Xu, C Xu, arXiv.org. 230452772023</p>
<p>Lanesegnet: Map learning with lane segment perception for autonomous driving. T Li, P Jia, B Wang, L Chen, K Jiang, J Yan, H Li, ICLR2024</p>
<p>A versatile and efficient reinforcement learning framework for autonomous driving. G Wang, H Niu, D Zhu, J Hu, X Zhan, G Zhou, arXiv.org. 211011573. 2021</p>
<p>Label efficient visual abstractions for autonomous driving. A Behl, K Chitta, A Prakash, E Ohn-Bar, A Geiger, IROS2020</p>
<p>Segmented encoding for sim2real of rl-based end-to-end autonomous driving. S.-H Chung, S.-H Kong, S Cho, I M A Nahrendra, IV2022</p>
<p>Auto-encoding variational bayes. D P Kingma, M Welling, arXiv.org. 131261142013</p>
<p>Policy-based reinforcement learning for training autonomous driving agents in urban areas with affordance learning. M Ahmed, A Abobakr, C P Lim, S Nahavandi, TITS. 2022</p>
<p>Conditional affordance learning for driving in urban environments. A Sauer, N Savinov, A Geiger, CoRL2018</p>
<p>Multi-task long-range urban driving based on hierarchical planning and reinforcement learning. X Zhang, M Wu, H Ma, T Hu, J Yuan, ITSC2021</p>
<p>Deductive reinforcement learning for visual autonomous urban driving navigation. C Huang, R Zhang, M Ouyang, P Wei, J Lin, J Su, L Lin, TNNLS. 2021</p>
<p>Latent attention augmentation for robust autonomous driving policies. R Cheng, C Agia, F Shkurti, D Meger, G Dudek, IROS2021</p>
<p>Taskinduced representation learning. J Yamada, K Pertsch, A Gunjal, J J Lim, ICLR2022</p>
<p>Learning generalizable representations for reinforcement learning via adaptive metalearner of behavioral similarities. J Chen, S Pan, ICLR2022</p>
<p>Visual point cloud forecasting enables scalable autonomous driving. Z Yang, L Chen, Y Sun, H Li, CVPR. 2024</p>
<p>Model-predictive policy learning with uncertainty regularization for driving in dense traffic. M Henaff, A Canziani, Y Lecun, ICLR2019</p>
<p>Uncertainty-aware modelbased reinforcement learning: Methodology and application in autonomous driving. J Wu, Z Huang, C Lv, 2022IV</p>
<p>Iso-dream: Isolating and leveraging noncontrollable visual dynamics in world models. M Pan, X Zhu, Y Wang, X Yang, NeurIPS2022</p>
<p>Generalized predictive model for autonomous driving. J Yang, S Gao, Y Qiu, L Chen, T Li, B Dai, K Chitta, P Wu, J Zeng, P Luo, CVPR. 2024</p>
<p>S Gao, J Yang, L Chen, K Chitta, Y Qiu, A Geiger, J Zhang, H Li, Vista: A generalizable driving world model with high fidelity and versatile controllability. 17398. 20242405</p>
<p>Driving into the future: Multiview visual forecasting and planning with world model for autonomous driving. Y Wang, J He, L Fan, H Li, Y Chen, Z Zhang, CVPR. 2024</p>
<p>High-resolution image synthesis with latent diffusion models. R Rombach, A Blattmann, D Lorenz, P Esser, B Ommer, CVPR. 2022</p>
<p>Modelbased imitation learning for urban driving. A Hu, G Corrado, N Griffiths, Z Murez, C Gurau, H Yeo, A Kendall, R Cipolla, J Shotton, NeurIPS2022</p>
<p>Multitask learning. R Caruana, Machine Learning. 1997</p>
<p>Multi-task learning with attention for end-to-end autonomous driving. K Ishihara, A Kanervisto, J Miura, V Hautamaki, CVPR Workshops. 2021</p>
<p>Rethinking self-driving: Multi-task knowledge for better generalization and accident explanation ability. Z Li, T Motoyoshi, K Sasaki, T Ogata, S Sugano, arXiv.org. 180911100. 2018</p>
<p>End-to-end learning of driving models from large-scale video datasets. H Xu, Y Gao, F Yu, T Darrell, CVPR. 2017</p>
<p>Learning end-to-end autonomous driving using guided auxiliary supervision. A Mehta, A Subramanian, A Subramanian, ICVGIP. 2018</p>
<p>Learning to steer by mimicking features from heterogeneous auxiliary networks. Y Hou, Z Ma, C Liu, C C Loy, AAAI. 2019</p>
<p>Sam: Squeeze-and-mimic networks for conditional visual driving policy learning. A Zhao, T He, Y Liang, H Huang, G Van Den Broeck, S Soatto, CoRL2020</p>
<p>Explainability of deep vision-based autonomous driving systems: Review and challenges. Ã‰ Zablocki, H Ben-Younes, P PÃ©rez, M Cord, 2022IJCV</p>
<p>Explaining how a deep neural network trained with end-to-end learning steers a car. M Bojarski, P Yeres, A Choromanska, K Choromanski, B Firner, L Jackel, U Muller, arXiv.org. 170479112017</p>
<p>Visualbackprop: Efficient visualization of cnns for autonomous driving. M Bojarski, A Choromanska, K Choromanski, B Firner, L J Ackel, U Muller, P Yeres, K Zieba, ICRA. 2018</p>
<p>Predicting model failure using saliency maps in autonomous driving systems. S Mohseni, A Jagadeesh, Z Wang, arXiv.org. 1905.07679, 2019</p>
<p>Interpretable learning for selfdriving cars by visualizing causal attention. J Kim, J Canny, ICCV. 2017</p>
<p>Visual explanation by attention branch network for end-to-end learning-based self-driving. K Mori, H Fukui, T Murase, T Hirakawa, T Yamashita, H Fujiyoshi, IV2019</p>
<p>Deep object-centric policies for autonomous driving. D Wang, C Devin, Q.-Z Cai, F Yu, T Darrell, ICRA2019</p>
<p>Explaining autonomous driving by learning end-to-end visual attention. L Cultrera, L Seidenari, F Becattini, P Pala, A Del Bimbo, CVPR Workshops. 2020</p>
<p>Scaling self-supervised end-to-end driving with multiview attention learning. Y Xiao, F Codevilla, D P Bustamante, A M Lopez, arXiv.org. 230231982023</p>
<p>Plant: Explainable planning transformers via object-level representations. K Renz, K Chitta, O.-B Mercea, A S Koepke, Z Akata, A Geiger, CoRL2022</p>
<p>Interpretable end-to-end driving model for implicit scene understanding. Y Sun, X Wang, Y Zhang, J Tang, X Tang, J Yao, ITSC2023</p>
<p>Using eye gaze to enhance generalization of imitation networks to unseen environments. C Liu, Y Chen, M Liu, B E Shi, TNNLS. 2020</p>
<p>Dsdnet: Deep structured self-driving network. W Zeng, S Wang, R Liao, Y Chen, B Yang, R Urtasun, ECCV. 2020</p>
<p>Lookout: Diverse multi-future prediction and planning for self-driving. A Cui, S Casas, A Sadat, R Liao, R Urtasun, ICCV. 2021</p>
<p>Explainable object-induced action decision for autonomous vehicles. Y Xu, X Yang, L Gong, H.-C Lin, T.-Y Wu, Y Li, N Vasconcelos, CVPR. 2020</p>
<p>Driving behavior explanation with multi-level fusion. H Ben-Younes, Ã‰ Zablocki, P PÃ©rez, M Cord, Pattern Recognition. 2022</p>
<p>Adapt: Action-aware driving caption transformer. B Jin, X Liu, Y Zheng, P Li, H Zhao, T Zhang, Y Zheng, G Zhou, J Liu, ICRA2023</p>
<p>On calibration of modern neural networks. C Guo, G Pleiss, Y Sun, K Q Weinberger, ICML. 2017</p>
<p>A general framework for uncertainty estimation in deep learning. A Loquercio, M Segu, D Scaramuzza, 2020RA-L</p>
<p>Evaluating uncertainty quantification in end-to-end autonomous driving control. R Michelmore, M Kwiatkowska, Y Gal, arXiv.org. 181168172018</p>
<p>Can autonomous vehicles identify, recover from, and adapt to distribution shifts?. A Filos, P Tigkas, R Mcallister, N Rhinehart, S Levine, Y Gal, ICML. 2020</p>
<p>Visualbased autonomous driving deployment from a stochastic and uncertainty-aware perspective. L Tai, P Yun, Y Chen, C Liu, H Ye, M Liu, IROS2019</p>
<p>Vtgnet: A visionbased trajectory generation network for autonomous vehicles in urban environments. P Cai, Y Sun, H Wang, M Liu, 2020IV</p>
<p>On a formal model of safe and scalable self-driving cars. S Shalev-Shwartz, S Shammah, A Shashua, arXiv.org. 170863742017</p>
<p>Stochastic model predictive control with a safety guarantee for automated driving. T BrÃ¼digam, M Olbrich, D Wollherr, M Leibold, 2021IV</p>
<p>Probabilistic safetyassured adaptive merging control for autonomous vehicles. Y Lyu, W Luo, J M Dolan, ICRA2021</p>
<p>Realtime mpc with control barrier functions for autonomous driving using safety enhanced collocation. J P Allamaa, P Patrinos, T Ohtsuka, T D Son, arXiv.org. 240166482024</p>
<p>Shortcut learning in deep neural networks. R Geirhos, J Jacobsen, C Michaelis, R S Zemel, W Brendel, M Bethge, F A Wichmann, Nature Machine Intelligence. 2020</p>
<p>Causal confusion in imitation learning. P De Haan, D Jayaraman, S Levine, NeurIPS2019</p>
<p>Offroad obstacle avoidance through end-to-end learning. U Muller, J Ben, E Cosatto, B Flepp, Y Lecun, NeurIPS2005</p>
<p>Chauffeurnet: Learning to drive by imitating the best and synthesizing the worst. M Bansal, A Krizhevsky, A S Ogale, RSS2019</p>
<p>Resolving copycat problems in visual imitation learning via residual action prediction. C Chuang, D Yang, C Wen, Y Gao, ECCV. 2022</p>
<p>A systematic study of the class imbalance problem in convolutional neural networks. M Buda, A Maki, M A Mazurowski, 2018NN</p>
<p>What is the effect of importance weighting in deep learning?. J Byrd, Z Lipton, ICML. 2019</p>
<p>knn approach to unbalanced data distributions: a case study involving information extraction. I Mani, I Zhang, ICML Workshops. 2003</p>
<p>Exploratory undersampling for class-imbalance learning. X.-Y Liu, J Wu, Z.-H Zhou, 2008TCYB</p>
<p>Dynamic few-shot visual learning without forgetting. S Gidaris, N Komodakis, CVPR. 2018</p>
<p>mixup: Beyond empirical risk minimization. H Zhang, M Cisse, Y N Dauphin, D Lopez-Paz, ICLR2017</p>
<p>Focal loss for dense object detection. T.-Y Lin, P Goyal, R Girshick, K He, P DollÃ¡r, ICCV. 2017</p>
<p>Classbalanced loss based on effective number of samples. Y Cui, M Jia, T.-Y Lin, Y Song, S Belongie, CVPR. 2019</p>
<p>Enhanced transfer learning for autonomous driving with systematic accident simulation. S Akhauri, L Y Zheng, M C Lin, IROS2020</p>
<p>Improving the generalization of end-to-end driving through procedural generation. Q Li, Z Peng, Q Zhang, C Liu, B Zhou, arXiv.org. 201213681. 2020</p>
<p>Microscopic traffic simulation using sumo. P A Lopez, M Behrisch, L Bieker-Walz, J Erdmann, Y.-P FlÃ¶tterÃ¶d, R Hilbrich, L LÃ¼cken, J Rummel, P Wagner, E WieÃŸner, ITSC. 2018</p>
<p>Scalable end-to-end autonomous vehicle testing via rare-event simulation. M O'kelly, A Sinha, H Namkoong, R Tedrake, J C Duchi, NeurIPS2018</p>
<p>Generating adversarial driving scenarios in high-fidelity simulators. Y Abeysirigoonawardena, F Shkurti, G Dudek, ICRA2019</p>
<p>Multimodal safety-critical scenarios generation for decisionmaking algorithms evaluation. W Ding, B Chen, B Li, K J Eun, D Zhao, RA-L. 2021</p>
<p>CAT: Closedloop adversarial training for safe end-to-end driving. L Zhang, Z Peng, Q Li, B Zhou, CoRL2023</p>
<p>A survey on deep domain adaptation for lidar perception. L T Triess, M Dreissig, C B Rist, J M ZÃ¶llner, IV Workshops. 2021</p>
<p>Virtual to real reinforcement learning for autonomous driving. Y You, X Pan, Z Wang, C Lu, BMVC. 2017</p>
<p>Learning to drive from simulation without real world labels. A Bewley, J Rigley, Y Liu, J Hawke, R Shen, V.-D Lam, A Kendall, ICRA2019</p>
<p>Domain adaptation in reinforcement learning via latent unified state representation. J Xing, T Nagata, K Chen, X Zou, E Neftci, J L Krichmar, AAAI. 2021</p>
<p>Domain randomization for transferring deep neural networks from simulation to the real world. J Tobin, R Fong, A Ray, J Schneider, W Zaremba, P Abbeel, IROS2017</p>
<p>Sim-to-real transfer of robotic control with dynamics randomization. X B Peng, M Andrychowicz, W Zaremba, P Abbeel, ICRA2018</p>
<p>Sim-to-real reinforcement learning for deformable object manipulation. J Matas, S James, A J Davison, CoRL2018</p>
<p>Simulation-based reinforcement learning for real-world autonomous driving. B Osi Åƒski, A Jakubowski, P ZiÄ™cina, P MiÅ‚oÅ›, C Galias, S Homoceanu, H Michalewski, ICRA2020</p>
<p>A survey of zero-shot generalisation in deep reinforcement learning. R Kirk, A Zhang, E Grefenstette, T RocktÃ¤schel, 2023JAIR</p>
<p>Prototypical networks for few-shot learning. J Snell, K Swersky, R Zemel, NeurIPS2017</p>
<p>Diffstack: A differentiable and modular control stack for autonomous vehicles. P Karkus, B Ivanovic, S Mannor, M Pavone, CoRL2022</p>
<p>Open-sourced data ecosystem in autonomous driving: the present and future. H Li, Y Li, H Wang, J Zeng, P Cai, H Xu, D Lin, J Yan, F Xu, L Xiong, arXiv.org. 231234082023</p>
<p>Segment anything. A Kirillov, E Mintun, N Ravi, H Mao, C Rolland, L Gustafson, T Xiao, S Whitehead, A C Berg, W.-Y Lo, ICCV. 2023</p>
<p>Dinov2: Learning robust visual features without supervision. M Oquab, T Darcet, T Moutakanni, H Vo, M Szafraniec, V Khalidov, P Fernandez, D Haziza, F Massa, A El-Nouby, 2024TMLR</p>
<p>Flamingo: a visual language model for few-shot learning. J.-B Alayrac, J Donahue, P Luc, A Miech, I Barr, Y Hasson, K Lenc, A Mensch, K Millican, M Reynolds, NeurIPS2022</p>
<p>Training language models to follow instructions with human feedback. L Ouyang, J Wu, X Jiang, D Almeida, C Wainwright, P Mishkin, C Zhang, S Agarwal, K Slama, A Ray, NeurIPS2022</p>
<p>Masked autoencoders are scalable vision learners. K He, X Chen, S Xie, Y Li, P DollÃ¡r, R Girshick, CVPR. 2022</p>            </div>
        </div>

    </div>
</body>
</html>