<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1256 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1256</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1256</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-26.html">extraction-schema-26</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <p><strong>Paper ID:</strong> paper-206561353</p>
                <p><strong>Paper Title:</strong> Amplify scientific discovery with artificial intelligence</p>
                <p><strong>Paper Abstract:</strong> Many human activities are a bottleneck in progress Technological innovations are penetrating all areas of science, making predominantly human activities a principal bottleneck in scientific progress while also making scientific advancement more subject to error and harder to reproduce. This is an area where a new generation of artificial intelligence (AI) systems can radically transform the practice of scientific discovery. Such systems are showing an increasing ability to automate scientific data analysis and discovery processes, can search systematically and correctly through hypothesis spaces to ensure best results, can autonomously discover complex patterns in data, and can reliably apply small-scale scientific processes consistently and transparently so that they can be easily reproduced. We discuss these advances and the steps that could help promote their development and deployment.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1256.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1256.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DENDRAL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DENDRAL</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An early AI system (1970s) that analyzed mass spectrometry data to propose molecular-structure hypotheses; cited as an early application of AI to scientific discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>DENDRAL</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Rule-based AI system developed in the 1970s to analyze mass spectrometry data and generate hypotheses about molecular structures; represents an early application of domain-encoded knowledge and automated reasoning in chemistry.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Chemistry (organic/analytical chemistry)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Generates candidate molecular structures consistent with mass spectrometry data, effectively automating part of the structure-elucidation reasoning process.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>demonstrated reasoning capabilities</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The paper describes DENDRAL as an early system that "developed ... for analyzing mass spectrometry data in order to hypothesize molecular structures," and uses it as evidence that AI "demonstrated reasoning capabilities for analyzing scientific data." The paper does not classify the discovery as incremental or transformational.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Not specified in this paper; the paper only references DENDRAL as historical proof of concept without describing quantitative evaluation methods.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Not specified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty is described implicitly by historical context: DENDRAL is presented as an early, pioneering example of automating a nontrivial scientific reasoning task (structure hypothesis from mass spectra). The paper does not provide an explicit novelty metric.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Not provided in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>The paper does not give specific limitations for DENDRAL here; it uses DENDRAL as an illustrative early success but notes generally that methods to measure AI impact in science are lacking.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Amplify scientific discovery with artificial intelligence', 'publication_date_yy_mm': '2014-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1256.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1256.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>robot scientists</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>robot scientists</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Autonomous laboratory systems that can plan and execute experiments and analyze results; cited as recent breakthroughs demonstrating AI applicability across sciences.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>robot scientists</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Automated laboratory platforms (hardware + software) that can design, execute, and analyze experiments with varying degrees of autonomy, codifying experimental procedures and integrating data analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Laboratory sciences / biology (general experimental sciences)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Used to perform experimental cycles with reduced human intervention, enabling automated hypothesis-driven experiment execution, data collection, and analysis; presented as evidence of broader applicability of AI techniques to discovery tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>broader applicability</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The paper groups robot scientists with other recent breakthroughs as demonstrating the "broader applicability of AI techniques for scientific discovery," implying these systems extend AI beyond narrow tasks into experimental automation.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Not detailed in this paper; robot scientists are referenced at high level without specific metrics or experimental evaluation protocols described here.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Not specified in this paper (implicit validation would be experimental replication and confirmation by domain scientists, but the paper does not detail these).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Characterized as a recent breakthrough that broadens AI applicability to experimental laboratory work; novelty is indicated by their ability to automate experiment execution rather than by quantified novelty metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Not provided in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Paper highlights general challenges in measuring AI impact on science; specifically, it notes a lack of clear methods to quantify the impact of AI systems like robot scientists.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Amplify scientific discovery with artificial intelligence', 'publication_date_yy_mm': '2014-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1256.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1256.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>software formulating laws</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>software that formulates laws for complex dynamical systems</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Automated software that can discover mathematical laws or governing equations from data for complex dynamical systems; cited as an example of AI discovering higher-level scientific relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>software that formulates laws for complex dynamical systems</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Algorithms that search hypothesis spaces (often symbolic/regression or equation-discovery methods) to find compact expressions or laws that explain observed dynamical data.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Physics / dynamical systems / general empirical sciences</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Extracts candidate governing equations or mathematical relationships from experimental or observational data, thereby generating law-like descriptions of system behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>broader applicability</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The paper cites such software as a recent breakthrough demonstrating "broader applicability of AI techniques for scientific discovery," implying significance beyond narrow pattern recognition.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Not specified in this paper; the paper does not enumerate metrics such as goodness-of-fit, parsimony, or predictive accuracy for these systems.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Not specified here; typical validation would include comparison to known laws or experimental predictive performance, but the paper does not provide details.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Presented as noteworthy because it can "formulate laws" from data, indicating novelty in producing interpretable, law-like outputs rather than only correlative models.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Not provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Paper emphasizes lack of standardized measures to quantify AI impact; this makes assessing how law-formulating software compares to human-derived laws difficult.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Amplify scientific discovery with artificial intelligence', 'publication_date_yy_mm': '2014-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1256.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1256.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hanalyzer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hanalyzer (high-throughput analyzer)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A semantic, NLP-driven system that integrates biomedical database assertions and literature to reason about semantic networks and suggest novel gene–disease correlations for experimental follow-up.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Hanalyzer</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Combines natural language processing to extract semantic networks from PubMed, integrates assertions from other biomedical sources using Semantic Web technology, and reasons over the integrated semantic information to suggest potentially novel correlations.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Biomedicine / genomics / systems biology</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Finds new correlations (e.g., candidate genes to investigate) by reasoning over an integrated semantic network built from literature and databases; results are presented as suggestions for scientists to generate testable hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>suggest novel correlations</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The paper states Hanalyzer "reasons about the network to find new correlations that suggest new genes to investigate," framing its outputs as novel correlations to drive further hypothesis generation.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Not quantitatively detailed in this paper; evaluation implied via the production of candidate correlations and the subsequent potential for scientist-driven hypothesis testing.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Validation is presented implicitly as downstream: scientists can generate and test hypotheses suggested by Hanalyzer; the paper does not describe specific validation experiments or metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty is assessed qualitatively: Hanalyzer's novelty lies in automated extraction/integration of assertions and reasoning to suggest previously unrecognized correlations; no numerical novelty metrics are provided.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Not provided in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>The paper notes the complexity of developing explicit representations of scientific processes and that successful systems become "junior participants," but it also emphasizes the broader problem of lacking measurement methods to quantify AI's impact.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Amplify scientific discovery with artificial intelligence', 'publication_date_yy_mm': '2014-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1256.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1256.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Wings</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Wings</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A system using Semantic Web and AI planning to reason about model and algorithm selection and to automatically customize data-analysis workflows for water-quality data and daily conditions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Wings</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Uses Semantic Web technologies and AI planning to reason about choices of models and algorithms and to automatically generate customized analysis workflows based on domain knowledge and context.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Environmental science / water-quality data analysis / scientific workflow management</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Automates selection and configuration of models and algorithms for water-quality analysis, producing customized workflows adapted to daily conditions, thereby reducing manual decision-making in data processing.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>workflow automation and reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The paper describes Wings as reasoning about model/algorithm choices and customizing workflows, emphasizing automated process reasoning rather than explicit claims of radical discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Not specified in this paper; no quantitative evaluation metrics are described here.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Not specified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty described qualitatively as the ability to reason about process choices and automate workflow customization using Semantic Web and planning techniques.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Not provided in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Paper highlights general community challenges in adopting AI and measuring its impact; specific limitations of Wings are not detailed here.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Amplify scientific discovery with artificial intelligence', 'publication_date_yy_mm': '2014-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1256.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1256.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Eureqa</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Eureqa</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A broadly usable system that searches large hypothesis spaces for mathematical relationships consistent with observed data, ranks promising candidates, and can design experiments to test them.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Eureqa</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Automated symbolic regression/hypothesis-search tool that explores a vast space of candidate functional forms consistent with observed data, selects promising hypotheses, and supports experiment design to test them.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Multiple scientific fields (data-driven law/hypothesis discovery)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Searches for and proposes mathematical relationships or predictive models consistent with empirical data; selects promising hypotheses and can suggest experiments for validation.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>searches a vast space of hypotheses</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The paper states Eureqa "searches a vast space of hypotheses consistent with given data observed in an experiment, selects those most promising, and designs experiments to test them," framing its discovery mode as hypothesis-space search.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Not detailed numerically in this paper; the described evaluation flow is selection of promising hypotheses from the search space and experimental testing designed by the system.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Paper indicates that Eureqa designs experiments to test its hypotheses, implying experimental validation by follow-up testing, but no specific validation protocols or metrics are provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty is framed as the ability to automatically search large hypothesis spaces and propose testable hypotheses, rather than via quantitative novelty scores in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Not provided in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Paper notes a broader lack of metrics to measure AI impact on scientific discovery which affects assessment of tools like Eureqa; no system-specific limitations are given here.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Amplify scientific discovery with artificial intelligence', 'publication_date_yy_mm': '2014-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1256.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e1256.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Sunfall</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Sunfall</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A visual analytics system that incorporates usability and cognitive-load principles to reduce scientist workload and lower false-positive rates in supernova identification.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Sunfall</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A visual analytics interface designed with usability and cognitive-load considerations to assist scientists in tasks such as identifying supernovae, thereby reducing cognitive burden and error rates.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Astrophysics (supernova detection) / visual analytics</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Helps scientists identify supernovae by presenting data and analytical tools in a way that reduces workload and decreases false-positive identifications.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>usability-driven analytics improving detection</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The paper describes Sunfall as incorporating usability principles to reduce workload and false-positive rates, framing its contribution as improvement in human–AI analysis rather than an autonomous scientific breakthrough.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Reported qualitatively in the paper: reduction in scientists' workload and false-positive rates is cited, but no numerical values are provided in this text.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Implicit validation via measured reductions in false-positive rates and workload in the deployment context; the paper does not give experimental details or numeric results.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty characterized by design emphasis on cognitive-load and usability to improve analytic outcomes; no quantitative novelty metrics provided.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Qualitative claims of reduced workload and reduced false-positive rates; no numerical metrics given in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Paper notes absence of standardized measurement approaches for AI impact, which complicates objective assessment of systems like Sunfall; system-specific quantitative results are not presented here.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Amplify scientific discovery with artificial intelligence', 'publication_date_yy_mm': '2014-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1256.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e1256.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Watson</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>IBM Watson (cognitive computing)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A language-based cognitive computing system that demonstrated performance exceeding top human Jeopardy! players and is being applied in medical centers to help clinicians keep up with medical literature.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>IBM Watson</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A large-scale language-based cognitive system combining natural language processing, information retrieval, and probabilistic reasoning to answer complex questions and summarize literature.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Language/knowledge processing; applied to biomedical literature and medical decision support</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Processes vast, changing medical literature to assist clinicians with treatment decisions and keep them current; demonstrated broad language-reasoning capability by outperforming top human players on Jeopardy! (cited as an example of cognitive computing capability).</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>cognitive computing</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The paper uses the term "cognitive computing" (as used by IBM) to describe Watson and cites its Jeopardy! performance as evidence of the category's capabilities; the paper frames Watson as an example of language-based cognitive systems transitioning to scientific/medical applications.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>The paper cites Watson's Jeopardy! victory (comparison to top human players) as an evaluation of capability; for medical use, evaluation methods are not specified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Jeopardy! performance is used as an empirical benchmark vs humans; for clinical applications, the paper does not describe validation methods or clinical trial results.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty is presented as the ability to process and reason over large, changing textual corpora to assist domain experts; the Jeopardy! comparison is used to illustrate novelty in language reasoning performance.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>No numerical clinical impact metrics are provided in this paper; Jeopardy! outcome is an implicit metric of comparative performance against humans.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>The paper explicitly notes Watson "beat the best human players in the televised Jeopardy! game," using that human comparison as evidence of cognitive computing capability; no numeric Jeopardy! scores are provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>While Watson's language capability is highlighted, the paper notes the broader challenge that AI impact in scientific domains lacks standard measures; clinical effectiveness and adoption barriers are not detailed.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Amplify scientific discovery with artificial intelligence', 'publication_date_yy_mm': '2014-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1256.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e1256.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DARPA Big Mechanism</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DARPA Big Mechanism program</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A DARPA initiative to auto-synthesize systems-biology models of cancer by integrating fragmentary causal hypotheses automatically extracted from the literature.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>DARPA Big Mechanism (Information Innovation Office)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Programmatic effort to develop automated systems that read literature, extract fragmentary causal hypotheses, and integrate them into larger mechanistic models (in this case, for cancer systems biology).</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Systems biology / cancer biology</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Aims to synthesize mechanistic systems-biology models by knitting together causal hypotheses gathered through automated literature reading, thereby accelerating model construction from scattered published results.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td>synthesize new systems-biology models</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The paper describes DARPA's effort as an attempt to "synthesize new systems-biology models of cancer by knitting together fragmentary causal hypotheses gathered by automatically reading papers," framing it as model synthesis rather than incremental data analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Not specified in this paper; the programmatic goal is described but evaluation metrics or methods for the resulting models are not given here.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Not specified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty is framed qualitatively as the automated integration of fragmentary causal claims into larger mechanistic models; no quantitative novelty measures are provided.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Not provided in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Paper highlights the general absence of clear metrics to assess AI's scientific impact, which applies to programmatic efforts such as Big Mechanism; specifics about scalability, accuracy of extracted causal claims, and integration fidelity are not detailed here.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Amplify scientific discovery with artificial intelligence', 'publication_date_yy_mm': '2014-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Scientific Discovery: Computational Explorations of the Creative Processes <em>(Rating: 2)</em></li>
                <li>Applications of Artificial Intelligence for Organic Chemistry: The DENDRAL Project <em>(Rating: 2)</em></li>
                <li>Eureqa desktop <em>(Rating: 1)</em></li>
                <li>Smart Machines <em>(Rating: 1)</em></li>
                <li>Information Innovation Office, DARPA <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1256",
    "paper_id": "paper-206561353",
    "extraction_schema_id": "extraction-schema-26",
    "extracted_data": [
        {
            "name_short": "DENDRAL",
            "name_full": "DENDRAL",
            "brief_description": "An early AI system (1970s) that analyzed mass spectrometry data to propose molecular-structure hypotheses; cited as an early application of AI to scientific discovery.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "DENDRAL",
            "system_description": "Rule-based AI system developed in the 1970s to analyze mass spectrometry data and generate hypotheses about molecular structures; represents an early application of domain-encoded knowledge and automated reasoning in chemistry.",
            "discovery_domain": "Chemistry (organic/analytical chemistry)",
            "discovery_description": "Generates candidate molecular structures consistent with mass spectrometry data, effectively automating part of the structure-elucidation reasoning process.",
            "discovery_type": "demonstrated reasoning capabilities",
            "discovery_type_justification": "The paper describes DENDRAL as an early system that \"developed ... for analyzing mass spectrometry data in order to hypothesize molecular structures,\" and uses it as evidence that AI \"demonstrated reasoning capabilities for analyzing scientific data.\" The paper does not classify the discovery as incremental or transformational.",
            "evaluation_methods": "Not specified in this paper; the paper only references DENDRAL as historical proof of concept without describing quantitative evaluation methods.",
            "validation_approaches": "Not specified in this paper.",
            "novelty_assessment": "Novelty is described implicitly by historical context: DENDRAL is presented as an early, pioneering example of automating a nontrivial scientific reasoning task (structure hypothesis from mass spectra). The paper does not provide an explicit novelty metric.",
            "impact_metrics": "Not provided in the paper.",
            "comparison_to_human_discoveries": false,
            "comparison_details": null,
            "success_rate": null,
            "challenges_limitations": "The paper does not give specific limitations for DENDRAL here; it uses DENDRAL as an illustrative early success but notes generally that methods to measure AI impact in science are lacking.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1256.0",
            "source_info": {
                "paper_title": "Amplify scientific discovery with artificial intelligence",
                "publication_date_yy_mm": "2014-10"
            }
        },
        {
            "name_short": "robot scientists",
            "name_full": "robot scientists",
            "brief_description": "Autonomous laboratory systems that can plan and execute experiments and analyze results; cited as recent breakthroughs demonstrating AI applicability across sciences.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "robot scientists",
            "system_description": "Automated laboratory platforms (hardware + software) that can design, execute, and analyze experiments with varying degrees of autonomy, codifying experimental procedures and integrating data analysis.",
            "discovery_domain": "Laboratory sciences / biology (general experimental sciences)",
            "discovery_description": "Used to perform experimental cycles with reduced human intervention, enabling automated hypothesis-driven experiment execution, data collection, and analysis; presented as evidence of broader applicability of AI techniques to discovery tasks.",
            "discovery_type": "broader applicability",
            "discovery_type_justification": "The paper groups robot scientists with other recent breakthroughs as demonstrating the \"broader applicability of AI techniques for scientific discovery,\" implying these systems extend AI beyond narrow tasks into experimental automation.",
            "evaluation_methods": "Not detailed in this paper; robot scientists are referenced at high level without specific metrics or experimental evaluation protocols described here.",
            "validation_approaches": "Not specified in this paper (implicit validation would be experimental replication and confirmation by domain scientists, but the paper does not detail these).",
            "novelty_assessment": "Characterized as a recent breakthrough that broadens AI applicability to experimental laboratory work; novelty is indicated by their ability to automate experiment execution rather than by quantified novelty metrics.",
            "impact_metrics": "Not provided in the paper.",
            "comparison_to_human_discoveries": false,
            "comparison_details": null,
            "success_rate": null,
            "challenges_limitations": "Paper highlights general challenges in measuring AI impact on science; specifically, it notes a lack of clear methods to quantify the impact of AI systems like robot scientists.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1256.1",
            "source_info": {
                "paper_title": "Amplify scientific discovery with artificial intelligence",
                "publication_date_yy_mm": "2014-10"
            }
        },
        {
            "name_short": "software formulating laws",
            "name_full": "software that formulates laws for complex dynamical systems",
            "brief_description": "Automated software that can discover mathematical laws or governing equations from data for complex dynamical systems; cited as an example of AI discovering higher-level scientific relationships.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "software that formulates laws for complex dynamical systems",
            "system_description": "Algorithms that search hypothesis spaces (often symbolic/regression or equation-discovery methods) to find compact expressions or laws that explain observed dynamical data.",
            "discovery_domain": "Physics / dynamical systems / general empirical sciences",
            "discovery_description": "Extracts candidate governing equations or mathematical relationships from experimental or observational data, thereby generating law-like descriptions of system behavior.",
            "discovery_type": "broader applicability",
            "discovery_type_justification": "The paper cites such software as a recent breakthrough demonstrating \"broader applicability of AI techniques for scientific discovery,\" implying significance beyond narrow pattern recognition.",
            "evaluation_methods": "Not specified in this paper; the paper does not enumerate metrics such as goodness-of-fit, parsimony, or predictive accuracy for these systems.",
            "validation_approaches": "Not specified here; typical validation would include comparison to known laws or experimental predictive performance, but the paper does not provide details.",
            "novelty_assessment": "Presented as noteworthy because it can \"formulate laws\" from data, indicating novelty in producing interpretable, law-like outputs rather than only correlative models.",
            "impact_metrics": "Not provided in this paper.",
            "comparison_to_human_discoveries": false,
            "comparison_details": null,
            "success_rate": null,
            "challenges_limitations": "Paper emphasizes lack of standardized measures to quantify AI impact; this makes assessing how law-formulating software compares to human-derived laws difficult.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1256.2",
            "source_info": {
                "paper_title": "Amplify scientific discovery with artificial intelligence",
                "publication_date_yy_mm": "2014-10"
            }
        },
        {
            "name_short": "Hanalyzer",
            "name_full": "Hanalyzer (high-throughput analyzer)",
            "brief_description": "A semantic, NLP-driven system that integrates biomedical database assertions and literature to reason about semantic networks and suggest novel gene–disease correlations for experimental follow-up.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Hanalyzer",
            "system_description": "Combines natural language processing to extract semantic networks from PubMed, integrates assertions from other biomedical sources using Semantic Web technology, and reasons over the integrated semantic information to suggest potentially novel correlations.",
            "discovery_domain": "Biomedicine / genomics / systems biology",
            "discovery_description": "Finds new correlations (e.g., candidate genes to investigate) by reasoning over an integrated semantic network built from literature and databases; results are presented as suggestions for scientists to generate testable hypotheses.",
            "discovery_type": "suggest novel correlations",
            "discovery_type_justification": "The paper states Hanalyzer \"reasons about the network to find new correlations that suggest new genes to investigate,\" framing its outputs as novel correlations to drive further hypothesis generation.",
            "evaluation_methods": "Not quantitatively detailed in this paper; evaluation implied via the production of candidate correlations and the subsequent potential for scientist-driven hypothesis testing.",
            "validation_approaches": "Validation is presented implicitly as downstream: scientists can generate and test hypotheses suggested by Hanalyzer; the paper does not describe specific validation experiments or metrics.",
            "novelty_assessment": "Novelty is assessed qualitatively: Hanalyzer's novelty lies in automated extraction/integration of assertions and reasoning to suggest previously unrecognized correlations; no numerical novelty metrics are provided.",
            "impact_metrics": "Not provided in the paper.",
            "comparison_to_human_discoveries": false,
            "comparison_details": null,
            "success_rate": null,
            "challenges_limitations": "The paper notes the complexity of developing explicit representations of scientific processes and that successful systems become \"junior participants,\" but it also emphasizes the broader problem of lacking measurement methods to quantify AI's impact.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1256.3",
            "source_info": {
                "paper_title": "Amplify scientific discovery with artificial intelligence",
                "publication_date_yy_mm": "2014-10"
            }
        },
        {
            "name_short": "Wings",
            "name_full": "Wings",
            "brief_description": "A system using Semantic Web and AI planning to reason about model and algorithm selection and to automatically customize data-analysis workflows for water-quality data and daily conditions.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Wings",
            "system_description": "Uses Semantic Web technologies and AI planning to reason about choices of models and algorithms and to automatically generate customized analysis workflows based on domain knowledge and context.",
            "discovery_domain": "Environmental science / water-quality data analysis / scientific workflow management",
            "discovery_description": "Automates selection and configuration of models and algorithms for water-quality analysis, producing customized workflows adapted to daily conditions, thereby reducing manual decision-making in data processing.",
            "discovery_type": "workflow automation and reasoning",
            "discovery_type_justification": "The paper describes Wings as reasoning about model/algorithm choices and customizing workflows, emphasizing automated process reasoning rather than explicit claims of radical discovery.",
            "evaluation_methods": "Not specified in this paper; no quantitative evaluation metrics are described here.",
            "validation_approaches": "Not specified in this paper.",
            "novelty_assessment": "Novelty described qualitatively as the ability to reason about process choices and automate workflow customization using Semantic Web and planning techniques.",
            "impact_metrics": "Not provided in the paper.",
            "comparison_to_human_discoveries": false,
            "comparison_details": null,
            "success_rate": null,
            "challenges_limitations": "Paper highlights general community challenges in adopting AI and measuring its impact; specific limitations of Wings are not detailed here.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1256.4",
            "source_info": {
                "paper_title": "Amplify scientific discovery with artificial intelligence",
                "publication_date_yy_mm": "2014-10"
            }
        },
        {
            "name_short": "Eureqa",
            "name_full": "Eureqa",
            "brief_description": "A broadly usable system that searches large hypothesis spaces for mathematical relationships consistent with observed data, ranks promising candidates, and can design experiments to test them.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Eureqa",
            "system_description": "Automated symbolic regression/hypothesis-search tool that explores a vast space of candidate functional forms consistent with observed data, selects promising hypotheses, and supports experiment design to test them.",
            "discovery_domain": "Multiple scientific fields (data-driven law/hypothesis discovery)",
            "discovery_description": "Searches for and proposes mathematical relationships or predictive models consistent with empirical data; selects promising hypotheses and can suggest experiments for validation.",
            "discovery_type": "searches a vast space of hypotheses",
            "discovery_type_justification": "The paper states Eureqa \"searches a vast space of hypotheses consistent with given data observed in an experiment, selects those most promising, and designs experiments to test them,\" framing its discovery mode as hypothesis-space search.",
            "evaluation_methods": "Not detailed numerically in this paper; the described evaluation flow is selection of promising hypotheses from the search space and experimental testing designed by the system.",
            "validation_approaches": "Paper indicates that Eureqa designs experiments to test its hypotheses, implying experimental validation by follow-up testing, but no specific validation protocols or metrics are provided here.",
            "novelty_assessment": "Novelty is framed as the ability to automatically search large hypothesis spaces and propose testable hypotheses, rather than via quantitative novelty scores in this paper.",
            "impact_metrics": "Not provided in the paper.",
            "comparison_to_human_discoveries": false,
            "comparison_details": null,
            "success_rate": null,
            "challenges_limitations": "Paper notes a broader lack of metrics to measure AI impact on scientific discovery which affects assessment of tools like Eureqa; no system-specific limitations are given here.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1256.5",
            "source_info": {
                "paper_title": "Amplify scientific discovery with artificial intelligence",
                "publication_date_yy_mm": "2014-10"
            }
        },
        {
            "name_short": "Sunfall",
            "name_full": "Sunfall",
            "brief_description": "A visual analytics system that incorporates usability and cognitive-load principles to reduce scientist workload and lower false-positive rates in supernova identification.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Sunfall",
            "system_description": "A visual analytics interface designed with usability and cognitive-load considerations to assist scientists in tasks such as identifying supernovae, thereby reducing cognitive burden and error rates.",
            "discovery_domain": "Astrophysics (supernova detection) / visual analytics",
            "discovery_description": "Helps scientists identify supernovae by presenting data and analytical tools in a way that reduces workload and decreases false-positive identifications.",
            "discovery_type": "usability-driven analytics improving detection",
            "discovery_type_justification": "The paper describes Sunfall as incorporating usability principles to reduce workload and false-positive rates, framing its contribution as improvement in human–AI analysis rather than an autonomous scientific breakthrough.",
            "evaluation_methods": "Reported qualitatively in the paper: reduction in scientists' workload and false-positive rates is cited, but no numerical values are provided in this text.",
            "validation_approaches": "Implicit validation via measured reductions in false-positive rates and workload in the deployment context; the paper does not give experimental details or numeric results.",
            "novelty_assessment": "Novelty characterized by design emphasis on cognitive-load and usability to improve analytic outcomes; no quantitative novelty metrics provided.",
            "impact_metrics": "Qualitative claims of reduced workload and reduced false-positive rates; no numerical metrics given in the paper.",
            "comparison_to_human_discoveries": false,
            "comparison_details": null,
            "success_rate": null,
            "challenges_limitations": "Paper notes absence of standardized measurement approaches for AI impact, which complicates objective assessment of systems like Sunfall; system-specific quantitative results are not presented here.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1256.6",
            "source_info": {
                "paper_title": "Amplify scientific discovery with artificial intelligence",
                "publication_date_yy_mm": "2014-10"
            }
        },
        {
            "name_short": "Watson",
            "name_full": "IBM Watson (cognitive computing)",
            "brief_description": "A language-based cognitive computing system that demonstrated performance exceeding top human Jeopardy! players and is being applied in medical centers to help clinicians keep up with medical literature.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "IBM Watson",
            "system_description": "A large-scale language-based cognitive system combining natural language processing, information retrieval, and probabilistic reasoning to answer complex questions and summarize literature.",
            "discovery_domain": "Language/knowledge processing; applied to biomedical literature and medical decision support",
            "discovery_description": "Processes vast, changing medical literature to assist clinicians with treatment decisions and keep them current; demonstrated broad language-reasoning capability by outperforming top human players on Jeopardy! (cited as an example of cognitive computing capability).",
            "discovery_type": "cognitive computing",
            "discovery_type_justification": "The paper uses the term \"cognitive computing\" (as used by IBM) to describe Watson and cites its Jeopardy! performance as evidence of the category's capabilities; the paper frames Watson as an example of language-based cognitive systems transitioning to scientific/medical applications.",
            "evaluation_methods": "The paper cites Watson's Jeopardy! victory (comparison to top human players) as an evaluation of capability; for medical use, evaluation methods are not specified in this paper.",
            "validation_approaches": "Jeopardy! performance is used as an empirical benchmark vs humans; for clinical applications, the paper does not describe validation methods or clinical trial results.",
            "novelty_assessment": "Novelty is presented as the ability to process and reason over large, changing textual corpora to assist domain experts; the Jeopardy! comparison is used to illustrate novelty in language reasoning performance.",
            "impact_metrics": "No numerical clinical impact metrics are provided in this paper; Jeopardy! outcome is an implicit metric of comparative performance against humans.",
            "comparison_to_human_discoveries": true,
            "comparison_details": "The paper explicitly notes Watson \"beat the best human players in the televised Jeopardy! game,\" using that human comparison as evidence of cognitive computing capability; no numeric Jeopardy! scores are provided here.",
            "success_rate": null,
            "challenges_limitations": "While Watson's language capability is highlighted, the paper notes the broader challenge that AI impact in scientific domains lacks standard measures; clinical effectiveness and adoption barriers are not detailed.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1256.7",
            "source_info": {
                "paper_title": "Amplify scientific discovery with artificial intelligence",
                "publication_date_yy_mm": "2014-10"
            }
        },
        {
            "name_short": "DARPA Big Mechanism",
            "name_full": "DARPA Big Mechanism program",
            "brief_description": "A DARPA initiative to auto-synthesize systems-biology models of cancer by integrating fragmentary causal hypotheses automatically extracted from the literature.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "DARPA Big Mechanism (Information Innovation Office)",
            "system_description": "Programmatic effort to develop automated systems that read literature, extract fragmentary causal hypotheses, and integrate them into larger mechanistic models (in this case, for cancer systems biology).",
            "discovery_domain": "Systems biology / cancer biology",
            "discovery_description": "Aims to synthesize mechanistic systems-biology models by knitting together causal hypotheses gathered through automated literature reading, thereby accelerating model construction from scattered published results.",
            "discovery_type": "synthesize new systems-biology models",
            "discovery_type_justification": "The paper describes DARPA's effort as an attempt to \"synthesize new systems-biology models of cancer by knitting together fragmentary causal hypotheses gathered by automatically reading papers,\" framing it as model synthesis rather than incremental data analysis.",
            "evaluation_methods": "Not specified in this paper; the programmatic goal is described but evaluation metrics or methods for the resulting models are not given here.",
            "validation_approaches": "Not specified in this paper.",
            "novelty_assessment": "Novelty is framed qualitatively as the automated integration of fragmentary causal claims into larger mechanistic models; no quantitative novelty measures are provided.",
            "impact_metrics": "Not provided in the paper.",
            "comparison_to_human_discoveries": false,
            "comparison_details": null,
            "success_rate": null,
            "challenges_limitations": "Paper highlights the general absence of clear metrics to assess AI's scientific impact, which applies to programmatic efforts such as Big Mechanism; specifics about scalability, accuracy of extracted causal claims, and integration fidelity are not detailed here.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1256.8",
            "source_info": {
                "paper_title": "Amplify scientific discovery with artificial intelligence",
                "publication_date_yy_mm": "2014-10"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Scientific Discovery: Computational Explorations of the Creative Processes",
            "rating": 2,
            "sanitized_title": "scientific_discovery_computational_explorations_of_the_creative_processes"
        },
        {
            "paper_title": "Applications of Artificial Intelligence for Organic Chemistry: The DENDRAL Project",
            "rating": 2,
            "sanitized_title": "applications_of_artificial_intelligence_for_organic_chemistry_the_dendral_project"
        },
        {
            "paper_title": "Eureqa desktop",
            "rating": 1,
            "sanitized_title": "eureqa_desktop"
        },
        {
            "paper_title": "Smart Machines",
            "rating": 1,
            "sanitized_title": "smart_machines"
        },
        {
            "paper_title": "Information Innovation Office, DARPA",
            "rating": 2,
            "sanitized_title": "information_innovation_office_darpa"
        }
    ],
    "cost": 0.01517675,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>POLICY</p>
<p>Yolanda Gil 
Mark Greaves 
Pacif c Northwest National Laboratory
99354RichlandWAUSA</p>
<p>James Hendler 
Information Technology and Web Science
Rensselaer Polytechnic Institute
12203TroyNYUSA</p>
<p>Haym Hirsh 
Cornell University
14850IthacaNYUSA</p>
<p>ARTIFICIAL INTELLIGENCE 1 Information Sciences Institute
Marina del Rey
University of Southern California
90292CAUSA</p>
<p>POLICY
10.1126/science.125943910 OCTOBER 2014 • VOL 346 ISSUE 6206 171 Many human activities are a bottleneck in progress Published by AAAS
SCIENCE sciencemag.org T echnological innovations are penetrating all areas of science, making predominantly human activities a principal bottleneck in scientific progress while also making scientific advancement more subject to error and harder to reproduce. This is an area where a new generation of artificial intelligence (AI) systems can radically transform the practice of scientific discovery. Such systems areshowing an increasing ability to automate scientific data analysis and discovery processes, can search systematically and correctly through hypothesis spaces to ensure best results, can autonomously discover complex patterns in data, and can reliably apply small-scale scientific processes consistently and transparently so that they can be easily reproduced. We discuss these advances and the steps that could help promote their development and deployment.Applying AI to the practice of science is not new. AI pioneer and Nobel laureate Herbert Simon hypothesized that cognitive mechanisms involved in scientific discovery are a special case of general human capabilities for problem-solving and, with colleagues, developed systems in the 1970s and 1980s that demonstrated reasoning capabilities for analyzing scientific data ( 1). Also in the 1970s, Joshua Lederberg (another Nobel winner) and colleagues developed the DENDRAL system for analyzing mass spectrometry data in order to hypothesize molecular structures ( 2). More recent breakthroughs, such as robot scientists and software that formulates laws for complex dynamical systems, demonstrate broader applicability of AI techniques for scientific discovery ( 3).Over the past two decades, AI has seen accelerating scientific advances and concomitant commercial-sector successes because of advances on three fronts: steady scholarly advances, especially as success has increased the numbers of interested participants; Moore's law and steady exponential increases in computing power; and exponential increases in, and broad availability of, relevant data in volumes never previously seen. Those scientific efforts that have leveraged AI advances have largely harnessed sophisticated machine-learning techniques to create correlative predictions from large sets of "big data." Such work aligns well with the current needs of peta-and exascale science. However, AI has far broader capacity to accelerate scientific discovery, and AI-based systems that can represent hypotheses, reason with models of the data, and design hypothesis-driven data collection techniques can reduce the error-prone human bottleneck in scientific discovery.SEARCHING AND SYNTHESIZING.What do these intelligent systems look like today? AI techniques are amplifying existing tools in identifying relevant results from the broader scientific community. Search engines are some of the most important and frequently used tools in the general scientific arsenal. Major search engines all use AI techniques for tasks like query suggestion and result customization. Increasingly, scientists in many fields are augmenting the power of search by using machine-readable ontologies and Semantic Web technology ( 4) to tag not just scientific articles but also figures and videos, blogs, data sets, and computational services, which allow information-finding beyond current search limitations.We can project a not-so-distant future where "intelligent science assistant" programs identify and summarize relevant research described across the worldwide multilingual spectrum of blogs, preprint archives, and discussion forums; find or generate new hypotheses that might confirm or conflict with ongoing work; and even rerun old analyses when a new computational method becomes available. Aided by such a system, the scientist will focus on more of the creative aspects of research, with a larger fraction of the routine work left to the artificially intelligent assistant.New types of intelligent systems that can enhance scientific efforts in this manner are transitioning from academic and industrial research laboratories. A term gathering popularity for systems that intelligently process online information beyond search is "cognitive computing," used by IBM in describing the Watson system that beat the best human players in the televised Jeopardy! game ( 5). One kind of cognitive system includes language-based programs like Watson, which is now being used by IBM and a number of prominent medical centers in developing tools for improving medical treatment by helping doctors keep up with constantly changing medical literature. To enhance these capabilities, the U.S. Defense Advanced Research Projects Agency (DARPA) recently announced a major effort to synthesize new systems-biology models of cancer by knitting together fragmentary causal hypotheses gathered by automatically reading papers in the literature ( 6). Another group of cognitive systems, based largely on advances in neural networks and neurologically inspired computation, is beginning to show promise in the analysis of nontextual processing, especially of online images and video, across a wide range of areas including Amplify scientific discovery with artificial intelligence Schematic of Hanalyzer. Hanalyzer is an example of a modern scientific discovery system. It integrates assertions from biomedical databases and then reasons about the resulting semantic information to suggest novel correlations from which scientists can generate testable hypotheses.</p>
<p>T echnological innovations are penetrating all areas of science, making predominantly human activities a principal bottleneck in scientific progress while also making scientific advancement more subject to error and harder to reproduce. This is an area where a new generation of artificial intelligence (AI) systems can radically transform the practice of scientific discovery. Such systems are</p>
<p>showing an increasing ability to automate scientific data analysis and discovery processes, can search systematically and correctly through hypothesis spaces to ensure best results, can autonomously discover complex patterns in data, and can reliably apply small-scale scientific processes consistently and transparently so that they can be easily reproduced. We discuss these advances and the steps that could help promote their development and deployment.</p>
<p>Applying AI to the practice of science is not new. AI pioneer and Nobel laureate Herbert Simon hypothesized that cognitive mechanisms involved in scientific discovery are a special case of general human capabilities for problem-solving and, with colleagues, developed systems in the 1970s and 1980s that demonstrated reasoning capabilities for analyzing scientific data ( 1). Also in the 1970s, Joshua Lederberg (another Nobel winner) and colleagues developed the DENDRAL system for analyzing mass spectrometry data in order to hypothesize molecular structures ( 2). More recent breakthroughs, such as robot scientists and software that formulates laws for complex dynamical systems, demonstrate broader applicability of AI techniques for scientific discovery ( 3).</p>
<p>Over the past two decades, AI has seen accelerating scientific advances and concomitant commercial-sector successes because of advances on three fronts: steady scholarly advances, especially as success has increased the numbers of interested participants; Moore's law and steady exponential increases in computing power; and exponential increases in, and broad availability of, relevant data in volumes never previously seen. Those scientific efforts that have leveraged AI advances have largely harnessed sophisticated machine-learning techniques to create correlative predictions from large sets of "big data." Such work aligns well with the current needs of peta-and exascale science. However, AI has far broader capacity to accelerate scientific discovery, and AI-based systems that can represent hypotheses, reason with models of the data, and design hypothesis-driven data collection techniques can reduce the error-prone human bottleneck in scientific discovery.</p>
<p>SEARCHING AND SYNTHESIZING.</p>
<p>What do these intelligent systems look like today? AI techniques are amplifying existing tools in identifying relevant results from the broader scientific community. Search engines are some of the most important and frequently used tools in the general scientific arsenal. Major search engines all use AI techniques for tasks like query suggestion and result customization. Increasingly, scientists in many fields are augmenting the power of search by using machine-readable ontologies and Semantic Web technology ( 4) to tag not just scientific articles but also figures and videos, blogs, data sets, and computational services, which allow information-finding beyond current search limitations.</p>
<p>We can project a not-so-distant future where "intelligent science assistant" programs identify and summarize relevant research described across the worldwide multilingual spectrum of blogs, preprint archives, and discussion forums; find or generate new hypotheses that might confirm or conflict with ongoing work; and even rerun old analyses when a new computational method becomes available. Aided by such a system, the scientist will focus on more of the creative aspects of research, with a larger fraction of the routine work left to the artificially intelligent assistant.</p>
<p>New types of intelligent systems that can enhance scientific efforts in this manner are transitioning from academic and industrial research laboratories. A term gathering popularity for systems that intelligently process online information beyond search is "cognitive computing," used by IBM in describing the Watson system that beat the best human players in the televised Jeopardy! game ( 5). One kind of cognitive system includes language-based programs like Watson, which is now being used by IBM and a number of prominent medical centers in developing tools for improving medical treatment by helping doctors keep up with constantly changing medical literature. To enhance these capabilities, the U.S. Defense Advanced Research Projects Agency (DARPA) recently announced a major effort to synthesize new systems-biology models of cancer by knitting together fragmentary causal hypotheses gathered by automatically reading papers in the literature ( 6). Another group of cognitive systems, based largely on advances in neural networks and neurologically inspired computation, is beginning to show promise in the analysis of nontextual processing, especially of online images and video, across a wide range of areas including Amplify scientific discovery with artificial intelligence Schematic of Hanalyzer. Hanalyzer is an example of a modern scientific discovery system. It integrates assertions from biomedical databases and then reasons about the resulting semantic information to suggest novel correlations from which scientists can generate testable hypotheses.</p>
<p>sciencemag.org SCIENCE biological imaging ( 7), species preservation ( 8), and quantum chemistry ( 9). DIGESTING DATA. AI techniques have accelerated the pace and quality of analysis of the huge quantities of data that can stream from modern laboratory equipment. To derive scientific insight from data at this scale, standard methods include applying dimensionality-reduction techniques and feature extractors to create high-speed classifiers based on machine-learning approaches, such as Bayesian networks or support-vector machines. Because the phenomena under study often exist in nonstationary environments or in contexts with only small quantities of labeled data that can be used for trainingcomplex, unsupervised, and reinforcement machine-learning techniques are critical for data analysis. These types of approaches are being used in recent projects in data-rich areas as diverse as chemical structure prediction, pathway analysis and identification in systems biology, the processing of large-scale geophysics data, and others.</p>
<p>Another, more ambitious class of intelligent systems is being developed under the rubric of Discovery Science or, increasingly, Discovery Informatics ( 10). These systems enhance the intelligent assistants described earlier with the capability to attack scientific tasks that combine rote work with increasing amounts of adaptivity and freedom. These systems use encoded knowledge of scientific domains and processes in order to assist with tasks that previously required human knowledge and reasoning. In fact, several sciences have significant investments in the representation of vast amounts of scientific knowledge and are poised to explore new intelligent systems that exploit that knowledge for discovery.</p>
<p>For example, the Hanalyzer (short for high-throughput analyzer) uses natural language processing to automatically extract a semantic network from all PubMed papers relevant to a specific scientist, uses Semantic Web technology to integrate assertions from other biomedical sources, and reasons about the network to find new correlations that suggest new genes to investigate ( 11) (see the figure). The Wings system uses Semantic Web technologies and AI planning to reason about specific choices of models and algorithms for water-quality data and customizes workflows automatically for daily conditions ( 12). Eureqa, usable in many scientific fields, searches a vast space of hypotheses consistent with given data observed in an experiment, selects those most promising, and designs experiments to test them ( 13). Sunfall incorporates usability principles and cognitive load considerations in the design of a visual analytics interface; this reduces scientists' workload and false-positive rates in identifying supernovae ( 14).</p>
<p>These four systems are representative of the ways that more advanced AI can serve scientific ends. They are based on explicit representations of science processes, and they reason about these to automate processes and assist the human scientist. Development of the explicit representations of scientific processes on which they are based is complex. When successful, the computer can become a real (although junior) participant in the science process, doing what it does best: applying algorithmic methods and bringing knowledge to bear in a consistent, systematic, and complete manner.</p>
<p>A VIRTUOUS CIRCLE. Developing systems like these is not just an exercise in AI application-it affects the direction of AI research. Addressing real challenges of science pushes the AI envelope in many areas, including knowledge representation, automatic inference, process reasoning, hypothesis generation, natural language processing, machine learning, collaborative interaction, and intelligent user interfaces. This interaction creates a virtuous circle where advances in science go hand in hand with advances in AI. This virtuous circle can only work well if balanced and well oiled.</p>
<p>What are the best ways to immerse AI research into scientific practice so that it can deliver on this promise? First, and perhaps most obviously, is conceiving new means of bringing interdisciplinary research teams together at an earlier stage of research and in a sustainable manner. Increasingly, there is a realization in academia that scientists must gain broad knowledge and skills in computation and programming. This should include AI components-training and supporting students and young researchers. In addition, basic research to advance AI in domains of science practice needs to be facilitated and rewarded in academia, as standard criteria for research merit focus primarily on theoretical advances in computing per se and thus do not transfer well to this kind of multidisciplinary research.</p>
<p>A significant challenge that appears to be specific to AI is to attract scientific researchers to engage in this joint research. Scientists have made significant invest-ments in the past in advanced computing technologies, such as high-end computing, distributed databases, and sensor networks. However, their interest in AI seems relatively limited. With AI systems having impacts in the consumer sector (e.g., speech recognition systems, real-time automated language translation, and self-driving cars and selfnavigating drones), why are scientists not enthusiastic about embracing AI?</p>
<p>One hypothesis is the lack of clear methods to measure the impact of AI in science. There are exceptions in some areas of AI, such as machine learning and language processing, where metrics to compare systems have been defined and improvement has been measured. But there has been little research into such measurement more generally, especially for the heuristic methods of the reasoning field. Methods to quantify significant advances because of the use of new AI technologies in scientific fields are needed to validate the impact of AI on scientific discovery.</p>
<p>Another reason may be the limited work of the AI community in disseminating and marketing ideas to scientists. Although many non-AI scientists attend supercomputing and database conferences, few are compelled to attend an AI conference. Possibly, researchers are influenced by the unrealistic science fiction images of super-smart machines, rather than the realities of current technological advances. Understanding the sources of hesitation of scientists to embrace AI will be a first step toward changing the culture and bringing these communities together.</p>
<p>The world faces deep problems that challenge traditional methodologies and ideologies. These challenges will require the best brains on our planet. In the modern world, the best brains are a combination of humans and intelligent computers, able to surpass the capabilities of either one alone. ■</p>
<p>P Langley, H A Simon, G L Bradshaw, J M Zytkow, Scientific Discovery: Computational Explorations of the Creative Processes. Cambridge, MAMIT PressP. Langley, H. A. Simon, G. L. Bradshaw, J. M. Zytkow, Scientific Discovery: Computational Explorations of the Creative Processes (MIT Press, Cambridge, MA, 1987).</p>
<p>Applications of Artificial Intelligence for Organic Chemistry: The DENDRAL Project. R K Lindsay, McGraw-HillNew YorkR. K. Lindsay et al., Applications of Artificial Intelligence for Organic Chemistry: The DENDRAL Project (McGraw-Hill, New York, 1980).</p>
<p>. D Waltz, B G Buchanan, Science. 32443D. Waltz, B. G. Buchanan, Science 324, 43 (2009).</p>
<p>. J Hendler, Science. 299520J. Hendler, Science 299, 520 (2003).</p>
<p>J KellyIII, S Hamm, Smart Machines. New YorkColumbia Univ. PressJ. Kelly III, S. Hamm, Smart Machines (Columbia Univ. Press, New York, 2013).</p>
<p>Information Innovation Office, DARPA; www.darpa.mil/ Our_Work/I2O/Programs/Big_Mechanism.aspx. Information Innovation Office, DARPA; www.darpa.mil/ Our_Work/I2O/Programs/Big_Mechanism.aspx.</p>
<p>. S N Deepa, B Devi, Indian J. Sci. Technol. 41538S. N. Deepa, B. Aruna Devi, Indian J. Sci. Technol. 4, 1538 (2011).</p>
<p>. M Martialay, Citizen Scientist. The ApproachM. Martialay, "Citizen Scientist," The Approach;</p>
<p>. C Caetano, Int. J. Quantum Chem. 1112732C. Caetano et al., Int. J. Quantum Chem. 111, 2732 (2011).</p>
<p>. S M Leach, PLOS Comput. Biol. 51000215S. M. Leach et al., PLOS Comput. Biol. 5, e1000215 (2009).</p>
<p>. Y Gil, IEEE Intell. Syst. 2662Y. Gil et al., IEEE Intell. Syst. 26, 62 (2011).</p>
<p>. Eureqa desktop. Eureqa desktop, www.nutonian.com/products/eureqa/.</p>
<p>. C R Aragon, S J Bailey, S Poon, K Runge, R C Thomas, J. Phys. Conf. Ser. 12512091C. R. Aragon, S. J. Bailey, S. Poon, K. Runge, R. C. Thomas, J. Phys. Conf. Ser. 125, 012091 (2008).</p>            </div>
        </div>

    </div>
</body>
</html>