<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-727 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-727</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-727</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-20.html">extraction-schema-20</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <p><strong>Paper ID:</strong> paper-250451049</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2207.05723v2.pdf" target="_blank">Latent Variable Models for Bayesian Causal Discovery</a></p>
                <p><strong>Paper Abstract:</strong> Learning predictors that do not rely on spurious correlations involves building causal representations. However, learning such a representation is very challenging. We, therefore, formulate the problem of learning a causal representation from high dimensional data and study causal recovery with synthetic data. This work introduces a latent variable decoder model, Decoder BCD, for Bayesian causal discovery and performs experiments in mildly supervised and unsupervised settings. We present a series of synthetic experiments to characterize important factors for causal discovery and show that using known intervention targets as labels helps in unsupervised Bayesian inference over structure and parameters of linear Gaussian additive noise latent structural causal models.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e727.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e727.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Decoder BCD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Decoder Bayesian Causal Discovery (Decoder BCD)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A latent-variable decoder model introduced in this paper that extends BCD Nets to perform Bayesian structure learning in a low-dimensional linear Gaussian SCM inferred from high-dimensional observations; it jointly learns a decoder from latent causal variables to observed data while inferring a posterior over DAG structure and noise parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Decoder BCD</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Decoder BCD is a fully differentiable latent-variable Bayesian causal discovery model that extends BCD Nets to the setting where true causal variables are not observed. It parameterizes the DAG via a factorization W = (P L P^T)^T (with permutation matrix P and strictly lower-triangular L) and performs variational inference over P, L and Σ using an ELBO objective; additionally it learns a decoder that maps sampled latent causal variable realizations back to high-dimensional observations X. Training losses used include reconstruction MSE(X, X_hat) and (in mildly supervised runs) a KL divergence between the inferred observational joint q(z) and the ground-truth observational joint p(z). The model inherits priors from BCD Nets (horseshoe prior on L for sparsity, Gumbel-Sinkhorn prior on P for permutations, Gaussian prior on Σ) and uses ancestral sampling in the latent SCM to generate latents that are decoded to observations during training. Interventional data (single- or multi-node, fixed or sampled values) and interventional targets-as-labels can be incorporated to improve identifiability and edge-orientation in the unsupervised setting.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Synthetic high-dimensional linear-projection environment (latent linear Gaussian SCM projected to high-D)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>A synthetic, non-interactive simulation environment where a d-dimensional linear Gaussian additive-noise SCM (identifiable under equal noise variances) is sampled via ancestral sampling to produce latent data z; high-dimensional observed data X is generated by a linear projection X = z P (with D >> d). Interventional datasets are synthesized by zeroing columns in W for intervened nodes and sampling from the mutated SCM; interventions in the paper are chosen randomly (single or multi-node) and values are fixed or sampled from a uniform range. The environment allows passive observation and offline interventional datasets but does not perform active/closed-loop experiment selection in Decoder BCD itself.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Implicit sparsity and supervision: horseshoe sparsity prior on L (to shrink irrelevant edges), using KL alignment between inferred and true observational joint as a mild supervision signal, and incorporation of interventional targets-as-labels (single- or multi-node interventions with varied values) to disambiguate spurious correlations and orient edges in latent space.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Irrelevant/weak edges (spurious correlations between latent variables induced by projection), measurement noise from projection, and identifiability issues due to observational equivalence (MEC ambiguity); interventions are used to address orientation confounding.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>No explicit detector for distractor variables; reliance on Bayesian sparsity prior (horseshoe) to shrink spurious edges and on mismatch between reconstructed X and expected latent joint (KL(true||learned)) as a supervision signal to reveal poor latent recovery.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Bayesian shrinkage via the horseshoe prior on L to downweight/spike-to-zero spurious edge weights; variational posterior can place low mass on spurious structures.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Use of interventional data (single- and multi-node interventions, varied intervention values) to test and disambiguate edge orientation and refute edges that are not consistent with interventional distributions; KL divergence between posterior observational joint and GT joint is used as an objective to align/refute candidate latent structures in the mildly supervised setting.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Qualitative improvements reported: with mild supervision (KL(true||learned)) the expected Structural Hamming Distance (SHD) approaches 0 and MSE(L, L_gt) approaches 0 (complete graph recovery). Using interventional targets-as-labels and large amounts of interventional data (e.g., 300 obs + 3300 interventional points) improves SHD, AUROC, MSE and KL metrics; multi-node interventions with uniformly sampled values performed best in the experiments. Exact numeric metrics are not provided in-text.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Without KL supervision and without (sufficient) interventional data, unsupervised Decoder BCD often fails: learning from observational data alone does not reliably orient edges (SHD remains high); learning a single edge from observational or mixed observational/interventional data with fixed intervention values was insufficient to orient that edge.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>1) Mild supervision via a KL loss over the observational joint enables full recovery (SHD→0) in the supervised case. 2) Unsupervised learning from observational data alone frequently fails to orient edges or recover L. 3) Incorporating interventional targets-as-labels substantially improves latent graph and parameter recovery; multi-node interventions with varied (uniformly sampled) intervention values outperform fixed-value interventions. 4) Horseshoe sparsity prior and interventional data together help downweight/refute spurious latent edges, but designing losses that guarantee latent-structure recovery from low reconstruction loss remains an open challenge.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e727.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e727.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BCD Nets</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bayesian Causal Discovery Nets (BCD Nets)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A variational Bayesian structure learning method that parameterizes DAGs with a permutation matrix and a strictly lower-triangular matrix to enforce acyclicity and obtains a posterior over graph structures and noise parameters via ELBO optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Bcd nets: Scalable variational approaches for bayesian causal discovery</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>BCD Nets</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>BCD Nets formulates Bayesian structure learning as variational inference over a parameterization W = (P L P^T)^T, where P is a permutation matrix and L is strictly lower-triangular, ensuring a hard DAG constraint. It factorizes the posterior q(P, L, Σ) and optimizes an ELBO with priors including a horseshoe prior on L for sparsity, a Gumbel-Sinkhorn (Gumbel Sinkhorn) prior on P for permutations, and Gaussian priors on noise covariances. The approach samples P, L, Σ from the variational posterior, computes likelihoods under the implied linear Gaussian SCM, and updates variational parameters via gradient-based optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Tabular observational/interventional datasets of observed causal variables</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Works on datasets where the causal variables are observed (i.e., not the high-dimensional projection case)—the methods handle observational and interventional samples and recover posterior distributions over DAGs; not inherently an interactive/virtual-lab environment.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Sparsity-inducing horseshoe prior on L (regularization) to favor sparse graphs and shrink spurious edges; Bayesian posterior quantification to reflect uncertainty over edges which can reduce reliance on spurious signals.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Spurious/weak edges (irrelevant connections), sampling noise; observational indistinguishability (MEC) ameliorated by interventional data when available.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>No explicit distractor detector; spurious edges are de-emphasized by posterior shrinkage under the horseshoe prior and low posterior edge probabilities.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Prior-driven shrinkage (horseshoe) that pulls small/irrelevant edge weights toward zero; variational posterior places low probability on spurious structures.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Integration of interventional data into likelihood allows structures incompatible with interventions to receive low posterior mass; the Bayesian posterior can thus refute spurious edges inconsistent with interventional observations.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Reported as a scalable variational approach that can recover ground-truth DAGs when causal variables are observed; in the present paper BCD Nets is used as the foundational model but numeric performance details appear in the original BCD Nets paper rather than here.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>BCD Nets provides a Bayesian variational framework with hard DAG constraint and sparsity priors that can downweight spurious edges via horseshoe shrinkage and incorporate interventional data to disambiguate structures; the current paper uses BCD Nets as the backbone but extends it to the latent-decoder setting where additional challenges arise.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e727.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e727.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DiBS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Differentiable Bayesian Structure Learning (DiBS)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A differentiable Bayesian structure learning method that represents distributions over DAGs with soft DAG constraints and performs variational inference via gradient-based optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Dibs: Differentiable bayesian structure learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>DiBS</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>DiBS performs variational Bayesian inference over graph structures using continuous relaxations; unlike BCD Nets' hard DAG factorization, DiBS uses a soft DAG constraint and represents distributions over adjacency matrices, enabling gradient-based posterior approximation. It targets posterior distributions over DAGs using differentiable samplers and likelihoods.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Tabular datasets of observed causal variables (observational and interventional)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Operates on datasets where causal variables are observed; can incorporate interventional data and quantify posterior uncertainty over graphs; not an interactive experiment-selection framework per se.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Mentioned as an alternative Bayesian structure learning approach that uses a soft DAG constraint; DiBS is capable of posterior estimation over graphs but is not evaluated in the current paper's latent-decoder experiments.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e727.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e727.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Tigas et al. (2022)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Interventions, where and how? experimental design for causal models at scale</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An active experimental-design approach that uses mutual information objectives to choose which nodes to intervene on and with what values, aiming to efficiently recover graph structure.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Interventions, where and how? experimental design for causal models at scale</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Mutual-information-based active intervention selection (Tigas et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>This method formulates active experiment selection for causal discovery by optimizing a mutual information objective to choose both which variables to intervene on and the intervention values, thereby focusing experimental budget on the most informative interventions for structure learning.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Active intervention design for SCMs (general, not necessarily latent-projection)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>An active-learning framework that plans interventions to run in a laboratory or simulated SCM to maximize information gain about the causal graph; contrasts with the current paper's random intervention generation.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>By selecting maximally informative interventions, the approach implicitly helps reveal and disambiguate spurious correlations by targeting experiments that disambiguate competing graph hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Confounding or observational ambiguity that leads to spurious correlations; the method targets experiments to resolve ambiguous orientations.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Selection criterion (mutual information) identifies experiments expected to most reduce posterior uncertainty, implicitly detecting where spurious/ambiguous signals exist.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Interventions chosen via mutual information serve to falsify graph hypotheses inconsistent with interventional outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td>Mutual information maximization over candidate interventions (select nodes and values expected to maximize reduction in uncertainty over graph structure).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Cited as a related active experimental-design approach that could be complementary to the paper's line of work; unlike Decoder BCD, Tigas et al. explicitly design interventions to be maximally informative, which would better target spurious correlations than the random intervention protocol used in this paper.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Bcd nets: Scalable variational approaches for bayesian causal discovery <em>(Rating: 2)</em></li>
                <li>Dibs: Differentiable bayesian structure learning <em>(Rating: 2)</em></li>
                <li>Interventions, where and how? experimental design for causal models at scale <em>(Rating: 2)</em></li>
                <li>Learning neural causal models with active interventions <em>(Rating: 1)</em></li>
                <li>Bayesian structure learning with generative flow networks <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-727",
    "paper_id": "paper-250451049",
    "extraction_schema_id": "extraction-schema-20",
    "extracted_data": [
        {
            "name_short": "Decoder BCD",
            "name_full": "Decoder Bayesian Causal Discovery (Decoder BCD)",
            "brief_description": "A latent-variable decoder model introduced in this paper that extends BCD Nets to perform Bayesian structure learning in a low-dimensional linear Gaussian SCM inferred from high-dimensional observations; it jointly learns a decoder from latent causal variables to observed data while inferring a posterior over DAG structure and noise parameters.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "Decoder BCD",
            "method_description": "Decoder BCD is a fully differentiable latent-variable Bayesian causal discovery model that extends BCD Nets to the setting where true causal variables are not observed. It parameterizes the DAG via a factorization W = (P L P^T)^T (with permutation matrix P and strictly lower-triangular L) and performs variational inference over P, L and Σ using an ELBO objective; additionally it learns a decoder that maps sampled latent causal variable realizations back to high-dimensional observations X. Training losses used include reconstruction MSE(X, X_hat) and (in mildly supervised runs) a KL divergence between the inferred observational joint q(z) and the ground-truth observational joint p(z). The model inherits priors from BCD Nets (horseshoe prior on L for sparsity, Gumbel-Sinkhorn prior on P for permutations, Gaussian prior on Σ) and uses ancestral sampling in the latent SCM to generate latents that are decoded to observations during training. Interventional data (single- or multi-node, fixed or sampled values) and interventional targets-as-labels can be incorporated to improve identifiability and edge-orientation in the unsupervised setting.",
            "environment_name": "Synthetic high-dimensional linear-projection environment (latent linear Gaussian SCM projected to high-D)",
            "environment_description": "A synthetic, non-interactive simulation environment where a d-dimensional linear Gaussian additive-noise SCM (identifiable under equal noise variances) is sampled via ancestral sampling to produce latent data z; high-dimensional observed data X is generated by a linear projection X = z P (with D &gt;&gt; d). Interventional datasets are synthesized by zeroing columns in W for intervened nodes and sampling from the mutated SCM; interventions in the paper are chosen randomly (single or multi-node) and values are fixed or sampled from a uniform range. The environment allows passive observation and offline interventional datasets but does not perform active/closed-loop experiment selection in Decoder BCD itself.",
            "handles_distractors": true,
            "distractor_handling_technique": "Implicit sparsity and supervision: horseshoe sparsity prior on L (to shrink irrelevant edges), using KL alignment between inferred and true observational joint as a mild supervision signal, and incorporation of interventional targets-as-labels (single- or multi-node interventions with varied values) to disambiguate spurious correlations and orient edges in latent space.",
            "spurious_signal_types": "Irrelevant/weak edges (spurious correlations between latent variables induced by projection), measurement noise from projection, and identifiability issues due to observational equivalence (MEC ambiguity); interventions are used to address orientation confounding.",
            "detection_method": "No explicit detector for distractor variables; reliance on Bayesian sparsity prior (horseshoe) to shrink spurious edges and on mismatch between reconstructed X and expected latent joint (KL(true||learned)) as a supervision signal to reveal poor latent recovery.",
            "downweighting_method": "Bayesian shrinkage via the horseshoe prior on L to downweight/spike-to-zero spurious edge weights; variational posterior can place low mass on spurious structures.",
            "refutation_method": "Use of interventional data (single- and multi-node interventions, varied intervention values) to test and disambiguate edge orientation and refute edges that are not consistent with interventional distributions; KL divergence between posterior observational joint and GT joint is used as an objective to align/refute candidate latent structures in the mildly supervised setting.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Qualitative improvements reported: with mild supervision (KL(true||learned)) the expected Structural Hamming Distance (SHD) approaches 0 and MSE(L, L_gt) approaches 0 (complete graph recovery). Using interventional targets-as-labels and large amounts of interventional data (e.g., 300 obs + 3300 interventional points) improves SHD, AUROC, MSE and KL metrics; multi-node interventions with uniformly sampled values performed best in the experiments. Exact numeric metrics are not provided in-text.",
            "performance_without_robustness": "Without KL supervision and without (sufficient) interventional data, unsupervised Decoder BCD often fails: learning from observational data alone does not reliably orient edges (SHD remains high); learning a single edge from observational or mixed observational/interventional data with fixed intervention values was insufficient to orient that edge.",
            "has_ablation_study": true,
            "number_of_distractors": null,
            "key_findings": "1) Mild supervision via a KL loss over the observational joint enables full recovery (SHD→0) in the supervised case. 2) Unsupervised learning from observational data alone frequently fails to orient edges or recover L. 3) Incorporating interventional targets-as-labels substantially improves latent graph and parameter recovery; multi-node interventions with varied (uniformly sampled) intervention values outperform fixed-value interventions. 4) Horseshoe sparsity prior and interventional data together help downweight/refute spurious latent edges, but designing losses that guarantee latent-structure recovery from low reconstruction loss remains an open challenge.",
            "uuid": "e727.0"
        },
        {
            "name_short": "BCD Nets",
            "name_full": "Bayesian Causal Discovery Nets (BCD Nets)",
            "brief_description": "A variational Bayesian structure learning method that parameterizes DAGs with a permutation matrix and a strictly lower-triangular matrix to enforce acyclicity and obtains a posterior over graph structures and noise parameters via ELBO optimization.",
            "citation_title": "Bcd nets: Scalable variational approaches for bayesian causal discovery",
            "mention_or_use": "mention",
            "method_name": "BCD Nets",
            "method_description": "BCD Nets formulates Bayesian structure learning as variational inference over a parameterization W = (P L P^T)^T, where P is a permutation matrix and L is strictly lower-triangular, ensuring a hard DAG constraint. It factorizes the posterior q(P, L, Σ) and optimizes an ELBO with priors including a horseshoe prior on L for sparsity, a Gumbel-Sinkhorn (Gumbel Sinkhorn) prior on P for permutations, and Gaussian priors on noise covariances. The approach samples P, L, Σ from the variational posterior, computes likelihoods under the implied linear Gaussian SCM, and updates variational parameters via gradient-based optimization.",
            "environment_name": "Tabular observational/interventional datasets of observed causal variables",
            "environment_description": "Works on datasets where the causal variables are observed (i.e., not the high-dimensional projection case)—the methods handle observational and interventional samples and recover posterior distributions over DAGs; not inherently an interactive/virtual-lab environment.",
            "handles_distractors": true,
            "distractor_handling_technique": "Sparsity-inducing horseshoe prior on L (regularization) to favor sparse graphs and shrink spurious edges; Bayesian posterior quantification to reflect uncertainty over edges which can reduce reliance on spurious signals.",
            "spurious_signal_types": "Spurious/weak edges (irrelevant connections), sampling noise; observational indistinguishability (MEC) ameliorated by interventional data when available.",
            "detection_method": "No explicit distractor detector; spurious edges are de-emphasized by posterior shrinkage under the horseshoe prior and low posterior edge probabilities.",
            "downweighting_method": "Prior-driven shrinkage (horseshoe) that pulls small/irrelevant edge weights toward zero; variational posterior places low probability on spurious structures.",
            "refutation_method": "Integration of interventional data into likelihood allows structures incompatible with interventions to receive low posterior mass; the Bayesian posterior can thus refute spurious edges inconsistent with interventional observations.",
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": "Reported as a scalable variational approach that can recover ground-truth DAGs when causal variables are observed; in the present paper BCD Nets is used as the foundational model but numeric performance details appear in the original BCD Nets paper rather than here.",
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "BCD Nets provides a Bayesian variational framework with hard DAG constraint and sparsity priors that can downweight spurious edges via horseshoe shrinkage and incorporate interventional data to disambiguate structures; the current paper uses BCD Nets as the backbone but extends it to the latent-decoder setting where additional challenges arise.",
            "uuid": "e727.1"
        },
        {
            "name_short": "DiBS",
            "name_full": "Differentiable Bayesian Structure Learning (DiBS)",
            "brief_description": "A differentiable Bayesian structure learning method that represents distributions over DAGs with soft DAG constraints and performs variational inference via gradient-based optimization.",
            "citation_title": "Dibs: Differentiable bayesian structure learning",
            "mention_or_use": "mention",
            "method_name": "DiBS",
            "method_description": "DiBS performs variational Bayesian inference over graph structures using continuous relaxations; unlike BCD Nets' hard DAG factorization, DiBS uses a soft DAG constraint and represents distributions over adjacency matrices, enabling gradient-based posterior approximation. It targets posterior distributions over DAGs using differentiable samplers and likelihoods.",
            "environment_name": "Tabular datasets of observed causal variables (observational and interventional)",
            "environment_description": "Operates on datasets where causal variables are observed; can incorporate interventional data and quantify posterior uncertainty over graphs; not an interactive experiment-selection framework per se.",
            "handles_distractors": null,
            "distractor_handling_technique": null,
            "spurious_signal_types": null,
            "detection_method": null,
            "downweighting_method": null,
            "refutation_method": null,
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Mentioned as an alternative Bayesian structure learning approach that uses a soft DAG constraint; DiBS is capable of posterior estimation over graphs but is not evaluated in the current paper's latent-decoder experiments.",
            "uuid": "e727.2"
        },
        {
            "name_short": "Tigas et al. (2022)",
            "name_full": "Interventions, where and how? experimental design for causal models at scale",
            "brief_description": "An active experimental-design approach that uses mutual information objectives to choose which nodes to intervene on and with what values, aiming to efficiently recover graph structure.",
            "citation_title": "Interventions, where and how? experimental design for causal models at scale",
            "mention_or_use": "mention",
            "method_name": "Mutual-information-based active intervention selection (Tigas et al.)",
            "method_description": "This method formulates active experiment selection for causal discovery by optimizing a mutual information objective to choose both which variables to intervene on and the intervention values, thereby focusing experimental budget on the most informative interventions for structure learning.",
            "environment_name": "Active intervention design for SCMs (general, not necessarily latent-projection)",
            "environment_description": "An active-learning framework that plans interventions to run in a laboratory or simulated SCM to maximize information gain about the causal graph; contrasts with the current paper's random intervention generation.",
            "handles_distractors": null,
            "distractor_handling_technique": "By selecting maximally informative interventions, the approach implicitly helps reveal and disambiguate spurious correlations by targeting experiments that disambiguate competing graph hypotheses.",
            "spurious_signal_types": "Confounding or observational ambiguity that leads to spurious correlations; the method targets experiments to resolve ambiguous orientations.",
            "detection_method": "Selection criterion (mutual information) identifies experiments expected to most reduce posterior uncertainty, implicitly detecting where spurious/ambiguous signals exist.",
            "downweighting_method": null,
            "refutation_method": "Interventions chosen via mutual information serve to falsify graph hypotheses inconsistent with interventional outcomes.",
            "uses_active_learning": true,
            "inquiry_strategy": "Mutual information maximization over candidate interventions (select nodes and values expected to maximize reduction in uncertainty over graph structure).",
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Cited as a related active experimental-design approach that could be complementary to the paper's line of work; unlike Decoder BCD, Tigas et al. explicitly design interventions to be maximally informative, which would better target spurious correlations than the random intervention protocol used in this paper.",
            "uuid": "e727.3"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Bcd nets: Scalable variational approaches for bayesian causal discovery",
            "rating": 2,
            "sanitized_title": "bcd_nets_scalable_variational_approaches_for_bayesian_causal_discovery"
        },
        {
            "paper_title": "Dibs: Differentiable bayesian structure learning",
            "rating": 2,
            "sanitized_title": "dibs_differentiable_bayesian_structure_learning"
        },
        {
            "paper_title": "Interventions, where and how? experimental design for causal models at scale",
            "rating": 2,
            "sanitized_title": "interventions_where_and_how_experimental_design_for_causal_models_at_scale"
        },
        {
            "paper_title": "Learning neural causal models with active interventions",
            "rating": 1,
            "sanitized_title": "learning_neural_causal_models_with_active_interventions"
        },
        {
            "paper_title": "Bayesian structure learning with generative flow networks",
            "rating": 1,
            "sanitized_title": "bayesian_structure_learning_with_generative_flow_networks"
        }
    ],
    "cost": 0.0117045,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Latent Variable Models for Bayesian Causal Discovery</p>
<p>Jithendaraa Subramanian 
Yashas Annadani 
Ivaxi Sheth 
Stefan Bauer 
Derek Nowrouzezahrai 
Samira Ebrahimi Kahou 
Latent Variable Models for Bayesian Causal Discovery</p>
<p>Learning predictors that do not rely on spurious correlations involves building causal representations. However, learning such representations is very challenging. We, therefore, formulate the problem of learning causal representations from high dimensional data and study causal recovery with synthetic data. This work introduces a latent variable decoder model, Decoder BCD, for Bayesian causal discovery and performs experiments in mildly supervised and unsupervised settings. We present a series of synthetic experiments to characterize important factors for causal discovery and show that using known intervention targets as labels helps in unsupervised Bayesian inference over structure and parameters of linear Gaussian additive noise latent structural causal models.</p>
<p>Introduction</p>
<p>Exploiting structure in the data to infer latent variables and capture causal mechanisms is crucial for causal representation learning . Such a representation would allow for counterfactual reasoning in a manner similar to that of humans, thereby moving away from models that rely on exploiting spurious correlations for prediction.</p>
<p>Causal mechanisms are usually modelled as Bayesian Networks or Directed Acyclic Graphs (DAG) and given information about the causal variables, one can learn the DAG with structure learning algorithms. Recently, there has been a flurry of works advancing structure learning algorithms (Shimizu et al., 2006;Zheng et al., 2018;He et al., 2019;Pamfil et al., 2020;Lorch et al., 2021;Annadani et al., 2021;Ng et al., 2020;Cundy et al., 2021;Deleu et  2022) that learn the structure of a DAG given data samples (of causal variables). Most of these works cast the discrete optimization of learning a DAG into a continuous one that is optimized through gradient descent, thereby sidestepping the computational intractability arising from the super-exponential nature of DAG search in the discrete case. However, all approaches learn a causal DAG on the premise that one has full access to the true causal variables which might not be realistic. A more realistic assumption would be that we have partial or no access to true causal variables and that one has to infer the structure along with the causal variables.</p>
<p>Here, we introduce a fully differentiable latent variable model, Decoder BCD, to study the problem of Bayesian structure learning in linear Gaussian additive noise models, from high dimensional data. We perform synthetic experiments to analyze why unsupervised causal discovery in latent variable models is difficult. Section 2 explains preliminaries for the setup and section 3 gives the problem setup. In section 4, we introduce Decoder BCD, a decoder model for Bayesian Causal Discovery in the latent space before discussing experiments and our findings in section 5. We discuss related work in section 6 before concluding in section 7.</p>
<p>Preliminaries</p>
<p>Structural Causal Models (SCM): We operate in the framework of SCM (Pearl, 2009) where node Z i represents a random causal variable with an independent noise variable i ∼ N (0, σ 2 i ), and parents P a G (Z i ) corresponding to a DAG G. We focus primarily on the family of linear Gaussian additive noise models. However, for a DAG to be identifiable from data, one either has to observe a non-Gaussian setting, or, in the case of a Gaussian one, have an equal noise variance assumption (all σ i = σ) (Peters &amp; Bühlmann, 2013). Since we are in the Gaussian setting, we assume the latter. Thus, we have d causal variables Z = [Z 1 , ...Z d ], and a joint distribution entailed by the DAG G such that,<br />
P (Z 1 , ...Z d ) = d i=1 P (Z i |P a G (Z i ))(1z i = f (P a G (z i )) + i , where f (.) is a linear function.
In our case, f is the weighted sum of values taken on by random variables P a G (Z i ), the weights given by the weighted adjacency matrix W , such that z = W T z + .</p>
<p>Bayesian Causal Discovery Nets (BCD Nets): We build Decoder BCD, our latent variable decoder model, upon BCD Nets (Cundy et al., 2021). Given samples of true causal variables, BCD Nets is a Bayesian structure learning method that obtains a posterior distribution over causal structures that best explains the data. Similar to other structure learning works (Lorch et al., 2021), BCD Nets introduces the problem of structure learning as a continuous constrained optimization problem. However, the DAG is parameterized such that one always ends up with a DAG and is therefore a hard constraint (in contrast to DiBS which has a soft DAG constraint). This is achieved by formulating the weighted adjacency matrix as W = (P LP T ) T where P is a permutation matrix and L is strictly lower triangular. When P is identity, this is equivalent to having a DAG of fixed ordering with each node j having its possible parents only in the node range [j + 1, d]. P allows one to transition between node orderings by permuting the rows and columns of L. Apart from estimating W (via P and L), BCD Nets also infers Σ, the noise covariance, for the noise variables on each node in the DAG.</p>
<p>Thus, overall, BCD Nets formulates the Bayesian Structure Learning problem as inference of P, L, and Σ with a unique factorization of the posterior as q φ (P, L, Σ) = q φ (P |L, Σ) · q φ (L, Σ). The model is trained on an ELBO loss (eq. 2) with a horseshoe prior on L, Gumbel Sinkhorn prior (Jang et al., 2016) on P , and a Gaussian prior on Σ.
E (L,Σ)∼q φ E P ∼q φ (.|L,Σ) log p(X|P, L, Σ) − log q φ (P |L, Σ) p(P |L, Σ) − log q φ (L, Σ) p(L, Σ)(2)
For finer details, we refer the reader to the original work (Cundy et al., 2021). Our work focuses more on extending BCD Nets to the high dimensional setting and studying unsupervised graph recovery in the latent space.</p>
<p>The Problem Setup</p>
<p>This work revolves around the Bayesian inference of causal variables Z and the causal structure G. Given n samples of high dimensional data X ∈ R n×D , we wish to recover a distribution over graph structures G -the (weighted) adjacency matrix -and the causal variables Z ∈ R n×d . Our setup revolves mostly around the recovery in linear isotropic Gaussian additive noise SCM, which is identifiable. Models like DiBS (Lorch et al., 2021), VCN , and BCD Nets (Cundy et al., 2021) can recover the Ground Truth (GT) DAG given only observational and interventional data. Given observational data, recovery is possible up to a Markov Equivalence Class (MEC).</p>
<p>We first generate a random ER (Erdos et al., 1960) DAGwith weighted adjacency matrix W GT with sparsity pattern G GT , the adjacency matrix -and consider this the ground truth and set the noise covariance to be Σ GT = σ 2 GT I, since we have an isotropic Gaussian assumption. In our experiments, σ GT is usually set to 0.1.</p>
<p>Data generation of the true causal variables:</p>
<p>The data generation is done by an ancestral sampling process, compactly given by z = W T z + . One could also get interventional data from this setup: (i) Choose the node set N being intervened upon, (ii) for every node in N , zero out the particular column in W to get the mutated DAGW and (iii) perform ancestral sampling using z =W T z + . This process is repeated multiple times to get n samples of z, and we will then organize these samples into a (n, d) matrix and term it z GT , or simply, z 1 .</p>
<p>Generating the true high dimensional data: We assume the observed low level data is a linear projection of the causal variables given by X GT = z GT P , where P ∈ R d×D is a projection matrix and we have D &gt;&gt; d in the real world. For most of the upcoming experiments, we will study recovery in the (simpler) limiting case where d equal to D. This work studies recovery in latent space in a case where direct access to true causal variables is not given, in contrast to existing structure learning works.</p>
<p>Decoder BCD</p>
<p>BCD Nets performs Bayesian inference over P, L, Σ given samples of true causal variables to best explain the data by training an ELBO loss (see eq. 2). Decoder BCD tries to infer the decoder parameters in addition to inferring P, L, Σ. It is trained over X GT instead of over z GT as in BCD Nets. Thus, we relax the assumption that we have access to samples of true causal variables. We can only access the high dimensional data that has to be explained by (Z, G) and we have to fit a structure,Ĝ, and estimate edge weights,Ŵ , to fit our best guess of the causal variables,ẑ. Algorithm 1 summarizes the inference mechanism of Decoder BCD. A diagrammatic overview is given in Figure 1.</p>
<p>Experiments and Findings</p>
<p>For all our experiments, for simplicity, we will stick to just learning the decoder and inferring the edge matrix L since this makes the optimization simpler for our studies. Such an assumption of fixing the permutation P to the GT, and thereby, the node orderings, is not unreasonable (He et al., 2019). Here, the focus is solely on inferring the edges L in latent space whilst learning a decoder. In all experiments, we train the model for 5000 steps across 20 random seeds, with a learning rate of 0.002 on ER-2 DAGs. We consider the case of the higher dimensional data being D = 10 dimensions that is generated by data from a d = 6 node Algorithm 1 Decoder BCD for causal discovery from high dimensional data 1. Initialize random distributions for P , L, Σ 2. For train steps:
(i) SampleP ,L,Σ ∼ q φ (P, L, Σ) (ii)Ŵ = (PLP T ) T (iii) Perform ancestral sampling:ẑ =Ŵ Tẑ + ; ∼ N (0,σ 2 ) andΣ =σ 2 I (iv) Decodeẑ to obtainX (v)
Update parameters of the distribution P (P, L, Σ) with loss as M SE(X,X) (vi) For supervised experiments, add an additional KL loss between true and posterior observational joint:
KL(q(z 1 , ...z d )||p(z 1 , ...z d ))
underlying SCM.</p>
<p>Metrics:</p>
<p>In our experiments, we refer to the expected Structural Hamming Distance across 64 samples of the inferred DAG as SHD, M SE(L,L) is the MSE between predicted L and L GT , AUROC (a value of 0.5 denotes a random baseline with null edges), and KL(true || learned) refers to the KL divergence between the posterior observational joint and the GT observational joint distributions.</p>
<p>Learning edge matrix L with supervision</p>
<p>For the supervised experiments, we add an additional KL loss on the inferred posterior observational joint q(z 1 , ...z d ) and the prior observational GT joint distribu- Finding 1: From figure 2, we can see the expected SHD approaching 0 as KL(true || learned) and M SE(L,L) approach 0. Using a KL over the observational joint distribu-tion results in complete graph recovery in the supervised case. This is expected since we provide a mild signal for the model to uncover the true causal variables. Instead of providing prior over the samples of true causal variables, we use the true observational joint distribution as a signal.
tion, p(z 1 , ...z d ) ∼ N (µ z , Σ z ), where Σ z is calculated with W GT instead</p>
<p>Unsupervised learning of a single edge weight</p>
<p>For this setting, instead of inferring the whole lower triangular edge matrix L, we infer only the last edge at position (d, d − 1). The other elements of the matrix are fixed to the GT and we observe graph recovery in this case. This subsection is split into two parts to study recovery with (i) observational data and (ii) a mix of observational and interventional data, to analyze the effects of interventional data. We use 1800 observational data points for case (i) and 1800 data points (50-50 split of observational and interventional data) for case (ii). The interventional data generation process for single node and multi node interventions is detailed in A.2. The interventional values are fixed to 100.</p>
<p>Finding 2: Figures 3 and 4 reveal that using observational and/or interventional data with single node or multi node interventions with fixed intervention values is not sufficient to learn to orient a single edge in the unsupervised case.</p>
<p>Unsupervised learning of edge weight L</p>
<p>In this experiment and in the next, we explore the problem of learning the entire lower triangular edge matrix L in an unsupervised setting. First, we consider the learning problem with various amounts of observational data to analyze its effect on edge recovery in the latent space, which is shown in figure 5.  We now consider learning L using interventional targets as labels to learn the structure in the latent space with a mix of 300 observational data points and 3300 interventional data points. For this experiment, we retrain Decoder BCD multiple times from scratch -each time with the same 300 observational data points but with more interventional data than the previous run. This helps us understand the usefulness of interventional data for graph recovery. This result is illustrated in figure 6. For the interventional data points, we chose to use a fixed intervention value of 100.0. The reason for this particular value was that we had to choose a value that is far from 0 -the mean of all the nodes in the causal graph. Note that in a linear Gaussian additive noise SCM, if one has 0 mean of the error variables , then all nodes in the graph have 0 mean. Finally, other than learning from randomly (single or multi) intervened nodes, we also performed an experiment to observe the effect of randomly chosen interventional values,  Finding 4: Figures 6 and 7 show that both single node and multi node interventions help in recovering the edge weights, measured across all the 4 metrics. However, multi node interventions with uniformly sampled intervention values results in the better inference of the structure and parameters of the latent SCM.</p>
<p>Related Works</p>
<p>To address the challenges of causal discovery, a variety of methods have been proposed. Some of these methods are based on structure learning using observational data and some take in to account interventional data (Lorch et al., 2021;Scherrer et al., 2021;Ke et al., 2019;Brouillard et al., 2020).</p>
<p>There has been an increasing focus on Bayesian structure learning (Yu et al., 2019;Annadani et al., 2021;Lorch et al., 2021;Cundy et al., 2021;Deleu et al., 2022) to quantify epistemic uncertainty that is crucial for reinforcement learning and active learning settings. Charpentier et al. (2022) follow almost exactly the same approach as Cundy et al. (2021) except that they operate on nonlinear Gaussian SCM instead of a linear one. There also exist many maximum likelihood based methods, one such example is (He et al., 2019). It is one of the few works that learn a structure in the latent space but they do not operate in a causality-based or SCM framework.</p>
<p>Markov Chain Monte Carlo (MCMC) is a popular technique for sampling from complex high dimensional probability distributions, such as the posterior distribution of DAGs. (Madigan et al., 1995) uses Metropolis-Hastings (Metropolis et al., 1953) to predict the posterior distribution through Markov space to perform single edge addition or deletion. (Eaton &amp; Murphy, 2007) propose a hybrid MCMC algorithm that uses an exact score based algorithm. (Kuipers et al., 2022) and (Viinikka et al., 2020) use more efficient MCMC samplers. (Deleu et al., 2022) uses a novel class of probabilistic models, GFlowNets , which model distribution over discrete entities like DAGs to approximate the posterior in place of MCMC algorithms. Section A.3 discusses related work in more detail. Finally, our work involved randomly selecting nodes to intervene on while also randomly selecting the values for the interventions. (Tigas et al., 2022) uses a mutual information objective to learn where (which nodes) and how (with what values) to perform interventions in an active learning scenario to recover the edges more efficiently. However, unlike ours, their SCM is not in the latent space.</p>
<p>Conclusion</p>
<p>In this work, we introduced our latent variable model, Decoder BCD, and studied the causal representation learning problem. We explored the cases where edge recovery failslearning to orient a single edge or learning with only observational data. To address this, we propose using interventional targets as labels to allow recovery of edges and edge weights in an SCM. Our experiments show that this is a promising direction for the unsupervised Bayesian causal discovery in latent space. However, our hypothesis of the observed data having a latent linear SCM and linear projection of the latent causal variables to higher dimension is a limitation (refer A.5) when it comes to mechanisms in the real world. Future work should explore nonlinear projections of the causal variables as well as nonlinear and non-Gaussian SCMs. Finally, we discuss some key challenges for future A. Appendix A.1. KL Loss for the mildly supervised experiments GivenŴ = (PLP T ) T , from inferredL, one can obtain the mean and covariance of the observational joint distribution q(z 1 , ...z d ) as follows:
z =Ŵ T z + ; ∼ N (0, σ) (3) z = (I −Ŵ ) −T (4) q(z 1 , ...z d ) ∼ N (μ z ,Σ z ) (5) µ z = 0 andΣ z = (I −Ŵ ) −T Σ(I −Ŵ ) −1(6)
To estimate the prior GT observational joint distribution, one would use W in place ofŴ in equation 6.</p>
<p>A.2. Generating interventional data for experiments that use single node and multi node interventions</p>
<p>Suppose we have to generate i interventional data points. We split the data generation process into s = 20 sets, each set generating i/s interventional data points. For single node interventions, we randomly choose a node and sample i/s data points. The process is repeated s times randomly to generate the i data points. For multi node interventions, we randomly choose a number in [2, d] to decide on the number of nodes to intervene on (call this x). We then choose x nodes without replacement and perform the interventions on these nodes and sample i/s data points. The process is repeated s times randomly to generate the i data points.</p>
<p>A.3. More Related Work</p>
<p>Since discrete optimization is hard and often involves enumeration of possible structures, the super-exponential nature of structure learning has resulted in the community resorting to relaxing the discrete optimization problem into a continuous one (Lorch et al., 2021;Cundy et al., 2021;Annadani et al., 2021;Scherrer et al., 2021;Ke et al., 2019;Zheng et al., 2018) and learning the parameters using gradient descent. (Loh &amp; Bühlmann, 2014) propose a scalable, scoring-based DAG learning approach to recover high dimensional, sparse causal graphs in a non-Gaussian setting where only some but not all exogenous noise variables are expected to be non-Gaussian. (Ghoshal &amp; Honorio, 2017) learns a linear structural equation model in polynomial time. (Ke et al., 2019) learns the causal structure from unknown interventions but operates on the Bernoulli distribution while  is in an active learning framework and the system determines the intervention that will be most useful in gaining knowledge about the graph structure. (Yang et al., 2022) proposes a variational autoencoder parameterised by exogenous variables to learn causal semantics of the data. Another family of works introduce assumptions to functional and parametric form of the data-generation structure. They exploit symmetries to learn the causal structure (Peters et al., 2017;Mooij et al., 2016).</p>
<p>Approaches to the problem are mostly employ score-based or constraint-based optimization. Most modern methods use some sort of a scoring function to rank estimated structure and use it to rank structures and optimizing for the score is expected to return the ground truth DAG. Popular scoring functions include Bayesian Information Criterion (BIC) and Bayesian Gaussian Equivalent marginal likelihood score (Geiger &amp; Heckerman, 1994). These methods typically use a regularization over the structure to induce sparsity and/or acyclicity. Some methods impose hard constraints as well that ensure the search is done only over the space of DAGs. (Shah &amp; Peters, 2020) is a constraint based approach that tests for conditional independence.</p>
<p>A.4. Key challenges for future study</p>
<p>One of the most important scientific questions of causal representation learning is regarding the relationship between high dimensional, observed variables and the low dimensional, causal variables: In this work, we perform synthetic data generation of z and project it to higher dimensions by using a random projection matrix P . We begin on the premise that real-world, high dimensional data can be explained by a few causal variables and the inferring these variables and their structure is the problem of causal inference that the brain solves for performing intelligent tasks. Thus, there must exist an operation that maps the low dimensional causal variables to the high dimensional, observed variables (eg. images, videos). For our problem setting, we assume this is true and try to generate high dimensional samples that are "causally consistent" by performing a linear projection X = zP . However, we do not know how this process of projection to higher dimensions might happen in reality.</p>
<p>What's the right loss function for unsupervised causal discovery? In all experiments, we found that the MSE over high dimensional data, X, goes down but this does not necessarily mean that graph recovery in the latent space gets better. Therefore, we need to look for alternative losses with a property such that reduction in loss over X guarantees a better recovery in the latent space (i.e., better graph structure recovery or better estimates of edge weight matrix L). Ideally, such a loss should result in a reduction in the KL divergence between the inferred posterior observational joint distribution and the GT observational joint distribution. We propose that this a better metric to measure since in the supervised experiments, getting a low enough value of this metric results in the SHD dropping steeply to 0.</p>
<p>A.5. Limitations</p>
<p>A limitation of this work is that we do not know if it is practical to assume a linear projection -it is just a formulation that we explore. Additionally, if it is a linear operation, are there any properties that the projection matrix P must hold to maintain this "causal consistency" in higher dimensions? If P needs to hold some properties for causal inference to be performed from high dimensions, what exactly are these properties? It is easy to see that a random projection matrix (which transforms a d-dimensional vector to D-dimensional vector) can be random enough to completely destroy the encoded information due to the causal generation process that occurred in the lower dimensions, and thus the high dimensional data could no longer be "causally consistent" for us to perform inference. And finally, one needs to focus on the question of whether the projection operation could be nonlinear.</p>
<p>Figure 1 .
1An illustration of the latent variable (decoder) model for Bayesian causal discovery and the exact values of the d random variables are given by</p>
<p>Figure 2 .
2of withŴ . The estimation of the prior and posterior observational joint distribution is detailed in A.Supervised learning of L on 600 observational data points with d = 6, D = 10</p>
<p>Figure 3 .
3Unsupervised learning of a single edge weight with 1800 observational data points</p>
<p>Figure 5
5shows that all metrics diverge with training but there is no trend with respect to the amount of observational</p>
<p>Figure 4 .Figure 5 .
45Unsupervised Unsupervised learning of the edge weight matrix with various amounts of observational data data that the model is given.</p>
<p>Figure 6 .
6Unsupervised learning of edge weights with random single node and multi node interventions</p>
<p>Figure 7 .
7Unsupervised learning of edge weights with uniform single node and multi node interventions rather than a fixed interventional value. Thus, instead of an intervention value of 100, we randomly sampled interventional values in Uniform(−10.0, 10.0) for each data point and repeated our previous experiment for the same amount of observational (300) and interventional (3300) data points. We summarize our findings for this experiment in figure 7.</p>
<p>al., * Work done while visiting Mila 1 Mila -Québec AI Institute 2 McGill University, Montréal 3 KTH, Stockholm 4É TS Montréal 5 CIFAR AI Chair. Correspondence to: Jithendaraa Subramanian <a href="&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#106;&#105;&#116;&#104;&#101;&#110;&#46;&#115;&#117;&#98;&#114;&#97;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;">&#106;&#105;&#116;&#104;&#101;&#110;&#46;&#115;&#117;&#98;&#114;&#97;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;</a>. Published at the ICML 2022 Workshop on Spurious Correlations, Invariance, and Stability. Baltimore, Maryland, USA. Copyright 2022 by the author(s).
These variables will also be referred to, at times, as samples of true causal variables
AcknowledgementsThe authors are grateful to Nan Rosemary Ke, Anirudh Goyal, Tristan Deleu and Sébastien Lachapelle for fruitful discussions and feedback. The authors are also thankful to Compute Canada and CIFAR for the compute and funding that made this work possible.
Variational causal networks: Approximate bayesian inference over causal structures. Y Annadani, J Rothfuss, A Lacoste, N Scherrer, A Goyal, Y Bengio, S Bauer, Annadani, Y., Rothfuss, J., Lacoste, A., Scherrer, N., Goyal, A., Bengio, Y., and Bauer, S. Variational causal net- works: Approximate bayesian inference over causal structures, 2021. URL https://arxiv.org/abs/ 2106.07635.</p>
<p>Flow network based generative models for non-iterative diverse candidate generation. E Bengio, M Jain, M Korablyov, D Precup, Y Bengio, Bengio, E., Jain, M., Korablyov, M., Precup, D., and Bengio, Y. Flow network based generative models for non-iterative diverse candidate generation, 2021. URL https://arxiv.org/abs/2106.04399.</p>
<p>Differentiable causal discovery from interventional data. P Brouillard, S Lachapelle, A Lacoste, S Lacoste-Julien, A Drouin, Brouillard, P., Lachapelle, S., Lacoste, A., Lacoste-Julien, S., and Drouin, A. Differentiable causal discovery from interventional data, 2020. URL https://arxiv. org/abs/2007.01754.</p>
<p>B Charpentier, S Kibler, S Günnemann, Differentiable dag sampling. Charpentier, B., Kibler, S., and Günnemann, S. Differen- tiable dag sampling, 2022.</p>
<p>Bcd nets: Scalable variational approaches for bayesian causal discovery. C Cundy, A Grover, S Ermon, Cundy, C., Grover, A., and Ermon, S. Bcd nets: Scal- able variational approaches for bayesian causal discov- ery, 2021. URL https://arxiv.org/abs/2112. 02761.</p>
<p>Bayesian structure learning with generative flow networks. T Deleu, A Góis, C Emezue, M Rankawat, S Lacoste-Julien, S Bauer, Y Bengio, Deleu, T., Góis, A., Emezue, C., Rankawat, M., Lacoste- Julien, S., Bauer, S., and Bengio, Y. Bayesian struc- ture learning with generative flow networks, 2022. URL https://arxiv.org/abs/2202.13903.</p>
<p>Exact bayesian structure learning from uncertain interventions. D Eaton, K Murphy, Proceedings of the Eleventh International Conference on Artificial Intelligence and Statistics. Meila, M. and Shen, X.the Eleventh International Conference on Artificial Intelligence and StatisticsSan Juan, Puerto Rico2of Proceedings of Machine Learning ResearchEaton, D. and Murphy, K. Exact bayesian structure learn- ing from uncertain interventions. In Meila, M. and Shen, X. (eds.), Proceedings of the Eleventh Interna- tional Conference on Artificial Intelligence and Statis- tics, volume 2 of Proceedings of Machine Learning Re- search, pp. 107-114, San Juan, Puerto Rico, 21-24 Mar 2007. PMLR. URL https://proceedings.mlr. press/v2/eaton07a.html.</p>
<p>On the evolution of random graphs. P Erdos, A Rényi, Publ. Math. Inst. Hung. Acad. Sci. 51Erdos, P., Rényi, A., et al. On the evolution of random graphs. Publ. Math. Inst. Hung. Acad. Sci, 5(1):17-60, 1960.</p>
<p>Learning gaussian networks. D Geiger, D Heckerman, Uncertainty Proceedings. ElsevierGeiger, D. and Heckerman, D. Learning gaussian networks. In Uncertainty Proceedings 1994, pp. 235-243. Elsevier, 1994.</p>
<p>Learning linear structural equation models in polynomial time and sample complexity. A Ghoshal, J Honorio, 10.48550/ARXIV.1707.04673Ghoshal, A. and Honorio, J. Learning linear structural equation models in polynomial time and sample com- plexity. 2017. doi: 10.48550/ARXIV.1707.04673. URL https://arxiv.org/abs/1707.04673.</p>
<p>Variational autoencoders with jointly optimized latent dependency structure. J He, Y Gong, J Marino, G Mori, A Lehrmann, International Conference on Learning Representations. He, J., Gong, Y., Marino, J., Mori, G., and Lehrmann, A. Variational autoencoders with jointly optimized la- tent dependency structure. In International Confer- ence on Learning Representations, 2019. URL https: //openreview.net/forum?id=SJgsCjCqt7.</p>
<p>Categorical reparameterization with gumbel-softmax. E Jang, S Gu, B Poole, Jang, E., Gu, S., and Poole, B. Categorical reparame- terization with gumbel-softmax, 2016. URL https: //arxiv.org/abs/1611.01144.</p>
<p>Learning neural causal models from unknown interventions. N R Ke, O Bilaniuk, A Goyal, S Bauer, H Larochelle, B Schölkopf, M C Mozer, C Pal, Y Bengio, Ke, N. R., Bilaniuk, O., Goyal, A., Bauer, S., Larochelle, H., Schölkopf, B., Mozer, M. C., Pal, C., and Bengio, Y. Learning neural causal models from unknown inter- ventions, 2019. URL https://arxiv.org/abs/ 1910.01075.</p>
<p>Efficient sampling and structure learning of bayesian networks. J Kuipers, P Suter, G Moffa, Journal of Computational and Graphical Statistics. Kuipers, J., Suter, P., and Moffa, G. Efficient sampling and structure learning of bayesian networks. Journal of Computational and Graphical Statistics, pp. 1-12, 2022.</p>
<p>High-dimensional learning of linear causal networks via inverse covariance estimation. P.-L Loh, P Bühlmann, The Journal of Machine Learning Research. 151Loh, P.-L. and Bühlmann, P. High-dimensional learning of linear causal networks via inverse covariance estimation. The Journal of Machine Learning Research, 15(1):3065- 3105, 2014.</p>
<p>Differentiable bayesian structure learning. L Lorch, J Rothfuss, B Schölkopf, A Krause, M Dibs ; Ranzato, A Beygelzimer, Y Dauphin, P Liang, Vaughan , Advances in Neural Information Processing Systems. J. W.Curran Associates, Inc34Lorch, L., Rothfuss, J., Schölkopf, B., and Krause, A. Dibs: Differentiable bayesian structure learning. In Ranzato, M., Beygelzimer, A., Dauphin, Y., Liang, P., and Vaughan, J. W. (eds.), Advances in Neural Information Processing Systems, volume 34, pp. 24111-24123. Curran Asso- ciates, Inc., 2021. URL https://proceedings. neurips.cc/paper/2021/file/ ca6ab34959489659f8c3776aaf1f8efd-Paper. pdf.</p>
<p>Bayesian graphical models for discrete data. International Statistical Review/Revue Internationale de Statistique. D Madigan, J York, D Allard, Madigan, D., York, J., and Allard, D. Bayesian graphical models for discrete data. International Statistical Re- view/Revue Internationale de Statistique, pp. 215-232, 1995.</p>
<p>Equation of state calculations by fast computing machines. N Metropolis, A W Rosenbluth, M N Rosenbluth, A H Teller, E Teller, 10.1063/1.1699114The Journal of Chemical Physics. 216Metropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., and Teller, E. Equation of state cal- culations by fast computing machines. The Journal of Chemical Physics, 21(6):1087-1092, 1953. doi: 10.1063/1.1699114. URL http://link.aip.org/ link/?JCP/21/1087/1.</p>
<p>Distinguishing cause from effect using observational data: methods and benchmarks. J M Mooij, J Peters, D Janzing, J Zscheischler, B Schölkopf, The Journal of Machine Learning Research. 171Mooij, J. M., Peters, J., Janzing, D., Zscheischler, J., and Schölkopf, B. Distinguishing cause from effect using ob- servational data: methods and benchmarks. The Journal of Machine Learning Research, 17(1):1103-1204, 2016.</p>
<p>On the role of sparsity and dag constraints for learning linear dags. I Ng, A Ghassami, K Zhang, H Larochelle, M Ranzato, R Hadsell, M Balcan, Lin , Advances in Neural Information Processing Systems. H.Curran Associates, Inc33Ng, I., Ghassami, A., and Zhang, K. On the role of sparsity and dag constraints for learning linear dags. In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H. (eds.), Advances in Neural Information Processing Systems, volume 33, pp. 17943-17954. Curran Asso- ciates, Inc., 2020. URL https://proceedings. neurips.cc/paper/2020/file/ d04d42cdf14579cd294e5079e0745411-Paper. pdf.</p>
<p>Dynotears: Structure learning from time-series data. R Pamfil, N Sriwattanaworachai, S Desai, P Pilgerstorfer, P Beaumont, K Georgatzis, Aragam , B , Pamfil, R., Sriwattanaworachai, N., Desai, S., Pilgerstor- fer, P., Beaumont, P., Georgatzis, K., and Aragam, B. Dynotears: Structure learning from time-series data, 2020. URL https://arxiv.org/abs/2002.00498.</p>
<p>. J Pearl, Causality, Cambridge university pressPearl, J. Causality. Cambridge university press, 2009.</p>
<p>Identifiability of gaussian structural equation models with equal error variances. J Peters, P Bühlmann, 10.1093/biomet/ast043Biometrika. 1011Peters, J. and Bühlmann, P. Identifiability of gaus- sian structural equation models with equal error vari- ances. Biometrika, 101(1):219-228, nov 2013. doi: 10.1093/biomet/ast043. URL https://doi.org/ 10.1093%2Fbiomet%2Fast043.</p>
<p>Elements of causal inference: foundations and learning algorithms. J Peters, D Janzing, B Schölkopf, The MIT PressPeters, J., Janzing, D., and Schölkopf, B. Elements of causal inference: foundations and learning algorithms. The MIT Press, 2017.</p>
<p>Learning neural causal models with active interventions. N Scherrer, O Bilaniuk, Y Annadani, A Goyal, P Schwab, B Schölkopf, M C Mozer, Y Bengio, S Bauer, N R Ke, Scherrer, N., Bilaniuk, O., Annadani, Y., Goyal, A., Schwab, P., Schölkopf, B., Mozer, M. C., Bengio, Y., Bauer, S., and Ke, N. R. Learning neural causal models with ac- tive interventions, 2021. URL https://arxiv.org/ abs/2109.02429.</p>
<p>Towards causal representation learning. B Schölkopf, F Locatello, S Bauer, N R Ke, N Kalchbrenner, A Goyal, Y Bengio, Schölkopf, B., Locatello, F., Bauer, S., Ke, N. R., Kalch- brenner, N., Goyal, A., and Bengio, Y. Towards causal representation learning, 2021. URL https://arxiv. org/abs/2102.11107.</p>
<p>The hardness of conditional independence testing and the generalised covariance measure. R D Shah, J Peters, 10.1214/19-aos1857The Annals of Statistics. 483Shah, R. D. and Peters, J. The hardness of conditional independence testing and the generalised covariance mea- sure. The Annals of Statistics, 48(3), jun 2020. doi: 10.1214/19-aos1857. URL https://doi.org/10. 1214%2F19-aos1857.</p>
<p>A linear non-gaussian acyclic model for causal discovery. S Shimizu, P O Hoyer, A Hyvärinen, A Kerminen, Jordan , M , Journal of Machine Learning Research. 710Shimizu, S., Hoyer, P. O., Hyvärinen, A., Kerminen, A., and Jordan, M. A linear non-gaussian acyclic model for causal discovery. Journal of Machine Learning Research, 7(10), 2006.</p>
<p>Interventions, where and how? experimental design for causal models at scale. P Tigas, Y Annadani, A Jesson, B Schölkopf, Y Gal, S Bauer, Tigas, P., Annadani, Y., Jesson, A., Schölkopf, B., Gal, Y., and Bauer, S. Interventions, where and how? experi- mental design for causal models at scale, 2022. URL https://arxiv.org/abs/2203.02016.</p>
<p>Towards scalable bayesian learning of causal dags. J Viinikka, A Hyttinen, J Pensar, M Koivisto, H Larochelle, M Ranzato, R Hadsell, M Balcan, Lin , Advances in Neural Information Processing Systems. H.Curran Associates, Inc33Viinikka, J., Hyttinen, A., Pensar, J., and Koivisto, M. Towards scalable bayesian learning of causal dags. In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H. (eds.), Advances in Neural Information Pro- cessing Systems, volume 33, pp. 6584-6594. Curran As- sociates, Inc., 2020. URL https://proceedings. neurips.cc/paper/2020/file/ 48f7d3043bc03e6c48a6f0ebc0f258a8-Paper. pdf.</p>
<p>M Yang, F Liu, Z Chen, X Shen, J Hao, J Wang, Causalvae, Structured causal disentanglement in variational autoencoder. Yang, M., Liu, F., Chen, Z., Shen, X., Hao, J., and Wang, J. Causalvae: Structured causal disentanglement in varia- tional autoencoder, 2022.</p>
<p>Y Yu, J Chen, T Gao, Yu , M Dag-Gnn, Dag structure learning with graph neural networks. Yu, Y., Chen, J., Gao, T., and Yu, M. Dag-gnn: Dag structure learning with graph neural networks, 2019. URL https: //arxiv.org/abs/1904.10098.</p>
<p>Dags with no tears: Continuous optimization for structure learning. X Zheng, B Aragam, P K Ravikumar, E P Xing, S Bengio, H Wallach, H Larochelle, K Grauman, N Cesa-Bianchi, Garnett , Advances in Neural Information Processing Systems. R.Curran Associates, Inc31Zheng, X., Aragam, B., Ravikumar, P. K., and Xing, E. P. Dags with no tears: Continuous optimization for structure learning. In Bengio, S., Wallach, H., Larochelle, H., Grauman, K., Cesa-Bianchi, N., and Garnett, R. (eds.), Advances in Neural Information Pro- cessing Systems, volume 31. Curran Associates, Inc., 2018. URL https://proceedings.</p>            </div>
        </div>

    </div>
</body>
</html>