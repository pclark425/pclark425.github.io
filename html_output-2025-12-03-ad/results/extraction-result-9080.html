<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9080 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9080</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9080</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-159.html">extraction-schema-159</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <p><strong>Paper ID:</strong> paper-016c8d91f8a102111dc5eb76ab4ce433b9e2ec53</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/016c8d91f8a102111dc5eb76ab4ce433b9e2ec53" target="_blank">How Well Do Large Language Models Perform on Faux Pas Tests?</a></p>
                <p><strong>Paper Venue:</strong> Annual Meeting of the Association for Computational Linguistics</p>
                <p><strong>Paper Abstract:</strong> Motivated by the question of the extent to which large language models “understand” social intelligence, we investigate the ability of such models to generate correct responses to questions involving descriptions of faux pas situations. The faux pas test is a test used in clinical psychology, which is known to be more challenging for children than individual tests of theory-of-mind or social intelligence. Our re-sults demonstrate that, while the models seem to sometimes offer correct responses, they in fact struggle with this task, and that many of the seemingly correct responses can be attributed to over-interpretation by the human reader (“the ELIZA effect”). An additional phenomenon observed is the failure of most models to generate a correct response to presupposition questions. Finally, in an experiment in which the models are tasked with generating original faux pas stories, we find that while some models are capable of generating novel faux pas stories, the stories are all explicit, as the models are limited in their abilities to describe situations in an implicit manner.</p>
                <p><strong>Cost:</strong> 0.02</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9080.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9080.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatGPT (OpenAI web-chat interface)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A conversational large language model accessed via OpenAI's ChatGPT web interface; described in the paper as trained on additional supervised and human-dialog data relative to earlier GPT-3 models.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Conversational LLM accessed via OpenAI's ChatGPT web interface; described in the paper as trained on additional supervised data including human-dialog data.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>Faux Pas Test (Baron-Cohen et al., 1999)</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>A clinical psychology Theory-of-Mind/social-intelligence test consisting of short stories (here: 20 stories, 10 containing faux pas and 10 control) with four questions per story (Q1 detection, Q2 identification, Q3 comprehension, Q4 false-belief). Scoring counts a story as correct only if all four sub-questions are correct.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Q1: 0.6, Q2: 0.7, Q3: 1.0, Q4: 0.7, Final: 0.3 (accuracy/proportion correct over 20 stories as reported in Table 1)</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td>Mean recognition rate M = 0.82 (SD = 0.156) for normally developing 9- to 11-year-old children; equivalent mean score 8.2/10 (SD = 1.56) reported in Baron-Cohen et al. (1999).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>LLM below human baseline (ChatGPT Final = 0.3 << human ~0.82).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>Zero-shot evaluation on 20 Baron-Cohen faux-pas/control stories. Evaluated with three prompt versions (open-ended, Elaborate, and Restricted/yes-no or quote-only responses). For detection closed-task, models were asked to answer Q1-Q4 with restricted formats (Yes/No or quotes) to reduce ELIZA effect. Single sample per model was used. Annotation performed by two experts (NLP researcher and clinical psychologist) with 82-100% initial agreement, reconciled to 100%. Note: paper footnote indicates ChatGPT advantage during submission may be due to web interface message history consistency; later API access (gpt-3.5-turbo-0301) removed that advantage.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>Small test set (20 stories) — insufficient for statistically significant system ranking; responses subject to ELIZA effect (human over-interpretation of plausible-but-incorrect model answers); ChatGPT's apparent advantage attributed partly to web-chat history at time of testing; models struggled with presupposition questions (Q2 on control stories).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9080.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9080.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-3 (text-davinci-003)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>GPT-3 family model (text-davinci-003 variant) from OpenAI, used in zero-shot evaluation in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Language models are few-shot learners</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3 (text-davinci-003)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Autoregressive large language model from OpenAI (cited Brown et al., 2020); used via the text-davinci-003 API in this study.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>Faux Pas Test (Baron-Cohen et al., 1999)</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>As above: 20 stories (10 faux pas, 10 control) with four questions per story assessing detection, identification, comprehension, and false belief.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Q1: 0.5, Q2: 0.8, Q3: 1.0, Q4: 0.6, Final: 0.3 (accuracy/proportion correct over 20 stories; Table 1)</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td>Mean recognition rate M = 0.82 (SD = 0.156); mean score 8.2/10 (SD = 1.56) for 9-11-year-old children (Baron-Cohen et al., 1999).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>LLM below human baseline (GPT-3 Final = 0.3 << human ~0.82).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>Zero-shot prompts; detection test used temperature=0 for text-davinci-003 (Appendix A.1.2). Both open-ended and restricted (yes/no or quote-only) prompts were used. Single sample selected per story for analysis. Annotated by two experts as described above.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>Small sample size; ELIZA effect observed on open-ended outputs; models sometimes produced plausible yet incorrect or delusional answers; struggled with Q2 presuppositions in control stories (often produced arbitrary quoted utterances).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9080.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9080.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Flan-T5-xxl</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>FLAN-T5-XXL</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An instruction-finetuned T5-family model (FLAN-T5) evaluated by the authors; performed best among non-ChatGPT models in final score but still well below child baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Scaling instruction-finetuned language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Flan-T5-xxl</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Instruction-finetuned variant of the T5 family (cited Chung et al., 2022); used via transformers AutoModelForSeq2SeqLM in zero-shot evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>Faux Pas Test (Baron-Cohen et al., 1999)</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>As above: detection + identification + comprehension + false-belief across 20 stories (10 faux pas, 10 control).</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Q1: 0.5, Q2: 0.7, Q3: 1.0, Q4: 0.7, Final: 0.4 (accuracy/proportion correct over 20 stories; Table 1)</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td>Mean recognition rate M = 0.82 (SD = 0.156); mean score 8.2/10 (SD = 1.56) for 9-11-year-old children.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>LLM below human baseline (Flan-T5-xxl Final = 0.4 << human ~0.82).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>Zero-shot evaluation using the transformers implementation (AutoModelForSeq2SeqLM). Prompted with story+question in different versions (open, elaborate, restricted). Single sample per story. Hyperparameters chosen to minimize randomness; do_sample=True for Flan-T5 in their setup and max_length large (Appendix A.1.2).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>Although Q3 often perfect, overall final score low; produces outputs that can create ELIZA effect; failed to generate implicit faux pas when tasked to create stories (generation study); small test set prevents strong comparative claims.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9080.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9080.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Flan-T5-xl</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>FLAN-T5-XL</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Another FLAN-T5 instruction-finetuned model evaluated in the paper; achieved identical highest reported final score (0.4) tied with Flan-T5-xxl.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Scaling instruction-finetuned language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Flan-T5-xl</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Instruction-finetuned T5-family variant (Chung et al., 2022) used via transformers; evaluated zero-shot on faux-pas stories.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>Faux Pas Test (Baron-Cohen et al., 1999)</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>20-story faux pas battery with 4 questions per story assessing social inference and false belief.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Q1: 0.5, Q2: 0.9, Q3: 1.0, Q4: 0.7, Final: 0.4 (accuracy/proportion correct over 20 stories; Table 1)</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td>Mean recognition rate M = 0.82 (SD = 0.156); mean score 8.2/10 (SD = 1.56) for children.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>LLM below human baseline (Flan-T5-xl Final = 0.4 << human ~0.82).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>Zero-shot prompts, restricted and open formats used. Transformers implementation with do_sample=True in their setup for Flan-T5 models; single sample selected per story. Annotated by expert pair.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>Small dataset; ELIZA effect concerns; model failed to generate implicit faux pas narratives in generation study; control Q2 presupposition failures observed across models.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9080.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e9080.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Flan-T5-large</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>FLAN-T5-Large</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A smaller FLAN-T5 instruction-finetuned model evaluated; had mixed sub-question performance but low final score.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Scaling instruction-finetuned language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Flan-T5-large</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Instruction-finetuned T5-family variant (Chung et al., 2022) evaluated in zero-shot manner on the faux-pas battery.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>Faux Pas Test (Baron-Cohen et al., 1999)</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Standard faux-pas battery (20 stories, 4 questions per story) testing social inference and false-belief reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Q1: 0.9, Q2: 0.5, Q3: 0.9, Q4: 0.4, Final: 0.2 (accuracy/proportion correct over 20 stories; Table 1)</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td>Mean recognition rate M = 0.82 (SD = 0.156); mean score 8.2/10 (SD = 1.56).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>LLM below human baseline (Flan-T5-large Final = 0.2 << human ~0.82).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>Zero-shot evaluation with story+question prompts; Flan-T5 models run via transformers AutoModelForSeq2SeqLM. Single sample per story. Annotation protocol as described.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>High Q1 but low Final indicates inconsistent sub-question performance; ELIZA effect and presupposition-handling issues affect interpretation; small sample size.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9080.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e9080.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>T5-11b</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>T5-11B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large T5-family model (11 billion parameters) evaluated in the study (T5 variant included among tested models).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Exploring the limits of transfer learning with a unified text-to-text transformer</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>T5-11b</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A T5-family conditional generation model; the paper used T5 variants including T5-11b via transformers for zero-shot QA.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>11B (implied by name presence in appendix list)</td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>Faux Pas Test (Baron-Cohen et al., 1999)</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>20 stories with 4 sub-questions each testing faux-pas detection, identification, comprehension, and false-belief.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Q1: 0.8, Q2: 0.7, Q3: 0.8, Q4: 0.5, Final: 0.1 (accuracy/proportion correct over 20 stories; Table 1)</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td>Mean recognition rate M = 0.82 (SD = 0.156); mean score 8.2/10 (SD = 1.56).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>LLM below human baseline (T5-11b Final = 0.1 << human ~0.82).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>T5 models prompted with story+question and suffix 'Answer:[MASK]' for T5 (Appendix A.1.1). Used transformers T5ForConditionalGeneration with beam search parameters described (Appendix A.1.2). Single sample per story. Annotation by experts.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>Although some sub-questions had high scores, extremely low final indicates inability to get all sub-questions simultaneously correct; small sample; ELIZA effect; presupposition failures.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9080.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e9080.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-2</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-2</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An earlier OpenAI autoregressive language model; evaluated but achieved final score 0 and was left out of Table 1.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Language models are unsupervised multitask learners</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-2</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>OpenAI GPT-2 autoregressive LM (Radford et al., 2019); used via transformers TFGPT2LMHeadModel in the experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>Faux Pas Test (Baron-Cohen et al., 1999)</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>20-story faux-pas battery with 4 questions per story.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Final score: 0 (models with final score 0 were left out of Table 1); sub-question accuracies not reported in table.</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td>Mean recognition rate M = 0.82 (SD = 0.156); mean score 8.2/10 (SD = 1.56).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>LLM well below human baseline (final = 0).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>GPT-2 was run via transformers implementation with sampling parameters (do_sample=True; top_k/top_p settings) listed in Appendix A.1.2. Single sample selected per story; annotation by experts.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>Final 0 indicates inability to answer all four sub-questions correctly for any story; paper notes many smaller models produced vague, incoherent, or out-of-context responses.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9080.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e9080.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-J</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-J</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An open-source autoregressive language model evaluated in the study; reported final score 0 and omitted from main table.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-J</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Open-source autoregressive LM (used via transformers AutoModelForCausalLM); evaluated zero-shot but produced poor outputs in detection tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>Faux Pas Test (Baron-Cohen et al., 1999)</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Standard faux-pas 20-story battery with four questions per story.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Final score: 0 (left out of Table 1); sub-question accuracies not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td>Mean recognition rate M = 0.82 (SD = 0.156); mean score 8.2/10 (SD = 1.56).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>LLM well below human baseline (final = 0).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>Run with transformers AutoModelForCausalLM and sampling params in Appendix A.1.2; single sample per story. Qualitative outputs for GPT-J described as vague, incoherent, and out-of-context in examples.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>Poor quality outputs; excluded from Table 1 due to final=0; small test set; ELIZA effect may still make some answers appear plausible despite being incorrect.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9080.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e9080.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Flan-T5-base</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>FLAN-T5-Base</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A smaller FLAN-T5 instruction-finetuned model evaluated but with final score 0 in the task.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Scaling instruction-finetuned language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Flan-T5-base</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Instruction-finetuned T5-family base variant used via transformers; included in the evaluated set but scored final 0.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>Faux Pas Test (Baron-Cohen et al., 1999)</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>20 faux-pas/control stories with 4 evaluation questions per story.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Final score: 0 (left out of Table 1); sub-question accuracies not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td>Mean recognition rate M = 0.82 (SD = 0.156); mean score 8.2/10 (SD = 1.56).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>LLM well below human baseline (final = 0).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>Run with transformers AutoModelForSeq2SeqLM; generation settings described in Appendix A.1.2; single sample selected.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>Did not produce sufficient correct answers to be included in Table 1; small dataset; potential ELIZA effect for open-ended responses.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9080.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e9080.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Flan-T5-small</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>FLAN-T5-Small</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A small FLAN-T5 instruction-finetuned model included in evaluation; yielded final score 0 and was omitted from Table 1.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Scaling instruction-finetuned language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Flan-T5-small</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Small instruction-finetuned T5 variant (Chung et al., 2022) used via transformers in zero-shot evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>Faux Pas Test (Baron-Cohen et al., 1999)</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>20 stories with 4 questions each testing social inference and false belief.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Final score: 0 (left out of Table 1); sub-question accuracies not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td>Mean recognition rate M = 0.82 (SD = 0.156); mean score 8.2/10 (SD = 1.56).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>LLM well below human baseline (final = 0).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>Evaluated zero-shot with the same prompt protocols (open/elaborate/restricted). Single sample used; hyperparameters chosen to reduce randomness.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>Did not produce acceptable overall answers; small dataset limits statistical claims.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9080.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e9080.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>T5-3b</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>T5-3B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A mid-sized T5-family conditional generation model included in the evaluations but with final score 0.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Exploring the limits of transfer learning with a unified text-to-text transformer</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>T5-3b</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A T5 variant (3B) used with transformers T5ForConditionalGeneration; included among tested T5 sizes in Appendix A.1.2.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>Faux Pas Test (Baron-Cohen et al., 1999)</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Faux-pas detection/identification/comprehension/false-belief across 20 stories.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Final score: 0 (left out of Table 1); sub-question accuracies not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td>Mean recognition rate M = 0.82 (SD = 0.156); mean score 8.2/10 (SD = 1.56).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>LLM well below human baseline (final = 0).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>T5 family prompted using Answer:[MASK] suffix for T5; generation with beam search settings as in Appendix A.1.2; single sample per story.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>Excluded from Table 1 due to final=0; limited dataset; ELIZA effect may confound perception of understanding in open responses.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9080.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e9080.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>T5-large</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>T5-Large</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large T5-family conditional generation model included in experiments; final score 0 and omitted from Table 1.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Exploring the limits of transfer learning with a unified text-to-text transformer</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>T5-large</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>T5-family model (large variant) used via transformers for zero-shot question-answering with T5-specific prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>Faux Pas Test (Baron-Cohen et al., 1999)</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>20-story faux-pas battery; four questions per story assessing social inference and false belief.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Final score: 0 (left out of Table 1); sub-question accuracies not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td>Mean recognition rate M = 0.82 (SD = 0.156); mean score 8.2/10 (SD = 1.56).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>LLM well below human baseline (final = 0).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>T5 models used Answer:[MASK] prompt format; beam search parameters described in Appendix A.1.2. Single sample chosen.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>Did not achieve any full-story correct responses; limited evaluation set.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9080.12">
                <h3 class="extraction-instance">Extracted Data Instance 12 (e9080.12)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>T5-base</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>T5-Base</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The base variant of the T5 family evaluated but with final score 0 in the faux-pas battery.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Exploring the limits of transfer learning with a unified text-to-text transformer</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>T5-base</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>T5-family base model used in the experiments with T5-specific prompting; included among tested sizes in Appendix.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>Faux Pas Test (Baron-Cohen et al., 1999)</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>20 stories with 4 questions each (detection, identification, comprehension, false belief).</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Final score: 0 (left out of Table 1); sub-question accuracies not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td>Mean recognition rate M = 0.82 (SD = 0.156); mean score 8.2/10 (SD = 1.56).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>LLM well below human baseline (final = 0).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>Evaluated zero-shot with T5 Answer:[MASK] prompt; beam-search generation per Appendix A.1.2; single sample per story.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>No full-story correct responses; small dataset; annotation by experts mitigates but does not remove inherent subjectivity in evaluating open-ended outputs.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9080.13">
                <h3 class="extraction-instance">Extracted Data Instance 13 (e9080.13)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>T5-small</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>T5-Small</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The small variant of the T5 family included in the evaluations; final score 0 and omitted from Table 1.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Exploring the limits of transfer learning with a unified text-to-text transformer</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>T5-small</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Small T5-family model used via transformers with T5-specific prompt formatting in the experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>Faux Pas Test (Baron-Cohen et al., 1999)</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Twenty stories (10 faux pas, 10 control) each with four evaluation questions testing ToM-related abilities.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>Final score: 0 (left out of Table 1); sub-question accuracies not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td>Mean recognition rate M = 0.82 (SD = 0.156); mean score 8.2/10 (SD = 1.56).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>LLM well below human baseline (final = 0).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>Same T5 prompt setup and generation hyperparameters as other T5 variants (Appendix A.1.2). Single sample selection.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>No full-story correct answers; limited dataset; qualitative issues (coherence, emotion mismatch) noted in generated stories and answers.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Neural theory-of-mind? On the limits of social intelligence in large LMs <em>(Rating: 2)</em></li>
                <li>Recognition of faux pas by normally developing children and children with asperger syndrome or high-functioning autism <em>(Rating: 2)</em></li>
                <li>Know what you don't know: Unanswerable questions for SQuAD <em>(Rating: 1)</em></li>
                <li>Which linguist invented the lightbulb? Presupposition verification for question-answering <em>(Rating: 1)</em></li>
                <li>CREPE: Open-Domain Question Answering with False Presuppositions <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9080",
    "paper_id": "paper-016c8d91f8a102111dc5eb76ab4ce433b9e2ec53",
    "extraction_schema_id": "extraction-schema-159",
    "extracted_data": [
        {
            "name_short": "ChatGPT",
            "name_full": "ChatGPT (OpenAI web-chat interface)",
            "brief_description": "A conversational large language model accessed via OpenAI's ChatGPT web interface; described in the paper as trained on additional supervised and human-dialog data relative to earlier GPT-3 models.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "ChatGPT",
            "model_description": "Conversational LLM accessed via OpenAI's ChatGPT web interface; described in the paper as trained on additional supervised data including human-dialog data.",
            "model_size": null,
            "test_battery_name": "Faux Pas Test (Baron-Cohen et al., 1999)",
            "test_description": "A clinical psychology Theory-of-Mind/social-intelligence test consisting of short stories (here: 20 stories, 10 containing faux pas and 10 control) with four questions per story (Q1 detection, Q2 identification, Q3 comprehension, Q4 false-belief). Scoring counts a story as correct only if all four sub-questions are correct.",
            "llm_performance": "Q1: 0.6, Q2: 0.7, Q3: 1.0, Q4: 0.7, Final: 0.3 (accuracy/proportion correct over 20 stories as reported in Table 1)",
            "human_baseline_performance": "Mean recognition rate M = 0.82 (SD = 0.156) for normally developing 9- to 11-year-old children; equivalent mean score 8.2/10 (SD = 1.56) reported in Baron-Cohen et al. (1999).",
            "performance_comparison": "LLM below human baseline (ChatGPT Final = 0.3 &lt;&lt; human ~0.82).",
            "experimental_details": "Zero-shot evaluation on 20 Baron-Cohen faux-pas/control stories. Evaluated with three prompt versions (open-ended, Elaborate, and Restricted/yes-no or quote-only responses). For detection closed-task, models were asked to answer Q1-Q4 with restricted formats (Yes/No or quotes) to reduce ELIZA effect. Single sample per model was used. Annotation performed by two experts (NLP researcher and clinical psychologist) with 82-100% initial agreement, reconciled to 100%. Note: paper footnote indicates ChatGPT advantage during submission may be due to web interface message history consistency; later API access (gpt-3.5-turbo-0301) removed that advantage.",
            "limitations_or_caveats": "Small test set (20 stories) — insufficient for statistically significant system ranking; responses subject to ELIZA effect (human over-interpretation of plausible-but-incorrect model answers); ChatGPT's apparent advantage attributed partly to web-chat history at time of testing; models struggled with presupposition questions (Q2 on control stories).",
            "uuid": "e9080.0"
        },
        {
            "name_short": "GPT-3",
            "name_full": "GPT-3 (text-davinci-003)",
            "brief_description": "GPT-3 family model (text-davinci-003 variant) from OpenAI, used in zero-shot evaluation in the paper.",
            "citation_title": "Language models are few-shot learners",
            "mention_or_use": "use",
            "model_name": "GPT-3 (text-davinci-003)",
            "model_description": "Autoregressive large language model from OpenAI (cited Brown et al., 2020); used via the text-davinci-003 API in this study.",
            "model_size": null,
            "test_battery_name": "Faux Pas Test (Baron-Cohen et al., 1999)",
            "test_description": "As above: 20 stories (10 faux pas, 10 control) with four questions per story assessing detection, identification, comprehension, and false belief.",
            "llm_performance": "Q1: 0.5, Q2: 0.8, Q3: 1.0, Q4: 0.6, Final: 0.3 (accuracy/proportion correct over 20 stories; Table 1)",
            "human_baseline_performance": "Mean recognition rate M = 0.82 (SD = 0.156); mean score 8.2/10 (SD = 1.56) for 9-11-year-old children (Baron-Cohen et al., 1999).",
            "performance_comparison": "LLM below human baseline (GPT-3 Final = 0.3 &lt;&lt; human ~0.82).",
            "experimental_details": "Zero-shot prompts; detection test used temperature=0 for text-davinci-003 (Appendix A.1.2). Both open-ended and restricted (yes/no or quote-only) prompts were used. Single sample selected per story for analysis. Annotated by two experts as described above.",
            "limitations_or_caveats": "Small sample size; ELIZA effect observed on open-ended outputs; models sometimes produced plausible yet incorrect or delusional answers; struggled with Q2 presuppositions in control stories (often produced arbitrary quoted utterances).",
            "uuid": "e9080.1"
        },
        {
            "name_short": "Flan-T5-xxl",
            "name_full": "FLAN-T5-XXL",
            "brief_description": "An instruction-finetuned T5-family model (FLAN-T5) evaluated by the authors; performed best among non-ChatGPT models in final score but still well below child baseline.",
            "citation_title": "Scaling instruction-finetuned language models",
            "mention_or_use": "use",
            "model_name": "Flan-T5-xxl",
            "model_description": "Instruction-finetuned variant of the T5 family (cited Chung et al., 2022); used via transformers AutoModelForSeq2SeqLM in zero-shot evaluation.",
            "model_size": null,
            "test_battery_name": "Faux Pas Test (Baron-Cohen et al., 1999)",
            "test_description": "As above: detection + identification + comprehension + false-belief across 20 stories (10 faux pas, 10 control).",
            "llm_performance": "Q1: 0.5, Q2: 0.7, Q3: 1.0, Q4: 0.7, Final: 0.4 (accuracy/proportion correct over 20 stories; Table 1)",
            "human_baseline_performance": "Mean recognition rate M = 0.82 (SD = 0.156); mean score 8.2/10 (SD = 1.56) for 9-11-year-old children.",
            "performance_comparison": "LLM below human baseline (Flan-T5-xxl Final = 0.4 &lt;&lt; human ~0.82).",
            "experimental_details": "Zero-shot evaluation using the transformers implementation (AutoModelForSeq2SeqLM). Prompted with story+question in different versions (open, elaborate, restricted). Single sample per story. Hyperparameters chosen to minimize randomness; do_sample=True for Flan-T5 in their setup and max_length large (Appendix A.1.2).",
            "limitations_or_caveats": "Although Q3 often perfect, overall final score low; produces outputs that can create ELIZA effect; failed to generate implicit faux pas when tasked to create stories (generation study); small test set prevents strong comparative claims.",
            "uuid": "e9080.2"
        },
        {
            "name_short": "Flan-T5-xl",
            "name_full": "FLAN-T5-XL",
            "brief_description": "Another FLAN-T5 instruction-finetuned model evaluated in the paper; achieved identical highest reported final score (0.4) tied with Flan-T5-xxl.",
            "citation_title": "Scaling instruction-finetuned language models",
            "mention_or_use": "use",
            "model_name": "Flan-T5-xl",
            "model_description": "Instruction-finetuned T5-family variant (Chung et al., 2022) used via transformers; evaluated zero-shot on faux-pas stories.",
            "model_size": null,
            "test_battery_name": "Faux Pas Test (Baron-Cohen et al., 1999)",
            "test_description": "20-story faux pas battery with 4 questions per story assessing social inference and false belief.",
            "llm_performance": "Q1: 0.5, Q2: 0.9, Q3: 1.0, Q4: 0.7, Final: 0.4 (accuracy/proportion correct over 20 stories; Table 1)",
            "human_baseline_performance": "Mean recognition rate M = 0.82 (SD = 0.156); mean score 8.2/10 (SD = 1.56) for children.",
            "performance_comparison": "LLM below human baseline (Flan-T5-xl Final = 0.4 &lt;&lt; human ~0.82).",
            "experimental_details": "Zero-shot prompts, restricted and open formats used. Transformers implementation with do_sample=True in their setup for Flan-T5 models; single sample selected per story. Annotated by expert pair.",
            "limitations_or_caveats": "Small dataset; ELIZA effect concerns; model failed to generate implicit faux pas narratives in generation study; control Q2 presupposition failures observed across models.",
            "uuid": "e9080.3"
        },
        {
            "name_short": "Flan-T5-large",
            "name_full": "FLAN-T5-Large",
            "brief_description": "A smaller FLAN-T5 instruction-finetuned model evaluated; had mixed sub-question performance but low final score.",
            "citation_title": "Scaling instruction-finetuned language models",
            "mention_or_use": "use",
            "model_name": "Flan-T5-large",
            "model_description": "Instruction-finetuned T5-family variant (Chung et al., 2022) evaluated in zero-shot manner on the faux-pas battery.",
            "model_size": null,
            "test_battery_name": "Faux Pas Test (Baron-Cohen et al., 1999)",
            "test_description": "Standard faux-pas battery (20 stories, 4 questions per story) testing social inference and false-belief reasoning.",
            "llm_performance": "Q1: 0.9, Q2: 0.5, Q3: 0.9, Q4: 0.4, Final: 0.2 (accuracy/proportion correct over 20 stories; Table 1)",
            "human_baseline_performance": "Mean recognition rate M = 0.82 (SD = 0.156); mean score 8.2/10 (SD = 1.56).",
            "performance_comparison": "LLM below human baseline (Flan-T5-large Final = 0.2 &lt;&lt; human ~0.82).",
            "experimental_details": "Zero-shot evaluation with story+question prompts; Flan-T5 models run via transformers AutoModelForSeq2SeqLM. Single sample per story. Annotation protocol as described.",
            "limitations_or_caveats": "High Q1 but low Final indicates inconsistent sub-question performance; ELIZA effect and presupposition-handling issues affect interpretation; small sample size.",
            "uuid": "e9080.4"
        },
        {
            "name_short": "T5-11b",
            "name_full": "T5-11B",
            "brief_description": "A large T5-family model (11 billion parameters) evaluated in the study (T5 variant included among tested models).",
            "citation_title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
            "mention_or_use": "use",
            "model_name": "T5-11b",
            "model_description": "A T5-family conditional generation model; the paper used T5 variants including T5-11b via transformers for zero-shot QA.",
            "model_size": "11B (implied by name presence in appendix list)",
            "test_battery_name": "Faux Pas Test (Baron-Cohen et al., 1999)",
            "test_description": "20 stories with 4 sub-questions each testing faux-pas detection, identification, comprehension, and false-belief.",
            "llm_performance": "Q1: 0.8, Q2: 0.7, Q3: 0.8, Q4: 0.5, Final: 0.1 (accuracy/proportion correct over 20 stories; Table 1)",
            "human_baseline_performance": "Mean recognition rate M = 0.82 (SD = 0.156); mean score 8.2/10 (SD = 1.56).",
            "performance_comparison": "LLM below human baseline (T5-11b Final = 0.1 &lt;&lt; human ~0.82).",
            "experimental_details": "T5 models prompted with story+question and suffix 'Answer:[MASK]' for T5 (Appendix A.1.1). Used transformers T5ForConditionalGeneration with beam search parameters described (Appendix A.1.2). Single sample per story. Annotation by experts.",
            "limitations_or_caveats": "Although some sub-questions had high scores, extremely low final indicates inability to get all sub-questions simultaneously correct; small sample; ELIZA effect; presupposition failures.",
            "uuid": "e9080.5"
        },
        {
            "name_short": "GPT-2",
            "name_full": "GPT-2",
            "brief_description": "An earlier OpenAI autoregressive language model; evaluated but achieved final score 0 and was left out of Table 1.",
            "citation_title": "Language models are unsupervised multitask learners",
            "mention_or_use": "use",
            "model_name": "GPT-2",
            "model_description": "OpenAI GPT-2 autoregressive LM (Radford et al., 2019); used via transformers TFGPT2LMHeadModel in the experiments.",
            "model_size": null,
            "test_battery_name": "Faux Pas Test (Baron-Cohen et al., 1999)",
            "test_description": "20-story faux-pas battery with 4 questions per story.",
            "llm_performance": "Final score: 0 (models with final score 0 were left out of Table 1); sub-question accuracies not reported in table.",
            "human_baseline_performance": "Mean recognition rate M = 0.82 (SD = 0.156); mean score 8.2/10 (SD = 1.56).",
            "performance_comparison": "LLM well below human baseline (final = 0).",
            "experimental_details": "GPT-2 was run via transformers implementation with sampling parameters (do_sample=True; top_k/top_p settings) listed in Appendix A.1.2. Single sample selected per story; annotation by experts.",
            "limitations_or_caveats": "Final 0 indicates inability to answer all four sub-questions correctly for any story; paper notes many smaller models produced vague, incoherent, or out-of-context responses.",
            "uuid": "e9080.6"
        },
        {
            "name_short": "GPT-J",
            "name_full": "GPT-J",
            "brief_description": "An open-source autoregressive language model evaluated in the study; reported final score 0 and omitted from main table.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-J",
            "model_description": "Open-source autoregressive LM (used via transformers AutoModelForCausalLM); evaluated zero-shot but produced poor outputs in detection tasks.",
            "model_size": null,
            "test_battery_name": "Faux Pas Test (Baron-Cohen et al., 1999)",
            "test_description": "Standard faux-pas 20-story battery with four questions per story.",
            "llm_performance": "Final score: 0 (left out of Table 1); sub-question accuracies not reported.",
            "human_baseline_performance": "Mean recognition rate M = 0.82 (SD = 0.156); mean score 8.2/10 (SD = 1.56).",
            "performance_comparison": "LLM well below human baseline (final = 0).",
            "experimental_details": "Run with transformers AutoModelForCausalLM and sampling params in Appendix A.1.2; single sample per story. Qualitative outputs for GPT-J described as vague, incoherent, and out-of-context in examples.",
            "limitations_or_caveats": "Poor quality outputs; excluded from Table 1 due to final=0; small test set; ELIZA effect may still make some answers appear plausible despite being incorrect.",
            "uuid": "e9080.7"
        },
        {
            "name_short": "Flan-T5-base",
            "name_full": "FLAN-T5-Base",
            "brief_description": "A smaller FLAN-T5 instruction-finetuned model evaluated but with final score 0 in the task.",
            "citation_title": "Scaling instruction-finetuned language models",
            "mention_or_use": "use",
            "model_name": "Flan-T5-base",
            "model_description": "Instruction-finetuned T5-family base variant used via transformers; included in the evaluated set but scored final 0.",
            "model_size": null,
            "test_battery_name": "Faux Pas Test (Baron-Cohen et al., 1999)",
            "test_description": "20 faux-pas/control stories with 4 evaluation questions per story.",
            "llm_performance": "Final score: 0 (left out of Table 1); sub-question accuracies not reported.",
            "human_baseline_performance": "Mean recognition rate M = 0.82 (SD = 0.156); mean score 8.2/10 (SD = 1.56).",
            "performance_comparison": "LLM well below human baseline (final = 0).",
            "experimental_details": "Run with transformers AutoModelForSeq2SeqLM; generation settings described in Appendix A.1.2; single sample selected.",
            "limitations_or_caveats": "Did not produce sufficient correct answers to be included in Table 1; small dataset; potential ELIZA effect for open-ended responses.",
            "uuid": "e9080.8"
        },
        {
            "name_short": "Flan-T5-small",
            "name_full": "FLAN-T5-Small",
            "brief_description": "A small FLAN-T5 instruction-finetuned model included in evaluation; yielded final score 0 and was omitted from Table 1.",
            "citation_title": "Scaling instruction-finetuned language models",
            "mention_or_use": "use",
            "model_name": "Flan-T5-small",
            "model_description": "Small instruction-finetuned T5 variant (Chung et al., 2022) used via transformers in zero-shot evaluation.",
            "model_size": null,
            "test_battery_name": "Faux Pas Test (Baron-Cohen et al., 1999)",
            "test_description": "20 stories with 4 questions each testing social inference and false belief.",
            "llm_performance": "Final score: 0 (left out of Table 1); sub-question accuracies not reported.",
            "human_baseline_performance": "Mean recognition rate M = 0.82 (SD = 0.156); mean score 8.2/10 (SD = 1.56).",
            "performance_comparison": "LLM well below human baseline (final = 0).",
            "experimental_details": "Evaluated zero-shot with the same prompt protocols (open/elaborate/restricted). Single sample used; hyperparameters chosen to reduce randomness.",
            "limitations_or_caveats": "Did not produce acceptable overall answers; small dataset limits statistical claims.",
            "uuid": "e9080.9"
        },
        {
            "name_short": "T5-3b",
            "name_full": "T5-3B",
            "brief_description": "A mid-sized T5-family conditional generation model included in the evaluations but with final score 0.",
            "citation_title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
            "mention_or_use": "use",
            "model_name": "T5-3b",
            "model_description": "A T5 variant (3B) used with transformers T5ForConditionalGeneration; included among tested T5 sizes in Appendix A.1.2.",
            "model_size": null,
            "test_battery_name": "Faux Pas Test (Baron-Cohen et al., 1999)",
            "test_description": "Faux-pas detection/identification/comprehension/false-belief across 20 stories.",
            "llm_performance": "Final score: 0 (left out of Table 1); sub-question accuracies not reported.",
            "human_baseline_performance": "Mean recognition rate M = 0.82 (SD = 0.156); mean score 8.2/10 (SD = 1.56).",
            "performance_comparison": "LLM well below human baseline (final = 0).",
            "experimental_details": "T5 family prompted using Answer:[MASK] suffix for T5; generation with beam search settings as in Appendix A.1.2; single sample per story.",
            "limitations_or_caveats": "Excluded from Table 1 due to final=0; limited dataset; ELIZA effect may confound perception of understanding in open responses.",
            "uuid": "e9080.10"
        },
        {
            "name_short": "T5-large",
            "name_full": "T5-Large",
            "brief_description": "A large T5-family conditional generation model included in experiments; final score 0 and omitted from Table 1.",
            "citation_title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
            "mention_or_use": "use",
            "model_name": "T5-large",
            "model_description": "T5-family model (large variant) used via transformers for zero-shot question-answering with T5-specific prompting.",
            "model_size": null,
            "test_battery_name": "Faux Pas Test (Baron-Cohen et al., 1999)",
            "test_description": "20-story faux-pas battery; four questions per story assessing social inference and false belief.",
            "llm_performance": "Final score: 0 (left out of Table 1); sub-question accuracies not reported.",
            "human_baseline_performance": "Mean recognition rate M = 0.82 (SD = 0.156); mean score 8.2/10 (SD = 1.56).",
            "performance_comparison": "LLM well below human baseline (final = 0).",
            "experimental_details": "T5 models used Answer:[MASK] prompt format; beam search parameters described in Appendix A.1.2. Single sample chosen.",
            "limitations_or_caveats": "Did not achieve any full-story correct responses; limited evaluation set.",
            "uuid": "e9080.11"
        },
        {
            "name_short": "T5-base",
            "name_full": "T5-Base",
            "brief_description": "The base variant of the T5 family evaluated but with final score 0 in the faux-pas battery.",
            "citation_title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
            "mention_or_use": "use",
            "model_name": "T5-base",
            "model_description": "T5-family base model used in the experiments with T5-specific prompting; included among tested sizes in Appendix.",
            "model_size": null,
            "test_battery_name": "Faux Pas Test (Baron-Cohen et al., 1999)",
            "test_description": "20 stories with 4 questions each (detection, identification, comprehension, false belief).",
            "llm_performance": "Final score: 0 (left out of Table 1); sub-question accuracies not reported.",
            "human_baseline_performance": "Mean recognition rate M = 0.82 (SD = 0.156); mean score 8.2/10 (SD = 1.56).",
            "performance_comparison": "LLM well below human baseline (final = 0).",
            "experimental_details": "Evaluated zero-shot with T5 Answer:[MASK] prompt; beam-search generation per Appendix A.1.2; single sample per story.",
            "limitations_or_caveats": "No full-story correct responses; small dataset; annotation by experts mitigates but does not remove inherent subjectivity in evaluating open-ended outputs.",
            "uuid": "e9080.12"
        },
        {
            "name_short": "T5-small",
            "name_full": "T5-Small",
            "brief_description": "The small variant of the T5 family included in the evaluations; final score 0 and omitted from Table 1.",
            "citation_title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
            "mention_or_use": "use",
            "model_name": "T5-small",
            "model_description": "Small T5-family model used via transformers with T5-specific prompt formatting in the experiments.",
            "model_size": null,
            "test_battery_name": "Faux Pas Test (Baron-Cohen et al., 1999)",
            "test_description": "Twenty stories (10 faux pas, 10 control) each with four evaluation questions testing ToM-related abilities.",
            "llm_performance": "Final score: 0 (left out of Table 1); sub-question accuracies not reported.",
            "human_baseline_performance": "Mean recognition rate M = 0.82 (SD = 0.156); mean score 8.2/10 (SD = 1.56).",
            "performance_comparison": "LLM well below human baseline (final = 0).",
            "experimental_details": "Same T5 prompt setup and generation hyperparameters as other T5 variants (Appendix A.1.2). Single sample selection.",
            "limitations_or_caveats": "No full-story correct answers; limited dataset; qualitative issues (coherence, emotion mismatch) noted in generated stories and answers.",
            "uuid": "e9080.13"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Neural theory-of-mind? On the limits of social intelligence in large LMs",
            "rating": 2
        },
        {
            "paper_title": "Recognition of faux pas by normally developing children and children with asperger syndrome or high-functioning autism",
            "rating": 2
        },
        {
            "paper_title": "Know what you don't know: Unanswerable questions for SQuAD",
            "rating": 1
        },
        {
            "paper_title": "Which linguist invented the lightbulb? Presupposition verification for question-answering",
            "rating": 1
        },
        {
            "paper_title": "CREPE: Open-Domain Question Answering with False Presuppositions",
            "rating": 1
        }
    ],
    "cost": 0.020066,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>How Well Do Large Language Models Perform on Faux Pas Tests?</h1>
<p>Natalie Shapira ${ }^{1}$ Guy Zwirn ${ }^{2}$ Yoav Goldberg ${ }^{1,3}$<br>${ }^{1}$ Bar-Ilan University, Ramat Gan, Israel<br>${ }^{2}$ Hadassah University Medical Center, Jerusalem, Israel<br>${ }^{3}$ Allen Institute for AI, Tel Aviv, Israel<br>nd1234@gmail.com</p>
<h4>Abstract</h4>
<p>Motivated by the question of the extent to which large language models "understand" social intelligence, we investigate the ability of such models to generate correct responses to questions involving descriptions of faux pas situations. The faux pas test is a test used in clinical psychology, which is known to be more challenging for children than individual tests of theory-of-mind or social intelligence. Our results demonstrate that, while the models seem to sometimes offer correct responses, they in fact struggle with this task, and that many of the seemingly correct responses can be attributed to over-interpretation by the human reader ("the ELIZA effect"). An additional phenomenon observed is the failure of most models to generate a correct response to presupposition questions. Finally, in an experiment in which the models are tasked with generating original faux pas stories, we find that while some models are capable of generating novel faux pas stories, the stories are all explicit, as the models are limited in their abilities to describe situations in an implicit manner.</p>
<h2>1 Introduction</h2>
<p>Theory of Mind (ToM) is the ability or skill to identify, evaluate or attribute mental states-beliefs, intents, desires, pretending, knowledge, etc.-to oneself and others and to understand that others have perspectives that are different from one's own (Wimmer and Perner, 1983). A social skill is any competence facilitating interaction and communication with others (Dowd and Tierney, 2005). Ideally, automated agents that interact with people should possess such social common sense abilities (Choi, 2022), and indeed, a recent trend in the field of AI aims to address challenges related to social skills and commonsense (Sakaguchi et al., 2021; Le et al., 2019; Talmor et al., 2022; Sap et al., 2019; Zellers et al., 2019; Hessel et al., 2022; Lin et al., 2020; Shapira et al., 2023).
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: A faux pas story from (Baron-Cohen et al., 1999) and sample answers of large language models. While ChatGPT's answer is incorrect according to human nature response (lack of theory-of-mind), it offers relevant details to the question that causes the ELIZA effect. Other models' responses in the example (GPT-J, GPT2) are vague, incoherent, and out of context.</p>
<p>To what extent do Large Language Models (LLMs; Brown et al., 2020; Bommasani et al., 2021; Zhao et al., 2023)—models that were trained on massive amounts of both supervised and unsupervised language data, and which constitute the current state of the art in language-based reasoning and communication-possess the ability to effectively reason about implicit social situations, that may not be explicitly discussed in texts? Sap et al. (2022) examine zero-shot theory-of-mind abilities in LLMs (GPT-3-Davinci; Brown et al., 2020) and show that the models struggle with ToMbased tasks. Since then, ChatGPT, ${ }^{1}$ a new model trained on additional supervised data and in particular human-dialog data, suggests improved abilities at such tasks.</p>
<p>We propose to push beyond the current theory-of-mind tests and consider the task of "recognition of faux pas", an established task in the clinical psychology domain (Baron-Cohen et al., 1999). The faux pas task combines the SocialIQa (Sap</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>et al., 2019) and the ToMi (Le et al., 2019) tasks mentioned in (Sap et al., 2022) and is considered to be more difficult for children than any of the individual tasks on their own. We show that the task is also challenging for state-of-the-art LLMs.</p>
<p>We describe two studies, examining different aspects related to the recognition of faux pas within LLMs. ${ }^{2}$ In the first study (§3) we evaluate, together with a clinical psychologist with diagnosis expertise, the faux pas test results on LLMs. At the first stage (§3.1) we perform a qualitative analysis of the responses of the models and propose a new annotation method that tries to capture quantitatively part of "the ELIZA effect" (Weizenbaum, 1976) a phenomenon where an individual may attribute understanding to a machine based on its ability to respond in a seemingly intelligent manner, even if the response does not fully answer the question. In the second stage, the models were restricted to closed-ended questions by requiring a yes or no answer or without explanations (§3.2). The results show that while the models seem to sometimes offer correct responses, they in fact struggle with this task and that many of the seemingly correct responses can be attributed to over-interpretation by the human reader.</p>
<p>An additional phenomenon observed is that most of the models failed to generate a correct response to "What did they say that they should not have said?" when the question was based on a false assumption and there was no problematic statement in the text.</p>
<p>In the second study (§4) we instruct models to generate 20 original faux pas stories which we manually evaluate, showing that while the best models can generate some faux pas stories, they can only do it in an explicit manner, and struggle with the implicit aspects, which are central to the ToM.</p>
<h2>2 Recognition of Faux Pas</h2>
<p>Faux Pas (French for "false step") is defined as "when a speaker says something without considering if it is something that the listener might not want to hear or know, and which typically has negative consequences that the speaker never intended" (Baron-Cohen et al., 1999).</p>
<p>One example of a faux pas situation is when a guest tells their hosts that they "like cakes except for apple pie", without realizing that the hosts have</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup>made an apple pie for them. The complexity of the situation depends not only on the content of the statement ("except for apple pie") but also on the context in which it was made (e.g., the host had made an apple pie and the guest was unaware). Faux pas is the "uhoh!" emotion most people would feel when they reveal the reality of the context. In the mentioned example, the statement may not be problematic if the hosts had made a cheesecake instead.</p>
<p>In the original test, ${ }^{3}$ the subject is told 10 stories that contain faux pas. At the end of each story, the subject is asked 4 questions:</p>
<ul>
<li>Q1 - Faux Pas Detection Question - In the story did someone say something that they should not have said?</li>
<li>Q2 - Identification Question - What did they say that they should not have said?</li>
<li>Q3 - Comprehensive Question (this question is different for each story)</li>
<li>Q4 - False Belief Question. Did they know/remember that? (this question is different for each story)</li>
</ul>
<p>Each faux pas story that is answered correctly (i.e., all four questions are correct) scored 1 point. In a clinical trial, the average score for 9 - to 11-year-old children is $8.2(\mathrm{SD}=1.56)$ out of 10 faux pas stories (Baron-Cohen et al., 1999).</p>
<p>We note that the faux pas test was initially developed to diagnose autism or Asperger syndrome in children. Here, we do not diagnose models.</p>
<p>Faux Pas as a task can be viewed as a composition of the two tasks that were presented separately by Sap et al. (2022): (1) SocialIQa (Sap et al., 2019) that is related to analyzing and understanding social situations such as reasoning about motivations (e.g., Why would someone accidentally push someone in a narrow elevator? to enter the elevator), what happens next (e.g., What would one want to do after food spilled on the floor? mop up) and emotional reaction (e.g, How would others feel after a scene where the hero is struggling with the villain? hope that the hero will win). (2) ToMi (Le et al., 2019) that is related to the ability to perceive the existence of different perspectives for different agents (e.g., Sally puts a marble in a basket and</p>
<p><sup id="fnref:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<p>left the room. Anne moves the marble to a closet. Where will Sally look for the marble?).</p>
<p>The compositionality between the data sets is currently at the essence level and not at the practical level. Faux-pas test is based on mental state inference and the ability to recognize false beliefs (Korman et al., 2017). The SocialIQa includes questions about reasoning about motivation and emotional reactions i.e., "mental state". The ToMi aims to assess the recognition of false beliefs. For example in the story mentioned in Figure 1, the reader is expected to infer (1) When someone is told "I never liked that object" when the object is a gift from that person, they may be hurt/feel disrespected (mental state). (2) Under the assumption of good intentions, a reasonable possible interpretation is that Richard did not remember/know that James brought him the gift although the reader knows this fact (false belief).</p>
<p>While most ToM clinical tests are designed for subjects with a mental age of 4-6 years, according to the literature, faux pas detection is a ToM clinical test designed to recognize Asperger Syndrome or High-Functioning Autism in children ages 7-11 (Baron-Cohen et al., 1999). This may suggest the difficulty of the test.</p>
<p>For the purposes of this study, we will use 20 examples ( 10 containing faux pas and 10 control examples) as they appear in the original test in the literature. In addition, aided by LLMs we attempted to generate additional 20 original faux pas stories and annotate their quality (§4)</p>
<h2>3 Study 1: Faux Pas Test Performance</h2>
<p>In this study the first and second authors of the paper (an NLP researcher and a clinical psychologist trained in diagnostics) manually evaluated the responses to the faux pas tests generated by 14 different language models that were run in a zeroshot manner (Liu et al., 2021) (for technical details regarding prompts and parameters see Appendix A.1). ${ }^{4}$</p>
<p>The annotation included 3 phases. Phase 1: A researcher (NLP researcher in study/table 1 and Clinical Psychology Diagnostician in studies/tables 2-3) labeled the data and produced simple guidelines. Phase 2: the other researcher labeled the data according to guidelines. Phase 3: both researchers</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Example of ChatGPT response demonstrates the dimensions of illusion.
discussed the final decision in cases where there was disagreement. The agreement between the two annotators was $82-100 \%$ and after reconciliation $100 \%$.</p>
<p>First, the models were given a story and an open-ended question "In the story did someone say something that they should not have said?" (§3.1). The results of this task raised concerns about ELIZA effect. To accommodate for that, in the second stage the models were given the complete test (4 questions) with closed-ended questions requiring a yes or no answer or without explanations "In the story did someone say something that they should not have said? Answer with "Yes" or "No" only, without explanations. In case of doubt, answer according to the most probable answer." (§3.2). ${ }^{5}$</p>
<p>We found the open-ended version of the questions (Table 2) both expensive (manually by experts) and problematic from the perspective of the ELIZA effect i.e., some responses contain the correct answer but at the same time also suggest the wrong answer, in a persuasive way, without a clearcut final answer ( $\S 3.1$ and Figure 2). The restricted yes/no version of the questions ( $\S 3.2$ and Table 1) is clear-cut and could be done automatically.</p>
<h3>3.1 Assessing the ELIZA Effect in Responses</h3>
<p>We assess the quality of the Q1 responses as an open-end question, on several quality factors. The goal is to appraise whether the response provides an ELIZA effect, giving an illusion of understanding (see Figure 2).</p>
<p>The annotation of the response consists of the following factors:
Correct: Contains the correct answer (even if not the full answer or there are also wrong parts in the response).</p>
<p><sup id="fnref2:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">Faux Pas</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;">Control</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Model</td>
<td style="text-align: center;">Q1</td>
<td style="text-align: center;">Q2</td>
<td style="text-align: center;">Q3</td>
<td style="text-align: center;">Q4</td>
<td style="text-align: center;">Final</td>
<td style="text-align: center;">Q1</td>
<td style="text-align: center;">Q2</td>
<td style="text-align: center;">Q3</td>
<td style="text-align: center;">Q4</td>
<td style="text-align: center;">Final</td>
</tr>
<tr>
<td style="text-align: left;">ChatGPT</td>
<td style="text-align: center;">0.6</td>
<td style="text-align: center;">0.7</td>
<td style="text-align: center;">$\mathbf{1 . 0}$</td>
<td style="text-align: center;">$\mathbf{0 . 7}$</td>
<td style="text-align: center;">0.3</td>
<td style="text-align: center;">$\mathbf{1 . 0}$</td>
<td style="text-align: center;">$\mathbf{1 . 0}$</td>
<td style="text-align: center;">$\mathbf{1 . 0}$</td>
<td style="text-align: center;">$\mathbf{0 . 9}$</td>
<td style="text-align: center;">$\mathbf{0 . 9}$</td>
</tr>
<tr>
<td style="text-align: left;">GPT3</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.8</td>
<td style="text-align: center;">$\mathbf{1 . 0}$</td>
<td style="text-align: center;">0.6</td>
<td style="text-align: center;">0.3</td>
<td style="text-align: center;">$\mathbf{1 . 0}$</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">$\mathbf{1 . 0}$</td>
<td style="text-align: center;">0.7</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: left;">Flan-T5-xxl</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.7</td>
<td style="text-align: center;">$\mathbf{1 . 0}$</td>
<td style="text-align: center;">$\mathbf{0 . 7}$</td>
<td style="text-align: center;">$\mathbf{0 . 4}$</td>
<td style="text-align: center;">0.8</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">$\mathbf{1 . 0}$</td>
<td style="text-align: center;">0.8</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: left;">Flan-T5-xl</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">$\mathbf{0 . 9}$</td>
<td style="text-align: center;">$\mathbf{1 . 0}$</td>
<td style="text-align: center;">$\mathbf{0 . 7}$</td>
<td style="text-align: center;">$\mathbf{0 . 4}$</td>
<td style="text-align: center;">0.6</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">0.8</td>
<td style="text-align: center;">0.7</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: left;">Flan-T5-large</td>
<td style="text-align: center;">$\mathbf{0 . 9}$</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.9</td>
<td style="text-align: center;">0.4</td>
<td style="text-align: center;">0.2</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">0.8</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.0</td>
</tr>
<tr>
<td style="text-align: left;">T5-11b</td>
<td style="text-align: center;">0.8</td>
<td style="text-align: center;">0.7</td>
<td style="text-align: center;">0.8</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.1</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">0.4</td>
<td style="text-align: center;">0.8</td>
<td style="text-align: center;">0.0</td>
</tr>
</tbody>
</table>
<p>Table 1: Accuracy of the responses to the 20 stories ( 10 faux pas and 10 control) by different models on the 4 faux pas questions. The final test result is correct when all 4 sub-questions are marked as correct. Models with a final score of 0 were left out of the table (GPT2, GPT-J, Flan-T5{base, small}, T5{3b, large, base, small}). Compared to average recognition rate $(\mathrm{M}=0.82, \mathrm{SD}=0.156)$ of normally developed children, all models fail on the faux pas task.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Model</th>
<th style="text-align: center;">Cor- <br> rect</th>
<th style="text-align: center;">Cohe- <br> rent</th>
<th style="text-align: center;">Persu- <br> asive</th>
<th style="text-align: center;">Equi- <br> vocal</th>
<th style="text-align: center;">Personi- <br> fication</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">ChatGPT</td>
<td style="text-align: center;">18</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">20</td>
</tr>
<tr>
<td style="text-align: left;">GPT3</td>
<td style="text-align: center;">16</td>
<td style="text-align: center;">16</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr>
<td style="text-align: left;">Flan-T5-xxl</td>
<td style="text-align: center;">11</td>
<td style="text-align: center;">16</td>
<td style="text-align: center;">13</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr>
<td style="text-align: left;">Flan-T5-xl</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">18</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
</tr>
<tr>
<td style="text-align: left;">Flan-T5-large</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr>
<td style="text-align: left;">T5-11b</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">19</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
</tbody>
</table>
<p>Table 2: The "ELIZA effect" - assessment of tested language models on their responses to the 20 control and faux pas stories. The scores are the number of stories that meet the criteria. A high score indicates an illusion of understanding.</p>
<p>Coherent: Correct grammar, in-context response, the response makes sense, the discourse flows (e.g., there is grounding, full-long answer, finished sentence, there is an answer to the question asked). We ignored unnecessary dots or question marks.
Persuasive: Providing information beyond "Yes" or "No" that supports decision such as: (A) Partial knowledge of the situation, e.g., the ability to answer some other questions related to the situation correctly i.e., providing information about Q4 as a response to Q1 "scratch points" even if they were not asked about the information in the current question. (B) Wrong but logical answers (e.g., a scenario in low probability but not zero) or contains general world knowledge (e.g., "it expresses negative feelings towards people who work as ...", "possibly to avoid any further discomfort or embarrassment").
Equivocal: Providing non-decisive wrong answers ("difficult to say for sure", "might still have been perceived", "but it's not necessarily", "possible"). Personification: Speaking in a human-like manner ("It doesn't seem like", "I think").</p>
<p>Table 2 summarizes the assessment annotation. As seen, a few language models provide responses that appear to demonstrate a good understanding,
however, we will next show that this is often indeed an illusion.</p>
<h3>3.2 Results on the Faux Pas Closed-Task</h3>
<p>As indicated in Table 1, the performance of the models on faux pas tests is inadequate. The highest score achieved by any of the evaluated models is 0.4 , by Flan-T5-xxl and Flan-T5-xl, which is significantly lower than the average recognition rate of $0.82(\mathrm{SD}=0.156)$ reported for normally developing 9- to 11-year-old children (Baron-Cohen et al., 1999).</p>
<p>Another noteworthy result is that all models (except ChatGPT) ${ }^{6}$ performed poorly in Q2 of the control stories, achieving a score of 0 . In the faux pas stories, question Q2 "What did they say that they should not have said?" is asking for a specific problematic statement that was made in the story, whereas in the control stories (which are neutral stories that do not contain any problematic statements), question Q2 is based on a false assumption, that there is a problematic statement in the text. The models' responses were either picking an arbitrary utterance from the story or generating delusional text (compared to ChatGPT which simply responds with "There doesn't seem to be anything inappropriate or disrespectful said in the story."). This is despite the fact that some of the models even recognized that there was no problematic statement in the story and answered the first question correctly. The difficulty of models with presupposition questions is a well-known phenomenon in the QA domain, as reported in previous research (Yu et al., 2022; Kim et al., 2021; Rajpurkar et al., 2018).</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<table>
<thead>
<tr>
<th style="text-align: left;">Model</th>
<th style="text-align: center;">Coherent</th>
<th style="text-align: center;">Full <br> Faux Pas</th>
<th style="text-align: center;">Explicit <br> Faux Pas</th>
<th style="text-align: center;">Control</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">ChatGPT</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">$10^{*}$</td>
</tr>
<tr>
<td style="text-align: left;">GPT3</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">$10^{*}$</td>
</tr>
<tr>
<td style="text-align: left;">Flan-T5-xxl</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr>
<td style="text-align: left;">Flan-T5-xl</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
</tbody>
</table>
<p>Table 3: Assessment of the 20 stories generated by language models ( 10 control and 10 faux pas).</p>
<ul>
<li>Too simplistic; only clear positive/neutral attitude.</li>
</ul>
<h2>4 Study 2: Generation Abilities</h2>
<p>In this study, we developed instructions for creating faux pas stories, which included a definition of faux pas, examples of two stories that contain faux pas, and two corresponding control stories. The instructions also highlighted potential pitfalls and asked to generate 20 new diverse stories (for the full instructions see Appendix A.3).</p>
<p>A model's (ChatGPT, GPT3-text-davinci-003, FlanT5-xxl and FlanT5-xl) output was evaluated by the first and second authors, experts in NLP and in clinical psychology. The results are summarized in Table 3.</p>
<p>ChatGPT generated 8 faux pas stories (with corresponding control stories). However, the stories had a limitation in that they were all explicit, and failed to create implicit situations where one of the characters lacks information (e.g., explicitly mentioning "not realizing that the woman was one of the guests at the dinner party"). ${ }^{7,8}$ Additionally, all control stories were too simplistic and contained clear positive/neutral attitudes.</p>
<p>GPT3 generated 10 stories with corresponding control stories, however, none of the stories were faux pas. Although some of the stories contained something offensive, the offense was not caused by a lack of information. E.g., a bad faux pas story: Sara and her friends were at the mall. They were looking at clothes when one of her friends, Emily, said "I love this dress, but I don't think I can afford it." Sara then said "You don't have to worry about money, your parents are rich." Emily</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup>was embarrassed because she had forgotten that her parents were wealthy. In this story, Sara said something that is considered a bit rude and also caused Emily to feel embarrassed, but it wasn't a result of Sara's false belief (it did not happen because she didn't know something). In addition, people do not usually forget their parents are rich, and the embarrassment emotion is bizarre in this context (it is not indicated that Sara is poor).</p>
<p>In addition, the stories had other problems, such as non-coherent-emotions issues (i.e., not using the appropriate emotion to describe situations). E.g., a non-coherent emotion story: John and his family were visiting his grandmother for the weekend. His grandmother asked him how school was going and he said "It's okay, but I'm not doing very well in math." His grandmother then said "Oh, that's too bad. Your father was never very good at math either." John was embarrassed because he had forgotten that his father had struggled with math in school. Besides that it is definitely not a faux pas story, there is another problem with the emotional coherence - why does the fact that John had forgotten that his father had struggled with math in school make him embarrassed? This is not the appropriate emotion here.</p>
<p>Like ChatGPT's control stories, the control stories generated by GPT3 were also too simplistic. Flan-T5-xxl barely succeeded in creating stories and failed to create faux pas or control stories. Flan-T5-xl failed to create stories at all (See Appendix A. 4 for examples and issues).</p>
<h2>5 Conclusion and Future Work</h2>
<p>In conclusion, the results of this study demonstrate that large language models struggle with correctly identifying and responding to faux-pas situations. This suggests that these models do not possess a strong notion of social intelligence and theory of mind. Additionally, the phenomenon of the "ELIZA effect" was observed, where seemingly correct responses were found to be attributed to over-interpretation by the human reader. Furthermore, when the models were tasked with generating original faux pas stories, it was found that they were limited in their abilities to describe situations in an implicit manner. Future work will look for more clinical tests that challenge today's LLMs and develop large-scale datasets and methods to crack the challenge.</p>
<h2>Limitations</h2>
<p>It is important to note that the study is based on a limited set of examples and although it is enough to give a signal if a system is struggling or not in faux pas tests, the number of stories is not sufficient for statistically significant ranking between systems.</p>
<h2>Ethical Statement</h2>
<p>The study's scope did not include the representation of harm toward specific populations. The narratives were evaluated by a clinical psychologist to ensure that they did not contain offensive content. However, it is important to acknowledge the potential value of further research on the representation of harm in relation to culturally sensitive and socially controversial topics.</p>
<h2>Acknowledgements</h2>
<p>We would like to thank Vered Shwartz, Ori Shapira, Osnat Baron Singer, Tamar Nissenbaum Putter, Maya Sabag, Arie Cattan, Uri Katz, Mosh Levy, Aya Soffer, David Konopnicki, and IBM-Research staff members for helpful discussions and contributions, each in their own way. We thank the anonymous reviewers for their insightful comments and suggestions. This project was partially funded by the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation program, grant agreement No. 802774 (iEXTRACT); and by the Computer Science Department of Bar-Ilan University.</p>
<h2>References</h2>
<p>Simon Baron-Cohen, Michelle O'riordan, Valerie Stone, Rosie Jones, and Kate Plaisted. 1999. Recognition of faux pas by normally developing children and children with asperger syndrome or high-functioning autism. Journal of autism and developmental disorders, 29(5):407-418.</p>
<p>Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, et al. 2021. On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258.</p>
<p>Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33:1877-1901.</p>
<p>Yejin Choi. 2022. The curious case of commonsense intelligence. Daedalus, 151(2):139-155.</p>
<p>Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. 2022. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416.</p>
<p>Tom P Dowd and Jeff Tierney. 2005. Teaching social skills to youth: A step-by-step guide to 182 basic to complex skills plus helpful teaching techniques. Boys Town Press.</p>
<p>Jack Hessel, Ana Marasović, Jena D Hwang, Lillian Lee, Jeff Da, Rowan Zellers, Robert Mankoff, and Yejin Choi. 2022. Do Androids laugh at electric sheep? Humor "Understanding" benchmarks from the new yorker caption contest. arXiv preprint arXiv:2209.06293.</p>
<p>Najoung Kim, Ellie Pavlick, Burcu Karagol Ayan, and Deepak Ramachandran. 2021. Which linguist invented the lightbulb? Presupposition verification for question-answering. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 3932-3945, Online. Association for Computational Linguistics.</p>
<p>Joanna Korman, Tiziana Zalla, and Bertram F Malle. 2017. Action understanding in high-functioning autism: The faux pas task revisited. In CogSci.</p>
<p>Matthew Le, Y-Lan Boureau, and Maximilian Nickel. 2019. Revisiting the evaluation of theory of mind through question answering. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 5872-5877.</p>
<p>Bill Yuchen Lin, Wangchunshu Zhou, Ming Shen, Pei Zhou, Chandra Bhagavatula, Yejin Choi, and Xiang Ren. 2020. CommonGen: A constrained text generation challenge for generative commonsense reasoning. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 1823-1840, Online. Association for Computational Linguistics.</p>
<p>Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. 2021. Pretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing. arXiv preprint arXiv:2107.13586.</p>
<p>Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9.</p>
<p>Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, et al. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. J. Mach. Learn. Res., 21(140):1-67.</p>
<p>Pranav Rajpurkar, Robin Jia, and Percy Liang. 2018. Know what you don't know: Unanswerable questions for SQuAD. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 784-789, Melbourne, Australia. Association for Computational Linguistics.</p>
<p>Keisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. 2021. Winogrande: An adversarial winograd schema challenge at scale. Communications of the ACM, 64(9):99-106.</p>
<p>Maarten Sap, Ronan Le Bras, Daniel Fried, and Yejin Choi. 2022. Neural theory-of-mind? On the limits of social intelligence in large LMs. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pages 3762-3780, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.</p>
<p>Maarten Sap, Hannah Rashkin, Derek Chen, Ronan Le Bras, and Yejin Choi. 2019. Social IQa: Commonsense reasoning about social interactions. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 44634473, Hong Kong, China. Association for Computational Linguistics.</p>
<p>Natalie Shapira, Oren Kalinsky, Alex Libov, Chen Shani, and Sofia Tolmach. 2023. Evaluating humorous response generation to playful shopping requests. In Advances in Information Retrieval: 45th European Conference on Information Retrieval, ECIR 2023, Dublin, Ireland, April 2-6, 2023, Proceedings, Part II, pages 617-626. Springer.</p>
<p>Alon Talmor, Ori Yoran, Ronan Le Bras, Chandra Bhagavatula, Yoav Goldberg, Yejin Choi, and Jonathan Berant. 2022. CommonsenseQA 2.0: Exposing the limits of AI through gamification. https://openreview.net/forum?id=qF7FlUT5dxa.</p>
<p>Joseph Weizenbaum. 1976. Computer power and human reason: From judgment to calculation.</p>
<p>Heinz Wimmer and Josef Perner. 1983. Beliefs about beliefs: Representation and constraining function of wrong beliefs in young children's understanding of deception. Cognition, 13(1):103-128.</p>
<p>Xinyan Velocity Yu, Sewon Min, Luke Zettlemoyer, and Hannaneh Hajishirzi. 2022. CREPE: OpenDomain Question Answering with False Presuppositions. arXiv preprint arXiv:2211.17257.</p>
<p>Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi. 2019. HellaSwag: Can a machine really finish your sentence? In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4791-4800, Florence, Italy. Association for Computational Linguistics.</p>
<p>Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. 2023. A survey of large language models.</p>
<h2>A Appendices</h2>
<h2>A. 1 Generative LMs</h2>
<h2>A.1.1 Prompts</h2>
<p>As input to the LLMs, we used the 20 stories with the 4 questions (Q1-Q4) as appeared in (BaronCohen et al., 1999). For each question we created 3 versions:
$\mathrm{Q}<em i="i">{1}$ : The original question $\mathrm{Q}</em>$
$\mathrm{Q}<em i="i">{i}$-Elaborate: $\mathrm{Q}</em>+$ Explain your answer.
$\mathrm{Q}<em i="i">{i}$-Restricted: $\mathrm{Q}</em>+$ :</p>
<ul>
<li>$\mathrm{Q}_{1}$ : Answer with "Yes" or "No" only, without explanations. In case of doubt, answer according to the most probable answer.</li>
<li>$\mathrm{Q}_{2}$ : Answer with a quote only, without explanations.</li>
<li>$\mathrm{Q}_{3}$ : Answer the question only, without explanations.</li>
<li>$\mathrm{Q}_{4}$ : Answer with "Yes" or "No" only, without explanations. In case of doubt, answer according to the most probable answer.</li>
</ul>
<p>The prompt for ChatGPT, GPT3, FlanT5, GPT-J, and GPT2 were simply story with a question (one at a time). The prompt for T5 was a story with a question with the suffix Answer:[MASK] ${ }^{9}$</p>
<h2>A.1.2 Parameters</h2>
<p>GPT-2 (Radford et al., 2019). Python package transformers implementation (TFGPT2LMHeadModel, GPT2Tokenizer); tensorflow random set seed 0 ; Generation by generate function; do_sample=True; max_length=50; top_k=50; top_p=0.95;
GPT-J. ${ }^{10}$ Python package transformers implementation (AutoModelForCausalLM, AutoTokenizer); torch; Generation by generate function; do_sample=True; max_new_tokens=100; temperature=0.9; num_return_sequences=1; pad_token_id=50256; eos_token_id=50256
T5 (Raffel et al., 2020) . Python package transformers implementation (T5Tokenizer, T5Config, T5ForConditionalGeneration); torch; Generation by generate function; num_beams=10, num_return_sequences=10, max_length=20,</p>
<p><sup id="fnref6:0"><a class="footnote-ref" href="#fn:0">1</a></sup>eos_token_id=32098, pad_token_id=32098; forced_eos_token_id=32098; from_pretrained:t5small, t5-base, t5-large, t5-3b, t5-11b
FlanT5 (Chung et al., 2022). Python package transformers implementation (AutoModelForSeq2SeqLM, AutoTokenizer); torch; Generation by generate function; do_sample=True; max_length=50000, from_pretrained:google/flan-t5-small, google/flan-t5-base, google/flan-t5-large, google/flan-t5-xl, google/flan-t5-xxl
GPT3 (Brown et al., 2020). Python package openai model=text-davinci-003; Generation by Completion.create function; For the detection test - temperature $=0$, max_tokens=50 For the generation test - temperature $=0,0.1$ and 0.2 ; max_tokens=3390</p>
<p>ChatGPT. ${ }^{11}$ The default values within the website.</p>
<h2>A.1.3 The sampling method</h2>
<p>A single sample (the first) was selected from each model for the analysis of the stories.</p>
<h2>A.1.4 Hyperparameter</h2>
<p>Hyperparameters were chosen to minimize randomness and bring the most probable answer (i.e., low temperature, sampling method) and to be sufficient for the expected tokens.</p>
<h2>A. 2 Faux Pas Task and Responses</h2>
<p>Table 4 describes examples of faux pas and control stories with questions and ground truth responses. Table 5 describes examples of different question versions.</p>
<p>Figure 2 demonstrates the different dimensions on an example response</p>
<h2>A. 3 Faux Pas Generation Instructions</h2>
<p>The exact instructions as they were given appear on the next page (all page).</p>
<h2>A. 4 Faux Pas Generation Examples</h2>
<p>Table 7 describes generation examples.</p>
<p><sup id="fnref3:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<h1>A Faux Pas Story</h1>
<p>James bought Richard a toy airplane for his birthday. A few months later, they were playing with it, and James accidentally dropped it. "Don't worry" said Richard, "I never liked it anyway. Someone gave it to me for my birthday."
Q1. In the story did someone say something that they should not have said? Yes
Q2. What did they say that they should not have said?
"I never liked it anyway. Someone gave it to me for my birthday."
Q3. What did James give Richard for his birthday?
A toy airplane
Q4. Did Richard remember James had given him the toy airplane for his birthday? No</p>
<h2>A Control Story</h2>
<p>Simon bought Robert a toy car for his birthday. A few months later, they were playing with it, and Simon dropped it. "Don't worry," said Robert, "it was only an accident".
Q1. In the story did someone say something that they should not have said? No
Q2. What did they say that they should not have said?
(Not relevant)
Q3. What did Simon give Robert for his birthday?
A toy car
Q4. Did Simon know Robert had given him the toy car for his birthday? Yes</p>
<p>Table 4: Ground Truth. Example of a faux pas and corresponding control stories and questions with ground truth responses from (Baron-Cohen et al., 1999)</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Q1</th>
<th style="text-align: left;">In the story did someone say something that they should not have said?</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Q1-Elaborate</td>
<td style="text-align: left;">In the story did someone say something that they should not have said? <br> Explain your answer.</td>
</tr>
<tr>
<td style="text-align: left;">Q1-Restricted</td>
<td style="text-align: left;">In the story did someone say something that they should not have said? <br> Answer with "Yes" or "No" only, without explanations. In case of doubt, answer <br> according to the most probable answer.</td>
</tr>
<tr>
<td style="text-align: left;">Q2</td>
<td style="text-align: left;">What did they say that they should not have said?</td>
</tr>
<tr>
<td style="text-align: left;">Q2-Elaborate</td>
<td style="text-align: left;">What did they say that they should not have said? <br> Explain your answer.</td>
</tr>
<tr>
<td style="text-align: left;">Q2-Restricted</td>
<td style="text-align: left;">What did they say that they should not have said? <br> Answer with a quote only, without explanations.</td>
</tr>
<tr>
<td style="text-align: left;">Q3</td>
<td style="text-align: left;">What did James give Richard for his birthday?</td>
</tr>
<tr>
<td style="text-align: left;">Q3-Elaborate</td>
<td style="text-align: left;">What did James give Richard for his birthday? <br> Explain your answer.</td>
</tr>
<tr>
<td style="text-align: left;">Q3-Restricted</td>
<td style="text-align: left;">What did James give Richard for his birthday? <br> Answer the question only, without explanations.</td>
</tr>
<tr>
<td style="text-align: left;">Q4</td>
<td style="text-align: left;">Did Richard remember James had given him the toy airplane for his birthday?</td>
</tr>
<tr>
<td style="text-align: left;">Q4-Elaborate</td>
<td style="text-align: left;">Did Richard remember James had given him the toy airplane for his birthday? <br> Explain your answer.</td>
</tr>
<tr>
<td style="text-align: left;">Q4-Restricted</td>
<td style="text-align: left;">Did Richard remember James had given him the toy airplane for his birthday? <br> Answer with "Yes" or "No" only, without explanations. In case of doubt, answer <br> according to the most probable answer.</td>
</tr>
</tbody>
</table>
<p>Table 5: Example of question versions for the story described in Table 4.</p>
<p>Faux Pas Generation Instructions
Faux Pas is defined as "when a speaker says something without considering if it is something that the listener might not want to hear or know, and which typically has negative consequences that the speaker never intended" Here are two stories that contains faux pas:</p>
<p>Story 1:
All of the class took part in a story competition. Emma really wanted to win. Whilst she was away from school, the results of the competition were announced: Alice was the winner. The next day, Alice saw Emma and said "I'm sorry about your story." "What do you mean?" said Emma. "Oh nothing," said Alice.</p>
<p>In the story did someone say something that they should not have said?
Yes
What did they say that they should not have said?
"I'm sorry about your story."
Did Alice realize that Emma hadn't heard the results of the competition?
No
Story 2:
Robert had just started at a new school. He said to his new friend, Andrew, "My Mum is a dinner lady at this school." Then Claire came over and said, "I hate dinner ladies. They're horrible." "Do you want to come and play rounders?" Andrew asked Claire. "No" she replied "I'm not feeling very well."</p>
<p>In the story did someone say something that they should not have said?
Yes
What did they say that they should not have said?
"I hate dinner ladies. They're horrible."
Did Clare know that Robert's Mum was a dinner lady?
No</p>
<p>And here are two control stories (i.e., that do not contains faux pas):
Control Story 1:
All of the class took part in a poetry competition. Jane really wanted to win. While she was away, the results of the competition were announced: Mary was the winner. The next day, Jane bumped into Mary. Mary said "How are you feeling?". "Fine thanks?" said Jane, "Oh good" said Mary.</p>
<p>In the story did someone say something that they should not have said?
No
Control Story 2:
David had just started at a new school. He said to his new friend, Mike, "My Mum is a teacher in this school." Then Jeff came over. "I hate school" he told them, "It's so small." "Do you want to come and play rounders?" Mike asked Jeff. "No" he replied "I'm not feeling very well."</p>
<p>In the story did someone say something that they should not have said?
No
Create new 10 faux pas stories and 10 control stories, make sure that (1) the stories are diverse with different topics, places, names, situations, emotions (2) the stories contain conversation (at least 2 different quotes), (3) in the faux pas stories there is a sentence to cite which could be the answer to "What did they say that they should not have said?" (4) the faux pas story contain a character that didn't know/remember something and that's what causes the faux pas. (5) the control stories are similar to the faux pas stories, and that contains some conversation that might confuse like as if it contains a faux pas, but without faux pas</p>
<p>Table 6: Faux pas generation instructions</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Model</th>
<th style="text-align: center;">Faux pas</th>
<th style="text-align: center;">Control</th>
<th style="text-align: center;">Issues</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">ChatGPT</td>
<td style="text-align: center;">At a dinner party, Clair was telling a story about a trip she took. She mentioned a woman in the story and, not realizing that the woman was one of the guests at the dinner party, said, "She was the most annoying person I've ever met"</td>
<td style="text-align: center;">At a dinner party, Clair was telling a story about a trip she took. She mentioned a woman in the story and said, "She was very helpful during my trip"</td>
<td style="text-align: center;">Fail to describe situations in an implicit manner "not realizing that the woman was one of the guests at the dinner party" explaining explicitly the ToM perspective of the character to the reader. The control story is too simplistic.</td>
</tr>
<tr>
<td style="text-align: center;">GPT3- <br> text- <br> davinci- <br> 003</td>
<td style="text-align: center;">John and his family were visiting his grandmother for the weekend. His grandmother asked him how school was going and he said "It's okay, but I'm not doing very well in math." His grandmother then said "Oh, that's too bad. Your father was never very good at math either." John was embarrassed because he had forgotten that his father had struggled with math in school.</td>
<td style="text-align: center;">John and his family were visiting his grandmother for the weekend. His grandmother asked him how school was going and he said "It's okay, but I'm not doing very well in math." His grandmother then said "Oh, that's too bad. Have you tried studying with a tutor?"</td>
<td style="text-align: center;">Definitely not a faux pas story. In addition, there is a problem with the emotion coherent in the story - why does the fact that John had forgotten that his father had struggled with math in school make him embarrassed? This is not the appropriate emotion here. Here too (like in ChatGPT's control story), the control story is too simplistic.</td>
</tr>
<tr>
<td style="text-align: center;">Flan- <br> T5-xxl</td>
<td style="text-align: center;">As soon as she got to the school, Susan told her friend, Amanda about the dinner for her family.</td>
<td style="text-align: center;">Bob is very tall and strong, his workplace is surprising when I see him run from one point to another.</td>
<td style="text-align: center;">Only a sentence that lacks the basic elements of faux pas story (e.g., conversation). No match between faux pas and control story.</td>
</tr>
<tr>
<td style="text-align: center;">Flan- <br> T5-xl</td>
<td style="text-align: center;">A: "I'm sorry about your story" <br> B: "That's terrible." C: "I don't <br> know if that'll work.</td>
<td style="text-align: center;">$-$</td>
<td style="text-align: center;">Not even a story</td>
</tr>
</tbody>
</table>
<p>Table 7: Faux pas generation examples. A faux pas and corresponding control story by ChatGPT. Not a faux pas story by GPT3. Barely a story by FlanT5-xxl. Not even a story by FlanT5-xl</p>
<h1>A A For every submission:</h1>
<p>A1. Did you describe the limitations of your work?
Right after the conclusion section (the limitation section is on page 5)
A2. Did you discuss any potential risks of your work?
In the ethical section right after the limitation section
A3. Do the abstract and introduction summarize the paper's main claims?
abstract right after the title and section 1 for the introduction summarize the paper's main claims
A4. Have you used AI writing assistants when working on this paper?
I used chatGPT as a linguistic editor and improver in rephrasing</p>
<h2>B $\checkmark$ Did you use or create scientific artifacts?</h2>
<p>we annotated LMM responses for stories and create new stories
$\checkmark$ B1. Did you cite the creators of artifacts you used?
1,2
$\checkmark$ B2. Did you discuss the license or terms for use and / or distribution of any artifacts?
3 For reasons of anonymity, we have not left a direct link. There is a note in the footnote that the data will be published. It will be free to use.
$\checkmark$ B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided that it was specified? For the artifacts you create, do you specify intended use and whether that is compatible with the original access conditions (in particular, derivatives of data accessed for research purposes should not be used outside of research contexts)?
1,2 the data we used is for free use.
$\checkmark$ B4. Did you discuss the steps taken to check whether the data that was collected / used contains any information that names or uniquely identifies individual people or offensive content, and the steps taken to protect / anonymize it?
ethical section
$\checkmark$ B5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and linguistic phenomena, demographic groups represented, etc.?
3
$\checkmark$ B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits, etc. for the data that you used / created? Even for commonly-used benchmark datasets, include the number of examples in train / validation / test splits, as these provide necessary context for a reader to understand experimental results. For example, small differences in accuracy on large test sets may be significant, while on small test sets they may not be.
sections 3,4</p>
<h2>C Did you run computational experiments?</h2>
<p>3,4
C1. Did you report the number of parameters in the models used, the total computational budget (e.g., GPU hours), and computing infrastructure used?</p>
<p>A Appendices A. 1 Generative LMs We ran systems in zero-shot mode on a relatively small cluster of stories. Running time was negligible.</p>
<p>The Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing assistance.</p>
<p>C2. Did you discuss the experimental setup, including hyperparameter search and best-found hyperparameter values?
A.1.4
C3. Did you report descriptive statistics about your results (e.g., error bars around results, summary statistics from sets of experiments), and is it transparent whether you are reporting the max, mean, etc. or just a single run?
A.1.3
C4. If you used existing packages (e.g., for preprocessing, for normalization, or for evaluation), did you report the implementation, model, and parameter settings used (e.g., NLTK, Spacy, ROUGE, etc.)?
A.1.2</p>
<p>D Did you use human annotators (e.g., crowdworkers) or research with human participants? 3,4 (as written in the paper, the author of the papers annotated the data)
D1. Did you report the full text of instructions given to participants, including e.g., screenshots, disclaimers of any risks to participants or annotators, etc.?
3,4
D2. Did you report information about how you recruited (e.g., crowdsourcing platform, students) and paid participants, and discuss if such payment is adequate given the participants' demographic (e.g., country of residence)?
3,4 (as written in the paper, the author of the papers annotated the data)
D3. Did you discuss whether and how consent was obtained from people whose data you're using/curating? For example, if you collected data via crowdsourcing, did your instructions to crowdworkers explain how the data would be used?
3,4 (as written in the paper, the author of the papers annotated the data)
D4. Was the data collection protocol approved (or determined exempt) by an ethics review board? the data is annotations of LLM. we discuss potential risks at the ethical section
D5. Did you report the basic demographic and geographic characteristics of the annotator population that is the source of the data?
3,4 (as written in the paper, the author of the papers annotated the data)</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{9}$ [MASK] is a necessary part of the syntax and the addition of "Answer" is the result of an initial experiment that showed that this addition helps to reduce the incoherent texts.
${ }^{10}$ https://arankomatsuzaki.wordpress.com/2021/ 06/04/gpt-j/&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref6:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:1">
<p>${ }^{11}$ https://chat.openai.com/chat&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 2 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:1" title="Jump back to footnote 2 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:1" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>