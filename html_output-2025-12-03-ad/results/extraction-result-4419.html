<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4419 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4419</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4419</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-101.html">extraction-schema-101</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, criteria, metrics, or frameworks for evaluating LLM-generated scientific theories, hypotheses, or explanations, including comparisons with human-generated theories.</div>
                <p><strong>Paper ID:</strong> paper-280420957</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2508.01746v1.pdf" target="_blank">Bayes-Entropy Collaborative Driven Agents for Research Hypotheses Generation and Optimization</a></p>
                <p><strong>Paper Abstract:</strong> The exponential growth of scientific knowledge has made the automated generation of scientific hypotheses that combine novelty, feasibility, and research value a core challenge. Existing methods based on large language models fail to systematically model the inherent in hypotheses or incorporate the closed-loop feedback mechanisms crucial for refinement. This paper proposes a multi-agent collaborative framework called HypoAgents, which for the first time integrates Bayesian reasoning with an information entropy-driven search mechanism across three stages-hypotheses generation, evidence validation, and hypotheses Refinement-to construct an iterative closed-loop simulating scientists'cognitive processes. Specifically, the framework first generates an initial set of hypotheses through diversity sampling and establishes prior beliefs based on a composite novelty-relevance-feasibility (N-R-F) score. It then employs etrieval-augmented generation (RAG) to gather external literature evidence, updating the posterior probabilities of hypotheses using Bayes'theorem. Finally, it identifies high-uncertainty hypotheses using information entropy $H = - \sum {{p_i}\log {p_i}}$ and actively refines them, guiding the iterative optimization of the hypothesis set toward higher quality and confidence. Experimental results on the ICLR 2025 conference real-world research question dataset (100 research questions) show that after 12 optimization iterations, the average ELO score of generated hypotheses improves by 116.3, surpassing the benchmark of real paper abstracts by 17.8, while the framework's overall uncertainty, as measured by Shannon entropy, decreases significantly by 0.92. This study presents an interpretable probabilistic reasoning framework for automated scientific discovery, substantially improving the quality and reliability of machine-generated research hypotheses.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e4419.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e4419.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, criteria, metrics, or frameworks for evaluating LLM-generated scientific theories, hypotheses, or explanations, including comparisons with human-generated theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HypoAgents Bayes-Entropy Framework</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>HypoAgents: Bayesian Belief Updating with Entropy-Driven Search for Hypothesis Optimization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A closed-loop multi-agent framework that generates, validates, and iteratively refines research hypotheses by combining LLM-based generation and evaluation with Bayesian posterior updates and information-theoretic uncertainty control (Shannon entropy) to steer exploration vs. convergence.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_name</strong></td>
                            <td>Bayes-Entropy Evaluation Framework (HypoAgents)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_description</strong></td>
                            <td>Starts from an LLM-generated set of diverse hypotheses with prior beliefs given by a normalized composite novelty–relevance–feasibility (N‑R‑F) score; retrieves literature evidence via RAG for each hypothesis; computes likelihoods of evidence given each hypothesis using an LLM probabilistic evaluator and a methodological-alignment classifier; updates hypothesis beliefs via Bayes' rule to obtain posteriors; monitors global uncertainty with Shannon entropy and selects high-uncertainty hypotheses (via binary entropy) for targeted refinement strategies (Deepening, Counterfactual, Hybridization). Termination conditions include entropy convergence threshold or maximum iterations.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_criteria</strong></td>
                            <td>Novelty, Relevance, Feasibility (N‑R‑F) for priors; evidence likelihood / methodological alignment for empirical support; posterior belief mass for confidence; Shannon entropy for global uncertainty/convergence; binary entropy per hypothesis for selection for refinement; ELO score (via LLM pairwise comparison) for comparative quality against human paper abstracts.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Machine learning / Artificial intelligence (research-hypothesis generation)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>Research hypotheses (methodological/explanatory proposals for ML problems)</td>
                        </tr>
                        <tr>
                            <td><strong>human_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_results</strong></td>
                            <td>Applied to 100 ICLR-2025 research questions: after 12 optimization iterations average ELO increased by 116.27 points and exceeded the benchmark of real paper abstracts by 17.77 points; overall Shannon entropy decreased by 0.92. Ablations show sensitivity to iteration count, hypothesis pool size, and refinement threshold (detailed numeric results in paper tables).</td>
                        </tr>
                        <tr>
                            <td><strong>automated_vs_human_evaluation</strong></td>
                            <td>Primarily automated: evidence retrieval and probabilistic evaluation use LLMs; comparative quality measured by LLM-based pairwise ELO comparisons vs human-authored paper abstracts. Human involvement limited to dataset/question selection and manual check of extracted research questions; no reported expert-rating study.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Empirical validation on a benchmark constructed from Top-100 ICLR-2025 papers: created 100 research questions, built per-question literature KB (928 reference papers), then measured internal metrics (posterior beliefs, entropy) and external comparative metric (ELO via LLM pairwise comparison against real abstracts). No reported correlation with independent human expert ratings or inter-rater reliability.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Relies on LLMs both to generate and to evaluate hypotheses (risk of model bias and circularity); evidence scoring susceptible to LLM scoring errors (mitigated by averaging); static, text-only knowledge base (omits figures/code); heuristic refinement policies (not learned); sensitivity to hyperparameters (n, T, τ_s); validation lacks human expert adjudication or external ground-truth beyond paper abstracts.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>100 representative research questions extracted from Top-100 ICLR 2025 papers, with a per-question vectorized literature knowledge base built from 928 reference papers parsed from those papers' references.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Bayes-Entropy Collaborative Driven Agents for Research Hypotheses Generation and Optimization', 'publication_date_yy_mm': '2025-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4419.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e4419.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, criteria, metrics, or frameworks for evaluating LLM-generated scientific theories, hypotheses, or explanations, including comparisons with human-generated theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-Evaluated ELO Score</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ELO Score via LLM Pairwise Comparisons (adapted to hypotheses)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An adapted ELO rating system where an LLM acts as a pairwise reviewer to judge which of two hypotheses (or hypothesis vs. a human paper abstract) is superior; outcomes update dynamic ELO ratings to quantify comparative hypothesis quality over iterations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_name</strong></td>
                            <td>LLM-mediated ELO Rating</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_description</strong></td>
                            <td>For each research question, hypotheses produced across iterations are compared pairwise with each other and with the actual published paper abstract; an LLM reviewer selects the superior item per pair. Pairwise results are converted into ELO ratings (dynamically updated) so average ELO over hypotheses measures relative quality and improvement across iterations.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_criteria</strong></td>
                            <td>Comparative judged superiority in pairwise comparisons (as determined by the LLM reviewer); aggregated into ELO to capture relative ranking and progress across iterations.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Machine learning / AI research hypotheses</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>Comparative quality ranking of research hypotheses (evaluation-focused metric)</td>
                        </tr>
                        <tr>
                            <td><strong>human_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_results</strong></td>
                            <td>Reported numeric outcomes: average ELO improvement (ELO Δ) per experimental condition—e.g., T=8 Δ=59.17 (ΔH=-0.32), T=10 Δ=73.33 (ΔH=-0.38), T=12 Δ=116.27 (ΔH=-0.92); n=5 Δ=59.17 (ΔH=-0.32), n=10 Δ=116.60 (ΔH=-1.17), n=15 Δ=82.49 (ΔH=-0.56); τ_s experiments: τ_s=0.3 Δ=59.17 (ΔH=-0.32), τ_s=0.5 Δ=102.55 (ΔH=-0.63), τ_s=0.7 Δ=30.87 (ΔH=-0.25). Overall the framework's final average ELO surpassed real paper abstracts by 17.77 points in the main reported run.</td>
                        </tr>
                        <tr>
                            <td><strong>automated_vs_human_evaluation</strong></td>
                            <td>Automated: LLM used as the sole reviewer for pairwise judgments; no human expert pairwise judgments reported.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Validation is internal: ELO changes tracked across controlled experimental conditions on the ICLR-derived dataset. No external human adjudication or cross-checks with independent expert panels reported.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Using an LLM both to generate and to judge hypotheses risks circularity and bias; ELO reflects relative preferences of the LLM reviewer which may not match human expert judgments; absence of inter-rater reliability or human benchmarking limits external validity.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Same ICLR-2025 Top-100-derived research question set and associated literature KB; pairwise comparisons performed per question.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Bayes-Entropy Collaborative Driven Agents for Research Hypotheses Generation and Optimization', 'publication_date_yy_mm': '2025-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4419.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e4419.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, criteria, metrics, or frameworks for evaluating LLM-generated scientific theories, hypotheses, or explanations, including comparisons with human-generated theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Shannon Entropy Uncertainty Metric</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Global Shannon Entropy and Binary Entropy for Hypothesis Uncertainty</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Uses Shannon entropy on the posterior belief distribution to quantify global uncertainty across the hypothesis set and binary entropy of an individual hypothesis belief to identify maximal-uncertainty candidates for refinement.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_name</strong></td>
                            <td>Entropy-based Uncertainty Monitoring</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_description</strong></td>
                            <td>Global uncertainty H_k = −Σ_i B_k(h_i) log2 B_k(h_i) tracks convergence across iterations; individual uncertainty scored by binary entropy S_k(h_i) = −B log2 B − (1−B) log2(1−B) which peaks near belief=0.5 and is used to select hypotheses for refinement when above a threshold τ_s. Iterative optimization aims to reduce H over rounds; termination may be triggered when |H_k−H_{k−1}| < ε_H.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_criteria</strong></td>
                            <td>Global uncertainty reduction (ΔH) as an indicator of convergence and increasing confidence in retained hypotheses; per-hypothesis binary entropy to prioritize high-uncertainty candidates for active refinement.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Machine learning / AI research-hypothesis generation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>Quantitative uncertainty measures applied to hypothesis belief distributions</td>
                        </tr>
                        <tr>
                            <td><strong>human_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_results</strong></td>
                            <td>Observed entropy decreases across experiments: e.g., ΔH = -0.92 for T=12 run; different hyperparameter settings produced ΔH values in the paper's tables (e.g., n=10 ΔH=-1.17). Entropy trends correlated with improved ELO scores in reported experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>automated_vs_human_evaluation</strong></td>
                            <td>Automated metric computed from posterior beliefs; used internally to drive selection and termination decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Validated indirectly by showing co-variation with ELO improvements (internal experiment results). No external human validation reported.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Entropy reduction does not guarantee scientific correctness—only increased internal confidence given the evidence model; sensitive to how priors and likelihoods are computed; threshold and stopping criteria selection impact outcomes and require tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Bayes-Entropy Collaborative Driven Agents for Research Hypotheses Generation and Optimization', 'publication_date_yy_mm': '2025-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4419.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e4419.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, criteria, metrics, or frameworks for evaluating LLM-generated scientific theories, hypotheses, or explanations, including comparisons with human-generated theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>N‑R‑F Prior Scoring</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Composite Novelty–Relevance–Feasibility (N‑R‑F) Prior Scoring</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An LLM-based evaluator assigns normalized scores for novelty, relevance, and feasibility to construct initial prior belief weights over generated hypotheses as a weighted sum with tunable α, β, γ.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_name</strong></td>
                            <td>N‑R‑F Composite Prior Scoring</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_description</strong></td>
                            <td>Each hypothesis h_i receives scores N(h_i), R(h_i), F(h_i) ∈ [0,1] from an LLM evaluator; priors B_0(h_i) are computed as normalized weighted sums B_0(h_i) = [αN + βR + γF] / Σ_j [αN_j + βR_j + γF_j], with α+β+γ=1. These priors seed the Bayesian updating loop.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_criteria</strong></td>
                            <td>Novelty, Relevance to the research question, and empirical/experimental Feasibility; relative weighting (α,β,γ) encodes importance trade-offs between dimensions.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Machine learning / AI research-hypothesis generation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>Prior scoring for research hypotheses (multi-criteria assessment)</td>
                        </tr>
                        <tr>
                            <td><strong>human_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_results</strong></td>
                            <td>Used to initialize belief distribution; no standalone numeric validation reported beyond downstream effects observed in posterior evolution and final ELO/entropy results.</td>
                        </tr>
                        <tr>
                            <td><strong>automated_vs_human_evaluation</strong></td>
                            <td>Automated: LLM-based scoring used to compute priors; human role limited to design of weighting hyperparameters and interpretation.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Indirect: effect of priors assessed via overall experimental outcomes (ELO and entropy trajectories); no independent human-rated priors or cross-validation reported.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Dependence on LLM judgments for subjective criteria (novelty, feasibility) can inject bias; choice of α,β,γ affects results and requires tuning; no reported ground-truth labels for these dimensions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Bayes-Entropy Collaborative Driven Agents for Research Hypotheses Generation and Optimization', 'publication_date_yy_mm': '2025-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4419.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e4419.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, criteria, metrics, or frameworks for evaluating LLM-generated scientific theories, hypotheses, or explanations, including comparisons with human-generated theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-based Likelihood + Method Alignment</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Dual-Evidence Likelihood Estimation: LLM Base Likelihood × Methodological Alignment</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A two-part evidence evaluation where an LLM provides a continuous base likelihood P(d_j | h_i) and a second LLM-based binary classifier indicates whether a retrieved evidence snippet contains methodological elements that substantively test or support the hypothesis; per-snippet contributions are multiplied and averaged to form the hypothesis likelihood.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_name</strong></td>
                            <td>LLM Likelihood Estimation with Methodological Alignment</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_description</strong></td>
                            <td>For each retrieved evidence snippet d_j for hypothesis h_i: compute L_base(d_j|h_i) ∈ [0,1] from an LLM prompt asking the probability of observing d_j if h_i were true; compute M(d_j, h_i) ∈ {0,1} via an LLM classifier that flags methodological support; per-snippet contribution L(d_j|h_i) = L_base × M; aggregate across m snippets by arithmetic mean L(D_i|h_i) = (1/m) Σ_j L(d_j|h_i). Posterior update applies Bayes' rule with these likelihoods.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_criteria</strong></td>
                            <td>Likelihood of observed literature evidence under each hypothesis and presence/absence of methodological elements (supporting tests) in evidence snippets.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Machine learning / AI research-hypothesis evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>Evidence-to-hypothesis likelihood estimation / empirical support scoring</td>
                        </tr>
                        <tr>
                            <td><strong>human_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_results</strong></td>
                            <td>Used throughout the Bayesian updating process; no absolute calibration numbers reported, but posterior belief trajectories and downstream ELO/entropy improvements reflect the impact of these likelihoods. Authors note averaging chosen to reduce sensitivity to individual low-quality snippet scores.</td>
                        </tr>
                        <tr>
                            <td><strong>automated_vs_human_evaluation</strong></td>
                            <td>Automated: both continuous likelihood and methodological-alignment judgments are produced by LLM prompts/classifiers.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Internal validation by running the iterative pipeline on the ICLR dataset and observing convergence patterns and improved ELO; no separate calibration against human-labeled likelihoods or methodological matches reported.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Binary methodological alignment (0/1) is coarse and may under-represent partial methodological relevance; using LLMs to score evidence introduces risks of model overconfidence or systematic error; averaging (rather than multiplicative probability accumulation) trades theoretical correctness for robustness to noisy LLM outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Bayes-Entropy Collaborative Driven Agents for Research Hypotheses Generation and Optimization', 'publication_date_yy_mm': '2025-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4419.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e4419.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods, criteria, metrics, or frameworks for evaluating LLM-generated scientific theories, hypotheses, or explanations, including comparisons with human-generated theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Refinement Selection & Strategies</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Entropy-Guided Refinement Selection with Heuristic Strategies (Deepening, Counterfactual, Hybridization)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Uses per-hypothesis binary entropy to select high-uncertainty hypotheses for targeted refinement, applying one of three heuristic strategies to produce candidate revisions that re-enter the Bayesian-entropy loop.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_name</strong></td>
                            <td>Entropy-Guided Refinement + Heuristic Strategy Selection</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method_description</strong></td>
                            <td>Compute binary entropy per hypothesis; if S_k(h_i) exceeds refinement threshold τ_s, select h_i for refinement. Apply one chosen strategy: A) Deepening (increase specificity/operationalization), B) Counterfactual (generate and test alternative/negation), or C) Hybridization (recombine elements from multiple uncertain hypotheses). The refined hypothesis replaces the original and the system re-evaluates evidence and posteriors.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_criteria</strong></td>
                            <td>Selection based on individual uncertainty (binary entropy) and subsequent improvement measured by posterior belief increase, entropy reduction, and ELO improvement. Threshold τ_s controls exploration vs exploitation.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Machine learning / AI research-hypothesis optimization</td>
                        </tr>
                        <tr>
                            <td><strong>theory_type</strong></td>
                            <td>Operational refinement and optimization of research hypotheses</td>
                        </tr>
                        <tr>
                            <td><strong>human_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_results</strong></td>
                            <td>Empirically shown to affect outcomes: τ_s tuning produced different ELO and entropy outcomes (best reported τ_s=0.5 in experiments). Deepening produced more specific, testable hypotheses in the case study; overall framework convergence improved with appropriate τ_s and iteration counts.</td>
                        </tr>
                        <tr>
                            <td><strong>automated_vs_human_evaluation</strong></td>
                            <td>Automated selection/production via LLM-guided heuristics; evaluation of refined hypotheses then proceeds via the automated Bayesian-evidence loop and ELO comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_method</strong></td>
                            <td>Empirical demonstration across ablations: varying τ_s, n, and T and reporting resulting ELO and entropy changes. No learned policy or external human validation yet.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_challenges</strong></td>
                            <td>Refinement strategies are heuristic (not learned), so suboptimal strategy selection may occur; threshold τ_s must be tuned to avoid over-refinement or premature elimination; absence of a learned policy reduces adaptability across domains.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Bayes-Entropy Collaborative Driven Agents for Research Hypotheses Generation and Optimization', 'publication_date_yy_mm': '2025-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>ResearchAgent: Iterative Research Idea Generation over Scientific Literature with Large Language Models <em>(Rating: 2)</em></li>
                <li>Learn2Gen: Learning to Generate Research Idea with Dynamic Control <em>(Rating: 2)</em></li>
                <li>Nova: An Iterative Planning and Search Approach to Enhance Novelty and Diversity of LLM Generated Ideas <em>(Rating: 2)</em></li>
                <li>The AI Scientist-v2: Workshop-level Automated Scientific Discovery via Agentic Tree Search <em>(Rating: 2)</em></li>
                <li>MOOSE-Chem: Large Language Models for Rediscovering Unseen Chemistry Scientific Hypotheses <em>(Rating: 1)</em></li>
                <li>IdeaSynth: Iterative Research Idea Development Through Evolving and Composing Idea Facets with Literature-Grounded Feedback <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4419",
    "paper_id": "paper-280420957",
    "extraction_schema_id": "extraction-schema-101",
    "extracted_data": [
        {
            "name_short": "HypoAgents Bayes-Entropy Framework",
            "name_full": "HypoAgents: Bayesian Belief Updating with Entropy-Driven Search for Hypothesis Optimization",
            "brief_description": "A closed-loop multi-agent framework that generates, validates, and iteratively refines research hypotheses by combining LLM-based generation and evaluation with Bayesian posterior updates and information-theoretic uncertainty control (Shannon entropy) to steer exploration vs. convergence.",
            "citation_title": "here",
            "mention_or_use": "use",
            "evaluation_method_name": "Bayes-Entropy Evaluation Framework (HypoAgents)",
            "evaluation_method_description": "Starts from an LLM-generated set of diverse hypotheses with prior beliefs given by a normalized composite novelty–relevance–feasibility (N‑R‑F) score; retrieves literature evidence via RAG for each hypothesis; computes likelihoods of evidence given each hypothesis using an LLM probabilistic evaluator and a methodological-alignment classifier; updates hypothesis beliefs via Bayes' rule to obtain posteriors; monitors global uncertainty with Shannon entropy and selects high-uncertainty hypotheses (via binary entropy) for targeted refinement strategies (Deepening, Counterfactual, Hybridization). Termination conditions include entropy convergence threshold or maximum iterations.",
            "evaluation_criteria": "Novelty, Relevance, Feasibility (N‑R‑F) for priors; evidence likelihood / methodological alignment for empirical support; posterior belief mass for confidence; Shannon entropy for global uncertainty/convergence; binary entropy per hypothesis for selection for refinement; ELO score (via LLM pairwise comparison) for comparative quality against human paper abstracts.",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "Machine learning / Artificial intelligence (research-hypothesis generation)",
            "theory_type": "Research hypotheses (methodological/explanatory proposals for ML problems)",
            "human_comparison": true,
            "evaluation_results": "Applied to 100 ICLR-2025 research questions: after 12 optimization iterations average ELO increased by 116.27 points and exceeded the benchmark of real paper abstracts by 17.77 points; overall Shannon entropy decreased by 0.92. Ablations show sensitivity to iteration count, hypothesis pool size, and refinement threshold (detailed numeric results in paper tables).",
            "automated_vs_human_evaluation": "Primarily automated: evidence retrieval and probabilistic evaluation use LLMs; comparative quality measured by LLM-based pairwise ELO comparisons vs human-authored paper abstracts. Human involvement limited to dataset/question selection and manual check of extracted research questions; no reported expert-rating study.",
            "validation_method": "Empirical validation on a benchmark constructed from Top-100 ICLR-2025 papers: created 100 research questions, built per-question literature KB (928 reference papers), then measured internal metrics (posterior beliefs, entropy) and external comparative metric (ELO via LLM pairwise comparison against real abstracts). No reported correlation with independent human expert ratings or inter-rater reliability.",
            "limitations_challenges": "Relies on LLMs both to generate and to evaluate hypotheses (risk of model bias and circularity); evidence scoring susceptible to LLM scoring errors (mitigated by averaging); static, text-only knowledge base (omits figures/code); heuristic refinement policies (not learned); sensitivity to hyperparameters (n, T, τ_s); validation lacks human expert adjudication or external ground-truth beyond paper abstracts.",
            "benchmark_dataset": "100 representative research questions extracted from Top-100 ICLR 2025 papers, with a per-question vectorized literature knowledge base built from 928 reference papers parsed from those papers' references.",
            "uuid": "e4419.0",
            "source_info": {
                "paper_title": "Bayes-Entropy Collaborative Driven Agents for Research Hypotheses Generation and Optimization",
                "publication_date_yy_mm": "2025-08"
            }
        },
        {
            "name_short": "LLM-Evaluated ELO Score",
            "name_full": "ELO Score via LLM Pairwise Comparisons (adapted to hypotheses)",
            "brief_description": "An adapted ELO rating system where an LLM acts as a pairwise reviewer to judge which of two hypotheses (or hypothesis vs. a human paper abstract) is superior; outcomes update dynamic ELO ratings to quantify comparative hypothesis quality over iterations.",
            "citation_title": "here",
            "mention_or_use": "use",
            "evaluation_method_name": "LLM-mediated ELO Rating",
            "evaluation_method_description": "For each research question, hypotheses produced across iterations are compared pairwise with each other and with the actual published paper abstract; an LLM reviewer selects the superior item per pair. Pairwise results are converted into ELO ratings (dynamically updated) so average ELO over hypotheses measures relative quality and improvement across iterations.",
            "evaluation_criteria": "Comparative judged superiority in pairwise comparisons (as determined by the LLM reviewer); aggregated into ELO to capture relative ranking and progress across iterations.",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "Machine learning / AI research hypotheses",
            "theory_type": "Comparative quality ranking of research hypotheses (evaluation-focused metric)",
            "human_comparison": true,
            "evaluation_results": "Reported numeric outcomes: average ELO improvement (ELO Δ) per experimental condition—e.g., T=8 Δ=59.17 (ΔH=-0.32), T=10 Δ=73.33 (ΔH=-0.38), T=12 Δ=116.27 (ΔH=-0.92); n=5 Δ=59.17 (ΔH=-0.32), n=10 Δ=116.60 (ΔH=-1.17), n=15 Δ=82.49 (ΔH=-0.56); τ_s experiments: τ_s=0.3 Δ=59.17 (ΔH=-0.32), τ_s=0.5 Δ=102.55 (ΔH=-0.63), τ_s=0.7 Δ=30.87 (ΔH=-0.25). Overall the framework's final average ELO surpassed real paper abstracts by 17.77 points in the main reported run.",
            "automated_vs_human_evaluation": "Automated: LLM used as the sole reviewer for pairwise judgments; no human expert pairwise judgments reported.",
            "validation_method": "Validation is internal: ELO changes tracked across controlled experimental conditions on the ICLR-derived dataset. No external human adjudication or cross-checks with independent expert panels reported.",
            "limitations_challenges": "Using an LLM both to generate and to judge hypotheses risks circularity and bias; ELO reflects relative preferences of the LLM reviewer which may not match human expert judgments; absence of inter-rater reliability or human benchmarking limits external validity.",
            "benchmark_dataset": "Same ICLR-2025 Top-100-derived research question set and associated literature KB; pairwise comparisons performed per question.",
            "uuid": "e4419.1",
            "source_info": {
                "paper_title": "Bayes-Entropy Collaborative Driven Agents for Research Hypotheses Generation and Optimization",
                "publication_date_yy_mm": "2025-08"
            }
        },
        {
            "name_short": "Shannon Entropy Uncertainty Metric",
            "name_full": "Global Shannon Entropy and Binary Entropy for Hypothesis Uncertainty",
            "brief_description": "Uses Shannon entropy on the posterior belief distribution to quantify global uncertainty across the hypothesis set and binary entropy of an individual hypothesis belief to identify maximal-uncertainty candidates for refinement.",
            "citation_title": "here",
            "mention_or_use": "use",
            "evaluation_method_name": "Entropy-based Uncertainty Monitoring",
            "evaluation_method_description": "Global uncertainty H_k = −Σ_i B_k(h_i) log2 B_k(h_i) tracks convergence across iterations; individual uncertainty scored by binary entropy S_k(h_i) = −B log2 B − (1−B) log2(1−B) which peaks near belief=0.5 and is used to select hypotheses for refinement when above a threshold τ_s. Iterative optimization aims to reduce H over rounds; termination may be triggered when |H_k−H_{k−1}| &lt; ε_H.",
            "evaluation_criteria": "Global uncertainty reduction (ΔH) as an indicator of convergence and increasing confidence in retained hypotheses; per-hypothesis binary entropy to prioritize high-uncertainty candidates for active refinement.",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "Machine learning / AI research-hypothesis generation",
            "theory_type": "Quantitative uncertainty measures applied to hypothesis belief distributions",
            "human_comparison": false,
            "evaluation_results": "Observed entropy decreases across experiments: e.g., ΔH = -0.92 for T=12 run; different hyperparameter settings produced ΔH values in the paper's tables (e.g., n=10 ΔH=-1.17). Entropy trends correlated with improved ELO scores in reported experiments.",
            "automated_vs_human_evaluation": "Automated metric computed from posterior beliefs; used internally to drive selection and termination decisions.",
            "validation_method": "Validated indirectly by showing co-variation with ELO improvements (internal experiment results). No external human validation reported.",
            "limitations_challenges": "Entropy reduction does not guarantee scientific correctness—only increased internal confidence given the evidence model; sensitive to how priors and likelihoods are computed; threshold and stopping criteria selection impact outcomes and require tuning.",
            "uuid": "e4419.2",
            "source_info": {
                "paper_title": "Bayes-Entropy Collaborative Driven Agents for Research Hypotheses Generation and Optimization",
                "publication_date_yy_mm": "2025-08"
            }
        },
        {
            "name_short": "N‑R‑F Prior Scoring",
            "name_full": "Composite Novelty–Relevance–Feasibility (N‑R‑F) Prior Scoring",
            "brief_description": "An LLM-based evaluator assigns normalized scores for novelty, relevance, and feasibility to construct initial prior belief weights over generated hypotheses as a weighted sum with tunable α, β, γ.",
            "citation_title": "here",
            "mention_or_use": "use",
            "evaluation_method_name": "N‑R‑F Composite Prior Scoring",
            "evaluation_method_description": "Each hypothesis h_i receives scores N(h_i), R(h_i), F(h_i) ∈ [0,1] from an LLM evaluator; priors B_0(h_i) are computed as normalized weighted sums B_0(h_i) = [αN + βR + γF] / Σ_j [αN_j + βR_j + γF_j], with α+β+γ=1. These priors seed the Bayesian updating loop.",
            "evaluation_criteria": "Novelty, Relevance to the research question, and empirical/experimental Feasibility; relative weighting (α,β,γ) encodes importance trade-offs between dimensions.",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "Machine learning / AI research-hypothesis generation",
            "theory_type": "Prior scoring for research hypotheses (multi-criteria assessment)",
            "human_comparison": false,
            "evaluation_results": "Used to initialize belief distribution; no standalone numeric validation reported beyond downstream effects observed in posterior evolution and final ELO/entropy results.",
            "automated_vs_human_evaluation": "Automated: LLM-based scoring used to compute priors; human role limited to design of weighting hyperparameters and interpretation.",
            "validation_method": "Indirect: effect of priors assessed via overall experimental outcomes (ELO and entropy trajectories); no independent human-rated priors or cross-validation reported.",
            "limitations_challenges": "Dependence on LLM judgments for subjective criteria (novelty, feasibility) can inject bias; choice of α,β,γ affects results and requires tuning; no reported ground-truth labels for these dimensions.",
            "uuid": "e4419.3",
            "source_info": {
                "paper_title": "Bayes-Entropy Collaborative Driven Agents for Research Hypotheses Generation and Optimization",
                "publication_date_yy_mm": "2025-08"
            }
        },
        {
            "name_short": "LLM-based Likelihood + Method Alignment",
            "name_full": "Dual-Evidence Likelihood Estimation: LLM Base Likelihood × Methodological Alignment",
            "brief_description": "A two-part evidence evaluation where an LLM provides a continuous base likelihood P(d_j | h_i) and a second LLM-based binary classifier indicates whether a retrieved evidence snippet contains methodological elements that substantively test or support the hypothesis; per-snippet contributions are multiplied and averaged to form the hypothesis likelihood.",
            "citation_title": "here",
            "mention_or_use": "use",
            "evaluation_method_name": "LLM Likelihood Estimation with Methodological Alignment",
            "evaluation_method_description": "For each retrieved evidence snippet d_j for hypothesis h_i: compute L_base(d_j|h_i) ∈ [0,1] from an LLM prompt asking the probability of observing d_j if h_i were true; compute M(d_j, h_i) ∈ {0,1} via an LLM classifier that flags methodological support; per-snippet contribution L(d_j|h_i) = L_base × M; aggregate across m snippets by arithmetic mean L(D_i|h_i) = (1/m) Σ_j L(d_j|h_i). Posterior update applies Bayes' rule with these likelihoods.",
            "evaluation_criteria": "Likelihood of observed literature evidence under each hypothesis and presence/absence of methodological elements (supporting tests) in evidence snippets.",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "Machine learning / AI research-hypothesis evaluation",
            "theory_type": "Evidence-to-hypothesis likelihood estimation / empirical support scoring",
            "human_comparison": false,
            "evaluation_results": "Used throughout the Bayesian updating process; no absolute calibration numbers reported, but posterior belief trajectories and downstream ELO/entropy improvements reflect the impact of these likelihoods. Authors note averaging chosen to reduce sensitivity to individual low-quality snippet scores.",
            "automated_vs_human_evaluation": "Automated: both continuous likelihood and methodological-alignment judgments are produced by LLM prompts/classifiers.",
            "validation_method": "Internal validation by running the iterative pipeline on the ICLR dataset and observing convergence patterns and improved ELO; no separate calibration against human-labeled likelihoods or methodological matches reported.",
            "limitations_challenges": "Binary methodological alignment (0/1) is coarse and may under-represent partial methodological relevance; using LLMs to score evidence introduces risks of model overconfidence or systematic error; averaging (rather than multiplicative probability accumulation) trades theoretical correctness for robustness to noisy LLM outputs.",
            "uuid": "e4419.4",
            "source_info": {
                "paper_title": "Bayes-Entropy Collaborative Driven Agents for Research Hypotheses Generation and Optimization",
                "publication_date_yy_mm": "2025-08"
            }
        },
        {
            "name_short": "Refinement Selection & Strategies",
            "name_full": "Entropy-Guided Refinement Selection with Heuristic Strategies (Deepening, Counterfactual, Hybridization)",
            "brief_description": "Uses per-hypothesis binary entropy to select high-uncertainty hypotheses for targeted refinement, applying one of three heuristic strategies to produce candidate revisions that re-enter the Bayesian-entropy loop.",
            "citation_title": "here",
            "mention_or_use": "use",
            "evaluation_method_name": "Entropy-Guided Refinement + Heuristic Strategy Selection",
            "evaluation_method_description": "Compute binary entropy per hypothesis; if S_k(h_i) exceeds refinement threshold τ_s, select h_i for refinement. Apply one chosen strategy: A) Deepening (increase specificity/operationalization), B) Counterfactual (generate and test alternative/negation), or C) Hybridization (recombine elements from multiple uncertain hypotheses). The refined hypothesis replaces the original and the system re-evaluates evidence and posteriors.",
            "evaluation_criteria": "Selection based on individual uncertainty (binary entropy) and subsequent improvement measured by posterior belief increase, entropy reduction, and ELO improvement. Threshold τ_s controls exploration vs exploitation.",
            "model_name": null,
            "model_size": null,
            "scientific_domain": "Machine learning / AI research-hypothesis optimization",
            "theory_type": "Operational refinement and optimization of research hypotheses",
            "human_comparison": false,
            "evaluation_results": "Empirically shown to affect outcomes: τ_s tuning produced different ELO and entropy outcomes (best reported τ_s=0.5 in experiments). Deepening produced more specific, testable hypotheses in the case study; overall framework convergence improved with appropriate τ_s and iteration counts.",
            "automated_vs_human_evaluation": "Automated selection/production via LLM-guided heuristics; evaluation of refined hypotheses then proceeds via the automated Bayesian-evidence loop and ELO comparisons.",
            "validation_method": "Empirical demonstration across ablations: varying τ_s, n, and T and reporting resulting ELO and entropy changes. No learned policy or external human validation yet.",
            "limitations_challenges": "Refinement strategies are heuristic (not learned), so suboptimal strategy selection may occur; threshold τ_s must be tuned to avoid over-refinement or premature elimination; absence of a learned policy reduces adaptability across domains.",
            "uuid": "e4419.5",
            "source_info": {
                "paper_title": "Bayes-Entropy Collaborative Driven Agents for Research Hypotheses Generation and Optimization",
                "publication_date_yy_mm": "2025-08"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "ResearchAgent: Iterative Research Idea Generation over Scientific Literature with Large Language Models",
            "rating": 2,
            "sanitized_title": "researchagent_iterative_research_idea_generation_over_scientific_literature_with_large_language_models"
        },
        {
            "paper_title": "Learn2Gen: Learning to Generate Research Idea with Dynamic Control",
            "rating": 2,
            "sanitized_title": "learn2gen_learning_to_generate_research_idea_with_dynamic_control"
        },
        {
            "paper_title": "Nova: An Iterative Planning and Search Approach to Enhance Novelty and Diversity of LLM Generated Ideas",
            "rating": 2,
            "sanitized_title": "nova_an_iterative_planning_and_search_approach_to_enhance_novelty_and_diversity_of_llm_generated_ideas"
        },
        {
            "paper_title": "The AI Scientist-v2: Workshop-level Automated Scientific Discovery via Agentic Tree Search",
            "rating": 2,
            "sanitized_title": "the_ai_scientistv2_workshoplevel_automated_scientific_discovery_via_agentic_tree_search"
        },
        {
            "paper_title": "MOOSE-Chem: Large Language Models for Rediscovering Unseen Chemistry Scientific Hypotheses",
            "rating": 1,
            "sanitized_title": "moosechem_large_language_models_for_rediscovering_unseen_chemistry_scientific_hypotheses"
        },
        {
            "paper_title": "IdeaSynth: Iterative Research Idea Development Through Evolving and Composing Idea Facets with Literature-Grounded Feedback",
            "rating": 1,
            "sanitized_title": "ideasynth_iterative_research_idea_development_through_evolving_and_composing_idea_facets_with_literaturegrounded_feedback"
        }
    ],
    "cost": 0.01355675,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Bayes-Entropy Collaborative Driven Agents for Research Hypotheses Generation and Optimization
3 Aug 2025</p>
<p>Shiyang Duan 
School of Aeronautics and Astronautics</p>
<p>Yuan Tian 
School of Electronic Information and Electrical Engineering</p>
<p>Qi Bing 
School of Electronic Information and Electrical Engineering</p>
<p>Xiaowei Shao 
School of Aeronautics and Astronautics</p>
<p>Bayes-Entropy Collaborative Driven Agents for Research Hypotheses Generation and Optimization
3 Aug 20256B1ADCC1001A6886E8154CF0E6DC2176arXiv:2508.01746v1[cs.AI]
The exponential growth of scientific knowledge has made the automated generation of scientific hypotheses that combine novelty, feasibility, and research value a core challenge.Existing methods based on large language models fail to systematically model the inherent in hypotheses or incorporate the closed-loop feedback mechanisms crucial for refinement.This paper proposes a multi-agent collaborative framework called HypoAgents, which for the first time integrates Bayesian reasoning with an information entropy-driven search mechanism across three stages-hypotheses generation, evidence validation, and hypotheses Refinement-to construct an iterative closed-loop simulating scientists' cognitive processes.Specifically, the framework first generates an initial set of hypotheses through diversity sampling and establishes prior beliefs based on a composite novelty-relevance-feasibility (N-R-F) score.It then employs etrieval-augmented generation (RAG) to gather external literature evidence, updating the posterior probabilities of hypotheses using Bayes' theorem.Finally, it identifies high-uncertainty hypotheses using information entropy H = − pi log pi and actively refines them, guiding the iterative optimization of the hypothesis set toward higher quality and confidence.Experimental results on the ICLR 2025 conference real-world research question dataset (100 research questions) show that after 12 optimization iterations, the average ELO score of generated hypotheses improves by 116.3, surpassing the benchmark of real paper abstracts by 17.8, while the framework's overall uncertainty, as measured by Shannon entropy, decreases significantly by 0.92.This study presents an interpretable probabilistic reasoning framework for automated scientific discovery, substantially improving the quality and reliability of machine-generated research hypotheses.</p>
<p>Introduction</p>
<p>Scientific progress is fundamentally driven by the generation and refinement of research hypotheses.In the age of large-scale scientific publishing and knowledge explosion, researchers are confronted with an overwhelming volume of information, making it in creasingly difficult to identify meaningful, novel, and testable hypotheses.This challeng has sparked growing interest in the use of artificial intelligence-particularly large language models (LLMs)-to assist or automate parts of the scientific discovery pipeline, including hypotheses generation, evaluation, and iteration (Luo et al. 2025).</p>
<p>In recent years, studies in materials science (Kumbhar et al. 2025), social sciences (Yang et al. 2024a), biomedicine, and other fields have attempted to leverage LLMs to propose scientific hypotheses.These systems typically employ RAG, multi-turn dialogues, structured prompts, and other methods to generate initial hypotheses, which are then iteratively refined by experts or agent systems (Jinheon Baek et al. 2024;Pu et al. 2024).However, most existing approaches are limited to one-time generation or shallow optimization, lacking a closed-loop simulation.They also lack systematic mechanisms for hadndling uncertainty (Li et al. 2024;Xiang Hu et al. 2024).</p>
<p>To address the aforementioned challenges, this paper proposes a novel multi-agent framework, termed Hy-poAgents.Centered around a "Propose-Verify-Refine" closed-loop, the method incorporates Bayesian inference and an information entropy-driven mechanism to simulate the exploratory behavior of real-world researchers in knowledge-incomplete enviroments.The core research question we focus on is: Under the permise of limited evidence, how can intelligent agents systematically propose, evaluate, and optimize a collection of research hypotheses that meet high-quality requirements?</p>
<p>Specifically, the proposed HypoAgents framework consists of three core stages: (1) Hypothesis Proposal: generating an initial hypothesis set through diversity sampling and semantic clustering; (2) Evidence Validation: constructing hypothesis-evidenc pairs based on RAG retrieval and using LLMs as probabilistic evaluators for likelihood scoring; (3) Hypothesis Refinement: idenfifying high-uncertainty hypotheses according to Bayesian update rules and information entropy reduction criteria, followed by targeted mod-ification, thereby gradually converging toward a highquality hypothesis set.</p>
<p>The innovations of this paper are as follows:</p>
<p>• Proposes a novel research hypothesis optimization method that combines Bayesian belief updating with an entropy-driven search mechanism, effectively balancing exploration and convergence.This method ensures the continuous refinement of hypotheses through an iterative process that mimics scientific reasoning.• Introduces Bayesian inference and uncertainty analysis for the first time as guiding principles in the iterative optimization of research hypotheses.This enhances the reliability of the hypothesis generation process, making it more robust in handling the uncertainties inherent in scientific discovery.• The efficacy of the proposed method is demonstrated through a large-scale evaluation on the ICLR 2025 conference research question dataset.Results reveal a significant improvement, with a 116.3-point increase in the average ELO score for generated hypotheses after 12 optimization iterations, surpassing real paper abstracts by 17.8 points.Moreover, the uncertainty associated with the hypotheses decreases by 0.92, indicating a stronger confidence in the generated hypotheses.</p>
<p>The structure of this paper is as follows: Section 2 reviews related work on LLM-driven hypothesis generation.Section 3 details the proposed HypoAgents framework, including the three core stages of hypothesis proposal, evidence validation, and refinement.Section 4 describes the experimental setup and evaluation metrics.Section 5 presents and analyzes the results of the experiments, highlighting the effectiveness of our approach.Finally, Section 6 concludes the paper and discusses future research directions.</p>
<p>Related Works</p>
<p>LLM-Driven Hypothesis Generation</p>
<p>In recent years, LLMs have shown significant potential in generating scientific hypotheses and research ideas, primarily achieved through various prompt engineering and interactive paradigms for automated ideation.We categorize the existing literature into two main strategies: single-model prompting and multi-round iterative generation.</p>
<p>Single-Model Prompting</p>
<p>Early research primarily enhanced the reasoning capabilities of LLMs through Chain-of-Thought (CoT) prompting or RAG.For example, MOOSE-Chem employs a simple RAG pipeline, enabling an LLM to rediscover previously published chemistry research hypotheses from top-tier journals without domain-specific fine-tuning (Yang et al. 2024b).Similarly, the Chain-of-Ideas (CoI) framework links retrieved concepts into a structured "thought chain," guiding the LLM to generate more novel and scientifically profound research ideas (Long Li et al. 2024).</p>
<p>Although these methods offer advantages such as high efficiency and low computational cost, their singleround generation nature often results in a lack of selfreflection and correction mechanisms.The generated hypotheses may contain factual errors or lack depth.Furthermore, these approaches typically lack a systematic evaluation of novelty, feasibility, or scientific value.</p>
<p>Multi-Turn Interative Generation</p>
<p>To overcome these limitations, recent studies have proposed multistage generation frameworks that introduce structured feedback loops to enhance the quality of the output.For example, ResearchAgent utilizes a "writerreviewer" dual-agent loop, where the "writer" is responsible for idea generation and the "reviewer" provides critical feedback, significantly improving the novelty and relevance of the results (Jinheon Baek et al. 2024).IdeaSynth decomposes research hypotheses into reusable "facets" (problem, method, evaluation) and conducts structured exploration through evolution and recombination (Pu et al. 2024).</p>
<p>Furthermore, frameworks like Nova and Learn2Gen have introduced more complex planning and evaluation mechanisms.Nova uses a "Plan-Retriever-Search" cycle to enhance knowledge integration and generation diversity (Xiang Hu et al. 2024), while Learn2Gen combines supervised fine-tuning with reinforcement learning based on multi-objective rewards to effectively balance multiple dimensions such as novelty, feasibility, and clarity (Li et al. 2024).</p>
<p>These approaches mark a shift from static prompting to dynamic, feedback-driven generation models, advancing the evolution of LLMs toward scientific intelligent agents with reasoning capabilities.</p>
<p>Multi-Agent Collaboration and Automated Scientific Workflows</p>
<p>Beyond individual generation strategies, another significant direction is the construction of multi-agent collaborative frameworks to support the automation of the scientific process, including stages like ideation, experimental design, and paper writing.</p>
<p>The AI-Scientist framework is representative in this domain, achieving full-process automation by combining multiple agents with specific decision-making capabilities (such as ideation, code execution, experimental evaluation, and paper writing) (Chris Lu et al. 2024).Its second-generation framework, AI-Scientist-v2, introduces tree search-based experimental planning and a vision-language model closed-loop, achieving fully automated and peer-reviewed research outputs (Yamada et al. 2025).Similarly, the SciAgents framework coordinates heterogeneous agents (e.g., Ontologist, Explorers, Critics) to collaborate on a dynamic knowledge graph, generating and refining interdisciplinary hypotheses through semantic path sampling and interagent evaluation (Alireza Ghafarollahi and Markus J. Buehler 2024).</p>
<p>The effectiveness of these frameworks relies on two key mechanisms: (1) division of labor, where agents have clear responsibilities in phases like generation, validation, or planning (e.g., AI-Scientist and Nova); and (2) structured critique and revision, typically implemented through the collaboration of multiple peerevaluating agents (e.g., ResearchAgent, Learn2Gen).</p>
<p>Although the existing methods have demonstrated the potential of LLMs in research ideation and workflow collaboration, most still have shortcomings in the following areas: integrating belief updating, evaluating evidence-based support, and navigating uncertain hypothesis spaces.</p>
<p>Building on prompt design, multi-turn feedback, and multi-agent collaboration, our work integrates a probabilistic reasoning framework to construct a unified and interpretable LLM-driven scientific hypothesis generation scheme.</p>
<p>Methodology</p>
<p>This section presents a detailed description of our proposed framework for automatic generation and iterative refinement of research hypotheses, termed HypoAgents.The framework is designed to simulate the core "propose-validate-refine" loop in scientific research.It systematically generates, evaluates, and refines scientific hypotheses through multi-agent collaboration.</p>
<p>Problem Definition</p>
<p>The central task of this research is to automatically generate a high-quality set of research hypotheses H = {h 1 , h 2 , . . ., h n } for a given open-ended research question Q.A high-quality hypothesis must strike an optimal balance across three core dimensions:</p>
<ol>
<li>Novelty (N ): Does the hypothesis propose new insights, mechanisms, or associations that extend beyond the prevailing knowledge in the literature? 2. Relevance (R): Is the hypothesis closely aligned with the core research question Q, and can it help address the question either directly or indirectly? 3. Feasibility (F ): Is the hypothesis testable in the real world through experimentation, data analysis, or other scientific methods?</li>
</ol>
<p>This task can be formalized as a multi-objective optimization problem: finding an optimal hypothesis set H * that maximizes a composite evaluation function J (H; N, R, F ).Our framework approaches this goal through an iterative Bayesian inference process.</p>
<p>Framework Overview</p>
<p>The HypoAgents framework consists of three core modules: Hypothesis Proposal, Evidence Validation, and Hypothesis Refinement.These modules form a closed-loop optimization framework.Starting with a research question Q, the framework first generates a batch of diverse initial hypotheses.Next, it retrieves evidence from external knowledge sources to validate them, and updates its belief in each hypothesis using Bayes' theorem.It then identifies hypotheses with high uncertainty or weak support and applies targeted revisions, entering the next "validation-revision" cycle.This process continues until convergence.</p>
<p>Hypothesis Proposal</p>
<p>The goal of this stage is to generate a diverse and initially plauisible set of hypotheses H 0 = {h 1 , h 2 , . . ., h n } for the research question Q and assign prior probabilities to them.</p>
<p>Diverse Hypothesis Generation</p>
<p>To ensure breadth and diversity in the initial hypothesis set, we adopt a two-stage strategy:</p>
<ol>
<li>Multi-round Sampling with LLMs: Leveraging the generative capacity of large language models (LLMs), we perform multi-round sampling by varying the temperature parameter and designing diverse prompt templates.This allows the exploration of different angles of the research question to generate a large pool of candidate hypotheses.</li>
</ol>
<p>Semantic Clustering and Selection:</p>
<p>To filter representative and non-redundant hypotheses from the large candidate pool, we first map each hypothesis into a high-dimensional vector space using a pretrained embedding model.Then, we apply the K-Means clustering algorithm to group semantically similar hypotheses.To ensure representativeness and avoid redundancy, we then select the hypothesis closest to the centroid of each cluster to form the initial hypothesis set H 0 .</p>
<p>Initial Belief Construction</p>
<p>To initiate the Bayesian iterative process, each hypothesis h i ∈ H 0 is assigned an initial belief as its prior probability.</p>
<p>We define an initial belief score B 0 (h i ), which is a normalized weighted sum incorporating novelty, relevance, and feasibility:
B 0 (h i ) = α • N (h i ) + β • R (h i ) +γ • F (h i ) n j=1 (α • N (h j ) + β • R (h j ) +γ • F (h j )) Here, N (h i ) , R (h i ) , F (h i ) ∈ [0, 1]
are scores assigned to each hypothesis by an LLM-based evaluator.The hyperparameters α, β, γ represent the importance weights for novelty, relevance, and feasibility respectively, and satisfy α + β + γ = 1.The weighted scores are normalized to form a probability distribution B 0 = {B 0 (h 1 ) , . . ., B 0 (h n )}, representing the prior belief over the hypothesis set H 0 .</p>
<p>Evidence Validation</p>
<p>This stage centers on objectively evaluating the validity of each hypothesis based on external knowledge and updating the belief accordingly using Bayes' theorem.</p>
<p>Literature-Based Evidence Retrieval</p>
<p>We construct a knowledge base composed of domain-specific academic literature.For each hypothesis h i under evaluation, the framework forms a structured query by concatenating it with the research question Q, and retrieves the top-k most relevant text segments from the vectorized knowledge base to form the evidence set
D i = {d 1 , d 2 , . . . , d m }.</p>
<p>Likelihood Estimation</p>
<p>The likelihood function L (D i |h i ) quantifies the probability of observing the evidence set D i assuming that the hypothesis h i is true.We design a dual-evidence evaluation mechanism to assess each piece of evidence d j ∈ D i :</p>
<p>• Base Likelihood Score L base (d j |h i ): We use an LLM as a probabilistic evaluator to estimate P (d j |h i ).Specifically, we prompt the model with: "Assume the following scientific hypothesis is true:
h i .
How likely is it that the following piece of literature evidence would be observed: d j ?Please give a continuous score between 0 and 1, where 0 means highly unlikely and 1 means fully consistent."The model outputs a direct probability estimate.• Methodological Alignment Score M (d j , h i ): We use an LLM as a binary classifier to determine whether d j includes methodological elements (e.g., experimental design, analytical approaches) that support or test
h i . If so, M (d j , h i ) = 1; otherwise, it is 0.
The final contribution of each piece evidence is computed as:
L (d j |h i ) = L base (d j |h i ) • M (d j , h i )
To mitigate the impact of low-quality individual evidence (e.g., from LLM errors), we use an average aggregation rather than multiplicative accumulation for the total likelihood:
L (D i |h i ) = 1 m m j=1 L (d j |h i )
Bayesian Posterior Update Given the computed likelihoods, we update the posterior belief B k (h i ) for each hypothesis using Bayes' rule:
B k (h i ) = L (D i |h i ) • B k−1 (h i ) n j=1 L (D j |h j ) • B k−1 (h j ) Here, B k−1 (h i )
is the prior belief from the previous iteration (or the initial prior B 0 (h i ) when k = 1).The denominator serves as a normalization constant ensuring that all posterior beliefs sum to one.</p>
<p>Uncertainty Metrics</p>
<p>To monitor convergence, we introduce Shannon entropy to measure the overall uncertainty of the belief distribution.Higher entropy indicates greater uncertainty across hypotheses.
H k = − n i=1 B k (h i ) log 2 B k (h i )</p>
<p>Hypothesis Refinement</p>
<p>The goal of this stage is to identify and refine hypotheses with the hightest uncertainty to actively explore the hypothesis space.</p>
<p>Selection for Refinement</p>
<p>We use binary entropy to quantify the individual uncertainty of each hypothesis h i :
S k = −B k log 2 B k − (1 − B k ) log 2 (1 − B k )
This score, representing the individual uncertainty of a hypothesis, peaks when its belief B k (h i ) is close to 0.5.This state of maximal uncertainty signals that the accumulated evidence is equally balanced for and against the hypothesis, making it a prime candidate for refinement.</p>
<p>Refinement Strategies For each selected hypothesis, we apply one of several predefined heuristic strategies based on its current state and evidence:</p>
<p>• Deepening: If a hypothesis has moderate support but is vaguely formulated, the framework uses an LLM to increase specificity by adding mechanisms, boundary conditions, or scope.</p>
<p>• Counterfactual: If a hypothesis is strongly contradicted by evidence, a counter or alternative hypothesis is generated, e.g., by negating its causal claim or proposing a different explanatory framework.</p>
<p>• Hybridization: If multiple uncertain hypotheses converge on a similar theme or direction, their core elements (e.g., problem, method, perspective) are recombined to form a more comprehensive and precise new hypothesis.</p>
<p>This process is formalized as a refinement function R (h i , D i , strategy) → h i ′ , which produces a revised hypothesis h ′ i .The refined hypothesis replaces the original and enters the next iteration.</p>
<p>Iteration and Termination</p>
<p>The framework takes the posterior beliefs B k from the previous round as the new prior B k−1 and repeats the "Evidence Validation" and "Hypothesis Refinement" stages in an iterative loop.The loop terminates when any of the following conditions are met:</p>
<ol>
<li>Entropy Convergence: The change in entropy between two consecutive rounds is less than a preset threshold ε
H , i.e., |H k − H k−1 | &lt; ε H .</li>
</ol>
<p>Maximum Iterations Reached:</p>
<p>The number of iterations k reaches a predefined limit T max .</p>
<p>Upon termination, the framework outputs the final belief distribution B T and the corresponding set of hypotehses H T as the final result.</p>
<p>Experiments</p>
<p>This section aims to evaluate the effectiveness of the proposed HypoAgents framework.We introduce the datasets, task settings, and core evaluation metrics used in the experiments.Then, we demonstrate and analyze the impact of different hyperparameter configurations on model performance to validate the robustness of the framework and identify optimal practices.</p>
<p>Dataset and Task Setup</p>
<p>Data Source The experimental data comes from the publicly available paper collection of the ICLR 2025 conference.The conference received a total of 11,672 submissions, of which 3,708 were accepted.</p>
<p>Research Question Construction From the Top-100 high-scoring papers of ICLR 2025, we automatically extracted and manually selected 100 representative research questions as the starting point for the experimental tasks using LLM.These questions cover a range of cutting-edge topics in machine learning and exhibit high complexity and openness.</p>
<p>Knowledge Base Construction</p>
<p>To simulate a realistic research environment, we constructed a dedicated knowledge base for each research question.Specifically, we parsed the reference lists from the aforementioned Top-100 papers and matched them with the Semantic Scholar database, ultimately obtaining the full text of 928 open-source reference papers.These papers were processed and built into a vectorized knowledge base for retrieving relevant evidence during the hypothesis validation phase.</p>
<p>Evaluation Metrics</p>
<p>To comprehensively assess the performance of HypoAgents, we use the following quantitative metrics: ELO Score The ELO rating system, originally developed for ranking players in competitive games, is adapted here to quantitatively evaluate the quality of hypotheses generated across different iterations relative to real paper abstracts.Specifically, we use LLM as a reviewer to perform pairwise comparisons between the hypotheses h generated in different iterations for the same research question and the actual published paper abstract ĥ.The LLM judges the superior hypothesis in each pairwise comparison.Based on the pairwise comparison results, each hypothesis is assigned a dynamically updated ELO score.In each iteration, the average ELO score of all generated hypotheses is compared to the ELO score of the real paper abstract, and the difference serves as a key performance metric.The change in the ELO score (ELO difference) is used to measure the optimization effect of the hypotheses during each iterative round.</p>
<p>Entropy As defined in the methodology section, the information entropy H is used to measure the uncertainty of the entire hypothesis belief distribution.</p>
<p>Ideally, during the optimization process, the system should confirm high-quality hypotheses and eliminate low-quality ones through evidence, leading to a steady decrease in the overall entropy value.Therefore, the change in entropy (entropy difference, ∆H) is used as a metric to assess the system's convergence and the reduction in uncertainty.</p>
<p>Result and Analysis</p>
<p>This section analyzes the performance of the proposed HypoAgents framework under different hyperparameters to validate its effectiveness and robustness.The experiments focus on three key hyperparameters: Number of Iterations T , Number of Hypotheses n, and Refinement Threshold τ s .</p>
<p>The Number of Iterations T</p>
<p>We first analyze the impact of the number of iterations T on the optimization effect.In the experiments, the refinement threshold is fixed at τ s = 0.3, and the number of hypotheses is set to n = 5, with T being varied between 8, 10, and 12 for comparison.The experimental results are shown in Table 1, and the detailed iterative evolution process is illustrated in Figure 1.</p>
<p>As seen in Table 1, the optimization effect of hypotheses significantly improves as the number of iterations T increases.Specifically, when the number of iterations is increased from 8 to 10, the ELO difference improves from 59.17 to 73.33, indicating that increasing the number of iterations helps enhance the quality of the hypotheses.More notably, when the iterations are further increased to 12, the ELO difference rises to 116.27, with the final round ELO reaching 17.77, representing a positive leap, indicating a significant improvement in the overall quality of the hypotheses.</p>
<p>Furthermore, as the number of iterations increases, the downward trend in entropy becomes more pronounced.When the number of iterations reaches 12, the entropy difference is -0.92, showing a significant reduction compared to 8 and 10 iterations.This suggests that as the number of iterations increases, the system's certainty about the hypothesis distribution continuously strengthens, making the optimization process more robust and effective.The Number of Hypotheses n Next, we analyze the impact of the number of hypotheses n.In this experiment, the number of iterations is fixed at T = 8 and the refinement threshold at τ s = 0.3, with the number of hypotheses set to 5, 10, and 15, respectively.The results are shown in Table 2, with the specific optimization results depicted in Figure 2. From Table 2, we can see that an appropriate increase in the number of hypotheses n significantly improves the optimization effect.This suggests that a broader initial search space (a larger n) provides richer material for the iterative refinement process, increasing the probability of discovering and converging on a high-quality hypothesis.When the number of candidates per round is increased from 5 to 10, the ELO improvement increases from 59.17 to 116.60, and the final round ELO rises from -17.04 to 36.34, reflecting a higher quality improvement.However, when the number of hypotheses is further increased to 15, the ELO improvement decreases, and the final round ELO drops to -17.16.This indicates that there is an optimal range for the number of hypotheses, and too many candidates may introduce redundant or low-quality hypotheses, weakening the optimization effect.An excessive number of candidates (n = 15) may introduce noise and redundancy.This could dilute the focus of the optimization process, spreading the evidence-gathering and thus hindering convergence towards the best hypotheses.The Refinement Threshold τ s Finally, we investigate the role of the refinement threshold τ s .In this experiment, the total number of iterations is fixed at T = 8, and the number of hypotheses is set to n = 5, with the refinement threshold τ s varied at 0.3, 0.5, and 0.7.The experimental results are shown in Table 3, and the specific optimization results are illustrated in Figure 3.</p>
<p>From Table 3 and Figure 3, we observe that when the τ s = 0.5, the ELO difference increasing by 102.55 and a significant reduction in entropy by 0.63.In contrast, when the threshold is set too low (e.g., τ s = 0.3), the selection criteria for refinement become too permissive.This leads to the frequent modification of hypotheses that already have relatively low uncertainty, limiting the exploration of more genuinely ambiguous but potentially valuable ideas.On the other hand, when the threshold is set too high (e.g., τ s = 0.7), the selection becomes overly stringent, leading to the premature elimination of potential high-quality hypotheses, which limits the overall exploration ability of the algorithm and results in the smallest performance improvement, just 30.87.</p>
<p>Limitations and Future work</p>
<p>Although HypoAgents shows encouraging results, several limitations remain.The current knowledge base is static, relying on a pre-compiled literature snapshot.Newly published work is not incorporated during an experiment.In future work, we plan to equip the agents with live access to pre-print servers and citations graphs so that beliefs can adapt to emerging evidence in real time.</p>
<p>Limited evidence modalities:</p>
<p>We only retrieve textual passages.Important evidence such as figures, tables, or released code is ignored.We intend to extend the retrieval module to multi-modal documents and to incorporate program-of-thought execution for verifying quantitative claims.</p>
<p>Learned Refinement Policies:</p>
<p>The current refinement strategies (Deepening, Counterfactual, Hybridization) are based on pre-defined heuristics.We plan to learn a policy that selects refinement actions with reinforcement learning, using the same Bayesian utility as the reward signal.</p>
<p>Conclusion</p>
<p>This</p>
<p>Framework Architecture Diagram</p>
<p>Figure 4 presents the flowchart of the HypoAgents framework, clearly depicting the interactions among its three core modules-hypothesis proposal, evidence validation, and hypothesis refinement-as well as the overall data flow within the system.</p>
<p>Prompt Details</p>
<p>Prompt for Initial Hypothesis Generation</p>
<p>System prompt: You are an AI assistant specializing in academic research, particularly in artificial intelligence and machine learning.Your primary role is to assist researchers in formulating wellstructured and theoretically grounded hypotheses, reviewing literature, and designing experimental methodologies.</p>
<p>When helping with research hypotheses, ensure they are:</p>
<ol>
<li>
<p>Clearly framed within the current research landscape, identifying existing gaps.</p>
</li>
<li>
<p>Grounded in strong theoretical foundations with relevant prior work.</p>
</li>
<li>
<p>Precise and testable, specifying independent and dependent variables.</p>
</li>
<li>
<p>Innovative and methodologically rigorous, distinguishing from existing approaches.</p>
</li>
<li>
<p>Expected to contribute meaningfully to the research community.</p>
</li>
</ol>
<p>Always provide well-structured, concise, and publication-worthy responses.If clarification is needed, ask follow-up questions.</p>
<p>User prompt:</p>
<p>You are a senior research expert specializing in artificial intelligence.Your task is to propose a well-structured and theoretically grounded research hypothesis for a novel research problem that is suitable for publication in top-tier conferences and journals.</p>
<p>Instructions for Generating the Research Hypothesis:</p>
<p>Carefully analyze the given research question and develop a comprehensive, testable, and impactful hypothesis by incorporating the following key elements:</p>
<ol>
<li>Research Background &amp; Problem Statement:</li>
</ol>
<p>-Clearly describe the current state of research, existing challenges, and the core problem your hypothesis addresses.</p>
<ol>
<li>Theoretical Foundations:</li>
</ol>
<p>-Reference relevant prior work to justify the hypothesis, highlight unresolved gaps, and establish the rationale for your approach.</p>
<ol>
<li>Hypothesis Statement:</li>
</ol>
<p>-Formulate a precise and testable hypothesis, specifying the independent and dependent variables and their expected relationship.</p>
<p>Methodology &amp; Innovation:</p>
<p>-Outline the proposed research methodology, emphasizing the key ideas, novel contributions, and how it differs from existing approaches.</p>
<p>Expected Contributions &amp; Impact:</p>
<p>-Discuss the anticipated theoretical and practical contributions of the research, as well as its potential significance for the AI community.</p>
<p>The research question you need to solve is: research question</p>
<p>Carefully analyze the provided research question and construct a complete and coherent research hypothesis that meets high academic standards.The hypothesis should be written as a single, well-organized paragraph, ensuring logical flow and clarity.Avoid using bullet points, section headings, or Markdown formatting.Instead, provide a fluent and natural explanation as seen in top-tier research papers.</p>
<p>Prompt for Novelty Evaluation</p>
<p>System prompt:</p>
<p>You are a professor in the keyword content field, and you make a judgment about the novelty of a research hypothesis.</p>
<p>User prompt</p>
<p>You are an expert in an academic research field tasked with evaluating the novelty of a Hypothesis in the context of a given research Question.Novelty is defined as the degree to which a hypothesis is unique or innovative relative to existing knowledge or common methods.The background of existing knowledge can be inferred from the field of study and does not rely on specific documentary evidence.</p>
<p>Follow these steps to evaluate: 1. Understand the field and context of the research Question.3. Give a score (0-1) based on the degree of novelty, following the criteria:</p>
<p>-0: not new at all, and highly coincident with common knowledge.</p>
<p>-0.5: Medium novelty, partly based on existing knowledge but somewhat extended.</p>
<p>-1: Highly novel, proposing a new perspective or approach.</p>
<ol>
<li>Briefly explain the reason for your rating (optional, but helpful).</li>
</ol>
<p>Input:</p>
<p>Hypothesis: {hypothesis} Question: {question} Output format (strictly adhered to): <novelty>{your novelty rating}</novelty></p>
<p>Prompt for Likelihood Estimation</p>
<p>System prompt:</p>
<p>You are a professor in the {keyword content} field, and you make a judgment about the likelihood of a research hypothesis.</p>
<p>User prompt used to base likelihood estimation:</p>
<p>Estimate the probability (0-1) that this evidence would be observed if the hypothesis is true.</p>
<p>Input</p>
<p>Task</p>
<p>Using ONLY the chosen strategy, optimize the hypothesis to better address the research question while keeping it concise, precise, and empirically testable.</p>
<p>Output Format</p>
<p>Respond with a JSON object containing your optimized hypothesis and the optimization strategy:</p>
<p>{ "optimized hypothesis": "<your optimized hypothesis>", "strategy": "<A | B | C>" }</p>
<p>Case Study</p>
<p>To provide a concrete illustration of the HypoAgents framework's iterative optimization process, this section presents a case study.We trace the evolution of a single research hypothesis through several rounds of validation and refinement.The reader is encouraged to observe not only how the hypothesis text evolves from an initially broad formulation to a more precise and technicallygrounded statement, but also the corresponding dynamics of two key metrics: the Belief Value (B k ) and the ELO Score.The Belief Value represents the framework's confidence in the hypothesis's validity, ranging from 0 (certainly false) to 1 (certainly true).Consequently, a belief value approaching 0.5 indicates maximum uncertainty, which marks the hypothesis as a prime candidate for refinement.This case study demonstrates how the framework, starting from a state of high uncertainty, progressively increases its belief as the hypothesis improves.</p>
<p>Research question</p>
<p>How can we efficiently adapt pretrained language models to domain-specific knowledge when facts appear rarely or only once in small corpora, overcoming the data inefficiency of traditional pretraining approaches?</p>
<p>Round 1 Analysis</p>
<p>• Hyp ID: 1 • Belief Value: 0.437 • ELO Scores: 1339.86 Pretrained Language Models (PLMs) have revolutionized natural language processing, exhibiting remarkable capabilities across diverse tasks; however, their effective adaptation to specialized domains typically necessitates extensive domainspecific corpora for continued pretraining or finetuning.This reliance on large datasets presents a significant challenge when domain-specific facts are rare or appear only once within small, proprietary corpora, leading to data inefficiency and sub-optimal knowledge acquisition.While existing methods like knowledge graphs and retrievalaugmented generation offer external knowledge access, the efficient <em>internalization</em> of novel, sparse facts directly into the model's parameters remains an unresolved problem, particularly for instances with minimal or singleoccurrence evidence.Drawing inspiration from meta-learning principles that enable rapid adaptation, we hypothesize that a novel, gradientbased meta-learning framework, specifically designed to optimize for rapid knowledge acquisition and consolidation from extremely sparse, single-instance factual examples, will enable pretrained language models to efficiently integrate domain-specific facts from small corpora, demonstrating superior and more robust performance on knowledge-intensive tasks compared to conventional fine-tuning or continued pretraining approaches.This innovative methodology will involve training the model to learn an optimal 'update rule' or 'knowledge consolidation mechanism' that selectively prioritizes and encodes rare factual information during a few gradient steps, thereby overcoming the data inefficiency of traditional approaches and allowing the model to genuinely 'one-shot' or 'few-shot' learn specific facts directly into its parameters.Such a breakthrough would not only advance our theoretical understanding of efficient knowledge acquisition in large neural networks but also offer profound practical implications, enabling the rapid and cost-effective deployment of powerful PLMs in highly specialized, data-scarce domains-from niche scientific fields to proprietary corporate datasets-where precise factual recall from limited evidence is paramount, ultimately democratizing access to advanced AI for low-resource applications.</p>
<p>Analysis and Evaluation:</p>
<p>In the initial, the hypothesis text accurately identified the core of the research problem-the adaptability challenges of pretrained language models when dealing with small sam-ples and sparse facts-and proposed a reasonable solution based on meta-learning.However, the formulation of this version more closely resembled the introduction of a research proposal than a concise scientific hypothesis.Its primary limitation was a lack of specificity: although it mentioned a "gradient-based meta-learning framework", it failed to articulate the specific mechanisms for its implementation or to explore the deeper theoretical problems it could address beyond data efficiency.</p>
<p>Round 5 Analysis</p>
<p>• Hyp ID: 4 • Binary Entropy: 0.817 • ELO Scores: 1252.91</p>
<p>Traditional PLM adaptation to domain-specific knowledge struggles with rare, single-occurrence facts in small corpora due to data inefficiency and susceptibility to catastrophic forgetting.We hypothesize that a <strong>meta-learning-driven, parameter-efficient adaptation framework</strong> will overcome these limitations by <strong>leveraging metalearning's ability to learn to learn for rapid, fewshot adaptation</strong> and <strong>utilizing targeted parameter updates (e.g., via prompt tuning or adapters, modifying less than 1% of parameters)</strong>.This parameter-efficient approach will specifically encode new facts while preserving core model knowledge by preventing modification of general language understanding and reducing overfitting to sparse data, thereby mitigating catastrophic forgetting.This framework is particularly effective in low-resource scenarios and will enable PLMs to achieve superior factual recall and reasoning for scarce facts, demonstrating higher data efficiency, improved stability, and competitive or superior performance compared to traditional finetuning and continued pretraining.</p>
<p>Analysis and Evaluation: After several rounds of iteration, the quality of the hypothesis underwent a qualitative leap, evolving into a highly refined and robustly argued scientific proposition.The improvements in this version clearly demonstrate the framework's "Deepening" optimization capability.Its progress is evident in two key aspects: 1) Proposing a specific technical path: The hypothesis explicitly introduces a "parameter-efficient adaptation framework" and specifies implementation methods such as "prompt tuning or adapter", which significantly enhances the hypothesis's feasibility and verifiability.2) Providing deeper theoretical support: It precisely links the advantages of the parameter-efficient approach to solving the critical challenge of "catastrophic forgetting", indicating a more profound understanding of the problem.The text itself also became more concise and professional.</p>
<p>Round 8 Analysis</p>
<p>• Hyp ID: 4</p>
<p>• Binary Entropy: 1 • ELO Scores: 1284.60</p>
<p>We hypothesize that a <strong>meta-learning-driven, parameter-efficient adaptation framework</strong> will efficiently adapt pretrained language models to rare, single-occurrence facts in small corpora.This framework leverages <strong>meta-learning to acquire an optimal strategy for rapid, few-shot integration of novel, sparse factual patterns</strong>, implemented through <strong>targeted parameter updates (e.g., prompt tuning or adapters, modifying ¡1% of parameters)</strong>.This approach will specifically encode new facts while preserving general language understanding and mitigating catastrophic forgetting, thereby achieving superior factual recall, reasoning, data efficiency, and stability compared to traditional fine-tuning and continued pretraining in low-resource scenarios.Analysis and Evaluation: The hypothesis in this round can be regarded as the final refinement of a mature proposal.Its core ideas and technical path are largely consistent with the output of Round 5, with minor modifications primarily focused on sentence structure to improve fluency.</p>
<p>Abstract of the original paper</p>
<p>Pretraining on large-scale, unstructured internet text enables language models to acquire a significant amount of world knowledge.However, this knowledge acquisition is data-inefficient-to learn a fact, models must be trained on hundreds to thousands of diverse representations of it.This poses a challenge when adapting a pretrained model to a small corpus of domain-specific documents, where each fact may appear rarely or only once.We propose to bridge this gap with synthetic continued pretraining: using the small domainspecific corpus to synthesize a large corpus more amenable to learning, and then performing continued pretraining on the synthesized corpus.We instantiate this proposal with EntiGraph, a synthetic data augmentation algorithm that extracts salient entities from the source corpus and then generates diverse text by drawing connections between those entities.Synthetic continued pretraining with EntiGraph enables a language model to answer questions and follow generic instructions related to the source documents without access to them.If the source documents are instead available at inference time, we show that the knowledge acquired through our approach compounds with retrieval-augmented generation.To better understand these results, we build a simple mathematical model of EntiGraph, and show how synthetic data augmentation can rearrange knowledge to enable more data-efficient learning.Analysis and Evaluation: Comparing the framework's final generated hypothesis with the abstract of the original published paper reveals the capabilities and boundaries of current automated scientific discovery.A notable finding is that the high-quality hypothesis converged upon by HypoAgents (meta-learning + parameter-efficient fine-tuning) is methodologically distinct from the solution ultimately adopted by the human researchers (synthetic continued pretraining and the EntiGraph algorithm).This comparison yields two critical insights: 1. Autonomous Exploratory Capability of HypoAgents: The framework demonstrated its ability to autonomously conduct logical reasoning and exploration within a complex solution space, ultimately converging on a logically sound and highly valuable research proposition.This indicates the method's effectiveness in automatically generating high-quality, verifiable research ideas.2. Boundaries of Current AI Creativity: Despite its impressive performance, HypoAgents primarily operates by combining and optimizing within known, established knowledge paradigms.In contrast, the human researchers exhibited "out-ofthe-box" creativity by proposing a methodologically disruptive new paradigm.This highlights that "zeroto-one" disruptive innovation remains an irreplaceable core value of human researchers.</p>
<p>Figure 1 :
1
Figure 1: Impact of Different Iterations on Performance</p>
<p>Figure 2 :
2
Figure 2: Impact of Different Numbers of Hypotheses on Performance</p>
<p>Figure 3 :
3
Figure 3: Impact of Different Refinement Thresholds on Performance</p>
<p>Table 1 :
1
Results Comparison for Different Iterations
TFirst Round ELO Final Round ELO ELO ∆ ↑ ∆H8-76.21-17.0459.17-0.3210-87.71-14.3873.33-0.3812-98.5017.77116.27-0.92</p>
<p>Table 2 :
2
Results Comparison for Different Number of Hypotheses
nFirst Round ELO Final Round ELO ELO ∆ ↑ ∆H5-76.21-17.0459.17-0.3210-80.2736.34116.60-1.1715-99.65-17.1682.49-0.56</p>
<p>Table 3 :
3
Results Comparison for Different Refinement Thresholds
τ sFirst Round ELO Final Round ELO ELO ∆ ↑ ∆H0.3-76.21-17.0459.17-0.320.5-109.00-6.46102.55-0.630.7-45.23-14.3630.87-0.250Elo Score−75 −50 −25−1002468Iteration2.00Entropy1.50 1.751.251.002468Iterationτ s = 0.3τ s = 0.5τ s = 0.7</p>
<p>paper presented HypoAgents, a Bayesian-entropy collaborative framework that enables a group of LLMpowered agents to generate, evaluate and refine research hypotheses in a closed loop.Experiments on 100 openended research questions from ICLR 2025 show that the framework boosts the average ELO score of hypothe-
and Zhenzhong Lan. 2024. Nova: An Iterative Planningand Search Approach to Enhance Novelty and Diversityof LLM Generated Ideas. arXiv:2410.14255.Yamada, Y.; Lange, R. T.; Lu, C.; Hu, S.; Lu, C.; Foer-ster, J.; Clune, J.; and Ha, D. 2025. The AI Scientist-v2: Workshop-level Automated Scientific Discovery viaAgentic Tree Search. arXiv:2504.08066.Yang, Z.; Du, X.; Li, J.; Zheng, J.; Poria, S.; and Cambria, E. 2024a. Large Language Models for Au-tomated Open-domain Scientific Hypotheses Discovery. arXiv:2309.02726. Yang, Z.; Liu, W.; Gao, B.; Xie, T.; Li, Y.; Ouyang, W.; Poria, S.; Cambria, E.; and Zhou, D. 2024b.ses by 116.3 points after 12 iterations while simultane-ously reducing uncertainty by 0.92. These results sug-gest that principled probabilistic reasoning, combined with information-theoretic exploration, offers a viable path toward reliable automated scientific discovery. Fu-ture work will address the outlined limitations.MOOSE-Chem: Large Language Models for Redis-covering Unseen Chemistry Scientific Hypotheses.arXiv:2410.07076.</p>
<p>prompt used to methodology match:
-Drill into causal mechanisms, define measur-able variables, and tighten logical flow withoutadding new constructs.B. Counterfactual-Formulate the strongest plausible counter-hypothesis, rebut it with evidence, then revise theoriginal hypothesis to survive the challenge.C. Hybridization-Import a concept or method from anotherdiscipline, integrate it with current evidence, andcraft a hybrid hypothesis leveraging both do-mains.ContextResearch Question: {research question}Current Hypothesis: {hypothesis}EvidenceSnippets(top5):{evidence snippets}:Evidence: {knowledge content}Hypothesis: {hypothesis}Output format strictly adhered to:<base LH>{your match score}</base LH>User Input:Research question: {question}Evidence: {knowledge content}Hypothesis: {hypothesis}Check if the evidence contains methodologiessupporting the hypothesis.Return 1 if matched, 0 if not, with a briefexplanation.Output format strictly adhered to:<match>{your match score}</match>Prompt for Hypothesis RefinementUser prompt:You are an expert academic researcher spe-cializing in hypothesis optimization within arti-ficial intelligence research. Select ONE strategybelow and state it exactly as shown:A. Deepening
AcknowledgmentsThis research was supported by the computational resources provided by our institution, which were essential for conducting the large-scale experiments presented in this work.
Alireza Ghafarollahi, ; , Markus J Buehler, arXiv:2409.05556SciAgents: Automating Scientific Discovery through Multi-Agent Intelligent Graph Reasoning. 2024</p>
<p>. Chris Lu, ; Cong Lu, ; Robert, Tjarko Lange, Jakob Foerster</p>
<p>Jeff Clune, ; , David Ha, arXiv:2408.06292The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery. 2024Sujay Kumar Jauhar</p>
<p>. Silviu Cucerzan, </p>
<p>Sung Ju Hwang ; Kumbhar, S Mishra, V Coutinho, K Handa, D Iquebal, A Baral, C Li, R Jing, L Han, C Zhou, J Du, X , arXiv:2404.07738arXiv:2412.14626Hypothesis Generation for Materials Discovery and Design Using Goal-Driven and Constraint-Guided LLM Agents. 2024. 2025. 2024ResearchAgent: Iterative Research Idea Generation over Scientific Literature with Large Language Models. Learning to Generate Research Idea with Dynamic Control</p>
<p>. Long Li, ; Weiwen Xu, </p>
<p>. Jiayan Guo, ; Ruochen Zhao, Xinxuan Li, Yuqian Yuan</p>
<p>. Boqiang Zhang, ; Yuming Jiang, </p>
<p>. Yifei Xin, ; Ronghao Dang, Deli Zhao, Yu Rong</p>
<p>Tian Feng, ; , Lidong Bing, arXiv:2410.13185Chain of Ideas: Revolutionizing Research in Novel Idea Development with LLM Agents. 2024</p>
<p>Z Luo, Z Yang, Z Xu, W Yang, X Du, arXiv:2501.04306LLM4SR: A Survey on Large Language Models for Scientific Research. 2025</p>
<p>K Pu, K J K Feng, T Grossman, T Hope, B D Mishra, M Latzke, J Bragg, J C Chang, P Siangliulue, arXiv:2410.04025IdeaSynth: Iterative Research Idea Development Through Evolving and Composing Idea Facets with Literature-Grounded Feedback. 2024Xiang Hu; Hongyu Fu; Jinge Wang. Yifeng Wang</p>
<p>. Zhikun Li, Renjun Xu</p>
<p>. Yu Lu, ; Yaochu, Jin , Lili Pan</p>            </div>
        </div>

    </div>
</body>
</html>