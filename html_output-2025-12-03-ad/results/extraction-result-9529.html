<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9529 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9529</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9529</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-165.html">extraction-schema-165</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <p><strong>Paper ID:</strong> paper-265066945</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2311.04929v1.pdf" target="_blank">An Interdisciplinary Outlook on Large Language Models for Scientific Research</a></p>
                <p><strong>Paper Abstract:</strong> In this paper, we describe the capabilities and constraints of Large Language Models (LLMs) within disparate academic disciplines, aiming to delineate their strengths and limitations with precision. We examine how LLMs augment scientific inquiry, offering concrete examples such as accelerating literature review by summarizing vast numbers of publications, enhancing code development through automated syntax correction, and refining the scientific writing process. Simultaneously, we articulate the challenges LLMs face, including their reliance on extensive and sometimes biased datasets, and the potential ethical dilemmas stemming from their use. Our critical discussion extends to the varying impacts of LLMs across fields, from the natural sciences, where they help model complex biological sequences, to the social sciences, where they can parse large-scale qualitative data. We conclude by offering a nuanced perspective on how LLMs can be both a boon and a boundary to scientific progress.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9529.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9529.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Taxonomic/Phenotype extraction</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Automated extraction of morphological, taxonomic, and geospatial information from biological text</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Mentioned use of LLMs and LLM-based toolkits to automatically annotate taxonomic texts and extract phenotypic (morphological) characters and geospatial/taxonomic facts from large corpora of biodiversity literature.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Biological sciences / biodiversity / taxonomy</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Large archives of taxonomic descriptions and biology literature (unstructured text in species descriptions); no numeric corpus size given in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_type</strong></td>
                            <td>phenotypic / taxonomic character extraction (rule-like morphological descriptors)</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_example</strong></td>
                            <td>Extraction of morphological character statements (e.g., presence/absence or descriptions of structures) and mappings from descriptive phrases to structured trait records for species occurrence and traits.</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_methodology</strong></td>
                            <td>Integration of foundational LLMs into existing text-mining toolkits to perform automated annotation and information extraction from taxonomic descriptions (mentioned generally; prior work references exist).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Not specified in this paper; prior referenced work has developed corpora and gold-standards for named-entity and trait extraction (references cited but evaluation details not recapitulated here).</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Authors state LLMs have potential to revolutionize and accelerate extraction of taxonomic and phenotypic data, enabling access to otherwise inaccessible data; no empirical results are reported in this review itself.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Claimed improvement relative to pre-LLM technologies that struggled with homonymy/synonymy in morphological descriptions, but no quantitative baseline comparison reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td>Phenotypic descriptions are difficult to mine due to homonymy and synonymy; domain-specific fine-tuning likely required; risk of inaccuracies if LLMs are applied without domain adaptation or verification.</td>
                        </tr>
                        <tr>
                            <td><strong>bias_or_hallucination_issues</strong></td>
                            <td>General concerns about hallucinations and misinformation apply; the paper cautions that outputs must be validated by experts to avoid dissemination of inaccuracies.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'An Interdisciplinary Outlook on Large Language Models for Scientific Research', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9529.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9529.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SMILES-BERT / ChemBERTa-2 / MoLFORMER</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>String-based chemical language models (SMILES-BERT, ChemBERTa-2) and MoLFORMER</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Language-model-based approaches that learn molecular representations from SMILES/string encodings and have been reported to perform well on molecular property prediction and generating molecular structures with specified characteristics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Large Scale Unsupervised Pre-Training for Molecular Property Prediction</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td>SMILES-BERT, ChemBERTa-2, MoLFORMER</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_description</strong></td>
                            <td>Transformer-based language models trained on string (SMILES) representations of molecules; ChemBERTa-2 is a RoBERTa-based chemical foundation model; MoLFORMER developed by IBM (details referenced in cited works). Specific sizes/parameter counts are not provided in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Chemistry / molecular property prediction and molecular generation</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Large corpora of molecular SMILES strings and chemical databases (specific datasets and sizes not enumerated in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_type</strong></td>
                            <td>structure–property relationships (qualitative/generalizable rules linking string-encoded structure to properties)</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_example</strong></td>
                            <td>Language models learn distributions and correlations enabling prediction of molecular properties and generation of molecules with target characteristics (no single law quoted; described as capturing molecular structure-property mappings).</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_methodology</strong></td>
                            <td>Self-supervised pretraining on large collections of molecular strings (unsupervised pretraining), then fine-tuning for downstream property prediction and generation tasks; described at a high level in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Benchmarks on molecular property prediction and generative tasks are referenced; specific evaluation protocols are in the cited works (not reproduced here).</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>The paper reports that such language models 'perform quite well' at learning molecular properties from string representations and can outperform some graph generative models in molecule generation; exact metrics are delegated to cited studies.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Stated comparisons show language models perform favorably versus some graph generative models and other deep learning methods (details and quantitative comparisons are in the original cited papers).</td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td>Domain-specific vocabulary and representation challenges; necessity of appropriate training data and possible need for fine-tuning; potential for model hallucination or misleading outputs if used without verification.</td>
                        </tr>
                        <tr>
                            <td><strong>bias_or_hallucination_issues</strong></td>
                            <td>The review emphasizes general LLM issues (hallucinations, misinformation); domain-specific models may mitigate but do not eliminate these risks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'An Interdisciplinary Outlook on Large Language Models for Scientific Research', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9529.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9529.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MOFormer / MOF studies</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MOFormer: transformer model for metal-organic framework property prediction (and ChatGPT-assisted MOF synthesis work)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Transformer-based, structure-agnostic model MOFormer and related LLM-enabled workflows for predicting properties and aiding synthesis prediction for metal-organic frameworks (MOFs), reported to outperform some traditional structure-based and structure-agnostic baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Moformer: self-supervised transformer model for metal-organic framework property prediction</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td>MOFormer (transformer-based, self-supervised)</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_description</strong></td>
                            <td>A self-supervised transformer model applied to MOF representations; pretraining further improves predictive accuracy (paper cites percent-improvement figures). Exact architecture and parameter counts are in the cited MOFormer paper.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Materials science — metal-organic frameworks (MOFs) property prediction and synthesis insights</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Corpora of MOF data and associated property labels used for pretraining and downstream tasks (this review does not give dataset sizes).</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_type</strong></td>
                            <td>structure–property prediction rules and synthesis patterns for MOFs (generalizable mappings from representations to band gaps and gas adsorption behaviors)</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_example</strong></td>
                            <td>Reported improvements in band gap prediction and gas adsorption prediction accuracy (e.g., MOFormer achieves 21.4% and 16.9% better in band gap prediction, and 35–48% and 25–42% better in various gas adsorption tasks compared to certain baselines, as summarized in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_methodology</strong></td>
                            <td>Self-supervised transformer pretraining on MOF data followed by task-specific fine-tuning; review notes the benefit of pretraining for improved downstream performance.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Benchmark comparisons against structure-agnostic baselines (Stoichiometric-120, revised autocorrelation features) and structure-based methods (SOAP); quantitative improvements are quoted in the review (from the MOFormer paper).</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>MOFormer is reported to substantially improve predictive accuracy on band gap and gas adsorption tasks versus selected baselines, and pretraining further boosts performance by an average of ~4–5% for some metrics (numbers quoted in the review reflect the cited study).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Explicit quantitative improvements over Stoichiometric-120, RACs, and in some cases SOAP are cited (see numbers above); the review attributes these gains to transformer-based representations and pretraining.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td>Need for domain-specific corpora and representation choices; applicability may depend on how well domain data can be cast into sequential/string representations; additional testing across domains needed.</td>
                        </tr>
                        <tr>
                            <td><strong>bias_or_hallucination_issues</strong></td>
                            <td>General LLM concerns apply; the review does not report hallucination specifics for MOFormer but cautions about verification and reproducibility.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'An Interdisciplinary Outlook on Large Language Models for Scientific Research', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9529.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9529.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Causal discovery / DAG construction</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLMs for causal discovery and automatic construction of Directed Acyclic Graphs (DAGs) from textual sources</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper references work in which LLMs (including GPT-4) are used to perform causal discovery tasks, counterfactual reasoning, and to generate DAGs by ingesting book content, papers, or theoretical sources to output causal graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td>GPT-4 (and other LLMs in referenced studies)</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_description</strong></td>
                            <td>General pre-trained LLMs (GPT-4 specifically referenced) used as reasoning engines for causal discovery; no architecture or parameter details provided beyond model names in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>General scientific domains where causal graphs are useful (social sciences, epidemiology, environmental sciences, biostatistics, etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Collections of theoretical texts, books, or research papers provided as input prompts to the LLM; no corpus sizes specified in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_type</strong></td>
                            <td>causal mechanism / causal graph extraction (rules about directional cause–effect relationships)</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_example</strong></td>
                            <td>LLMs can output causal graphs linking variables (e.g., deducing plausible arrows of causality between domain factors) when given domain texts; GPT-4 reportedly outperforms existing models in causal discovery tasks (as summarized).</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_methodology</strong></td>
                            <td>Researchers feed theoretical sources (books, papers) or cause–effect pairs into LLMs, which output candidate causal graphs/DAGs or assess arrow-of-causality between pairs; methodology described generally (prompting, possibly few-shot).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Comparisons against existing models and task benchmarks in causal discovery and counterfactual reasoning; expert verification is suggested though specific protocols are in cited works.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>The review reports that GPT-4 outperforms existing models in causal discovery and counterfactual reasoning tasks (no numeric scores provided); LLMs can drastically reduce effort in building or verifying causal graphs but carry caveats.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Reported outperformance of GPT-4 relative to existing models on causal tasks (citation provided in review), suggesting superior capability in some benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td>LLMs may fail on abstract tasks disconnected from real-world data, can produce incorrect causal inferences if prompts or inputs are incomplete, and outputs require domain expert scrutiny; reproducibility and explainability concerns persist.</td>
                        </tr>
                        <tr>
                            <td><strong>bias_or_hallucination_issues</strong></td>
                            <td>Risks of hallucinated causal links or biased inferences reflecting training data; authors caution that outputs must be validated and not treated as definitive without human oversight.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'An Interdisciplinary Outlook on Large Language Models for Scientific Research', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9529.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e9529.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Meta-analytic synthesis / literature summarization</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLM-enabled automated synthesis and summarization frameworks for aggregating findings across many studies (including tools like Bard and Elicit)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The review describes use of LLMs to automate meta-analytic-style synthesis and summarization across large numbers of publications, extracting patterns, themes, and potentially meta-analytic data (textual and tabular).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td>Bard, Elicit, and general pre-trained LLMs (e.g., GPT-family) as exemplars</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_description</strong></td>
                            <td>General pre-trained or retrieval-augmented models tailored to literature review tasks; Bard and Elicit are cited as models able to review and summarize literature while providing sources. Specific sizes/architectures are not detailed in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Cross-domain literature review and meta-analysis (economics, aviation safety, health, social sciences, etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Large collections of publications (the review references automated extraction of both textual and tabular data across many papers); specific corpus sizes are not given in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_type</strong></td>
                            <td>thematic patterns / synthesized findings / generalized principles across studies (meta-analytic themes and extracted empirical regularities)</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_example</strong></td>
                            <td>Automated identification of patterns and synthesis of findings across domains (e.g., extracting KPIs, consolidating study findings into summaries and aggregations); no single explicit law is reported in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>extraction_methodology</strong></td>
                            <td>Retrieval-augmented summarization and literature review workflows where LLMs parse many documents, extract claims/metrics, and synthesize summaries; examples include models that provide direct citations alongside summaries.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Mention of prior successful applications in diverse domains and that state-of-the-art models (Bard, Elicit) can provide direct sources; formal evaluation methods are delegated to cited systems and studies.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>LLMs can substantially accelerate literature review and meta-analytic data extraction, enabling rapid summarization and pattern detection; the review emphasizes potential but notes the need for validation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Framed as a large improvement in speed and scale over manual literature review; relative accuracy and validity compared to human meta-analysis are not quantified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td>Hallucinated citations and misinformation are a risk; LLMs without internet access cannot provide accurate citations; outputs require human critical review and verification.</td>
                        </tr>
                        <tr>
                            <td><strong>bias_or_hallucination_issues</strong></td>
                            <td>The review explicitly warns about hallucinations (non-existent citations) and misinformation when using LLMs for literature synthesis and stresses the need for cross-referencing authoritative sources.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'An Interdisciplinary Outlook on Large Language Models for Scientific Research', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Large Scale Unsupervised Pre-Training for Molecular Property Prediction <em>(Rating: 2)</em></li>
                <li>ChemBERTa-2: Towards Chemical Foundation Models <em>(Rating: 2)</em></li>
                <li>Moformer: self-supervised transformer model for metal-organic framework property prediction <em>(Rating: 2)</em></li>
                <li>ChatGPT Chemistry Assistant for Text Mining and Prediction of MOF Synthesis <em>(Rating: 2)</em></li>
                <li>Structured information extraction from complex scientific text with fine-tuned large language models <em>(Rating: 2)</em></li>
                <li>Causal Reasoning and Large Language Models: Opening a New Frontier for Causality <em>(Rating: 2)</em></li>
                <li>Can large language models build causal graphs? <em>(Rating: 2)</em></li>
                <li>Elicit: The AI Research Assistant <em>(Rating: 1)</em></li>
                <li>Bard, Bard, A Large Language Model from Google AI <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9529",
    "paper_id": "paper-265066945",
    "extraction_schema_id": "extraction-schema-165",
    "extracted_data": [
        {
            "name_short": "Taxonomic/Phenotype extraction",
            "name_full": "Automated extraction of morphological, taxonomic, and geospatial information from biological text",
            "brief_description": "Mentioned use of LLMs and LLM-based toolkits to automatically annotate taxonomic texts and extract phenotypic (morphological) characters and geospatial/taxonomic facts from large corpora of biodiversity literature.",
            "citation_title": "",
            "mention_or_use": "mention",
            "llm_model_name": null,
            "llm_model_description": null,
            "application_domain": "Biological sciences / biodiversity / taxonomy",
            "input_corpus_description": "Large archives of taxonomic descriptions and biology literature (unstructured text in species descriptions); no numeric corpus size given in this paper.",
            "qualitative_law_type": "phenotypic / taxonomic character extraction (rule-like morphological descriptors)",
            "qualitative_law_example": "Extraction of morphological character statements (e.g., presence/absence or descriptions of structures) and mappings from descriptive phrases to structured trait records for species occurrence and traits.",
            "extraction_methodology": "Integration of foundational LLMs into existing text-mining toolkits to perform automated annotation and information extraction from taxonomic descriptions (mentioned generally; prior work references exist).",
            "evaluation_method": "Not specified in this paper; prior referenced work has developed corpora and gold-standards for named-entity and trait extraction (references cited but evaluation details not recapitulated here).",
            "results_summary": "Authors state LLMs have potential to revolutionize and accelerate extraction of taxonomic and phenotypic data, enabling access to otherwise inaccessible data; no empirical results are reported in this review itself.",
            "comparison_to_baseline": "Claimed improvement relative to pre-LLM technologies that struggled with homonymy/synonymy in morphological descriptions, but no quantitative baseline comparison reported here.",
            "reported_limitations": "Phenotypic descriptions are difficult to mine due to homonymy and synonymy; domain-specific fine-tuning likely required; risk of inaccuracies if LLMs are applied without domain adaptation or verification.",
            "bias_or_hallucination_issues": "General concerns about hallucinations and misinformation apply; the paper cautions that outputs must be validated by experts to avoid dissemination of inaccuracies.",
            "uuid": "e9529.0",
            "source_info": {
                "paper_title": "An Interdisciplinary Outlook on Large Language Models for Scientific Research",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "SMILES-BERT / ChemBERTa-2 / MoLFORMER",
            "name_full": "String-based chemical language models (SMILES-BERT, ChemBERTa-2) and MoLFORMER",
            "brief_description": "Language-model-based approaches that learn molecular representations from SMILES/string encodings and have been reported to perform well on molecular property prediction and generating molecular structures with specified characteristics.",
            "citation_title": "Large Scale Unsupervised Pre-Training for Molecular Property Prediction",
            "mention_or_use": "mention",
            "llm_model_name": "SMILES-BERT, ChemBERTa-2, MoLFORMER",
            "llm_model_description": "Transformer-based language models trained on string (SMILES) representations of molecules; ChemBERTa-2 is a RoBERTa-based chemical foundation model; MoLFORMER developed by IBM (details referenced in cited works). Specific sizes/parameter counts are not provided in this review.",
            "application_domain": "Chemistry / molecular property prediction and molecular generation",
            "input_corpus_description": "Large corpora of molecular SMILES strings and chemical databases (specific datasets and sizes not enumerated in this paper).",
            "qualitative_law_type": "structure–property relationships (qualitative/generalizable rules linking string-encoded structure to properties)",
            "qualitative_law_example": "Language models learn distributions and correlations enabling prediction of molecular properties and generation of molecules with target characteristics (no single law quoted; described as capturing molecular structure-property mappings).",
            "extraction_methodology": "Self-supervised pretraining on large collections of molecular strings (unsupervised pretraining), then fine-tuning for downstream property prediction and generation tasks; described at a high level in this paper.",
            "evaluation_method": "Benchmarks on molecular property prediction and generative tasks are referenced; specific evaluation protocols are in the cited works (not reproduced here).",
            "results_summary": "The paper reports that such language models 'perform quite well' at learning molecular properties from string representations and can outperform some graph generative models in molecule generation; exact metrics are delegated to cited studies.",
            "comparison_to_baseline": "Stated comparisons show language models perform favorably versus some graph generative models and other deep learning methods (details and quantitative comparisons are in the original cited papers).",
            "reported_limitations": "Domain-specific vocabulary and representation challenges; necessity of appropriate training data and possible need for fine-tuning; potential for model hallucination or misleading outputs if used without verification.",
            "bias_or_hallucination_issues": "The review emphasizes general LLM issues (hallucinations, misinformation); domain-specific models may mitigate but do not eliminate these risks.",
            "uuid": "e9529.1",
            "source_info": {
                "paper_title": "An Interdisciplinary Outlook on Large Language Models for Scientific Research",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "MOFormer / MOF studies",
            "name_full": "MOFormer: transformer model for metal-organic framework property prediction (and ChatGPT-assisted MOF synthesis work)",
            "brief_description": "Transformer-based, structure-agnostic model MOFormer and related LLM-enabled workflows for predicting properties and aiding synthesis prediction for metal-organic frameworks (MOFs), reported to outperform some traditional structure-based and structure-agnostic baselines.",
            "citation_title": "Moformer: self-supervised transformer model for metal-organic framework property prediction",
            "mention_or_use": "mention",
            "llm_model_name": "MOFormer (transformer-based, self-supervised)",
            "llm_model_description": "A self-supervised transformer model applied to MOF representations; pretraining further improves predictive accuracy (paper cites percent-improvement figures). Exact architecture and parameter counts are in the cited MOFormer paper.",
            "application_domain": "Materials science — metal-organic frameworks (MOFs) property prediction and synthesis insights",
            "input_corpus_description": "Corpora of MOF data and associated property labels used for pretraining and downstream tasks (this review does not give dataset sizes).",
            "qualitative_law_type": "structure–property prediction rules and synthesis patterns for MOFs (generalizable mappings from representations to band gaps and gas adsorption behaviors)",
            "qualitative_law_example": "Reported improvements in band gap prediction and gas adsorption prediction accuracy (e.g., MOFormer achieves 21.4% and 16.9% better in band gap prediction, and 35–48% and 25–42% better in various gas adsorption tasks compared to certain baselines, as summarized in this paper).",
            "extraction_methodology": "Self-supervised transformer pretraining on MOF data followed by task-specific fine-tuning; review notes the benefit of pretraining for improved downstream performance.",
            "evaluation_method": "Benchmark comparisons against structure-agnostic baselines (Stoichiometric-120, revised autocorrelation features) and structure-based methods (SOAP); quantitative improvements are quoted in the review (from the MOFormer paper).",
            "results_summary": "MOFormer is reported to substantially improve predictive accuracy on band gap and gas adsorption tasks versus selected baselines, and pretraining further boosts performance by an average of ~4–5% for some metrics (numbers quoted in the review reflect the cited study).",
            "comparison_to_baseline": "Explicit quantitative improvements over Stoichiometric-120, RACs, and in some cases SOAP are cited (see numbers above); the review attributes these gains to transformer-based representations and pretraining.",
            "reported_limitations": "Need for domain-specific corpora and representation choices; applicability may depend on how well domain data can be cast into sequential/string representations; additional testing across domains needed.",
            "bias_or_hallucination_issues": "General LLM concerns apply; the review does not report hallucination specifics for MOFormer but cautions about verification and reproducibility.",
            "uuid": "e9529.2",
            "source_info": {
                "paper_title": "An Interdisciplinary Outlook on Large Language Models for Scientific Research",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "Causal discovery / DAG construction",
            "name_full": "LLMs for causal discovery and automatic construction of Directed Acyclic Graphs (DAGs) from textual sources",
            "brief_description": "The paper references work in which LLMs (including GPT-4) are used to perform causal discovery tasks, counterfactual reasoning, and to generate DAGs by ingesting book content, papers, or theoretical sources to output causal graphs.",
            "citation_title": "",
            "mention_or_use": "mention",
            "llm_model_name": "GPT-4 (and other LLMs in referenced studies)",
            "llm_model_description": "General pre-trained LLMs (GPT-4 specifically referenced) used as reasoning engines for causal discovery; no architecture or parameter details provided beyond model names in this review.",
            "application_domain": "General scientific domains where causal graphs are useful (social sciences, epidemiology, environmental sciences, biostatistics, etc.)",
            "input_corpus_description": "Collections of theoretical texts, books, or research papers provided as input prompts to the LLM; no corpus sizes specified in this review.",
            "qualitative_law_type": "causal mechanism / causal graph extraction (rules about directional cause–effect relationships)",
            "qualitative_law_example": "LLMs can output causal graphs linking variables (e.g., deducing plausible arrows of causality between domain factors) when given domain texts; GPT-4 reportedly outperforms existing models in causal discovery tasks (as summarized).",
            "extraction_methodology": "Researchers feed theoretical sources (books, papers) or cause–effect pairs into LLMs, which output candidate causal graphs/DAGs or assess arrow-of-causality between pairs; methodology described generally (prompting, possibly few-shot).",
            "evaluation_method": "Comparisons against existing models and task benchmarks in causal discovery and counterfactual reasoning; expert verification is suggested though specific protocols are in cited works.",
            "results_summary": "The review reports that GPT-4 outperforms existing models in causal discovery and counterfactual reasoning tasks (no numeric scores provided); LLMs can drastically reduce effort in building or verifying causal graphs but carry caveats.",
            "comparison_to_baseline": "Reported outperformance of GPT-4 relative to existing models on causal tasks (citation provided in review), suggesting superior capability in some benchmarks.",
            "reported_limitations": "LLMs may fail on abstract tasks disconnected from real-world data, can produce incorrect causal inferences if prompts or inputs are incomplete, and outputs require domain expert scrutiny; reproducibility and explainability concerns persist.",
            "bias_or_hallucination_issues": "Risks of hallucinated causal links or biased inferences reflecting training data; authors caution that outputs must be validated and not treated as definitive without human oversight.",
            "uuid": "e9529.3",
            "source_info": {
                "paper_title": "An Interdisciplinary Outlook on Large Language Models for Scientific Research",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "Meta-analytic synthesis / literature summarization",
            "name_full": "LLM-enabled automated synthesis and summarization frameworks for aggregating findings across many studies (including tools like Bard and Elicit)",
            "brief_description": "The review describes use of LLMs to automate meta-analytic-style synthesis and summarization across large numbers of publications, extracting patterns, themes, and potentially meta-analytic data (textual and tabular).",
            "citation_title": "",
            "mention_or_use": "mention",
            "llm_model_name": "Bard, Elicit, and general pre-trained LLMs (e.g., GPT-family) as exemplars",
            "llm_model_description": "General pre-trained or retrieval-augmented models tailored to literature review tasks; Bard and Elicit are cited as models able to review and summarize literature while providing sources. Specific sizes/architectures are not detailed in the review.",
            "application_domain": "Cross-domain literature review and meta-analysis (economics, aviation safety, health, social sciences, etc.)",
            "input_corpus_description": "Large collections of publications (the review references automated extraction of both textual and tabular data across many papers); specific corpus sizes are not given in this paper.",
            "qualitative_law_type": "thematic patterns / synthesized findings / generalized principles across studies (meta-analytic themes and extracted empirical regularities)",
            "qualitative_law_example": "Automated identification of patterns and synthesis of findings across domains (e.g., extracting KPIs, consolidating study findings into summaries and aggregations); no single explicit law is reported in the review.",
            "extraction_methodology": "Retrieval-augmented summarization and literature review workflows where LLMs parse many documents, extract claims/metrics, and synthesize summaries; examples include models that provide direct citations alongside summaries.",
            "evaluation_method": "Mention of prior successful applications in diverse domains and that state-of-the-art models (Bard, Elicit) can provide direct sources; formal evaluation methods are delegated to cited systems and studies.",
            "results_summary": "LLMs can substantially accelerate literature review and meta-analytic data extraction, enabling rapid summarization and pattern detection; the review emphasizes potential but notes the need for validation.",
            "comparison_to_baseline": "Framed as a large improvement in speed and scale over manual literature review; relative accuracy and validity compared to human meta-analysis are not quantified in this paper.",
            "reported_limitations": "Hallucinated citations and misinformation are a risk; LLMs without internet access cannot provide accurate citations; outputs require human critical review and verification.",
            "bias_or_hallucination_issues": "The review explicitly warns about hallucinations (non-existent citations) and misinformation when using LLMs for literature synthesis and stresses the need for cross-referencing authoritative sources.",
            "uuid": "e9529.4",
            "source_info": {
                "paper_title": "An Interdisciplinary Outlook on Large Language Models for Scientific Research",
                "publication_date_yy_mm": "2023-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Large Scale Unsupervised Pre-Training for Molecular Property Prediction",
            "rating": 2,
            "sanitized_title": "large_scale_unsupervised_pretraining_for_molecular_property_prediction"
        },
        {
            "paper_title": "ChemBERTa-2: Towards Chemical Foundation Models",
            "rating": 2,
            "sanitized_title": "chemberta2_towards_chemical_foundation_models"
        },
        {
            "paper_title": "Moformer: self-supervised transformer model for metal-organic framework property prediction",
            "rating": 2,
            "sanitized_title": "moformer_selfsupervised_transformer_model_for_metalorganic_framework_property_prediction"
        },
        {
            "paper_title": "ChatGPT Chemistry Assistant for Text Mining and Prediction of MOF Synthesis",
            "rating": 2,
            "sanitized_title": "chatgpt_chemistry_assistant_for_text_mining_and_prediction_of_mof_synthesis"
        },
        {
            "paper_title": "Structured information extraction from complex scientific text with fine-tuned large language models",
            "rating": 2,
            "sanitized_title": "structured_information_extraction_from_complex_scientific_text_with_finetuned_large_language_models"
        },
        {
            "paper_title": "Causal Reasoning and Large Language Models: Opening a New Frontier for Causality",
            "rating": 2,
            "sanitized_title": "causal_reasoning_and_large_language_models_opening_a_new_frontier_for_causality"
        },
        {
            "paper_title": "Can large language models build causal graphs?",
            "rating": 2,
            "sanitized_title": "can_large_language_models_build_causal_graphs"
        },
        {
            "paper_title": "Elicit: The AI Research Assistant",
            "rating": 1,
            "sanitized_title": "elicit_the_ai_research_assistant"
        },
        {
            "paper_title": "Bard, Bard, A Large Language Model from Google AI",
            "rating": 1,
            "sanitized_title": "bard_bard_a_large_language_model_from_google_ai"
        }
    ],
    "cost": 0.0145775,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>An Interdisciplinary Outlook on Large Language Models for Scientific Research
3 Nov 2023</p>
<p>James Boyko 
University of Michigan -Michigan Institute for Data Science</p>
<p>Joseph Cohen 
University of Michigan -Michigan Institute for Data Science</p>
<p>Nathan Fox 
University of Michigan -Michigan Institute for Data Science</p>
<p>Maria Han Veiga 
Department of Mathematics
Ohio State University</p>
<p>Jennifer I-Hsiu Li 
University of Michigan -Michigan Institute for Data Science</p>
<p>Jing Liu 
University of Michigan -Michigan Institute for Data Science</p>
<p>Bernardo Modenesi 
University of Michigan -Michigan Institute for Data Science</p>
<p>Andreas H Rauch 
University of Michigan -Michigan Institute for Data Science</p>
<p>Kenneth N Reid kenreid@umich.edu 
University of Michigan -Michigan Institute for Data Science</p>
<p>Soumi Tribedi 
University of Michigan -Michigan Institute for Data Science</p>
<p>Anastasia Visheratina 
University of Michigan -Michigan Institute for Data Science</p>
<p>Xin Xie 
University of Michigan -Michigan Institute for Data Science</p>
<p>An Interdisciplinary Outlook on Large Language Models for Scientific Research
3 Nov 202380C16DF152032DB84220B740BBD18CCEarXiv:2311.04929v1[cs.CL]
In this paper, we describe the capabilities and constraints of Large Language Models (LLMs) within disparate academic disciplines, aiming to delineate their strengths and limitations with precision.We examine how LLMs augment scientific inquiry, offering concrete examples such as accelerating literature review by summarizing vast numbers of publications, enhancing code development through automated syntax correction, and refining the scientific writing process.Simultaneously, we articulate the challenges LLMs face, including their reliance on extensive and sometimes biased datasets, and the potential ethical dilemmas stemming from their use.Our critical discussion extends to the varying impacts of LLMs across fields, from the natural sciences, where they help model complex biological sequences, to the social sciences, where they can parse large-scale qualitative data.We conclude by offering a nuanced perspective on how LLMs can be both a boon and a boundary to scientific progress.</p>
<p>Introduction</p>
<p>Large Language Models (LLMs) embody a class of artificial intelligence systems renowned for their massive training datasets, intricate neural network structures, and the advanced ability to mimic, generate, and fine-tune natural language.Developers train LLMs on extensive text corpuses that cover a wide array of linguistic styles, domains, and subjects.Throughout their training, LLMs cultivate a statistical grasp of language, which empowers them to produce coherent, context-aware text and tackle numerous natural language processing tasks.The substantial neural networks within LLMs, sometimes containing tens or hundreds of billions of parameters, enable them to discern subtle semantic links and generalize across varied language tasks effectively.The scale and architecture of LLMs enhance their capacity to encompass vast linguistic knowledge and demonstrate a type of artificial creativity reflective of their training data.LLMs's proficiency in engaging with and crafting human-like text paves the way for a multitude of applications, from machine translation to creative writing.Simultaneously, they raise important considerations about their interpretability, ethical use, and the risks of potential misuse.</p>
<p>LLMs stand at the forefront of current discourse for their transformative potential in scientific research.In recent years, several high-profile LLMs such as GPT-4 [1], BERT [2], and LaMDA [3] have made their mark, all of which rely on the innovative transformer architecture [4].These models, pre-trained on sprawling text datasets, are adept at emulating human-like conversational text, fielding questions, aiding translations, crafting summaries, and executing a range of natural language processing (NLP) tasks with notable accuracy [5].</p>
<p>LLMs exhibit a remarkable capacity to assimilate data at scales and speeds unattainable for human researchers, redefining the bounds of knowledge consumption and application.The skill of pre-trained LLMs to produce and critique text based on straightforward prompts opens avenues for automating laborious components of the scientific process.For instance, LLMs can bolster manuscript development and computational endeavors with their generative power, expedite information retrieval and review, or create code for initial data analysis.This optimization of research processes allows scientists to devote more time to nuanced analysis and insights, fostering a shift towards more strategic and interpretative scientific engagement.</p>
<p>The potential benefits of LLMs bring to the fore a host of environmental, ethical, and scientific concerns.For instance, the environmental footprint of LLMs is significant, owing to their resourceintensive training processes.Ethically, these models risk propagating biases and misinformation due to their reliance on data sourced from the internet.Additionally, the intricate and stochastic nature of their training complicates issues of reproducibility, trustworthiness, and intellectual property rights.Tackling these issues is paramount for the responsible and advantageous deployment of LLMs within the research community and broader society.</p>
<p>Although LLMs are a relatively new phenomenon, they have already generated considerable debate across various academic disciplines.Figure 1 illustrates the rapid increase in publications over recent years (sourced from Scopus database searches using the criteria "large PRE/1 language PRE/1 model").Yet, academic consensus on their research impact remains elusive.Recent literature captures a dichotomy of opinions: on one hand, some assert that LLMs are poised to transform research methodologies [6]; on the other, skeptics argue that LLMs will not significantly alter the research landscape [7].</p>
<p>In this paper, we deliver a concerted evaluation of LLMs from the multidisciplinary perspectives of Schmidt AI Fellows, Data Science Fellows, and Research Staff at the Michigan Institute for Data Science.With our collective expertise spanning over 10 diverse fields 1 , we endeavor to shed light on the utility of LLMs in broad research activities and their specific implementation in distinct scientific domains.Concurrently, we underscore the varying efficacy and potential limitations of LLMs across these disciplines.This document captures the contemporary state of LLMs at a time when the research environment is swiftly transforming, providing a timely overview of the current advantages, obstacles, and our collective viewpoint.In terms of terminology to describe LLMs, general pre-trained models, like GPT-4, have garnered significant mainstream attention, however, these models are just one class of LLM.Another class of models consists of pre-trained LLMs that are specialized on a domain by further training on domain specific data.Such models will be referred to as fine-tuned LLMs throughout the paper.Further, the transformer architecture, as the basis of LLMs, has been used to great success with sequential, but not necessarily textual, data in fields as diverse as biology, chemistry, economics and health sciences.We refer to these models as domain-specific LLMs.This work will discuss all three of these LLMs classes and their potential impact on scientific research.First we will discuss general research tasks before exploring domain-specific applications and the future outlook for LLMs in research.</p>
<p>Research Tasks: Applications and Challenges</p>
<p>LLMs provides great opportunities in promoting the research workflows across scientific domains.</p>
<p>Meanwhile, there still exist limitations and challenges that need to be noticed when LLMs are applied to research methodologies.Here we summarize applications and challenges of LLMs in general research workflows across scientific domains.As these research tasks are common across all fields of research, the discussion in this section focuses on general pre-trained and fine-tuned LLMs.</p>
<p>The next section (Sec.3) explores domain-specific models.</p>
<p>Engineering, NF: Environmental Science, MHV: Mathematics, JIL: Astronomy, JL: Genetics and Developmental Biology, BM: Economics and Statistics, AHR: Aerospace Engineering, KNR: Computer Science, ST: Chemistry, AV: Nanoscience &amp; Nanotechnology, and XX: Physics.</p>
<p>Applications</p>
<p>The potential for LLM integration in research workflows across scientific domains is immense.These opportunities will be summarized similarly to the categories identified by [8] and are ordered to reflect a general scientific research workflow: ideation and information review, coding and data analysis, and writing.For each research task, we review how LLMs can be used for each stage of the scientific process, specifically: ideation and information review in section 2.1.1,coding in section 2.1.2and writing in section 2.1.3,as well as some of the challenges associated with each task.Although challenges are mentioned briefly in each subsection, major challenges are described in detail in section 2.2.</p>
<p>Ideation and Information Review</p>
<p>Traditionally, information is gathered manually from the literature.Information review is the process of obtaining relevant information from a large collection of unstructured or semi-structured data, and is essential to research design and ideation.In many research domains, information is spread across unstructured text, figures, and tables in a huge body of research papers.While existing information retrieval (IR) systems such as Google Scholar, PubMed, and arXiv streamline the process of conducting thorough literature reviews, information overload remains an outstanding problem in most academic domains [9].Nonetheless, LLMs have already shown to have excellent performance on information retrieval and review tasks due to being pre-trained on a large corpus of data.LLMs can parse through texts, papers, and other natural language sources while extracting relevant information and relations at a pace no human can match.Potentially, these capabilities can lead to significant accelerations in the generation of research questions, summarization of existing literature, and identification of research gaps.</p>
<p>In addition, the potential for LLMs to automatically extract data from text sources could lead to an influx of meta-analytic data at an unprecedented scale.This can include both textual and tabular data [10,11] and has been successfully applied in many diverse domains such as economics, aviation safety, and health settings [e.g., [12][13][14][15][16].We will further showcase some fine-tuned and domain-specific LLMs in Section 3. Generally, these frameworks aim to automate the synthesis and summarization of findings across multiple studies, enabling researchers to gain valuable insights and identify patterns in the collected data.</p>
<p>Recent research states found that LLMs can now generate research questions [17].While current use has centered on general models, domain-specific LLMs are emerging, which will better integrate and apply to growing domain literature.These models promise to distill domain knowledge, sparking new research directions.Additionally, LLMs can foster interdisciplinary work by bridging knowledge gaps across scientific fields.</p>
<p>Coding</p>
<p>LLMs excel in many coding tasks such as code generation, completion, synthesis and translation [18].From simple text prompts, LLMs can generate and rewrite code with high readability and efficiency.The ubiquity of coding tasks in research means that these capabilities may be a massive aid for academics who need to conduct simulations, data processing, graphical visualization, or data analysis.The near instantaneous generation of code, combined with recursive feedback from users where any errors messages encountered are fed back into the LLM, can lead to massive time savings compared to a manual search of documentation or question-and-answer websites.Common coding errors, such as syntax errors, incorrect function usage or object instantiation, can now rapidly be solved with a few text prompts to a general pre-trained LLM.In the past this would require tedious line-by-line code checking or, as compared to prompting an LLM, more time spent searching for answers in code forums and online code documentation.Vaithilingam et al. [19] evaluated the usability of LLMs for code generation, and found that it is an excellent tool to kick-start a task without requiring the effort of searching online.These sorts of time and effort savings are especially significant when using new programming languages, or for researchers who do not have extensive programming experience.The lack of domain specificity of many coding tasks will heighten the usefulness of LLMs across a broad range of disciplines.To that end, examples of ChatGPT generating code already exist for a diverse set of tasks.Code for modeling carbon concentrations [12], molecular analysis [20][21][22], and even solving partial differential equations [23] have all been generated via ChatGPT without additional fine-tuning.Furthermore, LLMs are just as impressive at translating between coding languages as they are for generating new code from text prompts [24,25], enabling researchers to quickly and efficiently modernize existing code within their field.</p>
<p>LLM-based coding assistants can thus greatly streamline the code development pipeline.A useful LLM-based coding assistant is GitHub Copilot, which has integrated Codex, a LLM trained specifically for coding tasks, into an integrated development environment (IDE).Nonetheless, caution is needed as these models can generate bugs or security vulnerabilities that may be difficult to discern, especially when generating many lines of code [26].Tools such as Codex should be used with caution as powerful yet imperfect coding assistants.Another general concern of LLMs is reproducibility.Due to the stochastic nature of LLMs the same text prompt may generate different code, users should bear this in mind and check LLMs generated code for correctness and completeness.Nonetheless, even with errors, it is generally faster to code with LLM assistance, especially for unfamiliar coding tasks.</p>
<p>Writing</p>
<p>Effective communication of scientific results is essential for advancing research, securing funding, and informing the public; it hinges fundamentally on clear, precise writing.LLMs can be used to produce clear English statements based on a list of arguments and references, resembling advanced versions of grammar checking and editorial software [27].In addition, LLMs can prompt relevant ideas and topics during editing and rewriting, assisting authors to overcome writing blocks by presenting comprehensive perspectives.Using LLMs as a writing assistant is particularly beneficial for researchers unacquainted with scientific writing and non-native English speakers, as they can enhance writing style, composition, and punctuation, thus helping leveling the playing field.For public education and science communication purposes, LLMs can efficiently generate texts for diverse audiences, such as automated data summaries [28], press releases highlighting new discoveries, and outreach articles tailored to various educational backgrounds [17].Likewise, LLMs can facilitate the translation of scientific articles into multiple languages, thereby expanding the audience base.</p>
<p>General Challenges</p>
<p>Though LLMs have great promise for each stage of the scientific method, there are a number of limitations and challenges that need to be acknowledged by those looking to implement them in their own research.Challenges and limitations can be general, such as, explainability, reproducibility and environmental impact or primarily related to specific research tasks.Here, we highlight some of the key challenges and limitations users should be aware of when using LLMs for research.</p>
<p>With the increased popularity of LLMs, many scientific publishers have published updated policies on using generative AI in preparing scientific manuscripts.While some strictly prohibits any use of AI generated text [29], most journals allow LLMs as an editing tool for improving readability and languages [30][31][32][33][34], and producing new ideas and text solely based on LLMs, without critical review and editing by the human author, are generally considered scientific misconduct.As a tool/software, LLMs does not qualify for authorship per guidelines of all the above-mentioned journals, instead the use of LLMs should be disclosed and detailed in the methods or acknowledgments sections, similar to other software tools.However, with the fast evolution of LLMs, the policies regarding using LLMs in scientific research are likely to evolve with the technology.</p>
<p>Explainability</p>
<p>Explainability, within the scope of neural networks and machine learning (ML), refers to the extent to which a model's internal processes and decision-making pathways can be elucidated and understood by humans.This attribute, generally known as explainable artificial intelligence (XAI), is an emerging sub-field within artificial intelligence (AI) research.An ML model possessing high explainability allows not only for decomposing the effect of features on the outcome, but also for tracing how the model reached a particular result.Such transparent operation fosters trustworthiness, supports troubleshooting, enhances replicability, and assists in the tasks of bias detection and mitigation.In contrast, models with low explainability, often associated with complex LLMs like GPT-4 [1], obfuscate the inner workings behind their outputs, resulting in a 'black box' situation.</p>
<p>Even though seminal methods for LLMs explainability have been recently developed, e.g.[35][36][37][38], challenges remain.The opaqueness of LLMs, which are effectively black boxes to users, largely stems from their complex architecture, in conjunction with the uncertainty of the inner mechanisms for generating output 2 .Transformer-based LLMs embed words into vectors, and process these through multiple nonlinear layers with 'self-attention' mechanisms, then weighing the relevance of different parts of the input, and sampling from a probability distribution to produce text.Selfattention mechanisms allow a neural model to weigh and focus on different parts of the input based on their relevance to a given token, enabling the model to capture context-dependent relationships in sequences.Unfortunately, this context-based weighting system combined with stochastic sampling produces a somewhat opaque and non-inspectable algorithm, even with the use of state-of-the-art XAI tools.If a researcher is to inspect such a model with the intent of understanding how an output is generated, it would be required deep understanding of the mechanisms involved, in addition to a herculean task of combining the understanding of each submodel that compose the entirety LLMs.</p>
<p>LLMs generate responses based on patterns in their training data; thus, biases or inconsistencies in their outputs often reflect the training data's nature.Lack of transparency in the training data complicates understanding the reasons behind a LLM's specific outputs and assessing its reliability across different domains.The undisclosed nature of the training data for many LLMs hinders explainability, posing a significant barrier to their ethical use in sensitive areas and in building public trust.</p>
<p>Reproducibility</p>
<p>Reproducibility poses significant challenges to using LLMs as a central tool in research.The probabilistic sampling techniques and intricate training processes employed make obtaining consistent and reproducible results difficult.For example, given the same input and model state, the output will vary across runs due to the probabilistic sampling techniques used.However, reproducibility concerns stemming from this sampling procedure can be mitigated by adjusting model settings which regulate the randomness.For instance, a zero "temperature" setting makes GPT-3 output deterministic [8].Other aspects of reproducibility are more difficult to deal with.Model settings may be adjusted to control the output of identical prompts, but with even slight differences to the input prompt, such as punctuation, number of spaces, etc., divergent results may occur.Furthermore, LLMs are trained on distributed computing frameworks across multiple GPUs.The parallelization and synchronization parameters involved in distributed training are vast [39].Subtle differences in the learning process can lead to significant variations in the model's behavior and output.The computational scale required to train LLMs may make it infeasible to reproduce the exact training conditions or retrain the model from scratch.Finally, as with most software, LLMs are continuously updated and reproducing results from older model versions or comparing results across versions can be challenging if old versions are not maintained and available.</p>
<p>To address these challenges and promote reproducibility, making the training process of the LLM model more transparent and more open source would be helpful.Meanwhile, researchers and practitioners are increasingly documenting the exact training and evaluation procedures, sharing code and models, providing explicit instructions for environment setup, and establishing standardized evaluation benchmarks.By establishing clear guidelines, open-sourcing codes, and promoting transparency in the both model developer and research community, LLM reproducibility can be enhanced.</p>
<p>Privacy Concerns</p>
<p>While the ownership of data generated by LLMs is still unclear and yet to be settled in the courts, there's no ambiguity about the ownership of the data inputted into these models.This clarity contrasts sharply with another issue: a notable difference exists between LLMs functioning on standalone architectures and those integrated with wider networks.In the latter scenario, input data might be stored, examined, and potentially utilized for subsequent training by third parties.Popular LLMs privacy policies explicitly state that various data are captured during usage, for example, ChatGPT captures: log data, usage data, device information, cookies and analytics [40].Of particular import and concern for researchers is the statement "We may automatically collect information about ... the actions you take".Such a provision implies retention of all interactions with ChatGPT, encompassing facets like ideation, linguistic assistance, data interpretation, coding assistance, and more.Google's Bard 'Privacy Help Hub' states "To help with quality and improve our products (such as generative machine-learning models that power Bard), human reviewers read, annotate, and process your Bard conversations."[41].While this is stated clearly in the privacy notice for Chat-GPT and Bard, a substantial fraction of researchers will not delve into these privacy stipulations, whether due to a lack of awareness of the risks or a belief that the benefits of using LLMs outweigh the risks.Other LLMs may not be so clear with regard to stating the ownership of usage data.The ramifications are magnified when you consider data that is sensitive in nature.For instance, healthcare researchers working with confidential patient data, or researchers collaborating with government or industrial entities that involve propriety data of significant strategic or commercial value.</p>
<p>However, in response to the burgeoning concerns over data privacy and the potential misuse of sensitive information, several mitigation strategies are being devised and implemented across the academic and industrial spectrum.The University of Michigan, recognizing the utility of LLMs yet cognizant of their inherent privacy vulnerabilities, has pioneered a novel approach with the introduction of 'U-M GPT ' [42].This model is exclusively accessible to UM personnel, thereby ensuring a controlled environment and substantially reducing the risk of unintended data exposure of research related data and prompts to external entities.'U-M GPT' collects personal information for operational purposes, doesn't use user data to train its AI models, doesn't sell or license personal information, shares data with specific service providers (i.e.Microsoft Azure) for operational reasons, and implements measures to protect data, while being subject to periodic updates in its privacy policy (accurate as of publication of this article).Similarly, recognizing the need for enhanced data protection, OpenAI has announced an enterprise version of ChatGPT [43].This adaptation offers privacy guarantees, ensuring that sensitive information remains within the confines of the designated enterprise.There are also an increasing number of institutions and businesses that are opting for local installations of LLMs.By hosting models on their own infrastructure, they effectively sidestep the risks associated with cloud-based or third-party managed solutions.Such local deployments grant organizations full autonomy over data management, allowing them to institute data protection protocols in line with their specific requirements and the nature of the data they handle.Through these measures there are attempts to harness the potential of LLMs while concurrently addressing the pivotal issue of data security.This consideration can be found in current medical literature for dealing with sensitive data [44], social sciences for community based data pooling while retaining individual and community data security [45].</p>
<p>Environmental Impact</p>
<p>LLMs have both direct and indirect impacts on the environment.Training LLMs requires extensive computational resources, including powerful processors and high-capacity storage systems [46].These computations consume a substantial amount of electricity, which often comes from fossil fuel-based power generation, contributing to carbon emissions.Luccioni estimates the power consumption of training various LLMs, all with billions of parameters, to be in the range of 324 to 1287 MWh resulting in carbon emissions in the range of 30 to 552 tons of CO 2 [47].The authors further highlight the impact that local data center power usage efficiency and energy source has on carbon emissions.For example, a LLM trained in the central US would emit an order of magnitude more CO 2 than a LLM trained in France.Additionally, popular LLMs such as ChatGPT have millions of active users, resulting in an operational electricity cost that far exceeds training costs [48].</p>
<p>Maintaining and upgrading LLMs require constant hardware updates.The rapid development of more powerful hardware can render existing equipment obsolete, leading to electronic waste disposal concerns.To promote sustainability, it is important to consider the environmental implications of using LLMs.Before selecting an LLMs for use in your specific field, consider:</p>
<ol>
<li>
<p>Utilizing smaller models when possible, as they often require less energy.</p>
</li>
<li>
<p>Leveraging existing pretrained models rather than training new ones from scratch.</p>
</li>
<li>
<p>Being conscious of the location and energy sources when using computational resources.</p>
</li>
</ol>
<p>By choosing more environmentally-friendly approaches, scientists can help drive demand in a direction that is less taxing on our planet.Being informed and making sustainable choices can ensure that the benefits of LLMs are enjoyed without undue environmental costs.</p>
<p>Misinformation</p>
<p>LLMs are trained on vast amounts of data, often from unknown sources via the internet, which can lead to misinformation by absorbing the biases and inaccuracies present in their training data [49,50].This absorption is not limited to factual inaccuracies, but also extends to ethical and moral norms, reflecting the societal biases present in the data.This issue is further enforced by the fact that LLMs currently lack the ability to discern the veracity of the information processed.Generally, they do not have a built-in mechanism to fact-check or validate the information against reliable sources.As a result, an LLM might inadvertently spread misinformation, especially if it is prevalent in the training data.This is particularly concerning given the increasing reliance on LLMs for tasks such as document retrieval, sentence selection, and claim verification, where the accuracy and reliability of the information are paramount [51].Misinformation from LLMs could potentially misguide researchers, negatively impacting the progress of research by creating false paths for other scientists to follow.</p>
<p>Hallucinations</p>
<p>In addition to generating misinformation, as discussed in section 2.2.5, LLMs are also capable of generating information that is entirely fictional when asked about information outside its training data, resulting in what is often described as hallucinations.The presence of hallucinations poses serious challenges for scientific research [52,53].Researchers who rely on language models to assist in literature reviews will find that LLMs refers to non-existent citations, leading to potential confusion, wasted effort, and the danger of dissemination of misinformation.When it comes to using LLMs to explain theories and concepts, we have also faced incorrect explanations and interpretations of scenarios.Although a powerful tool, these models are not currently able to provide completely factual information and therefore researchers will need to critically evaluate and validate LLMgenerated information, cross-referencing it with established knowledge and authoritative sources.Existing models which are not integrated with the internet are unable to provide accurate citations for the content that they generate.However, this limitation is being overcome by state-of-the-art models such as Bard [54] and Elicit [55] which are able review and summarize literature directly while providing direct sources.Consequently, these looming IP challenges pose profound implications for the governance and regulatory landscape of LLMs, necessitating urgent scholarly attention and legislative action.Currently, OpenAI is facing a lawsuit over how it used people's data to train ChatGPT [56].Ultimately, LLMs should be treated as a tool in aiding the writing process in the research pipeline, and the human authors should be held accountable for any statements or ethical breaches.</p>
<p>Plagiarism and Intellectual Property</p>
<p>Domain-Specific Research Tasks</p>
<p>Effective application of language models for addressing domain-specific research comes down to one question: can data in that domain be meaningfully represented as a sequence?Language entails a structured sequence of words such that an overall meaning can be attached to it.In some domains, data are naturally sequentially structured and as a consequence, in such areas of research there have been a plethora of LLM applications in the past two to three years.In this section, we will discuss some recent applications of LLM architecture in solving research problems, sectioned into various domains.This section discusses domain-specific LLMs, models trained on non-textual data in a specific domain, as well as general or fine-tuned LLMs where appropriate.</p>
<p>Biological Sciences</p>
<p>For centuries, biological knowledge has been disseminated through the scientific literature.Vast archives of papers in scientific journals and preserved specimens in natural history museums contain invaluable information on biological diversity.However, this information has proven to be inaccessible for large data analysis [57] and its automatic extraction has been historically limited [58], thus hampering research into ongoing human-caused biodiversity crises.The efficient access and extraction of this information would give scientists access to a vast amount of data.With the remarkable improvements of LLMs to comprehend text, there is potential for the automated annotation of taxonomic texts with the eventual extraction of morphological character information [59][60][61][62].However, these phenotypic descriptions are often difficult to mine with pre-LLM technologies because of homonymy and synonymy of morphological descriptions [63].Although, the automatic extraction of morphological, taxonomic, and geospatial information from biological text [59][60][61][62] has seen active development in recent years and the integration of foundational LLMs into these toolkits has the potential to further revolutionize and accelerate biological sciences towards an even more data-driven science.</p>
<p>Chemical Sciences</p>
<p>Multiple language models have been shown to perform quite well in property prediction with stringbased representations.For example, LLMs like SMILES-BERT [64], ChemBERTa-2 [65], which was based on RoBERTa, and MoLFORMER [66] developed by IBM show that language models perform quite well at learning molecular properties solely from string-based short representations as compared to other deep learning (DL) methods.Language models have also been shown to perform better than some graph generative models in generating complex molecular structures with specified characteristics [67].</p>
<p>Engineering</p>
<p>As LLMs improve capabilities for applications in fundamental sciences, they will likely be useful for engineering applications in the future as well.At the time of this writing, LLM integration into engineering research remains sparse and somewhat limited in scope to the general tasks outlined in the previous section.As a result, LLMs have not yet made a significant impact on engineering problem-solving.Engineering problems often require careful application of mathematics, statics, dynamics, chemistry, principles from other domains, and specific domain experience that may not be well-documented or represented in training corpora.Despite these limitations, there is significant untapped potential for LLMs to positively impact engineering disciplines.Preliminary studies on LLM performance on the Fundamentals of Engineering (FE) exam, a standardized licensing test for professional engineers, have shown that models such as GPT-4 can achieve an overall accuracy of around 75% on the Environmental exam with minimal prompt modifications [68].Considering the passing score of 70% and the overall pass rate of 64% [68] this indicates the potential LLMs have in tackling engineering problems.</p>
<p>The existing research in engineering has positioned LLMs as a tool to optimize workflows and improve productivity.For example, compliance with federal regulations is essential for safety-critical applications, but reviewing these guidelines can be time-consuming and labor-intensive.Fine-tuned BERT models such as aeroBERT [14] and SafeAeroBERT [13] have already been researched for their potential usage in reviewing safety regulations for the aerospace industry.LLM-enabled code generation may prove instrumental for yielding process optimization benefits in additive manufacturing, where Gcode is used for controlling layer-by-layer printing and process parameters [69].A further potential application of LLMs in engineering is in aiding causal reasoning tasks.[70] uses LLMs to assess the arrow of causality between cause-effect pairs such as the rotation of a Stirling engine and the heat bath temperature as well as the cement ratio and the compressive strength of concrete.</p>
<p>While these cause-effect pairs are applied engineering, rather than research, this shows how LLMs can translate engineering domain knowledge into formal methods for downstream causal reasoning tasks, and is thus an exciting opportunity for enhancing research on causal effects in engineering.</p>
<p>Ultimately, the potential for LLMs in addressing fundamental problems in engineering will depend on how well data from engineering domains can be represented in forms amenable to the underlying transformer architecture.For example, we expect that creative representations of time series data that leverage text or sequences will help unlock its potential for high-dimensional anomaly detection, fault diagnosis, and prognostics problems.</p>
<p>Environmental Science and Sustainability</p>
<p>Given the multitude of urgent environmental challenges we face, the demand for innovative research methods to tackle these issues has become paramount.Some environmental fields using unstructured textual data, such as social surveys [71,72] or social media posts [73][74][75] can harness relatively simple LLMs methodologies such as sentiment analysis and topic clustering to enhance their research outputs.For example, the advent of LLMs has revolutionized how researchers can approach using social media data to address environmental challenges including, clean energy, climate change and ecosystem services [76][77][78].</p>
<p>However, most environmental science research uses multi-modal data and diverse data sources, not just textual data.Here, LLMs can provide numerous unique opportunities for environmental science research using diverse data structures.For example, LLMs can be combined with image data and computer vision (CV) methodologies for a range of tasks, including classifying satellite imagery [79] or identifying species in photographs [80].LLMs can also help create simulations, including, generating underwater simulations for testing marine exploratory robots [81], or ecosystem modeling for forecasting the impacts of environmental shifts on species distributions [80].</p>
<p>Environmental science research often requires interdisciplinary collaboration.LLMs can help to translate complex scientific concepts into language that is easier for experts and non-experts alike to understand, assisting in cross-disciplinary communication between researchers with different domain expertise [17].Furthermore, researchers in environmental science can benefit from LLMs as they provide a common platform for sharing information and ideas, thus facilitating experts in different fields (as well as policy-makers and the general public), to collaborate and develop new strategies for pressing and holistic environmental challenges such as the impact of climate change on public health [17].</p>
<p>Health Sciences</p>
<p>Health science studies deal with a range of textual data sets including patient information and notes, meta-analyses of previous studies, and social media discussions [82].However, simply using off-the-shelf LLMs for biomedical text mining frequently produces inadequate outcomes due to the lack of understanding of domain-specific terminology.Fine-tuned models have a more nuanced understanding of biomedical texts, thus providing state-of-the-art approaches to biomedical textual data analysis [83].Due to the rapidly increasing amount of biomedical documents, LLMs will be key to utilizing this data effectively.One example is BioBERT [84], which is the BERT model fine-tuned on biomedical texts and has shown significant improvement over off-the-shelf models in carrying out biomedical text-mining tasks.Another LLM specifically developed for health research is the GatorTron model [85], which was designed to improve clinical NLP tasks.By increasing previous model parameters from 110 million to 8.9 billion parameters and improving the accuracy of clinical NLP tasks, such as de-identification of records, the GatorTron model may pave the way for enabling medical AI systems to improve healthcare delivery.</p>
<p>LLMs can be an equally relevant tool for understanding problems of public health.For instance, the impact of the support of online communities in patients with mental disorders was assessed by [82], with the aid of language models for sentiment analysis of web scraped data.Analogously, [86] utilized topic modeling and social network analysis on Reddit data, in order to understand the relationship of Reddit communities and people suffering from eating disorders.With the help of NLP, [87] conduct an analysis of thousands of birth stories posted online, summarizing emotions and decisions taken in this often traumatic medical experience.</p>
<p>Materials Science</p>
<p>LLMs, with their extraordinary text-mining capacities, can search through vast repositories of materials science literature, synthesizing vast amounts of information into actionable insights.This capability not only speeds up materials discovery, but also paves the way for novel connections between existing knowledge.However, several challenges remain: non-textual data, tacit knowledge, and jargon.To fully exploit the potential of LLMs in materials science, it is crucial to develop mechanisms that can bridge these gaps, such as developing domain-specific models, utilizing multimodal neural networks (which can combine text data and images [88]), and tightening collaboration within material science communities across the globe.</p>
<p>Several groups developed materials-aware language models, namely MatSciBERT [89], Mate-rialBERT [90], and polymer-oriented MaterialsBERT [91].Unlike generic language models, these models were trained on a large corpus of materials science-centric publications, making them adept at understanding and generating content specifically in this domain.Such domain-specific LLMs can offer more accurate and contextually relevant outputs, substantially enhancing their utility for researchers in the field.For example, transformer architecture models were used for the prediction of metal-organic framework (MOF) synthesis [92] and property prediction [93].In comparison to structure-agnostic methods like Stoichiometric-120 and revised autocorrelation (RACs), a structureagnostic deep learning method based on the transformer model, named as MOFormer, not only achieves significantly higher accuracy-21.4% and 16.9% better in band gap prediction and 35-48% and 25-42% better in various gas adsorption prediction tasks, respectively -but also outperforms the structure-based Smooth Overlap of Atomic Positions (SOAP) method in band gap prediction even with less training data [93].Additionally, pretraining has been shown to further enhance the model's performance, improving MOFormer's accuracy by an average of 5.34% and 4.3% for band gap and gas adsorption prediction, respectively [93].</p>
<p>Recently, collaborative effort across eight countries and 22 institutions set up a hackathon to delve into the LLMs for materials science [94].This event underscored the growing interest and vast potential of LLMs within the materials science domain.Participants engaged in a comprehensive array of tasks, from accurate molecular energy predictions and prediction the compressive strength of concretes to molecule discovery by context and the extraction of insights from unstructured data sources.The variety of subjects tackled and the ability to produce working models in a short timeframe highlights the crucial role LLMs might play in the future of materials science.While the hackathon predominantly centered on materials science, the projects' diversity highlighted a salient feature of LLMs: their versatility and significant potential to build bridges connecting the diverse range of scientific disciplines.</p>
<p>Mathematics</p>
<p>Despite the large number of LLMs publications in mathematics (as depicted in Fig. 1), upon closer inspection, the majority of the research articles listed fall under either applied fields that use mathematics or mathematical aspects of LLMs.As such, at the moment, LLMs are more of a subject of study in mathematics than a method applied to study problems in the field of mathematics.For example, the question of how to use LLMs for mathematical reasoning and problem-solving is in itself an active field of research [95,96], as some state-of-the-art LLMs when applied to commonsense logic and mathematics research have been shown to be not up to standard [97,98].Other directions of research go towards mathematical aspects of LLMs [99,100].</p>
<p>Perhaps due to the lack of theoretical understanding of LLMs, they have not been used in mathematics research.The interaction between mathematics and LLMs, for now, will be towards improving and understanding LLMs, and not using LLMs as serious generative tools to solve Mathematics problems, as seen in some other fields.However, this does not mean that LLMs have not entered the mathematics research pipeline through the tasks delineated in the previous section.Furthermore, for example, in computational mathematics and scientific computing there are already many examples of the use of LLMs in the computation of scientific problems (e.g.[23,101]).</p>
<p>Social Sciences</p>
<p>The aforementioned work from [8] provided a thorough guide on how LLMs can be used as a research assistant from the perspective of a social scientist.Beyond research assistantship, however, LLMs can be useful as a central tool in a myriad of Social Sciences' analysis, as indicated by Fig. 1, since data in text format is rather common in this scientific field.In this section, we discuss: (i) general methods involving LLMs useful for social scientists; (ii) LLMs as an object of social studies per se; and (iii) several research examples employing language models in subfields ranging from Economics, Business, Finance, to technology adoption and public affairs.</p>
<p>General LLMs tools.Several methods employing LLMs can be potentially useful in the social scientist toolkit.The first one, already utilized by Environmental and Health Sciences (see sections 3.4 and 3.5), is sentiment analysis.[102] provided learning materials for this task, which could employ LLMs or other language methods.Even though LLMs outperformed several tools for sentiment analysis, [103] illuminated potential caveats of LLMs in tasks involving structured sentiment information.Another useful tool for the social scientist concerns the application of pretrained models for specific language oriented tasks.For instance, [104] developed the TweetEval, a standardized tool to execute several tasks on tweets, including sentiment analysis, while also providing benchmarks for evaluating performance.A further distinct domain specific language model is SciBERT [105], trained on the Social Science Citation Index journals.SciBERT performs state-of-the-art sequence tagging, sentence classification, dependency parsing, etc., in the academic literature of Social Sciences.A final tool worth mentioning regards the use of LLMs for aiding causal inference tasks.Notably, GPT-4 outperforms existing models in causal discovery tasks and counterfactual reasoning [70].In fields such as Social Sciences, Biostatistics, Computer Science, Epidemiology and Environmental Sciences, LLMs can aid researchers in creating Directed Acyclic Graphs (DAGs) that are essential for causal effects estimation.Researchers input e.g.book content, papers, or other sources of theoretical information into a language model, outputting the causal graph of interest [106].Despite potential drawbacks, this application can drastically reduce the effort put into building causal graphs, or serving as a verification tool, in addition to existing methods in causal inference.</p>
<p>LLMs being assessed.LLMs themselves can be the object of study for social scientists.[107] raised the concern that language models often fail to reflect societal norms and values in situations not seen before.These authors provided a methodology to train language models to better extrapolate learned values in new scenarios.Another set of researchers [108] applied a series of canonical cognitive psychology tests on GPT-3, finding that these models perform at least as good as humans in most tasks, but failing causal reasoning tasks.In related work, Deep Mind social researchers [109] tested language models on abstract reasoning problems.They found that the state-of-the-art LLMs, with 7-70 billion parameters, mimicked human behavior considerably closely in realistic situations, but performed poorly on abstract tasks disconnected from reality, which is in line with [110].Sub-field specific applications.LLMs were utilized to summarize a high volume of the Spanish parliament documents with RoBERTa and GPT-2 [111], potentially making policy more straightforward to follow and aiding policy decision-making.[112] employed language models to analyze administrative data as well, measuring the spatial variation of religiosity in Indonesia.In the sub-fields of Business and Finance, [113] is a seminal work on sentiment analysis to forecast sales.</p>
<p>More recently, [114] identified key factors on tweets that are correlated to startup business success.[115] measured the correlation between moods captured on Twitter and the Dow Jones Industrial Average over time, while [116] and [117] performed sentiment analysis of financial news and microblogs, respectively.In the last month, [118] demonstrated that although LLMs have been utilized</p>
<p>for financial sentiment analysis, they still fail to accurately interpret numerical magnitudes and to capture some financial contexts.In terms of technology business, [119] measured consumer sentiment towards high-tech products, and [120] and [121] established connections between technology adoption and their impact on consumers using language models.</p>
<p>Finally, in the sub-field of Economics, [122] provides an overview of language-oriented tasks and methods for economists.[123] and [124] studied the labor market with language models.While [123] analyzed job postings data with DistilBERT to measure the actual shift to remote work due to the COVID-19 pandemic, [124] employed the Gensim language model to go through over one million higher education syllabi, establishing connections between higher education skills and workplace activities and earnings, using data from the Department of Labor.[125] converted product text information to numeric data using LLMs, in order to measure hedonic prices, i.e. the contribution of products' characteristics to the final price of the product.A further application in the sub-field of Economics is rather speculative when compared to the applications described above, as it has yet to be fully explored.With data abundance, advancements in computing power, developments of refined ML and economic models, researchers are now able to estimate the effects of policy interventions or treatment effects for granular and specific subpopulations in the dataset [126][127][128].</p>
<p>Despite the granularity of results exhibited in these projects, characterizing these subpopulations at scale remains an outstanding challenge, especially when these relatively small subgroups lie at a complicated intersection of a multitude of variables -e.g.gender, race, social economic status, education, etc.In order to tackle this subgroup characterization task, social scientists could employ LLMs, feeding into LLMs all of the characteristic values of each group -e.g. a group could consist of mostly elderly Asian males -outputting a subpopulation description from the language model.If successfully implemented, this could aid policy regulators and the general population to search for specific subgroups in a study, and understand their composition on the fly.In the limit, if researchers can feed the treatment effect estimates associated with each subgroup, LLMs could aid not only in explaining group dynamics, but aid in interpreting results and major trends that stem from complex models.</p>
<p>Conclusion and Future Outlook</p>
<p>There has been much debate about the extent to which LLMs will catalyze a new research paradigm [129,130].Even in the short time that they have been readily available, pre-trained and finetuned LLMs are quickly becoming an indispensable tool for assisting in general research tasks.By automating research steps that are often manually carried out and time-intensive, such as information retrieval and code creation, language models will benefit most domains by increasing a researcher's efficiency and productivity.</p>
<p>In Section 2, we discussed the immense potential of LLMs to facilitate ideation, coding, and writing tasks for researchers.Utilizing LLMs for these tasks also helps breakdown disciplinary barriers, especially when these barriers are maintained by jargon [131].For example, LLMs can serve as powerful mediators in interdisciplinary dialogue, enabling researchers to communicate and share knowledge more efficiently.By unraveling domain-specific specialized terminology, they make work accomplished in one field available to all.This demystification of language encourages crossdisciplinary idea exchange, promoting a shared understanding of concepts.In this way, LLMs serve as bridges that connect researchers, fostering interdisciplinary collaborations.As such, these models not only amplify the capabilities of researchers within their respective fields but also hold the promise of catalyzing interdisciplinary research [17].In contrast, as we discussed in Section 3, when tasks are domain-specific or require high accuracy for data outside the training set, some form of finetuning will be necessary.For example, several fine-tuned BERT models have demonstrated the impact of fine-tuning to improve their efficiency for domain-specific information retrieval and review [13,14,16].Furthermore, some domains are starting to investigate advanced NLP tasks such as topic modeling and sentiment analysis of social media data for environmental science [132], and web scraping to incorporate online information to improve financial predictions [117].</p>
<p>Here we have provided a current snapshot of LLMs and their applications, but recognizing they are still evolving is crucial.Existing literature has yet to push the boundaries of testing LLMs for solving fundamental science problems in research.These models cut across multiple disciplines, which utilize similar data types that are sequential but not necessarily textual.For example, LLMs hold immense potential to be trained to produce outputs that are not just deterministic responses but probabilistic inferences based on string representations of data.This capability could revolutionize the way we interpret and utilize data by enabling these models to estimate the likelihood of various outcomes or predict trends from raw data encoded as text.Such a development would allow LLMs to process and analyze large datasets, identify patterns, and generate statistical predictions, thereby serving as advanced tools for data analysis in fields ranging from scientific research to financial forecasting.The ability to output probabilities rather than certainties adds a layer of sophistication to the model's decision-making processes, reflecting more accurately the uncertain nature of realworld data and allowing for more nuanced and informed decision-making.Harnessing LLMs for the assessment of string representation data has already been explored in learning molecular properties [66], the generation of new protein structures [133], and the prediction of metal-organic framework properties [93].These innovative approaches show great promise for LLMs to revolutionize the research paradigm outside of NLP or general research tasks.However, the applications of LLMs in this manner may not be ubiquitous across scientific domains and further testing is needed to validate its applicability for different domains.In contrast, Multimodal Language Models may provide the next major advancement in general use LLMs.These models can perceive input and generates output in arbitrary combinations (any-to-any) of text, image, video, and audio [134].For instance, these models may assist in the interpretation of complex figures, tables, and mathematics by processing them as input images and producing textual responses.By automating research steps that are often manually carried out and time-intensive, language models will benefit most domains by increasing a researcher's efficiency and productivity.</p>
<p>Finally, it is important to consider that regardless of the application and despite their immense promise for streamlining the research workflow, there are several caveats that researchers need to acknowledge when harnessing LLMs for their research.As state-of-the-art LLMs are black box models, quantifying exactly how outputs are generated remains difficult.The results could be heavily influenced by biases [49,50], or hallucinations [52,53] arising from the training set.Ultimately, the researcher is responsible for their work, regardless of inaccuracies stemming from LLM usage.</p>
<p>Researchers need to be responsible when using LLMs, following the best possible ethical practices, and actively acknowledging and accounting for the limitations and biases of LLMs in their research.</p>
<p>This manuscript comprehensively outlines the dualistic nature of LLMs within an array of scientific disciplines, offering clarity on their distinct advantages and limitations.We have highlighted the universal strengths of LLMs in automating general tasks such as aggregating research data, refining manuscript development, and enhancing coding efficiency, which resonate across various scientific arenas.For example, in materials sciences, LLMs are capable in synthesizing vast quantities of data into actionable insights.In chemistry, they expedite the discovery and characterization of novel substances, markedly accelerating the research cycle.</p>
<p>Specific applications of LLMs are also discussed, with each field witnessing tailored benefits.</p>
<p>In health sciences, LLMs demonstrate prowess in mining extensive datasets for patterns pertinent to diseases.LLMs in environmental science bolster climate modeling and biodiversity evaluations, essential for environmental stewardship.In engineering, these models have the potential to review safety regulations and foster security for workers, while in biological sciences, they advance the interpretation of taxonomic data, demanding precision to prevent the dissemination of inaccuracies.</p>
<p>Acknowledging these benefits, we do not overlook the need for ethical diligence, comprehensive verification measures, and expert involvement to ensure the responsible application of LLMs, thereby averting the propagation of biases and fallacies.We draw attention to the unequal accessibility of LLMs and call for transparency in their creation and operational aspects, the potential for misinformation and hallucinations, privacy concerns, lack of reproducibility of output as well as the consideration of their environmental implications.</p>
<p>Our evaluative commentary aims to foster further discussion and clear considerations of the integration of LLMs in scientific research, promoting a balanced view that capitalizes on their potential while conscientiously navigating their constraints.We conclude with a cautiously optimistic outlook, positing that LLMs, when employed judiciously, will indeed serve as a catalyst for more dynamic and introspective scientific inquiry.</p>
<p>Figure 1 :
1
Figure 1: Number of Large Language Model publications.Scopus search for "large PRE/1 language PRE/1 model" within Article Title, Abstracts or Keywords.Search carried out on November 3 rd 2023.</p>
<p>Plagiarism and intellectual property (IP) issues of LLMs revolve around the concern of unauthorized content reproduction or generation that may infringe upon established copyright laws, trademark protections, and other forms of IP rights.Being trained on large-scale datasets, LLMs often encompass numerous works that are subject to IP rights.As LLMs generate outputs based on their learned patterns and structures from these datasets, there exists a non-negligible probability that their generated content could unintentionally mimic or replicate protected works, thus inadvertently plagiarizing.LLM's ability to create novel content engenders ambiguity concerning who owns the IP rights to such generated outputs.The delineation between what constitutes a transformative use, permissible under fair use doctrine, versus explicit infringement remains a gray area in AI law.</p>
<p>The science domain backgrounds of the authors are, JB: Ecology and Evolutionary Biology, JC: Mechanical
The uncertainty associated from LLMs outputs stems from unclear source of training data, or unavailable training scripts and environment, in addition to the stochastic process of generating outputs. All of these factors impact both the ability to explain and reproduce results from these models.
AcknowledgmentsThis work is supported by the Eric and Wendy Schmidt AI in Science Postdoctoral Fellowship, a Schmidt Futures program.
GPT-4. arXiv:2303.08774[cs.CL]2023OpenAITechnical Report</p>
<p>Pre-training of Deep Bidirectional Transformers for Language Understanding. J Devlin, M W Chang, K Lee, Toutanova K Bert, arXiv:1810.04805[cs.CL]2019</p>
<p>LaMDA: Language Models for Dialog Applications. R Thoppilan, D D Freitas, J Hall, arXiv:2201.08239[cs.CL]2022</p>
<p>Attention Is All You Need. A Vaswani, N Shazeer, N Parmar, arXiv:1706.03762[cs.CL]2017</p>
<p>ChatGPT for good? On opportunities and challenges of large language models for education. E Kasneci, K Seßler, S Küchemann, Learning and Individual Differences. 1031022742023</p>
<p>Our new promethean moment. T L Friedman, 2023</p>
<p>Opinion -Noam Chomsky: The False Promise of ChatGPT -nytimes. N Chomsky, -Jun-202328</p>
<p>Language Models and Cognitive Automation for Economic Research. A Korinek, 10.3386/w30957National Bureau of Economic Research. 2023Working Paper 30957</p>
<p>A Survey of Information Retrieval Techniques. M F Nyamisa, W Mwangi, Cheruiyot Wk, 2017</p>
<p>Leveraging LLMs for KPIs Retrieval from Hybrid Long-Document: A Comprehensive Framework and Dataset. C Yue, X Xu, X Ma, arXiv:2305.16344[cs.CL]2023</p>
<p>InPars-v2: Large Language Models as Efficient Dataset Generators for Information Retrieval. V Jeronymo, L H Bonifacio, H Q Abonizio, abs/2301.01820ArXiv. 2023</p>
<p>. J J Zhu, J Jiang, M Yang, Ren Zj, ChatGPT and environmental research. Environmental Science &amp; Technology. 2023</p>
<p>Towards a Safety-Informed Aerospace-Specific Language Model. Andrade Sr, Walsh Hs Safeaerobert, 10.2514/6.2023-3437AIAA AVIATION 2023 Forum. San Diego, CA and OnlineAmerican Institute of Aeronautics and Astronautics2023visited on 06/13/2023</p>
<p>Tikayat Ray, A Cole, B F , Pinon Fischer, O J White, R T Mavris, D N Aerobert-Classifier, Classification of Aerospace Requirements Using BERT. 202310279</p>
<p>Structured information extraction from complex scientific text with fine-tuned large language models. A Dunn, J Dagdelen, N Walker, arXiv:2212.052382022cond-mat. visited on 06/13/2023</p>
<p>Building astroBERT, a language model for. F Grezes, S Blanco-Cuaresma, A Accomazzi, arXiv:2112.00590arXiv:2112.00590Astronomy &amp; Astrophysics. arXiv e-prints 2021</p>
<p>Use of ChatGPT: What does it mean for biology and environmental science?. E Agathokleous, C J Saitanis, C Fang, Yu Z , Science of The Total Environment. 8881641542023</p>
<p>A systematic evaluation of large language models of code. F F Xu, U Alon, G Neubig, Hellendoorn Vj, 10.1145/3520312.3534862Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming. the 6th ACM SIGPLAN International Symposium on Machine ProgrammingSan Diego CA USAACM2022visited on 06/13/2023</p>
<p>Expectation vs. Experience: Evaluating the Usability of Code Generation Tools Powered by Large Language Models. P Vaithilingam, T Zhang, Glassman El, CHI Conference on Human Factors in Computing Systems Extended Abstracts. 2022</p>
<p>Natural language processing models that automate programming will transform chemistry research and teaching. G M Hocky, A D White, Digital Discovery. 22022</p>
<p>The future of chemistry is language. A D White, Nat Rev Chem. 72023</p>
<p>Do Large Language Models Understand Chemistry? A Conversation with ChatGPT. Castro Nascimento, C M Pimentel, A S , 36926868Journal of Chemical Information and Modeling. 632023</p>
<p>ChatGPT for programming numerical methods. A Kashefi, T Mukerji, Journal of Machine Learning for Modeling and Computing. 42023</p>
<p>Unsupervised Translation of Programming Languages. B Roziere, M A Lachaux, L Chanussot, Lample G ; Larochelle, H Ranzato, M Hadsell, R Balcan, M , Lin H , Advances in Neural Information Processing Systems. Curran Associates, Inc202033</p>
<p>SPoC: Search-based Pseudocode to Code. S Kulal, P Pasupat, K Chandra, Advances in Neural Information Processing Systems. Curran Associates, Inc201932</p>
<p>Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation. J Liu, C S Xia, Y Wang, L Zhang, arXiv:2305.01210[cs.SE]2023</p>
<p>E T Vishniac, Editorial, On the Use of Chatbots in Writing Scientific Manuscripts. Bulletin of the AAS 2023. </p>
<p>A data science platform to enable time-domain astronomy. M W Coughlin, J S Bloom, G Nir, arXiv:2305.00108arXiv:2305.001082023</p>
<p>Science Journals: Editorial Policies. </p>
<p>On the Use of Chatbots in Writing Scientific Manuscripts. </p>
<p>10.1021/acsnano.3c01544Best Practices for Using AI When Writing Scientific Manuscripts. </p>
<p>ICML 2023: Clarification on Large Language Model Policy LLM. </p>
<p>. Nature Editorial Policies: Artificial Intelligence. </p>
<p>Combustion and Flame: Guide for Authors. </p>
<p>Language models can explain neurons in language models. S Bills, N Cammarata, D Mossing, 14.0520232023</p>
<p>Explaining black box text modules in natural language with language models. C Singh, A R Hsu, R Antonello, arXiv:2305.09863[cs.AI]2023</p>
<p>Visualizing and Explaining Language Models. Amp Braşoveanu, R Andonie, arXiv:2205.10238[cs.CL]2022</p>
<p>Explanations from Large Language Models Make Small Reasoners Better. S Li, J Chen, Y Shen, arXiv:2210.06726[cs.CL]2022</p>
<p>Dynamic Stale Synchronous Parallel Distributed Training for Deep Learning. X Zhao, An A Liu, J , Chen Bx, arXiv:1908.11848[cs.DC]2019</p>
<p>Local Large Language Models for Complex Structured Medical Tasks. V Bumgardner, A Mullen, S Armstrong, C Hickey, Talbert J , arXiv:2308.017272023arXiv preprint</p>
<p>Secure Community Transformers: Private Pooled Data for LLMs. T South, G Zuskind, R Mahari, T Hardjono, </p>
<p>Tracking and Predicting the Carbon Footprint of Training Deep Learning Models. Lfw Anthony, B Kanding, Selvan R Carbontracker, arXiv:2007.030512020cs, eess, stat. visited on 06/23/2023</p>
<p>Estimating the Carbon Footprint of BLOOM, a 176B Parameter Language Model. A S Luccioni, S Viguier, A L Ligozat, arXiv:2211.02001[cs].2022visited on 06/23/2023</p>
<p>ChatGPT Sets Record for Fastest Growing User Base, Analyst Note. Reuters. Reuters, 2023visited on 06/15/2023</p>
<p>More human than human: Measuring ChatGPT political bias. F Motoki, V P Neto, V Rodrigues, Public Choice. 2023</p>
<p>Bias Out-of-the-Box: An Empirical Analysis of Intersectional Occupational Biases in Popular Generative Language Models. H R Kirk, Y Jun, F Volpin, Advances in Neural Information Processing Systems. Curran Associates, Inc202134</p>
<p>Combining fact extraction and verification with neural semantic matching networks. Y Nie, H Chen, M Bansal, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence201933</p>
<p>A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity. Y Bang, S Cahyawijaya, N Lee, arXiv:2302.04023[cs.CL]2023</p>
<p>Artificial hallucinations in ChatGPT: implications in scientific writing. H Alkaissi, S I Mcfarlane, Cureus. 152023</p>
<p>Bard, Bard, A Large Language Model from Google AI. 2023</p>
<p>Elicit: The AI Research Assistant. Ought, 2023</p>
<p>FTC is investigating ChatGPT-maker OpenAI for potential harm to consumers. B Fung, 2023visited on 08/21/2023</p>
<p>Dataset search in biodiversity research: Do metadata in data repositories reflect scholarly information needs?. F Löffler, V Wesp, B König-Ries, Klan F , PLoS ONE. 162020</p>
<p>Applications of Natural Language Processing in Biodiversity Science. A E Thessen, H Cui, Mozzherin Dy, Advances in Bioinformatics. 2012. 2012</p>
<p>Multiple annotation for biodiversity: developing an annotation framework among biology, linguistics and text technology. A Lücking, C Driller, M Stoeckel, G Abrami, A Pachzelt, Mehler A , Language Resources and Evaluation. 562021</p>
<p>COPIOUS: A gold standard corpus of named entities towards extracting species occurrence from biodiversity literature. Nth Nguyen, R Gabud, S Ananiadou, Biodiversity Data Journal. 2019</p>
<p>Automated Trait Extraction using ClearEarth, a Natural Language Processing System for Text Mining in Natural Sciences. A E Thessen, J Preciado, P Jain, J H Martin, M Palmer, R A Bhat, 2018</p>
<p>Semi-automatic Extraction of Plants Morphological Characters from Taxonomic Descriptions Written in Spanish. M A Mora, J E Araya, Biodiversity Data Journal. 2018</p>
<p>A Semantic Model for Species Description Applied to the Ensign Wasps (Hymenoptera: Evaniidae) of New Caledonia. J P Balhoff, I Mikó, M J Yoder, P L Mullins, Deans Ar, Systematic Biology. 622013</p>
<p>Large Scale Unsupervised Pre-Training for Molecular Property Prediction. S Wang, Y Guo, Y Wang, H Sun, J Huang, Smiles-Bert, 10.1145/3307339.3342186Proceedings of the 10th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics. the 10th ACM International Conference on Bioinformatics, Computational Biology and Health InformaticsNiagara Falls NY USAACM2019visited on 08/14/2023</p>
<p>ChemBERTa-2: Towards Chemical Foundation Models. W Ahmad, E Simon, S Chithrananda, G Grand, B Ramsundar, Publisher: arXiv Version Number: 1. 2022</p>
<p>Large-scale chemical language representations capture molecular structure and properties. J Ross, B Belgodere, V Chenthamarakshan, I Padhi, Y Mroueh, P Das, Nat Mach Intell. 42022</p>
<p>Language models can learn complex molecular distributions. D Flam-Shepherd, K Zhu, Aspuru-Guzik A , Nat Commun. 1332932022</p>
<p>V Pursnani, Y Sermet, I Demir, arXiv:2304.12198Performance of ChatGPT on the US Fundamentals of Engineering Exam: Comprehensive Assessment of Proficiency and Potential Implications for Professional Environmental Engineering Practice. 2023arXiv preprint</p>
<p>Assessing the capabilities of ChatGPT to improve additive manufacturing troubleshooting. S Badini, S Regondi, E Frontoni, Pugliese R , Advanced Industrial and Engineering Polymer Research. 2023</p>
<p>Causal Reasoning and Large Language Models: Opening a New Frontier for Causality. E Kıcıman, R Ness, A Sharma, Tan C , arXiv:2305.00050[cs.AI]2023</p>
<p>A comparison of cultural ecosystem service survey methods within South England. S Willcock, B J Camp, Ksh Peh, Ecosystem Services. 262017</p>
<p>Climate change views, energy policy preferences, and intended actions across welfare state regimes: Evidence from the European Social Survey. S T Marquart-Pyatt, H Qian, M K Houser, A M Mccright, International Journal of Sociology. 492019</p>
<p>photosearcher" package in R: An accessible and reproducible method for harvesting large datasets from Flickr. N Fox, T August, F Mancini, SoftwareX. 121006242020</p>
<p>Social media data for environmental sustainability: A critical review of opportunities, threats, and ethical use. A Ghermandi, J Langemeyer, Van Berkel, D , One Earth. 62023</p>
<p>Enriching social media data allows a more robust representation of cultural ecosystem services. N Fox, L J Graham, F Eigenbrod, J M Bullock, K E Parks, Ecosystem Services. 501013282021</p>
<p>Public sentiment toward solar energy-opinion mining of twitter using a transformer-based language model. S Y Kim, K Ganesan, P Dickens, S Panda, Sustainability. 1326732021</p>
<p>Topic Modelling and Opinion Analysis On Climate Change Twitter Data Using LDA And BERT Model. S E Uthirapathy, D Sandanam, Procedia Computer Science. 2182023</p>
<p>Using Social Media Text Data to Analyze the Characteristics and Influencing Factors of Daily Urban Green Space Usage-A Case Study of Xiamen. C Fan, S Li, Y Liu, Forests. 1415692023</p>
<p>A multi-task metadataset for classifying satellite imagery using vision-language models. J Roberts, K Han, Albanie S Satin, arXiv:2304.116192023arXiv preprint</p>
<p>The role of large language models in ecology and biodiversity conservation: Opportunities and Challenges. H Doi, T Osawa, N Tsutsumida, 2023</p>
<p>Can ChatGPT be leveraged for taxonomic investigations? Potential and limitations of a new technology. A A Davinack, Zootaxa. 52702023</p>
<p>Why Do Users of Online Mental Health Communities Get Likes and Reposts: A Combination of Text Mining and Empirical Analysis. J Liu, J Kong, Healthcare. 92021</p>
<p>Large language models in medicine. A J Thirunavukarasu, Dsj Ting, K Elangovan, L Gutierrez, T F Tan, Dsw Ting, Nature Medicine. 2023</p>
<p>BioBERT: a pre-trained biomedical language representation model for biomedical text mining. J Lee, W Yoon, S Kim, Bioinformatics. 362020</p>
<p>A large language model for electronic health records. X Yang, A Chen, N Pournejatian, NPJ Digital Medicine. 51942022</p>
<p>Pro-Eating Disorders and Pro-Recovery Communities on Reddit: Text and Network Comparative Analyses. Y Fettach, L Benhiba, 10.1145/3366030.3366058Proceedings of the 21st International Conference on Information Integration and Web-Based Applications &amp; Services. iiWAS2019. Munich, Germany. the 21st International Conference on Information Integration and Web-Based Applications &amp; Services. iiWAS2019. Munich, GermanyAssociation for Computing Machinery2020</p>
<p>Narrative Paths and Negotiation of Power in Birth Stories. M Antoniak, D Mimno, Levy K , Proc. ACM Hum.-Comput. Interact. 32019</p>
<p>Learning transferable visual models from natural language supervision. A Radford, J Kim, C Hallacy, PMLR. 2021International Conference on Machine Learning. </p>
<p>MatSciBERT: A materials domain language model for text mining and information extraction. T Gupta, M Zaki, N Krishnan, Computational Materials. 81022022</p>
<p>Materialbert for natural language processing of materials science texts. M Yoshitake, F Sato, H Kawano, H Teraoka, Sci. Technol. Adv. Mater. 22022</p>
<p>A general-purpose material property data extraction pipeline from large polymer corpora using natural language processing. P Shetty, A Rajan, C Kuenneth, Computational Materials. 9522023</p>
<p>ChatGPT Chemistry Assistant for Text Mining and Prediction of MOF Synthesis. Z Zheng, O Zhang, C Borgs, J T Chayes, O M Yaghi, arXiv:2306.112962023arXiv preprint</p>
<p>Moformer: self-supervised transformer model for metal-organic framework property prediction. Z Cao, R Magar, Y Wang, Barati Farimani, A , Journal of the American Chemical Society. 1452023</p>
<p>14 Examples of How LLMs Can Transform Materials Science and Chemistry: A Reflection on a Large Language Model Hackathon. K Jablonka, Q Ai, A Al-Feghali, Digital Discovery. 2023</p>
<p>Show Your Work: Scratchpads for Intermediate Computation with Language Models. M Nye, A J Andreassen, G Gur-Ari, arXiv:2112.00114[cs.LG]2021</p>
<p>Let's Verify Step by Step. H Lightman, V Kosaraju, Y Burda, arXiv:2305.20050[cs.LG]2023</p>
<p>Mathematics, word problems, common sense, and artificial intelligence. E Davis, arXiv:2301.09723[cs.AI]2023</p>
<p>Mathematical Capabilities of ChatGPT. S Frieder, L Pinchetti, A Chevalier, arXiv:2301.13867[cs.LG]2023</p>
<p>A Mathematical Investigation of Hallucination and Creativity in GPT Models. M Lee, Mathematics. 112023</p>
<p>A Mathematical Framework for Transformer Circuits. N Elhage, N Nanda, C Olsson, Transformer Circuits Thread 2021</p>
<p>Genome-scale language models reveal SARS-CoV-2 evolutionary dynamics. M Zvyagin, A Brace, K Hippe, 2022</p>
<p>Sentiment analysis : mining opinions, sentiments, and emotions. B Liu, 2015New York, NY</p>
<p>Sentiment Analysis in the Era of Large Language Models: A Reality Check. W Zhang, Y Deng, B Liu, S J Pan, Bing L , arXiv:2305.15005[cs.CL]2023</p>
<p>Unified Benchmark and Comparative Evaluation for Tweet Classification. F Barbieri, J Camacho-Collados, Espinosa Anke, L , Neves L Tweeteval, 10.18653/v1/2020.findings-emnlp.148Findings of the Association for Computational Linguistics: EMNLP 2020. Association for Computational Linguistics2020</p>
<p>SsciBERT: A Pre-trained Language Model for Social Science Texts. S Shen, J Liu, L Lin, arXiv:2206.04510[cs.CL]2022</p>
<p>Can large language models build causal graphs?. S Long, T Schuster, A Piché, arXiv:2303.05279[cs.CL]2023</p>
<p>Training Socially Aligned Language Models in Simulated Human Society. R Liu, R Yang, C Jia, arXiv:2305.16960[cs.CL]2023</p>
<p>Using cognitive psychology to understand GPT-3. M Binz, E Schulz, Proceedings of the National Academy of Sciences. 1202023</p>
<p>Language models show human-like content effects on reasoning. I Dasgupta, A K Lampinen, Scy Chan, arXiv:2207.07051[cs.CL]2022</p>
<p>Understanding Causality with Large Language Models: Feasibility and Opportunities. C Zhang, S Bauer, P Bennett, arXiv:2304.05524[cs.LG]2023</p>
<p>Leveraging Large Language Models for Topic Classification in the Domain of Public Affairs. A Peña, A Morales, J Fierrez, arXiv:2306.02864[cs.AI]2023</p>
<p>Language Models in Sociological Research: An Application to Classifying Large Administrative Data and Measuring Religiosity. J L Jensen, D Karell, C Tanigawa-Lau, N Habash, M Oudah, Dfs Fani, Sociological Methodology. 522022</p>
<p>Exploring the value of online product reviews in forecasting sales: The case of motion pictures. C Dellarocas, X( Zhang, Awad Nf, Journal of Interactive Marketing. 212007</p>
<p>Detecting Indicators for Startup Business Success: Sentiment Analysis Using Text Data Mining. J R Saura, P Palos-Sanchez, Grilo A , Sustainability. 112019</p>
<p>Twitter mood predicts the stock market. J Bollen, H Mao, X Zeng, Journal of Computational Science. 22011</p>
<p>Sentiment analysis of financial news using unsupervised approach. A Yadav, C K Jha, A Sharan, V Vaish, International Conference on Computational Intelligence and Data Science. 2020167</p>
<p>Leveraging hierarchical language models for aspect-based sentiment analysis on financial data. M Lengkeek, F Van Der Knaap, F Frasincar, Information Processing &amp; Management. 601034352023</p>
<p>Instruct-FinGPT: Financial Sentiment Analysis by Instruction Tuning of General-Purpose Large Language Models. B Zhang, H Yang, X Y Liu, arXiv:2306.12659[cs.CL]2023</p>
<p>A framework for big data analytics in commercial social networks: A case study on sentiment analysis and fake review detection for marketing decision-making. E Kauffmann, J Peral, D Gil, A Ferrández, R Sellers, Mora H , Industrial Marketing Management. 902020</p>
<p>Consumer Insight on Driverless Automobile Technology Adoption via Twitter Data: A Sentiment Analytic Approach. M A Kwarteng, A Ntsiful, R K Botchway, M Pilik, Zk ; Oplatková, S K Sharma, Y K Dwivedi, B Metri, Rana Np Cham, Re-imagining Diffusion and Adoption of Information Technology and Systems: A Continuing Conversation. Springer International Publishing2020</p>
<p>Technology adoption news and corporate reputation: sentiment analysis about the introduction of Bitcoin. F Caviggioli, L Lamberti, P Landoni, Meola P , Journal of Product &amp; Brand Management. 292020</p>
<p>Text Algorithms in Economics. CEPR Discussion Papers 18125. S Hansen, Ash E , C.E.P.R. Discussion Papers. 2023</p>
<p>Remote Work across Jobs, Companies, and Space. S Hansen, P J Lambert, N Bloom, S J Davis, R Sadun, B Taska, 10.3386/w31007National Bureau of Economic Research. 2023Working Paper 31007</p>
<p>Connecting higher education to workplace activities and earnings. H Chau, S Bana, B Bouvier, Frank M , Plos one. 182023</p>
<p>Hedonic Prices and Quality Adjusted Price Indices Powered by AI. P Bajari, Z Cen, V Chernozhukov, arXiv:2305.000442023econ.GN</p>
<p>Estimation and Inference of Heterogeneous Treatment Effects using Random Forests. S Wager, S Athey, Journal of the American Statistical Association. 1132018</p>
<p>What is a labor market? classifying workers and jobs using network theory. J Fogel, B Modenesi, 2023Tech. rep</p>
<p>Using Causal Forests to Predict Treatment Heterogeneity: An Application to Summer Jobs. J M Davis, S B Heller, American Economic Review. 1072017</p>
<p>ChatGPT and other large language models are double-edged swords. Y Shen, L Heacock, J Elias, 2023</p>
<p>Paradigm shift presented by Large Language Models (LLM) in Deep Learning. N Chacko, V Chacko, ADVANCES IN EMERGING COMPUTING TECHNOLOGIES. 202340</p>
<p>More than just jargon-the nature and role of specialist language in learning disciplinary knowledge. R Woodward-Kron, Journal of English for Academic Purposes. 72008</p>
<p>Y Liu, M Ott, N Goyal, arXiv:1907.11692A robustly optimized bert pretraining approach. 2019arXiv preprint</p>
<p>Evolutionary-scale prediction of atomic-level protein structure with a language model. Z Lin, H Akin, R Rao, Science. 3792023</p>
<p>NExT-GPT: Any-to-Any Multimodal LLM. S Wu, H Fei, L Qu, W Ji, Chua Ts, abs/2309.05519CoRR. 2023</p>            </div>
        </div>

    </div>
</body>
</html>