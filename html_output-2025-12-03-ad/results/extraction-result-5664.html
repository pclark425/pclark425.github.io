<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5664 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5664</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5664</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-116.html">extraction-schema-116</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <p><strong>Paper ID:</strong> paper-259097639</p>
                <p><strong>Paper Title:</strong> Prompt Engineering with ChatGPT: A Guide for Academic Writers</p>
                <p><strong>Paper Abstract:</strong> Prompt engineering is a relatively new discipline that refers to the practice of developing and optimizing prompts to effectively utilize large language models, particularly in natural language processing tasks. However, not many writers and researchers are familiar about this discipline. Hence, in this paper, I aim to highlight the significance of prompt engineering for academic writers and researchers, particularly the fledgling, in the rapidly evolving world of artificial intelligence. I also discuss the concepts of prompt engineering, large language models, and the techniques and pitfalls of writing prompts. Here, I contend that by acquiring prompt engineering skills, academic writers can navigate the changing landscape and leverage large language models to enhance their writing process. As artificial intelligence continues to advance and penetrate the arena of academic writing, prompt engineering equips writers and researchers with the essential skills to effectively harness the power of language models. This enables them to confidently explore new opportunities, enhance their writing endeavors, and remain at the forefront of utilizing cutting-edge technologies in their academic pursuits.</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5664.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5664.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Instructive prompt</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Instructive prompt (explicit task instruction)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prompt format that gives a clear, specific task instruction (e.g., 'Write a comparative analysis...') to guide model behavior and produce focused outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Prompt Engineering with ChatGPT: A Guide for Academic Writers</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Guided text generation / focused writing</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Generate structured, task-specific text such as essays, analyses, or summaries when provided with an explicit instruction.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Single-turn prompt containing a direct instruction specifying the task (e.g., 'Write a comparative analysis of the advantages and limitations of different imaging modalities...'), often combined with other elements (context, input data, output indicator).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>improved</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>The paper states that explicit instructions guide the model's behavior toward the desired output and improve focus and quality of the response by constraining the task.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Prompt Engineering with ChatGPT: A Guide for Academic Writers', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5664.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5664.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>System prompt</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>System prompt (context or starting point)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prompt format that supplies a high-level starting context or framing sentence to orient the model (e.g., 'In the field of biomedical engineering, the use of nanomaterials has revolutionized...').</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Prompt Engineering with ChatGPT: A Guide for Academic Writers</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Contextualized generation / framing</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Provide context or domain framing so that generated outputs are relevant to a specific field or perspective.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Begin prompt with a domain-level or topic-level statement that establishes tone, scope, or domain knowledge prior to the specific instruction or question.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>improved</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Providing a system-like opening or domain context helps the model generate outputs aligned with the intended domain and reduces off-topic or generic responses.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Prompt Engineering with ChatGPT: A Guide for Academic Writers', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5664.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5664.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Question-answer prompt</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Question-answer prompt (QA-structured prompt)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prompt style that frames the task as specific questions to elicit targeted answers or organize output around research questions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Prompt Engineering with ChatGPT: A Guide for Academic Writers</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Targeted Q&A and structured responses</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Answering specific research questions or producing responses structured around explicit question prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Prompts formulated as direct questions (e.g., 'What are the key challenges in developing personalized medical devices...?') to focus the model on particular points.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>improved</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>The paper argues QA prompts structure output and focus the model on specific points, improving relevance and organization.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Prompt Engineering with ChatGPT: A Guide for Academic Writers', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5664.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e5664.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Contextual prompt</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Contextual prompt (additional background/context included)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prompt format that supplies explicit background information or situational context (geographic, domain, or dataset specifics) to disambiguate the task and produce more precise responses.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Prompt Engineering with ChatGPT: A Guide for Academic Writers</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Context-aware generation / decision recommendations</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Tasks where background details (e.g., location, target population, domain constraints) materially affect the appropriateness of the response.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Prompt includes contextual qualifiers (e.g., 'Propose effective strategies to alleviate poverty in urban areas of developing countries...') to narrow scope and guide reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Compared implicitly to context-free/vague prompts (no context provided).</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>improved</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>The paper states that including context reduces generic or incomplete answers by clarifying scope and relevant constraints, leading to more accurate and useful outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Prompt Engineering with ChatGPT: A Guide for Academic Writers', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5664.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e5664.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mixed prompt</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mixed prompt (combination of instruction, context, examples)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A composite prompt that combines several elements (instruction, context, input data, examples) to comprehensively specify the task and desired output.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Prompt Engineering with ChatGPT: A Guide for Academic Writers</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Complex structured generation / case-study analysis</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Tasks that require multiple constraints, examples, or structured outputs, such as case study discussion or multi-part essays.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Prompt contains multiple elements (instruction + context + input data + output indicator), sometimes with a case study or explicit sub-questions to guide the model.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Compared implicitly to single-element prompts (instruction-only or context-only).</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>improved</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Combining elements gives the model clearer constraints and richer information, which the paper argues leads to more comprehensive and targeted outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Prompt Engineering with ChatGPT: A Guide for Academic Writers', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5664.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e5664.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Ambiguity / vague prompt</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Ambiguity (vague or underspecified prompts)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Prompts lacking specificity (e.g., 'Discuss the impact of technology on society') that lead to unfocused, overly general responses from the model.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Prompt Engineering with ChatGPT: A Guide for Academic Writers</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Open-ended summarization / general discussion</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Tasks where the prompt does not define scope, audience, or level of detail, resulting in broad or shallow outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Short, generic prompts without context, scope, or formatting instructions.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Compared implicitly to refined prompts with explicit scope or constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>reduced</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>The paper explains that ambiguity causes the model to produce unfocused responses lacking concrete examples or depth because the task boundaries are unspecified.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Prompt Engineering with ChatGPT: A Guide for Academic Writers', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5664.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e5664.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bias reinforcement</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bias reinforcement via prompt phrasing</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Prompts that embed biased assumptions (e.g., 'Explain why women are less suited for leadership positions') which can induce the model to reproduce or amplify those biases.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Prompt Engineering with ChatGPT: A Guide for Academic Writers</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Content generation with ethical/fairness considerations</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Generation tasks where prompt wording can introduce normative assumptions affecting fairness or accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Prompts containing leading or biased premises that the model may accept and elaborate upon.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Compared implicitly to neutral/unbiased prompt formulations.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>reduced</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>The paper warns that biased prompt language can propagate and even amplify societal biases present in training data, producing harmful outputs; the remedy is to remove biased assumptions and rephrase prompts neutrally.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Prompt Engineering with ChatGPT: A Guide for Academic Writers', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5664.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e5664.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Overfitting / overly-specific prompt</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Overfitting (overly-specific or dataset-locked prompts)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Extremely specific prompts (e.g., 'List the names of the seven dwarfs from Snow White') that may constrain the model to a narrow response, reducing generality.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Prompt Engineering with ChatGPT: A Guide for Academic Writers</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Specific fact retrieval vs. generalization</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Tasks where either narrow specificity is desired (fact recall) or broader generalization is preferred (comparative analysis across examples).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Highly specific prompts tied to a single dataset/example or a narrow target, which can produce precise but potentially overfitted outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Compared implicitly to broader prompts that ask for generalization across examples.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>reduced (for generality) / improved (for precision)</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>The paper notes that over-specific prompts can limit the model's ability to generalize and produce diverse answers, but also acknowledges that specificity may be appropriate when the user explicitly wants very precise information.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td>The paper explicitly mentions that in some cases (fact recall) over-specific prompts are appropriate and desirable, i.e., they do not represent a problem but a feature.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Prompt Engineering with ChatGPT: A Guide for Academic Writers', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5664.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e5664.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Conflicting instructions / unintended side effects</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Conflicting instructions (prompts with mixed or contradictory directives)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Prompts that contain inconsistent or contradictory instructions (e.g., ask for two opposing stances) which can confuse the model and yield nonsensical or incoherent outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Prompt Engineering with ChatGPT: A Guide for Academic Writers</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Coherent argumentation / stance-taking</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Tasks requiring consistent reasoning and avoiding internal conflicts in directives.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Prompts that include multiple instructions that are logically inconsistent or that demand contradictory outputs within the same request.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>reduced</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>The paper explains that conflicting or complex prompts may confuse the model, producing unintended side effects or incoherent answers; removing contradictions and ensuring coherence improves outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Prompt Engineering with ChatGPT: A Guide for Academic Writers', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5664.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e5664.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Output indicator</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Output indicator (format/length/structure specification)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prompt element that specifies the desired format, structure, or length of the model's output (e.g., 'present in a well-structured essay format, approximately 1500 words').</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Prompt Engineering with ChatGPT: A Guide for Academic Writers</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Controlled-format generation (length, structure, style)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Tasks where the user prescribes the presentation of the output, such as essay format, bullet points, and target word count.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Prompt includes explicit output indicators (desired format, sections, length) to constrain style and structure of the generated text.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>improved</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Specifying output format helps the model produce responses that match user expectations for structure and length, improving usability of generated text.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Prompt Engineering with ChatGPT: A Guide for Academic Writers', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5664.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e5664.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how the format or presentation of problems (e.g., prompt wording, structure, context, formatting) affects the performance of large language models (LLMs), including details of the formats used, tasks evaluated, models tested, performance results, and any explanations or comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Unrealistic expectations / model limitations</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Unrealistic dependency on model limitations (expecting impossible guarantees)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A class of problematic prompts that ask the model to perform beyond its capabilities (e.g., predict stock outcomes with 100% accuracy), which leads to misleading/confident but unsupported outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Prompt Engineering with ChatGPT: A Guide for Academic Writers</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Predictive forecasting / high-certainty decision tasks</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Tasks where users request deterministic or perfectly accurate predictions from a probabilistic language model.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>Prompts that demand unrealistic certainty or guarantees of correctness (e.g., 'Predict with 100% accuracy...'), failing to account for model hallucination and limitations.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_direction</strong></td>
                            <td>reduced</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>The paper explains that such prompts lead to overconfidence and hallucination; users should combine model outputs with external validation and domain expertise.</td>
                        </tr>
                        <tr>
                            <td><strong>counterexample_or_null_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Prompt Engineering with ChatGPT: A Guide for Academic Writers', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>A prompt pattern catalog to enhance prompt engineering with ChatGPT <em>(Rating: 2)</em></li>
                <li>ChatGPT for good? On opportunities and challenges of large language models for education <em>(Rating: 2)</em></li>
                <li>Sparks: Inspiration for science writing using language models <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5664",
    "paper_id": "paper-259097639",
    "extraction_schema_id": "extraction-schema-116",
    "extracted_data": [
        {
            "name_short": "Instructive prompt",
            "name_full": "Instructive prompt (explicit task instruction)",
            "brief_description": "A prompt format that gives a clear, specific task instruction (e.g., 'Write a comparative analysis...') to guide model behavior and produce focused outputs.",
            "citation_title": "Prompt Engineering with ChatGPT: A Guide for Academic Writers",
            "mention_or_use": "mention",
            "model_name": "ChatGPT",
            "model_size": null,
            "task_name": "Guided text generation / focused writing",
            "task_description": "Generate structured, task-specific text such as essays, analyses, or summaries when provided with an explicit instruction.",
            "problem_format": "Single-turn prompt containing a direct instruction specifying the task (e.g., 'Write a comparative analysis of the advantages and limitations of different imaging modalities...'), often combined with other elements (context, input data, output indicator).",
            "comparison_format": null,
            "performance": null,
            "performance_comparison": null,
            "format_effect_size": null,
            "format_effect_direction": "improved",
            "explanation_or_hypothesis": "The paper states that explicit instructions guide the model's behavior toward the desired output and improve focus and quality of the response by constraining the task.",
            "counterexample_or_null_result": null,
            "uuid": "e5664.0",
            "source_info": {
                "paper_title": "Prompt Engineering with ChatGPT: A Guide for Academic Writers",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "System prompt",
            "name_full": "System prompt (context or starting point)",
            "brief_description": "A prompt format that supplies a high-level starting context or framing sentence to orient the model (e.g., 'In the field of biomedical engineering, the use of nanomaterials has revolutionized...').",
            "citation_title": "Prompt Engineering with ChatGPT: A Guide for Academic Writers",
            "mention_or_use": "mention",
            "model_name": "ChatGPT",
            "model_size": null,
            "task_name": "Contextualized generation / framing",
            "task_description": "Provide context or domain framing so that generated outputs are relevant to a specific field or perspective.",
            "problem_format": "Begin prompt with a domain-level or topic-level statement that establishes tone, scope, or domain knowledge prior to the specific instruction or question.",
            "comparison_format": null,
            "performance": null,
            "performance_comparison": null,
            "format_effect_size": null,
            "format_effect_direction": "improved",
            "explanation_or_hypothesis": "Providing a system-like opening or domain context helps the model generate outputs aligned with the intended domain and reduces off-topic or generic responses.",
            "counterexample_or_null_result": null,
            "uuid": "e5664.1",
            "source_info": {
                "paper_title": "Prompt Engineering with ChatGPT: A Guide for Academic Writers",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Question-answer prompt",
            "name_full": "Question-answer prompt (QA-structured prompt)",
            "brief_description": "A prompt style that frames the task as specific questions to elicit targeted answers or organize output around research questions.",
            "citation_title": "Prompt Engineering with ChatGPT: A Guide for Academic Writers",
            "mention_or_use": "mention",
            "model_name": "ChatGPT",
            "model_size": null,
            "task_name": "Targeted Q&A and structured responses",
            "task_description": "Answering specific research questions or producing responses structured around explicit question prompts.",
            "problem_format": "Prompts formulated as direct questions (e.g., 'What are the key challenges in developing personalized medical devices...?') to focus the model on particular points.",
            "comparison_format": null,
            "performance": null,
            "performance_comparison": null,
            "format_effect_size": null,
            "format_effect_direction": "improved",
            "explanation_or_hypothesis": "The paper argues QA prompts structure output and focus the model on specific points, improving relevance and organization.",
            "counterexample_or_null_result": null,
            "uuid": "e5664.2",
            "source_info": {
                "paper_title": "Prompt Engineering with ChatGPT: A Guide for Academic Writers",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Contextual prompt",
            "name_full": "Contextual prompt (additional background/context included)",
            "brief_description": "A prompt format that supplies explicit background information or situational context (geographic, domain, or dataset specifics) to disambiguate the task and produce more precise responses.",
            "citation_title": "Prompt Engineering with ChatGPT: A Guide for Academic Writers",
            "mention_or_use": "mention",
            "model_name": "ChatGPT",
            "model_size": null,
            "task_name": "Context-aware generation / decision recommendations",
            "task_description": "Tasks where background details (e.g., location, target population, domain constraints) materially affect the appropriateness of the response.",
            "problem_format": "Prompt includes contextual qualifiers (e.g., 'Propose effective strategies to alleviate poverty in urban areas of developing countries...') to narrow scope and guide reasoning.",
            "comparison_format": "Compared implicitly to context-free/vague prompts (no context provided).",
            "performance": null,
            "performance_comparison": null,
            "format_effect_size": null,
            "format_effect_direction": "improved",
            "explanation_or_hypothesis": "The paper states that including context reduces generic or incomplete answers by clarifying scope and relevant constraints, leading to more accurate and useful outputs.",
            "counterexample_or_null_result": null,
            "uuid": "e5664.3",
            "source_info": {
                "paper_title": "Prompt Engineering with ChatGPT: A Guide for Academic Writers",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Mixed prompt",
            "name_full": "Mixed prompt (combination of instruction, context, examples)",
            "brief_description": "A composite prompt that combines several elements (instruction, context, input data, examples) to comprehensively specify the task and desired output.",
            "citation_title": "Prompt Engineering with ChatGPT: A Guide for Academic Writers",
            "mention_or_use": "mention",
            "model_name": "ChatGPT",
            "model_size": null,
            "task_name": "Complex structured generation / case-study analysis",
            "task_description": "Tasks that require multiple constraints, examples, or structured outputs, such as case study discussion or multi-part essays.",
            "problem_format": "Prompt contains multiple elements (instruction + context + input data + output indicator), sometimes with a case study or explicit sub-questions to guide the model.",
            "comparison_format": "Compared implicitly to single-element prompts (instruction-only or context-only).",
            "performance": null,
            "performance_comparison": null,
            "format_effect_size": null,
            "format_effect_direction": "improved",
            "explanation_or_hypothesis": "Combining elements gives the model clearer constraints and richer information, which the paper argues leads to more comprehensive and targeted outputs.",
            "counterexample_or_null_result": null,
            "uuid": "e5664.4",
            "source_info": {
                "paper_title": "Prompt Engineering with ChatGPT: A Guide for Academic Writers",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Ambiguity / vague prompt",
            "name_full": "Ambiguity (vague or underspecified prompts)",
            "brief_description": "Prompts lacking specificity (e.g., 'Discuss the impact of technology on society') that lead to unfocused, overly general responses from the model.",
            "citation_title": "Prompt Engineering with ChatGPT: A Guide for Academic Writers",
            "mention_or_use": "mention",
            "model_name": "ChatGPT",
            "model_size": null,
            "task_name": "Open-ended summarization / general discussion",
            "task_description": "Tasks where the prompt does not define scope, audience, or level of detail, resulting in broad or shallow outputs.",
            "problem_format": "Short, generic prompts without context, scope, or formatting instructions.",
            "comparison_format": "Compared implicitly to refined prompts with explicit scope or constraints.",
            "performance": null,
            "performance_comparison": null,
            "format_effect_size": null,
            "format_effect_direction": "reduced",
            "explanation_or_hypothesis": "The paper explains that ambiguity causes the model to produce unfocused responses lacking concrete examples or depth because the task boundaries are unspecified.",
            "counterexample_or_null_result": null,
            "uuid": "e5664.5",
            "source_info": {
                "paper_title": "Prompt Engineering with ChatGPT: A Guide for Academic Writers",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Bias reinforcement",
            "name_full": "Bias reinforcement via prompt phrasing",
            "brief_description": "Prompts that embed biased assumptions (e.g., 'Explain why women are less suited for leadership positions') which can induce the model to reproduce or amplify those biases.",
            "citation_title": "Prompt Engineering with ChatGPT: A Guide for Academic Writers",
            "mention_or_use": "mention",
            "model_name": "ChatGPT",
            "model_size": null,
            "task_name": "Content generation with ethical/fairness considerations",
            "task_description": "Generation tasks where prompt wording can introduce normative assumptions affecting fairness or accuracy.",
            "problem_format": "Prompts containing leading or biased premises that the model may accept and elaborate upon.",
            "comparison_format": "Compared implicitly to neutral/unbiased prompt formulations.",
            "performance": null,
            "performance_comparison": null,
            "format_effect_size": null,
            "format_effect_direction": "reduced",
            "explanation_or_hypothesis": "The paper warns that biased prompt language can propagate and even amplify societal biases present in training data, producing harmful outputs; the remedy is to remove biased assumptions and rephrase prompts neutrally.",
            "counterexample_or_null_result": null,
            "uuid": "e5664.6",
            "source_info": {
                "paper_title": "Prompt Engineering with ChatGPT: A Guide for Academic Writers",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Overfitting / overly-specific prompt",
            "name_full": "Overfitting (overly-specific or dataset-locked prompts)",
            "brief_description": "Extremely specific prompts (e.g., 'List the names of the seven dwarfs from Snow White') that may constrain the model to a narrow response, reducing generality.",
            "citation_title": "Prompt Engineering with ChatGPT: A Guide for Academic Writers",
            "mention_or_use": "mention",
            "model_name": "ChatGPT",
            "model_size": null,
            "task_name": "Specific fact retrieval vs. generalization",
            "task_description": "Tasks where either narrow specificity is desired (fact recall) or broader generalization is preferred (comparative analysis across examples).",
            "problem_format": "Highly specific prompts tied to a single dataset/example or a narrow target, which can produce precise but potentially overfitted outputs.",
            "comparison_format": "Compared implicitly to broader prompts that ask for generalization across examples.",
            "performance": null,
            "performance_comparison": null,
            "format_effect_size": null,
            "format_effect_direction": "reduced (for generality) / improved (for precision)",
            "explanation_or_hypothesis": "The paper notes that over-specific prompts can limit the model's ability to generalize and produce diverse answers, but also acknowledges that specificity may be appropriate when the user explicitly wants very precise information.",
            "counterexample_or_null_result": "The paper explicitly mentions that in some cases (fact recall) over-specific prompts are appropriate and desirable, i.e., they do not represent a problem but a feature.",
            "uuid": "e5664.7",
            "source_info": {
                "paper_title": "Prompt Engineering with ChatGPT: A Guide for Academic Writers",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Conflicting instructions / unintended side effects",
            "name_full": "Conflicting instructions (prompts with mixed or contradictory directives)",
            "brief_description": "Prompts that contain inconsistent or contradictory instructions (e.g., ask for two opposing stances) which can confuse the model and yield nonsensical or incoherent outputs.",
            "citation_title": "Prompt Engineering with ChatGPT: A Guide for Academic Writers",
            "mention_or_use": "mention",
            "model_name": "ChatGPT",
            "model_size": null,
            "task_name": "Coherent argumentation / stance-taking",
            "task_description": "Tasks requiring consistent reasoning and avoiding internal conflicts in directives.",
            "problem_format": "Prompts that include multiple instructions that are logically inconsistent or that demand contradictory outputs within the same request.",
            "comparison_format": null,
            "performance": null,
            "performance_comparison": null,
            "format_effect_size": null,
            "format_effect_direction": "reduced",
            "explanation_or_hypothesis": "The paper explains that conflicting or complex prompts may confuse the model, producing unintended side effects or incoherent answers; removing contradictions and ensuring coherence improves outputs.",
            "counterexample_or_null_result": null,
            "uuid": "e5664.8",
            "source_info": {
                "paper_title": "Prompt Engineering with ChatGPT: A Guide for Academic Writers",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Output indicator",
            "name_full": "Output indicator (format/length/structure specification)",
            "brief_description": "A prompt element that specifies the desired format, structure, or length of the model's output (e.g., 'present in a well-structured essay format, approximately 1500 words').",
            "citation_title": "Prompt Engineering with ChatGPT: A Guide for Academic Writers",
            "mention_or_use": "mention",
            "model_name": "ChatGPT",
            "model_size": null,
            "task_name": "Controlled-format generation (length, structure, style)",
            "task_description": "Tasks where the user prescribes the presentation of the output, such as essay format, bullet points, and target word count.",
            "problem_format": "Prompt includes explicit output indicators (desired format, sections, length) to constrain style and structure of the generated text.",
            "comparison_format": null,
            "performance": null,
            "performance_comparison": null,
            "format_effect_size": null,
            "format_effect_direction": "improved",
            "explanation_or_hypothesis": "Specifying output format helps the model produce responses that match user expectations for structure and length, improving usability of generated text.",
            "counterexample_or_null_result": null,
            "uuid": "e5664.9",
            "source_info": {
                "paper_title": "Prompt Engineering with ChatGPT: A Guide for Academic Writers",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Unrealistic expectations / model limitations",
            "name_full": "Unrealistic dependency on model limitations (expecting impossible guarantees)",
            "brief_description": "A class of problematic prompts that ask the model to perform beyond its capabilities (e.g., predict stock outcomes with 100% accuracy), which leads to misleading/confident but unsupported outputs.",
            "citation_title": "Prompt Engineering with ChatGPT: A Guide for Academic Writers",
            "mention_or_use": "mention",
            "model_name": "ChatGPT",
            "model_size": null,
            "task_name": "Predictive forecasting / high-certainty decision tasks",
            "task_description": "Tasks where users request deterministic or perfectly accurate predictions from a probabilistic language model.",
            "problem_format": "Prompts that demand unrealistic certainty or guarantees of correctness (e.g., 'Predict with 100% accuracy...'), failing to account for model hallucination and limitations.",
            "comparison_format": null,
            "performance": null,
            "performance_comparison": null,
            "format_effect_size": null,
            "format_effect_direction": "reduced",
            "explanation_or_hypothesis": "The paper explains that such prompts lead to overconfidence and hallucination; users should combine model outputs with external validation and domain expertise.",
            "counterexample_or_null_result": null,
            "uuid": "e5664.10",
            "source_info": {
                "paper_title": "Prompt Engineering with ChatGPT: A Guide for Academic Writers",
                "publication_date_yy_mm": "2023-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "A prompt pattern catalog to enhance prompt engineering with ChatGPT",
            "rating": 2,
            "sanitized_title": "a_prompt_pattern_catalog_to_enhance_prompt_engineering_with_chatgpt"
        },
        {
            "paper_title": "ChatGPT for good? On opportunities and challenges of large language models for education",
            "rating": 2,
            "sanitized_title": "chatgpt_for_good_on_opportunities_and_challenges_of_large_language_models_for_education"
        },
        {
            "paper_title": "Sparks: Inspiration for science writing using language models",
            "rating": 1,
            "sanitized_title": "sparks_inspiration_for_science_writing_using_language_models"
        }
    ],
    "cost": 0.010822749999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Prompt Engineering with ChatGPT: A Guide for Academic Writers
7 June 2023</p>
<p>Louie Giray louiegiray@gmail.com 0000-0002-1940-035X
General Education Department
Colegio de Muntinlupa
Muntinlupa CityPhilippines</p>
<p>General Education Department
Colegio de Muntinlupa
Muntinlupa CityPhilippines</p>
<p>Prompt Engineering with ChatGPT: A Guide for Academic Writers
7 June 20232CCCF7FAC2ADAC5B15CB1CF70D7AC9E110.1007/s10439-023-03272-4Received: 31 May 2023 / Accepted: 1 June 2023 /
Prompt engineering is a relatively new discipline that refers to the practice of developing and optimizing prompts to effectively utilize large language models, particularly in natural language processing tasks.However, not many writers and researchers are familiar about this discipline.Hence, in this paper, I aim to highlight the significance of prompt engineering for academic writers and researchers, particularly the fledgling, in the rapidly evolving world of artificial intelligence.I also discuss the concepts of prompt engineering, large language models, and the techniques and pitfalls of writing prompts.Here, I contend that by acquiring prompt engineering skills, academic writers can navigate the changing landscape and leverage large language models to enhance their writing process.As artificial intelligence continues to advance and penetrate the arena of academic writing, prompt engineering equips writers and researchers with the essential skills to effectively harness the power of language models.This enables them to confidently explore new opportunities, enhance their writing endeavors, and remain at the forefront of utilizing cutting-edge technologies in their academic pursuits.Keywords Academic writing  ChatGPT  Large language models  Natural language processing  Prompt engineering  PromptsAssociate Editor Stefan M. Duma oversaw the review of this article.</p>
<p>Prologue: What is Prompt Engineering?</p>
<p>You are embarking on a journey into the fascinating world of artificial intelligence, particularly in the field of natural language processing.Prompt engineering, a concept within this domain, revolves around embedding the task description that an AI aims to accomplish within the input itself, often in the form of a question, rather than providing it explicitly.This approach involves converting one or more tasks into a prompt-based dataset and training a language model using a technique known as "prompt-based learning" or "prompt learning" [1].</p>
<p>Prompt engineering is a relatively recent discipline that focuses on developing and optimizing prompts to effectively utilize large language models (LLMs) across a wide range of applications and research areas [2].To grasp the essence of prompt engineering, let's draw an analogy.Imagine you have a well-organized library, filled with an extensive collection of books.The books represent the vast knowledge and capabilities of language models, while the library serves as the AI system.Traditionally, when you want to retrieve information from the library, you approach the librarian, explicitly stating the information you seek.</p>
<p>In AI terms, this corresponds to providing explicit instructions or queries to the language model.However, prompt engineering offers a different approach.Instead of interacting directly with the librarian, you place a carefully crafted question or prompt on each bookshelf.The questions represent the task descriptions or prompts that guide the language model toward the desired outcome.The librarian, or in this case, the language model, becomes adept at understanding and utilizing the prompts to provide relevant and accurate information.</p>
<p>By employing prompt engineering techniques, academic writers and researchers can unlock the full potential of language models, harnessing their capabilities across various domains.This discipline opens up new avenues for improving AI systems and enhancing their performance in a range of applications, from text generation to image synthesis and beyond.</p>
<p>What are Large Language Models like ChatGPT?</p>
<p>As an academic writer new to prompt engineering, it's pivotal for you to familiarize yourself with the concept and potential of LLMs.These advanced machine learning models are capable of performing various natural language processing (NLP) tasks with remarkable proficiency [3].They can generate and classify text, engage in conversational question answering, and even facilitate language translation.</p>
<p>LLMs, including ChatGPT by OpenAI, have been trained on extensive text data from books, articles, and websites to develop a deep understanding of language structure, semantics, and context.By utilizing this knowledge, LLMs can generate text that resembles human-like responses and provide valuable insights across different domains of NLP.ChatGPT specifically has gained widespread recognition and usage within the field, amassing a million subscribers in just five days, surpassing the time it took Facebook and Instagram to achieve the same milestone [4].</p>
<p>When it comes to text generation, LLMs excel at producing coherent and contextually relevant content based on prompts or inputs.This makes them invaluable tools for tasks such as content creation, creative writing, and even automated storytelling.Moreover, LLMs shine in conversational question answering, where they can comprehend and respond to queries, resembling a knowledgeable conversation partner.</p>
<p>Additionally, LLMs play a vital role in language translation tasks.Their ability to grasp the intricacies of multiple languages enables them to facilitate accurate and efficient translation between different language pairs.By harnessing the power of LLMs, researchers and academic writers have made significant progress in the field of machine translation, paving the way for enhanced cross-cultural communication and understanding [1].By incorporating prompt engineering techniques, you can leverage LLMs like ChatGPT to enhance your academic writing and explore new avenues of research and knowledge dissemination.</p>
<p>What is a Prompt and its Elements?</p>
<p>As an academic writer, it's important to understand first what a prompt is in the age of artificial intelligence.In simple terms, a prompt is a specific instruction or query you provide to a language model to guide its behavior and generate desired outputs.Second, we should know its elements and their significance.The elements of a prompt [5] include the following:</p>
<p>( Understanding these elements is crucial because they allow us to effectively communicate our intentions to the model.By carefully crafting the prompt, we can guide the model's behavior and improve the quality of its responses.These elements provide the necessary structure and context for the model to generate accurate and meaningful outputs in line with our objectives.</p>
<p>Here's an example:</p>
<p>(1) Instruction "Write an essay discussing the role of nanotechnology in targeted drug delivery for cancer treatment."(2) Context "Explore the applications of nanotechnology in biomedical engineering, focusing on its potential to improve the effectiveness and safety of cancer treatments through targeted drug delivery systems."(3) Input data "Provide an overview of nanotechnologybased drug delivery systems, such as nanoparticles or nanocarriers, and their ability to selectively deliver anticancer drugs to tumor sites.Discuss the advantages, challenges, and potential future advancements in this field."(4) Output indicator "Please present your findings in a well-structured essay format, including an introduction, main body paragraphs covering key aspects of nanotechnology in drug delivery, and a conclusion.Aim for approximately 1500 words."</p>
<p>In this example, the instruction directs the writer to compose an essay that discusses the role of nanotechnology in targeted drug delivery for cancer treatment within the field of biomedical engineering.The context highlights the significance of nanotechnology in improving cancer treatments.The input data specify the key points to be covered, such as nanotechnology-based drug delivery systems and their potential advantages, challenges, and future prospects.Lastly, the output indicator outlines the desired format and word count for the essay.</p>
<p>Having a clear understanding of prompt elements empowers us to leverage prompt engineering techniques effectively.We can tailor the behavior of language models like ChatGPT to suit our specific needs, whether it's academic writing, research inquiries, or other applications.</p>
<p>What are the Techniques of Prompt Engineering?</p>
<p>In prompt engineering, there are various types of prompting techniques used to optimize the performance of language models.Academic writers can effectively use prompting techniques to guide their writing and generate relevant content.Here are a few examples of how prompting techniques can be applied in the context of biomedical engineering:</p>
<p>(1) Instructive prompt An academic writer can use an instructive prompt to guide their writing toward a specific task.For example:</p>
<p> "Write a comparative analysis of the advantages and limitations of different imaging modalities used in medical diagnostics." "Summarize the recent advancements in tissue engineering for organ regeneration, highlighting their potential applications in biomedical engineering."</p>
<p>(2) System prompt A system prompt can provide a starting point or context the academic writer to develop their content.For example:</p>
<p> "In the field of biomedical engineering, the use of nanomaterials has revolutionized..."  "The emerging field of bioinformatics has greatly contributed to..."</p>
<p>(3) Question-answer prompt Academic writers can use question-answer prompts to structure their writing around specific research questions.For example:</p>
<p> "What are the key challenges in developing personalized medical devices for patient-specific applications in biomedical engineering?" "Discuss the role of biomaterials in tissue engineering and their potential impact on regenerative medicine."</p>
<p>(4) Contextual prompt Providing additional context in a prompt can help academic writers focus on specific aspects of their topic.For example:</p>
<p> "Considering the current advancements in neuroprosthetics, analyze the ethical implications and social impact of these technologies." "Given recent studies on drug delivery systems, critically evaluate the effectiveness and safety of targeted drug delivery approaches in cancer treatment."</p>
<p>(5) Mixed prompt Academic writers can use mixed prompts that combine multiple elements to guide their writing in a comprehensive manner.For example:  "Given the following case study on the application of tissue engineering in cartilage regeneration, discuss the challenges faced in achieving long-term functional outcomes and propose potential strategies for improving clinical translation."By incorporating these prompting techniques, academic writers can structure their writing, generate focused content, and ensure that their work aligns with the specific objectives of their research or academic assignment in the field of biomedical engineering.Prompting techniques provide a framework for organizing thoughts and guiding the flow of information, resulting in well-structured and coherent academic writing.</p>
<p>What are the Common Pitfalls of Writing Prompts?</p>
<p>Prompts play a crucial role in guiding AI models like Chat-GPT, but they can be prone to several pitfalls.Ambiguity, bias reinforcement, overfitting, lack of context, ethical considerations, unintended side effects, and unrealistic dependency on model limitations are key challenges.Understanding these pitfalls is essential for effective prompt engineering and generating accurate, relevant, and responsible responses.</p>
<p>Ambiguity</p>
<p>You may encounter the issue of ambiguity when you come across prompts like this: "Discuss the impact of technology on society."This type of prompt lacks specificity, resulting in a response that lacks focus and precision.As a result, the generated output may be a generalized overview, lacking indepth exploration of specific aspects or concrete examples necessary for a comprehensive analysis.</p>
<p>To overcome this problem, you must correct the prompt by introducing clear parameters and explicit guidelines.For instance, you can refine the prompt to be more specific, such as: "Examine the socio-economic implications of artificial intelligence in healthcare, highlighting both its benefits and challenges through case studies of its implementation in medical diagnostics and patient care."By providing specific instructions, you can guide ChatGPT to generate accurate, detailed, and insightful responses that effectively address the complex and nuanced relationship between technology and society.</p>
<p>Bias Reinforcement</p>
<p>The issue of bias reinforcement becomes apparent when confronted with prompts such as: "Explain why women are less suited for leadership positions."This particular prompt contains a biased assumption, propagating the notion that women are inherently less capable of excelling in leadership roles.Consequently, there is a risk that the model, when responding to such prompts, may inadvertently perpetuate or even amplify gender biases.</p>
<p>To solve this, you should correct the prompt by eliminating biased language and ensuring that prompts are free from any preconceived notions or assumptions regarding gender, race, or other sensitive factors.A more appropriate and inclusive prompt could be: "Examine the factors that contribute to gender disparities in leadership positions, considering both societal and organizational barriers, and propose strategies for promoting gender equality in leadership roles."By promoting inclusivity, you can guide ChatGPT to generate responses that are unbiased, fair, and conducive to fostering gender equality.</p>
<p>Overfitting</p>
<p>The phenomenon of overfitting becomes a concern when faced with prompts such as: "List the names of the seven dwarfs from Snow White."While this prompt may seem overly specific to the Snow White example, it is important to note that it could be exactly what the academic writer desires to know.In cases where the writer explicitly seeks such precise information, tailoring the prompt to a specific dataset or example can be appropriate.However, it is crucial to strike a balance between specificity and generality to avoid limiting the model's ability to generate more diverse or contextually relevant responses.</p>
<p>To address the limitations of overfitting, you should evaluate your academic requirements and consider broader perspectives.By offering alternative prompts that encompass a wider scope, you can encourage the model to explore various fairy tales beyond Snow White.This approach accommodates the interests of a broader audience while still meeting your specific research needs.It allows for a more comprehensive analysis and ensures that the model's responses are not overly confined to a single example.</p>
<p>Lack of Context</p>
<p>When it comes to the issue of lack of context, it is crucial for you to recognize the importance of providing sufficient background information in your prompts.For instance, a prompt like "What is the best solution for poverty?" lacks the necessary context, such as the specific geographic location or the underlying factors contributing to poverty.This deficiency can lead to a generic or incomplete response from the model.</p>
<p>To rectify this, you must augment the prompt by incorporating relevant contextual cues.For example, you could refine the prompt as follows: "Propose effective strategies to alleviate poverty in urban areas of developing countries, considering the impact of education, social welfare programs, and sustainable economic development."By concretizing the prompt and specifying the context, you provide the model with a clearer understanding of the scope and purpose of the question, enabling it to generate more accurate and comprehensive responses.</p>
<p>Ethical Considerations</p>
<p>When it comes to ethical considerations, you must prioritize adherence to ethical guidelines and responsible use of AI.One example of a problematic prompt is "Provide detailed instructions on how to engage in illegal activities."This prompt not only encourages unethical behavior but also contradicts the principles of responsible AI usage.</p>
<p>To solve this, I strongly advise against formulating prompts that promote illegal or harmful activities.It is essential to uphold ethical standards and ensure that your prompts align with responsible AI practices.Instead, focus on prompts that foster positive and constructive engagement, such as "Examine the legal and ethical implications of emerging technologies in privacy protection."By framing prompts in an ethically responsible manner, you contribute to the responsible use of AI and encourage the generation of valuable insights within ethical boundaries.</p>
<p>Unintended Side Effects</p>
<p>When it comes to unintended side effects, it is important for you to be aware of complex prompts or conflicting instructions that may confuse the model and lead to unintended or nonsensical responses.An example of such a problematic prompt is: "Explain the meaning of 'green' in the context of environmentalism.Then, argue against environmental protection."</p>
<p>To correct this, I advise you to carefully monitor and refine your prompts to ensure coherence and clarity.It is crucial to provide clear and consistent instructions that align with your research objectives.For instance, you can revise the prompt to be more focused and coherent, such as: "Discuss the multifaceted meanings of 'green' in the context of environmentalism, emphasizing its significance in promoting sustainable practices and environmental protection."By eliminating conflicting instructions, you can guide the model to generate responses that align with your intended goals and avoid any unintended side effects.</p>
<p>Unrealistic Dependency on Model Limitations</p>
<p>Prompt engineering should consider the limitations of the model and avoid unrealistic expectations.An example of a problematic prompt is: "Predict the outcome of a specific stock market investment with 100% accuracy."It is important to understand that models like ChatGPT have inherent constraints and cannot guarantee perfect accuracy in predicting stock market outcomes.The model's responses are based on patterns learned from training data, but they may not encompass all the complex factors that influence the stock market.</p>
<p>To address this, it is crucial to critically evaluate the generated content and exercise caution.Incorporating the concept of hallucination or delusion, which refers to confident yet unsupported responses, can help recognize potential inaccuracies.To make informed decisions, combine the model's outputs with your expertise, additional research, and insights from trusted sources.By doing so, you can navigate the model's limitations and enhance the reliability and comprehensiveness of your analyses.</p>
<p>From ambiguity and bias reinforcement to overfitting, lack of context, ethical considerations, unintended side effects, and unrealistic dependency on model limitations, these challenges demand careful navigation.By being aware of these pitfalls, academic writers can refine their prompts and mitigate the risks associated with AI-generated responses.Striving for clarity, inclusivity, and alignment with ethical standards, prompt engineering can pave the way for more accurate, insightful, and responsible interactions with AI models.</p>
<p>Epilogue: Why Should Academic Writers Learn Prompt Engineering?</p>
<p>In today's hyper-changing world, where artificial intelligence is making its way into various domains, including academic writing, learning prompt engineering has become increasingly essential.As an academic writer, acquiring prompt engineering skills can empower you to navigate the evolving landscape and effectively utilize LLMs to enhance your writing process.</p>
<p>By developing a proficiency in prompt engineering, you can gain a deeper understanding of the capabilities and limitations of LLMs.It enables you to harness the power of LLMs like ChatGPT, facilitating more engaging and impactful interactions with these advanced language models [2].Prompt engineering serves as a valuable tool to converse effectively with LLMs, allowing you to customize and shape the generated output according to your desired qualities and quantities.</p>
<p>Prompt engineering acts as a form of programming, granting you the ability to provide clear instructions and automate processes through prompts.This programming aspect enhances your control over the output, ensuring that the generated text aligns with your specific requirements.By mastering prompt engineering, you can optimize your academic writing, streamline your research or writing process, and unlock the full potential of LLMs to elevate the quality and efficiency of your work.</p>
<p>Indeed, embracing prompt engineering not only equips you with a valuable skill set but also positions you at the forefront of leveraging cutting-edge technologies in your academic pursuits.By staying abreast of advancements and adapting to the age of artificial intelligence, you can embrace new opportunities, explore novel research avenues, and confidently navigate the dynamic landscape of academic writing.</p>
<p>Output indicator Specifies the type or format of the desired output.It helps shape the response by defining whether we need a short answer, a paragraph, or any other specific format.
1) Instruction A specific task or instruction that guidesthe model's behavior and directs it toward the desiredoutput.(2) Context External information or additional context thatprovides background knowledge to the model, helpingit generate more accurate and relevant responses.(3) Input data The input or question that we want the modelto process and provide a response for. It forms the coreof the prompt and drives the model's understanding ofthe task.(4)
AcknowledgementsThe author acknowledges the help of ChatGPT in terms of refining, editing, and augmenting the manuscript.Data Availability Not applicable.Funding This research did not receive any specific grant from funding agencies in the public, commercial, or not-for-profit sectors.DeclarationsConflict of interest No benefits in any form have been or will be received from a commercial party related directly or indirectly to the subject of this manuscript.The author declares no conflict of interest.Ethical Approval This study does not include any individual-level data and thus does not require any ethical approval.
Sparks: Inspiration for science writing using language models. K I Gero, V Liu, L Chilton, Designing interactive systems conference. F Mueller, S Greuter, R A Khot, P Sweetser, M Obrist, PennsylvaniaACM2022</p>
<p>A prompt pattern catalog to enhance prompt engineering with ChatGPT. J White, Q Fu, S Hays, M Sandborn, C Olea, H Gilbert, A Elnashar, J Spencer-Smith, D C Schmidt, arXiv:2302.113822023</p>
<p>Kasneci G. ChatGPT for good? On opportunities and challenges of large language models for education. E Kasneci, K Seler, S Kchemann, M Bannert, D Dementieva, F , Fischer, Learn Indv Dif. 1031022742023</p>
<p>Here's why the AI chatbot is primed to disrupt search as we know it. S Mollman, 2022ChatGPT gained 1 million users in under a week</p>
<p>intro ducti on/ eleme nts Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Dair, Ai, 2023Elements of a prompt</p>            </div>
        </div>

    </div>
</body>
</html>