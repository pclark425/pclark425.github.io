<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5467 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5467</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5467</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-109.html">extraction-schema-109</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <p><strong>Paper ID:</strong> paper-d135910e2cbf42d255673de57f588cfe3630a726</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/d135910e2cbf42d255673de57f588cfe3630a726" target="_blank">Is there an exemplar theory of concepts?</a></p>
                <p><strong>Paper Venue:</strong> Psychonomic Bulletin & Review</p>
                <p><strong>Paper TL;DR:</strong> It is concluded that exemplars are certainly important in some categorization judgments and in category-learning experiments, but that there is no exemplar theory of human concepts in a broad sense.</p>
                <p><strong>Cost:</strong> 0.021</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5467.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5467.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Prototype theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Prototype theory (summary-description / feature-based models)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts are represented as summary descriptions (prototypes) or structured associations of features that capture what is typical of a category, supporting generalization and hierarchical inference at the category level.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Cognitive representations of semantic categories.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Prototype theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Represents a category by a summary or average description (a prototype) or by a network of category nodes linked to features; category membership and inference are performed by matching items to these summary descriptions and propagating feature or category relations.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>prototype / feature-based / semantic-network (symbolic/structured summary)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Abstracted summary representations; encodes generic (category-level) properties; supports hierarchical links and inheritance; efficient storage (one representation per category); supports compositional/structured relations among categories and features.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Rosch & Mervis (1975) and Rosch et al. (1976) basic-level findings, typicality effects, capacity to represent generic knowledge and hierarchical inheritance; prototype/feature models explain basic-level advantage and many semantic memory phenomena cited in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Some category-learning experiments show exemplar advantages when few, repeated exemplars are trained; prototype-only accounts must be extended to capture exemplar effects and fine-grained episodic influences.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Natural-category representation, basic-level categorization, semantic memory, induction (when paired with structured knowledge), sentence verification/hierarchical inference.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Contrasted with exemplar models which store instances rather than summaries; prototype models naturally support generic knowledge and hierarchical inference whereas exemplar models struggle with those phenomena.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Match incoming stimulus features to stored category prototype(s) or activate category nodes that propagate feature inferences and hierarchical inheritance; typicality determined by distance from prototype.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Does not by itself capture exemplar-specific effects or fine-grained instance memory; needs extensions to account for situations where specific exemplars dominate classification or for dynamic learning that produces both prototypes and retained exemplars.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Is there an exemplar theory of concepts?', 'publication_date_yy_mm': '2016-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5467.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5467.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Exemplar theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Exemplar theory / exemplar models (Medin & colleagues; Nosofsky)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts are represented as memories of specific encountered instances (exemplars); categorization and generalization emerge from similarity-based retrieval and aggregation of those stored exemplars.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Context theory of classification learning.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Exemplar theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Stores individual labeled instances in memory; classification of new items is done by retrieving similar exemplars and using their categories/properties (often via similarity-weighted aggregation governed by similarity functions like exponential or multiplicative rules).</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>exemplar / memory-based (episodic-instance representations)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Instance-level representations with frequency-sensitive storage; similarity-based retrieval (Shepard exponential or Medin multiplicative rules); can capture variability and atypical exemplars; little or no explicit summary abstraction.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Strong support in laboratory category-learning tasks with repeated exposure to a small set of exemplars (Medin & Schaffer 1978; Nosofsky 1988; Smith & Minda 1998) and Brooks-style exemplar effects where salient familiar exemplars influence classification (Brooks 1987; Allen & Brooks 1991; Thibaut & Gelaes 2006).</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Paper argues exemplar models lack accounts for hierarchical structure, basic-level advantage, generic knowledge representation, causal/feature-structure effects in induction, and computational scalability for large real-world categories; no comprehensive exemplar account of induction or hierarchical inference is presented.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Laboratory category learning, similarity-based categorization, tasks showing exemplar-specific bias or reminding effects, some rapid-learning cases with few exemplars.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Explains detailed instance effects better than prototype models in constrained learning tasks, but contrasts with prototype and theory-based models in failing to naturally represent category-level generalizations, hierarchical links, and causal knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Encode each encounter as an exemplar; retrieve exemplars by similarity; compute aggregated category evidence (weighted by similarity and possibly frequency); similarity functions (e.g., Shepard exponential, Medin multiplicative) determine influence of exemplars.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to represent and compute hierarchies and inheritance, generic facts (e.g., 'mammals have four-chambered hearts'), and causal relations; scaling to millions of exemplars and deriving coverage/diversity effects in induction remain unresolved according to the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Is there an exemplar theory of concepts?', 'publication_date_yy_mm': '2016-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5467.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5467.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Exemplar effects (Brooks)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Brooks-style exemplar effects (salient exemplar influence / reminding)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Salient, well-learned exemplars can bias categorization and property attribution beyond category descriptions, often via implicit memory and reminding processes.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Decentralized control of categorization: The role of prior processing episodes.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Brooks exemplar effects / reminding-based exemplar influence</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Prior processing episodes (salient exemplars) implicitly prime or remind during later classification, causing those exemplars to dominate judgments even when a rule or summary would be more appropriate.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>episodic/salient exemplar influence (implicit memory/reminding)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Long-lasting implicit influence, requires high similarity to known exemplar, can override explicit rules, not necessarily stored with explicit category labels for all hierarchies.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Brooks (1987) and follow-ups (Brooks, Norman, & Allen 1991; Allen & Brooks 1991) show exemplar memory influencing categorization even when harmful; effects persist over weeks consistent with implicit memory.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>These effects do not equate to a full exemplar theory of concepts; they are task- or exemplar-specific and do not explain broad knowledge-based inference or hierarchical structures.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Categorization tasks where specific studied exemplars are salient; medical diagnosis analogs; lab learning paradigms with intense study of a few exemplars.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Unlike global exemplar theory, Brooks effects are compatible with hybrid views where both exemplar influences and summary/rule knowledge coexist; they resemble implicit memory/reminding accounts more than full-instance-repository models.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Implicit memory cues and reminding retrieve specific exemplar traces which bias categorization and property attribution when high similarity occurs.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Do not provide a mechanism for representing general categorical knowledge or explaining broad conceptual phenomena; unclear how to scale to naturalistic concept use.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Is there an exemplar theory of concepts?', 'publication_date_yy_mm': '2016-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5467.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e5467.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Semantic network / hierarchical model</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Collins & Quillian hierarchical semantic network model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts are represented as nodes in a network with hierarchical (is-a) links to superordinate categories and linked features; inference and verification traverse links.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Retrieval time from semantic memory.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Hierarchical semantic network model</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Concepts are nodes organized in a tree-like hierarchy; properties are stored at nodes and inherited by subordinate nodes via links, and retrieval/inference time corresponds to link distance.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>symbolic semantic network (hierarchical links)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Explicit hierarchical (is-a) structure; inheritance of properties via links; compositional relations among categories; supports fast sentence verification via link traversal.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Sentence-verification reaction-time patterns and classic semantic-memory experiments cited in the paper (Collins & Quillian tradition) motivate hierarchical representations and basic-level effects.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Empirical findings such as typicality effects and gradations of category membership are problematic for strictly rigid inheritance models; exemplar and prototype accounts handle graded typicality better.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Sentence verification, hierarchical inference, semantic memory organization.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Provides explicit hierarchical inference mechanisms that exemplar models lack; contrasted with prototype and distributed models which handle graded typicality and feature overlap differently.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Inference by traversing network links; property retrieval via node lookup and inheritance along 'is-a' links.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Rigid inheritance sometimes fails to capture typicality/gradedness and knowledge-driven modulations; how to reconcile with feature/causal knowledge remains an open question.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Is there an exemplar theory of concepts?', 'publication_date_yy_mm': '2016-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5467.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e5467.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Theory-theory / causal models</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Theory-theory (causal models of categories)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts are organized into theory-like causal structures where features and categories are linked by causal and explanatory relations that guide inference and generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Causal models: How people think about the world and its alternatives.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Theory-theory / causal models</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Represents category knowledge as causal structures or simple theories (e.g., how features arise or interact), enabling people to make principled inferences about novel cases beyond mere similarity.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>theory-like / causal / structured knowledge</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Causal relations among features, generative/explanatory structure, domain knowledge biasing induction, supports content-sensitive generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Studies showing that causal beliefs influence categorization and induction (Rehder & Hastie 2001; Ahn 1998; Kim & Ahn 2002) and Rehder's 2009 demonstrations that causal links reduce similarity effects in induction.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Requires representing abstract causal relations not tied to single exemplars; exemplar and pure similarity-based models have difficulty capturing these effects without added structure.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Category-based induction, causal reasoning, feature centrality judgments, concept learning guided by background knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Explains property-based and content-sensitive induction better than exemplar/prototype similarity-only accounts; Bayesian structured models operationalize elements of theory-theory.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Inference by causal/structural reasoning (propagating effects through causal links), using background theories to assess relevance and explain feature co-occurrence.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Computational specification and learning of causal theories from experience; integration with exemplar and prototype information in real-time categorization.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Is there an exemplar theory of concepts?', 'publication_date_yy_mm': '2016-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5467.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e5467.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Structured Bayesian models</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Structured statistical / Bayesian models of induction (Kemp & Tenenbaum)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts and inductive generalization are modeled as structured probabilistic generative models that capture category structure and feature relations, enabling principled inference from sparse data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Structured statistical models of inductive reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Structured Bayesian models / Kemp & Tenenbaum</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Represents categories and feature distributions using structured probabilistic models and priors (e.g., hierarchical/graphical structures) and computes induction by Bayesian inference over these models.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>theory-like / structured probabilistic / generative</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Explicit structural assumptions, probabilistic generalization, can encode hierarchical and causal relations, principled handling of sparse data and diversity/coverage effects.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Kemp & Tenenbaum (2009) exemplify how structured statistical models account for a range of inductive reasoning phenomena, including coverage/diversity effects and principled generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Computational complexity and specification of appropriate priors; empirical work often assumes category-level feature associations rather than instance repositories.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Category-based induction, structured generalization, learning from few examples, hierarchical inference.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Provides a formal alternative to similarity-based and exemplar approaches, naturally handling diversity/coverage and causal/structured effects that exemplar models struggle with.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Bayesian inference over structured hypothesis spaces (graphs, hierarchies, generative processes) to compute likelihoods of property transfer and generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How these structured models are learned incrementally in development and integrated with episodic exemplar memory in natural cognition.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Is there an exemplar theory of concepts?', 'publication_date_yy_mm': '2016-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5467.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e5467.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SUSTAIN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SUSTAIN (Supervised and Unsupervised STratified Adaptive Incremental Network)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A clustering/network model of category learning that can capture both exemplar-like and prototype-like behavior by forming and adapting clusters representing groups of exemplars.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>SUSTAIN: A network model of category learning.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>SUSTAIN (clustering hybrid model)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Forms clusters of stimuli during learning; clusters can act like stored exemplars (fine-grained) or merge to produce prototype-like summaries, allowing both exemplar and prototype effects depending on experience.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>clustering / hybrid exemplar-prototype (network)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Adaptive cluster formation; can represent both single exemplars and compressed summary clusters; learning-driven flexibility; accounts for shifts between exemplar and prototype-like behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Love, Medin & Gureckis (2004) show SUSTAIN captures many empirical patterns in category learning and can blur exemplar/prototype distinctions.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Modeling of broad conceptual phenomena (hierarchies, causal knowledge, induction beyond lab tasks) is not fully demonstrated; may need extension for generic knowledge representation.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Category learning experiments, modeling transitions between exemplar and prototype-like representations.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Bridges exemplar and prototype accounts better than pure-instance or pure-summary models; still may not provide full account of knowledge effects discussed in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Incremental cluster creation and adjustment based on errors/similarity; retrieval via cluster matching with attention-weighted dimensions.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Whether cluster dynamics scale to real-world conceptual knowledge and how clusters encode causal and hierarchical relations remain open.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Is there an exemplar theory of concepts?', 'publication_date_yy_mm': '2016-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5467.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e5467.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Distributed/connectionist models</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Distributed memory / connectionist models of categorization (Knapp & Anderson; Rogers et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Concepts are represented as distributed patterns across units (features) in connectionist networks; category knowledge emerges from learned weight patterns rather than explicit symbolic entries.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Theory of categorization based on distributed memory storage.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Distributed / connectionist feature-based models</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Uses distributed representations in neural-network-like architectures where concepts correspond to patterns of activation across units; learning modifies weights to capture feature correlations and category structure.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>distributed / feature-based / connectionist</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Distributed and graded representations; graceful degradation (used to model semantic dementia); can capture feature correlations and graded typicality; learning-based emergence of categories.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Knapp & Anderson (1984) and Rogers et al. (2004) provide computational implementations and account for neuropsychological patterns (e.g., patterns of semantic deterioration) consistent with distributed feature representations.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Explicit hierarchical inheritance and causal theory-like structure are not naturally explicit; mapping to symbolic inferences can be hard without additional structure.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Semantic memory modeling, category learning, modeling patterns of impairment in dementia and aphasia.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>More flexible and neuropsychologically grounded than pure symbolic networks; contrasted with exemplar models in storage format (distributed patterns vs discrete instances) and with prototype models in how summaries emerge.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Learning via weight adjustment across distributed units; generalization via overlap in activation patterns; degradation via damage to weights/units.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to represent explicit causal relations and hierarchical inheritance in purely distributed codes; integration with episodic exemplar memory.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Is there an exemplar theory of concepts?', 'publication_date_yy_mm': '2016-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5467.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e5467.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Context theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Context theory of classification learning (Medin & Schaffer)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An exemplar-based account that emphasizes the role of contextual similarity (multiplicative similarity across dimensions) in classification decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Context theory of classification learning.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Classifies by computing similarity of a test item to stored exemplars using multiplicative rules over feature dimensions, emphasizing how context and diagnostic features weight exemplar influence.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>exemplar-based (similarity multiplicative)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Similarity computed multiplicatively across dimensions; emphasizes context/diagnostic features; instances stored as exemplars with labels.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Medin & Schaffer (1978) and follow-up work explain many lab classification patterns, especially with diagnostic dimensions and small training sets.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>As discussed in the paper, difficulty scaling to hierarchical inference and representing generic knowledge detached from specific exemplars.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Laboratory classification tasks, learning with diagnostic feature dimensions.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>A canonical exemplar competitor to prototype models; stronger on instance-specific and diagnostic-dimension phenomena but weaker on representing category-level generic knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Similarity-based retrieval using multiplicative combination of dimension-specific similarities; exemplar aggregation for categorization.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to derive hierarchical relations or encode generic (non-experiential) knowledge within this framework.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Is there an exemplar theory of concepts?', 'publication_date_yy_mm': '2016-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5467.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e5467.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Shepard's law</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Shepard's universal law of generalization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A quantitative empirical finding that generalization declines approximately exponentially with psychological distance in stimulus space.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Toward a universal law of generalization for psychological science.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Shepard generalization law</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>States that the probability of generalizing a response from one stimulus to another falls off exponentially with their psychological distance; often instantiated via exponential similarity functions in models.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>similarity-based quantitative law (functional similarity metric)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Exponential fall-off of influence with distance; underlies many exemplar/prototype similarity functions.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Cited as foundational to exemplar similarity functions (Shepard 1987) and widely reproduced in generalization tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Does not specify representational format (exemplar vs prototype) and may be subordinate to content/causal factors in some induction tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Generalization, similarity-based categorization, model similarity kernels.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Provides a formal similarity kernel used by both exemplar and prototype models; theory-based and causal accounts can override similarity-based predictions in many tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Computes similarity as an exponential function of psychological distance to weight exemplar/prototype influence.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Psychological distance metrics and role of structured knowledge/causal relations in modulating or bypassing similarity-based generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Is there an exemplar theory of concepts?', 'publication_date_yy_mm': '2016-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5467.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e5467.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Basic-level advantage (Rosch)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Basic-level advantage in categorization (Rosch et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Empirical regularity that mid-level ('basic') categories (e.g., 'chair', 'dog') are preferred, learned earlier, and recognized faster than more-general or more-specific levels.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Basic objects in natural categories.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Basic-level advantage / family-resemblance findings</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Observation that there is a preferred level of categorization that maximizes informativeness and distinctiveness; prototype/feature models explain this by feature coherence at that level.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>empirical phenomenon informing prototype/feature models</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Preferred naming level, faster identification, developmental acquisition order, tied to feature informativeness and distinctiveness.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Rosch et al. (1976) and related work show basic-level naming/processing advantages and developmental patterns (Anglin 1977).</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Exemplar accounts struggle to explain why superordinate classification is slower if classification relies on exemplar similarity; exemplar explanations require additional assumptions.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Naming, object recognition, developmental word learning.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Prototype/feature representations naturally explain the effect via category-level summaries; exemplar models need mechanisms to produce the observed level preference.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Prototype-match or feature-distinctiveness computations that make the basic level optimally informative and distinct from neighbors.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How hybrid/hierarchical storage combining exemplars and summaries would produce basic-level advantages in realistic learning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Is there an exemplar theory of concepts?', 'publication_date_yy_mm': '2016-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5467.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e5467.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Inductive coverage/diversity effects</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Coverage and diversity effects in category-based induction (Osherson et al.; Rips)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Empirical findings that inductive strength depends on how well premise categories cover a superordinate (coverage) and on the diversity of premises: broader/diverse premises yield stronger generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Category-based induction.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Coverage/diversity effects in induction</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>People generalize properties more strongly when premises are representative/cover the superordinate category well and when multiple premises are diverse, implying reliance on category-level representativeness beyond simple pairwise similarity.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>empirical induction phenomenon (requires category-level representation)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Dependence on representativeness/coverage and premise diversity; sensitivity to content and feature relevance.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Osherson et al. (1990), Rips (1975), and subsequent studies show coverage and diversity effects in CBI tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Exemplar models find it hard to compute coverage from stored exemplars (would require comparing large exemplar sets); exemplar-similarity alone does not predict coverage/diversity patterns easily.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Category-based induction problems, multi-premise generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Structured/prototype/Bayesian models naturally encode coverage and diversity; exemplar-only approaches struggle without added mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Models compute representativeness/coverage via similarity matrices or structured priors (in Bayesian approaches) rather than pure exemplar matching.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How exemplar storage and retrieval mechanisms could efficiently instantiate coverage computations in real-world cognition.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Is there an exemplar theory of concepts?', 'publication_date_yy_mm': '2016-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5467.12">
                <h3 class="extraction-instance">Extracted Data Instance 12 (e5467.12)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Property-type effects (Heit & Rubinstein)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Similarity and property effects in inductive reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Empirical finding that the nature of the property (e.g., biological vs behavioral) changes inductive strength, reflecting domain knowledge rather than only similarity.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Similarity and property effects in inductive reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Property-type/content effects in induction</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>The tendency to generalize depends not only on category similarity but also on the type of property being transferred and background knowledge about relevance of categories to that property.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>empirical knowledge-sensitive induction phenomenon</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Content sensitivity; differential generalization for biological vs behavioral properties; reliance on domain knowledge and category membership.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Heit & Rubinstein (1994) documented differing inductive strengths depending on property type, supporting theory-based influences on induction.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Pure similarity-based exemplar models cannot account for content-dependent differences because similarity stays constant while induction strength varies.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Inductive reasoning, developmental generalization, distinguishing when to rely on similarity vs category membership.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Supports theory-theory / causal / prototype-based representations over exemplar-only accounts for many inductions.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Use of domain knowledge (e.g., biological taxonomies) to weigh or select which features/properties are relevant for induction.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to computationally integrate property-type sensitivity with exemplar or distributed representations in a unified cognitive architecture.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Is there an exemplar theory of concepts?', 'publication_date_yy_mm': '2016-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5467.13">
                <h3 class="extraction-instance">Extracted Data Instance 13 (e5467.13)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Rehder causal-generalization findings</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Causal-based property generalization (Rehder)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Empirical results showing that known causal links among features can drive induction and reduce the influence of exemplar similarity in generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Causal-based property generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Causal-based property generalization</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>When causal relations among features are known, people base generalization on causal structure rather than on surface similarity between exemplars, indicating use of structured causal knowledge in concept use.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>causal/theory-like representation influencing induction</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Causal prioritization over similarity; feature relevance determined by causal links; domain knowledge modulates generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Rehder (2009) and related work show similarity has little effect on induction when causal links explain the generalization, emphasizing structured knowledge use.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Exemplar and similarity-based models struggle to accommodate causal-structure-driven patterns without additional mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Property generalization, causal reasoning within categorization, laboratory induction tasks with known causal structures.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Aligns with theory-theory and structured Bayesian approaches; challenges pure exemplar/prototype similarity-only models.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Inference proceeds via causal chains and assessment of causal relevance for transferring properties between categories.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How causal structure is learned and represented alongside exemplar memories; computational integration across levels.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Is there an exemplar theory of concepts?', 'publication_date_yy_mm': '2016-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Cognitive representations of semantic categories. <em>(Rating: 2)</em></li>
                <li>Basic objects in natural categories. <em>(Rating: 2)</em></li>
                <li>Context theory of classification learning. <em>(Rating: 2)</em></li>
                <li>Similarity, frequency, and category representations. <em>(Rating: 2)</em></li>
                <li>SUSTAIN: A network model of category learning. <em>(Rating: 2)</em></li>
                <li>Structured statistical models of inductive reasoning. <em>(Rating: 2)</em></li>
                <li>Decentralized control of categorization: The role of prior processing episodes. <em>(Rating: 2)</em></li>
                <li>Retrieval time from semantic memory. <em>(Rating: 2)</em></li>
                <li>Structure and deterioration of semantic memory: A neuropsychological and computational investigation. <em>(Rating: 2)</em></li>
                <li>Category-based induction. <em>(Rating: 2)</em></li>
                <li>Similarity and property effects in inductive reasoning. <em>(Rating: 1)</em></li>
                <li>Causal-based property generalization. <em>(Rating: 1)</em></li>
                <li>Learning categories at different hierarchical levels: A comparison of category learning models. <em>(Rating: 1)</em></li>
                <li>Toward a universal law of generalization for psychological science. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5467",
    "paper_id": "paper-d135910e2cbf42d255673de57f588cfe3630a726",
    "extraction_schema_id": "extraction-schema-109",
    "extracted_data": [
        {
            "name_short": "Prototype theory",
            "name_full": "Prototype theory (summary-description / feature-based models)",
            "brief_description": "Concepts are represented as summary descriptions (prototypes) or structured associations of features that capture what is typical of a category, supporting generalization and hierarchical inference at the category level.",
            "citation_title": "Cognitive representations of semantic categories.",
            "mention_or_use": "mention",
            "theory_or_model_name": "Prototype theory",
            "theory_or_model_description": "Represents a category by a summary or average description (a prototype) or by a network of category nodes linked to features; category membership and inference are performed by matching items to these summary descriptions and propagating feature or category relations.",
            "representation_format_type": "prototype / feature-based / semantic-network (symbolic/structured summary)",
            "key_properties": "Abstracted summary representations; encodes generic (category-level) properties; supports hierarchical links and inheritance; efficient storage (one representation per category); supports compositional/structured relations among categories and features.",
            "empirical_support": "Rosch & Mervis (1975) and Rosch et al. (1976) basic-level findings, typicality effects, capacity to represent generic knowledge and hierarchical inheritance; prototype/feature models explain basic-level advantage and many semantic memory phenomena cited in the paper.",
            "empirical_challenges": "Some category-learning experiments show exemplar advantages when few, repeated exemplars are trained; prototype-only accounts must be extended to capture exemplar effects and fine-grained episodic influences.",
            "applied_domains_or_tasks": "Natural-category representation, basic-level categorization, semantic memory, induction (when paired with structured knowledge), sentence verification/hierarchical inference.",
            "comparison_to_other_models": "Contrasted with exemplar models which store instances rather than summaries; prototype models naturally support generic knowledge and hierarchical inference whereas exemplar models struggle with those phenomena.",
            "functional_mechanisms": "Match incoming stimulus features to stored category prototype(s) or activate category nodes that propagate feature inferences and hierarchical inheritance; typicality determined by distance from prototype.",
            "limitations_or_open_questions": "Does not by itself capture exemplar-specific effects or fine-grained instance memory; needs extensions to account for situations where specific exemplars dominate classification or for dynamic learning that produces both prototypes and retained exemplars.",
            "uuid": "e5467.0",
            "source_info": {
                "paper_title": "Is there an exemplar theory of concepts?",
                "publication_date_yy_mm": "2016-06"
            }
        },
        {
            "name_short": "Exemplar theory",
            "name_full": "Exemplar theory / exemplar models (Medin & colleagues; Nosofsky)",
            "brief_description": "Concepts are represented as memories of specific encountered instances (exemplars); categorization and generalization emerge from similarity-based retrieval and aggregation of those stored exemplars.",
            "citation_title": "Context theory of classification learning.",
            "mention_or_use": "mention",
            "theory_or_model_name": "Exemplar theory",
            "theory_or_model_description": "Stores individual labeled instances in memory; classification of new items is done by retrieving similar exemplars and using their categories/properties (often via similarity-weighted aggregation governed by similarity functions like exponential or multiplicative rules).",
            "representation_format_type": "exemplar / memory-based (episodic-instance representations)",
            "key_properties": "Instance-level representations with frequency-sensitive storage; similarity-based retrieval (Shepard exponential or Medin multiplicative rules); can capture variability and atypical exemplars; little or no explicit summary abstraction.",
            "empirical_support": "Strong support in laboratory category-learning tasks with repeated exposure to a small set of exemplars (Medin & Schaffer 1978; Nosofsky 1988; Smith & Minda 1998) and Brooks-style exemplar effects where salient familiar exemplars influence classification (Brooks 1987; Allen & Brooks 1991; Thibaut & Gelaes 2006).",
            "empirical_challenges": "Paper argues exemplar models lack accounts for hierarchical structure, basic-level advantage, generic knowledge representation, causal/feature-structure effects in induction, and computational scalability for large real-world categories; no comprehensive exemplar account of induction or hierarchical inference is presented.",
            "applied_domains_or_tasks": "Laboratory category learning, similarity-based categorization, tasks showing exemplar-specific bias or reminding effects, some rapid-learning cases with few exemplars.",
            "comparison_to_other_models": "Explains detailed instance effects better than prototype models in constrained learning tasks, but contrasts with prototype and theory-based models in failing to naturally represent category-level generalizations, hierarchical links, and causal knowledge.",
            "functional_mechanisms": "Encode each encounter as an exemplar; retrieve exemplars by similarity; compute aggregated category evidence (weighted by similarity and possibly frequency); similarity functions (e.g., Shepard exponential, Medin multiplicative) determine influence of exemplars.",
            "limitations_or_open_questions": "How to represent and compute hierarchies and inheritance, generic facts (e.g., 'mammals have four-chambered hearts'), and causal relations; scaling to millions of exemplars and deriving coverage/diversity effects in induction remain unresolved according to the paper.",
            "uuid": "e5467.1",
            "source_info": {
                "paper_title": "Is there an exemplar theory of concepts?",
                "publication_date_yy_mm": "2016-06"
            }
        },
        {
            "name_short": "Exemplar effects (Brooks)",
            "name_full": "Brooks-style exemplar effects (salient exemplar influence / reminding)",
            "brief_description": "Salient, well-learned exemplars can bias categorization and property attribution beyond category descriptions, often via implicit memory and reminding processes.",
            "citation_title": "Decentralized control of categorization: The role of prior processing episodes.",
            "mention_or_use": "mention",
            "theory_or_model_name": "Brooks exemplar effects / reminding-based exemplar influence",
            "theory_or_model_description": "Prior processing episodes (salient exemplars) implicitly prime or remind during later classification, causing those exemplars to dominate judgments even when a rule or summary would be more appropriate.",
            "representation_format_type": "episodic/salient exemplar influence (implicit memory/reminding)",
            "key_properties": "Long-lasting implicit influence, requires high similarity to known exemplar, can override explicit rules, not necessarily stored with explicit category labels for all hierarchies.",
            "empirical_support": "Brooks (1987) and follow-ups (Brooks, Norman, & Allen 1991; Allen & Brooks 1991) show exemplar memory influencing categorization even when harmful; effects persist over weeks consistent with implicit memory.",
            "empirical_challenges": "These effects do not equate to a full exemplar theory of concepts; they are task- or exemplar-specific and do not explain broad knowledge-based inference or hierarchical structures.",
            "applied_domains_or_tasks": "Categorization tasks where specific studied exemplars are salient; medical diagnosis analogs; lab learning paradigms with intense study of a few exemplars.",
            "comparison_to_other_models": "Unlike global exemplar theory, Brooks effects are compatible with hybrid views where both exemplar influences and summary/rule knowledge coexist; they resemble implicit memory/reminding accounts more than full-instance-repository models.",
            "functional_mechanisms": "Implicit memory cues and reminding retrieve specific exemplar traces which bias categorization and property attribution when high similarity occurs.",
            "limitations_or_open_questions": "Do not provide a mechanism for representing general categorical knowledge or explaining broad conceptual phenomena; unclear how to scale to naturalistic concept use.",
            "uuid": "e5467.2",
            "source_info": {
                "paper_title": "Is there an exemplar theory of concepts?",
                "publication_date_yy_mm": "2016-06"
            }
        },
        {
            "name_short": "Semantic network / hierarchical model",
            "name_full": "Collins & Quillian hierarchical semantic network model",
            "brief_description": "Concepts are represented as nodes in a network with hierarchical (is-a) links to superordinate categories and linked features; inference and verification traverse links.",
            "citation_title": "Retrieval time from semantic memory.",
            "mention_or_use": "mention",
            "theory_or_model_name": "Hierarchical semantic network model",
            "theory_or_model_description": "Concepts are nodes organized in a tree-like hierarchy; properties are stored at nodes and inherited by subordinate nodes via links, and retrieval/inference time corresponds to link distance.",
            "representation_format_type": "symbolic semantic network (hierarchical links)",
            "key_properties": "Explicit hierarchical (is-a) structure; inheritance of properties via links; compositional relations among categories; supports fast sentence verification via link traversal.",
            "empirical_support": "Sentence-verification reaction-time patterns and classic semantic-memory experiments cited in the paper (Collins & Quillian tradition) motivate hierarchical representations and basic-level effects.",
            "empirical_challenges": "Empirical findings such as typicality effects and gradations of category membership are problematic for strictly rigid inheritance models; exemplar and prototype accounts handle graded typicality better.",
            "applied_domains_or_tasks": "Sentence verification, hierarchical inference, semantic memory organization.",
            "comparison_to_other_models": "Provides explicit hierarchical inference mechanisms that exemplar models lack; contrasted with prototype and distributed models which handle graded typicality and feature overlap differently.",
            "functional_mechanisms": "Inference by traversing network links; property retrieval via node lookup and inheritance along 'is-a' links.",
            "limitations_or_open_questions": "Rigid inheritance sometimes fails to capture typicality/gradedness and knowledge-driven modulations; how to reconcile with feature/causal knowledge remains an open question.",
            "uuid": "e5467.3",
            "source_info": {
                "paper_title": "Is there an exemplar theory of concepts?",
                "publication_date_yy_mm": "2016-06"
            }
        },
        {
            "name_short": "Theory-theory / causal models",
            "name_full": "Theory-theory (causal models of categories)",
            "brief_description": "Concepts are organized into theory-like causal structures where features and categories are linked by causal and explanatory relations that guide inference and generalization.",
            "citation_title": "Causal models: How people think about the world and its alternatives.",
            "mention_or_use": "mention",
            "theory_or_model_name": "Theory-theory / causal models",
            "theory_or_model_description": "Represents category knowledge as causal structures or simple theories (e.g., how features arise or interact), enabling people to make principled inferences about novel cases beyond mere similarity.",
            "representation_format_type": "theory-like / causal / structured knowledge",
            "key_properties": "Causal relations among features, generative/explanatory structure, domain knowledge biasing induction, supports content-sensitive generalization.",
            "empirical_support": "Studies showing that causal beliefs influence categorization and induction (Rehder & Hastie 2001; Ahn 1998; Kim & Ahn 2002) and Rehder's 2009 demonstrations that causal links reduce similarity effects in induction.",
            "empirical_challenges": "Requires representing abstract causal relations not tied to single exemplars; exemplar and pure similarity-based models have difficulty capturing these effects without added structure.",
            "applied_domains_or_tasks": "Category-based induction, causal reasoning, feature centrality judgments, concept learning guided by background knowledge.",
            "comparison_to_other_models": "Explains property-based and content-sensitive induction better than exemplar/prototype similarity-only accounts; Bayesian structured models operationalize elements of theory-theory.",
            "functional_mechanisms": "Inference by causal/structural reasoning (propagating effects through causal links), using background theories to assess relevance and explain feature co-occurrence.",
            "limitations_or_open_questions": "Computational specification and learning of causal theories from experience; integration with exemplar and prototype information in real-time categorization.",
            "uuid": "e5467.4",
            "source_info": {
                "paper_title": "Is there an exemplar theory of concepts?",
                "publication_date_yy_mm": "2016-06"
            }
        },
        {
            "name_short": "Structured Bayesian models",
            "name_full": "Structured statistical / Bayesian models of induction (Kemp & Tenenbaum)",
            "brief_description": "Concepts and inductive generalization are modeled as structured probabilistic generative models that capture category structure and feature relations, enabling principled inference from sparse data.",
            "citation_title": "Structured statistical models of inductive reasoning.",
            "mention_or_use": "mention",
            "theory_or_model_name": "Structured Bayesian models / Kemp & Tenenbaum",
            "theory_or_model_description": "Represents categories and feature distributions using structured probabilistic models and priors (e.g., hierarchical/graphical structures) and computes induction by Bayesian inference over these models.",
            "representation_format_type": "theory-like / structured probabilistic / generative",
            "key_properties": "Explicit structural assumptions, probabilistic generalization, can encode hierarchical and causal relations, principled handling of sparse data and diversity/coverage effects.",
            "empirical_support": "Kemp & Tenenbaum (2009) exemplify how structured statistical models account for a range of inductive reasoning phenomena, including coverage/diversity effects and principled generalization.",
            "empirical_challenges": "Computational complexity and specification of appropriate priors; empirical work often assumes category-level feature associations rather than instance repositories.",
            "applied_domains_or_tasks": "Category-based induction, structured generalization, learning from few examples, hierarchical inference.",
            "comparison_to_other_models": "Provides a formal alternative to similarity-based and exemplar approaches, naturally handling diversity/coverage and causal/structured effects that exemplar models struggle with.",
            "functional_mechanisms": "Bayesian inference over structured hypothesis spaces (graphs, hierarchies, generative processes) to compute likelihoods of property transfer and generalization.",
            "limitations_or_open_questions": "How these structured models are learned incrementally in development and integrated with episodic exemplar memory in natural cognition.",
            "uuid": "e5467.5",
            "source_info": {
                "paper_title": "Is there an exemplar theory of concepts?",
                "publication_date_yy_mm": "2016-06"
            }
        },
        {
            "name_short": "SUSTAIN",
            "name_full": "SUSTAIN (Supervised and Unsupervised STratified Adaptive Incremental Network)",
            "brief_description": "A clustering/network model of category learning that can capture both exemplar-like and prototype-like behavior by forming and adapting clusters representing groups of exemplars.",
            "citation_title": "SUSTAIN: A network model of category learning.",
            "mention_or_use": "mention",
            "theory_or_model_name": "SUSTAIN (clustering hybrid model)",
            "theory_or_model_description": "Forms clusters of stimuli during learning; clusters can act like stored exemplars (fine-grained) or merge to produce prototype-like summaries, allowing both exemplar and prototype effects depending on experience.",
            "representation_format_type": "clustering / hybrid exemplar-prototype (network)",
            "key_properties": "Adaptive cluster formation; can represent both single exemplars and compressed summary clusters; learning-driven flexibility; accounts for shifts between exemplar and prototype-like behavior.",
            "empirical_support": "Love, Medin & Gureckis (2004) show SUSTAIN captures many empirical patterns in category learning and can blur exemplar/prototype distinctions.",
            "empirical_challenges": "Modeling of broad conceptual phenomena (hierarchies, causal knowledge, induction beyond lab tasks) is not fully demonstrated; may need extension for generic knowledge representation.",
            "applied_domains_or_tasks": "Category learning experiments, modeling transitions between exemplar and prototype-like representations.",
            "comparison_to_other_models": "Bridges exemplar and prototype accounts better than pure-instance or pure-summary models; still may not provide full account of knowledge effects discussed in the paper.",
            "functional_mechanisms": "Incremental cluster creation and adjustment based on errors/similarity; retrieval via cluster matching with attention-weighted dimensions.",
            "limitations_or_open_questions": "Whether cluster dynamics scale to real-world conceptual knowledge and how clusters encode causal and hierarchical relations remain open.",
            "uuid": "e5467.6",
            "source_info": {
                "paper_title": "Is there an exemplar theory of concepts?",
                "publication_date_yy_mm": "2016-06"
            }
        },
        {
            "name_short": "Distributed/connectionist models",
            "name_full": "Distributed memory / connectionist models of categorization (Knapp & Anderson; Rogers et al.)",
            "brief_description": "Concepts are represented as distributed patterns across units (features) in connectionist networks; category knowledge emerges from learned weight patterns rather than explicit symbolic entries.",
            "citation_title": "Theory of categorization based on distributed memory storage.",
            "mention_or_use": "mention",
            "theory_or_model_name": "Distributed / connectionist feature-based models",
            "theory_or_model_description": "Uses distributed representations in neural-network-like architectures where concepts correspond to patterns of activation across units; learning modifies weights to capture feature correlations and category structure.",
            "representation_format_type": "distributed / feature-based / connectionist",
            "key_properties": "Distributed and graded representations; graceful degradation (used to model semantic dementia); can capture feature correlations and graded typicality; learning-based emergence of categories.",
            "empirical_support": "Knapp & Anderson (1984) and Rogers et al. (2004) provide computational implementations and account for neuropsychological patterns (e.g., patterns of semantic deterioration) consistent with distributed feature representations.",
            "empirical_challenges": "Explicit hierarchical inheritance and causal theory-like structure are not naturally explicit; mapping to symbolic inferences can be hard without additional structure.",
            "applied_domains_or_tasks": "Semantic memory modeling, category learning, modeling patterns of impairment in dementia and aphasia.",
            "comparison_to_other_models": "More flexible and neuropsychologically grounded than pure symbolic networks; contrasted with exemplar models in storage format (distributed patterns vs discrete instances) and with prototype models in how summaries emerge.",
            "functional_mechanisms": "Learning via weight adjustment across distributed units; generalization via overlap in activation patterns; degradation via damage to weights/units.",
            "limitations_or_open_questions": "How to represent explicit causal relations and hierarchical inheritance in purely distributed codes; integration with episodic exemplar memory.",
            "uuid": "e5467.7",
            "source_info": {
                "paper_title": "Is there an exemplar theory of concepts?",
                "publication_date_yy_mm": "2016-06"
            }
        },
        {
            "name_short": "Context theory",
            "name_full": "Context theory of classification learning (Medin & Schaffer)",
            "brief_description": "An exemplar-based account that emphasizes the role of contextual similarity (multiplicative similarity across dimensions) in classification decisions.",
            "citation_title": "Context theory of classification learning.",
            "mention_or_use": "mention",
            "theory_or_model_description": "Classifies by computing similarity of a test item to stored exemplars using multiplicative rules over feature dimensions, emphasizing how context and diagnostic features weight exemplar influence.",
            "representation_format_type": "exemplar-based (similarity multiplicative)",
            "key_properties": "Similarity computed multiplicatively across dimensions; emphasizes context/diagnostic features; instances stored as exemplars with labels.",
            "empirical_support": "Medin & Schaffer (1978) and follow-up work explain many lab classification patterns, especially with diagnostic dimensions and small training sets.",
            "empirical_challenges": "As discussed in the paper, difficulty scaling to hierarchical inference and representing generic knowledge detached from specific exemplars.",
            "applied_domains_or_tasks": "Laboratory classification tasks, learning with diagnostic feature dimensions.",
            "comparison_to_other_models": "A canonical exemplar competitor to prototype models; stronger on instance-specific and diagnostic-dimension phenomena but weaker on representing category-level generic knowledge.",
            "functional_mechanisms": "Similarity-based retrieval using multiplicative combination of dimension-specific similarities; exemplar aggregation for categorization.",
            "limitations_or_open_questions": "How to derive hierarchical relations or encode generic (non-experiential) knowledge within this framework.",
            "uuid": "e5467.8",
            "source_info": {
                "paper_title": "Is there an exemplar theory of concepts?",
                "publication_date_yy_mm": "2016-06"
            }
        },
        {
            "name_short": "Shepard's law",
            "name_full": "Shepard's universal law of generalization",
            "brief_description": "A quantitative empirical finding that generalization declines approximately exponentially with psychological distance in stimulus space.",
            "citation_title": "Toward a universal law of generalization for psychological science.",
            "mention_or_use": "mention",
            "theory_or_model_name": "Shepard generalization law",
            "theory_or_model_description": "States that the probability of generalizing a response from one stimulus to another falls off exponentially with their psychological distance; often instantiated via exponential similarity functions in models.",
            "representation_format_type": "similarity-based quantitative law (functional similarity metric)",
            "key_properties": "Exponential fall-off of influence with distance; underlies many exemplar/prototype similarity functions.",
            "empirical_support": "Cited as foundational to exemplar similarity functions (Shepard 1987) and widely reproduced in generalization tasks.",
            "empirical_challenges": "Does not specify representational format (exemplar vs prototype) and may be subordinate to content/causal factors in some induction tasks.",
            "applied_domains_or_tasks": "Generalization, similarity-based categorization, model similarity kernels.",
            "comparison_to_other_models": "Provides a formal similarity kernel used by both exemplar and prototype models; theory-based and causal accounts can override similarity-based predictions in many tasks.",
            "functional_mechanisms": "Computes similarity as an exponential function of psychological distance to weight exemplar/prototype influence.",
            "limitations_or_open_questions": "Psychological distance metrics and role of structured knowledge/causal relations in modulating or bypassing similarity-based generalization.",
            "uuid": "e5467.9",
            "source_info": {
                "paper_title": "Is there an exemplar theory of concepts?",
                "publication_date_yy_mm": "2016-06"
            }
        },
        {
            "name_short": "Basic-level advantage (Rosch)",
            "name_full": "Basic-level advantage in categorization (Rosch et al.)",
            "brief_description": "Empirical regularity that mid-level ('basic') categories (e.g., 'chair', 'dog') are preferred, learned earlier, and recognized faster than more-general or more-specific levels.",
            "citation_title": "Basic objects in natural categories.",
            "mention_or_use": "mention",
            "theory_or_model_name": "Basic-level advantage / family-resemblance findings",
            "theory_or_model_description": "Observation that there is a preferred level of categorization that maximizes informativeness and distinctiveness; prototype/feature models explain this by feature coherence at that level.",
            "representation_format_type": "empirical phenomenon informing prototype/feature models",
            "key_properties": "Preferred naming level, faster identification, developmental acquisition order, tied to feature informativeness and distinctiveness.",
            "empirical_support": "Rosch et al. (1976) and related work show basic-level naming/processing advantages and developmental patterns (Anglin 1977).",
            "empirical_challenges": "Exemplar accounts struggle to explain why superordinate classification is slower if classification relies on exemplar similarity; exemplar explanations require additional assumptions.",
            "applied_domains_or_tasks": "Naming, object recognition, developmental word learning.",
            "comparison_to_other_models": "Prototype/feature representations naturally explain the effect via category-level summaries; exemplar models need mechanisms to produce the observed level preference.",
            "functional_mechanisms": "Prototype-match or feature-distinctiveness computations that make the basic level optimally informative and distinct from neighbors.",
            "limitations_or_open_questions": "How hybrid/hierarchical storage combining exemplars and summaries would produce basic-level advantages in realistic learning.",
            "uuid": "e5467.10",
            "source_info": {
                "paper_title": "Is there an exemplar theory of concepts?",
                "publication_date_yy_mm": "2016-06"
            }
        },
        {
            "name_short": "Inductive coverage/diversity effects",
            "name_full": "Coverage and diversity effects in category-based induction (Osherson et al.; Rips)",
            "brief_description": "Empirical findings that inductive strength depends on how well premise categories cover a superordinate (coverage) and on the diversity of premises: broader/diverse premises yield stronger generalization.",
            "citation_title": "Category-based induction.",
            "mention_or_use": "mention",
            "theory_or_model_name": "Coverage/diversity effects in induction",
            "theory_or_model_description": "People generalize properties more strongly when premises are representative/cover the superordinate category well and when multiple premises are diverse, implying reliance on category-level representativeness beyond simple pairwise similarity.",
            "representation_format_type": "empirical induction phenomenon (requires category-level representation)",
            "key_properties": "Dependence on representativeness/coverage and premise diversity; sensitivity to content and feature relevance.",
            "empirical_support": "Osherson et al. (1990), Rips (1975), and subsequent studies show coverage and diversity effects in CBI tasks.",
            "empirical_challenges": "Exemplar models find it hard to compute coverage from stored exemplars (would require comparing large exemplar sets); exemplar-similarity alone does not predict coverage/diversity patterns easily.",
            "applied_domains_or_tasks": "Category-based induction problems, multi-premise generalization.",
            "comparison_to_other_models": "Structured/prototype/Bayesian models naturally encode coverage and diversity; exemplar-only approaches struggle without added mechanisms.",
            "functional_mechanisms": "Models compute representativeness/coverage via similarity matrices or structured priors (in Bayesian approaches) rather than pure exemplar matching.",
            "limitations_or_open_questions": "How exemplar storage and retrieval mechanisms could efficiently instantiate coverage computations in real-world cognition.",
            "uuid": "e5467.11",
            "source_info": {
                "paper_title": "Is there an exemplar theory of concepts?",
                "publication_date_yy_mm": "2016-06"
            }
        },
        {
            "name_short": "Property-type effects (Heit & Rubinstein)",
            "name_full": "Similarity and property effects in inductive reasoning",
            "brief_description": "Empirical finding that the nature of the property (e.g., biological vs behavioral) changes inductive strength, reflecting domain knowledge rather than only similarity.",
            "citation_title": "Similarity and property effects in inductive reasoning.",
            "mention_or_use": "mention",
            "theory_or_model_name": "Property-type/content effects in induction",
            "theory_or_model_description": "The tendency to generalize depends not only on category similarity but also on the type of property being transferred and background knowledge about relevance of categories to that property.",
            "representation_format_type": "empirical knowledge-sensitive induction phenomenon",
            "key_properties": "Content sensitivity; differential generalization for biological vs behavioral properties; reliance on domain knowledge and category membership.",
            "empirical_support": "Heit & Rubinstein (1994) documented differing inductive strengths depending on property type, supporting theory-based influences on induction.",
            "empirical_challenges": "Pure similarity-based exemplar models cannot account for content-dependent differences because similarity stays constant while induction strength varies.",
            "applied_domains_or_tasks": "Inductive reasoning, developmental generalization, distinguishing when to rely on similarity vs category membership.",
            "comparison_to_other_models": "Supports theory-theory / causal / prototype-based representations over exemplar-only accounts for many inductions.",
            "functional_mechanisms": "Use of domain knowledge (e.g., biological taxonomies) to weigh or select which features/properties are relevant for induction.",
            "limitations_or_open_questions": "How to computationally integrate property-type sensitivity with exemplar or distributed representations in a unified cognitive architecture.",
            "uuid": "e5467.12",
            "source_info": {
                "paper_title": "Is there an exemplar theory of concepts?",
                "publication_date_yy_mm": "2016-06"
            }
        },
        {
            "name_short": "Rehder causal-generalization findings",
            "name_full": "Causal-based property generalization (Rehder)",
            "brief_description": "Empirical results showing that known causal links among features can drive induction and reduce the influence of exemplar similarity in generalization.",
            "citation_title": "Causal-based property generalization.",
            "mention_or_use": "mention",
            "theory_or_model_name": "Causal-based property generalization",
            "theory_or_model_description": "When causal relations among features are known, people base generalization on causal structure rather than on surface similarity between exemplars, indicating use of structured causal knowledge in concept use.",
            "representation_format_type": "causal/theory-like representation influencing induction",
            "key_properties": "Causal prioritization over similarity; feature relevance determined by causal links; domain knowledge modulates generalization.",
            "empirical_support": "Rehder (2009) and related work show similarity has little effect on induction when causal links explain the generalization, emphasizing structured knowledge use.",
            "empirical_challenges": "Exemplar and similarity-based models struggle to accommodate causal-structure-driven patterns without additional mechanisms.",
            "applied_domains_or_tasks": "Property generalization, causal reasoning within categorization, laboratory induction tasks with known causal structures.",
            "comparison_to_other_models": "Aligns with theory-theory and structured Bayesian approaches; challenges pure exemplar/prototype similarity-only models.",
            "functional_mechanisms": "Inference proceeds via causal chains and assessment of causal relevance for transferring properties between categories.",
            "limitations_or_open_questions": "How causal structure is learned and represented alongside exemplar memories; computational integration across levels.",
            "uuid": "e5467.13",
            "source_info": {
                "paper_title": "Is there an exemplar theory of concepts?",
                "publication_date_yy_mm": "2016-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Cognitive representations of semantic categories.",
            "rating": 2
        },
        {
            "paper_title": "Basic objects in natural categories.",
            "rating": 2
        },
        {
            "paper_title": "Context theory of classification learning.",
            "rating": 2
        },
        {
            "paper_title": "Similarity, frequency, and category representations.",
            "rating": 2
        },
        {
            "paper_title": "SUSTAIN: A network model of category learning.",
            "rating": 2
        },
        {
            "paper_title": "Structured statistical models of inductive reasoning.",
            "rating": 2
        },
        {
            "paper_title": "Decentralized control of categorization: The role of prior processing episodes.",
            "rating": 2
        },
        {
            "paper_title": "Retrieval time from semantic memory.",
            "rating": 2
        },
        {
            "paper_title": "Structure and deterioration of semantic memory: A neuropsychological and computational investigation.",
            "rating": 2
        },
        {
            "paper_title": "Category-based induction.",
            "rating": 2
        },
        {
            "paper_title": "Similarity and property effects in inductive reasoning.",
            "rating": 1
        },
        {
            "paper_title": "Causal-based property generalization.",
            "rating": 1
        },
        {
            "paper_title": "Learning categories at different hierarchical levels: A comparison of category learning models.",
            "rating": 1
        },
        {
            "paper_title": "Toward a universal law of generalization for psychological science.",
            "rating": 1
        }
    ],
    "cost": 0.02083725,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Is there an exemplar theory of concepts?</h1>
<p>Gregory L. Murphy ${ }^{1}$</p>
<p>Published online: 9 June 2016
(C) Psychonomic Society, Inc. 2015</p>
<h4>Abstract</h4>
<p>It is common to describe two main theories of concepts: prototype theories, which rely on some form of summary description of a category, and exemplar theories, which claim that concepts are represented as remembered category instances. This article reviews a number of important phenomena in the psychology of concepts, arguing that they have no proposed exemplar explanation. In some of these cases, it is difficult to see how an exemplar theory would be adequate. The article concludes that exemplars are certainly important in some categorization judgments and in category-learning experiments, but that there is no exemplar theory of human concepts in a broad sense.</p>
<p>Keywords Concepts $\cdot$ Categories $\cdot$ Semantic memory $\cdot$ Induction $\cdot$ Categorization</p>
<p>The two main theories of concepts are prototype and exemplar models-all the textbooks say so, including my own chapter in an introductory textbook (Murphy, 2013) and standard cognitive psychology texts such as Goldstein (2014). Prototype models are summary descriptions of the category as a whole, based on properties that are often found in the category. They include feature-based models (e.g., Rogers et al., 2004; Rosch \&amp; Mervis, 1975; Smith, Rips, \&amp; Shoben, 1974) and network models, in which category nodes are linked to the category's features as well as to other categories (e.g., Collins \&amp; Quillian, 1969). Categories formed by rules are also summary descriptions, because the rule describes the category as a whole.</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>Exemplar models assume that this summary description is not needed, instead representing categories by memories of instances (exemplars) that are labeled with their category name (Medin \&amp; Schaffer, 1978; Smith \&amp; Medin, 1981). Research has suggested that "instances" are not category members but are encounters with category members. That is, if you encounter a mouse three times (identifying it as a mouse), that is effectively three exemplars, in terms of its influence on later classification (Barsalou, Huttenlocher, \&amp; Lamberts, 1998; Nosofsky, 1988). ${ }^{1}$ In discussing this distinction, I will focus on the issue of summary representations versus memory for instances and will refer to such theories as prototype and exemplar models, ignoring other important differences between the theories.</p>
<p>Prototype theory arose through the work of Eleanor Rosch on natural categories (e.g., Rosch, 1975; Rosch \&amp; Mervis, 1975). As a result, it has focused on familiar natural categories and their structure. Exemplar theory arose from the learning tradition; Douglas Medin was a researcher on discrimination learning in animals when he applied the theory to human learning. Theoretically, exemplar models seem to make the most sense within category-learning experiments, in which a small number of exemplars are presented over and over again in a classification task. Under those circumstances, it seems reasonable that individual exemplars would be remembered, along with their categorizations. Furthermore, evidence for such processes also seems strongest when the categories are smaller and poorly structured, when prototypes cannot suffice</p>
<p><sup id="fnref:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<p>for learning the categories (Blair \&amp; Homa, 2001; Smith \&amp; Minda, 1998). Indeed, many of the earliest demonstrations of the better performance of exemplar theory were in studies in which the categories were extremely difficult to learn (e.g., Medin \&amp; Schaffer, 1978; Medin \&amp; Schwanenflugel, 1981; see Murphy, 2005, for a discussion).</p>
<p>Another source of exemplar theory came about through a very different rationale and experimental paradigm. The late Lee Brooks (1987) argued that particularly salient and familiar exemplars could influence categorization above and beyond any category description. For example, if you see a dog that looks quite similar to your own dog, you would likely be much faster to identify it as a dog and, Brooks suggested, attribute characteristics to it that your own dog has. However, Brooks did not say that you were likely to remember every dog you encountered or that every dog in memory would influence your classification. Indeed, his experiments with novel categories generally involved intense study of a few exemplars, which then were shown to influence the categorization of novel items even when this influence was harmful (Allen \&amp; Brooks, 1991; Thibaut \&amp; Gelaes, 2006). In those experiments, people learned both a category rule (not quite a prototype, but an experimental analogue) and specific exemplars. Memory of similar exemplars could overcome use of the rule. Although Brooks did not specify a detailed model, it seems likely that he had in mind that people used both specific, very familiar exemplars and the rule, to varying degrees. Furthermore, he often emphasized that the similarity between known exemplars and new items should be great in order to observe exemplar effects.</p>
<p>The differences between Brooks's approach and exemplar models arising from classification-learning experiments led me (Murphy, 2002, chap. 4) to distinguish the two, calling the Medin-derived models exemplar models and the Brookslike demonstrations exemplar effects. I suggested that Brooks's exemplar effects were essentially cases of implicit memory, in which prior experience influenced later judgments. Like implicit memory effects, they are found even after a gap of some weeks, suggesting that explicit recall of exemplars might not be occurring (Brooks, Norman, \&amp; Allen, 1991). Furthermore, such effects are quite similar to reminding effects found in problem solving (e.g., Ross, 1984). Given all this, the evidence for exemplar effects seems quite strong and very consistent with other research in cognitive psychology.</p>
<p>The evidence for exemplar models, however, did not seem as strong to me when I reviewed the field over a decade ago (Murphy, 2002, chap. 13). Although it seems very likely that such models are good descriptions of many (but not all) category-learning experiments, there were many questions about how the models could be applied to real-world category learning and concept use. Furthermore, the proponents of this theory did not seem to be attempting to broaden its application
to other topics in the psychology of concepts outside of category-learning experiments. This absence, which continues to this day, makes me propose that in fact there is no exemplar theory of concepts, when we understand concepts to be the mental representations of things in the world that are involved in planning, reasoning, communication, learning, and all the things that concepts are supposed to be involved in. There is an exemplar theory of category-learning experiments of the sort that psychologists often do, but such experiments are a tool to explore theories-they are not the actual domain of behavior we are trying to explain when we develop theories of concepts.</p>
<p>The remainder of this article outlines this argument. I discuss some basic phenomena in the psychology of concepts and ask whether each has an exemplar explanation and whether that explanation is plausible. In many of these cases, the problem is not that the theory is not correct, but that no account has been put forward at all. In each case, some kind of prototype model has been proposed (or can be immediately devised) to address that phenomenon. Unfortunately, space does not allow me to develop the prototype explanations here.</p>
<h2>Phenomena of concepts</h2>
<h2>Hierarchical structure</h2>
<p>Since at least Linnaeus, it has been known that many categories are structured into hierarchies, in which more-specific categories are nested underneath general ones, often forming a tree structure. Even outside the Linnaean realm of biology we have nested categories, such as side-door refrigerator, refrigerator, kitchen appliance, appliance, machine, and artifact. Rosch, Mervis, Gray, Johnson, and Boyes-Braem (1976) documented this in a set of familiar concepts and also introduced the notion that a mid-level category was generally basic-that is, the easiest and preferred way to categorize objects. When people walk into a kitchen, they see a refrigerator rather than a machine or a side-door refrigerator, unless a specific task induces a different categorization. Furthermore, children learn words at this level sooner than at more-specific and more-general levels (Anglin, 1977). Within prototype theory, there is a generally accepted explanation of this advantage-namely that basiclevel categories are informative but also distinct from other categories (Murphy \&amp; Brownell, 1985; Rosch et al., 1976).</p>
<p>In prototype theory, hierarchical structure can be represented in terms of links between concepts, or else by inference from typical features (see Murphy, Hampton, \&amp; Milovanovic, 2012, for a recent discussion). In the context of exemplar theory, however, it is not clear how to represent hierarchical structure itself. One of the properties of such hierarchies is that people are able to affirm statements such as "All refrigerators are appliances" or "A squirrel is an animal," and many</p>
<p>experiments have tested sentence verification of this sort since Collins and Quillian (1969; Murphy et al., 2012). If knowledge of squirrels is in terms of remembered exemplars, how is the hierarchy to be represented? The simplest way would be to encode each exemplar with all its categories. Of course, this would be rather inefficient, since every squirrel I see would have to be remembered as a squirrel, rodent, mammal, vertebrate, and animal. And I see a lot of squirrels. Also, it is puzzling that each exemplar should be remembered this way, because when I see squirrels, it very seldom crosses my mind that they are mammals or animals, much less vertebrates. Since I am not in a learning experiment in which I have to respond with what categories each squirrel is in, it seems unlikely that I would encode these categories with my memories of these squirrel encounters.</p>
<p>Therefore, it seems more likely that in my memory of squirrel exemplars, many are encoded as "squirrel," a few as "mammal," a few more as "animal," and probably none as "vertebrate." How from this set of exemplars do we derive a hierarchy? We cannot follow the standard practice of exemplar models in experiments, of checking each exemplar to see which categories it is in: All the "squirrels" are not also encoded as "mammal," and so forth. So, on the basis of exemplars, we would have to answer false to the question of whether all squirrels are mammals. Of course, some squirrels are in fact encoded both as mammals and squirrels, so perhaps we could accept this partial overlap as evidence for a hierarchical relation. The problem is that such partial overlap also occurs for categories that do not have a hierarchical relationship, like pets or New York City residents, and people do not claim that all squirrels are pets or New York residents. So, it is very difficult to see how the conceptual hierarchy would be represented in terms of exemplars and how people draw inferences such as that squirrels must breathe because they are animals. This seems like a huge issue for the exemplar theory.</p>
<p>The only study I know taking the exemplar approach that has tested hierarchically organized categories is Palmeri (1999). However, he avoided the problem I just noted by making two separate models: One learned the categories at one level and another at the higher level, analogous to one model learning to classify birds versus mammals, and the other learning to classify dogs, horses, moose, and so on. So, in fact, neither model represented a hierarchy or the relation between categories at the different levels. Palmeri's goal was to compare different learning models' performance on the two levels rather than to construct a model of category hierarchies; my point is that his solution suggests the difficulties of trying to build an exemplar model of hierarchical concepts.</p>
<p>Another challenge for exemplar theories is explaining the basic-level advantage. People are faster at identifying something as a squirrel than as a mammal or as a chair than as a diningroom chair (Murphy \&amp; Brownell, 1985; Rosch et al., 1976; Smith, Balzano, \&amp; Walker, 1978). As was mentioned earlier, this is typically explained by the fact that chair is an informative category that will closely match its members, whereas furniture is a vague category that does not match its members as closely. (I will not address subordinate classification here.)</p>
<p>When classification is by virtue of exemplars, it is not clear that the explanation of the slowness of superordinate classification applies. Categorization is not performed by using the vague representation of mammals but instead by using exemplars encoded as mammals. Assuming that some squirrels are encoded as mammals (or else one would not have represented the hierarchy), a new squirrel is very likely to match those squirrels just as much as it matches squirrels encoded as squirrels. Remembered exemplars are concrete, and when they represent abstract categories, they do so concretely. Thus, the slowness of superordinate classification that prototype theory ascribes to the abstract properties and vagueness of general categories simply does not apply for exemplar theory: There are no abstract properties, only remembered squirrels. The new squirrel matches my remembered squirrel exemplars encoded as mammals just as much as those encoded as squirrels, so the basic-level advantage should not occur.</p>
<p>There are ways to try to address this problem. For example, one could point out that squirrels are not very similar to other mammal exemplars (e.g., seals, humans, or cows), which slows down their classification as mammals. However, this is inconsistent with the theme of exemplar models that close similarity is used in classification, dating from Medin and Schaffer's (1978) multiplicative similarity rule, and continued in Shepard's (1987) widely adopted exponential similarity function. That is, moderate similarity to multiple exemplars generally counts for less in classification than very close similarity to a single exemplar. Exemplar reminding effects also seem to work only with high levels of similarity (Thibaut \&amp; Gelaes, 2006). As Smith and Minda (1998) pointed out, exemplar models of experimental results can have such a fast similarity drop-off that only one learned exemplar is effectively influencing the categorization of a given item. Thus, it seems awkward that very close similarity of exemplars is required in order to explain categorization in learning experiments, but the dissimilarity of squirrels to cows is necessary to explain why squirrels are not easily classified as mammals. Cows should not affect how a squirrel is classified into any category, according to exemplar theory.</p>
<p>My argument, then, is in the form of a puzzle: It is simply unclear to me how exemplar models propose to represent hierarchical structure and the basic-level advantage in learning and category use. I have not proven that it cannot do so; it is possible that an exemplar theory can be developed to account for these phenomena. But what puzzles me is, where is that theory? The hierarchical nature of categories has been known roughly forever, and the basic level since 1976. If there is an exemplar theory of concepts, what is its explanation of these very familiar phenomena that are in all the textbooks?</p>
<h2>Knowledge effects</h2>
<p>Concepts are part of our knowledge of the world. They are the way that we gain access to information that we can then apply to the objects and events around us. Prototype theory directly represents that knowledge, by its very nature as a description of classes of objects, as well as by the relations linking different conceptual entities. Exemplars represent such knowledge more implicitly, by embodying the experiences of individual instances, from which we can infer generalizations.</p>
<p>Concepts not only contain knowledge of the world, they are also formed and processed in the light of our other knowledge. For example, we learn concepts that are consistent with our knowledge faster than we do arbitrary concepts (Murphy \&amp; Allopenna, 1994). When constructing concepts without feedback, we discover the category structure if the concept's properties go together in a way that fits our expectations (Spalding \&amp; Murphy, 1996). We learn many more of a concept's properties when they are related to a consistent theme than if they are not (Hoffman, Harris, \&amp; Murphy, 2008).</p>
<p>One of the most exciting topics in higher-level cognition has been the discovery of people's knowledge of causal structures and the reasoning that they engage in with such structures (e.g., Sloman, 2005). Researchers have documented that the properties of concepts are causally related and then showed that such relations influenced classification, both with artificially constructed (e.g., Rehder \&amp; Hastie, 2001) and natural (Ahn, 1998; Kim \&amp; Ahn, 2002) concepts. Investigation into the internal causal structure of concepts continues today (see the next section).</p>
<p>Finally, within both developmental and adult studies of concepts, people's beliefs about domains have been shown to influence their judgments about categories. The most prominent such proposal is Medin and Ortony's (1989) psychological essentialism, which claims that people think of some categories as having an invisible essence that determines category membership. This remarkably productive idea has led to advances as far-flung as early conceptual development (Gelman, 2003) and the psychology of prejudice and social groups (Hirschfeld, 1996; Rhodes, Leslie, \&amp; Tworek, 2012).</p>
<p>The knowledge referred to by the writers in these fields is almost always generic knowledge-that is, knowledge of an entire category or set of objects possessing a property. For example, I believe that wings enable flying, and animals that fly can live in trees. Such knowledge could influence my classification of something as a bird (Rehder, 2009). However, this is not knowledge about a particular bird or about the object I am evaluating-it is knowledge about the billions of animals with wings. Similarly, people's belief that something hatched from an egg that was laid by a robin must have the robin's underlying essence is not a belief about a specific exemplar but about robins (or birds or species) in general.</p>
<p>Prototypes represent such general knowledge very easily, because they are descriptions of whole classes of entities, and therefore can contain generalizations about those entities. If you learn a new fact about birds, you have a summary representation of that category to link it to. Other knowledge can be inferred by hierarchical inference (e.g., robins have the properties of birds) or via causal inferences involving generic properties (e.g., wings usually enable flying). Although much work is still to be done to specify the structure of all that knowledge and how such inferences work, representing concepts as general descriptions causes no problems in constructing such explanations.</p>
<p>Exemplar theory does not store generalizations, by definition, but instead yields them through some kind of processing. For example, it does not say that feathers are an important property of birds, but that fact is implicitly represented by most bird exemplars having feathers represented with them, and few other animal concepts having feathers. As a result, a new exemplar having feathers is likely to be classified as a bird, because it will be much more similar to things in memory labeled as bird than to other things.</p>
<p>There are two main problems with this approach to knowledge representation, however. The first is how to represent knowledge that is not tied to an experience with exemplars. I firmly believe that mammals have four-chambered hearts, but this knowledge is not tied to any exemplar of a whale, bat, cow, or human I have ever seen. I might also believe that mammals evolved from dinosaur ancestors, but that is obviously also something not associated with individual exemplars.</p>
<p>Wings enable flying in my view of the world, but that is not only because of the pairing of wings and flying things in many exemplars. First of all, I may well not notice either the wings or flying of some things that have both properties. When I see pictures of birds in books, they are often perched; when I swat at flying insects, I often do not perceive their wings. Furthermore, I have some (very sketchy) beliefs about how wings enable flying. I do not think that if I attached wings to a rock or a pig that it would fly. I have some idea of why ostriches and penguins do not fly, in spite of having wings. In order to make a prediction about a new animal with wings, I must reason through my beliefs about wings, how they support a body in the air, the relative sizes of the wings and body, and so on. How is such knowledge represented in exemplar representations?</p>
<p>This illustrates the second issue with exemplar theories, that it is not clear what reasoning processes would allow people to make specific predictions or generalizations about concepts using exemplar knowledge. Most exemplar models focus on classification and do not provide standard mechanisms for feature inference. Furthermore, given that much of the knowledge that we apply is based on feature relations (such as the causal research cited above), it is not clear how exemplar</p>
<p>models would represent and use that knowledge. Is "wings enable flying" simply a statistical relationship between exemplars with wings and those that fly? That is the most obvious exemplar representation, but it does not seem likely to be adequate. Feathers and beaks are very highly correlated but have no direct causal connection. How would biases such as essentialism apply to exemplar representations to yield the results in the literature? One might argue that the use of knowledge and causal reasoning are simply separate processes from the learning of categories, but research suggests that categorization and generalization are closely tied to the causal relations of categories' features (Kim \&amp; Ahn, 2002; Rehder, 2009). Initial category learning is also strongly influenced by prior knowledge (Hoffman et al., 2008; Murphy \&amp; Allopenna, 1994).</p>
<p>I cannot argue that exemplar representations are in some way incompatible with all of these knowledge effects, but I simply do not have a clue how exemplar theories would attempt to account for them. And, as in the first section, I am not aware of a detailed attempt to account for them within exemplar theory. Instead, people who study these issues almost never talk about exemplars, and researchers who work on exemplar theory almost never talk about knowledge or how their concept representations could explain knowledge effects. So, I cannot say that knowledge effects are inconsistent with exemplar theories, but I can ask again, "Where is the exemplar theory of all these phenomena?"</p>
<h2>Induction</h2>
<p>It is now often repeated (at least, by me) that the purpose of having concepts is to make inductions. We do not need concepts in order to recall facts about individual entities we have encountered; we need them in order to understand and make predictions about new objects and situations. This function was important enough to appear in the first paragraph of Smith and Medin's (1981) classic book. Since then, research on category-based induction (CBI) has exploded (Feeney \&amp; Heit, 2007).</p>
<p>Many of the problems of exemplar theory for explaining induction are inherent in the problems discussed above. For example, I have not experienced seeds in many apples I have encountered (I avoid them), so why am I so certain that a new apple I have bought will have seeds inside it? Much research in CBI involves the transfer of properties from one or more premise categories to a conclusion category (Osherson, Smith, Wilkie, Lpez, \&amp; Shafir, 1990). For example, if grizzly bears and brown bears love onions, what is the probability that all bears love onions? It is hard to know how to represent such a question in terms of exemplars, because the premises are usually universally quantified, but one's exemplar representations of grizzly bears does not include the information that each one loves onions, nor does it seem likely that this information could be easily attached to each exemplar. Because the
properties used are usually hypothetical or even imaginary, people should not (and presumably do not) store the properties with actual exemplars. (I have discussed the bears loving onions example for many years, but I do not actually believe that grizzly bears love onions.)</p>
<p>Research on CBI has shown that two variables are important in such problems. First, the similarity between the premise and conclusion categories influences the degree to which the properties from one will be attributed to the other (Rips, 1975). It is not very difficult to think of an exemplar process that would explain this. In hearing the question, exemplars representing the premise categories could be activated, and their similarity to exemplars of the conclusion category could be computed. Of course, this could run into some of the problems mentioned above, such as the very few exemplars I have in memory for grizzly bears or larks. Also, calculating the similarity of two categories is not trivial if there are many exemplars in each. So, I think it would be possible to propose an exemplar account of the typicality effect, though I do not know whether it would be psychologically plausible.</p>
<p>The second variable is the coverage of the premise categories to their superordinate category (I am simplifying a bit here). That is, people draw stronger inferences when the premise categories are more representative of their category as a whole. People will generalize a property from a robin to a penguin more than they will from an owl, because robins are more similar to birds in general (Dunsmoor \&amp; Murphy, 2014; Rips, 1975). For multiple premises, the better the categories cover the entire superordinate category, the stronger the inference will be (Osherson et al., 1990). As a result, inference is stronger when the premise categories are diverse, because they would as a whole be more similar to their superordinate category.</p>
<p>I am not sure how an exemplar model would explain this effect. Indeed, the effect seems incompatible with the general goal of exemplar models to explain category phenomena by the similarity of test items to learned exemplars. Why should a robin's representativeness of the bird category, which was not mentioned in the question, affect its induction to penguins? Why is the similarity of a robin to a penguin not sufficient?</p>
<p>Assuming that coverage is important, how would an exemplar model calculate it? Osherson et al. (1990) calculated coverage by using similarity judgments between pairs of categories used in their stimuli, but they did this at the level of subcategories (e.g., comparing robin to swallow, lark, etc.). A true exemplar model would have to compare the exemplars in these categories-that is, all of the robins in memory to all of the swallows, all of the larks, all of the chickens, and so on. For large categories and multiple premises, that seems computationally unrealistic.</p>
<p>Another problem is related to the previous section's discus-sion-namely, that the content of the features and categories is important. In an important demonstration, Heit and Rubinstein (1994) found that the nature of the property changed the</p>
<p>inductive strength. For example, people generalized a biological property from whales to rabbits more than they did a behavioral property. This is easily explained by people's beliefs about the biological relationship between whales and rabbits (both being mammals), but it cannot be explained by any account that relies on exemplar similarity, which would be equal in the two inductions. Similarly, Gelman and Markman (1986) found that children sensibly generalize some properties on the basis of category membership (e.g., behavioral tendencies), and others on the basis of appearance (e.g., weight). Rehder (2009) discussed evidence that induction is based on causal relations between features (when they are known). In addition to impressive evidence for such effects, he found that the similarity between exemplars in induction problems has little effect when causal links can explain the induction. This is contrary to the usual mechanism of exemplar models, which is based on similarity between items. ${ }^{2}$ In all these cases, some kind of generic information is accessed during induction, and (as was discussed in the previous section) such knowledge is a summary representation.</p>
<p>Perhaps as a result of these problems, no exemplar model of CBI seems to exist. In a review of the developmental literature on induction, Hayes (2007) outlined the main theories of CBI. This is useful here as a checklist to make sure that I have not missed an exemplar account. Although some of the models are quite task-specific, to the degree that they make claims about category representation, they refer to features associated with a category, to knowledge-related features, and to other summary representations. I do not see any exemplar theories in his list. Recent Bayesian models of category knowledge and inference (e.g., Kemp \&amp; Tenenbaum, 2009) have also assumed that features are associated with categories and do not seem to use exemplars as a way of representing category knowledge and implementing induction.</p>
<p>Unlike with some of the other examples I have considered here, I think it would be possible to develop an exemplar account that could yield some of the observed phenomena of CBI (though it would have to address some of the earlier representational issues). My guess is that this account would not be as convincing as the current proposals, but the more concrete problem is that no such account seems to have been put forward. That is, where is the exemplar theory of category-based induction? When knowledge effects, which are rife in this domain, are introduced, I do not see how exemplar theories could account for the results, but right now there is no extant theory of those effects for us to evaluate.</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup>## The rest of the concepts literature</p>
<p>Much of the research on concepts has been rather different from the standard category-learning study that exemplar theory has focused on. Perhaps the most productive example is research on conceptual development. Throughout the 1980s and 1990s, research on adult concepts focused on the prototype-versus-exemplar debate. However, it is remarkable how little that debate impinged on research in conceptual development during the same time period. There, the focus was on topics such as how children induce categories on the basis of very little evidence, the use of categories in induction, and word learning. None of this work was phrased in terms of exemplar knowledge. It might be possible to recast some of it in exemplar terms, though some of it is explicitly about biases and knowledge that apply to categories as a whole (e.g., essentialism).</p>
<p>Conceptual development is a very large and complex area, and I cannot make a broad statement about whether its results would or would not be explicable in terms of exemplar representations. However, it simply does not seem that exemplar theory has made significant inroads into this large field, which presumably is about the same content matter as adult research on concepts.</p>
<p>Concepts are also intimately linked to the semantic representations of words (Murphy, 2002, chap. 11). However, within the psycholinguistic literature, there has also been little influence of exemplar theory. Has an exemplar account proposed how we interpret words in context or how we choose which word to utter? The accounts that I am familiar with are all description-based-that is, words are associated with semantic properties that describe the things referred to by the word. Theories of aphasia and loss of semantic knowledge in dementia also assume category-level descriptions (Rogers et al., 2004).</p>
<h2>Conclusion</h2>
<p>My conclusion to this very brief review is that, surprisingly, there is not really an exemplar theory of concepts. There is an exemplar theory of category learning, within the usual paradigm of repeated exemplars. That theory seems to have strong support in some experimental circumstances. Furthermore, we also have good evidence that specific salient exemplars can influence one's classification. However, no well-developed exemplar theory of concepts as a whole seems to have addressed the broader phenomena of natural concepts.</p>
<p>There are two obvious explanations for this gap: One is that it would be difficult to devise such a theory, and the other is that the proponents of exemplar models have simply not turned their attention to issues beyond category learningand researchers on those other topics have for some reason</p>
<p>neglected exemplar models. The first seems more plausible to me. Theories of general knowledge and hierarchical representation are not trivial issues that a theory of concepts might neglect. If it were easy to construct exemplar accounts that straightforwardly address those phenomena, I think they would have been constructed. Concept and word learning in children are central topics in cognitive science; it is hard to believe that exemplar theories of these things are simply waiting to be brought into existence but that no one has thought to do so for the past 25 years.</p>
<p>My inference is only an inference, and it might be wrong. But if it is wrong, it seems reasonable to require exemplar theorists to expand their theories to give serious accounts of the well-known phenomena in the field. If strong claims about how categories are represented are to be taken seriously, then the full breadth of findings in the field needs to be addressed. So, if an exemplar theory of concepts is to be made, it is time for one to be put forward.</p>
<h2>Recommendations</h2>
<p>Textbooks and review articles have almost universally discussed two main approaches to concepts: exemplar and prototype theories. In reality, each approach is a large class of possible models, with considerable diversity. My argument that there is no exemplar theory should not be taken to imply that any single prototype account explains everything. Rather, my claim is that most of the accounts put forward to explain the conceptual behaviors reviewed here are, at least implicitly, prototype accounts; they rely on category-level descriptions and (often structured) associations between properties and categories.</p>
<p>Concepts are important because they represent vast amounts of complex knowledge and allow us to understand and draw inferences about new objects and classes of things. They are also fascinating because of how quickly children acquire a vast fund of concepts, on the basis of less evidence than one might expect. The standard category-learning task is not in and of itself a central topic in the psychology of concepts: It is a tool to understand how concepts are acquired and represented. And although it is a very important tool, I think we have to recognize that a theory that explains this task but that has not been extended to the central cases of real-world concept use is not a true theory of concepts.</p>
<p>So, if I were writing an introductory textbook chapter on concepts today, how would I frame this debate? Following Smith and Medin's (1981) example, I would introduce Rosch's prototype notion as the alternative to the classical view of concepts. Then I would point out that in addition to such general representations, people are influenced by specific exemplars, describing some of the classic Brooks research. I would describe the category-learning task and point out that in category-learning experiments, people can learn individual
exemplars and classify new items in terms of similarity to them. However, I do not think I would describe this as "Some believe concepts are prototypes and some believe that they are exemplars," because that debate could not be carried over into the rest of the chapter, that talked about induction, conceptual development, word meaning, and so on. It makes little sense to claim that there are two theories if only one of them has anything to say about two-thirds of the material in the chapter.</p>
<p>Rather than phrasing the issue as a debate between two incompatible theories, it might be more productive to develop psychologically plausible accounts of how the two kinds of information work together to produce our rich store of conceptual knowledge, allowing each kind of knowledge to explain the tasks that are most suited for it. Early connectionist models (e.g., Knapp \&amp; Anderson, 1984) and more recent clustering models (Love, Medin, \&amp; Gureckis, 2004) have emphasized that exemplar and summary information can blur into one another. A distinct exemplar can be remembered as a separate item. As more exemplars similar to it are encoded, however, the details of that exemplar may become lost (through interference) or less relevant, as they are combined with new information. Such models can represent both "exemplar-like" and "prototype-like" effects, while not restricting themselves to one kind of representation. Perhaps such approaches can serve as the basis for a more encompassing theory of concepts.</p>
<p>Author Note The writing of this article was supported in part by NSF Grant No. BCS 1128769. I thank Brian Ross and the reviewers for very helpful comments, although the opinions expressed are my own.</p>
<h2>References</h2>
<p>Ahn, W.-K. (1998). Why are different features central for natural kinds and artifacts? The role of causal status in determining feature centrality. Cognition, 69, 135-178.
Allen, S. W., \&amp; Brooks, L. R. (1991). Specializing the operation of an explicit rule. Journal of Experimental Psychology: General, 120, 319. doi:10.1037/0096-3445.120.1.3</p>
<p>Anglin, J. M. (1977). Word, object and conceptual development. New York, NY: W. W. Norton.
Barsalou, L. W., Huttenlocher, J., \&amp; Lamberts, K. (1998). Basing categorization on individuals and events. Cognitive Psychology, 36, 203-272.
Blair, M., \&amp; Homa, D. (2001). Expanding the search for a linear separability constraint on category learning. Memory \&amp; Cognition, 29, 1153-1164. doi:10.3758/BF03206385
Brooks, L. R. (1987). Decentralized control of categorization: The role of prior processing episodes. In U. Neisser (Ed.), Concepts and conceptual development: Ecological and intellectual factors in categorization (pp. 141-174). Cambridge, UK: Cambridge University Press.
Brooks, L. R., Norman, G. R., \&amp; Allen, S. W. (1991). Role of specific similarity in a medical diagnosis task. Journal of Experimental Psychology: General, 120, 278-287. doi:10.1037/0096-3445.120. 2.278</p>
<p>Collins, A. M., \&amp; Quillian, M. R. (1969). Retrieval time from semantic memory. Journal of Verbal Learning and Verbal Behavior, 8, 241-248.
Dunsmoor, J. E., \&amp; Murphy, G. L. (2014). Stimulus typicality determines how broadly fear is generalized. Psychological Science, 25, 1816-1821.
Feeney, A., \&amp; Heit, E. (2007). Inductive reasoning: Experimental, developmental, and computational approaches. Cambridge, UK: Cambridge University Press.
Gelman, S. A. (2003). The essential child: Origins of essentialism in everyday thought. Oxford, UK: Oxford University Press.
Gelman, S. A., \&amp; Markman, E. M. (1986). Categories and induction in young children. Cognition, 23, 183-209.
Goldstein, E. B. (2014). Cognitive psychology: Connecting mind, research, and everyday experience (4th ed.). Stamford, CT: Cengage.
Hayes, B. K. (2007). The development of inductive reasoning. In A. Feeney \&amp; E. Heit (Eds.), Inductive reasoning: Experimental, developmental, and computational approaches (pp. 25-54). Cambridge, UK: Cambridge University Press.
Heit, E., \&amp; Rubinstein, J. (1994). Similarity and property effects in inductive reasoning. Journal of Experimental Psychology: Learning, Memory, and Cognition, 20, 411-422. doi:10.1037/0278-7393.20.2.411
Hirschfeld, L. A. (1996). Race in the making: Cognition, culture, and the child's construction of human kinds. Cambridge, MA: MIT Press.
Hoffman, A. B., Harris, H. D., \&amp; Murphy, G. L. (2008). Prior knowledge enhances the category dimensionality effect. Memory \&amp; Cognition, 36, 256-270. doi:10.3758/MC.36.2.256
Kemp, C., \&amp; Tenenbaum, J. B. (2009). Structured statistical models of inductive reasoning. Psychological Review, 116, 20-58.
Kim, N. S., \&amp; Ahn, W.-K. (2002). Clinical psychologists' theory-based representations of mental disorders predict their diagnostic reasoning and memory. Journal of Experimental Psychology: General, 131, 451-476. doi:10.1037/0096-3445.131.4.451
Knapp, A. G., \&amp; Anderson, J. A. (1984). Theory of categorization based on distributed memory storage. Journal of Experimental Psychology: Learning, Memory, and Cognition, 10, 616-637. doi: 10.1037/0278-7393.10.4.616</p>
<p>Love, B. C., Medin, D. L., \&amp; Gureckis, T. M. (2004). SUSTAIN: A network model of category learning. Psychological Review, 111, 309-332. doi:10.1037/0033-295X.111.2.309
Medin, D. L., \&amp; Ortony, A. (1989). Psychological essentialism. In S. Vosniadou \&amp; A. Ortony (Eds.), Similarity and analogical reasoning (pp. 179-195). Cambridge, UK: Cambridge University Press.
Medin, D. L., \&amp; Schaffer, M. M. (1978). Context theory of classification learning. Psychological Review, 85, 207-238. doi:10.1037/0033295X.85.3.207
Medin, D. L., \&amp; Schwanenflugel, P. J. (1981). Linear separability in classification learning. Journal of Experimental Psychology: Human Learning and Memory, 7, 355-368. doi:10.1037/0278-7393.7.5.355
Murphy, G. L. (2002). The big book of concepts. Cambridge, MA: MIT Press.
Murphy, G. L. (2005). The study of concepts inside and outside the lab: Medin vs. Medin. In W.-K. Ahn, R. L. Goldstone, B. C. Love, A. B. Markman, \&amp; P. Wolff (Eds.), Categorization inside and outside the lab: Essays in honor of Douglas Medin (pp. 179-195). Washington, DC: American Psychological Association.
Murphy, G. L. (2013). Categories and concepts. In E. Diener \&amp; R. Biswas-Diener (Eds.), Psychology (Noba Textbook Series) (pp. 813-842). Champaign, IL: DEF Publishers.
Murphy, G. L., \&amp; Allopenna, P. D. (1994). The locus of knowledge effects in concept learning. Journal of Experimental Psychology: Learning, Memory, and Cognition, 20, 904-919. doi:10.1037/ 0278-7393.20.4.904
Murphy, G. L., \&amp; Brownell, H. H. (1985). Category differentiation in object recognition: Typicality constraints on the basic category advantage. Journal of Experimental Psychology: Learning, Memory, and Cognition, 11, 70-84. doi:10.1037/0278-7393.11.1.70
Murphy, G. L., Hampton, J. A., \&amp; Milovanovic, G. S. (2012). Semantic memory redux: An experimental test of hierarchical category
representation. Journal of Memory and Language, 67, 521-539. doi:10.1016/j.jml.2012.07.005
Nosofsky, R. M. (1988). Similarity, frequency, and category representations. Journal of Experimental Psychology: Learning, Memory, and Cognition, 14, 54-65. doi:10.1037/0278-7393.14.1.54
Osherson, D. N., Smith, E. E., Wilkie, O., Lpez, A., \&amp; Shafir, E. (1990). Category-based induction. Psychological Review, 97, 185-200. doi: 10.1037/0033-295X.97.2.185</p>
<p>Palmeri, T. J. (1999). Learning categories at different hierarchical levels: A comparison of category learning models. Psychonomic Bulletin \&amp; Review, 6, 495-503.
Rehder, B. (2009). Causal-based property generalization. Cognitive Science, 33, 301-344.
Rehder, B., \&amp; Hastie, R. (2001). Causal knowledge and categories: The effects of causal beliefs on categorization, induction, and similarity. Journal of Experimental Psychology: General, 130, 323-360. doi: 10.1037/0096-3445.130.2.323</p>
<p>Rhodes, M., Leslie, S.-J., \&amp; Tworek, C. M. (2012). Cultural transmission of social essentialism. Proceedings of the National Academy of Sciences, 109, 13526-13531.
Rips, L. J. (1975). Inductive judgments about natural categories. Journal of Verbal Learning and Verbal Behavior, 14, 665-681.
Rogers, T. T., Lambon Ralph, M. A., Garrard, P., Bozeat, S., McClelland, J. L., Hodges, J. R., \&amp; Patterson, K. (2004). Structure and deterioration of semantic memory: A neuropsychological and computational investigation. Psychological Review, 111, 205-235.
Rosch, E. (1975). Cognitive representations of semantic categories. Journal of Experimental Psychology: General, 104, 192-233. doi: 10.1037/0096-3445.104.3.192</p>
<p>Rosch, E., \&amp; Mervis, C. B. (1975). Family resemblance: Studies in the internal structure of categories. Cognitive Psychology, 7, 573-605. doi:10.1016/0010-0285(75)90024-9
Rosch, E., Mervis, C. B., Gray, W. D., Johnson, D. M., \&amp; Boyes-Braem, P. (1976). Basic objects in natural categories. Cognitive Psychology, 8, 382-439. doi:10.1016/0010-0285(76)90013-X
Ross, B. H. (1984). Remindings and their effects in learning a cognitive skill. Cognitive Psychology, 16, 371-416. doi:10.1016/0010-0285(84)90014-8
Shepard, R. N. (1987). Toward a universal law of generalization for psychological science. Science, 237, 1317-1323. doi:10.1126/ science. 3629243
Sloman, S. (2005). Causal models: How people think about the world and its alternatives. New York, NY: Oxford University Press.
Smith, E. E., Balzano, G. J., \&amp; Walker, J. (1978). Nominal, perceptual, and semantic codes in picture categorization. In J. W. Cotton \&amp; R. L. Klatzky (Eds.), Semantic factors in cognition (pp. 137-168). Hillsdale, NJ: Erlbaum.
Smith, E. E., \&amp; Medin, D. L. (1981). Categories and concepts. Cambridge, MA: Harvard University Press.
Smith, J. D., \&amp; Minda, J. P. (1998). Prototypes in the mist: The early epochs of category learning. Journal of Experimental Psychology: Learning, Memory, and Cognition, 24, 1411-1436. doi:10.1037/ 0278-7393.24.6.1411
Smith, E. E., Rips, L. J., \&amp; Shoben, E. J. (1974). Semantic memory and psychological semantics. In G. H. Bower (Ed.), The psychology of learning and motivation (Vol. 8, pp. 1-45). New York, NY: Academic Press.
Spalding, T. L., \&amp; Murphy, G. L. (1996). Effects of background knowledge on category construction. Journal of Experimental Psychology: Learning, Memory, and Cognition, 22, 525-538. doi: 10.1037/0278-7393.22.2.525</p>
<p>Thibaut, J.-P., \&amp; Gelaes, S. (2006). Exemplar effects in the context of a categorization rule: Featural and holistic influences. Journal of Experimental Psychology: Learning, Memory, and Cognition, 32, 1403-1415. doi:10.1037/0278-7393.32.6.1403</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{2}$ To be clear, some prototype models also do not account for content effects, such as Osherson et al.'s (1990) seminal model. To explain such effects, any theory would have to refer to more general knowledge beyond the categories involved. My point is that there is no exemplar account of how such knowledge would be represented or accessed.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:1">
<p>${ }^{1}$ It is important to understand that exemplars refers to actual instances that are members of a category (or encounters with such instances). Sometimes the term is loosely used to refer to subcategories-for example, "swallow is an exemplar of the category of birds." However, swallows are not an exemplar but are a category with many thousands of individual members.&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>