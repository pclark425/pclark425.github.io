<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2423 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2423</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2423</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-67.html">extraction-schema-67</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <p><strong>Paper ID:</strong> paper-274417374</p>
                <p><strong>Paper Title:</strong> Optimization of Flame Retardant Polypropylene via Machine Learning</p>
                <p><strong>Paper Abstract:</strong> In this study, we explore the application of Multi-Objective Bayesian Optimization (MOBO), a machine learning-based method, for the development of flame-retardant polypropylene (PP) formulations. This approach leverages the power of Gaussian Processes (GPs) to accurately model the behavior in the Limiting Oxygen Index (LOI) flame test and uses the qNEHVI acquisition function for efficient design space exploration. We focus on a bi-objective optimization strategy, aiming to maximize LOI values while minimizing the content of flame retardant (FR) additives. Our research successfully navigates the complexities of optimizing material properties by proposing an optimal formulation within a constrained evaluation framework, comprising five iterations of three parallel evaluations with a total budget of 20 points. This work highlights MOBO’s potential as a transformative tool for advanced materials science, particularly in achieving high-performance flame-retardant materials.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2423.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2423.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MOBO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Multi-Objective Bayesian Optimization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Bayesian optimization framework that searches for Pareto-optimal trade-offs among multiple objectives by iteratively fitting probabilistic surrogate models and selecting new experiments to maximize expected multi-objective utility (here hypervolume improvement).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Optimization of Flame Retardant Polypropylene via Machine Learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Multi-Objective Bayesian Optimization (MOBO)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An active-learning optimization system that fits Gaussian Process (GP) surrogate models to multiple objectives (here: maximize LOI, minimize FR additive content), approximates the Pareto front, and uses an acquisition function that computes expected improvement in Pareto-front quality (hypervolume improvement) to select new experiments. The system operates in iterative batches (three parallel evaluations per iteration) inside a fixed total experimental budget (20 points), and can constrain the objective space via threshold/reference point settings to move from exploration to exploitation.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Materials science — formulation optimization (flame-retardant polypropylene)</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Selects new experiments by optimizing an acquisition function (expected hypervolume improvement) computed from GPs; operates in batches of q=3 per iteration until the fixed budget of 20 total evaluations is exhausted. Early iterations left unconstrained to promote exploration; later iterations apply thresholds on objective space (LOI >= 25, FR <= 27) to favor exploitation.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Primarily measured in number of experimental evaluations (20 point budget) and algorithmic complexity described qualitatively as O(N) with N samples; computational overhead arises from fitting fully Bayesian GPs and computing expected hypervolume improvement for candidate batches.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Expected Hypervolume Improvement (HVI) — the acquisition function estimates the expected increase in dominated hypervolume if candidate experiments are evaluated.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Implicitly balanced by the acquisition function (expected HVI) which rewards points that either improve current Pareto front (exploitation) or reduce uncertainty where potential for hypervolume improvement exists (exploration); procedural staging used: unconstrained early iterations for exploration, then objective-space thresholds to bias toward exploitation.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>No explicit diversity-promoting subroutine is implemented; diversity arises implicitly from the probabilistic uncertainty in GPs and the expected hypervolume improvement objective which can favor diverse candidates that collectively increase Pareto hypervolume. Additionally, batched (parallel) selection picks multiple candidates per iteration, which can increase variety in evaluated points.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed number of experiments (experimental evaluation budget of 20 points total); also mentions computational complexity limits and a practical parameter-count limit (<20 parameters).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>The total number of evaluations is fixed prior to optimization (20 points); optimization proceeds in 5 iterations of 3 parallel evaluations after initialization (5 initial points + 15 active-learning points). Stopping criteria are preset by budget rather than adaptive convergence metrics, although the paper notes alternative stopping rules (plateauing hypervolume).</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Improvement in Pareto hypervolume (HyperVolume Improvement) and meeting prespecified objective thresholds (e.g., LOI > 27 and FR wt% < 25 are interpreted as 'optimal' / high-impact formulations).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Total experimental budget: 20 formulations (5 init + 15 active); reported predictive metrics for LOI: MAPE between 2.2% and 3.8% across iterations, Pearson correlation 0.97–0.99, Fisher exact test p-values decreasing to 0.0005; achieved an optimal formulation with LOI > 27 and total FR content 24 wt.-% (17% APP, 7% PER, 76% PP). Hypervolume initial value reported as 7.99 with increases tracked through iterations (Table 3).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Contrasted qualitatively with traditional Design of Experiments (DoE) approaches; Bayesian optimization favored for small-data expensive evaluations. No quantitative head-to-head baseline experiment reported (e.g., random search or DoE trial counts).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Qualitative: MOBO required only 20 points to propose an optimal formulation; paper states DoE requires many more evaluations as variables grow but provides no numerical comparison. No explicit numerical improvement vs random or DoE is reported.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Reported achievement of an optimal formulation within the fixed 20-point budget; no percentage reduction vs a baseline provided. Paper notes BO is effective for <100 datapoints and that MOBO is suitable for expensive-to-evaluate problems.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>The paper discusses tradeoffs qualitatively: acquisition functions manage exploration vs exploitation; using thresholds shifts search toward exploitation at the cost of exploration; fixed-budget termination trades potential extra discovery for experimental constraints; computational expense (O(N)) and parameter-count limits (<20) constrain scaling. The hypervolume metric is used to monitor Pareto improvement but the authors did not perform an explicit quantitative cost vs information-gain tradeoff analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Recommended pattern: initialize with literature-informed points, allow unconstrained exploration for several iterations, then impose objective-space thresholds to focus exploitation; use batched parallel evaluations (q=3) to accelerate convergence under a fixed experimental budget; set budget a priori or alternatively monitor hypervolume plateau to stop.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Optimization of Flame Retardant Polypropylene via Machine Learning', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2423.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2423.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>qNEHVI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>parallel Noisy Expected Hypervolume Improvement (qNEHVI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A batch acquisition function that selects q candidate experiments to maximize the expected improvement in Pareto-dominated hypervolume under noisy observations, combining GP predictive distributions and multi-objective utility to allocate experimental effort.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Optimization of Flame Retardant Polypropylene via Machine Learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>qNEHVI (parallel Noisy Expected Hypervolume Improvement)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An acquisition function implemented within the MOBO framework that computes the expected hypervolume improvement from evaluating a batch of q candidate points under GP predictive posteriors with noise; it ranks and selects batches that maximize expected gain in Pareto hypervolume, thereby allocating experimental resources to points with high expected contribution to multi-objective improvement.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Multi-objective experimental design / active learning in materials optimization</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Optimizes batches of q=3 candidate formulations per iteration to maximize expected hypervolume improvement; early iterations run unconstrained to favor exploration, later iterations apply objective thresholds to focus the acquisition on a reduced outcome region (exploitation).</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Computational cost implied by acquisition optimization over batches (increases with batch size q and number of candidate evaluations); overall algorithmic scaling described as O(N) with N samples; no wall-clock or monetary cost numbers provided.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Expected Hypervolume Improvement (expected HVI) — the acquisition's objective; effectively an expected-utility measure quantifying how much the Pareto-dominated volume would increase by evaluating the batch.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Exploration achieved by favoring candidates with large predictive uncertainty and potential to improve hypervolume; exploitation achieved by favoring candidates predicted to improve current Pareto front. The expected HVI naturally balances these via GP predictive mean and variance. Objective thresholding further biases selection toward exploitation when applied.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Diversity between batch members is induced implicitly by the joint expected-HVI objective, which rewards sets of points that collectively increase hypervolume (thus favoring complementary/ diverse candidates) but no explicit diversity penalty or determinantal selection is implemented.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed experimental budget (20 total evaluations); batch size fixed at q=3 per iteration.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Selects q candidates per iteration until budget is exhausted; thresholds may be set in the Ax implementation to restrict objective space and thereby concentrate remaining budget into promising regions.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Expected increase in Pareto hypervolume (expected HVI) is the acquisition's measure of potential high-impact (breakthrough) experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Applied with q=3 over 5 active iterations (15 active evaluations) plus initializations; contributed to finding candidate with LOI > 27 and FR content 24 wt.-%. No separate ablation comparing qNEHVI to other acquisitions provided in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>No quantitative baseline acquisition functions (e.g., qEI, qNEI, entropy search) evaluated in the experimental study; literature-level comparison notes BO preferred to DoE for small-data expensive tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Not quantified against alternative acquisition functions or random selection in this work.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Enabled batched evaluation choice (three parallel experiments per iteration), which the authors state speeds convergence; no numerical speed-up vs other strategies reported.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper describes qualitatively that qNEHVI balances exploration and exploitation via expected hypervolume improvement and that objective thresholds can be used to trade exploration for exploitation in later iterations; no explicit mathematical tradeoff curves between computational cost and expected gain are presented.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Using qNEHVI in batches with initial unconstrained exploration followed by threshold-constrained exploitation is an effective practical recipe for allocating a small fixed experimental budget in multi-objective materials optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Optimization of Flame Retardant Polypropylene via Machine Learning', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2423.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2423.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GP surrogate</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Gaussian Process surrogate model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Probabilistic nonparametric regression model used as the surrogate for unknown objective functions, providing predictive means and uncertainties used by acquisition functions to guide experiment selection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Optimization of Flame Retardant Polypropylene via Machine Learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Gaussian Process (GP) surrogate modeling</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A fully Bayesian Gaussian Process surrogate with a Matérn 5/2 kernel (default in Ax) was trained on experimental data for the objectives, producing predictive distributions (mean and variance) used to compute expected hypervolume improvement. Training used Leave-One-Out Cross-Validation (LOOCV) to guard against overfitting.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Surrogate modeling within active learning and Bayesian optimization for materials formulation (LOI prediction).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>The GP's predictive mean and variance are inputs to the acquisition function; high predictive uncertainty can make a candidate attractive (exploration), while high predicted objective value favors exploitation. Thus GP outputs drive resource allocation decisions via the acquisition function.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Computational cost tied to fitting GP posteriors and making predictive draws; paper notes MOBO with GPs is computationally expensive with complexity scaling O(N) (statement in paper), but no wall-clock numbers provided.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>GP predictive variance contributes to expected HVI calculation; GP itself does not report an explicit information-gain scalar but enables expected-utility computations based on predictive distributions.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Exploration encouraged where GP predictive variance is large; exploitation encouraged where GP predictive mean predicts better objectives. Acquisition function merges these signals into expected hypervolume improvement.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>No explicit diversity mechanism in GP modeling; diversity in acquisition outcomes arises from posterior uncertainty structure.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Induced by experimental budget (20 points); GP fitting operates on incrementally growing dataset as budget is consumed.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>GP is retrained after each batch of evaluations; LOOCV used during training to reduce overfitting and potentially improve selection quality under small budgets.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>GP enables estimation of expected HVI for candidate points; high expected HVI indicates potential breakthroughs.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Predictive performance reported for LOI: MAPE < 5% across iterations, Pearson correlation 0.97–0.99, Fisher test p-values indicating strong discrimination capability as iterations progressed.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>No other surrogate model (e.g., random forest, neural net) compared in this study.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Not applicable—GP chosen as standard Bayesian-optimization surrogate; reported metrics demonstrate high predictive accuracy but no cross-model comparison given.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>GP predictive accuracy (low MAPE, high Pearson correlation) supports efficient selection of promising experiments within limited budgets; no quantitative efficiency gain vs alternative surrogates provided.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper notes the modelling-experiment loop trades computational cost (GP fitting and acquisition computation) against the value of reducing the number of expensive physical experiments; specific analyses or cost curves are not provided.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Use fully Bayesian GP with LOOCV for small-data, expensive-to-evaluate materials problems; rely on GP predictive uncertainty to drive exploration in early iterations and exploitation later via thresholding.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Optimization of Flame Retardant Polypropylene via Machine Learning', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2423.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2423.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Ax platform</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Ax (Adaptive Experimentation) platform, ax.client</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A software platform developed by Meta for adaptive experiment design and Bayesian optimization that provides implementations of GPs, acquisition functions (including qNEHVI), batch selection, and utilities for setting thresholds and running iterations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Optimization of Flame Retardant Polypropylene via Machine Learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Ax platform (ax.client)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Implementation and orchestration framework used to run the MOBO workflow: initialization, GP fitting (fully Bayesian), acquisition optimization (qNEHVI), batch proposal (q=3), and applying objective thresholds. Ax provides configurable kernel defaults (Matérn 5/2) and interfaces for setting thresholds that influence hypervolume reference points.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Software infrastructure for active experimental design in materials optimization and other domains requiring Bayesian optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Ax optimizes acquisition functions (here qNEHVI) to select batch candidates under user-specified constraints and thresholds. It supports parallel evaluation proposals and allows setting objective thresholds which alter the hypervolume calculation and thereby influence allocation.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Platform-level costs are the computational expense of surrogate fitting and acquisition optimization (no wall-clock or dollar costs reported); complexity scales with dataset size and batch-optimization difficulty.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Supports acquisition functions based on expected information/utility (expected HVI) and computes those quantities using GP posteriors.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Delegated to acquisition functions (qNEHVI) executed by Ax; Ax allows initial unconstrained runs for exploration and later thresholded runs for exploitation by adjusting the hypervolume reference/threshold settings.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>No additional explicit diversity modules reported; batched acquisition via qNEHVI can produce complementary candidates in a batch.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed experimental budget managed by user (20 points total) and batch size settings.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Ax runs a fixed number of iterations/batches respecting the budget and can enforce thresholds to focus remaining budget; it does not perform automatic budget reallocation beyond acquisition-driven candidate selection.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Uses the acquisition's expected HVI and hypervolume tracking to prioritize and detect high-impact experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Operational details: used to run 5 iterative batches of 3 evaluations each, initialization of 5 literature points; thresholds applied starting at iteration 4. No platform-level runtime or throughput metrics reported.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Platform was used directly; no alternative orchestration frameworks compared in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Enables batched candidate generation and thresholding to expedite convergence under a fixed experimental budget; no quantitative speed-up vs other tooling reported.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper reports that Ax's thresholding and batching features permit pragmatic tradeoffs between exploration and exploitation under a constrained budget; the paper highlights practical constraints (computation, parameter count) but does not quantify platform overheads.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Use Ax to implement MOBO with qNEHVI and threshold-setting for a small-budget, parallel experimental campaign; initialize with literature-informed points, allow exploratory batches, then set thresholds to concentrate remaining budget.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Optimization of Flame Retardant Polypropylene via Machine Learning', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2423.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2423.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hypervolume / HVI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hypervolume and Hypervolume Improvement (HVI) metric</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-objective utility metric that measures the volume of objective space dominated by the current Pareto front relative to a reference point; hypervolume improvement for a candidate quantifies its expected contribution to enlarging that volume.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Optimization of Flame Retardant Polypropylene via Machine Learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Hypervolume (HV) and Hypervolume Improvement (HVI)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Used as the multi-objective utility: the hypervolume (volume dominated by the Pareto front w.r.t. a reference point) is computed to evaluate Pareto-front quality, and expected hypervolume improvement is computed probabilistically (qNEHVI) from GP posteriors to rank candidate experiments. The paper tracks hypervolume over iterations as a monitor of optimization progress.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Multi-objective optimization monitoring and acquisition utility in materials design optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocate experimental evaluations to candidates that maximize expected HVI, i.e., those predicted to yield the largest expected increase in dominated objective-space volume.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Computing hypervolume and expected hypervolume improvement incurs algorithmic cost that scales with Pareto front size and number of candidate evaluations; no explicit numerical cost data provided.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Expected hypervolume improvement is the information/utility metric — it quantifies the expected benefit (in dominated volume) from evaluating a candidate or batch.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Expected HVI favors points that either (a) are likely to directly extend the Pareto front (exploitation) or (b) reduce uncertainty in regions where extension is possible (exploration); it inherently balances these via GP predictive distributions.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>By construction, hypervolume improvement for batches rewards candidate sets that complement each other (increase volume jointly), so batch HVI indirectly incentivizes diversity across batch members. No separate explicit diversity regularizer used.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed experimental budget (20 total evaluations) and iterative batch size (q=3) used while tracking hypervolume growth.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Hypervolume is used as a monitoring metric; the experimenter chose a fixed-budget stop but notes hypervolume plateau could alternatively determine stopping.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Large increases in hypervolume (HVI) are interpreted as breakthroughs in multi-objective performance space; paper uses both HVI and meeting chosen thresholds (e.g., LOI and FR content) to mark important discoveries.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Initial hypervolume reported as 7.99; hypervolume is tracked across iterations (Table 3) to evaluate progress, though the paper does not list the full sequence of HV numbers in the main text besides the start value.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>No alternative multi-objective utility metric (e.g., Pareto front spacing metrics) was compared experimentally in this work.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Not applicable / not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Using HVI as the acquisition objective guided the system to an optimal formulation within the 20-evaluation budget; however the paper does not provide quantitative comparisons showing how many fewer experiments were needed vs an alternative metric.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper discusses using hypervolume to balance exploration and exploitation and to track convergence; thresholding the objective space reduces the hypervolume search region to focus remaining budget, trading exploratory potential for targeted improvement.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Monitoring hypervolume improvement and using expected HVI to allocate batches is an effective heuristic for prioritizing experiments in small-budget multi-objective materials optimization campaigns; one may set thresholds or switch stopping rules when hypervolume exhibits a plateau.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Optimization of Flame Retardant Polypropylene via Machine Learning', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2423.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2423.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Active-learning loop (budgeted batch)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Iterative active-learning loop with batched experiments under fixed budget</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An experimental-design workflow where a surrogate model is iteratively trained, acquisition-driven batches of experiments are proposed and executed, and the budget is consumed until a pre-set total number of evaluations is reached.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Optimization of Flame Retardant Polypropylene via Machine Learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Active-learning loop with fixed-budget batched evaluations</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Workflow steps: (1) initialize model with literature-defined formulations (5 points), (2) train fully Bayesian GPs with LOOCV, (3) approximate Pareto front, (4) propose a batch of 3 new candidate experiments via qNEHVI, (5) prepare and evaluate those formulations experimentally, then return results to update the surrogate. Repeat until fixed budget of 20 total evaluations is exhausted. From iteration 4 onward, objective thresholds are applied to focus search.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Experimental design and discovery in materials formulation optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocate budget in equal-size batches (q=3) chosen by maximizing expected hypervolume improvement; initial batch choices are unconstrained to promote exploration, and later batches apply thresholds to concentrate remaining budget on promising regions.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Budget counted in number of physical experiments (20 total); computational cost of retraining models and optimizing acquisition between batches is discussed qualitatively as scaling with dataset size (O(N)).</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Expected Hypervolume Improvement guides batch selection, serving as the proxy for expected information/utility from each experimental allocation.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Two-tiered: acquisition-driven balance via expected HVI; operationally, the experimenters left early iterations unconstrained to favor exploration and applied thresholds later to bias toward exploitation.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Batching provides a mechanism to evaluate multiple hypotheses in parallel, increasing empirical diversity per iteration; beyond that, no distinct algorithmic diversity-promoting constraint is applied.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed experimental-evaluation budget (count of experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Budget enforced by fixed number of iterations and batch sizes; thresholds used mid-run to reallocate remaining budget toward regions satisfying outcome constraints (e.g., LOI >= 25, FR <= 27).</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Large observed hypervolume improvements between iterations and the emergence of formulations meeting or exceeding target thresholds (LOI > 27 combined with FR wt% < 25) are treated as breakthroughs.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Execution used: 5 initialization points + 5 active iterations? (paper used 5 iterations total with 3 parallel evaluations each after init) resulting in 20 total evaluations. Predictive metrics for LOI (MAPE < 5%, Pearson r 0.97–0.99) reported. Found optimal formulation with LOI > 27 and FR = 24 wt.-%.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Qualitative comparison to conventional DoE (Design of Experiments) which executes all formulations simultaneously; no controlled baseline experiment reported (random search, uniform grid, or DoE experimental counts).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Not quantitatively compared to baseline methods in the paper; arguments are qualitative (BO is effective with <100 datapoints and reduces needed experiments vs DoE as dimensionality rises).</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Empirical outcome: identified an optimal formulation within the pre-specified 20-evaluation budget. No numeric percent reduction in required experiments vs baselines provided.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Authors discuss practical tradeoffs: fixed-budget campaigns provide planning convenience but may forgo further improvement; thresholding improves exploitation but reduces exploratory coverage; MOBO faces computational cost scaling and dimensionality limitations, limiting its use in very large design spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Practical recommendation: predefine a total experimental budget, seed the model with literature-informed points, allow early unconstrained exploratory batches, then set outcome-space thresholds to concentrate the remaining budget; use batched acquisition (qNEHVI) to efficiently select multiple complementary experiments each iteration.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Optimization of Flame Retardant Polypropylene via Machine Learning', 'publication_date_yy_mm': '2024-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Bayesian Optimization <em>(Rating: 2)</em></li>
                <li>A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning <em>(Rating: 1)</em></li>
                <li>Practical Bayesian Optimization of Machine Learning Algorithms (review by P. Frazier) <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2423",
    "paper_id": "paper-274417374",
    "extraction_schema_id": "extraction-schema-67",
    "extracted_data": [
        {
            "name_short": "MOBO",
            "name_full": "Multi-Objective Bayesian Optimization",
            "brief_description": "A Bayesian optimization framework that searches for Pareto-optimal trade-offs among multiple objectives by iteratively fitting probabilistic surrogate models and selecting new experiments to maximize expected multi-objective utility (here hypervolume improvement).",
            "citation_title": "Optimization of Flame Retardant Polypropylene via Machine Learning",
            "mention_or_use": "use",
            "system_name": "Multi-Objective Bayesian Optimization (MOBO)",
            "system_description": "An active-learning optimization system that fits Gaussian Process (GP) surrogate models to multiple objectives (here: maximize LOI, minimize FR additive content), approximates the Pareto front, and uses an acquisition function that computes expected improvement in Pareto-front quality (hypervolume improvement) to select new experiments. The system operates in iterative batches (three parallel evaluations per iteration) inside a fixed total experimental budget (20 points), and can constrain the objective space via threshold/reference point settings to move from exploration to exploitation.",
            "application_domain": "Materials science — formulation optimization (flame-retardant polypropylene)",
            "resource_allocation_strategy": "Selects new experiments by optimizing an acquisition function (expected hypervolume improvement) computed from GPs; operates in batches of q=3 per iteration until the fixed budget of 20 total evaluations is exhausted. Early iterations left unconstrained to promote exploration; later iterations apply thresholds on objective space (LOI &gt;= 25, FR &lt;= 27) to favor exploitation.",
            "computational_cost_metric": "Primarily measured in number of experimental evaluations (20 point budget) and algorithmic complexity described qualitatively as O(N) with N samples; computational overhead arises from fitting fully Bayesian GPs and computing expected hypervolume improvement for candidate batches.",
            "information_gain_metric": "Expected Hypervolume Improvement (HVI) — the acquisition function estimates the expected increase in dominated hypervolume if candidate experiments are evaluated.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Implicitly balanced by the acquisition function (expected HVI) which rewards points that either improve current Pareto front (exploitation) or reduce uncertainty where potential for hypervolume improvement exists (exploration); procedural staging used: unconstrained early iterations for exploration, then objective-space thresholds to bias toward exploitation.",
            "diversity_mechanism": "No explicit diversity-promoting subroutine is implemented; diversity arises implicitly from the probabilistic uncertainty in GPs and the expected hypervolume improvement objective which can favor diverse candidates that collectively increase Pareto hypervolume. Additionally, batched (parallel) selection picks multiple candidates per iteration, which can increase variety in evaluated points.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Fixed number of experiments (experimental evaluation budget of 20 points total); also mentions computational complexity limits and a practical parameter-count limit (&lt;20 parameters).",
            "budget_constraint_handling": "The total number of evaluations is fixed prior to optimization (20 points); optimization proceeds in 5 iterations of 3 parallel evaluations after initialization (5 initial points + 15 active-learning points). Stopping criteria are preset by budget rather than adaptive convergence metrics, although the paper notes alternative stopping rules (plateauing hypervolume).",
            "breakthrough_discovery_metric": "Improvement in Pareto hypervolume (HyperVolume Improvement) and meeting prespecified objective thresholds (e.g., LOI &gt; 27 and FR wt% &lt; 25 are interpreted as 'optimal' / high-impact formulations).",
            "performance_metrics": "Total experimental budget: 20 formulations (5 init + 15 active); reported predictive metrics for LOI: MAPE between 2.2% and 3.8% across iterations, Pearson correlation 0.97–0.99, Fisher exact test p-values decreasing to 0.0005; achieved an optimal formulation with LOI &gt; 27 and total FR content 24 wt.-% (17% APP, 7% PER, 76% PP). Hypervolume initial value reported as 7.99 with increases tracked through iterations (Table 3).",
            "comparison_baseline": "Contrasted qualitatively with traditional Design of Experiments (DoE) approaches; Bayesian optimization favored for small-data expensive evaluations. No quantitative head-to-head baseline experiment reported (e.g., random search or DoE trial counts).",
            "performance_vs_baseline": "Qualitative: MOBO required only 20 points to propose an optimal formulation; paper states DoE requires many more evaluations as variables grow but provides no numerical comparison. No explicit numerical improvement vs random or DoE is reported.",
            "efficiency_gain": "Reported achievement of an optimal formulation within the fixed 20-point budget; no percentage reduction vs a baseline provided. Paper notes BO is effective for &lt;100 datapoints and that MOBO is suitable for expensive-to-evaluate problems.",
            "tradeoff_analysis": "The paper discusses tradeoffs qualitatively: acquisition functions manage exploration vs exploitation; using thresholds shifts search toward exploitation at the cost of exploration; fixed-budget termination trades potential extra discovery for experimental constraints; computational expense (O(N)) and parameter-count limits (&lt;20) constrain scaling. The hypervolume metric is used to monitor Pareto improvement but the authors did not perform an explicit quantitative cost vs information-gain tradeoff analysis.",
            "optimal_allocation_findings": "Recommended pattern: initialize with literature-informed points, allow unconstrained exploration for several iterations, then impose objective-space thresholds to focus exploitation; use batched parallel evaluations (q=3) to accelerate convergence under a fixed experimental budget; set budget a priori or alternatively monitor hypervolume plateau to stop.",
            "uuid": "e2423.0",
            "source_info": {
                "paper_title": "Optimization of Flame Retardant Polypropylene via Machine Learning",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "qNEHVI",
            "name_full": "parallel Noisy Expected Hypervolume Improvement (qNEHVI)",
            "brief_description": "A batch acquisition function that selects q candidate experiments to maximize the expected improvement in Pareto-dominated hypervolume under noisy observations, combining GP predictive distributions and multi-objective utility to allocate experimental effort.",
            "citation_title": "Optimization of Flame Retardant Polypropylene via Machine Learning",
            "mention_or_use": "use",
            "system_name": "qNEHVI (parallel Noisy Expected Hypervolume Improvement)",
            "system_description": "An acquisition function implemented within the MOBO framework that computes the expected hypervolume improvement from evaluating a batch of q candidate points under GP predictive posteriors with noise; it ranks and selects batches that maximize expected gain in Pareto hypervolume, thereby allocating experimental resources to points with high expected contribution to multi-objective improvement.",
            "application_domain": "Multi-objective experimental design / active learning in materials optimization",
            "resource_allocation_strategy": "Optimizes batches of q=3 candidate formulations per iteration to maximize expected hypervolume improvement; early iterations run unconstrained to favor exploration, later iterations apply objective thresholds to focus the acquisition on a reduced outcome region (exploitation).",
            "computational_cost_metric": "Computational cost implied by acquisition optimization over batches (increases with batch size q and number of candidate evaluations); overall algorithmic scaling described as O(N) with N samples; no wall-clock or monetary cost numbers provided.",
            "information_gain_metric": "Expected Hypervolume Improvement (expected HVI) — the acquisition's objective; effectively an expected-utility measure quantifying how much the Pareto-dominated volume would increase by evaluating the batch.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Exploration achieved by favoring candidates with large predictive uncertainty and potential to improve hypervolume; exploitation achieved by favoring candidates predicted to improve current Pareto front. The expected HVI naturally balances these via GP predictive mean and variance. Objective thresholding further biases selection toward exploitation when applied.",
            "diversity_mechanism": "Diversity between batch members is induced implicitly by the joint expected-HVI objective, which rewards sets of points that collectively increase hypervolume (thus favoring complementary/ diverse candidates) but no explicit diversity penalty or determinantal selection is implemented.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Fixed experimental budget (20 total evaluations); batch size fixed at q=3 per iteration.",
            "budget_constraint_handling": "Selects q candidates per iteration until budget is exhausted; thresholds may be set in the Ax implementation to restrict objective space and thereby concentrate remaining budget into promising regions.",
            "breakthrough_discovery_metric": "Expected increase in Pareto hypervolume (expected HVI) is the acquisition's measure of potential high-impact (breakthrough) experiments.",
            "performance_metrics": "Applied with q=3 over 5 active iterations (15 active evaluations) plus initializations; contributed to finding candidate with LOI &gt; 27 and FR content 24 wt.-%. No separate ablation comparing qNEHVI to other acquisitions provided in the paper.",
            "comparison_baseline": "No quantitative baseline acquisition functions (e.g., qEI, qNEI, entropy search) evaluated in the experimental study; literature-level comparison notes BO preferred to DoE for small-data expensive tasks.",
            "performance_vs_baseline": "Not quantified against alternative acquisition functions or random selection in this work.",
            "efficiency_gain": "Enabled batched evaluation choice (three parallel experiments per iteration), which the authors state speeds convergence; no numerical speed-up vs other strategies reported.",
            "tradeoff_analysis": "Paper describes qualitatively that qNEHVI balances exploration and exploitation via expected hypervolume improvement and that objective thresholds can be used to trade exploration for exploitation in later iterations; no explicit mathematical tradeoff curves between computational cost and expected gain are presented.",
            "optimal_allocation_findings": "Using qNEHVI in batches with initial unconstrained exploration followed by threshold-constrained exploitation is an effective practical recipe for allocating a small fixed experimental budget in multi-objective materials optimization.",
            "uuid": "e2423.1",
            "source_info": {
                "paper_title": "Optimization of Flame Retardant Polypropylene via Machine Learning",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "GP surrogate",
            "name_full": "Gaussian Process surrogate model",
            "brief_description": "Probabilistic nonparametric regression model used as the surrogate for unknown objective functions, providing predictive means and uncertainties used by acquisition functions to guide experiment selection.",
            "citation_title": "Optimization of Flame Retardant Polypropylene via Machine Learning",
            "mention_or_use": "use",
            "system_name": "Gaussian Process (GP) surrogate modeling",
            "system_description": "A fully Bayesian Gaussian Process surrogate with a Matérn 5/2 kernel (default in Ax) was trained on experimental data for the objectives, producing predictive distributions (mean and variance) used to compute expected hypervolume improvement. Training used Leave-One-Out Cross-Validation (LOOCV) to guard against overfitting.",
            "application_domain": "Surrogate modeling within active learning and Bayesian optimization for materials formulation (LOI prediction).",
            "resource_allocation_strategy": "The GP's predictive mean and variance are inputs to the acquisition function; high predictive uncertainty can make a candidate attractive (exploration), while high predicted objective value favors exploitation. Thus GP outputs drive resource allocation decisions via the acquisition function.",
            "computational_cost_metric": "Computational cost tied to fitting GP posteriors and making predictive draws; paper notes MOBO with GPs is computationally expensive with complexity scaling O(N) (statement in paper), but no wall-clock numbers provided.",
            "information_gain_metric": "GP predictive variance contributes to expected HVI calculation; GP itself does not report an explicit information-gain scalar but enables expected-utility computations based on predictive distributions.",
            "uses_information_gain": null,
            "exploration_exploitation_mechanism": "Exploration encouraged where GP predictive variance is large; exploitation encouraged where GP predictive mean predicts better objectives. Acquisition function merges these signals into expected hypervolume improvement.",
            "diversity_mechanism": "No explicit diversity mechanism in GP modeling; diversity in acquisition outcomes arises from posterior uncertainty structure.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Induced by experimental budget (20 points); GP fitting operates on incrementally growing dataset as budget is consumed.",
            "budget_constraint_handling": "GP is retrained after each batch of evaluations; LOOCV used during training to reduce overfitting and potentially improve selection quality under small budgets.",
            "breakthrough_discovery_metric": "GP enables estimation of expected HVI for candidate points; high expected HVI indicates potential breakthroughs.",
            "performance_metrics": "Predictive performance reported for LOI: MAPE &lt; 5% across iterations, Pearson correlation 0.97–0.99, Fisher test p-values indicating strong discrimination capability as iterations progressed.",
            "comparison_baseline": "No other surrogate model (e.g., random forest, neural net) compared in this study.",
            "performance_vs_baseline": "Not applicable—GP chosen as standard Bayesian-optimization surrogate; reported metrics demonstrate high predictive accuracy but no cross-model comparison given.",
            "efficiency_gain": "GP predictive accuracy (low MAPE, high Pearson correlation) supports efficient selection of promising experiments within limited budgets; no quantitative efficiency gain vs alternative surrogates provided.",
            "tradeoff_analysis": "Paper notes the modelling-experiment loop trades computational cost (GP fitting and acquisition computation) against the value of reducing the number of expensive physical experiments; specific analyses or cost curves are not provided.",
            "optimal_allocation_findings": "Use fully Bayesian GP with LOOCV for small-data, expensive-to-evaluate materials problems; rely on GP predictive uncertainty to drive exploration in early iterations and exploitation later via thresholding.",
            "uuid": "e2423.2",
            "source_info": {
                "paper_title": "Optimization of Flame Retardant Polypropylene via Machine Learning",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "Ax platform",
            "name_full": "Ax (Adaptive Experimentation) platform, ax.client",
            "brief_description": "A software platform developed by Meta for adaptive experiment design and Bayesian optimization that provides implementations of GPs, acquisition functions (including qNEHVI), batch selection, and utilities for setting thresholds and running iterations.",
            "citation_title": "Optimization of Flame Retardant Polypropylene via Machine Learning",
            "mention_or_use": "use",
            "system_name": "Ax platform (ax.client)",
            "system_description": "Implementation and orchestration framework used to run the MOBO workflow: initialization, GP fitting (fully Bayesian), acquisition optimization (qNEHVI), batch proposal (q=3), and applying objective thresholds. Ax provides configurable kernel defaults (Matérn 5/2) and interfaces for setting thresholds that influence hypervolume reference points.",
            "application_domain": "Software infrastructure for active experimental design in materials optimization and other domains requiring Bayesian optimization.",
            "resource_allocation_strategy": "Ax optimizes acquisition functions (here qNEHVI) to select batch candidates under user-specified constraints and thresholds. It supports parallel evaluation proposals and allows setting objective thresholds which alter the hypervolume calculation and thereby influence allocation.",
            "computational_cost_metric": "Platform-level costs are the computational expense of surrogate fitting and acquisition optimization (no wall-clock or dollar costs reported); complexity scales with dataset size and batch-optimization difficulty.",
            "information_gain_metric": "Supports acquisition functions based on expected information/utility (expected HVI) and computes those quantities using GP posteriors.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Delegated to acquisition functions (qNEHVI) executed by Ax; Ax allows initial unconstrained runs for exploration and later thresholded runs for exploitation by adjusting the hypervolume reference/threshold settings.",
            "diversity_mechanism": "No additional explicit diversity modules reported; batched acquisition via qNEHVI can produce complementary candidates in a batch.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Fixed experimental budget managed by user (20 points total) and batch size settings.",
            "budget_constraint_handling": "Ax runs a fixed number of iterations/batches respecting the budget and can enforce thresholds to focus remaining budget; it does not perform automatic budget reallocation beyond acquisition-driven candidate selection.",
            "breakthrough_discovery_metric": "Uses the acquisition's expected HVI and hypervolume tracking to prioritize and detect high-impact experiments.",
            "performance_metrics": "Operational details: used to run 5 iterative batches of 3 evaluations each, initialization of 5 literature points; thresholds applied starting at iteration 4. No platform-level runtime or throughput metrics reported.",
            "comparison_baseline": "Platform was used directly; no alternative orchestration frameworks compared in the paper.",
            "performance_vs_baseline": "Not reported.",
            "efficiency_gain": "Enables batched candidate generation and thresholding to expedite convergence under a fixed experimental budget; no quantitative speed-up vs other tooling reported.",
            "tradeoff_analysis": "Paper reports that Ax's thresholding and batching features permit pragmatic tradeoffs between exploration and exploitation under a constrained budget; the paper highlights practical constraints (computation, parameter count) but does not quantify platform overheads.",
            "optimal_allocation_findings": "Use Ax to implement MOBO with qNEHVI and threshold-setting for a small-budget, parallel experimental campaign; initialize with literature-informed points, allow exploratory batches, then set thresholds to concentrate remaining budget.",
            "uuid": "e2423.3",
            "source_info": {
                "paper_title": "Optimization of Flame Retardant Polypropylene via Machine Learning",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "Hypervolume / HVI",
            "name_full": "Hypervolume and Hypervolume Improvement (HVI) metric",
            "brief_description": "A multi-objective utility metric that measures the volume of objective space dominated by the current Pareto front relative to a reference point; hypervolume improvement for a candidate quantifies its expected contribution to enlarging that volume.",
            "citation_title": "Optimization of Flame Retardant Polypropylene via Machine Learning",
            "mention_or_use": "use",
            "system_name": "Hypervolume (HV) and Hypervolume Improvement (HVI)",
            "system_description": "Used as the multi-objective utility: the hypervolume (volume dominated by the Pareto front w.r.t. a reference point) is computed to evaluate Pareto-front quality, and expected hypervolume improvement is computed probabilistically (qNEHVI) from GP posteriors to rank candidate experiments. The paper tracks hypervolume over iterations as a monitor of optimization progress.",
            "application_domain": "Multi-objective optimization monitoring and acquisition utility in materials design optimization.",
            "resource_allocation_strategy": "Allocate experimental evaluations to candidates that maximize expected HVI, i.e., those predicted to yield the largest expected increase in dominated objective-space volume.",
            "computational_cost_metric": "Computing hypervolume and expected hypervolume improvement incurs algorithmic cost that scales with Pareto front size and number of candidate evaluations; no explicit numerical cost data provided.",
            "information_gain_metric": "Expected hypervolume improvement is the information/utility metric — it quantifies the expected benefit (in dominated volume) from evaluating a candidate or batch.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Expected HVI favors points that either (a) are likely to directly extend the Pareto front (exploitation) or (b) reduce uncertainty in regions where extension is possible (exploration); it inherently balances these via GP predictive distributions.",
            "diversity_mechanism": "By construction, hypervolume improvement for batches rewards candidate sets that complement each other (increase volume jointly), so batch HVI indirectly incentivizes diversity across batch members. No separate explicit diversity regularizer used.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Fixed experimental budget (20 total evaluations) and iterative batch size (q=3) used while tracking hypervolume growth.",
            "budget_constraint_handling": "Hypervolume is used as a monitoring metric; the experimenter chose a fixed-budget stop but notes hypervolume plateau could alternatively determine stopping.",
            "breakthrough_discovery_metric": "Large increases in hypervolume (HVI) are interpreted as breakthroughs in multi-objective performance space; paper uses both HVI and meeting chosen thresholds (e.g., LOI and FR content) to mark important discoveries.",
            "performance_metrics": "Initial hypervolume reported as 7.99; hypervolume is tracked across iterations (Table 3) to evaluate progress, though the paper does not list the full sequence of HV numbers in the main text besides the start value.",
            "comparison_baseline": "No alternative multi-objective utility metric (e.g., Pareto front spacing metrics) was compared experimentally in this work.",
            "performance_vs_baseline": "Not applicable / not reported.",
            "efficiency_gain": "Using HVI as the acquisition objective guided the system to an optimal formulation within the 20-evaluation budget; however the paper does not provide quantitative comparisons showing how many fewer experiments were needed vs an alternative metric.",
            "tradeoff_analysis": "Paper discusses using hypervolume to balance exploration and exploitation and to track convergence; thresholding the objective space reduces the hypervolume search region to focus remaining budget, trading exploratory potential for targeted improvement.",
            "optimal_allocation_findings": "Monitoring hypervolume improvement and using expected HVI to allocate batches is an effective heuristic for prioritizing experiments in small-budget multi-objective materials optimization campaigns; one may set thresholds or switch stopping rules when hypervolume exhibits a plateau.",
            "uuid": "e2423.4",
            "source_info": {
                "paper_title": "Optimization of Flame Retardant Polypropylene via Machine Learning",
                "publication_date_yy_mm": "2024-11"
            }
        },
        {
            "name_short": "Active-learning loop (budgeted batch)",
            "name_full": "Iterative active-learning loop with batched experiments under fixed budget",
            "brief_description": "An experimental-design workflow where a surrogate model is iteratively trained, acquisition-driven batches of experiments are proposed and executed, and the budget is consumed until a pre-set total number of evaluations is reached.",
            "citation_title": "Optimization of Flame Retardant Polypropylene via Machine Learning",
            "mention_or_use": "use",
            "system_name": "Active-learning loop with fixed-budget batched evaluations",
            "system_description": "Workflow steps: (1) initialize model with literature-defined formulations (5 points), (2) train fully Bayesian GPs with LOOCV, (3) approximate Pareto front, (4) propose a batch of 3 new candidate experiments via qNEHVI, (5) prepare and evaluate those formulations experimentally, then return results to update the surrogate. Repeat until fixed budget of 20 total evaluations is exhausted. From iteration 4 onward, objective thresholds are applied to focus search.",
            "application_domain": "Experimental design and discovery in materials formulation optimization.",
            "resource_allocation_strategy": "Allocate budget in equal-size batches (q=3) chosen by maximizing expected hypervolume improvement; initial batch choices are unconstrained to promote exploration, and later batches apply thresholds to concentrate remaining budget on promising regions.",
            "computational_cost_metric": "Budget counted in number of physical experiments (20 total); computational cost of retraining models and optimizing acquisition between batches is discussed qualitatively as scaling with dataset size (O(N)).",
            "information_gain_metric": "Expected Hypervolume Improvement guides batch selection, serving as the proxy for expected information/utility from each experimental allocation.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Two-tiered: acquisition-driven balance via expected HVI; operationally, the experimenters left early iterations unconstrained to favor exploration and applied thresholds later to bias toward exploitation.",
            "diversity_mechanism": "Batching provides a mechanism to evaluate multiple hypotheses in parallel, increasing empirical diversity per iteration; beyond that, no distinct algorithmic diversity-promoting constraint is applied.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Fixed experimental-evaluation budget (count of experiments).",
            "budget_constraint_handling": "Budget enforced by fixed number of iterations and batch sizes; thresholds used mid-run to reallocate remaining budget toward regions satisfying outcome constraints (e.g., LOI &gt;= 25, FR &lt;= 27).",
            "breakthrough_discovery_metric": "Large observed hypervolume improvements between iterations and the emergence of formulations meeting or exceeding target thresholds (LOI &gt; 27 combined with FR wt% &lt; 25) are treated as breakthroughs.",
            "performance_metrics": "Execution used: 5 initialization points + 5 active iterations? (paper used 5 iterations total with 3 parallel evaluations each after init) resulting in 20 total evaluations. Predictive metrics for LOI (MAPE &lt; 5%, Pearson r 0.97–0.99) reported. Found optimal formulation with LOI &gt; 27 and FR = 24 wt.-%.",
            "comparison_baseline": "Qualitative comparison to conventional DoE (Design of Experiments) which executes all formulations simultaneously; no controlled baseline experiment reported (random search, uniform grid, or DoE experimental counts).",
            "performance_vs_baseline": "Not quantitatively compared to baseline methods in the paper; arguments are qualitative (BO is effective with &lt;100 datapoints and reduces needed experiments vs DoE as dimensionality rises).",
            "efficiency_gain": "Empirical outcome: identified an optimal formulation within the pre-specified 20-evaluation budget. No numeric percent reduction in required experiments vs baselines provided.",
            "tradeoff_analysis": "Authors discuss practical tradeoffs: fixed-budget campaigns provide planning convenience but may forgo further improvement; thresholding improves exploitation but reduces exploratory coverage; MOBO faces computational cost scaling and dimensionality limitations, limiting its use in very large design spaces.",
            "optimal_allocation_findings": "Practical recommendation: predefine a total experimental budget, seed the model with literature-informed points, allow early unconstrained exploratory batches, then set outcome-space thresholds to concentrate the remaining budget; use batched acquisition (qNEHVI) to efficiently select multiple complementary experiments each iteration.",
            "uuid": "e2423.5",
            "source_info": {
                "paper_title": "Optimization of Flame Retardant Polypropylene via Machine Learning",
                "publication_date_yy_mm": "2024-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Bayesian Optimization",
            "rating": 2,
            "sanitized_title": "bayesian_optimization"
        },
        {
            "paper_title": "A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning",
            "rating": 1,
            "sanitized_title": "a_tutorial_on_bayesian_optimization_of_expensive_cost_functions_with_application_to_active_user_modeling_and_hierarchical_reinforcement_learning"
        },
        {
            "paper_title": "Practical Bayesian Optimization of Machine Learning Algorithms (review by P. Frazier)",
            "rating": 2,
            "sanitized_title": "practical_bayesian_optimization_of_machine_learning_algorithms_review_by_p_frazier"
        }
    ],
    "cost": 0.016416,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Optimization of Flame Retardant Polypropylene via Machine Learning</p>
<p>Eric Verret eric.verret@centralelille.fr 
UMR 8207-UMET-Unite Materiaux et Transformations
Univ. Lille
CNRS
INRAE, Centrale Lille
LilleFrance</p>
<p>Université de Lorraine
CNRS
LEMTA
France</p>
<p>Anthony Collin 
Université de Lorraine
CNRS
LEMTA
France</p>
<p>Sophie Duquesne 
UMR 8207-UMET-Unite Materiaux et Transformations
Univ. Lille
CNRS
INRAE, Centrale Lille
LilleFrance</p>
<p>Optimization of Flame Retardant Polypropylene via Machine Learning
CFFCADCB7697FD546D72A1238DBA6EF710.1088/1742-6596/2885/1/012017
In this study, we explore the application of Multi-Objective Bayesian Optimization (MOBO), a machine learning-based method, for the development of flame-retardant polypropylene (PP) formulations.This approach leverages the power of Gaussian Processes (GPs) to accurately model the behavior in the Limiting Oxygen Index (LOI) flame test and uses the qNEHVI acquisition function for efficient design space exploration.We focus on a bi-objective optimization strategy, aiming to maximize LOI values while minimizing the content of flame retardant (FR) additives.Our research successfully navigates the complexities of optimizing material properties by proposing an optimal formulation within a constrained evaluation framework, comprising five iterations of three parallel evaluations with a total budget of 20 points.This work highlights MOBO's potential as a transformative tool for advanced materials science, particularly in achieving high-performance flame-retardant materials.</p>
<p>Introduction</p>
<p>Polypropylene (PP) is a thermoplastic polymer widely recognized for its versatility and costeffectiveness in a broad range of applications.PP unique properties such as chemical resistance and elasticity make it indispensable in industries ranging from packaging to automotive components.However, its applications are constrained by its inherent flammability.Development of flame retardant solutions has catalyzed significant research [1].One common strategy to flame retard materials is to use intumescent systems; these systems expand significantly when exposed to heat, forming a protective char layer that insulates the underlying material from the effects of fire.Such intumescent formulations are, however, complex, and optimizing them is time-consuming.In recent times, machine learning has increasingly played a crucial role in the field of formulation.Specifically, by leveraging its capabilities to analyze extensive datasets, discern patterns, and tackle complex prediction tasks, machine learning has become a valuable asset in developing new flame retardant materials [2].However, much of the literature on using machine learning for flame retardant materials focuses on prediction techniques rather than on optimization techniques [3,4,5].Therefore, there is a critical need to develop such approach in this field.Traditional statistical approaches, such as Design of Experiments (DoE), are costly in terms of number of required evaluations, this number increasing drastically with the number of variables [6].In numerous machine learning articles, Bayesian optimization (BO) is the favored approach when dealing with datasets comprising fewer than 100 training datapoints.This method proves to be particularly effective in such scenarios [7].Moreover, BO is a powerful IOP Publishing doi:10.1088/1742-6596/2885/1/012017 2 machine learning approach employed to optimize functions that are noisy or computationally expensive.It serves as a global optimization technique for tackling complex, difficult-to-evaluate functions often referred to as "black-box" functions [8,9].BO appears thus a suitable approach for the optimisation of FR materials.In this context, the objective of this study is to investigate a new methodology to optimize the chemical composition of an intumescent formulation by using Multi-Objective Bayesian Optimization (MOBO).The objective of this work is to investigate alternative methods to traditional DoE approaches when they encounter limitations.</p>
<p>Materials and methods</p>
<p>In this work, a commercial Polypropylene (PP) supplied by ATOFINA (PPC 5724), was used.Pentaerythritol (PER) supplied by Aldrich served as a char former, and Ammonium Polyphosphate (APP, Exolit AP422 from Clariant) was utilized as an acid source.These raw materials were selected due to the extensive available literature documenting their use [10].All formulations were prepared using a compounding mixer (Thermo Fisher Scientific, 250 cm 3 ).Plates, (10 cm x 10 cm x 0.3 cm) were prepared by thermocompression at 180°C with a pressure of 3kN during 15min.A saw blade was used to prepare LOI barrels (1 cm x 10 cm x 0.3 cm).Subsequently, the fire performance was assessed using a LOI device (Fire Testing Technology, West Sussex, UK).In this study, two parameters were identified as key output values.One of these values is the Limiting Oxygen Index (LOI), parameter to maximise.The second one is the FR additives, i.e.APP + PER content to minimize since it is generally observed that as the weight percentage of FR additives increases, the mechanical properties of the material tend to diminish.This is a common issue in flame-retardant materials, where the percentage of flame-retardant fillers is often minimized to avoid compromising the materials mechanical properties [11].Table 1, presents the design space of the formulation.It follows a mixture design principle, where the sum of the weight percentages of all components is equal to 100%.Only one constrain is imposed : 0 % &lt; APP + PER &lt; 30 %.</p>
<p>Bayesian optimization (BO)</p>
<p>Generality</p>
<p>Bayesian optimization is a sequential design strategy for global optimization of black-box functions that does not assume any functional forms.It is usually employed to optimize expensive-to-evaluate or noisy functions.The BO approach consists of two primary steps which are iteratively repeated (active learning loop) [12].</p>
<p>Step 1: Developing a surrogate model, typically a Gaussian Process (GP), trained on experimental data.GPs, central to Bayesian Optimization, assume a prior distribution as a multivariate normal, characterized by a specific mean vector and covariance function (Kernel),</p>
<p>Step 2: Proposing new experiments through optimization with an acquisition function.This function balances exploiting known areas and exploring new ones by considering the surrogate model's accuracy and variability.This stage addresses the critical explorationexploitation trade-off, efficiently guiding the search process by finding a balance between investigating uncharted regions and leveraging areas known to offer valuable results.</p>
<p>Literature offers various acquisition strategies for different optimization goals, including monoobjective, multi-objective, and multi-fidelity scenarios, each tailored to maximize search efficiency under specific conditions.</p>
<p>Multi-Objective Bayesian Optimization (MOBO)</p>
<p>In MOBO, the aim is to optimize multiple objectives simultaneously, often involving trade-offs to find a balance among objectives.The Pareto front represents solutions that are optimal across all objectives, where improving one typically worsens another.MOBO seeks to iteratively discover this Pareto front through an active learning loop, using measures like hypervolume (Figure 1) to evaluate the Pareto front quality.</p>
<p>Figure 1: Hypervolume (HV) in blue, also called the dominated space; the Hypervolume Improvement (HVI) in yellow.With f 1 (x) and f 2 (x), objectives both to maximize, x 1 , x 2 , x 3 dominated solutions (Pareto optimal solutions), x 4 nondominated solution and x 5 new point to evaluate, r the reference point The hypervolume metric is commonly used for assessing a Pareto front quality, representing the volume enclosed by the Pareto front and a designated reference point (Figure 1).Evaluating a new point involves measuring the hypervolume improvement, which is the potential increase in enclosed volume upon its addition to the front.Given the unknown function values at new points, probabilistic surrogate model (GPs) estimate these values from existing data.Enhancing the optimization speed, the strategy of parallel evaluation proposes evaluating several points concurrently, optimizing the convergence rate by assessing multiple potential improvements simultaneously.</p>
<p>Framework</p>
<p>The MOBO framework used in this study is divided in 5 steps: For the step 1. the model was initialized with formulations defined according to the literature [13].Steps 2 to 5 are iteratively repeated until reaching the stopping criteria (active learning loop), which is defined as 15 points beyond the initial dataset (20 points in total).The literature describes two distinct approaches for determining stopping criteria: the first approach, that we IOP Publishing doi:10.1088/1742-6596/2885/1/0120174 have adopted, involves setting a predefined number of points before initiating the active learning process.The alternative is to follow a metric (such as outcomes values or hypervolume in a multi-objective setting) and to stop the active learning process once a plateau is observed.
•
The MOBO framework was implemented using the Ax platform [14], with the help of ax.client Python class, developed by META.In this context, a fully Bayesian approach was employed, utilizing a Gaussian Process surrogate model.The acquisition function chosen was parallel Noisy Expected Hypervolume Improvement (qNEHVI).By default, this model employs a Matérn 5/2 kernel.Leave-One-Out Cross-Validation (LOOCV) was employed as a training procedure to avoid overfitting of the model.Users have the flexibility to modify a crucial parameter in the Ax platform package: the threshold value for objectives.These values serve as a reference for the computation of the hypervolume and tightening the outcome space for the generation of the new experiment.In this study, no threshold was set for the first three iterations to allow the system to perform sufficient exploration.From the fourth iteration, the objective space was constrained.The threshold for the LOI (Limiting Oxygen Index) was set at a minimum of 25 vol.-% and the additives content to a maximum of 27 wt.-%.</p>
<p>Results and discussion</p>
<p>Optimisation of the systems</p>
<p>Figure 2A highlights the different formulations and results obtained in the study, in blue, the formulation used to initialize the model are presented.These points are defined according to the literature but the LOI values are determined experimentally.The model attempts to explore the design space in iterations 1 (red points) and 2 (green points) by keeping one parameter constant.From a mathematical perspective, these points are interesting because they diverge significantly from those given in the initialization step.However, from a formulation point of view, these points are less intriguing since it is known that an intumescences requires a char former and an acid source to occur [15].Iteration 3 (black point) aims to explore the design space with a focus on formulations containing at least 20 % FR.For iteration 4 and 5, a threshold for the objectives was defined.</p>
<p>Figure 2: A: The design space of formulations; B: Trad-off plot, the red dash line present the threshold set to find the optimal formulation One of the formulations suggested by the model meets the optimal condition of having an LOI greater than 27 and an FR weight percentage lower than 25.The values to define an optimal solution are up to the decision-maker and can differ from the threshold set for the reference point in the hypervolume, which is the case here.The formulations proposed in iterations 4 (purple points) and 5 (yellow points) exhibit nearly identical LOI values but with different FR wt%.This indicates that the algorithms have understood that fire performance is influenced not only by the FR content but also by the ratio of components in the formulation.The optimal formulation contains 17% APP, 7% PER, and 76% PP (total additives content 24 wt.-%).</p>
<p>Performance metric thought iteration</p>
<p>In order to ensure, the predictive accuracy of the algorithm, three distinct parameters were used.The first of these is the Mean Absolute Percentage Error (MAPE), which measures the discrepancy between the actual and predicted values in terms of a percentage.MAPE is calculated as
1 n n i=1 A i −F i A i
× 100%, A i represents the actual value and F i denotes the forecast value.We calculate the ratio of their difference to the actual value A i .This ratio is then taken as an absolute value and aggregated for each forecasted point in time.This sum is divided by the total number of data points n to get the average.The second parameter is the correlation coefficient of Pearson, which illustrates the linear relationship between two variables.In this scenario, it facilitates an analysis of the correlation between the predicted values and the actual outcomes.A value nearing 1 indicates a robust positive correlation between the actual and predicted outcomes.The final metric used to evaluate the prediction quality is the p-value derived from Fisher's exact test.This test assesses whether the model can effectively differentiate between the lower half and the upper half of the dataset.A high p-value (p &gt; 0.10) implies that the model's ability to identify superior segments is no better than random chance.Table 2 uniformly demonstrates that MAPE values are under 5%, highlighting the prediction precision of our model across the domain.Additionally, the correlation coefficient further supports this high level of accuracy, with values ranging between 0.97 and 0.99, indicating a strong correlation between predicted and actual outcomes.Moreover, the application of the Fisher exact test yields consistent p-values, confirming that our predictions are dependable and not based on random chance.Here, we only evaluate the variable LOI, as the FR weight percentage is a linear combination of PER and APP.Evaluating the performance metric indicates the accuracy of the prediction but does not reflect the quality of the new point from an optimization perspective.Another approach to assess the quality of the new points is to evaluate the HyperVolume value at each iteration (Table 3).Tracking this value can illustrate the efficiency of the point batches.An increase in this value may indicate an improvement in the overall quality of the solution space being explored.</p>
<p>As the hypervolume expands, it suggests that the new points are contributing to a broader, more optimal search area, potentially leading to better solutions.This method of monitoring hypervolume changes serves as a metric for the progressive enhancement of the algorithm's performance over time.But as defined previously, the total budget of evaluation was fixed before the optimisation process, so this enhancement is just theoretical.</p>
<p>Conclusion</p>
<p>This study investigates the use of the efficiency of Multi-Objective Bayesian Optimization (MOBO) for optimizing complex materials, including flame retardants.The accurate modeling of fire performance by Gaussian Processes (GPs) and the effective design space exploration through the qNEHVI acquisition function are key highlights.This strategy enabled to propose an optimal formulation within five iterations of three parallel evaluations, all within a total budget of 20 points, showing the potential of this approach in material science.However, while MOBO appears highly promising for optimizing complex materials like flame retardant formulations, this active learning loop can also present limitations from an experimental point of view.Indeed, the traditional Design of Experiments (DoE), with presupposed models, offers the advantage of planning and conducting all formulations at the same time, providing a more convenient approach to experimentation in some cases.Another drawback of BO, is the limitation in the design space, where the number of parameters should be fewer than 20.MOBO is computationally expensive (O N , with N samples), which can be a limitation for its use with large datasets.</p>
<p>Step 1 :
1
Initialization of the model with 5 formulations defined according to the literature, • Step 2: Training of GPs on the objectives, • Step 3: Approximation of the pareto front, • Step 4: New Experiments (set of three formulations for upcoming evaluation), • Step 5: Preparation and fire performance assessment of the recommended formulations.</p>
<p>Table 1 :
1
Overview of input variables range and output metrics
Range of Input (%)Output MetricsPP APP PERNameObjectiveMin7000Limiting oxygen index (LOI)MaximizeMax 1002515FR weight percentage (FR wt%) Minimize</p>
<p>Table 2 :
2
Performance metrics of the model for the variable LOI across iterations
MetricInitial data Iteration 1 Iteration 2 Iteration 3 Iteration 4 Iteration 5MAPE (%)2.52.33.82.23.63.0Correlation coefficient0.980.990.980.970.980.98p-value fisher exact test 0.10000.05000.00700.00030.00300.0005</p>
<p>Table 3 :
3
Table 3 shows hypervolume (HV) values starting at 7.99, indicating Hypervolume values through iteration
IOP Publishingdoi:10.1088/1742-6596/2885/1/012017</p>
<p>. W Zhao, C K Kundu, Z Li, Li X Zhang, Z , Composites Part A: Applied Science and Manufacturing. 1451063822021</p>
<p>. H Nguyen, T Nguyen, K T Le, T Zhang, G , molecules. 2610222021</p>
<p>. F Chen, J Wang, Z Guo, F Jiang, R Ouyang, P Ding, ACS Applied Materials &amp; Interfaces. 132021</p>
<p>. Z Chen, B Yang, N Song, T Chen, Q Zhang, C Li, J Jiang, T Chen, Yu Y Liu, L X , Chemical Engineering Journal. 4551405472023</p>
<p>. Z Chen, B Yang, N Song, Y Liu, F Rong, X Zhang, T Chen, Q Zhang, J Jiang, T Chen, Composites Communications. 441017562023</p>
<p>. S Greenhill, S Rana, S Gupta, P Vellanki, S Venkatesh, IEEE access. 82020</p>
<p>. G Baird, M Liu, H Sayeed, T D Sparks, arXiv:2202.023802022arXiv preprint</p>
<p>. P Frazier, arXiv:1807.028112018arXiv preprint</p>
<p>Garnett R 2023 Bayesian Optimization. Cambridge University Press</p>
<p>. F Seidi, E Movahedifar, G Naderi, V Akbari, F Ducos, R Shamsi, H Vahabi, M R Saeb, Polymers. 1217012020</p>
<p>. X Almeras, Le Bras, M Hornsby, P Bourbigot, S Marosi, G Keszei, S Poutch, F , Polymer degradation and stability. 822003</p>
<p>. M S Handcock, M L Stein, Technometrics. 351993</p>
<p>. M Dong, X Gu, S Zhang, Industrial &amp; Engineering Chemistry Research. 532014</p>
<p>. E Bakshy, M Balandat, K Kashin, Url, </p>
<p>. Z Lei, Y Cao, F Xie, H Ren, Journal of applied polymer science. 1242012</p>            </div>
        </div>

    </div>
</body>
</html>