<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9249 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9249</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9249</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-162.html">extraction-schema-162</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-610902</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/1712.00557v1.pdf" target="_blank">Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection</a></p>
                <p><strong>Paper Abstract:</strong> Automated analysis methods are crucial aids for monitoring and defending a network to protect the sensitive or confidential data it hosts. This work introduces a flexible, powerful, and unsupervised approach to detecting anomalous behavior in computer and network logs, one that largely eliminates domain-dependent feature engineering employed by existing methods. By treating system logs as threads of interleaved"sentences"(event log lines) to train online unsupervised neural network language models, our approach provides an adaptive model of normal network behavior. We compare the effectiveness of both standard and bidirectional recurrent neural network language models at detecting malicious activity within network log data. Extending these models, we introduce a tiered recurrent architecture, which provides context by modeling sequences of users' actions over time. Compared to Isolation Forest and Principal Components Analysis, two popular anomaly detection algorithms, we observe superior performance on the Los Alamos National Laboratory Cyber Security dataset. For log-line-level red team detection, our best performing character-based model provides test set area under the receiver operator characteristic curve of 0.98, demonstrating the strong fine-grained anomaly detection performance of this approach on open vocabulary logging sources.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9249.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9249.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Event Model (EM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A unidirectional LSTM language model run over the token sequence of a single log-line; per-token predictive cross-entropy is used and aggregated to produce an anomaly score for the log-line. Trained online daily in an unsupervised fashion.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Event Model (EM)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Unidirectional LSTM language model (recurrent neural network)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Sequences of tokens (log-line token sequences); supports word-level or character-level tokenization</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>Computer/network authentication logs (LANL dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Outlier/rare events in log-lines (malicious red-team activity)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Unsupervised sequence likelihood scoring: model predicts next-token distributions via LSTM; cross-entropy (negative log-likelihood) per token is summed/aggregated per log-line and used as an anomaly score; models updated online (daily) on new data.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Isolation Forest (on aggregated per-user-day features); Principal Components Analysis (reconstruction error on aggregated features)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Area under ROC curve (AUC), Average Percentile (AP), recall vs proportion-of-data-flagged</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>EM (event-level) performed comparably to baselines when using character tokenization and outperformed baselines when using word tokenization (exact per-model numeric breakdown in paper tables). EM was generally outperformed by bidirectional variants (BEM).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Comparable or better depending on tokenization: with word tokenization EM outperformed PCA/IsolationForest baselines; with character tokenization EM was comparable to baselines but below the bidirectional models.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Relies on tokenization choice (word requires OOV handling and vocabulary management); single-log-line context (no explicit cross-line context) — tiered models were explored but did not improve performance; performance sensitive to day-level normalization for word tokenization.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Operating a language model directly on raw log-line token sequences removes extensive feature engineering, produces fine-grained (token- and log-line-level) anomaly scores, and supports online updating with fixed memory bounds.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection', 'publication_date_yy_mm': '2017-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9249.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9249.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BEM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bidirectional Event Model (BEM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A bidirectional LSTM language model over tokens of a log-line that combines forward and backward hidden states to predict tokens; used to score entire log-lines by sequence likelihood.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Bidirectional Event Model (BEM)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Bidirectional LSTM language model (two LSTMs, forward and backward)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Sequences of tokens (complete log-line token sequences); supports word-level or character-level tokenization</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>Computer/network authentication logs (LANL dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Outlier/rare events in log-lines (malicious red-team activity)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Unsupervised bidirectional sequence likelihood: combine forward LSTM (history) and backward LSTM (future within the log-line) hidden states to predict each token, compute cross-entropy per token and aggregate to produce a per-log-line anomaly score; trained online daily.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Isolation Forest (aggregated features); PCA (aggregated features)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUC (ROC), Average Percentile (AP), recall vs percent flagged</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Best-performing model in the study: the bidirectional character-based model achieved log-line-level AUC = 0.98. Character BEM reached 100% recall when flagging ~12% of the data and 80% recall at ~3% of the data; it substantially outperformed baseline methods.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Significantly better than PCA and Isolation Forest baselines (especially at log-line granularity); bidirectional LSTMs gave the most pronounced performance gains.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Character-level vs word-level trade-offs: word tokenization can be more interpretable and benefits more from diff normalization; character models can be less interpretable. (The paper notes tiered models provided no additional gain over BEM.)</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Bidirectional sequence modeling over log-lines yields large gains in anomaly detection accuracy in this domain; character-level bidirectional LSTMs can achieve near-perfect AUC on event-level red-team detection in open-vocabulary logs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection', 'publication_date_yy_mm': '2017-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9249.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9249.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>T-EM / T-BEM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Tiered Event Models (T-EM, T-BEM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A two-tier recurrent architecture: lower tier is an event-level LSTM (EM or BEM) that models tokens in a log-line; upper tier is an LSTM over sequences of a user's log-lines that produces context vectors fed into the lower tier.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Tiered Event Model (T-EM / T-BEM)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Two-tier LSTM (lower-tier token-level LSTM; upper-tier log-line sequence LSTM across a user's events)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Hierarchical sequences: token sequences per log-line and sequences of log-lines per user (temporal sequences of events)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>Computer/network authentication logs (LANL dataset), per-user event streams</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>User behavior anomalies and atypical event sequences over time (outliers in inter-event context)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Jointly trained hierarchical LSTM: lower-tier produces hidden states per log-line whose final state and mean hidden states are fed to an upper-tier LSTM modeling user activity across log-lines; upper-tier outputs context vectors concatenated into lower-tier inputs for subsequent lines; loss computed on lower-tier cross-entropy and used for anomaly scoring.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>EM/BEM (single-tier language models), Isolation Forest, PCA</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUC, Average Percentile (AP)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Tiered models performed comparably to but not better than single-event (EM/BEM) models on the LANL authentication logs in this study.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Did not improve upon single-event language models in these experiments; comparable performance.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Training/minibatching complications due to variable numbers of log-lines per user per day (risk of overly weighting active users); had to fix the number of log-lines per user per day for training, discarding excess lines; no empirical performance gain observed on user-centric authentication logs (authors hypothesize tiered models may be more helpful when tracking computers or using richer logging sources).</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Although intuitively appealing for modeling inter-event context, a tiered RNN did not outperform well-tuned event-level language models in this dataset; event-level model weights (trained daily) captured sufficient context for user behavior in this application.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection', 'publication_date_yy_mm': '2017-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9249.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9249.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Character tokenization</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Character-level tokenization (printable-ASCII alphabet)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Tokenization strategy that represents log-lines as sequences of characters rather than words; avoids open-vocabulary issues and represents any string without OOV tokens.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Character-level language model</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>LSTM / Bidirectional LSTM operating on character tokens</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Character sequences (fine-grained sequences); suitable for arbitrary strings and open-vocabulary fields</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>Computer/network authentication logs (LANL dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Outlier/rare token sequences and unusual string patterns in log-lines (e.g., novel usernames, IPs, command strings)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Use printable-ASCII characters as tokens; run LSTM/Bi-LSTM over characters in a log-line; compute cross-entropy per character aggregated to give event anomaly scores; no OOV vocabulary needed.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Word-level language models; IsolationForest; PCA</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUC, AP, recall vs percent flagged</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Character BEM achieved the best log-line-level results (AUC = 0.98). Character-level models achieved high recall with small analyst budgets (e.g., 80% recall at ~3% of data flagged). Character models were less reliant on day-level 'diff' normalization than word models.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Character-level bidirectional LSTM exceeded baselines and outperformed word-level day-aggregate methods at event-level detection; comparable to or slightly worse than word models on some day-level metrics but strongest at log-line granularity.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Less interpretable: token-level contributions are less easily mapped to human-readable fields than word-tokenized models; may require additional tooling to present context to analysts. Hyperparameters were tuned for diff-mode word models, so char models might improve further with dedicated tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Character-level language modeling over constrained log-line languages can match or exceed word-level models for fine-grained event detection while eliminating vocabulary maintenance and enabling immediate (per-event) scoring.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection', 'publication_date_yy_mm': '2017-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9249.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e9249.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Word tokenization</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Word-level tokenization with <oov></td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Tokenization strategy splitting log-lines by a delimiter (e.g., space) into words/tokens; builds a fixed vocabulary from training data and uses an <oov> token for rare/unseen tokens.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Word-level language model</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>LSTM / Bidirectional LSTM operating on word tokens</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Sequences of word tokens (categorical fields and tokens), with fixed vocabulary plus <oov></td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>Computer/network authentication logs (LANL dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Outlier/rare tokens or unusual combinations of token fields in log-lines</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Split log-lines into word tokens, map infrequent tokens to <oov>, train LSTM/Bi-LSTM to predict next word token; compute per-token cross-entropy and aggregate to produce anomaly scores; optionally maintain/update vocabulary in sliding-window deployments.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Character-level models; IsolationForest; PCA</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUC, AP, recall vs percent flagged</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Word tokenization generally performed better than character tokenization at day-level detection; word bidirectional models outperformed baselines at day-level. Word models benefited strongly from 'diff' (user-day normalization) mode.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Word-level language models outperformed PCA/IsolationForest baselines at day-level detection; however the best event-level performance was achieved by character BEM.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Requires vocabulary management and OOV handling; performance is sensitive to day-level normalization (diff) and vocabulary drift in online settings; more brittle to open-vocabulary fields unless vocabulary is periodically updated.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Word-level tokenization yields interpretable anomaly decompositions (allows pinpointing which log-line fields contributed most), and gives better day-level performance when combined with user-day normalization.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection', 'publication_date_yy_mm': '2017-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9249.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e9249.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Isolation Forest (iso)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Isolation Forest anomaly detector</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An unsupervised ensemble tree-based anomaly detector applied here to aggregated per-user-day feature vectors to provide baseline comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Isolation Forest</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Ensemble isolation-tree based unsupervised anomaly detection</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Fixed-dimensional aggregated feature vectors (per-user-day; 108 dimensions in this study)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>Aggregated statistics extracted from LANL authentication logs (per-user-day counts and common/uncommon indicators)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Anomalous user-days (outlier aggregated behavior)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Compute per-user-day aggregate features (108-d) then apply Isolation Forest to score user-days by outlierness (scikit-learn implementation).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>PCA on same aggregated features; compared against language-model-based event scoring aggregated to user-day</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUC, Average Percentile (AP), recall vs percent flagged</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Isolation Forest was the best of the aggregate-feature baselines and slightly outperformed PCA; however it required far larger analyst budgets to reach comparable recall (e.g., to reach 80% recall it needed ~55% of data flagged versus ~3% for character event model).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Serves as a baseline; language-model event-level methods, especially character BEM, substantially outperformed isolation forest in event detection efficiency.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Relies on hand-crafted aggregation/feature engineering; aggregates across events and thus loses fine-grained, log-line-level anomalies; brittle to site-specific differences in feature definitions and distributions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection', 'publication_date_yy_mm': '2017-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9249.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e9249.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PCA baseline</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Principal Components Analysis (PCA) anomaly baseline</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A PCA-based anomaly detection baseline that compresses aggregated per-user-day features and uses reconstruction error as anomaly score.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Principal Components Analysis (PCA) anomaly detector</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Linear dimensionality reduction (PCA) with reconstruction-error-based anomaly scoring</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Aggregated per-user-day numeric features (108-dimensional vector)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>Aggregated statistics from LANL authentication logs</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Anomalous user-days (outliers in aggregated feature space)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Fit PCA on aggregated user-day feature vectors and compute reconstruction error for each user-day as anomaly score.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Isolation Forest; compared to event-level language models aggregated to user-day</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUC, Average Percentile (AP)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>PCA performed similarly to Isolation Forest, but isolation forest had a slight edge; both were substantially worse than event-level language models at detecting red-team events with low analyst budget.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Used as a baseline; event-level language models (especially bidirectional character models) outperformed PCA baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Requires engineered aggregated features; loses per-event detail; sensitive to the choice of aggregation window and features.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection', 'publication_date_yy_mm': '2017-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Bidirectional recurrent neural networks <em>(Rating: 2)</em></li>
                <li>Long short-term memory <em>(Rating: 2)</em></li>
                <li>Character-based neural machine translation <em>(Rating: 1)</em></li>
                <li>Finding function in form: Compositional character models for open vocabulary word representation <em>(Rating: 1)</em></li>
                <li>Poisson factorization for peer-based anomaly detection <em>(Rating: 1)</em></li>
                <li>Malware classification with recurrent networks <em>(Rating: 1)</em></li>
                <li>Deep learning for unsupervised insider threat detection in structured cybersecu- rity data streams <em>(Rating: 2)</em></li>
                <li>A clockwork RNN <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9249",
    "paper_id": "paper-610902",
    "extraction_schema_id": "extraction-schema-162",
    "extracted_data": [
        {
            "name_short": "EM",
            "name_full": "Event Model (EM)",
            "brief_description": "A unidirectional LSTM language model run over the token sequence of a single log-line; per-token predictive cross-entropy is used and aggregated to produce an anomaly score for the log-line. Trained online daily in an unsupervised fashion.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Event Model (EM)",
            "model_type": "Unidirectional LSTM language model (recurrent neural network)",
            "model_size": null,
            "data_type": "Sequences of tokens (log-line token sequences); supports word-level or character-level tokenization",
            "data_domain": "Computer/network authentication logs (LANL dataset)",
            "anomaly_type": "Outlier/rare events in log-lines (malicious red-team activity)",
            "method_description": "Unsupervised sequence likelihood scoring: model predicts next-token distributions via LSTM; cross-entropy (negative log-likelihood) per token is summed/aggregated per log-line and used as an anomaly score; models updated online (daily) on new data.",
            "baseline_methods": "Isolation Forest (on aggregated per-user-day features); Principal Components Analysis (reconstruction error on aggregated features)",
            "performance_metrics": "Area under ROC curve (AUC), Average Percentile (AP), recall vs proportion-of-data-flagged",
            "performance_results": "EM (event-level) performed comparably to baselines when using character tokenization and outperformed baselines when using word tokenization (exact per-model numeric breakdown in paper tables). EM was generally outperformed by bidirectional variants (BEM).",
            "comparison_to_baseline": "Comparable or better depending on tokenization: with word tokenization EM outperformed PCA/IsolationForest baselines; with character tokenization EM was comparable to baselines but below the bidirectional models.",
            "limitations_or_failure_cases": "Relies on tokenization choice (word requires OOV handling and vocabulary management); single-log-line context (no explicit cross-line context) — tiered models were explored but did not improve performance; performance sensitive to day-level normalization for word tokenization.",
            "unique_insights": "Operating a language model directly on raw log-line token sequences removes extensive feature engineering, produces fine-grained (token- and log-line-level) anomaly scores, and supports online updating with fixed memory bounds.",
            "uuid": "e9249.0",
            "source_info": {
                "paper_title": "Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection",
                "publication_date_yy_mm": "2017-12"
            }
        },
        {
            "name_short": "BEM",
            "name_full": "Bidirectional Event Model (BEM)",
            "brief_description": "A bidirectional LSTM language model over tokens of a log-line that combines forward and backward hidden states to predict tokens; used to score entire log-lines by sequence likelihood.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Bidirectional Event Model (BEM)",
            "model_type": "Bidirectional LSTM language model (two LSTMs, forward and backward)",
            "model_size": null,
            "data_type": "Sequences of tokens (complete log-line token sequences); supports word-level or character-level tokenization",
            "data_domain": "Computer/network authentication logs (LANL dataset)",
            "anomaly_type": "Outlier/rare events in log-lines (malicious red-team activity)",
            "method_description": "Unsupervised bidirectional sequence likelihood: combine forward LSTM (history) and backward LSTM (future within the log-line) hidden states to predict each token, compute cross-entropy per token and aggregate to produce a per-log-line anomaly score; trained online daily.",
            "baseline_methods": "Isolation Forest (aggregated features); PCA (aggregated features)",
            "performance_metrics": "AUC (ROC), Average Percentile (AP), recall vs percent flagged",
            "performance_results": "Best-performing model in the study: the bidirectional character-based model achieved log-line-level AUC = 0.98. Character BEM reached 100% recall when flagging ~12% of the data and 80% recall at ~3% of the data; it substantially outperformed baseline methods.",
            "comparison_to_baseline": "Significantly better than PCA and Isolation Forest baselines (especially at log-line granularity); bidirectional LSTMs gave the most pronounced performance gains.",
            "limitations_or_failure_cases": "Character-level vs word-level trade-offs: word tokenization can be more interpretable and benefits more from diff normalization; character models can be less interpretable. (The paper notes tiered models provided no additional gain over BEM.)",
            "unique_insights": "Bidirectional sequence modeling over log-lines yields large gains in anomaly detection accuracy in this domain; character-level bidirectional LSTMs can achieve near-perfect AUC on event-level red-team detection in open-vocabulary logs.",
            "uuid": "e9249.1",
            "source_info": {
                "paper_title": "Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection",
                "publication_date_yy_mm": "2017-12"
            }
        },
        {
            "name_short": "T-EM / T-BEM",
            "name_full": "Tiered Event Models (T-EM, T-BEM)",
            "brief_description": "A two-tier recurrent architecture: lower tier is an event-level LSTM (EM or BEM) that models tokens in a log-line; upper tier is an LSTM over sequences of a user's log-lines that produces context vectors fed into the lower tier.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Tiered Event Model (T-EM / T-BEM)",
            "model_type": "Two-tier LSTM (lower-tier token-level LSTM; upper-tier log-line sequence LSTM across a user's events)",
            "model_size": null,
            "data_type": "Hierarchical sequences: token sequences per log-line and sequences of log-lines per user (temporal sequences of events)",
            "data_domain": "Computer/network authentication logs (LANL dataset), per-user event streams",
            "anomaly_type": "User behavior anomalies and atypical event sequences over time (outliers in inter-event context)",
            "method_description": "Jointly trained hierarchical LSTM: lower-tier produces hidden states per log-line whose final state and mean hidden states are fed to an upper-tier LSTM modeling user activity across log-lines; upper-tier outputs context vectors concatenated into lower-tier inputs for subsequent lines; loss computed on lower-tier cross-entropy and used for anomaly scoring.",
            "baseline_methods": "EM/BEM (single-tier language models), Isolation Forest, PCA",
            "performance_metrics": "AUC, Average Percentile (AP)",
            "performance_results": "Tiered models performed comparably to but not better than single-event (EM/BEM) models on the LANL authentication logs in this study.",
            "comparison_to_baseline": "Did not improve upon single-event language models in these experiments; comparable performance.",
            "limitations_or_failure_cases": "Training/minibatching complications due to variable numbers of log-lines per user per day (risk of overly weighting active users); had to fix the number of log-lines per user per day for training, discarding excess lines; no empirical performance gain observed on user-centric authentication logs (authors hypothesize tiered models may be more helpful when tracking computers or using richer logging sources).",
            "unique_insights": "Although intuitively appealing for modeling inter-event context, a tiered RNN did not outperform well-tuned event-level language models in this dataset; event-level model weights (trained daily) captured sufficient context for user behavior in this application.",
            "uuid": "e9249.2",
            "source_info": {
                "paper_title": "Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection",
                "publication_date_yy_mm": "2017-12"
            }
        },
        {
            "name_short": "Character tokenization",
            "name_full": "Character-level tokenization (printable-ASCII alphabet)",
            "brief_description": "Tokenization strategy that represents log-lines as sequences of characters rather than words; avoids open-vocabulary issues and represents any string without OOV tokens.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Character-level language model",
            "model_type": "LSTM / Bidirectional LSTM operating on character tokens",
            "model_size": null,
            "data_type": "Character sequences (fine-grained sequences); suitable for arbitrary strings and open-vocabulary fields",
            "data_domain": "Computer/network authentication logs (LANL dataset)",
            "anomaly_type": "Outlier/rare token sequences and unusual string patterns in log-lines (e.g., novel usernames, IPs, command strings)",
            "method_description": "Use printable-ASCII characters as tokens; run LSTM/Bi-LSTM over characters in a log-line; compute cross-entropy per character aggregated to give event anomaly scores; no OOV vocabulary needed.",
            "baseline_methods": "Word-level language models; IsolationForest; PCA",
            "performance_metrics": "AUC, AP, recall vs percent flagged",
            "performance_results": "Character BEM achieved the best log-line-level results (AUC = 0.98). Character-level models achieved high recall with small analyst budgets (e.g., 80% recall at ~3% of data flagged). Character models were less reliant on day-level 'diff' normalization than word models.",
            "comparison_to_baseline": "Character-level bidirectional LSTM exceeded baselines and outperformed word-level day-aggregate methods at event-level detection; comparable to or slightly worse than word models on some day-level metrics but strongest at log-line granularity.",
            "limitations_or_failure_cases": "Less interpretable: token-level contributions are less easily mapped to human-readable fields than word-tokenized models; may require additional tooling to present context to analysts. Hyperparameters were tuned for diff-mode word models, so char models might improve further with dedicated tuning.",
            "unique_insights": "Character-level language modeling over constrained log-line languages can match or exceed word-level models for fine-grained event detection while eliminating vocabulary maintenance and enabling immediate (per-event) scoring.",
            "uuid": "e9249.3",
            "source_info": {
                "paper_title": "Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection",
                "publication_date_yy_mm": "2017-12"
            }
        },
        {
            "name_short": "Word tokenization",
            "name_full": "Word-level tokenization with &lt;oov&gt;",
            "brief_description": "Tokenization strategy splitting log-lines by a delimiter (e.g., space) into words/tokens; builds a fixed vocabulary from training data and uses an &lt;oov&gt; token for rare/unseen tokens.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Word-level language model",
            "model_type": "LSTM / Bidirectional LSTM operating on word tokens",
            "model_size": null,
            "data_type": "Sequences of word tokens (categorical fields and tokens), with fixed vocabulary plus &lt;oov&gt;",
            "data_domain": "Computer/network authentication logs (LANL dataset)",
            "anomaly_type": "Outlier/rare tokens or unusual combinations of token fields in log-lines",
            "method_description": "Split log-lines into word tokens, map infrequent tokens to &lt;oov&gt;, train LSTM/Bi-LSTM to predict next word token; compute per-token cross-entropy and aggregate to produce anomaly scores; optionally maintain/update vocabulary in sliding-window deployments.",
            "baseline_methods": "Character-level models; IsolationForest; PCA",
            "performance_metrics": "AUC, AP, recall vs percent flagged",
            "performance_results": "Word tokenization generally performed better than character tokenization at day-level detection; word bidirectional models outperformed baselines at day-level. Word models benefited strongly from 'diff' (user-day normalization) mode.",
            "comparison_to_baseline": "Word-level language models outperformed PCA/IsolationForest baselines at day-level detection; however the best event-level performance was achieved by character BEM.",
            "limitations_or_failure_cases": "Requires vocabulary management and OOV handling; performance is sensitive to day-level normalization (diff) and vocabulary drift in online settings; more brittle to open-vocabulary fields unless vocabulary is periodically updated.",
            "unique_insights": "Word-level tokenization yields interpretable anomaly decompositions (allows pinpointing which log-line fields contributed most), and gives better day-level performance when combined with user-day normalization.",
            "uuid": "e9249.4",
            "source_info": {
                "paper_title": "Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection",
                "publication_date_yy_mm": "2017-12"
            }
        },
        {
            "name_short": "Isolation Forest (iso)",
            "name_full": "Isolation Forest anomaly detector",
            "brief_description": "An unsupervised ensemble tree-based anomaly detector applied here to aggregated per-user-day feature vectors to provide baseline comparisons.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Isolation Forest",
            "model_type": "Ensemble isolation-tree based unsupervised anomaly detection",
            "model_size": null,
            "data_type": "Fixed-dimensional aggregated feature vectors (per-user-day; 108 dimensions in this study)",
            "data_domain": "Aggregated statistics extracted from LANL authentication logs (per-user-day counts and common/uncommon indicators)",
            "anomaly_type": "Anomalous user-days (outlier aggregated behavior)",
            "method_description": "Compute per-user-day aggregate features (108-d) then apply Isolation Forest to score user-days by outlierness (scikit-learn implementation).",
            "baseline_methods": "PCA on same aggregated features; compared against language-model-based event scoring aggregated to user-day",
            "performance_metrics": "AUC, Average Percentile (AP), recall vs percent flagged",
            "performance_results": "Isolation Forest was the best of the aggregate-feature baselines and slightly outperformed PCA; however it required far larger analyst budgets to reach comparable recall (e.g., to reach 80% recall it needed ~55% of data flagged versus ~3% for character event model).",
            "comparison_to_baseline": "Serves as a baseline; language-model event-level methods, especially character BEM, substantially outperformed isolation forest in event detection efficiency.",
            "limitations_or_failure_cases": "Relies on hand-crafted aggregation/feature engineering; aggregates across events and thus loses fine-grained, log-line-level anomalies; brittle to site-specific differences in feature definitions and distributions.",
            "uuid": "e9249.5",
            "source_info": {
                "paper_title": "Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection",
                "publication_date_yy_mm": "2017-12"
            }
        },
        {
            "name_short": "PCA baseline",
            "name_full": "Principal Components Analysis (PCA) anomaly baseline",
            "brief_description": "A PCA-based anomaly detection baseline that compresses aggregated per-user-day features and uses reconstruction error as anomaly score.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Principal Components Analysis (PCA) anomaly detector",
            "model_type": "Linear dimensionality reduction (PCA) with reconstruction-error-based anomaly scoring",
            "model_size": null,
            "data_type": "Aggregated per-user-day numeric features (108-dimensional vector)",
            "data_domain": "Aggregated statistics from LANL authentication logs",
            "anomaly_type": "Anomalous user-days (outliers in aggregated feature space)",
            "method_description": "Fit PCA on aggregated user-day feature vectors and compute reconstruction error for each user-day as anomaly score.",
            "baseline_methods": "Isolation Forest; compared to event-level language models aggregated to user-day",
            "performance_metrics": "AUC, Average Percentile (AP)",
            "performance_results": "PCA performed similarly to Isolation Forest, but isolation forest had a slight edge; both were substantially worse than event-level language models at detecting red-team events with low analyst budget.",
            "comparison_to_baseline": "Used as a baseline; event-level language models (especially bidirectional character models) outperformed PCA baseline.",
            "limitations_or_failure_cases": "Requires engineered aggregated features; loses per-event detail; sensitive to the choice of aggregation window and features.",
            "uuid": "e9249.6",
            "source_info": {
                "paper_title": "Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection",
                "publication_date_yy_mm": "2017-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Bidirectional recurrent neural networks",
            "rating": 2,
            "sanitized_title": "bidirectional_recurrent_neural_networks"
        },
        {
            "paper_title": "Long short-term memory",
            "rating": 2,
            "sanitized_title": "long_shortterm_memory"
        },
        {
            "paper_title": "Character-based neural machine translation",
            "rating": 1,
            "sanitized_title": "characterbased_neural_machine_translation"
        },
        {
            "paper_title": "Finding function in form: Compositional character models for open vocabulary word representation",
            "rating": 1,
            "sanitized_title": "finding_function_in_form_compositional_character_models_for_open_vocabulary_word_representation"
        },
        {
            "paper_title": "Poisson factorization for peer-based anomaly detection",
            "rating": 1,
            "sanitized_title": "poisson_factorization_for_peerbased_anomaly_detection"
        },
        {
            "paper_title": "Malware classification with recurrent networks",
            "rating": 1,
            "sanitized_title": "malware_classification_with_recurrent_networks"
        },
        {
            "paper_title": "Deep learning for unsupervised insider threat detection in structured cybersecu- rity data streams",
            "rating": 2,
            "sanitized_title": "deep_learning_for_unsupervised_insider_threat_detection_in_structured_cybersecu_rity_data_streams"
        },
        {
            "paper_title": "A clockwork RNN",
            "rating": 1,
            "sanitized_title": "a_clockwork_rnn"
        }
    ],
    "cost": 0.014179999999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection</p>
<p>Aaron Tuor 
Pacific Northwest National Laboratory Richland
Washington</p>
<p>Ryan Baerwolf 
Western Washington University Bellingham
Washington</p>
<p>Nicolas Knowles 
Western Washington University Bellingham
Washington</p>
<p>Brian Hutchinson 
Pacific Northwest National Laboratory Richland
Washington</p>
<p>Western Washington University Bellingham
Washington</p>
<p>Nicole Nichols 
Pacific Northwest National Laboratory Richland
Washington</p>
<p>Robert Jasper 
Pacific Northwest National Laboratory Richland
Washington</p>
<p>Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection</p>
<p>Automated analysis methods are crucial aids for monitoring and defending a network to protect the sensitive or confidential data it hosts. This work introduces a flexible, powerful, and unsupervised approach to detecting anomalous behavior in computer and network logs; one that largely eliminates domain-dependent feature engineering employed by existing methods. By treating system logs as threads of interleaved "sentences" (event log lines) to train online unsupervised neural network language models, our approach provides an adaptive model of normal network behavior. We compare the effectiveness of both standard and bidirectional recurrent neural network language models at detecting malicious activity within network log data. Extending these models, we introduce a tiered recurrent architecture, which provides context by modeling sequences of users' actions over time. Compared to Isolation Forest and Principal Components Analysis, two popular anomaly detection algorithms, we observe superior performance on the Los Alamos National Laboratory Cyber Security dataset. For log-line-level red team detection, our best performing character-based model provides test set area under the receiver operator characteristic curve of 0.98, demonstrating the strong fine-grained anomaly detection performance of this approach on open vocabulary logging sources.</p>
<p>Introduction</p>
<p>To minimize cyber security risks, it is essential that organizations be able to rapidly detect and mitigate malicious activity on their computer networks. These threats can originate from a variety of sources including malware, phishing, port scanning, etc. Attacks can lead to unauthorized network access to perpetrate further damage such as theft of credentials, intellectual property, and other business sensitive information. In a typical scenario, cyber defenders and network administrators are tasked with sifting through vast amounts of data from various logging sources to assess potential security risks. Unfortunately, the amount of data for even a modestly-sized network can quickly grow beyond the ability of a single person or team to assess, leading to delayed response. The desire for automated assistance has and continues to encourage inter-domain research in cyber security and machine learning.</p>
<p>Signature-based approaches for automated detection can be highly effective for characterizing individual threats. De-spite their high precision, they suffer from low recall and may fail to detect subtle mutations or novel attacks. Alternatively, given an unlabeled training set of typically benign activity logs, one can build a model of "normal behavior". During online joint training and evaluation of this model, patterns of normal usage will be reinforced and atypical malicious activity will stand out as anomalous. The features used to identify unusual behavior are typically statistical feature vectors associated with time slices, e.g., vectors of counts for types of activities taking place in a 24-hour window. Such systems developed in research have been criticized as brittle to differences in site-specific properties of real-world operational networks such as security constraints and variable usage patterns (Sommer and Paxson 2010).</p>
<p>The approach we introduce aims to minimize site-specific assumptions implicit in feature engineering, and effectively model variability in network usage by direct online learning of language models over log lines. Language models assign probabilities to sequences of tokens and are a core component of speech recognition, machine translation, and other language processing systems. Specifically, we explore the effectiveness of several recurrent neural network (RNN) language models for use in a network anomaly detection system. Our system dynamically updates the network language model each day based on the previous day's events. When the language model assigns a low probability to a log-line it is flagged as anomalous. There are several advantages to this approach:</p>
<ol>
<li>
<p>Reduced feature engineering: Our model acts directly on raw string tokens, rather than hand-designed domainspecific statistics. This dramatically reduces the time to deployment, and makes it agnostic to the specific network or logging source configuration. It also removes the "blind spots" introduced when tens of thousands of log-lines are distilled down to a single aggregated feature vector, allowing our model to capture patterns that would have otherwise been lost.</p>
</li>
<li>
<p>Fine grained assessment: The response time for analysts can be improved by providing more specific and relevant events of interest. Baseline systems that alert to a user's day aggregate require sifting through tens of thousands of actions. Our approach can provide log-line-level or even token-level scores to the analyst, helping them quickly lo-cate the suspicious activity.</p>
</li>
<li>
<p>Real time processing: With the ability to process events in real time and fixed bounds on memory usage which do not grow over time, our approach is suitable for the common scenario in which log-line events are appearing in a high-volume, high-velocity log stream.</p>
</li>
</ol>
<p>We assess our models using the publicly available Los Alamos National Laboratory (LANL) Cyber Security Dataset, which contains real (de-identified) data with ground truth red team attacks, and demonstrate language models definitively outperforming standard unsupervised anomaly detection approaches.</p>
<p>Prior work</p>
<p>Machine learning has been widely explored for network anomaly detection, with techniques such as isolation forest (Gavai et al. 2015;Liu, Ting, and Zhou 2008) and principal component analysis (Novakov et al. 2013;Ringberg et al. 2007) attracting significant interest. Machine learning classifiers ranging from decision trees to Naïve Bayes have been used for cyber security tasks such as malware detection, network intrusion, and insider threat detection. Extensive discussion of machine learning applications in cyber security is presented in (Bhattacharyya and Kalita 2013; Buczak and Guven 2016;Dua and Du 2016;Kumar, Kumar, and Sachdeva 2010;Zuech, Khoshgoftaar, and Wald 2015;Rubin-Delanchy, Lawson, and Heard 2016).</p>
<p>Deep learning approaches are also gaining adoption for specialized cyber defense tasks. In an early use of recurrent neural networks, Debar, Becker, and Siboni (1992) model sequences of Unix shell commands for network intrusion detection. Anomaly detection has been demonstrated using deep belief networks on the KDD Cup 1999 dataset (Alrawashdeh and Purdy 2016), and Bivens et al. (2002) use multi-layer perceptrons for the DARPA 1999 dataset. Both approaches use aggregated features and synthetic network data. Tuor et al. (2017) andVeeramachaneni et al. (2016) both employ deep neural network autoencoders for unsupervised network anomaly detection using time aggregated statistics as features.</p>
<p>Some works of note have been previously published on the LANL data. Turcotte, Heard and Kent (2016) develop an online statistical model for anomaly detection in network activity using Multinomial-Dirichlet models. Similarly, Turcotte et al. (2016) use Poission Factorization (Gopalan, Hofman, and Blei 2013) on the LANL authentication logs. A user/computer authentication count matrix is constructed by assuming each count comes from a Poisson distribution parameterized by latent factors for users and computers. The learned distributions are then used to predict unlikely authentication behavior.</p>
<p>Several variants of tiered recurrent networks have been explored in the machine learning and natural language processing communities (Koutnik et al. 2014;Ling et al. 2015b;Ling et al. 2015a;Chung et al. 2015). They are often realized by a lower tier pre-processing network, whose output is fed to an upper tier network and the separate tiers are jointly trained. Ling et al. (2015b) use a character-level convolutional neural network to feed a word level long short-term memory (LSTM) RNN for machine translation, with predictions made at the word-level. Both Hwang and Sung (2016) and Ling et al. (2015a) use a character-based LSTM to feed a second word or utterance-based LSTM for language modeling. Pascanu et al. (2015) create activity models from real world data on a per-event (command) basis and sequences of system calls are then modeled using RNN and echo state networks. The learned features are used to independently train neural network and logistic regression classifiers. Max pooling is applied to hidden layers of the unsupervised RNN for each time step in a session and the result is concatenated to the final hidden state to produce feature vectors for the classifier. This is similar to our tiered approach, in which we use the average of all hidden states concatenated with the final hidden state as input to the upper-tier RNN. In contrast, our model is completely unsupervised and all components are jointly trained.</p>
<p>Approach</p>
<p>Our approach learns normal behavior for users, processing a stream of computer and network log-lines as follows: 1. Initialize model weights randomly 2. For each day k in chronological order:</p>
<p>(a) Given model M k−1 , produce log-line-level anomaly scores for all events in day k (b) Optionally, produce an aggregated anomaly score each user for day k (from the log-line-level scores) (c) Send per-user-day or per-user-event anomaly scores in rank order to analysts for inspection (d) Update model weights to minimize loss on all log-lines in day k, yielding model M k</p>
<p>This methodology interleaves detection and training in an online fashion. In this section we detail the components of our approach.</p>
<p>Log-Line Tokenization</p>
<p>To work directly from arbitrary log formats, we treat loglines as sequences of tokens. For this work, we consider two tokenization granularities: word-level and character-level.</p>
<p>For word tokenization, we assume that tokens in the logline are delimited by a known character (e.g., space or comma). After splitting the log-lines on this delimiter, we define a shared vocabulary of "words" over all log fields, consisting of the sufficiently-frequent tokens appearing in the training set. To allow our model to handle previously unseen tokens, we add an "out of vocbulary" token to our vocabulary, <oov>. (For instance, not every IP address will be represented in a training set; likewise, new PCs and users are continually being added to large networks.) To ensure that <oov> has non-zero probability, we replace sufficiently infrequent tokens in the training data with <oov>. During evaluation, tokens not seen before are labeled <oov>. In order to accommodate shifting word distributions in an online environment, a fixed size vocabulary could be periodically updated using a sliding window of word frequency statistics. For simplicity, we assume we have a fixed training set from which we produce a fixed vocabulary.</p>
<p>To avoid the challenges of managing a word-level vocabulary, we also develop language models using a characterlevel tokenization. In this case our primitive vocabulary, the alphabet of printable ASCII characters, circumvents the open vocabulary issue by its ability to represent any log entry irrespective of the network, logging source, or log field. With character-level tokenization, we keep the delimiter token in the sequence, to provide our models with cues to transitions between log-line fields.</p>
<p>Recurrent Neural Network Language Models</p>
<p>To produce log-line-level anomaly scores, we use recurrent neural networks in two ways: 1) as a language model over individual log-lines, and 2) to model the state of a user over time. We first present two recurrent models that focus only on (1), and then a tiered model that accomplishes both (1) and (2). Both were implemented 1 for our experiments using TensorFlow (Abadi et al. 2015).</p>
<p>Event Model (EM). First we consider a simple RNN model that operates on the token (e.g., word) sequences of individual log-lines (events). Specifically, we consider a Long Short-Term Memory (LSTM) (Hochreiter and Schmidhuber 1997) network whose inputs are token embeddings and from whose output we predict distributions over the next token.</p>
<p>For a log-line with K tokens, each drawn from a shared vocabulary of size C, let X (1:K) = x (1) , x (2) , . . . , x (K) denote a sequence of one-hot representations of the tokens (each x (t) ∈ R C ).</p>
<p>In this model, the hidden representation at token t, h (t) , from which we make our predictions, is a function of x (1) , x (2) , . . . , x (t) according to the usual LSTM equations:
h (t) = o (t) • tanh(c (t) ) (1) c (t) = f (t) • c (t−1) + i (t) • g (t)
(2)
g (t) = tanh x (t) W (g,x) + h (t−1) W (g,h) + b (g) (3) f (t) = σ x (t) W (f,x) + h (t−1) W (f,h) + b (f ) (4) i (t) = σ x (t) W (i,x) + h (t−1) W (i,h) + b (i)(5)o (t) = σ x (t) W (o,x) + h (t−1) W (o,h) + b (o) ,(6)
where the initial hidden and cell states, c (0) and h (0) , are set to zero vectors, and • and σ denote element-wise multiplication and logistic sigmoid, respectively. Vector g (t) is a hidden representation based on the current input and previous hidden state, while vectors f (t) , i (t) , and o (t) , are the standard LSTM gates. The matrices (W) and bias vectors (b) are the model parameters. We use each h (t−1) to produce a probability distribution p (t) over the token at time t, as follows:
p (t) = softmax h (t−1) W (p) + b (p)(7)
1 Code will soon be available at https://github.com/pnnl/safekit We use cross-entropy loss,
LSTM LSTM … softmax softmax LSTM x (K-1) softmax p (2) p (K) LSTM LSTM LSTM x (1) x (3) x (2) <eos> LSTM softmax p (K-1) LSTM x (K-2) x (K) p(1 K K t=1 H(x (t) , p (t) ),(8)
for two important purposes: first, as per-log-line anomaly score and second, as the training objective to update model weights. We train this model using stochastic mini-batch (non-truncated) back-propagation through time.</p>
<p>Bidirectional Event Model (BEM). Following the language model formulation suggested in (Schuster and Paliwal 1997), we alternatively model the structure of log lines with a bidirectional LSTM. We define a new set of hidden vec-
tors h b (K+1) , h b (K) , . . . , h b
(1) by running the LSTM equations backwards in time (starting with initial zero cell and hidden states at time K + 1 set to zero). The weights W and biases b for the backward LSTM are denoted with superscript b.</p>
<p>The probability distribution p (t) over the token at time t is then:
p (t) = softmax h (t−1) W (p) + h b (t+1) W b (p) + b (p) (9)
Tiered Event Models (T-EM, T-BEM). To incorporate inter-log-line context, we propose a two-tiered recurrent neural network. The lower-tier can be either event model (EM or BEM), but with the additional input of a context vector (generated by the upper-tier) concatenated to the token embedding at each time step. The input to the upper-tier model is the hidden states of the lower-tier model. This upper tier models the dynamics of user behavior over time, producing the context vectors provided to the lower-tier RNN. This model is illustrated in Fig. 2. In this model, x (u,j) denotes user u's jth log line, which consists of a sequence of tokens as described in the previous subsections. The upper-tier models a sequence of user log lines, x (u,1) , x (u,2) , . . . , x (u,Tu) , using an LSTM. For each user u and each log line j in the user's log line sequence, a lower-tier LSTM is applied to the tokens of x (u,j) . The input to the upper-tier model at log-line j is the concatenation of: 1) the final lower-tier hidden state(s) and 2) the average of the lower-tier hidden states. In the case of a lower-tier EM, (1) refers to the hidden state at time K; for the BEM, (1) is the concatenation of the forward hidden state at time K and the backward hidden state at time 1. For (2), we average over hidden states primarily to provide many short-cut connections in the LSTM, which aids trainability. The output of the upper-tier LSTM at log-line j is a hidden statê h (u,j) . This hidden vector serves to provide context for the lower-tier model at the next time step: specifically,ĥ (u,j−1) is concatenated to each of the inputs of the lower-tier model operating on the jth log-line. Note that the upper-tier model serves only to propagate context information across individual log-lines; no loss is computed directly on the values produced by the upper-tier model. The upper-and lower-tier models are trained jointly to minimize the cross-entropy loss of the lower-tier model. We unroll the two-tier model for a fixed number of log-lines, fully unrolling each of the lower-tier models within that window. The lower-tier model's cross-entropy loss is also used to detect anomalous behavior, as is described further in Section 4.2.</p>
<p>Minibatching becomes more challenging for the tiered model, as the number of log-lines per day can vary dramatically between users. This poses two problems: first, it introduces the possibility that the most active users may have a disproportionate impact on model weights; second, it means that toward the end of the day, there may not be enough users to fill the minibatch. To counteract the first problem, we fix the number of log-lines per user per day that the model will train on. The remaining log-lines are not used in any gradient updates. We leave compensating for the inefficiency that results from the second to future work.</p>
<p>Baselines</p>
<p>Anomaly detection in streaming network logs often relies upon computing statistics over windows of time and applying anomaly detection techniques to those vectors. Below we describe the aggregate features and two anomaly detection techniques that are typical of prior work.</p>
<p>Aggregate Features</p>
<p>We first define the set of per-userday features, which summarize users' activities in the day. To aggregate the features that have a small number of distinct values (e.g. success/failure, logon orientation) we count the number of occurrences for each distinct value for the user-day. For fields that have a larger number of distinct values (pcs, users, domains), we count the number of common and uncommon events that occurred, rather than the number of occurrences of each distinct value (this approach avoids high dimensional sparse features). Furthermore, we define two categories of common/uncommon; to the individual entity/user, and relative to all users. A value is defined as uncommon for the user if it accounts for fewer than 5% of the values observed in that field (up to that point in time), and common otherwise. A value is defined as uncommon for all users if it occurs fewer times than the average value for the field, and common otherwise.</p>
<p>For the LANL dataset, the prior featurization strategy yields a 108-dimensional aggregate feature vector per userday. These feature vectors then serve as the input to the baseline models described next.</p>
<p>Models We consider two baseline models. The first uses Principal Components Analysis (pca) to learn a low dimensional representation of the aggregate features; the anomaly score is proportional to the reconstruction error after mapping the compressed representation back into the original dimension (Shyu et al. 2003). The second is an isolation forest (iso) based approach (Liu, Ting, and Zhou 2008) as implemented in scikit-learn's outlier detection tools (Pedregosa et al. 2011). This was noted as the best performing anomaly detection algorithm in the recent DARPA insider threat detection program, (Gavai et al. 2015).</p>
<p>Experiments</p>
<p>In this section we describe experiments to evaluate the effectiveness of the proposed event modeling algorithms.</p>
<p>Data</p>
<p>The Los Alamos National Laboratory (LANL) Cyber Security Dataset (Kent 2016) consists of event logs from LANL's internal computer network collected over a period of 58 consecutive days. The data set contains over one billion loglines from authentication, process, network flow, and DNS logging sources. Identifying fields (e.g., users, computers, and processes) have been anonymized.</p>
<p>The recorded network activities included both normal operational network activity as well as a series of red team activities that compromised account credentials over the first 30 days of data. Information about known red team attack events is used only for evaluation; our approach is strictly unsupervised.</p>
<p>For the experiments presented in this paper, we rely only on the authentication event logs, whose fields and statistics are summarized in Figure 3a. We filter these events to only those log-lines linked to an actual user, removing computercomputer interaction events. Events on weekends and holidays contain drastically different frequencies and distributions of activities. In a real deployment a separate model would be trained for use on those days, but because no malicious events were in that data it was also withheld. Table 3b has statistics of our data split; the first 12 days serve as the development set, while the remaining 18 days are the independent test set.</p>
<p>Assessment Granularity</p>
<p>Our model learns normal behavior and assigns relatively high loss to events that are unexpected. A principal advantage of our approach is this ability to score the anomaly of  individual events, allowing us to flag at the event-level or aggregate anomalies over any larger timescale. For this work, we consider two timescales. First, we assess based on individual events; a list of events would be presented to the analyst, sorted descending by anomaly score. Second, to facilitate comparison with traditional aggregation methods, we aggregate anomaly scores over all of a user's events for the day (specifically, taking the max), producing a single anomaly score per-user, per-day. In this scenario, a list of user-days would be provided to the analyst, sorted descending by anomaly score. We refer to this approach as max, because the anomaly scores provided to the analyst are produced by taking the maximum score over the event scores in the window for that user (where event-level scoring is just taking the max over a singleton set of one event).</p>
<p>In order to counter systematic offsets in users' anomaly scores for a day we also consider a simple normalization strategy, which we refer to as diff, by which every raw score is first normalized by subtracting the user's average event-level anomaly score for the day.</p>
<p>Metrics</p>
<p>We consider two performance metrics. First, we assess results using the standard area under the receiver operator characteristic curve (AUC) which characterizes the trade-off in model detection performance between true positives and false positives, effectively sweeping through all possible analyst budgets. False positives are detections that are not truly red team events, while true positives are detections that are.</p>
<p>To quantify the proportion of the data the analyst must sift through to diagnose malicious behavior on the network, we use the Average Percentile (AP) metric. Specifically, for each red team event or user-day, we note the percentile of its anomaly amongst all anomaly scores for the day. We then average these percentiles for all of the malicious events or  user-days. Note that if all true malicious events or user-days are flagged as the most anomalous on the respective days, then AP ≈ 100, while if all malicious events or user-days are ranked as the least anomalous on their respective days, AP ≈ 0. For both AUC and AP, a higher score is better.</p>
<p>Our model hyperparameters were manually tuned to maximize AP for day-level diff scores on the development set. No separate training set is needed as our approach is unsupervised and trained online.</p>
<p>Results and Analysis</p>
<p>We begin by exploring the user-day granularity performance. Table 1 summarizes model detection performance at this granularity on the test set for the AUC and AP metrics using the diff method to produce day level scores from the language models. A few trends are evident from these results. First, the aggregate feature baselines have nearequivalent performance by both metrics, with the isolation forest approach having a slight edge. We hypothesize the feature representation, which is common to these methods, could be a bottleneck in performance. This highlights the "blind spot" issue feature engineering introduces. Second, despite having only the context of a single log-line at a time, as opposed to features aggregated over an entire day, the event model (EM) performs comparably to the baseline models when a forward pass LSTM network is used with  a character tokenization and outperforms the baselines with word tokenization. The most pronounced performance gain results from using bidirectional models. Finally, word-level tokenization performs better than character-level; however, even the bidirectional character models perform appreciably better than the baselines. It is clear from these results that the tiered models perform comparably to, but not better than, the event-level models. This suggests that the event level model is able to characterize normal user behavior from information stored in the model weights of the network, which are trained each day to model user activity. Given the context of the past day's activity stored in the model weights, the categorical variables represented by the fields in an individual log line may eliminate the need for explicit event context modeling. We leave tracking the state of individual computers, rather than users, to future work, but hypothesize that it may make the tiered approach more effective.</p>
<p>Next, we broaden our analysis of language modeling approaches, comparing performance across all language models, tokenization strategies, anomaly granularity, and normalization techniques. Figure 4 plots AUC for all language model types using word tokenization, contrasting max and diff normalization modes. Figure 5 compares the same variations for character tokenization. Table 2 presents these results in tabular form. With few exceptions, log-line-level granularity vastly outperforms day-level; this is true for both the character-level and word-level tokenization strategies, with an average gain of 0.1 AUC. The most interesting outcome of these comparisons is that word tokenization performance gains are heavily reliant on the diff normalization, whereas for character tokenization the diff normalization has a minor detrimental effect for some models. This suggests that the character-level model could be used to provide a more immediate response time, not having to wait until the day is done to obtain the day statistics used in diff mode. The two tokenization strategies may in fact be complementary as the versatility and response time gains of a character tokenization come at the expense of easy interpretibility of a word tokenization: the word tokenization allows anomaly scores to be decomposed into individual log-line fields, enabling analysts to pinpoint features of the event that most contributed to it being flagged. Since we tuned hyperparameters using diff mode, the character-level model has potential to do better with additional tuning.</p>
<p>Next, Figures 6 and 7 visualize the average percentiles of red team detections for the subset of the test set with the most red-team activity. Anomaly scores for both word and character tokenizations are computed without average userday offset normalization. Red team log-line-level scores are plotted as purple x's with the x coordinate being the second in time at which the event occurred and y coordinate the anomaly score for that event. Percentile ranges are colored to provide context for the red-team anomaly scores against the backdrop of other network activity. The spread of non-normalized anomaly scores is much greater for the word-level tokenizations (Fig. 7) than character-level (Fig.  6), which could explain the different sensitivity of word level tokenization to normalization. Also notice that there is an expected bump in percentiles for windows of frequent redteam activity. Curiously, at the end of day 14 there are massive bumps for the 99th percentile, which suggest unplanned and un-annotated anomalous events on the LANL network for those hours. Notice that for the character tokenization almost all non-normalized red team anomaly scores are above the 95th percentile, with a large proportion above the 99th percentile.</p>
<p>Finally, Figure 8 plots the ROC curves for the best aggregate baseline (iso), the best user-day granularity language model (word BEM), and the best event-level granularity model (character BEM). It illustrates the qualitatively different curves obtained with the baselines, the user-day granularity, and the event-level granularity.</p>
<p>Since the proportion of red-team to normal events is vanishingly low in the data-set (&lt; 0.001%), the false-positive rate is effectively the proportion of data flagged to achieve a particular recall. From this observation, Figure 8 shows the character event model can achieve 100% recall from only 12% of the data whereas the other models considered only achieve 100% recall when nearly all of the data has been  Figure 6: Character-level red-team log-line anomaly scores in relation to percentiles over time. Figure 7: Word-level red-team log-line anomaly scores in relation to percentiles over time. handed to the analyst. Further, the character event model can achieve 80% recall by flagging only 3% of the data whereas the word day language model needs 14% of the data and the aggregate isolation forest model needs 55% of the data to achieve the same result.</p>
<p>Conclusion</p>
<p>This work builds upon advances in language modeling to address computer security log analysis, proposing an unsupervised, online anomaly detection approach. We eliminate the usual effort-intensive feature engineering stage, making our approach fast to deploy and agnostic to the system configuration and monitoring tools. It further confers the key advantage of event-level detection which allows for a near immediate alert response following anomalous activity.</p>
<p>In experiments using the Los Alamos National Laboratory Cyber Security Dataset, bidirectional language models significantly outperformed standard methods at day-level detection. The best log-line-level detection performance was achieved with a bidirectional character-based language model, obtaining a 0.98 area under the ROC curve, showing that for the constrained language domain of network logs, character based language modeling can achieve comparable accuracy to word based modeling for event level detection. We have therefore demonstrated a simple and effective approach to modeling dynamic networks with open vocabulary logs (e.g. with new users, PCs, or IP addresses).</p>
<p>We propose to extend this work in several ways. First, potential modeling advantages of tiered architectures merit further investigation. The use of tiered architectures to track PCs instead of network users, or from a richer set of logging sources other than simply authentication logs may take better advantage of their modeling power. Next, we anticipate interpretability can become lost with such detailed granularity provided by log-line-level detection from a characterbased model, therefore future work will explore alternate methods of providing context to an analyst. Finally, we are interested in exploring the robustness of this approach to adversarial tampering. Similarly performing models could have different levels of resilience that would lead to selection of one over another.</p>
<p>Figure 1 :
1Event Models. Set of black bordered nodes and connections illustrate the EM model while set of all nodes and connections illustrate the BEM model.</p>
<p>Figure 2 :
2Tiered Event Model (T-EM)</p>
<p>Figure 3 :
3Dataset statistics: (a) Authentication log fields and statistics and (b) dataset splits.</p>
<p>of AUC for day-level and log-line-level analysis with and without user-day normalization. Figures 4 and 5 provide a visualization of these results.</p>
<p>Figure 4 :Figure 5 :
45Word model comparison of AUC at day-level and log-line-level granularities. Character model comparison of AUC at day-level and log-line-level granularities.</p>
<p>Figure 8 :
8ROC curves for best performing baseline, word language model evaluated at day-granularity, and character language model evaluated at log-line-granularity.
Acknowledgments The research described in this paper is part of the Analysis in Motion Initiative at Pacific Northwest National Laboratory. It was conducted under the Laboratory Directed Research and Development Program at PNNL, a multi-program national laboratory operated by Battelle for the U.S. Department of Energy. The authors would also like to thank the Nvidia corporation for their donations of Titan X and Titan Xp GPUs used in this research.
. [ References, Abadi, References [Abadi et al. 2015] Abadi, M.; Agarwal, A.; Barham, P.; Brevdo, E.; Chen, Z.; Citro, C.; Corrado, G. S.; Davis, A.; Dean, J.; Devin, M.; Ghemawat, S.; Goodfellow, I.; Harp, A.; Irving, G.; Isard, M.; Jia, Y.; Jozefowicz, R.; Kaiser, L.; Kudlur, M.; Levenberg, J.; Mané, D.; Monga, R.; Moore, S.;</p>
<p>TensorFlow: Largescale machine learning on heterogeneous systems. Software available from tensorflow.org. D Murray, C Olah, M Schuster, J Shlens, B Steiner, I Sutskever, K Talwar, P Tucker, V Vanhoucke, V Vasudevan, F Viégas, O Vinyals, P Warden, M Wattenberg, M Wicke, Y Yu, X Zheng, K Alrawashdeh, C Purdy, D K Bhattacharyya, J K Kalita, Network anomaly detection: A machine learning perspective. CRC PressMachine Learning and Applications (ICMLA)Murray, D.; Olah, C.; Schuster, M.; Shlens, J.; Steiner, B.; Sutskever, I.; Talwar, K.; Tucker, P.; Vanhoucke, V.; Vasude- van, V.; Viégas, F.; Vinyals, O.; Warden, P.; Wattenberg, M.; Wicke, M.; Yu, Y.; and Zheng, X. 2015. TensorFlow: Large- scale machine learning on heterogeneous systems. Software available from tensorflow.org. [Alrawashdeh and Purdy 2016] Alrawashdeh, K., and Purdy, C. 2016. Toward an online anomaly intrusion detection system based on deep learning. In Machine Learning and Applications (ICMLA), 2016 15th IEEE International Con- ference on, 195-200. IEEE. [Bhattacharyya and Kalita 2013] Bhattacharyya, D. K., and Kalita, J. K. 2013. Network anomaly detection: A machine learning perspective. CRC Press.</p>
<p>Networkbased intrusion detection using neural networks. Bivens, Intelligent Engineering Systems through Artificial Neural Networks. 121[Bivens et al. 2002] Bivens, A.; Palagiri, C.; Smith, R.; Szy- manski, B.; Embrechts, M.; et al. 2002. Network- based intrusion detection using neural networks. Intelli- gent Engineering Systems through Artificial Neural Net- works 12(1):579-584.</p>
<p>A survey of data mining and machine learning methods for cyber security intrusion detection. A L Buczak, E Guven, Chung, Gated feedback recurrent neural networks. In International Conference on Machine Learning. 18Proc. IEEE Symposium on Research in Security and Privacy[Buczak and Guven 2016] Buczak, A. L., and Guven, E. 2016. A survey of data mining and machine learning meth- ods for cyber security intrusion detection. IEEE Communi- cations Surveys &amp; Tutorials 18(2):1153-1176. [Chung et al. 2015] Chung, J.; Gulcehre, C.; Cho, K.; and Bengio, Y. 2015. Gated feedback recurrent neural networks. In International Conference on Machine Learning, 2067- 2075. [Debar, Becker, and Siboni 1992] Debar, H.; Becker, M.; and Siboni, D. 1992. A neural network component for an intrusion detection system. In Proc. IEEE Symposium on Research in Security and Privacy, 240-250.</p>
<p>Supervised and unsupervised methods to detect insider threat from enterprise social and online activity data. S Dua, X Du, G Gavai, K Sricharan, D Gunning, J Hanley, M Singhal, R Rolleston, Journal of Wireless Mobile Networks, Ubiquitous Computing, and Dependable Applications. 64CRC pressData mining and machine learning in cybersecurityand Du 2016] Dua, S., and Du, X. 2016. Data mining and machine learning in cybersecurity. CRC press. [Gavai et al. 2015] Gavai, G.; Sricharan, K.; Gunning, D.; Hanley, J.; Singhal, M.; and Rolleston, R. 2015. Supervised and unsupervised methods to detect insider threat from en- terprise social and online activity data. Journal of Wireless Mobile Networks, Ubiquitous Computing, and Dependable Applications 6(4):47-63.</p>
<p>Character-level language modeling with hierarchical recurrent neural networks. Hofman Gopalan, P Blei ; Gopalan, J M Hofman, D M Blei, S Hochreiter, J Schmidhuber, K Hwang, W Sung, A D Kent, arXiv:1311.1704arXiv:1609.03777Scalable recommendation with Poisson factorization. Kent937arXiv preprintNeural computation[Gopalan, Hofman, and Blei 2013] Gopalan, P.; Hofman, J. M.; and Blei, D. M. 2013. Scalable recommendation with Poisson factorization. arXiv preprint arXiv:1311.1704. [Hochreiter and Schmidhuber 1997] Hochreiter, S., and Schmidhuber, J. 1997. Long short-term memory. Neural computation 9(8):1735-1780. [Hwang and Sung 2016] Hwang, K., and Sung, W. 2016. Character-level language modeling with hierarchical recur- rent neural networks. arXiv preprint arXiv:1609.03777. [Kent 2016] Kent, A. D. 2016. Cyber security data sources for dynamic network research. Dynamic Networks and Cyber-Security 1:37.</p>
<p>. [ Koutnik, arXiv:1402.3511A clockwork RNN. arXiv preprint[Koutnik et al. 2014] Koutnik, J.; Greff, K.; Gomez, F.; and Schmidhuber, J. 2014. A clockwork RNN. arXiv preprint arXiv:1402.3511.</p>
<p>The use of artificial intelligence based techniques for intrusion detection: a review. Kumar Kumar, G Kumar, K Kumar, M Sachdeva, Artificial Intelligence Review. 344Kumar, Kumar, and Sachdeva 2010] Kumar, G.; Kumar, K.; and Sachdeva, M. 2010. The use of artificial intelligence based techniques for intrusion detection: a review. Artificial Intelligence Review 34(4):369-387.</p>
<p>Ling, arXiv:1508.02096Finding function in form: Compositional character models for open vocabulary word representation. arXiv preprint[Ling et al. 2015a] Ling, W.; Luís, T.; Marujo, L.; Astudillo, R. F.; Amir, S.; Dyer, C.; Black, A. W.; and Trancoso, I. 2015a. Finding function in form: Compositional charac- ter models for open vocabulary word representation. arXiv preprint arXiv:1508.02096.</p>
<p>arXiv:1511.04586Character-based neural machine translation. arXiv preprintet al. 2015b] Ling, W.; Trancoso, I.; Dyer, C.; and Black, A. W. 2015b. Character-based neural machine trans- lation. arXiv preprint arXiv:1511.04586.</p>
<p>Studies in applying PCA and wavelet algorithms for network traffic anomaly detection. Ting Zhou, F T Liu, K M Ting, Z.-H Zhou, Novakov, Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on. IEEE12High Performance Switching and Routing (HPSR). Pedregosa et al. 2011. Passos, A.; Cournapeau, D.; Brucher, M.; Perrot, M.; and Duchesnay, E. 2011. Scikit-learn: Machine learning in Python, Ting, and Zhou 2008] Liu, F. T.; Ting, K. M.; and Zhou, Z.-H. 2008. Isolation forest. In Proc. ICDM. [Novakov et al. 2013] Novakov, S.; Lung, C.-H.; Lam- badaris, I.; and Seddigh, N. 2013. Studies in applying PCA and wavelet algorithms for network traffic anomaly detection. In High Performance Switching and Routing (HPSR), 2013 IEEE 14th International Conference on, 185- 190. IEEE. [Pascanu et al. 2015] Pascanu, R.; Stokes, J. W.; Sanossian, H.; Marinescu, M.; and Thomas, A. 2015. Malware classi- fication with recurrent networks. In Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Con- ference on, 1916-1920. IEEE. [Pedregosa et al. 2011] Pedregosa, F.; Varoquaux, G.; Gram- fort, A.; Michel, V.; Thirion, B.; Grisel, O.; Blondel, M.; Prettenhofer, P.; Weiss, R.; Dubourg, V.; Vanderplas, J.; Pas- sos, A.; Cournapeau, D.; Brucher, M.; Perrot, M.; and Duch- esnay, E. 2011. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research 12:2825-2830.</p>
<p>Anomaly detection for cyber security applications. Dynamic Networks and Cyber-Security 1:137. Ringberg, SIGMETRICS. 45Bidirectional recurrent neural networks[Ringberg et al. 2007] Ringberg, H.; Soule, A.; Rexford, J.; and Diot, C. 2007. Sensitivity of PCA for traffic anomaly detection. In SIGMETRICS. [Rubin-Delanchy, Lawson, and Heard 2016] Rubin- Delanchy, P.; Lawson, D. J.; and Heard, N. A. 2016. Anomaly detection for cyber security applications. Dy- namic Networks and Cyber-Security 1:137. [Schuster and Paliwal 1997] Schuster, M., and Paliwal, K. K. 1997. Bidirectional recurrent neural networks. IEEE Trans- actions on Signal Processing 45(11):2673-2681.</p>
<p>Outside the closed world: On using machine learning for network intrusion detection. [ Shyu, Proc. Symposium on Security and Privacy. Symposium on Security and PrivacyProc. ICDM[Shyu et al. 2003] Shyu, M.-L.; Chen, S.-C.; Sarinnapakorn, K.; and Chang, L. 2003. A novel anomaly detection scheme based on principal component classifier. In Proc. ICDM. [Sommer and Paxson 2010] Sommer, R., and Paxson, V. 2010. Outside the closed world: On using machine learn- ing for network intrusion detection. In Proc. Symposium on Security and Privacy.</p>
<p>Deep learning for unsupervised insider threat detection in structured cybersecurity data streams. Artificial Intelligence for Cybersecurity Workshop at AAAI. et al. 2017] Tuor, A.; Kaplan, S.; Hutchinson, B.; Nichols, N.; and Robinson, S. 2017. Deep learning for un- supervised insider threat detection in structured cybersecu- rity data streams. In Artificial Intelligence for Cybersecurity Workshop at AAAI.</p>
<p>Poisson factorization for peer-based anomaly detection. Turcotte, Intelligence and Security Informatics (ISI), 2016 IEEE Conference on. IEEETurcotte et al. 2016] Turcotte, M.; Moore, J.; Heard, N.; and McPhall, A. 2016. Poisson factorization for peer-based anomaly detection. In Intelligence and Security Informat- ics (ISI), 2016 IEEE Conference on, 208-210. IEEE.</p>
<p>Modelling user behavior in a network using computer event logs. Dynamic Networks and Cyber-Security 1:67. Heard Turcotte, M J Kent ; Turcotte, N A Heard, A D Kent, K Veeramachaneni, I Arnaldo, V Korrapati, C Bassias, K Li, R Zuech, T M Khoshgoftaar, Wald , R , Proc. HPSC and IDS. [Zuech, Khoshgoftaar, and Wald. HPSC and IDS. [Zuech, Khoshgoftaar, and Wald23Intrusion detection and big heterogeneous data: a surveyTurcotte, Heard, and Kent 2016] Turcotte, M. J.; Heard, N. A.; and Kent, A. D. 2016. Modelling user behavior in a network using computer event logs. Dynamic Networks and Cyber-Security 1:67. [Veeramachaneni et al. 2016] Veeramachaneni, K.; Arnaldo, I.; Korrapati, V.; Bassias, C.; and Li, K. 2016. AI 2 : Training a big data machine to defend. In Proc. HPSC and IDS. [Zuech, Khoshgoftaar, and Wald 2015] Zuech, R.; Khosh- goftaar, T. M.; and Wald, R. 2015. Intrusion detection and big heterogeneous data: a survey. Journal of Big Data 2(1):3.</p>            </div>
        </div>

    </div>
</body>
</html>