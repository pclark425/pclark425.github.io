<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6949 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6949</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6949</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-134.html">extraction-schema-134</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform self‑reflection or self‑critique, including the specific reflection method, number of generate‑then‑reflect iterations, tasks or benchmarks evaluated, performance before and after reflection, evaluation metrics, and any reported limitations or failure cases.</div>
                <p><strong>Paper ID:</strong> paper-270391870</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2406.08434v1.pdf" target="_blank">TasTe: Teaching Large Language Models to Translate through Self-Reflection</a></p>
                <p><strong>Paper Abstract:</strong> Large language models (LLMs) have exhibited remarkable performance in various natural language processing tasks. Techniques like instruction tuning have effectively enhanced the proficiency of LLMs in the downstream task of machine translation. However, the existing approaches fail to yield satisfactory translation outputs that match the quality of supervised neural machine translation (NMT) systems. One plausible explanation for this discrepancy is that the straightforward prompts employed in these methodologies are unable to fully exploit the acquired instruction-following capabilities. To this end, we propose the TasTe framework, which stands for translating through self-reflection. The self-reflection process includes two stages of inference. In the first stage, LLMs are instructed to generate preliminary translations and conduct self-assessments on these translations simultaneously. In the second stage, LLMs are tasked to refine these preliminary translations according to the evaluation results. The evaluation results in four language directions on the WMT22 benchmark reveal the effectiveness of our approach compared to existing methods. Our work presents a promising approach to unleash the potential of LLMs and enhance their capabilities in MT. The codes and datasets are open-sourced at https://github.com/YutongWang1216/ReflectionLLMMT.</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6949.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6949.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform self‑reflection or self‑critique, including the specific reflection method, number of generate‑then‑reflect iterations, tasks or benchmarks evaluated, performance before and after reflection, evaluation metrics, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TASTE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>TASTE: Teaching Large Language Models to Translate through Self-Reflection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A two-stage self-reflection framework for LLM machine translation where the model (1) generates a draft translation and predicts its quality (label or score) and (2) refines the draft conditioned on that predicted quality to produce a final translation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BLOOMZ-7b1-mt; LLaMA-2-7b</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Transformer-based large language models (instruction-tuned backbones). Both were fine-tuned via supervised multi-task instruction tuning on Basic Translation, Quality Prediction (TC or QE), and Draft Refinement tasks; training used either full-parameter tuning or fixing the embedding layer (FixEmb).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_name</strong></td>
                            <td>TASTE two-stage self-reflection (Draft Generation + Quality Prediction → Draft Refinement)</td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_description</strong></td>
                            <td>Stage 1: generate a preliminary translation (draft) and simultaneously predict its quality (either classification label: Good/Medium/Bad, or a QE integer score 0–100). Stage 2: feed the draft plus its predicted quality into a second prompt and have the model refine the draft into a final translation.</td>
                        </tr>
                        <tr>
                            <td><strong>iteration_type</strong></td>
                            <td>generate-then-reflect (two-stage)</td>
                        </tr>
                        <tr>
                            <td><strong>num_iterations</strong></td>
                            <td>1</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Machine Translation (WMT-related evaluation; WMT22 test sets; languages: Zh⇔En and De⇔En)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Standard machine translation on WMT test domains (news, social, e-commerce, conversation); evaluation on German⇔English and Chinese⇔English directions.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>BLEU (SacreBLEU) and COMET (wmt22-comet-da)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_before_reflection</strong></td>
                            <td>MT-FixEmb baseline (no reflection): BLEU 19.41, COMET 72.06 (reported baseline in paper comparisons)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_after_reflection</strong></td>
                            <td>TASTE (FixEmb, with two-stage reflection): BLEU 21.98, COMET 76.38 (reported improvement over MT-FixEmb baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>improvement_observed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Authors report heterogeneous gains across translation directions (inconsistent improvements likely due to uneven multilingual knowledge); extra compute cost (two-stage inference roughly doubles inference time); performance depends on accuracy of quality prediction; manipulations of predicted labels degrade refinement (setting all labels to 'Good', 'Bad', random, or removing labels caused worse COMET and larger/smaller edit behaviors); 'Good' drafts show minimal improvement while 'Bad' drafts gain the most (per-label ∆COMET: Good +0.45, Medium +2.06, Bad +7.79 for LLaMA-2-7b Zh⇒En); quality-prediction signals are essential (removing Quality Prediction training caused largest BLEU drop in ablation); freezing embedding layer (FixEmb) was important — full-parameter tuning yielded worse generalization/overfitting in experiments; some specific failure cases remain (e.g., severe lexical/syntactic errors in drafts that are only partially fixed).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'TasTe: Teaching Large Language Models to Translate through Self-Reflection', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6949.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6949.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform self‑reflection or self‑critique, including the specific reflection method, number of generate‑then‑reflect iterations, tasks or benchmarks evaluated, performance before and after reflection, evaluation metrics, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Quality Prediction (TC / QE)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Self Quality Prediction: Text Classification (TC) and Quality Estimation (QE)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Subtasks used within TASTE where the model, while generating a draft, also predicts either a coarse quality label (Good/Medium/Bad — TC) or a continuous integer score (0–100 — QE) to guide refinement.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BLOOMZ-7b1-mt; LLaMA-2-7b</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Same fine-tuned backbones as TASTE; models are trained to produce translations and quality predictions jointly as part of multitask SFT.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_name</strong></td>
                            <td>Quality Prediction (TC / QE) used as guidance signal</td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_description</strong></td>
                            <td>During draft generation, the model produces an assessment: either a categorical quality label (TC: Good/Medium/Bad) or a numerical score (QE: 0–100, COMET-scaled). The predicted quality is included in the Stage 2 prompt to steer the draft refinement.</td>
                        </tr>
                        <tr>
                            <td><strong>iteration_type</strong></td>
                            <td>generate-then-reflect (guidance signal produced alongside generation)</td>
                        </tr>
                        <tr>
                            <td><strong>num_iterations</strong></td>
                            <td>1</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Quality prediction as part of MT pipeline (WMT multi-candidate training data; evaluated on WMT22 splits)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Predict quality of candidate translations (labels or scores) while generating translations, used both as an auxiliary training task and as a control signal for refinement.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>For TC: precision/recall/F1 (weighted macro across Good/Medium/Bad); For QE: Pearson correlation (r) vs COMET; also compared to perplexity correlation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_before_reflection</strong></td>
                            <td>Not applicable as standalone 'before' value; reported baseline comparisons show perplexity correlates poorly with COMET.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_after_reflection</strong></td>
                            <td>Reported metrics for quality prediction: TC F1 values > 67.6 (weighted F1); QE predictions show significant Pearson correlation with gold COMET scores (p < 0.01). LLaMA-2 outperformed BLOOMZ in QE and TC accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>improvement_observed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Quality estimates are imperfect (TC still only ~67–70 F1); errors in predicted labels can harm refinement — experiments that set, randomized, or removed labels caused COMET decreases; QE and TC performed similarly overall (no clear winner), indicating limits to granularity benefit.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'TasTe: Teaching Large Language Models to Translate through Self-Reflection', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6949.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6949.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform self‑reflection or self‑critique, including the specific reflection method, number of generate‑then‑reflect iterations, tasks or benchmarks evaluated, performance before and after reflection, evaluation metrics, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Draft Refinement</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Draft Refinement (Stage 2 of TASTE)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The model receives a draft translation plus its predicted quality label/score and produces a refined final translation; aims to correct errors and reduce hallucinated/unaligned words.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-2-7b (primary analysis); BLOOMZ-7b1-mt also evaluated</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Fine-tuned LLMs apply a second-stage prompt that contains the draft and its quality tag to generate a revised translation.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_name</strong></td>
                            <td>Draft Refinement (guided revision using model's own quality prediction)</td>
                        </tr>
                        <tr>
                            <td><strong>reflection_method_description</strong></td>
                            <td>One-shot refinement: feed draft + predicted quality into a second prompt; model rewrites/edits the draft into a higher-quality translation.</td>
                        </tr>
                        <tr>
                            <td><strong>iteration_type</strong></td>
                            <td>single-step refinement (generate→refine)</td>
                        </tr>
                        <tr>
                            <td><strong>num_iterations</strong></td>
                            <td>1</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Refinement of model-generated drafts on WMT22 translation directions (analysis mainly Zh⇒En)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Measure improvement from preliminary draft to refined translation (COMET, UTW, edit distance).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>COMET for quality changes; Unaligned Translation Words (UTW) percentage for hallucination; average Levenshtein-based edit distance between draft and refined outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_before_reflection</strong></td>
                            <td>Preliminary drafts (stage 1) baseline COMET distribution; exact aggregate baseline varies by model/direction (example: many drafts had lower COMET scores prior to refinement).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_after_reflection</strong></td>
                            <td>Observed majority of refined outputs have higher COMET than drafts. Reported average COMET increments for LLaMA-2-7b Zh⇒En: Good +0.45, Medium +2.06, Bad +7.79. UTW decreased by >15 percentage points after refinement.</td>
                        </tr>
                        <tr>
                            <td><strong>improvement_observed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Less improvement for drafts already labeled 'Good'; when label signals are removed or corrupted (all 'Good', all 'Bad', random, or blank), performance decreases and edit behaviors change (e.g., when all labels 'Bad' model makes more edits but not necessarily better ones); refinement is bounded by quality-prediction reliability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'TasTe: Teaching Large Language Models to Translate through Self-Reflection', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Iterative translation refinement with large language models <em>(Rating: 2)</em></li>
                <li>Improving llm-based machine translation with systematic self-correction <em>(Rating: 2)</em></li>
                <li>Guiding large language models to post-edit machine translation with error annotations <em>(Rating: 2)</em></li>
                <li>Deliberate then generate: Enhanced prompting framework for text generation <em>(Rating: 2)</em></li>
                <li>Deliberation networks: Sequence generation beyond one-pass decoding <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6949",
    "paper_id": "paper-270391870",
    "extraction_schema_id": "extraction-schema-134",
    "extracted_data": [
        {
            "name_short": "TASTE",
            "name_full": "TASTE: Teaching Large Language Models to Translate through Self-Reflection",
            "brief_description": "A two-stage self-reflection framework for LLM machine translation where the model (1) generates a draft translation and predicts its quality (label or score) and (2) refines the draft conditioned on that predicted quality to produce a final translation.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "BLOOMZ-7b1-mt; LLaMA-2-7b",
            "model_description": "Transformer-based large language models (instruction-tuned backbones). Both were fine-tuned via supervised multi-task instruction tuning on Basic Translation, Quality Prediction (TC or QE), and Draft Refinement tasks; training used either full-parameter tuning or fixing the embedding layer (FixEmb).",
            "model_size": "7B",
            "reflection_method_name": "TASTE two-stage self-reflection (Draft Generation + Quality Prediction → Draft Refinement)",
            "reflection_method_description": "Stage 1: generate a preliminary translation (draft) and simultaneously predict its quality (either classification label: Good/Medium/Bad, or a QE integer score 0–100). Stage 2: feed the draft plus its predicted quality into a second prompt and have the model refine the draft into a final translation.",
            "iteration_type": "generate-then-reflect (two-stage)",
            "num_iterations": 1,
            "task_name": "Machine Translation (WMT-related evaluation; WMT22 test sets; languages: Zh⇔En and De⇔En)",
            "task_description": "Standard machine translation on WMT test domains (news, social, e-commerce, conversation); evaluation on German⇔English and Chinese⇔English directions.",
            "evaluation_metric": "BLEU (SacreBLEU) and COMET (wmt22-comet-da)",
            "performance_before_reflection": "MT-FixEmb baseline (no reflection): BLEU 19.41, COMET 72.06 (reported baseline in paper comparisons)",
            "performance_after_reflection": "TASTE (FixEmb, with two-stage reflection): BLEU 21.98, COMET 76.38 (reported improvement over MT-FixEmb baseline)",
            "improvement_observed": true,
            "limitations_or_failure_cases": "Authors report heterogeneous gains across translation directions (inconsistent improvements likely due to uneven multilingual knowledge); extra compute cost (two-stage inference roughly doubles inference time); performance depends on accuracy of quality prediction; manipulations of predicted labels degrade refinement (setting all labels to 'Good', 'Bad', random, or removing labels caused worse COMET and larger/smaller edit behaviors); 'Good' drafts show minimal improvement while 'Bad' drafts gain the most (per-label ∆COMET: Good +0.45, Medium +2.06, Bad +7.79 for LLaMA-2-7b Zh⇒En); quality-prediction signals are essential (removing Quality Prediction training caused largest BLEU drop in ablation); freezing embedding layer (FixEmb) was important — full-parameter tuning yielded worse generalization/overfitting in experiments; some specific failure cases remain (e.g., severe lexical/syntactic errors in drafts that are only partially fixed).",
            "uuid": "e6949.0",
            "source_info": {
                "paper_title": "TasTe: Teaching Large Language Models to Translate through Self-Reflection",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Quality Prediction (TC / QE)",
            "name_full": "Self Quality Prediction: Text Classification (TC) and Quality Estimation (QE)",
            "brief_description": "Subtasks used within TASTE where the model, while generating a draft, also predicts either a coarse quality label (Good/Medium/Bad — TC) or a continuous integer score (0–100 — QE) to guide refinement.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "BLOOMZ-7b1-mt; LLaMA-2-7b",
            "model_description": "Same fine-tuned backbones as TASTE; models are trained to produce translations and quality predictions jointly as part of multitask SFT.",
            "model_size": "7B",
            "reflection_method_name": "Quality Prediction (TC / QE) used as guidance signal",
            "reflection_method_description": "During draft generation, the model produces an assessment: either a categorical quality label (TC: Good/Medium/Bad) or a numerical score (QE: 0–100, COMET-scaled). The predicted quality is included in the Stage 2 prompt to steer the draft refinement.",
            "iteration_type": "generate-then-reflect (guidance signal produced alongside generation)",
            "num_iterations": 1,
            "task_name": "Quality prediction as part of MT pipeline (WMT multi-candidate training data; evaluated on WMT22 splits)",
            "task_description": "Predict quality of candidate translations (labels or scores) while generating translations, used both as an auxiliary training task and as a control signal for refinement.",
            "evaluation_metric": "For TC: precision/recall/F1 (weighted macro across Good/Medium/Bad); For QE: Pearson correlation (r) vs COMET; also compared to perplexity correlation.",
            "performance_before_reflection": "Not applicable as standalone 'before' value; reported baseline comparisons show perplexity correlates poorly with COMET.",
            "performance_after_reflection": "Reported metrics for quality prediction: TC F1 values &gt; 67.6 (weighted F1); QE predictions show significant Pearson correlation with gold COMET scores (p &lt; 0.01). LLaMA-2 outperformed BLOOMZ in QE and TC accuracy.",
            "improvement_observed": true,
            "limitations_or_failure_cases": "Quality estimates are imperfect (TC still only ~67–70 F1); errors in predicted labels can harm refinement — experiments that set, randomized, or removed labels caused COMET decreases; QE and TC performed similarly overall (no clear winner), indicating limits to granularity benefit.",
            "uuid": "e6949.1",
            "source_info": {
                "paper_title": "TasTe: Teaching Large Language Models to Translate through Self-Reflection",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Draft Refinement",
            "name_full": "Draft Refinement (Stage 2 of TASTE)",
            "brief_description": "The model receives a draft translation plus its predicted quality label/score and produces a refined final translation; aims to correct errors and reduce hallucinated/unaligned words.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "LLaMA-2-7b (primary analysis); BLOOMZ-7b1-mt also evaluated",
            "model_description": "Fine-tuned LLMs apply a second-stage prompt that contains the draft and its quality tag to generate a revised translation.",
            "model_size": "7B",
            "reflection_method_name": "Draft Refinement (guided revision using model's own quality prediction)",
            "reflection_method_description": "One-shot refinement: feed draft + predicted quality into a second prompt; model rewrites/edits the draft into a higher-quality translation.",
            "iteration_type": "single-step refinement (generate→refine)",
            "num_iterations": 1,
            "task_name": "Refinement of model-generated drafts on WMT22 translation directions (analysis mainly Zh⇒En)",
            "task_description": "Measure improvement from preliminary draft to refined translation (COMET, UTW, edit distance).",
            "evaluation_metric": "COMET for quality changes; Unaligned Translation Words (UTW) percentage for hallucination; average Levenshtein-based edit distance between draft and refined outputs.",
            "performance_before_reflection": "Preliminary drafts (stage 1) baseline COMET distribution; exact aggregate baseline varies by model/direction (example: many drafts had lower COMET scores prior to refinement).",
            "performance_after_reflection": "Observed majority of refined outputs have higher COMET than drafts. Reported average COMET increments for LLaMA-2-7b Zh⇒En: Good +0.45, Medium +2.06, Bad +7.79. UTW decreased by &gt;15 percentage points after refinement.",
            "improvement_observed": true,
            "limitations_or_failure_cases": "Less improvement for drafts already labeled 'Good'; when label signals are removed or corrupted (all 'Good', all 'Bad', random, or blank), performance decreases and edit behaviors change (e.g., when all labels 'Bad' model makes more edits but not necessarily better ones); refinement is bounded by quality-prediction reliability.",
            "uuid": "e6949.2",
            "source_info": {
                "paper_title": "TasTe: Teaching Large Language Models to Translate through Self-Reflection",
                "publication_date_yy_mm": "2024-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Iterative translation refinement with large language models",
            "rating": 2,
            "sanitized_title": "iterative_translation_refinement_with_large_language_models"
        },
        {
            "paper_title": "Improving llm-based machine translation with systematic self-correction",
            "rating": 2,
            "sanitized_title": "improving_llmbased_machine_translation_with_systematic_selfcorrection"
        },
        {
            "paper_title": "Guiding large language models to post-edit machine translation with error annotations",
            "rating": 2,
            "sanitized_title": "guiding_large_language_models_to_postedit_machine_translation_with_error_annotations"
        },
        {
            "paper_title": "Deliberate then generate: Enhanced prompting framework for text generation",
            "rating": 2,
            "sanitized_title": "deliberate_then_generate_enhanced_prompting_framework_for_text_generation"
        },
        {
            "paper_title": "Deliberation networks: Sequence generation beyond one-pass decoding",
            "rating": 1,
            "sanitized_title": "deliberation_networks_sequence_generation_beyond_onepass_decoding"
        }
    ],
    "cost": 0.012647499999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>TASTE: Teaching Large Language Models to Translate through Self-Reflection
12 Jun 2024</p>
<p>Yutong Wang wangyutong@stu.hit.edu.cn 
Institute of Computing and Intelligence
Harbin Institute of Technology
ShenzhenChina</p>
<p>Jiali Zeng 
Pattern Recognition Center
Tencent Inc
WeChat AIChina</p>
<p>Xuebo Liu liuxuebo@hit.edu.cn 
Institute of Computing and Intelligence
Harbin Institute of Technology
ShenzhenChina</p>
<p>Fandong Meng fandongmeng@tencent.com 
Pattern Recognition Center
Tencent Inc
WeChat AIChina</p>
<p>Jie Zhou 
Pattern Recognition Center
Tencent Inc
WeChat AIChina</p>
<p>Min Zhang zhangmin2021@hit.edu.cn 
Institute of Computing and Intelligence
Harbin Institute of Technology
ShenzhenChina</p>
<p>Pattern Recognition Center
Tencent Inc
WeChat AIChina</p>
<p>TASTE: Teaching Large Language Models to Translate through Self-Reflection
12 Jun 2024411C38C18DA66AC599266ED86A9FAC99arXiv:2406.08434v1[cs.CL]
Large language models (LLMs) have exhibited remarkable performance in various natural language processing tasks.Techniques like instruction tuning have effectively enhanced the proficiency of LLMs in the downstream task of machine translation.However, the existing approaches fail to yield satisfactory translation outputs that match the quality of supervised neural machine translation (NMT) systems.One plausible explanation for this discrepancy is that the straightforward prompts employed in these methodologies are unable to fully exploit the acquired instruction-following capabilities.To this end, we propose the TASTE framework, which stands for translating through selfreflection.The self-reflection process includes two stages of inference.In the first stage, LLMs are instructed to generate preliminary translations and conduct self-assessments on these translations simultaneously.In the second stage, LLMs are tasked to refine these preliminary translations according to the evaluation results.The evaluation results in four language directions on the WMT22 benchmark reveal the effectiveness of our approach compared to existing methods.Our work presents a promising approach to unleash the potential of LLMs and enhance their capabilities in MT.The codes and datasets are open-sourced at https://github.com/YutongWang1216/ReflectionLLMMT.</p>
<p>Introduction</p>
<p>Large language models (LLMs) like GPT-4 (Ope-nAI, 2023) have recently demonstrated dramatic performance across a wide range of natural language processing tasks (Bubeck et al., 2023;Liang et al., 2022).Their outstanding grasp of syntactic and semantic knowledge positions them as powerful instruments for the enhancement of machine  1: An example of the TASTE approach."Normal" denotes the output of the baseline LLM fine-tuned on a normal parallel corpus."Stage 1" and "Stage 2" denote the outputs of the first and second inference stages of the proposed self-reflection process, respectively.The highlight denotes the quality label predicted by the LLM.Inherent translation errors generated in the first stage, such as the red strikethrough part, are rectified in the second inference stage.</p>
<p>translation, capable of producing translations of superior quality (Hendy et al., 2023;Zhang et al., 2023a;Garcia and Firat, 2022).This substantial progress represents an evolution of the paradigm in machine translation, serving as the foundation of novel translation systems characterized by enhanced quality and reliability.Numerous studies are underway to unlock the vast potential of machine translation within LLMs.Prompt engineering aims to design effective prompt templates to guide LLMs in accomplishing specific language tasks.Some approaches attempt to integrate additional information relevant to the translation task to enhance the performance of LLMs (Ghazvininejad et al., 2023;Lu et al., 2023;He et al., 2024;Peng et al., 2023).Studies in In-Context Learning (ICL, Brown et al., 2020) seek to provide LLMs with more relevant and highquality translation exemplars, which assists LLMs in retrieving bilingual knowledge, facilitating the generation of translations of the highest possible quality (Vilar et al., 2023;Agrawal et al., 2023).However, assessments of LLMs reveal that, in most translation directions, their performance falls short of that exhibited by robust supervised baselines (Zhu et al., 2023).This shortfall is due to the fact that these approaches often treat the LLM machine translation task as a simple text generation task, focusing on adjusting the prompts to enhance the outcomes.However, the intrinsic features of the machine translation task, such as the need for diverse multilingual knowledge, are often overlooked.</p>
<p>Some studies recommend the tuning of relatively smaller LLMs for translation (Zhu et al., 2023;Xu et al., 2023).Instruction tuning of LLMs with a limited number of high-quality supervised instructions in machine translation tasks yields remarkable results in some instances (Zeng et al., 2023;Jiao et al., 2023;Zhu et al., 2023;Hendy et al., 2023).Despite these achievements, these attempts still fail to fully leverage the capacity of LLMs due to their overly straightforward inference process.Unlike supervised NMT models, LLMs generate translations through language modeling, which contains a more complicated inference process and relies more on inherent linguistic knowledge.Studies such as Chain-of-Thought (CoT) reveal that the introduction of intermediate reasoning steps in the inference process significantly increases the reasoning capabilities of language models (Wei et al., 2022b;Kojima et al., 2022).</p>
<p>In this paper, we introduce TASTE, a method that aims at improving the translation performance of LLMs by instilling the ability to self-reflect on their own outputs.Specifically, we segment the LLM translation process into two stages of inference.In the first stage, LLMs are prompted to generate preliminary translations while simultaneously making quality predictions for these translations.In the second stage, we instruct LLMs to refine these preliminary translations based on the predicted quality levels to produce final candidates.An example of the proposed process can be found in Table 1.This entire process can be regarded as a form of self-reflection, mirroring the common approach employed by humans to carry out tasks more effectively and impeccably.To establish a sufficient multitask capability for executing the entire reflective translation process, we conduct supervised fine-tuning (SFT) on LLMs using a multitask training dataset.This method demonstrates a remarkable stimulation of the potential of LLMs, providing a novel approach to enhance the translation performance of these models.</p>
<p>Our contributions are summarized as follows:</p>
<p>• We present the TASTE method, which guides LLMs through a two-stage inference process, allowing them to initially generate preliminary results and subsequently refine them into improved candidates based on their selfassessment results.</p>
<p>• We create a multi-task training set comprising tasks that are closely aligned with the TASTE process to equip LLMs with the capability to execute the whole inference process.</p>
<p>• We find that by employing the TASTE method, LLMs proficiently refine their initial translation candidates, resulting in superior final outcomes, which in turn contributes to an enhancement in their translation capabilities.</p>
<p>Related Work</p>
<p>Efforts to enhance the translation performance of LLMs can be categorized into two research lines: prompt engineering and instruction tuning.Prompt Engineering aims to design proper prompt templates and introduce prior knowledge or supplementary information to support the inference process.Dictionary-based approaches incorporate control hints in the prompt from bilingual or multilingual dictionaries to deal with rare words in source sentences (Ghazvininejad et al., 2023;Lu et al., 2023).He et al. (2024) extracts translation-related knowledge, such as topics, by self-prompting to guide the translation process.Studies in ICL (Brown et al., 2020) aim to provide LLMs with more relevant and high-quality translation exemplars.This approach assists LLMs in retrieving bilingual knowledge, facilitating the generation of translations of the highest possible quality (Vilar et al., 2023;Agrawal et al., 2023).Instruction tuning represents an efficient method to enhance the ability of LLMs to follow natural language instructions and yield outputs that align more closely with human preference in downstream zero-shot tasks (Wei et al., 2022a;Ouyang et al., 2022;Chung et al., 2024).Jiao et al. (2023) explore several translation instructions to improve the translation performance of LLMs.Zeng et al. (2023)</p>
<p>Multi-task Instruction Tuning</p>
<p>Two-Stage Inference (Self-Reflection)</p>
<p>Inference Stage 1</p>
<p>Translate from Chinese to English, and label the translation quality as "Good", "Medium" or "Bad".岛上飞车党为什么能轻轻松松就把一段山路做到封路? ### Response:</p>
<p>Why can the biker gang on the island easily seal off a mountain road?</p>
<p>Translate from Chinese to English.岛上飞车党为什么能轻轻松松就把一段山路做到封路? ### Hint: Draft with quality label:</p>
<p>[Medium] Why can the island's flying car party easily do a mountain road to seal the road?### Note: A translation with no errors could be ### Response:</p>
<p>Inference Stage 2</p>
<p>Why can the island's flying car party easily do a mountain road to seal the road?</p>
<p>[Medium]</p>
<p>Figure 1: The framework of our proposed TASTE method.</p>
<p>LLMs and calculate the additional loss.Zhang et al. (2023b) enhance the multilingual language generation and instruction following capabilities of LLMs through interactive translation tasks.</p>
<p>Additionally, several studies proposed to facilitate a similar reflection process, utilizing confidence-guided approaches or multi-step inference, to assist the translation procedure.Lu et al. (2022) train a confidence estimation network in parallel with the backbone network to predict the confidence levels for generated translations, determining the amount of hints the model requires to produce correct translations.Xia et al. (2017) introduce a second-pass decoder to the conventional encoderdecoder structure, polishing the initial drafts and generating the final outputs.Tan et al. (2022) divide the translation process into three stages and independently apply different continuous prompts to better shift language to translation tasks.Li et al. (2023) propose a deliberate-then-generate inference framework, where LLMs are first prompted to detect error types from given candidates and then generate their final answers.Chen et al. (2023) propose to iteratively prompt LLMs to self-correct their translations.Feng et al. (2024) introduce a self-correcting inference framework for LLMs accessible via APIs, where LLMs autonomously conduct MQM self-evaluations and refine the primary candidates based on the evaluation results.Ki and Carpuat (2024) utilize a trained fine-grained feedback model to identify defects in generated translations, subsequently directing LLMs to refine the translations based on the feedback.</p>
<p>Our work represents a fusion of instruction tuning and the CoT methodology.We introduce a multi-step inference translation process in imitation of the self-reflection mechanism observed in humans.The utilization of multitask training data, including Basic Translation, Quality Prediction, and Draft Refinement, substantiates not only the multi-step inference capability but also the comprehension of nuances in translation quality.</p>
<p>TASTE: Translate through Reflection</p>
<p>Overall Framework</p>
<p>In this work, we aim to enhance the translation capabilities of LLMs by instructing them to engage in self-reflection on their translation candidates, ultimately producing carefully refined outputs.This process is achieved through a two-stage inference.</p>
<p>In the first stage, we ask the models to generate preliminary translations.Different from the conventional machine translation process, we also require them to predict the quality of their own outputs simultaneously.These preliminary translations are named "drafts", and their corresponding quality predictions can take the form of either approximate labels or precise scores.This stage of inference can be formalized into the following formula:</p>
<p>(y, q) ∼ P (y, q | w, x; θ)</p>
<p>(1)
P (y 1:m , q | w, x; θ) =P (q | y 1:m , w, x; θ)P (y 1:m | w, x; θ) =P (q | y 1:m , w, x; θ) m t=1 P (y i | y 1:t−1 , w, x; θ)(2)
where θ represents the parameters of the LLM, x and w denote the source sentence and the rest of the prompt (including the instruction), respectively.The preliminary translation y 1:m is generated first, and the quality label (score) q is generated later according to y 1:m .The corresponding prompts of the first inference stage are illustrated in the "Inference Stage 1" box in Figure 1.</p>
<p>In the second stage, we guide the models to refine their drafts based on the quality predictions.Both the drafts and quality labels/scores are formatted into the input field of the prompts for LLMs.The models proceed to make appropriate adjustments to the drafts according to the predicted label/scores, yielding the final translation candidates in a refined form.This stage of inference can be formalized into the following formula:
y ′ ∼ P (y ′ | y, q, w ′ , x; θ)
(3)
P (y ′ 1:n | y, q, w ′ , x; θ) = n t=1 P (y ′ i | y ′ 1:t−1 , y, q, w ′ , x; θ)(4)
where w ′ denotes the new prompt employed in the second stage.The refined translation y ′ 1:n is generated according to the preliminary translation y with its predicted quality level q.The corresponding prompts of the second inference stage are shown in the "Inference Stage 2" box in Figure 1.</p>
<p>Multitask SFT</p>
<p>To ensure that LLMs achieve a comprehensive understanding of the task instructions, we conduct multitask SFT on the models.The multitasking approach consists of three components: Quality Prediction, Basic Translation, and Draft Refinement.</p>
<p>Quality Prediction In this sub-task, LLMs are tasked with generating translations and providing self-quality predictions for a given source sentence.The quality prediction task consists of two forms: a) Text Classification (TC), entailing label predictions of "Good", "Medium", or "Bad", and b) Quality Estimation (QE), involving integer score prediction ranging from 0 to 100.We utilize candidates of various qualities generated by multiple systems, along with their evaluated COMET scores, to construct fine-tuning instances.Please refer to Appendix A.1 for detailed information.The ground truth of the training data would be translations with gold quality labels/scores placed in the back.</p>
<p>Basic Translation</p>
<p>We utilize parallel data combined with a standardized instruction to conduct fine-tuning of LLMs for multilingual translation tasks, including German ⇔ English and Chinese ⇔ English language pairs .The instruction is formulated straightforwardly as "Translate from [SRC] to [TGT]".As shown in Figure 1, the Basic Translation instructions exhibit a high degree of similarity to their Quality Prediction counterparts, but they belong to two completely different tasks.To disambiguate instructions between these two tasks and prevent LLMs from obtaining lowquality translation knowledge, we follow Zeng et al. (2023) to append a distinguishing note "### Note: A translation with no errors could be" at the end of the Basic Translation input.</p>
<p>Draft Refinement In this sub-task, LLMs are asked to refine drafts based on quality labels/scores to produce final outputs.Given a source sentence and multiple candidates of various qualities, we designate the highest-scored output as the reference.The drafts are sampled from the remaining candidates, covering all quality levels.We incorporate a new field named "Hint" within the translation prompt.This field provides LLMs with translation drafts of the source sentence, with quality labels/scores placed in front of the drafts in the following format: "### Hint: Draft with quality label/score: [LABEL/SCORE] [Draft]".We fill in "label" or "score" based on whether the TC or QE approach is employed.Examples of the complete prompts are shown in To avoid possible data leakage in the training data, we evaluate the translation performance on the WMT22 test set (Kocmi et al., 2022), which covers domains such as news, social, e-commerce, and conversation.We present the translation results in German ⇔ English and Chinese ⇔ English directions.We report the BLEU scores by SacreBLEU (Post, 2018) and COMET scores by wmt22-comet-da (Rei et al., 2022).</p>
<p>Model Training</p>
<p>We employ BLOOMZ-7b1-mt 2 and LLaMA-2-7b 3 (Touvron et al., 2023) as our backbone models.</p>
<p>2 https://huggingface.co/bigscience/bloomz-7b1-mt 3 https://huggingface.co/meta-llama/Llama-2-7b</p>
<p>These models are all fine-tuned for 1 epoch with a batch size of 128.The learning rates are set to 2e-5, and the weight decay parameter is set to 0.0.The maximum text length is 768.We conducted the fine-tuning on eight NVIDIA A100 GPUs, using the Deep-Speed ZeRO stage3 for acceleration.</p>
<p>We employ two distinct training strategies, differing in the updated parameters:</p>
<p>Full-Parameter Tuning (Full) In this method, all the parameters in LLMs are involved in the training process.In comparison to methods that focus on training only a small set of parameters (such as Prefix Tuning and Low-Rank Adaption), fullparameter tuning is less susceptible to overfitting due to the larger parameter space.However, the main issue with this approach is excessive memory consumption and runtime demands.</p>
<p>Tuning with Fixed Embedding Layer (FixEmb)</p>
<p>The embedding layer is pre-trained on large-scale corpus and reflects the general distribution of word embeddings.Further tuning, especially when the number of trainable parameters is limited or the training corpus is not abundant enough, will introduce disturbances into these distributions, leading to a decline in the model's expressive capacity.To overcome this problem, we freeze the embedding layers of LLMs and fine-tune the rest of the parameters.This assists LLMs in maintaining correctness and diversity in their expressions.</p>
<p>Baselines</p>
<p>The MT-(•) baseline models represent the LLMs trained exclusively with the Basic Translation dataset, as outlined in Table 11.This dataset contains the German ⇔ English and Chinese ⇔ English translation directions.</p>
<p>Additionally, we present the results of WMT22 winners, NLLB-3.3B(Costa-jussà et al., 2022), a multilingual translation model trained in over 200 languages, Bayling (Zhang et al., 2023b), ParroT (Jiao et al., 2023), and TIM (Zeng et al., 2023), LLMs fine-tuned for machine translation with BLOOM or LLaMA as the backbone models.</p>
<p>Results</p>
<p>Our main results are shown in Table 2. Almost all of our methods outperform the corresponding MT-(•) baseline across both metrics and all language pairs, providing evidence of the effectiveness of our approach in enhancing the translation capabilities of LLMs.When utilizing BLOOMZ-7b1-mt as the backbone model, our FixEmb-(•) approaches achieve favorable results, particularly in Zh ⇔ En directions, and outperform ParroT and TIM across all language pairs on COMET scores.While employing LLaMA-2-7b as the backbone model, our FixEmb-(•) approaches also gain remarkable results, particularly in De ⇔ En directions, and beat Bayling in all directions except En ⇔ Zh.</p>
<p>There is no significant difference in translation performance observed between two different quality prediction approaches, (•)-QE and (•)-TC.This suggests that both of these approaches effectively aid LLMs in grasping the quality differences between varying translations.</p>
<p>The models trained with fixed embedding layers consistently outperform their counterparts trained with full parameters across all language pairs and both evaluation metrics.We argue that this is because fixing embedding layers during fine-tuning effectively preserves the expressive capability of LLMs against word distribution biases within the training data.This facilitates the generalization of LLMs across the word domain, mitigating overfitting and thereby enhancing their capacity to produce robust and diverse translations.We also train a merged model that handles QE and TC approaches simultaneously, and conduct a comparison of the translation performance across models of different scales.Please refer to Appendix A.3 and A.4 for more details.</p>
<p>Analysis</p>
<p>Unless mentioned otherwise, the subsequent experiments are conducted in the FixEmb-TC setting.</p>
<p>How Good Are LLMs at Quality</p>
<p>Prediction?</p>
<p>Quality Prediction constitutes an end-to-end process, where LLMs are instructed to predict quality labels or scores while generating translations.To validate the assertion that LLMs have genuinely acquired the capability to predict the quality of candidates, we evaluated the quality prediction outputs.</p>
<p>For TC, we construct gold labels for the instances according to their COMET scores following the same principle mentioned in Appendix A.2 and report the precision, recall, and F1 values of the predicted labels.For QE, we assessed the Pearson's correlation coefficient between the predicted quality scores and the gold COMET scores.Additionally, we present the Pearson's correlation coefficient between the perplexity values (PPL) of the candidates and the COMET scores for comparison.</p>
<p>As shown in Table 3, for the TC approach, the models exhibit a commendable level of accuracy in assigning quality labels to their translations, as evidenced by F1 values surpassing 67.6.In the QE task, our models produce scores with a satisfactory correlation with COMET scores (the p-values are all smaller than 0.01), while the perplexity values demonstrate a relatively poor correlation with COMET scores.These statistics demonstrate that our models can make precise quality predictions for their own generated translations, providing a dependable reference for the Draft Refinement task.</p>
<p>We can also discover that LLaMA-2 outperforms   BLOOMZ in terms of accuracy for both the QE and TC tasks, suggesting that LLaMA-2 possesses a more extensive bilingual knowledge base.</p>
<p>Effect of Draft Refinement</p>
<p>To analyze the influence of the Draft Refinement process (i.e., the second stage of inference), we perform the following two comparisons between the candidates obtained after the first and second inference stages.</p>
<p>Translation Quality We evaluate the COMET scores of the preliminary and refined translations.</p>
<p>The results are shown in Figure 2. In the plot, each point located above the diagonal line represents an instance where a quality improvement is achieved through refinement.As the plot demonstrates, a majority of the final candidates exhibit higher quality levels than their initial counterparts.Table 4 illustrates the proportions of preliminary translations with varying predicted quality labels and their respective average COMET score increments during the refinement process.The most significant score enhancements are observed in instances labeled as "Bad", which constitute the largest proportion of all instances.Subsequently, "Medium" instances show a moderate improvement, while "Good" instances exhibit the least noticeable enhancement.These observations highlight the ef-  ficacy of the Draft Refinement process in refining the preliminary translations generated in the first inference stage as well as rectifying potential generation failures, as evidenced by instances located in the top-left region of Figure 2.</p>
<p>Unaligned Translation Words (UTW) We measure the percentages of target words that remain unaligned in a word-to-word alignment between the source sentences and translations obtained after the first and second inference stages.The alignments are extracted using the tool developed by Dou and Neubig (2021).This measurement is also used by Hendy et al. (2023) to investigate the presence of words that have no support in the source sentences.</p>
<p>The results are shown in Figure 3.We can observe that the amount of UTW is significantly reduced during the draft refinement process, with a decrease of more than 15 percentage points.This observation suggests that the Draft Refinement process contributes to a reduction in hallucinations within the candidates, leading to a higher level of translation precision and mitigation of potential risks within the translation systems.</p>
<p>The Role of Quality Labels</p>
<p>To examine the impact of the predicted quality labels on the refinement process, we conduct experi- ments by modifying these labels with the following configurations: a) All the labels are set to "Good".b) All the labels are set to "Bad".c) All the labels are randomly sampled among "Good", "Medium", and "Bad".d) All the labels are removed from the prompts and the model is only provided with draft translations during the refinement process.Subsequently, we perform the refinement process, and calculate the average edit distances between the preliminary and refined translations as follows:
d = 1 n n i=1 (1 − LevRatio i ) = 1 n n i=1 LevDist i len 1 i + len 2 i (5)
Here, LevRatio i represents the Levenshtein distance radio 4 of the i-th instance, len 1 i and len 2 i represent the lengths of two strings, respectively, and LevDist i represents the Levenshtein distance between these strings.</p>
<p>We report the average edit distances and the COMET score of the refined translations in Table 5.In the cases where all the labels are set to "Good", the edit distances between the preliminary and refined translations are relatively small.This suggests that the model tends to make fewer modifications to the preliminary translations.Conversely, when all the labels are set to "Bad", the edit distances are relatively large, indicating that the model tends to make more modifications during refinement.Furthermore, noticeable performance decreases are observed when the labels are set to "Good", sampled randomly (i.e.Random), or removed from the prompts (i.e.Blank).These phenomena illustrate the impact of the quality labels in the refinement process, which is to assist LLMs in making reasonable adjustments based on the actual translation quality levels and generating high-quality final candidates.</p>
<p>Ablation Study</p>
<p>To emphasize the necessity of our multitask training set and prompt design, we conduct an ablation study.We choose BLOOMZ-7b1-mt as the backbone model and fine-tune it using various training sets with the FixEmb-TC method.BLEU and COMET scores in the Zh⇒En direction are reported.</p>
<p>Our multitask training set contains three parts: Basic Translation, Quality Prediction, and Draft Refinement.To demonstrate the rationality of this task combination, we remove a specific section of the training set separately, and the consequences are shown in Table 6.The performance of the model decreases when any subset of the training date is removed.This result implies that each of the sub-tasks is essential for our approach.When the Quality Prediction data is removed from the training set, the BLEU scores exhibit the most noticeable decrease.This observation suggests that the TASTE process heavily relies on the model's ability to discern various qualities of translations.</p>
<p>Comparison with Related Methods</p>
<p>TASTE vs CoT Our approach is based on a twostage inference, which is similar to the thought of CoT.To certify the superiority of our proposal, we perform a comparison with the CoT method.We apply the same prompts utilized in TASTE to guide a two-stage inference process with LLaMA-2-chat-7b and LLaMA-2-chat-13b, both of which undergo no fine-tuning process.The results are shown in Table 7.In many-to-English translation directions, the ICL method gains reasonable performance, yet our approach outperforms it significantly.In English-to-many directions, the  8, reveal a significant performance margin between the ICL methods and our TASTE approach.</p>
<p>TASTE as an APE Tool</p>
<p>In the proposed TASTE framework, the fine-tuned LLMs are employed for the evaluation and refinement of their own draft translations.This naturally leads to the question: Are the fine-tuned TASTE LLMs able to evaluate base translations generated by arbitrary systems and refine them as an Automatic Post-Editing (APE) tool?</p>
<p>To answer this question, we conducted an experiment utilizing TASTE as an automatic postediting tool.Initially, we select BLOOMZ-7b in the MT-FixEmb baseline setting to generate base translations.Subsequently, we employ LLaMA-2-7b in the FixEmb-TC setting as the APE model.We concatenate the base translation behind the prompt for the first inference stage and input it into the APE model to generate the quality label.Finally, we format the base translation and quality label into the prompt for the second inference stage to obtain the refined translation.</p>
<p>The results of this experiment, as indicated by the COMET scores before and after APE, are detailed in Table 9. Notable quality enhancements through the APE process can be observed, and the results even outperform the TASTE LLaMA-2-7b model due to the multi-system voting mechanism.This indicates that TASTE can not only serve as an effective inference framework for a single LLM but also as an APE tool to enhance translations generated by other translation systems.</p>
<p>Conclusion</p>
<p>We introduce TASTE, a novel approach that enables LLMs to translate through the self-reflection process.Our approach allows LLMs to initially generate a preliminary translation and autonomously assess its quality.Subsequently, the translation is refined based on the evaluation results, resulting in the final candidate.Our experiments and analyses provide evidence of the effectiveness of TASTE, as it successfully enhances the translation quality through the refinement process, consistently producing high-quality candidates across various translation directions.Furthermore, our findings underscore that LLMs possess significant potential for the translation quality prediction task.The translation process can leverage this capacity to discern different qualities among translations, leading to the generation of high-quality outcomes.</p>
<p>Limitations</p>
<p>The performance enhancement introduced by our approach exhibits inconsistency across different translation directions.We assume that this phenomenon is caused by the inherent uneven multilingual knowledge within the model, and a more in-depth exploration of the underlying principles is warranted.Additionally, considering the two inference stages in the TASTE process, the computation cost is twice that of the conventional translation generation process.However, it's worth noting that this extra time consumption can be mitigated through acceleration methods, such as quantification and speculative decoding.</p>
<p>Figure 2 :
2
Figure 2: Comparison between the COMET scores of the preliminary and refined translations.The results are obtained by LLaMA-2-7b in Zh⇒En direction.</p>
<p>SRC 但/But 口水鸡/Poached Chicken in Chili Sauce 整盒/whole box 是/is 生肉/row meat，没办 法/cannot 吃/eat， 是 否/whether 可 以/can 退款/refund?REF But the Poached Chicken in Chili Sauce is just a box of inedible raw chicken, and can I get a refund for it?Normal But the whole box of chicken is raw meat, so you can't eat it, can you refund?Stage 1 But the whole box is meat, can't eat, can you refund \n [Bad] Stage 2 But the whole box of spicy chicken is raw meat,</p>
<p>so I can't eat it.Can I get a refund?Table</p>
<p>employ examples in comparison to instruct Basic Translation Quality Prediction Draft Refinement
Translate from Chinese to English.Translate from German to English,Translate from English to German.另据塔斯社1月16日报道，曼图罗夫告诉and label the translation qualityOwning a dog brings with [...]记者，"车队"系列汽车将从2019年起对as "Good", "Medium" or "Bad".respond to our consultation.外零售，各种配置的车型都能买到。Eine gewisse Lautstärke gehört### Hint: Draft with quality### Note: A translation with nogenrebedingt bei einem solchenlabel: [Bad] Der Besitz eineserrors could be[...] bei etwa 98 Dezibel.[...] Beratung zu reagieren.### Response:### Response:### Response:Elsewhere, according to reportsAt the "Mint Mosquito"-Rocknacht,Der Besitz eines Hundes bringtby TASS [...] externally fromaccording to information [...] isbestimmte Verantwortlichkeiten2019. All configured models willabout 98 decibels.[...] auf unsere Konsultation zube available.[Bad]reagieren.</p>
<p>Table 14 .
14
We employ the WMT validation set to construct the training data for the Basic Translation task and utilize the MTME multi-candidate 1 dataset, which
4 Experimental Setups4.1 Data</p>
<p>Table 2 :
2
Main results of TASTE.LLaMA-2-7b and BLOOMZ-7b1-mt are chosen as the backbone model.QE and TC signify that the Quality Prediction subtask takes the form of quality estimation and text classification, respectively.The best results of each kind of backbone model are labeled using bold font.
contains source sentences and their candidate trans-lations generated by multiple systems to build thetraining data for the Quality Prediction and DraftRefinement tasks. For Quality Prediction, candi-dates across various quality levels are sampled toform training instances. For Draft Refinements, thecandidate with the highest COMET score is chosenas the reference, and the drafts to be refined aresampled from the other candidates covering vari-ous qualities. The data statistics and details of databuilding can be found in Appendix A.2.</p>
<p>Table 3 :
3
Evaluation results on quality prediction task in Zh ⇒ En direction.Precision, recall, and F1 values are calculated as weighted averages across three translation quality categories.PPL/Pred.represents Pearson's r between the perplexity values/predicted scores and the COMET scores.
ModelPPLPred.↑P↑R↑F1↑BLOOMZ -37.1076.8470.1 68.2 67.6LLaMA-20.0080.3370.5 70.1 69.8</p>
<p>Table 4 :
4
Proportions of preliminary translations with different predicted quality labels and their average COMET scores increments during refinement.These results are obtained by LLaMA-2-7b in Zh ⇒ En direction.
LabelProportion (%) ∆COMETGood31.890.45Medium32.802.06Bad35.317.79</p>
<p>Table 5 :
5
The edit distance between the preliminary and refined translations and the final COMET scores under different quality label configurations."Origin" represents the configuration where predicted labels remain unmodified."Blank" represents that quality labels are removed during refinement processes.These results are obtained by LLaMA-2-7b in Zh ⇒ En direction.</p>
<p>Table 7 :
7
COMET scores gained by our approach and the CoT method.
MethodBLEU COMETMT-FixEmb19.4172.06TASTE21.9876.38w/o Basic Translation20.0072.12w/o Quality Prediction17.8672.26w/o Draft Refinement19.3172.00Table 6: Ablation Study. We report the BLEUand COMET scores in En⇒De direction achieved byBLOOMZ-7b1-mt.SystemZh⇒En En⇒Zh De⇒En En⇒DeCoT-7b74.5073.7979.6374.37CoT-13b75.2175.3280.1073.55TASTE79.5384.2484.1183.80
https://github.com/google-research/mt-metrics-eval
AcknowledgementsThis work was supported in part by the National Natural Science Foundation of China (Grant No. 62206076), Guangdong Basic and Applied Basic Research Foundation (Grant No. 2024A1515011491), Shenzhen Science and Technology Program (Grant Nos.ZDSYS20230626091203008 and KJZD20231023094700001). Xuebo Liu was sponsored by CCF-Tencent Rhino-Bird Open Research Fund.We would like to thank the anonymous reviewers and meta-reviewer for their insightful suggestions.A AppendixA.1 Quality Prediction Task DesignsThe quality prediction task is designed in two forms: text classification (TC) and quality estimation (QE).Text Classification (TC) We instruct LLMs to categorize translations into three classes by the instruction "Translate from[SRC]to[TGT], and label the translation quality as "Good", "Medium" or "Bad"."For the candidates with the top 10% COMET scores, the gold  labels are assigned as "Good", while those with the bottom 50% of COMET scores are labeled as "Bad".Candidates falling within the remaining range are designated as "Medium".Quality Estimation (QE) We request LLMs to simultaneously predict integer quality scores ranging from 0 to 100 while generating translations by the following instruction: "Translate from [SRC] to[TGT], and score the translation quality from 0 to 100."Here, the placeholders "[SRC]" and "[TGT]" denote the source and target language, respectively.We amplify the COMET scores by a factor of one hundred and round them to use as gold scores.The QE task can be regarded as a more precise version of the TC task, which is perceived as more challenging for generative language models.The methodologies employed during the training and test phase will remain consistent.A.2 Data DetailsWMT Development Data We use humanwritten validation data from previous WMT competitions as the basic MT training data to align LLMs on the MT task.Specifically, we choose the newstest2017-2021 of German ⇔ English and Chinese ⇔ English as our MT training set.MTME Multi-Candidate Data This is a dataset containing source sentences and translation candidates of multiple MT systems on the WMT Metrics Shared Tasks built by Google Research.We use the candidates of newstest2019-2021 in German ⇔ English and Chinese ⇔ English directions to build training data for the Quality Prediction and Draft Refinement task.For Quality Prediction, the inputs for the LLMs are the instructions and the source sentences, and the text generation labels are sampled candidates with their corresponding quality labels/scores attached at the end.For Draft Refinement, we choose the candidate with the highest COMET score among all candidates of one source sentence as the label for the LLMs, and the draft translation is sampled from the rest of them.The inputs for the LLMs are the instructions, the source sentences, and the drafts with their corresponding quality labels/scores attached in the front.To enable the LLMs to have a good understanding of the translation quality, we carefully designed the proportion of the candidates with different quality levels.We classified the candidates into three categories by the COMET scores evaluated by wmt-22-comet-da.Candidates with the top 10% COMET scores are classified as "Good", while those with the bottom 50% of COMET scores are classified as "Bad".Candidates falling within the remaining range are designated as "Medium".For the Quality Prediction and Draft Refinement training set, the numbers of instances constructed by candidates of all three quality categories are shown in Table10.The sizes and sources of the training data for the three tasks are represented in Table11.Examples of the complete prompts and labels for these tasks are shown in Table14.A.3 Merged ModelWe also train a model that merges two types of Quality Prediction approaches, Text Classification (TC) and Quality Estimation (QE), to facilitate the TASTE self-reflection process and generate both preliminary and refined translations.Users have the flexibility to specify the approach by instructing the model in the first inference stage.If the instruction is "Translate from [SRC] to [TGT], and label the translation quality as "Good", "Medium" or "Bad"", then the TC approach is adopted, and the model predicts quality labels for the preliminary translation.Otherwise, if the instruction is "Translate from [SRC] to [TGT], and score the translation quality from 1 to 100", the model employs the QE approach and predicts quality scores.For training the merged model, we utilized 45.4k instances of Basic Translations, 45k instances for each of the two Quality Prediction approaches (TC and QE), and 20k instances for each of the two Draft Refinement styles (TC and QE).BLOOMZ-7b1-mt is employed as the backbone model.The results are shown in Table12.We observe that although there is a marginal decrease in translation performance, the merged model demonstrates the capability to handle two types of quality expression approaches simultaneously and successfully conducts the normal inference process as the nonmerged models.A.4 Effect of Model SizeWe report the COMET and BLEU scores yielded by BLOOMZ of various model sizes in Figure4and Table13.We can observe that with the increase in the number of model parameters, both the median and mean scores are consistently rising.This indicates that our proposed method is robust in terms of model parameter scaling.As mentioned in §5, LLMs depend on large amounts of parameters to memorize task-specific knowledge to perform multi-tasking.In addition, the instructions we designed for differ-ent tasks are highly similar, which makes it more challenging but essential for LLMs to grasp different types of knowledge.Another observation is that the distribution of scores achieved by larger models tends to be more concentrated than that obtained by smaller ones.This indicates that as the number of model parameters increases, the performance of LLMs is not only enhanced but also stabilized, which means bad cases occur less frequently, guaranteeing the lower bound of the capacity.A.5 Case StudySeveral cases of the translation process of TASTE are shown in Table15.The quality labels are predicted as "Bad" while some severe lexical or syntactic problems occur in the preliminary translations.In Case 1, an ambiguous Chinese character "扫" is inaccurately translated into "sweep", and the term "二维码" is literally translated as "twodimensional code" instead of "QR code".In Case 2, the preliminary translation is incomplete, omit- Draft Refinement Write a response that appropriately completes the request.\n\n###Request:\nTranslate from Chinese to English.虽然朱雨玲连追3分，但丁宁还是利用发球以11：9拿下首局。\n\n ### Hint:\nDraft with quality label:\n[Bad] Although he had only three points, he took the ball to 11:9.### Note: A translation with no errors could be\n\n ### Response: Although Zhu Yuling chased three points in a row, but Ding Ning used his serve to take the first set 11-9.Table14: Examples of the prompts and labels for the LLMs.We followJiao et al. (2023)to surround the inputs with "Write a response that appropriately completes the request.\n\n###Request:\n" and "### Response:" to guide the LLMs to complete specific tasks.The contents behind "### Response:" are the labels for the text generation fine-tuning of the LLMs.ting the latter part of the source sentence.In Case 3, the word order in the preliminary translation is notably awkward.All these issues are effectively addressed during the second inference stage, resulting in refined translations of high quality.Even when the predicted quality labels are designated as "Medium" or "Good", as seen in Case 4 and Case 5, the second stage inference continues to perform fine-tuning on the preliminary translations based on the actual context and linguistic nuances.age, want to learn the language, even in which city, these will be related to your learning or want to engage in the industry.[Medium] Stage 2 For example, your major, your age, the language you want to learn, and even the city you want to study in, are all related to the industry you want to work in.The packaging of the bagged water in the box is 100% recyclable, which can reduce packaging by 66% and carbon emission by 97%.Stage 1 The packaging box uses 100% recyclable packaging, which can reduce packaging by 66% and reduce carbon dioxide emissions by 97%.[Good] Stage 2 The bagged water in the box is packed in a 100% recyclable packaging box, which can reduce packaging by 66% and carbon dioxide emissions by 97%.Table15: Cases of translation process of TASTE in Chinese ⇒ English direction.The backbone model is LLaMA-2-7b trained with its embedding layer fixed."Stage 1" represents the preliminary translation generated during the first inference process, and "Stage 2" represents the refined translation generated during the second inference process.The predicted quality labels for the drafts are marked using highlights .
Incontext examples selection for machine translation. Sweta Agrawal, Chunting Zhou, Mike Lewis, Luke Zettlemoyer, Marjan Ghazvininejad, Findings of the Association for Computational Linguistics: ACL 2023. 2023</p>
<p>Alec Radford, Ilya Sutskever, and Dario Amodei. Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems. Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish; NeurIPS2020. 2020. 2020. December 6-12, 2020Language models are few-shot learners</p>
<p>Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, ArXiv preprint, abs/2303.12712Sparks of artificial general intelligence: Early experiments with gpt-4. 2023</p>
<p>Iterative translation refinement with large language models. Pinzhen Chen, Zhicheng Guo, Barry Haddow, Kenneth Heafield, abs/2306.038562023ArXiv preprint</p>
<p>Scaling instruction-finetuned language models. Chung Hyung Won, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Journal of Machine Learning Research. 25702024</p>
<p>No language left behind: Scaling human-centered machine translation. James Marta R Costa-Jussà, Onur Cross, Maha Çelebi, Kenneth Elbayad, Kevin Heafield, Elahe Heffernan, Janice Kalbassi, Daniel Lam, Jean Licht, Maillard, ArXiv preprint, abs/2207.046722022</p>
<p>Word alignment by fine-tuning embeddings on parallel corpora. Zi-Yi Dou, Graham Neubig, 10.18653/v1/2021.eacl-main.181Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main VolumeOnline. Association for Computational Linguistics2021</p>
<p>Improving llm-based machine translation with systematic self-correction. Zhaopeng Feng, Yan Zhang, Hao Li, Wenqiang Liu, Jun Lang, Yang Feng, Jian Wu, Zuozhu Liu, abs/2402.16379ArXiv preprint. 2024</p>
<p>Using natural language prompts for machine translation. Xavier Garcia, Orhan Firat, abs/2202.118222022ArXiv preprint</p>
<p>Dictionary-based phrase-level prompting of large language models for machine translation. Marjan Ghazvininejad, Hila Gonen, Luke Zettlemoyer, abs/2302.07856ArXiv preprint. 2023</p>
<p>Exploring humanlike translation strategy with large language models. Zhiwei He, Tian Liang, Wenxiang Jiao, Zhuosheng Zhang, Yujiu Yang, Rui Wang, Zhaopeng Tu, Shuming Shi, Xing Wang, 10.1162/tacl_a_00642/1199922024Transactions of the Association for Computational Linguistics12</p>
<p>How good are gpt models at machine translation? a comprehensive evaluation. Amr Hendy, Mohamed Abdelrehim, Amr Sharaf, Vikas Raunak, Mohamed Gabr, Hitokazu Matsushita, Young , Jin Kim, Mohamed Afify, Hany Hassan Awadalla, abs/2302.09210ArXiv preprint. 2023</p>
<p>Parrot: Translating during chat using large language models tuned with human translation and feedback. Wenxiang Jiao, Jen-Tse Huang, Wenxuan Wang, Zhiwei He, Tian Liang, Xing Wang, Shuming Shi, Zhaopeng Tu, Findings of the Association for Computational Linguistics: EMNLP 2023. 2023</p>
<p>Guiding large language models to post-edit machine translation with error annotations. Dayeon Ki, Marine Carpuat, abs/2404.078512024ArXiv preprint</p>
<p>Findings of the 2022 conference on machine translation (wmt22). Tom Kocmi, Rachel Bawden, Ondřej Bojar, Anton Dvorkovich, Christian Federmann, Mark Fishel, Thamme Gowda, Yvette Graham, Roman Grundkiewicz, Barry Haddow, Proceedings of the Seventh Conference on Machine Translation (WMT). the Seventh Conference on Machine Translation (WMT)2022</p>
<p>Large language models are zero-shot reasoners. Takeshi Kojima, Shane Shixiang, Machel Gu, Yutaka Reid, Yusuke Matsuo, Iwasawa, Advances in neural information processing systems. 202235</p>
<p>Deliberate then generate: Enhanced prompting framework for text generation. Bei Li, Rui Wang, Junliang Guo, Kaitao Song, Xu Tan, Hany Hassan, Arul Menezes, Tong Xiao, Jiang Bian, Jingbo Zhu, 2023. 19835ArXiv preprint, abs/2305</p>
<p>Holistic evaluation of language models. Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, abs/2211.09110ArXiv preprint. Ananya Kumar, et al. 2022</p>
<p>Chainof-dictionary prompting elicits translation in large language models. Hongyuan Lu, Haoyang Huang, Dongdong Zhang, Haoran Yang, Wai Lam, Furu Wei, abs/2305.06575ArXiv preprint. 2023</p>
<p>Learning confidence for transformerbased neural machine translation. Yu Lu, Jiali Zeng, Jiajun Zhang, Shuangzhi Wu, Mu Li, 10.18653/v1/2022.acl-long.167Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 60th Annual Meeting of the Association for Computational LinguisticsDublin, IrelandAssociation for Computational Linguistics20221</p>
<p>Gpt-4 technical report. 2023OpenAI</p>
<p>Training language models to follow instructions with human feedback. Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul F Christiano, Advances in Neural Information Processing Systems. Curran Associates, IncJan Leike, and Ryan Lowe. 202235</p>
<p>Yuanxin Ouyang, and Dacheng Tao. 2023. Towards making the most of ChatGPT for machine translation. Keqin Peng, Liang Ding, Qihuang Zhong, Li Shen, Xuebo Liu, Min Zhang, 10.18653/v1/2023.findings-emnlp.373Findings of the Association for Computational Linguistics: EMNLP 2023. SingaporeAssociation for Computational Linguistics</p>
<p>A call for clarity in reporting BLEU scores. Matt Post, 10.18653/v1/W18-6319Proceedings of the Third Conference on Machine Translation: Research Papers. the Third Conference on Machine Translation: Research PapersBrussels, BelgiumAssociation for Computational Linguistics2018</p>
<p>COMET-22: Unbabel-IST 2022 submission for the metrics shared task. Ricardo Rei, G C José, Duarte Souza, Chrysoula Alves, Ana C Zerva, Taisiya Farinha, Alon Glushkova, Luisa Lavie, Coheur, F T André, Martins, Proceedings of the Seventh Conference on Machine Translation (WMT). the Seventh Conference on Machine Translation (WMT)Abu Dhabi, United Arab EmiratesAssociation for Computational Linguistics2022</p>
<p>MSP: Multi-stage prompting for making pre-trained language models better translators. Zhixing Tan, Xiangwen Zhang, Shuo Wang, Yang Liu, 10.18653/v1/2022.acl-long.424Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 60th Annual Meeting of the Association for Computational LinguisticsDublin, IrelandAssociation for Computational Linguistics20221</p>
<p>Llama 2: Open foundation and fine-tuned chat models. Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, ArXiv preprint, abs/2307.092882023</p>
<p>Prompting palm for translation: Assessing strategies and performance. David Vilar, Markus Freitag, Colin Cherry, Jiaming Luo, Viresh Ratnakar, George Foster, Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics. Long Papers. the 61st Annual Meeting of the Association for Computational Linguistics20231</p>
<p>Finetuned language models are zero-shot learners. Jason Wei, Maarten Bosma, Y Vincent, Kelvin Zhao, Adams Wei Guu, Brian Yu, Nan Lester, Andrew M Du, Dai, V Quoc, Le, The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event. 2022a. April 25-29, 2022OpenReview.net</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Denny Quoc V Le, Zhou, Advances in neural information processing systems. 2022b35</p>
<p>Deliberation networks: Sequence generation beyond one-pass decoding. Yingce Xia, Fei Tian, Lijun Wu, Jianxin Lin, Tao Qin, Nenghai Yu, Tie-Yan Liu, Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems. Long Beach, CA, USA2017. 2017. December 4-9, 2017</p>
<p>A paradigm shift in machine translation: Boosting translation performance of large language models. Haoran Xu, Young , Jin Kim, Amr Sharaf, Hany Hassan Awadalla, abs/2309.11674ArXiv preprint. 2023</p>
<p>Tim: Teaching large language models to translate with comparison. Jiali Zeng, Fandong Meng, Yongjing Yin, Jie Zhou, abs/2307.044082023ArXiv preprint</p>
<p>Prompting large language model for machine translation: A case study. Biao Zhang, Barry Haddow, Alexandra Birch, International Conference on Machine Learning. PMLR2023a</p>
<p>Bayling: Bridging cross-lingual alignment and instruction following through interactive translation for large language models. Shaolei Zhang, Qingkai Fang, Zhuocheng Zhang, Zhengrui Ma, Yan Zhou, Langlin Huang, Mengyu Bu, Shangtong Gui, Yunji Chen, Xilin Chen, 2023bArXiv preprint, abs/2306.10968</p>
<p>Multilingual machine translation with large language models: Empirical results and analysis. Wenhao Zhu, Hongyi Liu, Qingxiu Dong, Jingjing Xu, Lingpeng Kong, Jiajun Chen, Lei Li, Shujian Huang, ArXiv preprint, abs/2304.046752023</p>            </div>
        </div>

    </div>
</body>
</html>