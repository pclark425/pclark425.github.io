<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9289 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9289</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9289</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-163.html">extraction-schema-163</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how different problem or prompt presentation formats affect the performance of large language models (LLMs) on tasks, including details about the formats, tasks, models, performance metrics, comparisons, and any explanations or findings.</div>
                <p><strong>Paper ID:</strong> paper-267750577</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2402.11347v1.pdf" target="_blank">PhaseEvo: Towards Unified In-Context Prompt Optimization for Large Language Models</a></p>
                <p><strong>Paper Abstract:</strong> Crafting an ideal prompt for Large Language Models (LLMs) is a challenging task that demands significant resources and expert human input. Existing work treats the optimization of prompt instruction and in-context learning examples as distinct problems, leading to sub-optimal prompt performance. This research addresses this limitation by establishing a unified in-context prompt optimization framework, which aims to achieve joint optimization of the prompt instruction and examples. However, formulating such optimization in the discrete and high-dimensional natural language space introduces challenges in terms of convergence and computational efficiency. To overcome these issues, we present PhaseEvo, an efficient automatic prompt optimization framework that combines the generative capability of LLMs with the global search proficiency of evolution algorithms. Our framework features a multi-phase design incorporating innovative LLM-based mutation operators to enhance search efficiency and accelerate convergence. We conduct an extensive evaluation of our approach across 35 benchmark tasks. The results demonstrate that PhaseEvo significantly outperforms the state-of-the-art baseline methods by a large margin whilst maintaining good efficiency.</p>
                <p><strong>Cost:</strong> 0.021</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9289.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9289.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how different problem or prompt presentation formats affect the performance of large language models (LLMs) on tasks, including details about the formats, tasks, models, performance metrics, comparisons, and any explanations or findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Zero-shot vs Few-shot (Instruction Induction)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Comparison of zero-shot and few-shot prompt presentation formats on instruction induction tasks</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper reports that PHASEEVO discovers both zero-shot and few-shot prompts and shows that few-shot prompts do not always outperform zero-shot; PHASEEVO-generated prompts (mix of zero- and few-shot) outperform prior zero-/few-shot baselines across many instruction-induction tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5 (primary; GPT-4 also evaluated)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Instruction Induction Tasks (24 tasks, Honovich et al. 2022)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>A suite of 24 instruction-induction tasks that require producing natural-language task descriptions or following short instructions (various language-understanding tasks).</td>
                        </tr>
                        <tr>
                            <td><strong>presentation_format</strong></td>
                            <td>PHASEEVO-generated prompts that may be zero-shot (instruction-only) or few-shot (instruction + in-context examples); PHASEEVO is free to produce either format depending on task.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>APE (zero-shot and few-shot), PromptBreeder (few-shot). Comparisons use APE zero-shot/few-shot and PromptBreeder few-shot prompts as alternatives.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>PHASEEVO (GPT-3.5) produced best prompts that outperform APE and PromptBreeder on many tasks; PHASEEVO produced few-shot prompts for 20/24 tasks and zero-shot for 4/24 tasks (per paper). Specific per-task scores are reported in Table 17 (many task-level accuracies ~0.6–1.0).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>PHASEEVO outperforms APE zero-shot on 21/24 tasks, outperforms APE few-shot on 17/24 tasks, and outperforms PromptBreeder on 18/24 tasks (counts from paper Table 17).</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>The paper hypothesizes that treating instruction and exemplification jointly (allowing both zero- and few-shot forms) enables finding a format better suited to each task; some tasks benefit from few-shot examples while others are best served by concise instruction-only prompts, so an unrestricted search over format yields superior results.</td>
                        </tr>
                        <tr>
                            <td><strong>null_or_negative_result</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>24 instruction induction tasks; for each task PHASEEVO searched prompts using GPT-3.5 as operator LLM (temperature 0.5 for mutation operators, 0 for evaluation); training/eval/test splits up to 50 train / up to 50 eval / provided test; PHASEEVO selected the prompt with highest dev score and reported test.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PhaseEvo: Towards Unified In-Context Prompt Optimization for Large Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9289.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9289.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how different problem or prompt presentation formats affect the performance of large language models (LLMs) on tasks, including details about the formats, tasks, models, performance metrics, comparisons, and any explanations or findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Initialization format: Pair vs Example (PHASEEVO-pair vs PHASEEVO-example)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Effect of different initialization formats (reverse-engineered input-output pairs vs human example prompts) on BBH tasks</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>PHASEEVO supports two initialization modes: 'pair' (reverse-engineer a prompt from input/output pairs) and 'example' (use human-provided prompt examples). These initialization formats lead to different final prompt forms and markedly different performance on some BBH tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5 (PHASEEVO agents); also evaluated PHASEEVO with GPT-4 for some tasks</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>BBH (Big-Bench Hard) subset — 8 representative tasks</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>A set of 8 challenging reasoning tasks from BBH covering diverse linguistic and reasoning phenomena (e.g., Causal Judgment, Dyck Languages, Hyperbaton, Formal Fallacies, etc.).</td>
                        </tr>
                        <tr>
                            <td><strong>presentation_format</strong></td>
                            <td>PHASEEVO-pair: initialization by Lamarckian reverse engineering from input/output pairs (prompt induced from Q/A pairs). PHASEEVO-example: initialization using human prompt examples (example-format prompts). Both yield prompts that may end up zero-shot or few-shot.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>PHASEEVO-pair versus PHASEEVO-example (direct comparison).</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Per Table 2: example highlights (mean (std) from table) — Causal Judgment: PHASEEVO-pair 69.97 (2.45) vs PHASEEVO-example 84.85 (5.45); Disambiguation: pair 69.90 (3.53) vs example 68.01 (0.40); Dyck Languages: pair 7.06 (1.23) vs example 35.48 (12.18); Hyperbaton: pair 58.49 (0.41) vs example 53.06 (4.95).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>Performance differences vary by task: some BBH tasks (e.g., Causal Judgment, Dyck Languages, Formal Fallacies in table) show large gains for the 'example' initialization, while others (e.g., Disambiguation) favor 'pair' initialization; the effect is task-dependent.</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>Examples from Table 2: Causal Judgment +14.88 absolute (84.85 vs 69.97); Dyck Languages +28.42 absolute (35.48 vs 7.06); Disambiguation -1.89 absolute (68.01 vs 69.90) in favor of 'pair'.</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>The authors attribute differences to the types of prior information each initialization injects: reverse-engineering from input/output pairs yields diverse prompts grounded in task examples (good when examples provide strong signal), while human example prompts encode domain priors that can help on tasks requiring structured guidance; the initialization significantly affects prompt length and content which in turn affects performance.</td>
                        </tr>
                        <tr>
                            <td><strong>null_or_negative_result</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>Evaluations on 8 BBH tasks; population sizes: phase 0 population size 15, later phases population 5; operator tolerances per operator analysis; reported means and standard deviations across 3 random seeds (per implementation details).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PhaseEvo: Towards Unified In-Context Prompt Optimization for Large Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9289.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9289.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how different problem or prompt presentation formats affect the performance of large language models (LLMs) on tasks, including details about the formats, tasks, models, performance metrics, comparisons, and any explanations or findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hamming vs Cosine for candidate similarity</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Using performance-vector Hamming distance vs embedding-cosine similarity to compute candidate similarity for pairing/selection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Instead of using embedding-based cosine similarity, PHASEEVO represents candidate behavior as binary performance vectors over the eval set and computes Hamming distance to pair candidates with complementary error patterns; this yields better search diversity and improved downstream prompt performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>PHASEEVO pipeline with GPT-3.5 operators (similarity calculation is an algorithmic choice independent of base LLM size)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Multiple tasks used in ablation (e.g., Causal Judgment, Disambiguation, Hyperbaton, Salient Translation)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Tasks from BBH and instruction-induction used as evaluation datasets for measuring fitness; performance vectors are computed across evaluation examples.</td>
                        </tr>
                        <tr>
                            <td><strong>presentation_format</strong></td>
                            <td>Candidate similarity computed either by (a) cosine similarity in embedding space (traditional lexical/semantic similarity) or (b) Hamming distance between binary performance vectors (whether candidate got each eval item correct).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Hamming distance (performance-vector) vs cosine similarity (embedding similarity).</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Per Table 5 (ablation): Causal Judgment average: Cosine 64.70 (2.31) vs Hamming 65.74 (2.87); Disambiguation average: Cosine 63.30 (0.00) vs Hamming 64.11 (1.28); Hyperbaton average: Cosine 74.70 (1.60) vs Hamming 79.30 (4.48); Salient Translation average: Cosine 49.56 (1.07) vs Hamming 50.33 (2.32).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>Hamming distance consistently improved or matched average and high scores across the reported tasks, with notable improvement on Hyperbaton (+4.6 absolute average shown).</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>Task examples: Hyperbaton average +4.6 absolute (79.30 vs 74.70); Causal Judgment average +1.04 absolute (65.74 vs 64.70); other tasks show smaller gains (~0.5–1.0).</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Hamming distance over performance vectors tends to pair candidates that make complementary mistakes, increasing genetic diversity during evolution; embedding cosine pairs linguistically similar prompts which may share the same errors, reducing benefit from crossover/EDA.</td>
                        </tr>
                        <tr>
                            <td><strong>null_or_negative_result</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>Ablation runs with same initial population for 4 iterations; similarity thresholding used in EDA selection; evaluation uses per-example correctness vectors to compute binary performance vectors; numbers reported as mean (std) across seeds.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PhaseEvo: Towards Unified In-Context Prompt Optimization for Large Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9289.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9289.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how different problem or prompt presentation formats affect the performance of large language models (LLMs) on tasks, including details about the formats, tasks, models, performance metrics, comparisons, and any explanations or findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Synthetic few-shot generation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Effect of generating synthetic few-shot examples (LLM-created examples) versus selecting examples from training sets</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>PHASEEVO can generate novel synthetic few-shot examples instead of selecting existing dataset examples; manual evaluation shows high fidelity of generated examples and little negative impact on final prompt performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5 (mutator / generator used to create synthetic examples)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Instruction deduction / instruction induction tasks (24 tasks; manual evaluation on examples)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Instruction induction tasks where few-shot examples can be included as in-context demonstrations; authors evaluated correctness of synthetic examples generated by PHASEEVO.</td>
                        </tr>
                        <tr>
                            <td><strong>presentation_format</strong></td>
                            <td>Few-shot prompts whose examples are synthetically generated by the LLM (as opposed to selecting examples from the available training set).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>Selecting few-shot examples from the labeled training set (baseline) versus using synthetic LLM-generated examples.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Manual evaluation on 92 generated examples across 24 instruction tasks: 90/92 examples accurate (97.8%); 24/92 (24.09%) matched samples present in the training set. Authors report that the two inaccurate examples did not change final prompt performance (score remained 94% in that case).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>LLM-generated examples are largely accurate and often novel, enabling PHASEEVO to expand the in-context example space beyond the training set; minor label errors in synthetic examples did not materially degrade prompt effectiveness in the evaluated cases.</td>
                        </tr>
                        <tr>
                            <td><strong>null_or_negative_result</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>Manual adjudication of 92 synthetic examples; 24 matched training samples; two specific incorrect sentiment labels were identified but empirically did not reduce the measured prompt score on the evaluated task.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PhaseEvo: Towards Unified In-Context Prompt Optimization for Large Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9289.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e9289.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how different problem or prompt presentation formats affect the performance of large language models (LLMs) on tasks, including details about the formats, tasks, models, performance metrics, comparisons, and any explanations or findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Prompt length dynamics</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Effect of prompt length variation (shorter vs longer prompts) on performance during PHASEEVO optimization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>PHASEEVO's unrestricted prompt search sometimes reduces prompt length during optimization, producing shorter but more effective prompts, showing that higher performance does not always require longer prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5 (PHASEEVO pipeline)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Various tasks across the benchmark suite (illustrated in Fig. 5)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Multiple tasks where prompt token length was monitored across optimization iterations.</td>
                        </tr>
                        <tr>
                            <td><strong>presentation_format</strong></td>
                            <td>Prompt presentations vary in token length and composition (zero-shot instruction-only to elaborative few-shot); PHASEEVO allows any form.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Qualitative: Fig. 5 shows average prompt token length across iterations can increase, decrease, or oscillate; the paper reports cases where PHASEEVO actively diminishes prompt length while improving performance (no single numeric aggregate effect size given).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>Because PHASEEVO jointly searches instruction and examples without constraints, it can discover concise instruction-only prompts that are more effective for certain tasks; thus longer prompts are not universally better and prompt length alone is not a reliable proxy for quality.</td>
                        </tr>
                        <tr>
                            <td><strong>null_or_negative_result</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>Prompt token length measured across optimization iterations; initialization scheme had significant impact on subsequent prompt length trajectories; operators (Lamarckian/Feedback) can both add and remove examples contributing to length changes.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PhaseEvo: Towards Unified In-Context Prompt Optimization for Large Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9289.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e9289.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how different problem or prompt presentation formats affect the performance of large language models (LLMs) on tasks, including details about the formats, tasks, models, performance metrics, comparisons, and any explanations or findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Detection tasks: prompt-example format (APO config) vs PHASEEVO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Comparison between APO-style prompt-examples format and PHASEEVO-optimized prompts on detection tasks (Ethos, Liar, Sarcasm)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>On three detection tasks configured per APO (prompt examples format), PHASEEVO achieves marginal improvements on simpler tasks and substantial improvement on a harder task (Liar).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>PHASEEVO (GPT-3.5 and GPT-4 variants)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Detection tasks: Ethos (hate speech), Liar (fake news detection), Sarcasm (Arabic sarcasm detection)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Binary or multiclass detection tasks that typically use prompt-example (few-shot) formats following APO configuration.</td>
                        </tr>
                        <tr>
                            <td><strong>presentation_format</strong></td>
                            <td>Prompt examples (few-shot) format as used in APO configuration vs PHASEEVO-optimized prompts (which may be few-shot or zero-shot).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_format</strong></td>
                            <td>APO (Pryzant et al., 2023) prompt-examples format</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Per Table 3: APO reported: Ethos 0.95, Liar 0.51, Sarcasm 0.85. PHASEEVO (GPT-3.5): Ethos 0.96 (0.96), Liar 0.61 (3.85), Sarcasm 0.87 (1.25). PHASEEVO (GPT-4): Ethos 0.96, Liar 0.69, Sarcasm 0.89.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>PHASEEVO marginally better on Ethos (+0.01) and Sarcasm (+0.02–0.04), substantially better on Liar (GPT-3.5: +0.10; GPT-4: +0.18 over APO's 0.51).</td>
                        </tr>
                        <tr>
                            <td><strong>format_effect_size</strong></td>
                            <td>Liar: +0.10 absolute with PHASEEVO (GPT-3.5) vs APO; +0.18 absolute with PHASEEVO (GPT-4) vs APO.</td>
                        </tr>
                        <tr>
                            <td><strong>explanation_or_hypothesis</strong></td>
                            <td>PHASEEVO's joint optimization of instruction and examples and ability to generate synthetic examples appear particularly beneficial on harder detection tasks (e.g., Liar) where example quality and instruction nuance matter more; on simpler tasks gains are marginal.</td>
                        </tr>
                        <tr>
                            <td><strong>null_or_negative_result</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>APO-style configuration followed for those datasets (50 train / 50 eval / 150 test); PHASEEVO run with GPT-3.5 operators and also evaluated using GPT-4 for comparison; reported values include runs with seeds / parentheses in table indicate additional statistics.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'PhaseEvo: Towards Unified In-Context Prompt Optimization for Large Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>APE <em>(Rating: 2)</em></li>
                <li>APO <em>(Rating: 2)</em></li>
                <li>PromptBreeder <em>(Rating: 2)</em></li>
                <li>AELP <em>(Rating: 2)</em></li>
                <li>EvoPrompt <em>(Rating: 2)</em></li>
                <li>OPRO <em>(Rating: 2)</em></li>
                <li>What makes good in-context examples for gpt-3? <em>(Rating: 1)</em></li>
                <li>Instruction induction: From few examples to natural language task descriptions <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9289",
    "paper_id": "paper-267750577",
    "extraction_schema_id": "extraction-schema-163",
    "extracted_data": [
        {
            "name_short": "Zero-shot vs Few-shot (Instruction Induction)",
            "name_full": "Comparison of zero-shot and few-shot prompt presentation formats on instruction induction tasks",
            "brief_description": "The paper reports that PHASEEVO discovers both zero-shot and few-shot prompts and shows that few-shot prompts do not always outperform zero-shot; PHASEEVO-generated prompts (mix of zero- and few-shot) outperform prior zero-/few-shot baselines across many instruction-induction tasks.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5 (primary; GPT-4 also evaluated)",
            "model_size": null,
            "task_name": "Instruction Induction Tasks (24 tasks, Honovich et al. 2022)",
            "task_description": "A suite of 24 instruction-induction tasks that require producing natural-language task descriptions or following short instructions (various language-understanding tasks).",
            "presentation_format": "PHASEEVO-generated prompts that may be zero-shot (instruction-only) or few-shot (instruction + in-context examples); PHASEEVO is free to produce either format depending on task.",
            "comparison_format": "APE (zero-shot and few-shot), PromptBreeder (few-shot). Comparisons use APE zero-shot/few-shot and PromptBreeder few-shot prompts as alternatives.",
            "performance": "PHASEEVO (GPT-3.5) produced best prompts that outperform APE and PromptBreeder on many tasks; PHASEEVO produced few-shot prompts for 20/24 tasks and zero-shot for 4/24 tasks (per paper). Specific per-task scores are reported in Table 17 (many task-level accuracies ~0.6–1.0).",
            "performance_comparison": "PHASEEVO outperforms APE zero-shot on 21/24 tasks, outperforms APE few-shot on 17/24 tasks, and outperforms PromptBreeder on 18/24 tasks (counts from paper Table 17).",
            "format_effect_size": null,
            "explanation_or_hypothesis": "The paper hypothesizes that treating instruction and exemplification jointly (allowing both zero- and few-shot forms) enables finding a format better suited to each task; some tasks benefit from few-shot examples while others are best served by concise instruction-only prompts, so an unrestricted search over format yields superior results.",
            "null_or_negative_result": false,
            "experimental_details": "24 instruction induction tasks; for each task PHASEEVO searched prompts using GPT-3.5 as operator LLM (temperature 0.5 for mutation operators, 0 for evaluation); training/eval/test splits up to 50 train / up to 50 eval / provided test; PHASEEVO selected the prompt with highest dev score and reported test.",
            "uuid": "e9289.0",
            "source_info": {
                "paper_title": "PhaseEvo: Towards Unified In-Context Prompt Optimization for Large Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "Initialization format: Pair vs Example (PHASEEVO-pair vs PHASEEVO-example)",
            "name_full": "Effect of different initialization formats (reverse-engineered input-output pairs vs human example prompts) on BBH tasks",
            "brief_description": "PHASEEVO supports two initialization modes: 'pair' (reverse-engineer a prompt from input/output pairs) and 'example' (use human-provided prompt examples). These initialization formats lead to different final prompt forms and markedly different performance on some BBH tasks.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5 (PHASEEVO agents); also evaluated PHASEEVO with GPT-4 for some tasks",
            "model_size": null,
            "task_name": "BBH (Big-Bench Hard) subset — 8 representative tasks",
            "task_description": "A set of 8 challenging reasoning tasks from BBH covering diverse linguistic and reasoning phenomena (e.g., Causal Judgment, Dyck Languages, Hyperbaton, Formal Fallacies, etc.).",
            "presentation_format": "PHASEEVO-pair: initialization by Lamarckian reverse engineering from input/output pairs (prompt induced from Q/A pairs). PHASEEVO-example: initialization using human prompt examples (example-format prompts). Both yield prompts that may end up zero-shot or few-shot.",
            "comparison_format": "PHASEEVO-pair versus PHASEEVO-example (direct comparison).",
            "performance": "Per Table 2: example highlights (mean (std) from table) — Causal Judgment: PHASEEVO-pair 69.97 (2.45) vs PHASEEVO-example 84.85 (5.45); Disambiguation: pair 69.90 (3.53) vs example 68.01 (0.40); Dyck Languages: pair 7.06 (1.23) vs example 35.48 (12.18); Hyperbaton: pair 58.49 (0.41) vs example 53.06 (4.95).",
            "performance_comparison": "Performance differences vary by task: some BBH tasks (e.g., Causal Judgment, Dyck Languages, Formal Fallacies in table) show large gains for the 'example' initialization, while others (e.g., Disambiguation) favor 'pair' initialization; the effect is task-dependent.",
            "format_effect_size": "Examples from Table 2: Causal Judgment +14.88 absolute (84.85 vs 69.97); Dyck Languages +28.42 absolute (35.48 vs 7.06); Disambiguation -1.89 absolute (68.01 vs 69.90) in favor of 'pair'.",
            "explanation_or_hypothesis": "The authors attribute differences to the types of prior information each initialization injects: reverse-engineering from input/output pairs yields diverse prompts grounded in task examples (good when examples provide strong signal), while human example prompts encode domain priors that can help on tasks requiring structured guidance; the initialization significantly affects prompt length and content which in turn affects performance.",
            "null_or_negative_result": false,
            "experimental_details": "Evaluations on 8 BBH tasks; population sizes: phase 0 population size 15, later phases population 5; operator tolerances per operator analysis; reported means and standard deviations across 3 random seeds (per implementation details).",
            "uuid": "e9289.1",
            "source_info": {
                "paper_title": "PhaseEvo: Towards Unified In-Context Prompt Optimization for Large Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "Hamming vs Cosine for candidate similarity",
            "name_full": "Using performance-vector Hamming distance vs embedding-cosine similarity to compute candidate similarity for pairing/selection",
            "brief_description": "Instead of using embedding-based cosine similarity, PHASEEVO represents candidate behavior as binary performance vectors over the eval set and computes Hamming distance to pair candidates with complementary error patterns; this yields better search diversity and improved downstream prompt performance.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "PHASEEVO pipeline with GPT-3.5 operators (similarity calculation is an algorithmic choice independent of base LLM size)",
            "model_size": null,
            "task_name": "Multiple tasks used in ablation (e.g., Causal Judgment, Disambiguation, Hyperbaton, Salient Translation)",
            "task_description": "Tasks from BBH and instruction-induction used as evaluation datasets for measuring fitness; performance vectors are computed across evaluation examples.",
            "presentation_format": "Candidate similarity computed either by (a) cosine similarity in embedding space (traditional lexical/semantic similarity) or (b) Hamming distance between binary performance vectors (whether candidate got each eval item correct).",
            "comparison_format": "Hamming distance (performance-vector) vs cosine similarity (embedding similarity).",
            "performance": "Per Table 5 (ablation): Causal Judgment average: Cosine 64.70 (2.31) vs Hamming 65.74 (2.87); Disambiguation average: Cosine 63.30 (0.00) vs Hamming 64.11 (1.28); Hyperbaton average: Cosine 74.70 (1.60) vs Hamming 79.30 (4.48); Salient Translation average: Cosine 49.56 (1.07) vs Hamming 50.33 (2.32).",
            "performance_comparison": "Hamming distance consistently improved or matched average and high scores across the reported tasks, with notable improvement on Hyperbaton (+4.6 absolute average shown).",
            "format_effect_size": "Task examples: Hyperbaton average +4.6 absolute (79.30 vs 74.70); Causal Judgment average +1.04 absolute (65.74 vs 64.70); other tasks show smaller gains (~0.5–1.0).",
            "explanation_or_hypothesis": "Hamming distance over performance vectors tends to pair candidates that make complementary mistakes, increasing genetic diversity during evolution; embedding cosine pairs linguistically similar prompts which may share the same errors, reducing benefit from crossover/EDA.",
            "null_or_negative_result": false,
            "experimental_details": "Ablation runs with same initial population for 4 iterations; similarity thresholding used in EDA selection; evaluation uses per-example correctness vectors to compute binary performance vectors; numbers reported as mean (std) across seeds.",
            "uuid": "e9289.2",
            "source_info": {
                "paper_title": "PhaseEvo: Towards Unified In-Context Prompt Optimization for Large Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "Synthetic few-shot generation",
            "name_full": "Effect of generating synthetic few-shot examples (LLM-created examples) versus selecting examples from training sets",
            "brief_description": "PHASEEVO can generate novel synthetic few-shot examples instead of selecting existing dataset examples; manual evaluation shows high fidelity of generated examples and little negative impact on final prompt performance.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5 (mutator / generator used to create synthetic examples)",
            "model_size": null,
            "task_name": "Instruction deduction / instruction induction tasks (24 tasks; manual evaluation on examples)",
            "task_description": "Instruction induction tasks where few-shot examples can be included as in-context demonstrations; authors evaluated correctness of synthetic examples generated by PHASEEVO.",
            "presentation_format": "Few-shot prompts whose examples are synthetically generated by the LLM (as opposed to selecting examples from the available training set).",
            "comparison_format": "Selecting few-shot examples from the labeled training set (baseline) versus using synthetic LLM-generated examples.",
            "performance": "Manual evaluation on 92 generated examples across 24 instruction tasks: 90/92 examples accurate (97.8%); 24/92 (24.09%) matched samples present in the training set. Authors report that the two inaccurate examples did not change final prompt performance (score remained 94% in that case).",
            "performance_comparison": null,
            "format_effect_size": null,
            "explanation_or_hypothesis": "LLM-generated examples are largely accurate and often novel, enabling PHASEEVO to expand the in-context example space beyond the training set; minor label errors in synthetic examples did not materially degrade prompt effectiveness in the evaluated cases.",
            "null_or_negative_result": false,
            "experimental_details": "Manual adjudication of 92 synthetic examples; 24 matched training samples; two specific incorrect sentiment labels were identified but empirically did not reduce the measured prompt score on the evaluated task.",
            "uuid": "e9289.3",
            "source_info": {
                "paper_title": "PhaseEvo: Towards Unified In-Context Prompt Optimization for Large Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "Prompt length dynamics",
            "name_full": "Effect of prompt length variation (shorter vs longer prompts) on performance during PHASEEVO optimization",
            "brief_description": "PHASEEVO's unrestricted prompt search sometimes reduces prompt length during optimization, producing shorter but more effective prompts, showing that higher performance does not always require longer prompts.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5 (PHASEEVO pipeline)",
            "model_size": null,
            "task_name": "Various tasks across the benchmark suite (illustrated in Fig. 5)",
            "task_description": "Multiple tasks where prompt token length was monitored across optimization iterations.",
            "presentation_format": "Prompt presentations vary in token length and composition (zero-shot instruction-only to elaborative few-shot); PHASEEVO allows any form.",
            "comparison_format": null,
            "performance": "Qualitative: Fig. 5 shows average prompt token length across iterations can increase, decrease, or oscillate; the paper reports cases where PHASEEVO actively diminishes prompt length while improving performance (no single numeric aggregate effect size given).",
            "performance_comparison": null,
            "format_effect_size": null,
            "explanation_or_hypothesis": "Because PHASEEVO jointly searches instruction and examples without constraints, it can discover concise instruction-only prompts that are more effective for certain tasks; thus longer prompts are not universally better and prompt length alone is not a reliable proxy for quality.",
            "null_or_negative_result": null,
            "experimental_details": "Prompt token length measured across optimization iterations; initialization scheme had significant impact on subsequent prompt length trajectories; operators (Lamarckian/Feedback) can both add and remove examples contributing to length changes.",
            "uuid": "e9289.4",
            "source_info": {
                "paper_title": "PhaseEvo: Towards Unified In-Context Prompt Optimization for Large Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "Detection tasks: prompt-example format (APO config) vs PHASEEVO",
            "name_full": "Comparison between APO-style prompt-examples format and PHASEEVO-optimized prompts on detection tasks (Ethos, Liar, Sarcasm)",
            "brief_description": "On three detection tasks configured per APO (prompt examples format), PHASEEVO achieves marginal improvements on simpler tasks and substantial improvement on a harder task (Liar).",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "PHASEEVO (GPT-3.5 and GPT-4 variants)",
            "model_size": null,
            "task_name": "Detection tasks: Ethos (hate speech), Liar (fake news detection), Sarcasm (Arabic sarcasm detection)",
            "task_description": "Binary or multiclass detection tasks that typically use prompt-example (few-shot) formats following APO configuration.",
            "presentation_format": "Prompt examples (few-shot) format as used in APO configuration vs PHASEEVO-optimized prompts (which may be few-shot or zero-shot).",
            "comparison_format": "APO (Pryzant et al., 2023) prompt-examples format",
            "performance": "Per Table 3: APO reported: Ethos 0.95, Liar 0.51, Sarcasm 0.85. PHASEEVO (GPT-3.5): Ethos 0.96 (0.96), Liar 0.61 (3.85), Sarcasm 0.87 (1.25). PHASEEVO (GPT-4): Ethos 0.96, Liar 0.69, Sarcasm 0.89.",
            "performance_comparison": "PHASEEVO marginally better on Ethos (+0.01) and Sarcasm (+0.02–0.04), substantially better on Liar (GPT-3.5: +0.10; GPT-4: +0.18 over APO's 0.51).",
            "format_effect_size": "Liar: +0.10 absolute with PHASEEVO (GPT-3.5) vs APO; +0.18 absolute with PHASEEVO (GPT-4) vs APO.",
            "explanation_or_hypothesis": "PHASEEVO's joint optimization of instruction and examples and ability to generate synthetic examples appear particularly beneficial on harder detection tasks (e.g., Liar) where example quality and instruction nuance matter more; on simpler tasks gains are marginal.",
            "null_or_negative_result": false,
            "experimental_details": "APO-style configuration followed for those datasets (50 train / 50 eval / 150 test); PHASEEVO run with GPT-3.5 operators and also evaluated using GPT-4 for comparison; reported values include runs with seeds / parentheses in table indicate additional statistics.",
            "uuid": "e9289.5",
            "source_info": {
                "paper_title": "PhaseEvo: Towards Unified In-Context Prompt Optimization for Large Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "APE",
            "rating": 2
        },
        {
            "paper_title": "APO",
            "rating": 2
        },
        {
            "paper_title": "PromptBreeder",
            "rating": 2,
            "sanitized_title": "promptbreeder"
        },
        {
            "paper_title": "AELP",
            "rating": 2
        },
        {
            "paper_title": "EvoPrompt",
            "rating": 2
        },
        {
            "paper_title": "OPRO",
            "rating": 2
        },
        {
            "paper_title": "What makes good in-context examples for gpt-3?",
            "rating": 1,
            "sanitized_title": "what_makes_good_incontext_examples_for_gpt3"
        },
        {
            "paper_title": "Instruction induction: From few examples to natural language task descriptions",
            "rating": 1,
            "sanitized_title": "instruction_induction_from_few_examples_to_natural_language_task_descriptions"
        }
    ],
    "cost": 0.0205515,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>PhaseEvo: Towards Unified In-Context Prompt Optimization for Large Language Models
17 Feb 2024</p>
<p>Wendi Cui 
Jiaxin Zhang 
Zhuohang Li 
Hao Sun 
Damien Lopez 
Kamalika Das 
Bradley Malin 
Sricharan Kumar 
PhaseEvo: Towards Unified In-Context Prompt Optimization for Large Language Models
17 Feb 2024AFDE6765F86E872FDE31FB1AF59DB650arXiv:2402.11347v1[cs.CL]
Crafting an ideal prompt for Large Language Models (LLMs) is a challenging task that demands significant resources and expert human input.Existing work treats the optimization of prompt instruction and in-context learning examples as distinct problems, leading to sub-optimal prompt performance.This research addresses this limitation by establishing a unified in-context prompt optimization framework, which aims to achieve joint optimization of the prompt instruction and examples.However, formulating such optimization in the discrete and high-dimensional natural language space introduces challenges in terms of convergence and computational efficiency.To overcome these issues, we present PHASEEVO, an efficient automatic prompt optimization framework that combines the generative capability of LLMs with the global search proficiency of evolution algorithms.Our framework features a multi-phase design incorporating innovative LLM-based mutation operators to enhance search efficiency and accelerate convergence.We conduct an extensive evaluation of our approach across 35 benchmark tasks.The results demonstrate that PHASEEVO significantly outperforms the state-of-the-art baseline methods by a large margin whilst maintaining good efficiency.</p>
<p>Introduction</p>
<p>Large Language Models (LLMs) have exhibited extraordinary performance across various domains and tasks (Bubeck et al., 2023;Yang et al., 2023b), largely owing to their remarkable ability of in-context learning (ICL).Prompt engineering seeks to craft effective prompts that unleash the complete capabilities of LLMs.It is becoming an increasingly popular option for quickly adapting LLMs for downstream tasks due to its compatibility with black-box APIs (e.g., GPT-4 (OpenAI, 2023) and PaLM (Chowdhery 1 Intuit 2 Intuit AI Research 3 Vanderbilt University 4 University of Cambridge 5 Vanderbilt University Medical Center.Correspondence to: Jiaxin Zhang <a href="&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#106;&#105;&#97;&#120;&#105;&#110;&#95;&#122;&#104;&#97;&#110;&#103;&#64;&#105;&#110;&#116;&#117;&#105;&#116;&#46;&#99;&#111;&#109;">&#106;&#105;&#97;&#120;&#105;&#110;&#95;&#122;&#104;&#97;&#110;&#103;&#64;&#105;&#110;&#116;&#117;&#105;&#116;&#46;&#99;&#111;&#109;</a>.</p>
<p>Local Global Local</p>
<p>Global</p>
<p>PhaseEvo</p>
<p>Does the provided text contain hate speech?Return a Boolean value of True or False Your task is to evaluate whether the provided input includes any offensive language...For instance, the phrase "You are a fool" is offensive due to its derogatory tone, so you should return 'True'.</p>
<p>The phrase "This is a damn tasty pizza" includes profanity but is not offensive, so you should return 'False'.A good prompt design can substantially improve LLM's performance (Zhu et al., 2023); however, manually tuning a prompt is a long process that often requires significant human effort and expert knowledge.</p>
<p>Automating prompt optimization is a non-trivial task that involves discrete variables and complex high-dimensional spaces (Zhou et al., 2023).To avoid optimizing discrete long prompts, existing research treats the optimization of instruction and examples as separate tasks: one line of research (Pryzant et al., 2023;Chen et al., 2023;Yang et al., 2023a;Guo et al., 2023) takes the zero-shot prompting approach (Kojima et al., 2022) to focus on optimizing a short instruction that comprises one or few sentences; while the other line of work (Liu et al., 2021;Lu et al., 2021;2022;Zhang et al., 2022b;An et al., 2023) emphasizes more the importance of few-shot examples (Brown et al., 2020) and seeks to selecting the best set of examples from a pre-defined dataset given a fixed instruction.Although such treatment effectively reduces the optimization complexity, it overlooks the significance of the interplay between instruction and ex-emplification, resulting in sub-optimal performance (Hsieh et al., 2023).</p>
<p>In this work, we explore the joint optimization of instruction and examples.However, such formulation results in a complex combinatorial optimization problem that naturally brings two challenges: (1) how to design an optimization framework that efficiently navigates the high-dimensional joint space of instructions and examples, steering clear of local minima to ensure continuous performance enhancement?(2) what strategies can be employed to improve the efficiency of the algorithm, enabling fast convergence with a reasonable level of computational complexity?</p>
<p>To address these challenges, we propose PHASEEVO, a unified in-context prompt optimization framework that simultaneously optimizes the prompt instruction and examples.</p>
<p>As illustrated in Figure 1, in contrast to most previous instruction optimization strategies (Zhou et al., 2023;Pryzant et al., 2023;Chen et al., 2023;Guo et al., 2023;Fernando et al., 2023), our formulation does not impose any restrictions or assumptions on the format of the optimized prompt, thereby unlocking the full potential of prompt optimization.Notably, our approach not only explores innovative instructions but is also capable of producing novel examples to further improve the generalizability of LLMs.Consequently, the generated prompt from PHASEEVO is highly adaptive and can take any form from a simple zero-shot instruction-only prompt to an elaborative few-shot prompt with detailed examples, depending on the specific task at hand.Our experiments additionally highlight cases where PHASEEVO actively diminishes the length of the prompt (Fig. 5) during optimization, resulting in shorter yet more effective prompts.This challenges the prevailing notion that prompt engineering typically yields longer prompts that compromise efficiency for performance.</p>
<p>To improve search efficiency in high-dimensional spaces and minimize LLM inference costs, PHASEEVO strategically deviates from the random operation selection seen in traditional evolutionary approaches.Instead, it adopts a quad-phased design, alternating between global search and local optimization.This design aims to strike a balance between exploration and exploitation within the expansive high-dimensional search space.To further improve convergence speed, we conduct an extensive analysis of a suite of LLM-based evolutionary operators to identify their unique strengths and features.Based on our findings, we incorporate two innovative designs to enhance the efficiency and efficacy of the optimization algorithm.First, instead of relying on lexical similarity, we introduce a task-aware similarity metric based on performance-based vectors and hamming distance that achieves better performance.Second, instead of employing a preset step limit for each phase, we design an adaptive termination strategy to ensure the attainment of maximum performance improvement in the current phase before transitioning to the next one.</p>
<p>We conduct an extensive evaluation on a total number of 35 benchmark tasks to compare our method with six latest LLM-based prompt optimization approaches including APE (Zhou et al., 2023), APO (Pryzant et al., 2023), OPRO (Yang et al., 2023a), PromptBreeder (Fernando et al., 2023), EvoPrompt (Guo et al., 2023), and AELP (Hsieh et al., 2023).Our findings indicate that PHASEEVO demonstrates substantial improvements compared to state-of-theart methods, achieving an average improvement of 46% over AELP (Hsieh et al., 2023) on the 8 Big Bench Hard benchmark (Suzgun et al., 2022a).Notably, these advancements are achieved with the lowest computational cost among all methods.</p>
<p>Preliminaries</p>
<p>Problem Formulation.Considering the task T specified by a dataset D = (Q, A) of input/output pairs, the LLM L produces the corresponding output A via prompting with the concatenation of prompt P and a given input Q, i.e., [P; Q].The objective of prompt optimization is to design the best natural language prompt P * that maximizes the performance of L on T .</p>
<p>Typically, an ideal prompt P consists of instruction, denoted by I and examples denoted by E as in-context learning (ICL) demonstrations.Our goal of joint prompt optimization is to search for the optimal prompt P * (I,E) given L that maximizes the performance towards a performance metric function F (e.g., accuracy).This can be formally defined as the following optimization problem:
P * (I,E) = arg max P (I,E) ∈X E (Q,A) F(P (I,E) ; Q, A) | L ,(1)
where X denotes the sample space for a natural language prompt, a discrete and intractable space of arbitrarily large dimension, which makes the optimization problem in Eq.</p>
<p>(1) extremely difficult.</p>
<p>Evolutionary Algorithms.Current evolutionary algorithms utilize a random selection process of evolutionary operators at each phase to create new generations (Fernando et al., 2023;Guo et al., 2023).This type of global optimization approach facilitates exploration of the entire problem space but suffers from extremely high computational cost and slow convergence speed, due to the complexity of navigating the high-dimensional instruction-example joint space.</p>
<p>On the other hand, methods such as Feedback (Pryzant et al., 2023) and self-refinement (Madaan et al., 2023) which are inspired by the idea of gradient descent offer better computational efficiency.However, these methods offer very limited improvement in the prompting performance due to their tendency to steer towards local minima, resulting in sub-  optimal solutions.These challenges motivate us to design an exploration-exploitation strategy that strikes a balance between computational efficiency and prompt performance.</p>
<p>Methodology</p>
<p>We propose to design a unified in-context prompt optimization framework that subsumes both zero-shot and few-shot prompting strategies by jointly optimizing the instruction and examples.To achieve optimal performance while maintaining good efficiency, PHASEEVO employs and alternates between two distinct optimization strategies: (1) Exploration, where evolution operators are leveraged for a global search to broadly explore the entire solution space and prevent entrapment in locally optimal solutions; (2) Exploitation, involving the use of feedback gradient mutation for local search to expedite convergence and improve efficiency.Instead of depending on specific strategies, PHASEEVO aims to organize multiple mutation operators in a unified and organic manner.The selection of the optimal mutation operator at each phase of the optimization process ultimately leads to the maximum performance of the resulting prompt.</p>
<p>Mutation Operator</p>
<p>Following the insight of leveraging global search and local search, we introduce five mutation operators that can be categorized as global operators and local operators.The three global operators are:</p>
<p>• Lamarckian Mutation is a reverse-engineering operator O L that provides instructional prompt by learning from illustrative question-answer pairs  To better harness these mutation operators, we compare them along the following five dimensions that are critical to our exploration-exploitation strategy in terms of performance and efficiency:
(Q, A) = [(Q 1 , A 1 ), ..., (Q m , A m )] so that O L (Q i , L) = A i , i = 1, ..., m given the base LLM L.✓ - - - - • Feedback ✓ ✓ - • • • • •• •• EDA - - ✓ • • •• •• • Crossover - - ✓ • • •• •• • Semantic - ✓ - • • • • • • • • Estimation of
• Add or remove examples.This examines whether an operator can add or remove few-shot examples, to traverse the entire space of a joint prompt optimization problem.• Probability of improvement.This evaluates the probability (successful rate) of an operator that brings performance (score) improvement after iterations.• Convergence speed.This metric aims to evaluate how fast (in terms of iterations) an operator needs to optimize the current candidate to its local minimum solution.• Two or more parents?This indicates whether an operator needs two or more parents, which has the potential to combine genetic information from diverse branches, enhancing global exploration capability.• API cost per operation.It is the number of API calls needed to perform a specific operator via LLM agents.</p>
<p>We conducted a series of experiments where we ran each operator 100 times based on 4 different initialization settings to assess the performance of each operator regarding the five aspects.The goal is to obtain a comprehensive understanding of the inherent strengths and weaknesses of each operator.This allows us to select effective operators to efficiently find optimal solutions.</p>
<p>The evaluation results are presented in   propose to construct candidate vectors based on individual performance on the evaluation dataset, named "performance vectors".To exemplify, in an evaluation dataset comprising five elements, a candidate answering the first three queries correctly and the final two incorrectly would feature a vector representation of [1,1,1,0,0].</p>
<p>Rather than calculating the cosine similarity of embedding space, we propose to compute candidate similarity scores by Hamming distance, which calculates the distance between two vectors of equal length by examining the number of positions at which the corresponding symbols are different.This way ensures that one candidate is more likely to be paired with a candidate that does not contain the same mistakes, and thereby generates a diverse population with a more diverse set of genetic information.</p>
<p>Design 2: Adaptive Phase Stop Criteria.Each evolution phase is fully conducted before we transition to the next.The decision to proceed to the following phase is influenced by two primary criteria.</p>
<p>• Performance Gain.If no performance gain manifests after implementing the operators in a particular phase, it's indicative that the candidate has been thoroughly optimized by the operator.Consequently, we transition to the next phase.</p>
<p>• Operator-specific Tolerance.As operators inherently vary, more localized operators, such as Feedback Mutation, which have high improvement probabilities, could imply readiness for progress when no performance gain is perceived.However, global operators, e.g., evolution operators, might have low initial improvement probabilities but are capable of accessing broader branches worth exploration.Therefore, we assign greater tolerance and run them for a pre-defined time when a global operator does not introduce improvement.More details about the stop criteria can be found in Appendix B.2.</p>
<p>Experiments</p>
<p>Experimental Setup</p>
<p>Tasks and Datasets.We curate 35 benchmark tasks from three domains for thorough experiments: 8 Big Bench Hard (BBH) (Suzgun et al., 2022a); 3 NLP detection tasks, including Ethos (Mollas et al., 2021), Liar (Wang, 2017), and Sarcasm (Farha &amp; Magdy, 2020); 24 instruction induction tasks (Honovich et al., 2022).The task and dataset details are in Appendix D.</p>
<p>Baselines.We evaluate PHASEEVO against a variety of LLM-based approaches that have achieved state-of-the-art performance in prompt optimization:</p>
<p>• APE (Zhou et al., 2023) and APO (Pryzant et al., 2023): APE utilizes an iterative Monte Carlo Search strategy that emphasizes exploration, while APO emphasizes exploitation, which harnesses incorrect instances as feedback gradient to refine the original prompt.• OPRO (Yang et al., 2023a): OPRO leverages LLM as optimizers to generate better instruction via meta-prompt, solution-score pairs, and task descriptions.• PromptBreeder (Fernando et al., 2023), EvoPrompt (Guo et al., 2023) and AELP (Hsieh et al., 2023): these methods connect LLMs with evolution algorithms (EAs) to tackle prompt optimization tasks.Specifically, Evo-Prompt implements EAs using genetic algorithm (Holland, 1992) and differential evolution (Storn &amp; Price, 1997), while PromptBreeder introduces multiple mutation operators inspired by thinking styles.AELP focuses on long prompt optimization by mutating on a sentence level with a history-guided search.</p>
<p>Implementation Details.We utilized GPT-3.5 to develop LLM agents capable of performing various mutation operators.We set up training, development, and testing datasets, select the prompt with the highest score on the dev set, and report its score on the testing set.We run all the experi-  ments by setting 3 random seeds and the standard deviation is provided.More details are provided in Appendix D.
C R + D C R ED A + I ED A C R ED A C R + D ED A + I C R C R C R</p>
<p>Main Results</p>
<p>BBH Tasks.Following the practice of AELP (Hsieh et al., 2023), we conduct 8 BBH tasks to evaluate the performance of PHASEEVO holistically.We consider two initialization schemes PHASEEVO-pair and PHASEEVO-example and report the final results in Table 2. PHASEEVO demonstrates substantial improvements compared to state-of-the-art methods, achieving an average improvement of over AELP (46.0%↑),EvoPromopt (20.3%↑), and OPRO (23.5%↑).</p>
<p>Fig. 3 depicts the iterative history of prompt evolution, emphasizing the score variations for the best candidate, worst candidate, and the population's average across iterations.It has been observed that Feedback Mutation yields a performance boost within a single iteration and rarely introduces continual improvements.Global operators such as EDA and Crossover aid in escaping local minima and offering additional performance leaps (refer to Hyperbaton).This observation aligns with our initial operator analysis.The success of PHASEEVO lies in the organic organization of these mutation operators, effectively harnessing their advantages to maximum performance.</p>
<p>Detection Tasks.To present a more expansive comparison, we adopted the configuration outlined in APO (Pryzant et al., 2023) and conducted a comparative analysis against it across three tasks.It should be noted that data for the fourth task mentioned in the original paper is unavailable.Ac-cording to Table 3, PHASEEVO exhibits marginally superior performance to APO in relatively simple tasks such as Ethos (by 1%) and Sarcasm (by 4.7%).However, for more complex tasks such as Liar, PHASEEVOdemonstrates a significant improvement of 19.6% compared to APO.Moreover, we have also provided results for PHASEEVO using GPT-4, which demonstrated performance comparable to those of PHASEEVO employing GPT-3.5.</p>
<p>Analysis</p>
<p>Phase Evolution vs Random Evolution.To compare our PHASEEVO method with the random evolution strategy, we conducted additional experiments on four tasks from BBH.Using the same initial population and six iterations, we presented the average score and highest score of the population in Table 4. Significantly, PHASEEVO outperformed random evolution in both average and highest scores for all tasks.Such effectiveness is attributed to the advantages of our well-organized operators through the employment of the dual exploration-exploitation strategy.</p>
<p>Effect of Hamming Distance.An ablation study has been conducted to examine the impact of hamming distance on the performance-based vectors in comparison to the traditional cosine distance for similarity calculation.The study encompasses both distance calculations carried out in 4 iterations using the same initial population.2.</p>
<p>Effect of Operators on Prompt Length.Our method aims to explore the entirety of the prompt space, spanning both zero-shot and few-shot scenarios.Understanding the variation in prompt length and the impact of the operator on this fluctuation is crucial.Fig. 5 provides a visual representation of the average prompt token length throughout the iterations.Interestingly, the length can either increase, decrease, or oscillate, which aligns with the "unfettered" expectations of global search.Specifically, we observed the initialization phase had a significant impact on prompt length.This observation is in agreement with our analysis of the Lamarckian and Feedback operators, which hold the power to both add and remove examples.Synthetic Few-shot Examples.We observe that in certain cases PHASEEVO would generate novel synthetic few-shot examples instead of selecting from existing ones.To verify their veracity, we conduct a manual evaluation of the accu- racy of the few-shot examples generated by PHASEEVO on a total of 24 instruction deduction tasks.We find that 90 out of the 92 examples evaluated (97.8%) are accurate.Among them, 24 out of the 92 (24.09%) are aligned with samples present in the training set.There are two cases where the synthetic example is inaccurate: the sentiment of "A nonmystery mystery" is identified as "neutral" where the ground truth is "negative", and "Little more than a well-mounted history lesson" is identified as "neutral" where the ground truth is "negative".In both cases, we empirically validate that such a level of inaccuracy does not influence prompt performance (score remained 94% regardless of the labels).</p>
<p>Computational Cost.We monitor the computational cost of PHASEEVO based on the number of model API calls consumed by evaluation and operator application, and the number of iterations.As shown in Fig. 6, PHASEEVO is the most cost-effective method that significantly reduces multiple orders of magnitude compared to evolution strategies, such as PromptBreeder.PHASEEVO also performs competitively in terms of iterations compared to the gradient descent approach, e.g., APO.</p>
<p>Related Work</p>
<p>In-context prompting is an efficient approach for communicating LLMs but the performance is strongly affected by the design of the prompt in specifized tasks.Prompt optimization has thus obtained broader attention.One research direction is the continuous prompt approaches that tune embeddings of input tokens to generate better prompts (Li &amp; Liang, 2021;Zhang et al., 2021;Sun et al., 2022b;a;Chen et al., 2023).However, the optimized "soft" prompts from this paradigm often fall short of interpretability and are inaccessible for blackbox APIs.Discrete prompt approaches (Diao et al., 2022;Prasad et al., 2022), operating discrete tokens directly, offer an interactive interface to humans with better interpretability and show promising performance in various NLP tasks.Various methods have been proposed via gradient-based search (Shin et al., 2020), reinforcement learning (Zhang et al., 2022a;Deng et al., 2022;Sun et al., 2023) and ensemble methods (Hou et al., 2023;Pitis et al., 2023) while these methods encounter concerns in terms of scalability, reliability and efficiency (Wang et al., 2023).</p>
<p>More recent advancements rely on iterative sampling, scoring, and selection of exceptionally promising prompts, generating diverse possibilities for prompt optimization.2023) utilizes natural language feedback to refine prompt instructions.However, these prompt evolution/refinement strategies largely focus on prompt instructions, typically short sentences or paragraphs.Our research reformulates the problem by permitting unrestrained evolution of a unified in-context prompt, incorporating both instructions and examples, offering more avenues for improvement, yet it also poses new challenges with regard to navigating the high-dimensional joint space, while retaining high efficiency.While previous search and sampling algorithms have been investigated, such as Monte Carlo search (Zhou et al., 2023), Gibbs sampling (Xu et al., 2023), or Beam search (Pryzant et al., 2023), we introduce a novel dual exploration-exploitation strategy that leverages the indepth traits of each operator, utilizing an intuitive blend of global-local search, conducive to enhancing interactive dynamics during optimization.</p>
<p>Conclusion and Discussion</p>
<p>In this work, we propose a unified in-context prompt optimization framework that enables the joint optimization of prompt instruction and few-shot examples.Benefiting from the global-local phased optimization schedule and the design of novel LLM-based mutation operations, PHASEEVO achieves state-of-the-art performance over a wide range of benchmark tasks.Despite having achieved the lowest computational requirements among all baselines, PHASEEVO still needs around 12 iterations and 4, 000 API calls, which might be insufficient for supporting large-scale online applications.Future work could explore better initialization strategies or data compression techniques to further improve efficiency and reduce latency.</p>
<p>A. Operator Definition</p>
<p>Operators are used to generate new candidates.Seven types of operators, broadly categorized into five classes are used by PHASEEVO.The idea is to provide a diverse set of operators so that a broad cognitive space of linguistics is covered.</p>
<p>A.1. Lamarckian Mutation</p>
<p>Lamarckian Mutation follows the principles proposed in APE and Prompt Breeder (Zhou et al., 2023;Fernando et al., 2023).Given a set of input-output pairs for the task, an LLM agent is used to reverse-engineer the prompt from the provided demonstrating pairs.This type of mutation allows a diverse set of prompt candidates to be generated with no prior knowledge of the task.Any prompt candidate will have to be induced from the demonstrating pairs.The prompt used by the LLM agent is in Table 10.
Definition A.1. (Lamarckian Mutation) Given a set of input/output pairs (Q, A) = [(Q 1 , A 1 ), ..., (Q m , A m )] and a base LLM L, Lamarckian Mutation is to reverse engineer the instruction O L so that O L (Q i ) = A i , i = 1, ..., m.</p>
<p>A.2. Feedback Mutation</p>
<p>As evolution algorithms can take a while to converge, inspired by the concept of Gradient Descent in machine learning model training, we introduce an LLM agent that works as an examiner which examines the cases where the current task prompt fails and provides improvement guidance.Such guidance will be treated as gradient and be used by another LLM Agent as an improver to generate a new candidate.Though similar to what is proposed in APO (Pryzant et al., 2023), instead of only using gradient descent repeatedly, which has a higher probability of arriving at a local minimum, we take advantage of its fast converge rate to local minimum and combine it with an evolutionary algorithm to target global minimum.When applying Feedback Mutation, it will be applied to every candidate in the current generation.The prompt can be found in Table 11 -</p>
<p>A.3. ESTIMATION OF DISTRIBUTION MUTATION</p>
<p>The next class of operators takes a set of parents as input to generate a mutated candidate for the next generation.</p>
<p>Estimation of Distribution Mutation (EDA): Following the principles proposed by (Hauschild &amp; Pelikan, 2011) and work in (Fernando et al., 2023), we use a LLM agent that is fed with a subset of the current population to generate new candidate.To ensure the diversity and quality of the subset, we first rank the candidates in the current population by their fitness score in descending order.Then starting from the first item in the ordered candidates, we only add the candidate to the subset if it does not have a similarity score over a threshold with any other candidate that is already in the subset.This way candidates with higher fitness scores are more prone to be added to the subset and the diversity of the subset is achieved.More details on how similarity is calculated can be found in section 3.3.The subset will be randomized before feeding into the LLM agent so the candidate's fitness score does not dictate its order.The prompt can be found in Table 13.</p>
<p>EDA and Index Mutation: This is a variant of the EDA mutation above.Based on the observations that LLM is more prone to use examples that appear late in the in-context learning (Liu et al., 2023;Fernando et al., 2023), after generating the subset following procedures of EDA, the subset is ordered by their fitness score in ascending order.To further balance exploitation and exploration and avoid being too biased over the candidate with the highest fitness score (Fernando et al., 2023), we instructed LLM that the candidates are ranked by their fitness score in descending order so that the low health score candidates are taken into consideration during mutation.The prompt can be found in Table 14.</p>
<p>Definition A.3. (Estimation of Distribution Mutation -EDA) EDA generates a new candidate based on a list of parents.It is a function operator O E that performs O E (P,L) = p ′ .Given a list of prompts P = [p 1 , ..., p m ] and an LLM L, EDA provides a new prompt p ′ .Items in P satisfy the restriction that d(p i , p j ) &lt; t, where d is a function that calculates similarity, and t is a predefined threshold.If the items in P are ordered based on certain criteria, we call it EDA + Index (EDA+I).</p>
<p>A.4. Crossover Operator</p>
<p>This class of operators takes two parents as input to generate a crossover candidate for the next generation.The prompt can be found in Table 15.</p>
<p>Crossover Operator(CR): Following the concept of crossover in the evolution algorithm, we introduce an LLM agent to function as a crossover operator that takes two parents and generates a crossover candidate.It takes the best two candidates in the current population, namely the top two candidates with the highest fitness scores, and performs linguistic crossover.</p>
<p>Crossover with Diversity Operator(CR+D): This is a variance of the Crossover Operator.To provoke exploration, we follow a similar process in EDA where diversity in parents is considered.Thus it takes the best candidate and the most distinct individual to it as two parents for crossover operation.The distinctness between two candidates is measured by a similarity score.More details on how the similarity score is calculated can be found in section 3.</p>
<p>A.5. Semantic Mutation</p>
<p>This class of operators takes a candidate and uses an LLM agent to compose a new candidate that shares its semantic meaning.When applying Semantic Mutation, it will be applied to every candidate in the current generation.The prompt can be found in Table 16.</p>
<p>Definition A.5. (Semantic Mutation) Semantic Mutation is a function operator O S that performs O S (p, L) = p ′ where p′ is the generated prompt that shares the same semantic meaning as p.</p>
<p>B. Operator Analysis B.1. Few-Shot Additional / Removal Analysis</p>
<p>The ability to add and remove few-shot examples is crucial in dictating whether it is possible to traverse the full in-context prompt space.Thus we conduct the few-shot addition/ removal analysis to gauge each operator's capabilities.Below are examples of how operators add or remove few-shot examples.</p>
<p>Original Prompt</p>
<p>For each word, find its antonym and write it as the output.</p>
<p>Generated Feedback</p>
<ol>
<li>
<p>Clarify the definition of "antonym" to ensure that the prompt is asking for the opposite meaning of the word, rather than just a different word that is related in some way.</p>
</li>
<li>
<p>Provide more specific instructions for determining the antonym, such as indicating whether the opposite meaning should be an adjective or a noun.</p>
</li>
<li>
<p>Add a list of common antonyms for each word to help users who may not be familiar with all possible opposites.4. Provide a context or sentence for each word to help users determine the appropriate antonym.</p>
</li>
</ol>
<p>Generated Prompt</p>
<p>For each word, find its antonym, which is a word that has the opposite meaning, and write it as the output.The antonym should be a word that is commonly used to express the opposite meaning of the given word, and it should be of the same part of speech (e.g.noun, verb, adjective, adverb).</p>
<p>To help you identify the antonym, we have provided a list of common antonyms for each word.Additionally, we have included a context or sentence for each word to help you determine the appropriate antonym.</p>
<p>Example: Word: Hot Antonym: Cold Context: The soup is too hot to eat.</p>
<p>Please note that some words may have multiple antonyms depending on the context, so use your best judgment to determine the most appropriate one.</p>
<p>Original Prompt</p>
<p>For each word, remove the prefix or suffix that indicates a negative or opposite meaning, and write the resulting word as the output.</p>
<p>For example, for the input "destabilize," remove the prefix "de-" which indicates a negative meaning, and the resulting word is "stabilize Generated Feedback 1.Clarify the prompt to specify that it only applies to words with a negative or opposite prefix or suffix.This will prevent confusion and mistakes when dealing with words that do not have such affixes.</p>
<p>2.</p>
<p>Provide examples of common negative or opposite prefixes and suffixes, such as "un-" or "-less," to help users identify them more easily.</p>
<ol>
<li>
<p>Include a check to ensure that the resulting word is a valid English word, to avoid outputs like "ane" or "direct" that are not actual words.This could be done by cross-referencing the output with a dictionary or word list.</p>
</li>
<li>
<p>Consider adding an option to retain the original word if no negative or opposite prefix or suffix is present.This would eliminate confusion when dealing with words like "linear" that do not have such affixes.</p>
</li>
</ol>
<p>Generated Prompt</p>
<p>For each word that contains a negative or opposite prefix or suffix, remove the affix and write the resulting word as the output.Common negative or opposite prefixes and suffixes include "un-," "dis-," "in-," "-less," and "-ful."Please note that this prompt only applies to words with these specific affixes.</p>
<p>To ensure that the resulting word is a valid English word, we will cross-reference the output with a dictionary or word list.If the resulting word is not a valid English word, it will be excluded from the output.</p>
<p>If the original word does not contain a negative or opposite prefix or suffix, you may choose to retain the original word or exclude it from the output.Please specify your preference in the input.</p>
<p>Operator Input</p>
<p>Order adjectives correctly in English sentences.Q: Which sentence has the correct adjective order: Options: (A) rubber terrible ship (B) terrible rubber ship A: Let's think step by step.When there is more than one adjective before a noun, the adjectives need to respect the following order before a noun: " [1. opinion] [2. size] [3. age] [4. shape] [5. color] [6. origin] [7. material] [8. purpose] noun".Option (A): "rubber terrible ship".( 1) rubber" falls into the material category.( 2) "terrible" falls into the opinion category.Option (A) has the following adjective order: [7. material] [1. opinion] (or, in numeric terms, 7 1).Because 7 &lt; 1 is not correct, (A) does not have the correct ordering.Option (B): "terrible rubber ship".Option (B) has the following adjective order: [1. opinion] [7. material] (or, in numeric terms, 1 7).Because 1 &lt; 7 is correct, (B) has the correct ordering.So the answer is (B).</p>
<p>Q: Which sentence has the correct adjective order: Options: (A) repulsive small Brazilian exercise ship (B) Brazilian repulsive exercise small ship A: Let's think step by step.When there is more than one adjective before a noun, the adjectives need to respect the following order before a noun: " [1. opinion] [2. size] [3. age] [4. shape] [5. color] [6. origin] [7. material] [8. purpose] noun".Option (A): "repulsive small Brazilian exercise ship".( 1) "repulsive" falls into the opinion category.( 2) "small" falls into the size category.( 3) "Brazilian" falls into the origin category.( 4) "exercise" falls into the purpose category.Option (A) has the following adjective order: [1. opinion] [2. size] [6. origin] [8.purpose] (or, in numeric terms, 1 2 6 8).Because 1 &lt; 2 &lt; 6 &lt; 8 is correct, (A) has the correct ordering.Option (B): "Brazilian repulsive exercise small ship".Option (B) has the following adjective order: [6. origin] [1. opinion] [8. purpose] [2.size] (or, in numeric terms, 6 1 8 2).Because 6 &lt; 1 &lt; 8 &lt; 2 is not correct, (B) does not have the correct ordering.So the answer is (A).</p>
<p>Q: Which sentence has the correct adjective order: Options: (A) blue gold wonderful square shoe (B) wonderful square blue gold shoe A: Let's think step by step.When there is more than one adjective before a noun, the adjectives need to respect the following order before a noun: " [1. opinion] [2. size] [3. age] [4. shape] [5. color] [6. origin] [7. material] [8. purpose] noun".Option (A): "blue gold wonderful square shoe".( 1) "blue" falls into the color category.( 2) "gold" falls into the material category.( 3) "wonderful" falls into the opinion category.( 4) "square" falls into the shape category.The adjective order that Option (A) has is [5. color] [7. material] [1. opinion] [4.shape] (or, in numeric terms, 5 7 1 4).Because 5 &lt; 7 &lt; 1 &lt; 4 is not correct, (A) does not have the correct ordering.Option (B): "wonderful square blue gold shoe".Option (B) has the following adjective order: [1. opinion] [4. shape] [5. color] [7. material] (or, in numeric terms, 1 4 5 7 ).Because 1 &lt; 4 &lt; 5 &lt; 7 is correct, (B) has the correct ordering.So the answer is (B).</p>
<p>Operator Output</p>
<p>Rearrange the adjectives in the given sentence in the correct order.</p>
<p>B.2. Operator Feature Analysis</p>
<p>To study the features of each operator we conduct a preliminary experiment where we study four operators: EDA Mutation, Crossover, Feedback Mutation, and Semantic Mutation.</p>
<p>Initialization: As the initialized points have a tremendous impact on optimization problems.We randomly use four different seeds to create four initial populations for four different tasks: Causal Judgement, Salient Translation Error Detection, Disambiguation QA, and Hyperbaton.The idea is to provide various initialization points so that the performance of operators can be averaged to rule out the influence of initialization.</p>
<p>Operator Applications: For each initialization, we apply the following procedure for all four operators.</p>
<p>• For one round, starting with the initial population, we consecutively apply the operator 5 times.This is to study the value of applying the operator consecutively.</p>
<p>-For EDA and CrossOver, as they require multiple parents, we keep a population size of 5 for each generation after applying the operator.Performance gain is defined as whether the average health of the population is improved.-For Feedback Mutation and Semantic Mutation, as they only need one parent, we apply them to a random candidate from the initial population and use the new candidate as the base for the next mutation.Performance gain is defined as whether the new candidate has a higher fitness score than its parent.</p>
<p>• To reduce the impact of randomness during mutation, we run this process 5 rounds for each operator.</p>
<p>Thus for each operator, it will be run a total of 4 tasks * 5 rounds * 5 application = 100 times.• Probability Of Improvement: Figure 7 shows the number of times performance is improved by each operator.</p>
<p>EDA</p>
<p>Crossover and EDA Mutation introduces improvements in more steps with Semantic Mutation ranking third.Feedback Mutation introduces the least number of improvements.This result helps populate the Prob column in table 1.</p>
<p>• Convergence Speed: Figure 8 shows that for each operator, as they are applied in 5 consecutive steps, the number of times improvement is introduced for each step.Figure 9 shows the average percentage of performance gain operators brought in each step.</p>
<p>-For EDA Mutation and Crossover, each 5 step has a similar number of contributions for performance gains as shown in figure 8. From figure 9 we can also observe the first step brings the most improvement and the first 4 steps bring a similar improvement ratio.</p>
<p>-For Feedback Mutation and Semantic Mutation, the first step has a significantly higher chance of introducing improvement as shown in figure 8.This is especially true for Feedback Mutation where step 1 accounts for over 34% of the total improvement counts.As for the improvement ratio, the first step for both Feedback Mutation and Semantic Mutation introduces significantly more improvements than the rest of the steps shown in figure 9.</p>
<p>Based on the tests, we learned that the value gained for applying Feedback Mutation and Semantic Mutation is significantly reduced after the 1st application.We interpret it as Feedback Mutation and Semantic Mutation can jump to the local minimum pretty fast, namely in 1 step, thus leading to less possibility of improvement for steps 2 -5.Whereas for EDA Mutation and Crossover, as they are merging genetic information between candidates, the likelihood of improvement is relatively randomized.So even if the first round of applying them renders no improvement, there is still a chance of performance gain in the following run.In other words, we should be more patient with EDA Mutation and Crossover.Thus the operator tolerance (described in section 3.3-design 2) for EDA and Crossover is set to 4 and for Feedback Mutation and Semantic Mutation is 1.These learnings help populate the Speed column in table 1.  Step 1</p>
<p>EDA</p>
<p>Step 2</p>
<p>Step 3</p>
<p>Step 4</p>
<p>Step 5</p>
<p>Figure 9: Improvement Ratio: On the left, for EDA and Crossover, we observe an almost equal improvement ratio for the first four steps.Improvement Ratio is defined as the relative percentage of improvement in the average fitness score for the entire population.On the right, for Feedback and Semantic Mutation, we observe the first round contributes significantly more improvement compared to the others.As Feedback and Semantic Mutation take one input candidate, Improvement Ratio is defined as the relative performance improvement percentage for the candidate after mutation.</p>
<p>C. Operator Prompts</p>
<p>Operator Implementation: The state-of-art frameworks such as APO, EVOPROMPT, and AELP have already implemented operators such as feedback operator, crossover operator, and semantic operator with LLM.However, these implementations inflict restrictions on LLM with prompts.For example, in APO when implementing the feedback operator, the prompt specifically identified the use case to be zero-shot.(Pryzant et al., 2023) In EVOPROMPT-DE, when applying crossover operators, the focus is to only mutate the parts that two parents differentiate from each other.(Guo et al., 2023) In AELP, when applying semantic operators, it is restricted to a sentence level, not the whole prompt.(Hsieh et al., 2023).In PHASEEVO, we pay special attention not to apply any restrictions in our mutation prompt, realizing the full potential of LLMs.</p>
<p>Table 10: Lamarckian Mutation Prompt I gave a friend an instruction and some inputs.The friend read the instruction and wrote an output for every one of the inputs.Here are the input-output pairs:</p>
<h2 input="input" output="output" pairs="pairs">Example</h2>
<p>The instruction was:</p>
<p>Table 11: Gradient Descent Generation Prompt: Unlike APO which is also using gradient descent, we are NOT adding restrictions such as "zero-shot classifier prompt.",nor providing any differentiation between instructions and examples.Instead, we specifically ask LLM to output multiple feedback in one go.Also as are passing in the existing prompt as a whole, thus feedback should be on the paragraph/prompt level instead of the sentence/instruction level.We highlight the design that helps us achieve this below.</p>
<p>You are a quick improver.Given an existing prompt and a series of cases where it made mistakes.Look through each case carefully and identify what is causing the mistakes.Based on these observations, output ways to improve the prompts based on the mistakes.</p>
<h2 existing="existing" prompt="prompt">Existing Prompt</h2>
<h2>Cases where it gets wrong:## {wrong cases} ways to improve the existing prompt based on observations of the mistakes in the cases above are:</h2>
<p>Table 12: Gradient Descent Application Prompt: Following the principle of optimizing prompt as a whole, our operator prompts take input and output on the entire prompt level You are a quick improver.Given an existing prompt and feedback on how it should improve.Create an improved version based on the feedback.</p>
<h2>Existing Prompt ## {existing prompt} ## Feedback## {feedback} ## Improved Prompt## Table 13: EDA Prompt</h2>
<p>You are a mutator.Given a series of prompts, your task is to generate another prompt with the same semantic meaning and intentions.</p>
<h2 existing="existing" prompt="prompt">Existing Prompts</h2>
<p>The newly mutated prompt is:</p>
<p>Table 14: EDA+Index Prompt: The difference between EDA + Index and EDA is that EDA + Index takes advantage of the in-context learning technique and informs the order of the passed-in prompts You are a mutator.Given a series of prompts, your task is to generate another prompt with the same semantic meaning and intentions.The series of prompts are ranked by their quality from best to worst.</p>
<h2 existing="existing" prompt="prompt">Existing Prompts</h2>
<p>The newly mutated prompt is: • APO (Pryzant et al., 2023) uses feedback provided by LLM as gradients to approach prompt optimization.It uses beam search to find the best candidate.As it reports averaged performance, we are using the averaged performance to compare.</p>
<p>• PromptBreeder (Fernando et al., 2023) uses the evolution algorithm to tackle prompt optimization tasks and utilizes thinking styles, and mutation prompts to surface the best task prompt.As it reports the best candidate, we are using the best candidate to compare.</p>
<p>• AELP (Hsieh et al., 2023) uses existing prompts (Suzgun et al., 2022b) to target long prompt optimization and improves them by mutating on a sentence level with history-guided search.As it reports averaged performance, we are using the averaged performance to compare.</p>
<p>• EVOPROMPT (Guo et al., 2023) uses crossover mutation and semantic mutation with an evolution algorithm to find the best prompt.As it reports the best candidate, we are using the best candidate to compare.</p>
<p>• OPRO (Yang et al., 2023a) uses meta prompt, solution-score pairs, and task descriptions to generate candidates.As it reports the best candidate, we are using the best candidate to compare.</p>
<p>D.2. Benchmark tasks</p>
<p>• 24 Instruction Induction Tasks: These 24 instruction tasks (Honovich et al., 2022) span many facets of language understanding, from simple phrase structure to similarity and causality identification.Both training and testing data are provided for these tasks and we create our training and evaluation data set from the available training data and use the provided testing data set as is.Depending on the task, we use up to 50 training data and up to 50 evaluation data.We use input output pair format for these tasks.</p>
<p>• Ethos: Ethos (Mollas et al., 2021) is an online English hate speech detection data set with 997 online comments and hate speech labels.We select 50 for training, 50 for evaluation, and 150 for testing.We use prompt examples format for this data set following the practice of APO (Pryzant et al., 2023).</p>
<p>• Liar: Liar (Wang, 2017) is an English fake news detection data set with 4000 statements, context, and lie labels.We select 50 for training, 50 for evaluation, and 150 for testing.We use prompt examples format for this data set following the practice of APO (Pryzant et al., 2023).</p>
<p>• Sarcasm: Sarcasm (Farha &amp; Magdy, 2020) is an Arabic sarcasm detection data set with 10,000 online comments and sarcasm labels.We select 50 for training, 50 for evaluation, and 150 for testing.We use prompt examples format for this data set following the practice of APO (Pryzant et al., 2023).</p>
<p>• BBH: BBH (Aarohi &amp; bench authors, 2023) is a collaborative benchmark that aims to quantitatively measure the capabilities and limitations of language models.We followed the same practice in the AELP paper with the same tasks and randomly selected 50 for training, 50 for evaluation, and 125 for test.(Hsieh et al., 2023)</p>
<p>D.3. PHASEEVO Setting</p>
<p>• Population Size: In the experiments, for phase 0: Global initialization we set the population size to be 15.For the rest phases, we set the population to be 5.</p>
<p>• Operator Tolerance: Based on operator analysis in section B.2, the tolerance for Feedback Mutation and Semantic Mutation is set to 1.The tolerance for EDA Mutation and Crossover is set to 4. Thus the minimum number of times mutation will be applied in phase 2: global evolution mutation is 8.</p>
<p>• Model Configuration: For operators, we set the temperature to 0.5 to tap into LLM's creativity.For evaluations, we set the temperature to 0.</p>
<p>• Performance Gain in Stop Criteria: To improve efficiency, when evaluating performance gain to decide whether we should move to the next phase, we are only looking at the best candidate in the current population.</p>
<p>• New Generation Selection: To improve efficiency, after getting new candidates, we combine them with the current generation and use a greedy algorithm to select the top performer to be the new generation.</p>
<p>E. Additional Experiment Results</p>
<p>E.1.24 Instruction Induction Tasks PHASEEVO Create a list of words that rhyme with the given word.To ensure that your rhymes are accurate, make sure that the words have the same vowel sound and ending consonant sound.For example, "cat" rhymes with "bat" and "hat," but not with "dog" or "mat."</p>
<p>To get started, here are some examples of words that rhyme with the given word:</p>
<p>-Love: dove, glove, above, shove, of -Time: rhyme, chime, climb, mime, prime</p>
<p>To find more rhyming words, you can use a rhyming dictionary, online resources, or brainstorm with friends.Be creative and try to use a variety of different rhyming words instead of repeating the same one multiple times.</p>
<p>To avoid common pitfalls, make sure to double-check your spelling and pronunciation of the words.Also, avoid using words that only partially rhyme or have a different stress pattern.</p>
<p>After you've created your list, ask for feedback on the quality of your rhymes.This can help you to improve and refine your skills.</p>
<p>For an added challenge, consider generating rhyming words that fit a particular theme or context.This can help you to focus your creativity and generate more interesting and relevant rhymes.</p>
<p>F. Few-shot Add/ Removal Examples</p>
<p>Output Prompt</p>
<p>Your task is to evaluate whether the provided input includes any offensive language.This could be language that is sexist, racist, discriminatory, or advocates violence or harm.</p>
<p>Offensive language can also be identified by an aggressive or belittling tone.However, remember that the mere presence of profanity does not necessarily make a statement offensive.</p>
<p>The context and intention behind the statement should also be taken into account.If none of these conditions are fulfilled, return 'False'.</p>
<p>For instance, the phrase "You are a fool" is offensive due to its derogatory tone, so you should return 'True'.On the other hand, the phrase "This is a damn tasty pizza" includes profanity but is not offensive, so you should return 'False'.Similarly, a phrase like "All people of X race are lazy" is offensive because of its racist undertones, so you should return 'True'.In contrast, a phrase like "I dislike the color yellow" is not offensive, so you should return 'False'.In English grammar, the order of adjectives is important to convey accurate and effective descriptions.Here are two examples of sentences with adjectives.Determine which sentence has the correct adjective order.Choose the letter of the sentence with the correct adjective order as your answer.</p>
<p>F.2. Zero-shot to Zero-shot</p>
<p>Note: Adjective order generally follows the pattern of opinion, size, age, shape, color, origin, material, and purpose.If the adjectives do not fit into this pattern, the order is determined by the speaker's preference.</p>
<p>If you choose the incorrect sentence, we will explain why it is wrong to help you learn from your mistakes.Good luck!</p>
<p>G. Generated Prompts</p>
<p>In this section, we list the prompts generated by PHASEEVO with the best performance for each task.All prompts are generated by gpt-3.5.We observe a mix of few-shot prompts and zero-shot prompts for different tasks.This indicates both LLM's ability to perform in-context prompt optimization and PHASEEVO's ability to traverse the whole problem space to find optimal solutions.We also notice that the few-shot examples in the final prompts are largely generated by LLM instead of copied from example instruction or training sets.Thus it serves as further proof of LLM's capability of in-context prompt optimization and PHASEEVO's credibility in this problem space.</p>
<p>Table 24: BBH Prompts</p>
<p>Causal Judgment</p>
<p>Provide reactions to intentional actions in diverse scenarios, while also considering causation and its complexities.To assist with determining causation, provide specific guidelines and examples for each scenario.To avoid any confusion or misinterpretation, precise language and definitions will be used throughout the prompt.Additionally, feedback from experts and individuals with relevant experience in the field of causation will be incorporated to ensure accuracy and relevance.To challenge users' critical thinking skills, include diverse and complex scenarios that require creative problemsolving and a deeper understanding of causation in various areas of life.</p>
<p>Dyke</p>
<p>Languages</p>
<p>Correctly close all brackets, including nested brackets, in the provided sequence in the proper order from innermost to outermost.Mistakes such as forgetting to close a bracket or closing brackets in the wrong order can result in an error.If an error is made, a clear and concise message will indicate which bracket is not properly closed and suggest how to correct it.A visual representation of the correct sequence of closed brackets is provided below:
[ ( [ ( ) ] ) ]
Examples of valid and invalid inputs:</p>
<p>Formal Fallacies</p>
<p>Read the given argument carefully and determine whether it is deductively valid or invalid based on the explicitly stated premises.Provide a justification for your answer.</p>
<p>Disambiguation QA</p>
<p>For each sentence with a gender-neutral pronoun, determine the antecedent or state if it is ambiguous.Use (A) for the first option, (B) for the second option, or (C) for ambiguous.Additionally, provide an explanation of the antecedent (the person or thing the pronoun refers to) for each sentence.</p>
<p>Continuation of Table 24</p>
<p>Submission and Formatting Instructions for ICML 2024</p>
<p>Continuation of Table 24</p>
<p>Hyperbaton Test your knowledge of adjective order in English sentences with interactive exercises and quizzes.Learn the rule of opinion-size-age-shape-color-origin-material-purpose noun and apply it to different types of nouns such as animals, objects, and people.Practice constructing your own sentences and receive feedback on incorrect answers to improve your skills.By the end of this exercise, you'll be able to confidently order adjectives and communicate accurately in English.</p>
<p>Continuation of Table 24</p>
<p>Cause Effect</p>
<p>Determine the sentence that is the cause in each pair.Remember to thoroughly comprehend the meaning of each sentence before selecting the cause.Additionally, verify your output to ensure that you only include the sentence that is the cause.To aid in identifying cause and effect relationships, consider using keywords or phrases that indicate causality, analyzing the context of each sentence, and practicing with feedback and interactive activities.</p>
<p>Common Concept</p>
<p>For each input, come up with a category or characteristic that they have in common and write it as the output.Use your knowledge and experience to make educated guesses and be creative in your thinking.Also, try to keep the output concise and clear.</p>
<p>Diff</p>
<p>Subtract the second number from the first number and give me the result.Make sure to double check your calculations and write the answer as a string in a list format.Continued next page for Table 26 Continuation of Table 26 First Word Letter Write a program that takes in a word and returns a list containing the first letter of the word as a string.The program will be used to label items in a game.Make sure to handle cases where the input word is empty or only contains whitespace.You can use the string method 'strip()' to remove any leading or trailing whitespace.If the input is empty or contains only whitespace, return an empty list.</p>
<p>To ensure that your program works correctly, test it with the following examples:</p>
<p>Informal Formal</p>
<p>Reword the following sentences using more formal language, but also provide alternative rewordings that are more appropriate for different contexts:</p>
<p>Continuation of Table 26</p>
<p>Singular Plural Add an "s" or the correct plural form to the end of the input word, depending on the following rules:</p>
<p>1.If the word ends in "y" with a consonant before it, change the "y" to "ies" instead of just adding an "s". 2. If the word ends in "f" or "fe", change the "f" or "fe" to "ves" instead of just adding an "s". 3.If the word is already plural, return the input word as is instead of adding an "s". 4. If the word has an irregular plural form, return the correct plural form instead of just adding an "s".</p>
<p>Continuation of Table 26</p>
<p>Rhymes Create a list of words that rhyme with the given word.To ensure that your rhymes are accurate, make sure that the words have the same vowel sound and ending consonant sound.For example, "cat" rhymes with "bat" and "hat," but not with "dog" or "mat."</p>
<p>To get started, here are some examples of words that rhyme with the given word:</p>
<p>-Love: dove, glove, above, shove, of -Time: rhyme, chime, climb, mime, prime To find more rhyming words, you can use a rhyming dictionary, online resources, or brainstorm with friends.Be creative and try to use a variety of different rhyming words instead of repeating the same one multiple times.</p>
<p>To avoid common pitfalls, make sure to double-check your spelling and pronunciation of the words.Also, avoid using words that only partially rhyme or have a different stress pattern.</p>
<p>After you've created your list, ask for feedback on the quality of your rhymes.This can help you to improve and refine your skills.</p>
<p>For an added challenge, consider generating rhyming words that fit a particular theme or context.This can help you to focus your creativity and generate more interesting and relevant rhymes.</p>
<p>Second Word Letter</p>
<p>For each input word with at least two letters, identify and output the second letter.Please ensure that the input is a valid word in the specified language or dialect to prevent errors.The prompt is case-insensitive, so it will work for both uppercase and lowercase letters.</p>
<p>Examples: -Input: "hello" Output: "e" -Input: "apple" Output: "p" -Input: "book" Output: "o" Please note that the language or dialect of the input should be specified to avoid confusion with words that have different spellings or pronunciations in different regions.</p>
<p>Continued next page for Table 26</p>
<p>Sentence Similarity Rate the similarity of two given sentences on a scale of 1 to 5, where 1 indicates a significant difference in meaning and 5 indicates almost identical meaning.Please consider the following factors when rating:</p>
<p>-The overall message and purpose of the sentences -The structure and syntax of the sentences -The use of key words and phrases Provide a brief explanation for your rating, taking into account any minor differences in wording or details that may affect the similarity rating.Additionally, please provide context for the sentences being compared, such as the intended audience or purpose.</p>
<p>For reference, here are some examples of sentences that fall into each category:</p>
<p>Highly similar: "The cat sat on the mat" and "The mat was sat on by the cat" Moderately similar: "I enjoy playing soccer" and "Soccer is a fun sport to play" Not similar at all: "The sky is blue" and "I am going to the beach tomorrow" Thank you for your evaluation and explanation.</p>
<p>Sentiment</p>
<p>Please analyze the following statements and determine their overall sentiment as either ['negative', 'neutral', 'positive'].Keep in mind the context and any figurative language used.</p>
<p>Figure 1 :
1
Figure 1: An illustrative example of the unified in-context prompt optimization problem.</p>
<p>Figure 2 :
2
Figure 2: Illustration of PHASEEVO framework.</p>
<p>Figure 3 :
3
Figure 3: Iteration history of score values with different mutation operators during optimization.</p>
<p>Figure 4 :
4
Figure 4: Test accuracy of PHASEEVO on the instruction induction tasks.</p>
<p>Figure 5 :
5
Figure 5: Variation of prompt length during optimization.</p>
<p>Figure 6 :
6
Figure 6: Comparison of computational cost.</p>
<p>Fernando et al. (2023); Guo et al. (2023); Hsieh et al. (2023) proposed leveraging LLMs to implement evolution strategies in prompt searches.Yang et al. (2023a) demonstrates the capability of LLM as optimizers in prompt design.Pryzant et al. (2023); Zhou et al. (</p>
<ol>
<li>Definition A.2. (Feedback Mutation) Feedback Mutation generates a new prompt p ′ based on the existing prompt p ∈ P, and where p made mistakes for a task.The feedback operator O F first looks at the cases where the current p failed to generate a list of advice G, and then asks LLM L to apply such advice G to existing prompt p for generating the new prompt p ′ .</li>
</ol>
<p>3 .
3
Definition A.4. (Crossover Mutation -CR) Crossover generates a new candidate based on two parents.It is a function operator O C that performs O C (p 1 , p 2 , L) = p ′ where p 1 , p 2 are two prompts selected from a prompt population set P where P = [p 1 ..., p m ], p ′ is the generated prompt that hold features from both p 1 and p 2 .If p 2 = arg min p∈P d(p 1 , p i ) is applied for choosing p 2 , we call it Crossover + Distinct (CR + D).</p>
<p>Table 6 :
6
Lamarckian Operator Add Few-shot Example Operator Input I gave a friend an instruction and some examples The friend read the instruction and wrote an output for every one of the inputs.Here are the input-output pairs: the second number from the first number and write the result.If the result is negative, write the absolute value of the result.Here are the input-output pairs: Operator Add Few-shot Example: In this operation, few-shot examples are added based on the feedback.Individual feedback and their corresponding changes are colorcoded.</p>
<p>Figure 7 :
7
Figure 7: Operator Improvement CountAnalysis: There are two aspects we are particularly interested in.The first is what the likelihood of performance gain when applying an operator is (Probability of Improvement), and the second is how fast each operator can continously bring improvement (Convergence Speed).</p>
<p>Figure 8 :
8
Figure 8: Operator Improvement Pattern: EDA Mutation and Crossover have similar improvement counts for each step whereas for Feedback Mutation and Semantic Mutation, the first step introduced significantly more times of improvement compared to the others.</p>
<p>big, red, round ball bounced down the street.b) The round, red, big ball bounced down the street.Example 2: a) The delicious, homemade, chocolate cake was devoured by the guests.b) The chocolate, homemade, delicious cake was devoured by the guests.</p>
<p>Valid input: [ ( ) ] Valid input: [ ( [ ] ) ] Invalid input: [ ( [ ) ] Warning message: The bracket at position 8 is not properly closed.Please close the bracket to ensure proper syntax.Suggested correction: [ ( [ ] ) ] Invalid input: [ ( [ ] ) ] Warning message: The bracket at position 8 is not properly closed.Please close the bracket to ensure proper syntax.Suggested correction: [ ( [ ] ) ]</p>
<p>list of adjectival antonyms for each of these words, keeping in mind the given context:" ## Input ##: hot (in the context of weather) ## Output ##: ['cold', 'cool', 'chilly'] ## Input ##: happy (in the context of emotions) ## Output ##: ['sad', 'unhappy', 'depressed', 'miserable'] ## Input ##: big (in the context of size) ## Output ##: ['small', 'tiny', 'little', 'miniature'] ## Input ##: fast (in the context of speed) ## Output ##: ['slow', 'sluggish', 'leisurely', 'gradual'] ## Input ##: old (in the context of age) ## Output ##: ['young', 'new', 'fresh', 'modern']</p>
<p>Table 1 :
1
Qualitative analysis of mutation operators
OperatorAdd Remove ParentsProb Speed CostLamarckian</p>
<p>Distribution Mutation (EDA) is a function operator O E that generate a new prompt O E (P,L) = p ′ based on a list of parents P = [p 1 , ..., p k ].Items in P satisfy d(p i , p j ) &lt; t, where d is a distance metric and t is a threshold.If the items in P are ordered based on certain criteria, we refer to it as EDA + Index (EDA+I).• Crossover Operator(CR) is a function operator O C that performs O C (p 1 , p 2 , L) = p ′ where p 1 , p</p>
<p>2 are two parents selected from a population set P where P = [p 1 ..., p m ].If p 2 = arg min p∈P d(p 1 , p i ) is used to select p 2 , we refer to it as Crossover + Distinct (CR + D).The two local operators are: • Feedback Mutation is a function operator O F utilizes a batch of data to create "gradients" δ that provide feedback of the current prompt p.A new prompt p ′ is generated by editing the current prompt p in the opposite semantic direction of the gradient, e.g., p ′ = O F (p, −δ, L). • Semantic Mutation is a function operator O S that performs paraphrasing O S (p, L) = p ′ where p ′ is the new prompt that shares the same semantic meaning as p.</p>
<dl>
<dt>Table</dt>
<dd>
<p>requirements: size of population n, a dev set Ddev, score function F on the base LLM L, phase improvement t and threshold t * and minimum run time for phases Ki, designed evolution operators OL, OF , OE, OC and OS 2: initialization: generate diverse initial prompts P 0 = {p 0 1 , ..., p 0 n } by O l with input/output pairs or Os with existing prompt, and evaluate initial scores S 0 ← {s 0 Ddev)), and update P 3 ← {P * t , P 2 }, and S 3 ← {S * t , S 2 } 9: return the optimal in-context prompt p * , from the final population P 3 : p * ← arg max p∈P 3 F(p, Ddev)
3.2.2. PHASE 1: LOCAL FEEDBACK MUTATION Algorithm 1 Unified In-Context Prompt Optimization: PHASEEVOWhile an initial phase (Phase 0) may result in a diverse pop-ulation, each candidate could still be distant from its local. Lamarck-ian mutation is a crucial operator that introduces diverse i = F(p 0 i , Ddev)} 3: while t &lt; t  *  or k ≤ K1 dooptimal solution. To address this, we employ the Feedback Mutation Operator O F to expedite each candidate's conver-//Phase 0: Global Exploration //Phase 1: Local Exploitationsamples, enabling the addition of examples for global ini-tialization. Feedback mutation leads to faster convergence for exploitation and facilitates the addition or removal of examples. EDA and Crossover mutation are evolution opera-tors that share similar characteristics in exploring the global 4: Local Feedback Mutation: generate new prompts by feedback gradient descent, Pt ← O f (P 0 ), gence towards their local minimums, leveraging the "gradi-evaluate St ← F (P 0 , Ddev)), and update the population set P 1 ← {Pt, P 0 }, and score set S 1 ← {St, S 0 } ent" information. This involves the introduction of an LLM 5: while t &lt; t  *  or k ≤ K2 do //Phase 2: Global Exploration Examiner, which scrutinizes instances where the current 6: Global Evolution Mutation: select parent prompts from current population, {pr 1 , ..., pr k } ∈ P 1 , generate a new candidate falls short, and subsequently offers improvement guidance. Such information is taken as the feedback gradi-prompt by performing EDA operators pt ← Oe(pr 1 , ..., pr k ) or crossover operators pt ← Oc(pr 1 , ..., pr k ), evaluate on Ddev, st ← F (pt, Ddev), and update P 2 ← {P 1 , pt} and S 2 ← {S 1 , st} ent and is further utilized by an LLM Improver, to generate 7: while t &lt; t  *  or k ≤ K3 do //Phase 3: Local Exploitation space. Semantic mutation is better at locally exploiting the cost-effectiveness of operations than feedback mutation. For a more in-depth discussion on operators, please refer to new candidates by local exploitation. These new candi-dates contain global information inherited from the previous 8: Local Semantic Mutation: generate new prompts by the semantic operator P  *  t ← Os(P 2 ), evaluate S  *  t ← F(P 2 ,Appendix B.1 and B.2.phase and can thus be regarded as better initialization forthe next optimization phase.3.2. PHASEEVO Framework Our PHASEEVO framework introduces a dual exploration-exploitation strategy, i.e., "global exploration" → "local exploitation" → "global exploration" → "local exploita-tion" to approach global optima efficiently. Specifically, we initially utilize a diverse sampling to facilitate global exploration of the entire search space, incorporating instruc-tions and examples to optimize prompts jointly. Rather than solely relying on global search methods, such as evolu-tion mutation, we also employ feedback mutation for fast, localized exploitation via gradient descent. This leads to superior initialization after the initial stage of exploration and exploitation. However, some candidates can be trapped in local optima after the initial two phases. To resolve this, we leverage evolution operators in the third phase to es-3.2.3. PHASE 2: GLOBAL EVOLUTION MUTATION Phase 1 provides a more refined set of candidates, while some of them might be stuck in local optima. To address this issue, we prioritize exploration rather than exploitation in Phase 2, which helps to escape from these restricted locali-ties by conducting a global search. We leverage LLM agents that employ EDA (EDA-I) operators O E and CR (CR-D) operators O C to facilitate the increased interaction of ge-netic information among candidates on a larger global scale. Rather than employing cosine similarity as distance metrics, we adopt the Hamming distance (see more discussions in Section 3.3) for calculating similarity on performance-based vectors such that Phase 2 can promote greater diversity in the evolving generations.cape local optimum by exploring solutions at a global scale. Considering the low efficiency of global operators, we uti-3.2.4. PHASE 3: LOCAL SEMANTIC MUTATIONlize semantic mutations at the final phase to accelerate theUpon completing Phase 2's exploration, Phase 3 employsconvergence to the global optimal solution. Figure 2 is anlocal exploitation to hasten the "last mile" of convergence.illustration of the optimization process.As the concluding phase of PHASEEVO, the fitness scoreof the population is notably optimized at this stage relative3.2.1. PHASE 0: GLOBAL INITIALIZATIONto earlier phases. Consequently, the Semantic MutationOur objective is to create diverse candidates as the initialoperator O S is selected to expedite a more cost-effective exploitation of the candidates. Finally, we identify the bestpopulation to explore the vast joint space of instruction andcandidate as our ultimate optimal prompt and assess itsexample. We provide two types of initialization based on the availability of data (input output pair) and human expertperformance on the testing dataset D test . The workflow of PHASEEVO framework is shown in Algorithm 1.knowledge (prompt examples).3.3. PHASEEVO Design• Reverse Engineer from input/output pairs. Given aWithin our PHASEEVO framework, we propose two novelset of input/output pairs S = {(Q 1 , A 1 ), ..., (Q m , A m )}design schemes to improve performance and efficiency.from the training set D train for the task T , we define an LLM agent to apply Lamarckian Operator O L to reverse engineer the prompt from provided demonstrating pairs.Design 1: Performance vector with Hamming distance. Evolution operators like EDA and Crossover function optimally when parents exhibit distinct attributes. In• Human expert prompt example. This way allows hu-terms of evaluating similarity scores, we adhere to themans to jump-start the evolution process by incorporatingprinciple that similarity should be gauged based on theprior knowledge. We also perform the semantic operatorperformance of the prompts rather than their linguisticO S to enhance the diversity of the initial population.or semantic similarities. Inspired by this intuition, we
1</p>
</dd>
</dl>
<p>Table 2 :
2
Testing performance of the optimal prompt on 8 representative tasks from BBH.
MethodCausal JudgementDis -ambiguationDyck LanguagesFormal FallaciesHyperbatonLogical FiveColor ReasoningSalient TranslationOPRO (Yang et al., 2023a)71.9471.5336.7349.5175.9250.0065.5543.88EvoPrompt (Guo et al., 2023) 67.2453.7047.9650.8174.7961.4060.9047.58AELP (Hsieh et al., 2023)76.4762.6910.2757.9552.6472.5967.7438.93PHASEEVO-pair69.97 (2.45)69.90 (3.53)7.06 (1.23)58.49 (0.41) 84.36 (2.24) 45.49 (2.73)58.13 (2.36)48.38 (0.81)PHASEEVO-example84.85 (5.45) 68.01 (0.4)35.48 (12.18) 53.06 (4.95)81.58 (9.89)73.56 (8.99) 77.15 (4.13) 47.01 (0.88)Over AELP10.95% ↑11.50% ↑245.18% ↑0.93% ↑60.24% ↑1.34% ↑13.89% ↑24.27% ↑Over EvoPrompt32.36% ↑30.17% ↑-2.48% ↑15.73% ↑16.99% ↑34.36% ↑32.35% ↑3.19% ↑Over OPRO23.84% ↑0.84% ↑27.33% ↑18.91% ↑16.79% ↑65.04% ↑23.02% ↑12.31% ↑La m a Fe ed</p>
<p>Table 3 :
3
Testing performance on 3 detect tasks from APO.
MethodEthosLiarSarcasmAPO (Pryzant et al., 2023) 0.950.510.85PHASEEVO (GPT-3.5)0.96 (0.96) 0.61 (3.85) 0.87 (1.25)PHASEEVO (GPT-4)0.960.690.89Instruction Induction Tasks. To compare PHASEEVO-generated prompts with manually added few-shot exam-ples, we evaluated the optimized prompt from PHASEEVOagainst the best prompts from APE-fewshot (Zhou et al.,2023) and PromptBreeder-fewshot (Fernando et al., 2023)on APE's 24 instruction induction tasks. The results showthat PHASEEVO outperforms APE in 17 out of 24 tasksand PromptBreeder in 18 out of 24 tasks. The AppendixE.1 provides complete experimental results. Fig. 4 showsthat few-shot methods do not always outperform zero-shot
methods, highlighting the need for a joint in-context prompt search.Moreover, we observed that the prompts generated by PHASEEVO are easier to interpret and align better with the task description.Appendix E.3 provides more detail on prompt quality.</p>
<p>Table 4 :
4
Comparison of our phase evolution with traditional random evolution.
MethodCausal Judgement Average score High score Average score High score Average score High score Average score High score Disambiguation Hyperbaton Salient TranslationRandom Evo 67.70 (0.75)70.28 (0.56) 58.22 (2.47)61.3 (3.17)83.00 (0.15)87.8 (0.00)52.00 (2.35)56.80 (1.60)PHASEEVO69.88 (2.17)72.00 (3.09) 60.32 (2.73)62.9 (2.56)83.52 (0.71)87.8 (0.00)53.06 (0.80)56.80 (0.80)</p>
<p>Table 5
5displays
ization in prompt examples draws upon provided example prompts, consequently lacking the diversity that input output pair offers.Even so, prompt examples empowers users to introduce prior knowledge without leaning on LLM interpretation, and consequently, it performs better in more complex tasks such as Dyck Languages, Logical Five, and Color Reasoning, as illustrated in Table</p>
<p>Table 5 :
5
Performance comparison of hamming distance and cosine similarity.High score Average score High score Average score High score Average score High score
Causal Judgement Average score Cosine distance Method 64.70 (2.31) 67.86 (2.47) 58.96 (1.47) DisambiguationHyperbaton 63.30 (0.00) 74.70 (1.60)85.7 (0.00)Salient Translation 49.56 (1.07) 58.80 (0.00)Hamming distance 65.74 (2.87)69.60 (2.97) 64.11 (1.28)66.94 (2.88) 79.30 (4.48)86.78 (2.15) 50.33 (2.32)58.80 (0.00)</p>
<p>Table 8 :
8
Feedback Operator Remove Few-shot Example: In this operation, few-shot examples are removed based on the feedback.Individual feedback and their corresponding changes are colorcoded.</p>
<p>Table 9 :
9
Semantic Operator Remove Few-shot Example</p>
<p>Table 15 :
15
Cross Over PromptYou are a mutator who is familiar with the concept of cross-over in genetic algorithm, namely combining the genetic information of two parents to generate new offspring.Given two parent prompts, you will perform a cross-over to generate an offspring prompt that covers the same semantic meaning as both parents.</p>
<h1>ExampleParent prompt 1: Now you are a categorizer, your mission is to ascertain the sentiment of theprovided text, either favorable or unfavorableParent prompt 2: Assign a sentiment label to the given sentence from ['negative', 'posi-tive'] and return only the label without any other text.Offspring prompt: Your mission is to ascertain the sentiment of the provided text and as-sign a sentiment label from ['negative', 'positive'].## Given ##Parent prompt 1: {prompt 1}Parent prompt 2: {prompt 2}Offspring prompt:</h1>
<p>Table 16 :
16
(Zhou et al., 2023)rompt: To provoke LLM's creativity, we do not restrict to the semantic level but expand that to intentions, allowing LLM to not stick to a sentence-by-sentence mutation.APE(Zhou et al., 2023)uses LLM agent for instruction induction tasks.It proposes forward mode generation and reverse mode generation and uses log probability to generate and evaluate candidates.As it reports the best candidate, we are using the best candidate to compare.
You are a mutator. Given a prompt, your task is to generate another prompt with the same semanticmeaning and intentions.# Example:current prompt: Your mission is to ascertain the sentiment of the provided text and assign asentiment label from ['negative', 'positive'].mutated prompt: Determine the sentiment of the given sentence and assign a label from ['negative','positive'].Given:current prompt: {existing prompt}mutated prompt::</p>
<p>Table17shows the comparison between APE, PromptBreeder, and PHASEEVO evaluated by the best prompt on 24 instruction induction tasks.PHASEEVO outperforms 21/24 tasks over APE zero shot, 17 / 24 tasks over APE few shot and 18 / 24 tasks on Prompt Breeder.PHASEEVO generated few-shot prompts for 20 / 24 tasks and zero-shot examples for 4 / 24 tasks.For the full set of generated prompts please refer to table 26.
Continuation of Table 19Table 17: 24 Instruction Induction Task in APETaskAPE (zero-shot)APE shot)(few-PromptBreeder (few-shot)PHASEEVO-3.5PHASEEVO-4Antonyms0.830.860.870.890.91Cause Effect0.84110.961Common Concept0.270.3200.230.28Diff11111First Word Letter11111Informal For-mal0.650.700.070.60.67Large Ani-mal0.970.970.970.960.94Letters List0.9910.9911Taxonomy Animal0.660.7910.961Negation0.830.90.90.940.88Num Verb11111Active Pas-sive11111Singular Plu-ral11111Rhymes10.61111Second Word Letter0.870.690.9511Sentence Sim-ilarity0.360.430.560.380.55Sentiment0.940.930.930.940.94Continuation of Table 17</p>
<p>Table 20 :
20
Below are cases listing examples where few-shot examples are added or removed with PHASEEVO.Add Few-shot Example: added examples are highlighted.
F.1. Zero-shot to Few-shotTaskEthosInputIs the following text hate speech? \n ## Output Format ## True or FalsePrompt</p>
<p>Table 21 :
21
Zero-shot to Zero-shot
TaskEthosInputIs the following text hate speech? \n ## Output Format ## True or FalsePromptOutput PromptClassify the given text as hate speech or not and generate a binary output of 1 for Yes and 0 for No.F.3. Few-shot to Zero-shot</p>
<p>Table 22 :
22
Few-shot to Zero-shot
TaskHyperbatonContinuation of Table 22
We compare the best prompt obtained from PHASEEVO with gpt-3.5 and gpt-4.For gpt-3.5 we run 3 times and for gpt-4 we run once.PHASEEVO-4 outperforms PHASEEVO-3.5 in all tasks when the inputs are in the same format.However for more difficult tasks, because of the possibility of human-introduced prior knowledge, PHASEEVO-3.5-example outperforms PHASEEVO-4-pair.We notice that the prompts generated by PHASEEVO are easier to understand by humans.Below is a comparison between prompts generated for task Rhymes.The task description is: "Write a word that rhymes with the input word."The prompt generated by APE and Instruct Zero does not fit the task.The prompt generated by Prompt Breeder is not easy to understand how it relates to rhyme.The prompt generated by PHASEEVO is easy to understand with few shot examples added.Table19: Generated Prompt Comparison for task "Rhymes"Framework Generated Prompt APE write a function that takes in a string and outputs the string with the first letter capitalized.Continuation of Table19Continuation of Table19Instruct Zero Write a function that takes a word as input and returns the output word.Prompt BreederPrompt 0: If the last letter of the input is 'e', remove it.Prompt 1: remove the last two letters of the input and add the letters \xc2 \x93mote \xc2 \x94.Contexts Context 0: Q. pea A. If the last letter of the input is 'e', remove it.A. If the last letter of the input is 's', remove it.A. If the last letter of the input is 'y', remove it.A. If the last letter of the input is remove the last two letters of the input and add the letters \xc2 \x93mote \xc2 \x94.Therefore, the correct answer is (a) pea.Context 1: Q. night A. If the last letter of the input is 'e', remove it.A. If the last letter of the input is 't', remove it.A. If the last letter of the input is 'h', remove it.A. If the last letter of the input is remove the last two letters of the input and add the letters \xc2 \x93mote \xc2 \x94.Therefore, the correct answer is (The answer is night.Context 2: Q. add A. If the last letter of the input is 'e', remove it.A. If the last letter of the input is 'd', remove it.A. If the last letter of the input is 'a', remove it.A. If the last letter of the input is remove the last two letters of the input and add the letters \xc2 \x93mote \xc2 \x94.Therefore, the correct answer is (The answer is added.Continuation of Table 19Continuation of Table22Input Prompt Order adjectives correctly in English sentences.Q: Which sentence has the correct adjective order: Options: (A) rubber terrible ship (B) terrible rubber ship A: Let's think step by step.When there is more than one adjective before a noun, the adjectives need to respect the following order before a noun: "[1. opinion] [2. size] [3. age] [4. shape] [5. color] [6. origin] [7. material] [8. purpose]noun".Option (A): "rubber terrible ship".(1) rubber" falls into the material category.(2) "terrible" falls into the opinion category.Option (A) has the following adjective order:[7.material] [1.opinion] (or, in numeric terms, 7 1).Because 7 &lt; 1 is not correct, (A) does not have the correct ordering.Option (B): "terrible rubber ship".Option (B) has the following adjective order:[1. opinion] <a href="or, in numeric terms,1 7">7. material</a>.Because 1 &lt; 7 is correct, (B) has the correct ordering.So the answer is (B).Q: Which sentence has the correct adjective order: Options: (A) repulsive small Brazilian exercise ship (B) Brazilian repulsive exercise small ship A: Let's think step by step.When there is more than one adjective before a noun, the adjectives need to respect the following order before a noun: "[1. opinion] [2. size] [3. age] [4. shape] [5. color] [6. origin] [7. material] [8. purpose]noun".Option (A): "repulsive small Brazilian exercise ship".(1) "repulsive" falls into the opinion category.(2) "small" falls into the size category.(3) "Brazilian" falls into the origin category.(4) "exercise" falls into the purpose category.Option (A) has the following adjective order:[1. opinion] [2. size] [6. origin] [8.purpose] (or, in numeric terms, 1 2 6 8).Because 1 &lt; 2 &lt; 6 &lt; 8 is correct, (A) has the correct ordering.Option (B): "Brazilian repulsive exercise small ship".Option (B) has the following adjective order:[6. origin] [1. opinion] [8. purpose] [2.size] (or, in numeric terms, 6 1 8 2).Because 6 &lt; 1 &lt; 8 &lt; 2 is not correct, (B) does not have the correct ordering.So the answer is (A)....Output PromptIdentify the sentence with the correct order of adjectives: opinion, size, age, shape, color, origin, material, purpose.23Continuation of Table23Input Prompt Order adjectives correctly in English sentences.Q: Which sentence has the correct adjective order: Options: (A) rubber terrible ship (B) terrible rubber ship A: Let's think step by step.When there is more than one adjective before a noun, the adjectives need to respect the following order before a noun: "[1. opinion] [2. size] [3. age] [4. shape] [5. color] [6. origin] [7. material] [8. purpose]noun".Option (A): "rubber terrible ship".(1)rubber" falls into the material category.(2) "terrible" falls into the opinion category.Option (A) has the following adjective order:[7.material] [1.opinion] (or, in numeric terms, 7 1).Because 7 &lt; 1 is not correct, (A) does not have the correct ordering.Option (B): "terrible rubber ship".Option (B) has the following adjective order:[1. opinion] <a href="or, in numeric terms,1 7">7. material</a>.Because 1 &lt; 7 is correct, (B) has the correct ordering.So the answer is (B).Q: Which sentence has the correct adjective order: Options: (A) repulsive small Brazilian exercise ship (B) Brazilian repulsive exercise small ship A: Let's think step by step.When there is more than one adjective before a noun, the adjectives need to respect the following order before a noun: "[1. opinion] [2. size] [3. age] [4. shape] [5. color] [6. origin] [7. material] [8. purpose]noun".Option (A): "repulsive small Brazilian exercise ship".(1) "repulsive" falls into the opinion category.(2) "small" falls into the size category.(3) "Brazilian" falls into the origin category.(4) "exercise" falls into the purpose category.Option (A) has the following adjective order:[1. opinion] [2. size] [6. origin] [8.purpose] (or, in numeric terms, 1 2 6 8).Because 1 &lt; 2 &lt; 6 &lt; 8 is correct, (A) has the correct ordering.Option (B): "Brazilian repulsive exercise small ship".Option (B) has the following adjective order:[6. origin] [1. opinion] [8. purpose] [2.size] (or, in numeric terms, 6 1 8 2).Because 6 &lt; 1 &lt; 8 &lt; 2 is not correct, (B) does not have the correct ordering.So the answer is (A)....Continuation of Table 23Continuation of Table24Logical Deduction Five On a plate, there are three fruits: a red apple, a yellow banana, and a green pear.The banana is positioned to the immediate left of the apple, meaning there are no other fruits between them.The pear is the rightmost fruit, meaning it comes last in the order.Which of the following statements is true?(A) The red apple is the leftmost fruit.(B) The yellow banana is the leftmost fruit.(C) The green pear is the leftmost fruit.Explanation:To solve this prompt, pay attention to the precise language used to describe the relationships between the fruits and their positions in the order.The banana is to the immediate left of the apple, meaning it is directly adjacent to it and there are no other fruits between them.The pear is the rightmost fruit, meaning it comes last in the order.Therefore, the correct answer is (B) The yellow banana is the leftmost fruit.To further practice this concept, here are some additional examples:1. On a plate, there are three different colored balls: a blue ball, a red ball, and a green ball.The red ball is directly to the left of the blue ball, meaning there are no other balls between them.The green ball is the rightmost.Which of the following statements is true?(A) The blue ball is the leftmost ball.(B) The red ball is the leftmost ball.(C) The green ball is the leftmost ball.2. In a row of three houses, there is a blue house, a yellow house, and a green house.The blue house is in the middle, and the yellow house is directly to the left of the green house, meaning there are no other houses between them.Which of the following statements is true?(A) The blue house is the leftmost house.(B) The yellow house is the leftmost house.(C) The green house is the leftmost house.Feedback: If you selected the wrong answer, here's why: (A) The red apple is not the leftmost fruit.The yellow banana is directly to its left.(C) The green pear is not the leftmost fruit.The banana and the apple come before it in the order.To avoid confusion, use precise language to describe the relationships between objects and their positions in the order.Avoid using vague terms like "newer" or "older" without specifying their exact relationship to other objects in the order.Provide more context or details to help clarify any ambiguities in the prompt.Make sure the order of the objects is clearly defined and consistent throughout the prompt.Continuation of Table24Continuation of Table24Reasoning Colored Objects Identify the color of objects arranged in a row on a surface.Q: On the desk, there is a black stapler, a green highlighter, a yellow ruler, a blue pen, and a purple marker.What color is the pen?Options:According to this question, the objects are arranged in a row, from left to right, as follows: (1) a black stapler, (2) a green highlighter, (3) a yellow ruler, (4) a blue pen, and (5) a purple marker.The pen is the fourth item on the list, namely(4).The color of the pen is blue.So the answer is (E).Salient Translation Error DetectionRead the following translations from German to English and identify the type of error present in each one.The error can be one of the following types: Named Entities, Numerical Values, Modifiers or Adjectives, Negation or Antonyms, Facts, or Dropped Content.Write the corresponding letter for each error type in the options provided.Continuation of Table 24Causal Judgment Provide reactions to intentional actions in diverse scenarios, while also considering causation and its complexities.To assist with determining causation, provide specific guidelines and examples for each scenario.To avoid any confusion or misinterpretation, precise language and definitions will be used throughout the prompt.Additionally, feedback from experts and individuals with relevant experience in the field of causation will be incorporated to ensure accuracy and relevance.To challenge users' critical thinking skills, include diverse and complex scenarios that require creative problemsolving and a deeper understanding of causation in various areas of life.DykeLanguagesCorrectly close all brackets, including nested brackets, in the provided sequence in the proper order from innermost to outermost.Mistakes such as forgetting to close a bracket or closing brackets in the wrong order can result in an error.If an error is made, a clear and concise message will indicate which bracket is not properly closed and suggest how to correct it.A visual representation of the correct sequence of closed brackets is provided below:Examples of valid and invalid inputs:Warning message: The bracket at position 8 is not properly closed.Please close the bracket to ensure proper syntax.Suggested correction: [ ( [ ] ) ]Invalid input: [ ( [ ] ) ]Warning message: The bracket at position 8 is not properly closed.Please close the bracket to ensure proper syntax.Suggested correction: [ ( [ ] ) ]Formal FallaciesRead the given argument carefully and determine whether it is deductively valid or invalid b5rased on the explicitly stated premises.Provide a justification for your answer.Disambiguation QAFor each sentence with a gender-neutral pronoun, determine the antecedent or state if it is ambiguous.Use (A) for the first option, (B) for the second option, or (C) for ambiguous.Additionally, provide an explanation of the antecedent (the person or thing the pronoun refers to) for each sentence.HyperbatonTest your knowledge of adjective order in English sentences with interactive exercises and quizzes.Learn the rule of opinion-size-age-shape-color-origin-material-purpose noun and apply it to different types of nouns such as animals, objects, and people.Practice constructing your own sentences and receive feedback on incorrect answers to improve your skills.By the end of this exercise, you'll be able to confidently order adjectives and communicate accurately in English.Continuation of Table24Continuation of Table24Logical Deduction Five On a plate, there are three fruits: a red apple, a yellow banana, and a green pear.The banana is positioned to the immediate left of the apple, meaning there are no other fruits between them.The pear is the rightmost fruit, meaning it comes last in the order.Which of the following statements is true?(A) The red apple is the leftmost fruit.(B) The yellow banana is the leftmost fruit.(C) The green pear is the leftmost fruit.Explanation:To solve this prompt, pay attention to the precise language used to describe the relationships between the fruits and their positions in the order.The banana is to the immediate left of the apple, meaning it is directly adjacent to it and there are no other fruits between them.The pear is the rightmost fruit, meaning it comes last in the order.Therefore, the correct answer is (B) The yellow banana is the leftmost fruit.To further practice this concept, here are some additional examples:1. On a plate, there are three different colored balls: a blue ball, a red ball, and a green ball.The red ball is directly to the left of the blue ball, meaning there are no other balls between them.The green ball is the rightmost.Which of the following statements is true?(A) The blue ball is the leftmost ball.(B) The red ball is the leftmost ball.(C) The green ball is the leftmost ball.2. In a row of three houses, there is a blue house, a yellow house, and a green house.The blue house is in the middle, and the yellow house is directly to the left of the green house, meaning there are no other houses between them.Which of the following statements is true?(A) The blue house is the leftmost house.(B) The yellow house is the leftmost house.(C) The green house is the leftmost house.Feedback: If you selected the wrong answer, here's why: (A) The red apple is not the leftmost fruit.The yellow banana is directly to its left.(C) The green pear is not the leftmost fruit.The banana and the apple come before it in the order.To avoid confusion, use precise language to describe the relationships between objects and their positions in the order.Avoid using vague terms like "newer" or "older" without specifying their exact relationship to other objects in the order.Provide more context or details to help clarify any ambiguities in the prompt.Make sure the order of the objects is clearly defined and consistent throughout the prompt.Continuation of Table24Continuation of Table24Reasoning Colored Objects Identify the color of objects arranged in a row on a surface.Q: On the desk, there is a black stapler, a green highlighter, a yellow ruler, a blue pen, and a purple marker.What color is the pen?A: Let's think step by step.According to this question, the objects are arranged in a row, from left to right, as follows: (1) a black stapler, (2) a green highlighter, (3) a yellow ruler, (4) a blue pen, and (5) a purple marker.The pen is the fourth item on the list, namely(4).The color of the pen is blue.So the answer is (E).Continuation of Table 24Salient Translation Error DetectionRead the following translations from German to English and identify the type of error present in each one.The error can be one of the following types: Named Entities, Numerical Values, Modifiers or Adjectives, Negation or Antonyms, Facts, or Dropped Content.Write the corresponding letter for each error type in the options provided.LiarAnalyze the context and other information provided to determine the truthfulness of the statement.To do so, consider the following guidelines:1. Identify key sources of information, such as reputable news outlets or government reports, and consider the credibility of the sources.Look for corroborating evidence and consider any potential biases or conflicts of interest.2. Conduct additional research or seek out expert opinions when necessary to determine the truthfulness of a statement.Use resources or links to relevant information provided, and consider consulting with subject matter experts or fact-checking organizations.3. Note that the determination of truthfulness may not always be possible based on the information provided, and that additional research or analysis may be required.Use your best judgment and be transparent about any uncertainties or limitations in your analysis.Output Format: Assign 0 for true and 1 for false.Note that this determination is based on the information provided and may not be definitive.SarcasmDetermine if the input contains any language that could be considered derogatory or discriminatory towards a particular group based on their race, ethnicity, gender, sexual orientation, religion, or any other protected characteristic.If such language is found, output True.If not, output False.The prompt should be trained on a diverse dataset to improve its accuracy and reduce errors.Continuation of Table 26Large AnimalChoose one animal as the output based on its size.For example, if the input pair is "elephant, mouse", choose "elephant" as the output.If the input pair is "giraffe, lion", choose "giraffe" as the output.Use the following criteria to choose the output:-If one animal is significantly larger than the other, choose the larger animal as the output.-If the animals are similar in size, choose the animal with the name that comes first alphabetically as the output.Here are some examples of correct outputs:-"whale, dolphin" -&gt; choose "whale" as the output -"panda, koala" -&gt; choose "panda" as the output -"tiger, zebra" -&gt; choose "tiger" as the outputChoose the output carefully to avoid confusion and errors.Letters ListPlease write a program that takes in a word as input and outputs a list of its letters separated by spaces.The output should be a list with one element containing the separated letters in the same order as the input word.To ensure the program works correctly, please follow these guidelines:1. Input validation: Check that the input is a non-empty string containing only alphabetic characters.If the input is invalid, print an error message and exit the program.2. Separating the letters: Use the 'split()' method to separate the letters of the input word.Expected output format:The output should be a list with one element containing the separated letters in the same order as the input word.Here are some examples of valid and invalid input:Valid input: "hello" Expected output: ["h", "e", "l", "l", "o"] Invalid input: "hello world" Expected output: "Error: Input must be a non-empty string containing only alphabetic characters."Invalid input: "123" Expected output: "Error: Input must be a non-empty string containing only alphabetic characters."SIdentify the first word or phrase that starts with the letter given in the input.The identified word or phrase should not contain any punctuation or special characters, and should be case-insensitive.If there are no words or phrases starting with the given letter, return an empty list.Continued next page forHere are the input-output pairs:Input: She sang a beautiful song to the audience.Note: If there are multiple words or phrases starting with the given letter, the prompt will return the first one encountered.If the input contains multiple sentences or clauses, the prompt will identify the first word or phrase that starts with the given letter in the entire input text.The output will be in lowercaseSum"Write a program that takes two numbers as input and returns their sum as a string in a list.Make sure to test your program with different inputs to ensure it works correctly.Remember to convert the input numbers to integers before adding them together, and then convert the sum back to a string before putting it in a list.Also, make sure to use the correct syntax for creating a list with one element (i.e.use square brackets around the string).Good luck!"Continued next page for Table26Word In ContextCompare the usage of a given word in two different sentences and determine if they have the same or different meanings based on the context of the sentences.Write "same" or "not the same" as the output.To avoid ambiguity and ensure clarity, please provide sufficient context for the sentences.If the word has multiple meanings depending on the context, please indicate all correct answers.For example, consider the word "bank."In the sentence "I need to deposit my paycheck at the bank," and "I sat on the bank of the river and watched the sunset," the word "bank" has different meanings.Therefore, the correct answer would be "not the same."Please note that the comparison should be based on the context of the sentences, not just the isolated word
Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. S Aarohi, B , Transactions on Machine Learning Research. 2835-88562023</p>
<p>Skill-based few-shot selection for in-context learning. S An, B Zhou, Z Lin, Q Fu, B Chen, N Zheng, W Chen, J.-G Lou, arXiv:2305.142102023arXiv preprint</p>
<p>language models are few-shot learners. T Brown, B Mann, N Ryder, M Subbiah, J D Kaplan, P Dhariwal, A Neelakantan, P Shyam, G Sastry, A Askell, S Agarwal, A Herbert-Voss, G Krueger, T Henighan, R Child, A Ramesh, D Ziegler, J Wu, C Winter, C Hesse, M Chen, E Sigler, M Litwin, S Gray, B Chess, J Clark, C Berner, S Mccandlish, A Radford, I Sutskever, D Amodei, 2020</p>
<p>S Bubeck, V Chandrasekaran, R Eldan, J Gehrke, E Horvitz, E Kamar, P Lee, Y T Lee, Y Li, S Lundberg, arXiv:2303.12712Sparks of artificial general intelligence: Early experiments with gpt-4. 2023arXiv preprint</p>
<p>Instructzero: Efficient instruction optimization for black-box large language models. L Chen, J Chen, T Goldstein, H Huang, T Zhou, 2023</p>
<p>A Chowdhery, S Narang, J Devlin, M Bosma, G Mishra, A Roberts, P Barham, H W Chung, C Sutton, S Gehrmann, arXiv:2204.02311Scaling language modeling with pathways. 2022arXiv preprint</p>
<p>M Deng, J Wang, C.-P Hsieh, Y Wang, H Guo, T Shu, M Song, E P Xing, Z Hu, Rlprompt, arXiv:2205.12548Optimizing discrete text prompts with reinforcement learning. 2022arXiv preprint</p>
<p>Black-box prompt learning for pre-trained language models. S Diao, Z Huang, R Xu, X Li, Y Lin, X Zhou, T Zhang, arXiv:2201.085312022arXiv preprint</p>
<p>From arabic sentiment analysis to sarcasm detection: The arsarcasm dataset. n Proceedings of the 4th Workshop on Open-Source Arabic Corpora and Processing Tools, with a Shared Task on Offensive Language Detection. I A Farha, W Magdy, 2020</p>
<p>Promptbreeder:self-referential selfimprovement via prompt evolution. C Fernando, D Banarse, H Michalewski, H Osindero, T Rocktaschel, 2023</p>
<p>connecting large language models with evolutionary algorithms yields powerful prompt optimizers. Q Guo, R W Wang, J G Guo, B Li, K Song, X Tan, G Liu, J Bian, Y Yang, 2023</p>
<p>An introduction and survey of estimation of distribution algorithms. M Hauschild, M Pelikan, Swarm and evolutionary computation. 132011</p>
<p>Adaptation in natural and artificial systems: an introductory analysis with applications to biology, control, and artificial intelligence. J H Holland, 1992MIT press</p>
<p>Instruction induction: From few examples to natural language task descriptions. O Honovich, U Shaham, S R Bowman, O Levy, 2022</p>
<p>Promptboosting: Black-box text classification with ten forward passes. B Hou, J O'connor, J Andreas, S Chang, Y Zhang, International Conference on Machine Learning. PMLR2023</p>
<p>automatic engineering of long prompts. C.-J Hsieh, S Si, F X Yu, I S Dhillon, 2023</p>
<p>Large language models are zero-shot reasoners. Advances in neural information processing systems. T Kojima, S S Gu, M Reid, Y Matsuo, Y Iwasawa, 202235</p>
<p>Prefix-tuning: Optimizing continuous prompts for generation. X L Li, P Liang, arXiv:2101.001902021arXiv preprint</p>
<p>Lost in the middle: How language models use long contexts. F N Liu, K Lin, J Hewitt, A Paranjape, M Bevilacqua, F Petroni, P Liang, 2023</p>
<p>J Liu, D Shen, Y Zhang, B Dolan, L Carin, W Chen, arXiv:2101.06804What makes good in-context examples for gpt-3?. 2021arXiv preprint</p>
<p>Dynamic prompt learning via policy gradient for semi-structured mathematical reasoning. P Lu, L Qiu, K.-W Chang, Y N Wu, S.-C Zhu, T Rajpurohit, P Clark, A Kalyan, arXiv:2209.146102022arXiv preprint</p>
<p>Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity. Y Lu, M Bartolo, A Moore, S Riedel, P Stenetorp, arXiv:2104.087862021arXiv preprint</p>
<p>Self-refine: Iterative refinement with self-feedback. A Madaan, N Tandon, P Gupta, S Hallinan, L Gao, S Wiegreffe, U Alon, N Dziri, S Prabhumoye, Y Yang, arXiv:2303.176512023arXiv preprint</p>
<p>Ethos: An online hate speech detection dataset. I Mollas, Z Chrysopoulou, S Karlos, G Tsoumakas, 2021</p>
<p>ArXiv, abs/2303.08774Gpt-4 technical report. 2023257532815OpenAI</p>
<p>Boosted prompt ensembles for large language models. S Pitis, M R Zhang, A Wang, J Ba, arXiv:2304.059702023arXiv preprint</p>
<p>Grips: Gradient-free, edit-based instruction search for prompting large language models. A Prasad, P Hase, X Zhou, M Bansal, R Pryzant, D Iter, J Li, Y T Lee, Z Chenguang, M Zeng, arXiv:2203.072812022. 2023arXiv preprintAutomatic prompt optimization with "gradient descent" and beam search</p>
<p>Eliciting knowledge from language models with automatically generated prompts. T Shin, Y Razeghi, I V Logan, R L Wallace, E Singh, S Autoprompt, arXiv:2010.159802020arXiv preprint</p>
<p>Differential evolution-a simple and efficient heuristic for global optimization over continuous spaces. R Storn, K Price, Hüyük, A., and van der Schaar, M. Querydependent prompt evaluation and optimization with offline inverse rl. 1997. 2023112309arXiv e-prints</p>
<p>Bbtv2: towards a gradient-free future with large language models. T Sun, Z He, H Qian, Y Zhou, X.-J Huang, X Qiu, Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. the 2022 Conference on Empirical Methods in Natural Language Processing2022a</p>
<p>Blackbox tuning for language-model-as-a-service. T Sun, Y Shao, H Qian, X Huang, X Qiu, International Conference on Machine Learning. PMLR2022b</p>
<p>Challenging big-bench tasks and whether chain-of-thought can solve them. M Suzgun, N Scales, N Schärli, S Gehrmann, Y Tay, H W Chung, A Chowdhery, Q V Le, E H Chi, D Zhou, arXiv:2210.092612022aarXiv preprint</p>
<p>. M Suzgun, N Scales, N Schärli, S Gehrmann, Y Tay, H W Chung, A Chowdhery, Q V Le, E H Chi, D Zhou, J Wei, 2017large language models as optimizers. 2022b. Wang, W. Y. "liar, liar pants on fire": A new benchmark dataset for fake news detection</p>
<p>Promptagent: Strategic planning with language models enables expert-level prompt optimization. X Wang, C Li, Z Wang, F Bai, H Luo, J Zhang, N Jojic, E P Xing, Z Hu, arXiv:2310.164272023arXiv preprint</p>
<p>Reprompting: Automated chain-of-thought prompt inference through gibbs sampling. W Xu, A Banburski-Fahey, N Jojic, arXiv:2305.099932023arXiv preprint</p>
<p>challenging big-bench tasks and whether chain-of-thought can solve them. C Yang, X Wang, Y Lu, H Liu, Q V Le, D Zhou, X Chen, 2023a</p>
<p>Harnessing the power of llms in practice: A survey on chatgpt and beyond. J Yang, H Jin, R Tang, X Han, Q Feng, H Jiang, B Yin, X Hu, arXiv:2304.137122023barXiv preprint</p>
<p>Differentiable prompt makes pre-trained language models better few-shot learners. N Zhang, L Li, X Chen, S Deng, Z Bi, C Tan, F Huang, H Chen, arXiv:2108.131612021arXiv preprint</p>
<p>T Zhang, X Wang, D Zhou, D Schuurmans, J E Gonzalez, Tempera, arXiv:2211.11890Test-time prompting via reinforcement learning. 2022aarXiv preprint</p>
<p>Active example selection for in-context learning. Y Zhang, S Feng, C Tan, arXiv:2211.044862022barXiv preprint</p>
<p>Large language models are humanlevel prompt engineers. Y Zhou, A I Muresanu, Z Han, K Paster, S Pitis, H Chan, J Ba, 2023</p>
<p>Promptbench: Towards evaluating the robustness of large language models on adversarial prompts. K Zhu, J Wang, J Zhou, Z Wang, H Chen, Y Wang, L Yang, W Ye, N Z Gong, Y Zhang, arXiv:2306.045282023arXiv preprint</p>
<p>Unfortunately, I won't be able to make it to the meeting tomorrow. Regrettably, I am unable to attend the meeting tomorrow. casual</p>
<p>I must depart now, farewell!" (overly formal) Alternative: "I have to go now. see you later!" (casual</p>
<p>(formal) Alternative: "I'm sorry, but I can't help you with that. I apologize, but I am unable to assist you with that matter. casual</p>
<p>(formal) Alternative: "Thanks for inviting me, but I can't make it. Thank you for the invitation, however, I am unable to attend. casual</p>
<p>(casual) Continued next page for Table 26 Continuation of Table 26 Taxonomy Animal "List all the animals from the given inputs. ## Input ##: apple, banana, orange, kiwi, grape ## Output ##. (formal) Alternative: "I think this is the best option</p>
<h2>Input ##: dog, cat, fish, bird, hamster ## Output ##: ['dog', 'cat.</h2>
<h2>Input ##: elephant, giraffe, lion, tiger, zebra ## Output ##: ['elephant', 'giraffe.</h2>
<h2>Input ##: pencil, eraser, notebook, ruler, pen ## Output ##.</h2>
<h2>Input ##: turtle, snake, lizard, frog, salamander ## Output ##: ['turtle', 'snake.</h2>
<p>Negation For each input, negate the specified part of the statement and write it as an output. </p>
<p>Output: "Gary Kubiak will not play as a quarterback in the upcoming game. Note: When negating statements with proper nouns or names. simply negate the verb or action associated with the noun or name</p>
<p>Num Verbal Convert a given number into its English word representation, including commas for thousands and negative sign if applicable. ## Input 1 ## : 1234 ## Output 1 ##. </p>
<h2>Input 2 ##. 987654321</h2>
<p>Output 2 ##: ['nine hundred and eighty-seven million six hundred and fifty-four thousand three hundred and twenty. ## , </p>
<h2>Input 3 ## : 0 ## Output 3 ##.</h2>
<h2>Input 4 ## : -42.</h2>
<h2>Output 4 ##: ['negative forty-two.</h2>
<h2>Input 5 ##: 999999999 ## Output 5 ##.</h2>
<p>Continued next page for Table 26 1. The sun is shining and the birds are singing. Output: ['positive'</p>
<p>I failed my exam and now I have to retake the class. Output: ['negative'</p>
<p>My best friend surprised me with a thoughtful gift. Output: ['positive'</p>
<p>The traffic on the highway was backed up for miles. </p>
<p>I received a promotion at work and a raise in salary. Output: ['positive'</p>
<p>A non-mystery mystery. </p>
<p>Little more than a well-mounted history lesson. </p>
<p>Output: ['positive'] Note: This prompt uses more sophisticated language analysis techniques to better understand the sentiment of the input. However, providing more context for the input is still important for accurate sentiment analysis. 26but supremely good natured. Continued next page for Table 26 Continuation of Table</p>
<p>Please use gender-neutral language and avoid using words with different connotations or meanings. If you notice any incorrect synonyms, please flag them and provide feedback for improvement. Words to avoid using as synonyms include those with different connotations or meanings, such as "ecstatic" for "happy" or "depressed" for "sad. Trans En De Translate the following English words into German. ## Input ## : happy ## Output ##. Synonym Please provide a list of synonyms for the given words that convey a similar meaning and are commonly used in everyday language. Be sure to double-check your spelling and grammar before submitting. For example, if the word is "happy. 'glücklich'</p>
<h2>Input ## : love ## Output ##.</h2>
<h2>Input ## : cat ## Output ##.</h2>
<h2>Input ## : dog ## Output ##.</h2>
<h2>Input ## : house ## Output ##.</h2>
<h2>Input ## : tree ## Output ##.</h2>
<h2>Input ## : water ## Output ##.</h2>
<h2>Input ## : sun ## Output ##.</h2>
<h2>Input ## : moon ## Output ##.</h2>
<h2>Input ## : star ## Output ##.</h2>
<p>Trans En Es Convert these English terms into their corresponding Spanish translations. ## Input ## : happy ## Output ##. 'feliz'</p>
<h2>Input ## : beach ## Output ##. 'playa'</h2>
<h2>Input ## : computer ## Output ##. 'computadora'</h2>
<h2>Input ## : book ## Output ##.</h2>
<h2>Input ## : music ## Output ##. 'música'</h2>
<p>Continued next page for Table 26 Continuation of Table 26. </p>
<p>Trans En Fr Translate the following English words into French. ## Input ## : happy ## Output ##. 'heureux'</p>
<h2>Input ## : love ## Output ##.</h2>
<h2>Input ## : family ## Output ##. 'famille'</h2>
<h2>Input ## : friend ## Output ##. 'ami'</h2>
<h2>Input ## : music ## Output ##. 'musique'</h2>
<h2>Input ## : beach ## Output ##. 'plage'</h2>
<h2>Input ## : book ## Output ##. 'livre'</h2>
<h2>Input ## : movie ## Output ##. 'film'</h2>
<h2>Input ## : food ## Output ##. 'nourriture'</h2>
<h2>Input ## : travel ## Output ##. 'voyage'</h2>            </div>
        </div>

    </div>
</body>
</html>